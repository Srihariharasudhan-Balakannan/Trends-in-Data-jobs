title,company,experience,salary,locations,description,industry,department,employment_type,skills,scraped_at
Data Analyst,FedEx,2 - 4 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nCollect, analyze, and interpret complex data sets using Python and SQL to support business objectives.\nCollaborate with stakeholders to understand business needs, formulate analytic solutions, and provide actionable insights.\nDevelop and maintain data models and reports to track key performance indicators (KPIs) and business metrics.\nCreate meaningful data visualizations to communicate findings, trends, and actionable insights to non-technical stakeholders.\nConduct exploratory data analysis and identify patterns, trends, and opportunities for business improvement.\nSupport data quality initiatives, ensuring accuracy and consistency across data sources.\nUtilize statistical and quantitative techniques to support problem-solving and business optimization efforts.\n\n\n\n\nPreferred candidate profile\n\nPython: Proficiency in data manipulation, data analysis libraries (Pandas, NumPy),and data visualization libraries (Matplotlib, Seaborn).\nSQL: Strong command of SQL for data extraction, transformation, and complex queries.\nBusiness Acumen: Ability to understand business context and objectives, aligning analytics with organizational goals.\nQuantitative Aptitude: Strong analytical and problem-solving skills, with a keen attention to detail.\nData Visualization: Basic skills in data visualization to effectively communicate insights.\nStatistical Analysis: Foundational understanding of statistical methods (e.g., regression, hypothesis testing).\nCommunication Skills: Ability to distill complex data insights into clear,actionable recommendations for stakeholders.",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'SQL', 'Python', 'Power Bi', 'Business Insights', 'Tableau', 'Data Analytics']",2025-06-12 14:02:16
Data Analyst (English Required),Peroptyx,0 - 4 years,Not Disclosed,[],"Role & responsibilities\n\nFor thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.As part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.So, whether you are a student looking to earn as you learn, a retiree looking for a new challenge a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\nIdeal Candidate\nFluent in English (Strictly Required)\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\nApply Online Today!\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['Data Analysis', 'English', 'Mapping', 'Data Analytics']",2025-06-12 14:02:18
Client Data Analyst,JPMorgan Chase Bank,0 - 7 years,Not Disclosed,['Hyderabad'],"Take a lead role in acquiring, managing and retaining meaningful relationships that deliver outstanding experience to our customers\nJob Summary\nAs a Client Data Analyst within our client management team, you will engage with clients and assist the client-facing teams to ensure all client KYC records are compliant with regulatory standards. You will take ownership to execute end-to-end operational activities needed through the periodic renewal process of all clients. You will also own the accuracy and sanctity of information with drafting and gathering of client documents and verification of client data via publicly available and internal sources at a client level prior to final review by a KYC Quality Reviewer and the client-facing team.\nJob Responsibilities\nManage and drive KYC (Renewal/New Business/Ad hoc) book of work and the process end to end.\nCollect and verify confidential client data via publicly available and internal sources to ensure compliance with regulatory requirements for US, APAC, and EU local due diligence.\nExpose yourself to renewal work in an international KYC banking environment.\nWork on records renewals end to end - i. e. , outreach and sourcing, record enrichment, follow-ups with support departments and clients.\nUnderstand the firm s KYC requirements when completing documentation inclusive of Customer Identification Program (CIP), Enhanced Due Diligence (EDD), Local Due Diligence (LDD), Specialized Due Diligence (SpDD), and Product Due Diligence requirements (PDD).\nGain knowledge of multiple client types (i. e. , Corporates, Non-Banking Financial Institutions, Non-Operating/Asset Holding Companies, Governments, Organizations, Publicly Traded Companies, Small and Large Privately Held Operating Companies).\nUnderstand product ranges from Markets - Derivatives, Equities, Funds, FX, Trusts, Treasury Services, etc. , and other investment banking products.\nMaintain clear and professional communication with clients to address any KYC-related queries or concerns.\nSupport the front-line manager with day-to-day operations, creating an effective and efficient team through continuous communication, timely feedback, and appropriate supervisory practices.\nWork closely with the clients and KYC Relationship Officer as required, to obtain all necessary supporting evidence to fulfill KYC.\nRequired Qualifications, Skills, and Capabilities\nHave 8+ years of experience in KYC / AML client-facing / middle office role managing Investment banking.\nLearn quickly and adapt to the dynamic KYC process.\nDemonstrate strong research, analytical, and comprehension skills with the ability to analyze large amounts of data.\nExhibit excellent communication skills - both verbal and written.\nComprehend and analyze information received from the client.\nPromptly escalate and resolve issues, taking end-to-end ownership of records and their dependencies.\nProactively manage and drive forward your own career, identifying personal and team training needs for development.\nPreferred Qualifications, Skills, and Capabilities\nBe detail-oriented and possess analytical skills.\nDemonstrate a strong sense of ownership and responsibility, self-reliance, and willingness to ""own"" problems and creatively find solutions.\nDevelop an environment of continuous focus on quantifiable productivity and quality.",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Analytical skills', 'Training', 'Due diligence', 'Focus', 'Data Analyst', 'Investment banking', 'Management', 'banking products', 'Operations', 'Client management']",2025-06-12 14:02:21
Client Data Analyst,JPMorgan Chase Bank,0 - 7 years,Not Disclosed,['Bengaluru'],"Take a lead role in acquiring, managing and retaining meaningful relationships that deliver outstanding experience to our customers\nJob Summary\nAs a Client Data Analyst within our client management team, you will engage with clients and assist the client-facing teams to ensure all client KYC records are compliant with regulatory standards. You will take ownership to execute end-to-end operational activities needed through the periodic renewal process of all clients. You will also own the accuracy and sanctity of information with drafting and gathering of client documents and verification of client data via publicly available and internal sources at a client level prior to final review by a KYC Quality Reviewer and the client-facing team.\nJob Responsibilities\nManage and drive KYC (Renewal/New Business/Ad hoc) book of work and the process end to end.\nCollect and verify confidential client data via publicly available and internal sources to ensure compliance with regulatory requirements for US, APAC, and EU local due diligence.\nExpose yourself to renewal work in an international KYC banking environment.\nWork on records renewals end to end - i. e. , outreach and sourcing, record enrichment, follow-ups with support departments and clients.\nUnderstand the firm s KYC requirements when completing documentation inclusive of Customer Identification Program (CIP), Enhanced Due Diligence (EDD), Local Due Diligence (LDD), Specialized Due Diligence (SpDD), and Product Due Diligence requirements (PDD).\nGain knowledge of multiple client types (i. e. , Corporates, Non-Banking Financial Institutions, Non-Operating/Asset Holding Companies, Governments, Organizations, Publicly Traded Companies, Small and Large Privately Held Operating Companies).\nUnderstand product ranges from Markets - Derivatives, Equities, Funds, FX, Trusts, Treasury Services, etc. , and other investment banking products.\nMaintain clear and professional communication with clients to address any KYC-related queries or concerns.\nSupport the front-line manager with day-to-day operations, creating an effective and efficient team through continuous communication, timely feedback, and appropriate supervisory practices.\nWork closely with the clients and KYC Relationship Officer as required, to obtain all necessary supporting evidence to fulfill KYC.\nRequired Qualifications, Skills, and Capabilities\nHave 8+ years of experience in KYC / AML client-facing / middle office role managing Investment banking.\nLearn quickly and adapt to the dynamic KYC process.\nDemonstrate strong research, analytical, and comprehension skills with the ability to analyze large amounts of data.\nExhibit excellent communication skills - both verbal and written.\nComprehend and analyze information received from the client.\nPromptly escalate and resolve issues, taking end-to-end ownership of records and their dependencies.\nProactively manage and drive forward your own career, identifying personal and team training needs for development.\nPreferred Qualifications, Skills, and Capabilities\nBe detail-oriented and possess analytical skills.\nDemonstrate a strong sense of ownership and responsibility, self-reliance, and willingness to ""own"" problems and creatively find solutions.\nDevelop an environment of continuous focus on quantifiable productivity and quality.",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Analytical skills', 'Training', 'Due diligence', 'Focus', 'Data Analyst', 'Investment banking', 'Management', 'banking products', 'Operations', 'Client management']",2025-06-12 14:02:23
Data Analyst,PwC India,4 - 8 years,Not Disclosed,"['Bengaluru', 'Mumbai (All Areas)']","If Interested, please apply in the given link : https://forms.office.com/r/h5Qzqnb1Kr\n\nJob Title: Data Analyst (4 - 8 Years Experience)\nLocation: Bengaluru/ Mumbai\nType: Full-Time\nAbout the Role:\nWe are on the lookout for a sharp, self-driven Data Analyst with a strong command of SQL, Python, and relational databases. If solving complex data problems, building efficient data pipelines, and collaborating across teams excites you - youll thrive in this role.",,,,"['Python', 'SQL', 'Data analyst']",2025-06-12 14:02:25
Data Analyst - L3,Wipro,3 - 5 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of this role is to interpret data and turn into information (reports, dashboards, interactive visualizations etc) which can offer ways to improve a business, thus affecting business decisions.\nDo\n1. Managing the technical scope of the project in line with the requirements at all stages\na. Gather information from various sources (data warehouses, database, data integration and modelling) and interpret patterns and trends\nb. Develop record management process and policies\nc. Build and maintain relationships at all levels within the client base and understand their requirements.\nd. Providing sales data, proposals, data insights and account reviews to the client base\ne. Identify areas to increase efficiency and automation of processes\nf. Set up and maintain automated data processes\ng. Identify, evaluate and implement external services and tools to support data validation and cleansing.\nh. Produce and track key performance indicators\n2. Analyze the data sets and provide adequate information\na. Liaise with internal and external clients to fully understand data content\nb. Design and carry out surveys and analyze survey data as per the customer requirement\nc. Analyze and interpret complex data sets relating to customers business and prepare reports for internal and external audiences using business analytics reporting tools\nd. Create data dashboards, graphs and visualization to showcase business performance and also provide sector and competitor benchmarking\ne. Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool\nf. Develop predictive models and share insights with the clients as per their requirement\n\nDeliver\n\nNo Performance Parameter Measure\n1. Analyses data sets and provide relevant information to the clientNo. Of automation done, On-Time Delivery, CSAT score, Zero customer escalation, data accuracy\n\nMandatory Skills: Tableau.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Tableau', 'data warehouses', 'data integration', 'Data modelling']",2025-06-12 14:02:28
Data Analyst - L3,Wipro,4 - 8 years,Not Disclosed,['Bengaluru'],"? \n\nDo\n\n1. Managing the technical scope of the project in line with the requirements at all stages\n\na. Gather information from various sources (data warehouses, database, data integration and modelling) and interpret patterns and trends\n\nb. Develop record management process and policies\n\nc. Build and maintain relationships at all levels within the client base and understand their requirements.\n\nd. Providing sales data, proposals, data insights and account reviews to the client base\n\ne. Identify areas to increase efficiency and automation of processes\n\nf. Set up and maintain automated data processes\n\ng. Identify, evaluate and implement external services and tools to support data validation and cleansing.\n\nh. Produce and track key performance indicators\n\n2. Analyze the data sets and provide adequate information\n\na. Liaise with internal and external clients to fully understand data content\n\nb. Design and carry out surveys and analyze survey data as per the customer requirement\n\nc. Analyze and interpret complex data sets relating to customer’s business and prepare reports for internal and external audiences using business analytics reporting tools\n\nd. Create data dashboards, graphs and visualization to showcase business performance and also provide sector and competitor benchmarking\n\ne. Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool\n\nf. Develop predictive models and share insights with the clients as per their requirement",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'data mining', 'data warehousing', 'business analytics', 'data integration', 'python', 'data analytics', 'data validation', 'business analysis', 'dbms', 'dashboards', 'cleansing', 'business intelligence', 'sales', 'sql', 'analytics reporting', 'tableau', 'reporting tools']",2025-06-12 14:02:30
Data Analyst,Wiley,0 - 3 years,Not Disclosed,['Noida'],"Job Description:\nData Analyst\nLocation:\nNoida, Uttar Pradesh, IND\nOur mission is to unlock human potential. We welcome you for who you are, the background you bring, and we embrace individuals who get excited about learning. Bring your experiences, your perspectives, and your passion; it s in our differences that we empower the way the world learns.\nAbout the Role:\n\n\n\n\n\n\n\n\n\n\n#LI",,,,"['Product management', 'Publishing', 'Business reporting', 'Analytical', 'Data processing', 'Data Analyst', 'data visualization', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:02:32
Data Analyst,Insuredmine Infotech India PVT LTD,1 - 4 years,3-5 Lacs P.A.,['Bengaluru( HSR Layout )'],"We are seeking a skilled Data Analyst with a preference for candidates holding any degree. The ideal candidate will possess exceptional analytical capabilities, particularly in sales analysis, financial analysis, and other business operations data analysis. Proficiency in Excel and data presentation at an advanced level is a must for this role. The incumbent will be responsible for extracting, analyzing, and interpreting data to provide actionable insights that drive strategic decision-making across various business functions.\n\nKey Responsibilities:\nConduct in-depth sales analysis to identify trends, opportunities, and areas for improvement.\nPerform financial analysis to support budgeting, forecasting, and financial planning processes.\nUtilize advanced Excel functions to manipulate and analyze large datasets efficiently.\nDevelop and maintain dashboards, reports, and data visualizations to communicate key findings effectively.\nCollaborate with cross-functional teams to understand business requirements and provide data-driven solutions.\nConduct ad-hoc analysis to address specific business questions and challenges.\nIdentify opportunities for process optimization and automation to streamline\ndata analysis workflows.\nStay updated with industry trends and best practices in data analysis and\nbusiness intelligence.\nQualifications:\nBachelor's degree in Business Administration, Statistics, Economics, Computer Science, or a related field. MBA preferred.\nProven experience (2 years) in a data analysis role, preferably within sales, finance, or business operations.\nAdvanced proficiency in Microsoft Excel, including complex formulas, pivot tables, and data visualization techniques.\nStrong analytical and problem-solving skills, with the ability to translate data into actionable insights.\nExperience working with BI tools (e.g., Tableau, Power BI) is a plus.\nExcellent communication skills with the ability to present findings and\nrecommendations to stakeholders at all levels.\nAbility to work independently and manage multiple projects simultaneously.\nAttention to detail and a commitment to delivering high-quality, accurate results.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'Data Reporting', 'Data Visualization']",2025-06-12 14:02:34
Data Analyst,Primary Healthtech,1 - 5 years,2.5-4.5 Lacs P.A.,['Noida'],"Roles and Responsibilities\nCollect data from various sources, clean it, and analyze it using statistical tools.\nCreate reports based on analysis findings to present insights to stakeholders.\nDevelop dashboards and visualizations to effectively communicate results.\nManage databases by designing schema, writing queries, and optimizing performance.\nEnsure accuracy of data through quality control measures.\nDesired Candidate Profile\n1-5 years of experience in Data Analysis or related field (Data Analytics).\nB.Tech/B.E. degree in Any Specialization.\nProficiency in SQL programming language with knowledge of database management systems like MySQL or PostgreSQL.\nStrong understanding of statistics, data interpretation, and data visualization techniques.",Industry Type: Medical Devices & Equipment,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Interpretation', 'Data Analysis', 'Data Analytics', 'Data Management', 'Data Visualization', 'Data Reporting']",2025-06-12 14:02:37
Data Analyst,HARMAN,3 - 5 years,Not Disclosed,['Bengaluru'],"Introduction: Digital Transformation Solutions (DTS)\n.\nCombine the physical and digital, making technology a more dynamic force to solve challenges and serve humanity s needs\nWork at the convergence of cross channel UX, cloud, insightful data, IoT and mobility\nEmpower companies to create new digital business models, enter new markets, and improve customer experiences\nIntroduction: Corporate",,,,"['Supply chain', 'Data analysis', 'Change management', 'DTS', 'Manager Technology', 'Agile', 'Healthcare', 'Data analytics', 'Secondary research', 'SQL']",2025-06-12 14:02:39
Data Analyst,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Bengaluru'],"Req ID: 327898\n\nWe are currently seeking a Data Analyst to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesKey Responsibilities:\nConduct in-depth revenue analysis to identify trends and opportunities for growth.\nPerform P&L attribution, analyzing variances and providing detailed insights to stakeholders.\nExecute Independent Price Verification (IPV) processes to ensure the accuracy and consistency of financial data.\nLead data reconciliation efforts by identifying and resolving discrepancies in financial datasets.\nCollaborate with finance, operations, and IT teams to develop efficient processes and reporting mechanisms.\nDocument business requirements, workflows, and processes, translating them into technical specifications where necessary.\nDevelop and maintain financial models to support decision-making processes.\nMonitor financial performance and prepare detailed reports for senior management.\n\nMinimum Skills RequiredQualifications:\nBachelor's degree in Finance, Economics, Business, or a related field (Master""™s preferred).\nProven experience as a Business Analyst in the finance domain, with expertise in revenue, P&L attribution, IPV, and data reconciliation.\nStrong knowledge of financial principles, data analysis, and reporting tools.\nProficiency in data analytics platforms such as Excel, SQL, or Tableau.\nExcellent problem-solving skills and attention to detail.\nStrong communication and interpersonal skills for effective stakeholder management.\nAbility to work in a fast-paced, deadline-driven environment.\nPreferred\n\nSkills:\n\nCertification in Business Analysis (e.g., CBAP, CCBA) or related field is a plus.\nFamiliarity with financial systems and accounting software.\nExperience in Agile or Scrum methodologies.""",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data analysis', 'data reconciliation', 'stakeholder management', 'reporting tools', 'cbap', 'business analysis', 'variance analysis', 'ipv', 'sql', 'business requirement analysis', 'revenue', 'tableau', 'workflow analysis', 'scrum', 'technical specifications', 'agile']",2025-06-12 14:02:41
Data Analyst,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Bengaluru'],"Req ID: 327858\n\nWe are currently seeking a Data Analyst to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nJob DutiesKey ResponsibilitiesConduct in-depth revenue analysis to identify trends and opportunities for growth. Perform P&L attribution, analyzing variances and providing detailed insights to stakeholders. Execute Independent Price Verification (IPV) processes to ensure the accuracy and consistency of financial data. Lead data reconciliation efforts by identifying and resolving discrepancies in financial datasets. Collaborate with finance, operations, and IT teams to develop efficient processes and reporting mechanisms. Document business requirements, workflows, and processes, translating them into technical specifications where necessary. Develop and maintain financial models to support decision-making processes. Monitor financial performance and prepare detailed reports for senior management. Minimum Skills RequiredQualificationsBachelor's degree in Finance, Economics, Business, or a related field (Master""™s preferred). Proven experience as a Business Analyst in the finance domain, with expertise in revenue, P&L attribution, IPV, and data reconciliation. Strong knowledge of financial principles, data analysis, and reporting tools. Proficiency in data analytics platforms such as Excel, SQL, or Tableau. Excellent problem-solving skills and attention to detail. Strong communication and interpersonal skills for effective stakeholder management. Ability to work in a fast-paced, deadline-driven environment. Preferred\n\nSkills:\nCertification in Business Analysis (e.g., CBAP, CCBA) or related field is a plus. Familiarity with financial systems and accounting software. Experience in Agile or Scrum methodologies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data analysis', 'data reconciliation', 'stakeholder management', 'reporting tools', 'cbap', 'revenue analysis', 'business analysis', 'ipv', 'sql', 'business requirement analysis', 'revenue', 'tableau', 'workflow analysis', 'scrum', 'technical specifications', 'agile']",2025-06-12 14:02:44
Data Analyst,Brunel,4 - 8 years,Not Disclosed,['Bengaluru'],"Position: Data Analyst.\nContract: On Contract Role.\nDesign and develop dashboards and automation tools by programing in MS Access, MS Excel, and Tableau/Power BI dashboards for solutions in conjunction with multiple data sources such as SQL Database, SAP Hana, SharePoint etc.\nMaintain all supported solutions as defined by requestors located globally (AP, EU and NA zones).\nWork effectively with the business with regards to fixing breaks in the process and support changes.\nDemonstrate initiatives to identify process efficiencies.\nUnderstand business process changes and impact on the tools design.\nEscalate any design issues or conflicting priorities to ensure timely product delivery.\nWe are recruiting a Data Analyst to join one of our leading multinational clients and their expanding team. This position is based in Bangalore and offers an excellent opportunity for experienced proposal management professionals in the Conventional Energy sector.\nShould possess strong verbal communication and writing skills in English.\nKeen attention to details, strong analytical skills and problem-solving skills.\nProficient in MS Excel and Sharepoint.\nGood technical understanding of database/application design, development cycles and structural principles.\nAdvanced programming skills in Microsoft products: Access, advance Excel: (powerpivot, power query, power view), VBA Programming.\nGood technical knowledge or able to learn on Data Analytics platforms and auto process workflow: ServiceNow, PowerBI, Tableau.\nGood technical knowledge or able to learn on SQL Database server, Stored Procedures.",Industry Type: Power,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'tableau', 'Excel', 'MS Access', 'SQL database', 'Workflow', 'Data Analyst', 'Data analytics', 'Stored procedures', 'microsoft']",2025-06-12 14:02:46
"Data Analyst-Mapping, Modelling",Capco,1 - 8 years,Not Disclosed,['Bengaluru'],"Data warehousing migration programs that involve cross geography and multi-functional delivery\nTo align project timeline to ensure project success delivery.\nProvide support to Data Analysis, Mapping and Profiling\nPerform data requirement gathering, analysis and documentation.\nMapping of data attributes from different source systems to the target data models and ensuring the same business rules are followed\ninterpreting use case requirement and design of target data model/ data mart\nProfiling of data attributes to assess data quality that affects referential integrity and provide remediation recommendations.\nEnsures that data use is complies to the data architecture principles including golden sources and standard reference data.\nData modelling for better data integration within the data warehouse platform\nKey responsibilities are:\nTo work together with squad members for success delivery of projects that includes managing different stakeholders like business, other technology teams and internal development teams; Ensuring delivery is align to the timeline for each milestone.\nTo work closely with various stakeholders in analyzing the user requirements, profiling data, and finalizing the requirements for delivery (Do the right thing).\nTransforming data requirements into data models through design and modelling aligning to the data warehousing standards and processes.\nCreate data mapping templates for Data Model mapping.\nProfile data to assess data quality, suitability, and cardinality.\nSupport data store s inbound and/or outbound development activities - provide guidance and clarification to development team on the mapping developed.\nResponsible to provide direction on solution from a standard product / architecture perspective Participate in key decision-making discussions liaising with business stakeholders\nPerform SIT and support UAT.\nResponsible to manage the change request effectively and efficiently during the project delivery with all agreed controls\nAlign with the bank process and standards and ensure there are no deviations Deliver Functional documentation to the development team while collating the requirements from various stakeholders To ensure alignment to Data Quality Management Framework that includes Data Management through lineage documentation, data control to ensure data quality securities.",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Outbound', 'Data analysis', 'Data management', 'Management consulting', 'Data Analyst', 'Data quality', 'data mapping', 'Project delivery', 'Financial services', 'Data architecture']",2025-06-12 14:02:49
Data Analyst,Capgemini,4 - 6 years,Not Disclosed,['Bengaluru'],"Overview\nWe are seeking a highly motivated Data Analyst with strong technical and analytical skills to join our ADAS (Advanced Driver Assistance Systems) team. This role involves working with large-scale data from vehicle systems to drive insights, support data science initiatives, and contribute to the development of safer and smarter automotive technologies.\n\nResponsibilities:\nPerform data cleansing, aggregation, and analysis on large, complex datasets related to ADAS components and systems.\nBuild, maintain, and update dashboards and data visualizations to communicate insights effectively (Power BI preferred).\nDevelop and optimize data pipelines and ETL processes.\nCreate and maintain technical documentation, including data catalogs and process documentation.\nCollaborate with cross-functional teams including data scientists, software engineers, and system engineers.\nContribute actively to the internal data science community by sharing knowledge, tools, and best practices.\nWork independently on assigned projects, managing priorities and delivering results in a dynamic, unstructured environment.Required Qualifications:\nBachelors degree or higher in Computer Science, Data Science, or a related field.\nMinimum 3 years of experience in the IT industry, with at least 2 years in data analytics or data engineering roles.\nProficient in Python or Pyspark with solid software development fundamentals.\nStrong experience with SQL and relational databases.\nHands-on experience with data science, data engineering, or machine learning techniques.\nKnowledge of data modeling, data warehousing concepts, and ETL processes.\nFamiliarity with data visualization tools (Power BI preferred).\nBasic understanding of cloud platforms such as Azure or AWS.\nFundamental knowledge of ADAS functionalities is a plus.\nStrong problem-solving skills, self-driven attitude, and the ability to manage projects independently.Preferred Skills:\nExperience in automotive data or working with sensor data (e.g., radar, lidar, cameras).\nFamiliarity with agile development methodologies.\nUnderstanding of big data tools and platforms such as Databricks or Spark. Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.- Grade SpecificIs fully competent in it's own area and has a deep understanding of related programming concepts software design and software development principles. Works autonomously with minimal supervision. Able to act as a key contributor in a complex environment, lead the activities of a team for software design and software development. Acts proactively to understand internal/external client needs and offers advice even when not asked. Able to assess and adapt to project issues, formulate innovative solutions, work under pressure and drive team to succeed against its technical and commercial goals. Aware of profitability needs and may manage costs for specific project/work area. Explains difficult concepts to a variety of audiences to ensure meaning is understood. Motivates other team members and creates informal networks with key contacts outside own area.Skills (competencies)Verbal Communication",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'software development', 'pyspark', 'relational databases', 'sql', 'data analytics', 'software design', 'data warehousing', 'microsoft azure', 'power bi', 'machine learning', 'data engineering', 'data bricks', 'data science', 'data modeling', 'spark', 'adas', 'agile', 'etl', 'aws', 'big data']",2025-06-12 14:02:52
Data Analyst,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Pune'],"Req ID: 324676\n\nWe are currently seeking a Data Analyst to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nKey Responsibilities:\n\nExtract, transform, and load (ETL) data from various sources, ensuring data quality, integrity, and accuracy.\n\nPerform data cleansing, validation, and preprocessing to prepare structured and unstructured data for analysis.\n\nDevelop and execute queries, scripts, and data manipulation tasks using SQL, Python, or other relevant tools.\n\nAnalyze large datasets to identify trends, patterns, and correlations, drawing meaningful conclusions that inform business decisions.\n\nCreate clear and concise data visualizations, dashboards, and reports to communicate findings effectively to stakeholders.\n\nCollaborate with clients and cross-functional teams to gather and understand data requirements, translating them into actionable insights.\n\nWork closely with other departments to support their data needs.\n\nCollaborate with Data Scientists and other analysts to support predictive modeling, machine learning, and statistical analysis.\n\nContinuously monitor data quality and proactively identify anomalies or discrepancies, recommending corrective actions.\n\nStay up-to-date with industry trends, emerging technologies, and best practices to enhance analytical techniques.\n\nAssist in the identification and implementation of process improvements to streamline data workflows and analysis.\n\nBasic Qualifications:\n\n3 + years of proficiency in data analysis tools such as [Tools - e.g., Excel, SQL, R, Python].\n\n3+ years of experience supporting Software Engineering, Data Engineering, or Data Analytics projects.\n\n2+ years of experience leading a team supporting data related projects to develop end-to-end technical solutions.\n\nUndergraduate or Graduate degree preferred\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nStrong proficiency in data analysis tools such as Python, SQL, Talend (any ETL).\n\nExperience with data visualization tools like PowerBI.\n\nExperience with cloud data platforms .\n\nFamiliarity with ETL (Extract, Transform, Load) processes and tools.\n\nKnowledge of machine learning techniques and tools.\n\nExperience in a specific industry (e.g., financial services, healthcare, manufacturing) can be a plus.\n\nUnderstanding of data governance and data privacy regulations.\n\nAbility to query and manipulate databases and data warehouses.\n\nExcellent analytical and problem-solving skills.\n\nStrong communication skills with the ability to explain complex data insights to non-technical stakeholders.\n\nDetail-oriented with a commitment to accuracy.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'data analytics', 'data engineering', 'analysis tools', 'software engineering', 'python', 'data manipulation', 'talend', 'power bi', 'data warehousing', 'machine learning', 'dashboards', 'sql', 'data cleansing', 'data quality', 'r', 'predictive modeling', 'data visualization', 'etl']",2025-06-12 14:02:54
Data Analyst -Python,Sopra Steria,3 - 5 years,Not Disclosed,['Chennai'],"Experience working in large Software Development Teams\nKnowledge and experience in Agile Delivery mechanisms \nWork with business stakeholders, SCRUM masters, Designers and testers in SCRUM team.\nProficient in English language with ability to lead stakeholder conversations.\nExperience in generating insights through data and articulating stories addressing business problems.\nTotal Experience Expected: 6-8 years\n",,,,"['data mining', 'vlookup', 'sql', 'analytics', 'data science', 'advanced excel', 'data visualization', 'technical skills', 'python', 'macros', 'data analysis', 'data analytics', 'sas', 'insights', 'predictive analytics', 'business analysis', 'machine learning', 'excel', 'tableau', 'r', 'vba', 'predictive modeling', 'scrum', 'agile', 'statistics']",2025-06-12 14:02:57
Data Analyst (8+ years of experience),Western Digital,0 - 7 years,Not Disclosed,['Bengaluru'],"ESSENTIAL DUTIES AND RESPONSIBILITIES\nGathering data from diverse sources, including databases, APIs, and web scraping.\nPossessing deep knowledge of data analytics principles, tools, and technologies.\nHandling missing values, correcting errors, and ensuring data consistency, data quality, and optimizing data performance.\nCreate and maintain data models that structure and organize data within a domain, ensuring clarity and consistency.\nCreate data products, designed to solve specific business problems within a domain.\nPerforming statistical analysis and modeling to identify trends, patterns, and relationships in the data.\nPreparing reports, presentations, and dashboards to communicate insights and findings.\nUsing data to identify and solve business problems, improve processes, and make data-driven decisions.\nCollaborating with cross-functional teams including, Data Engineers, Data scientists, Business Analysts, Solution Architects, IT & Business teams.\nDocument and maintain end to end data flows, Data Lineage, Data Catalog for various data marts.\nBe a liaison between solution architects, BSA s and data engineers to ensure compliance to standards of Data integrations, data management and review the data solutions.\nStay updated with the latest industry trends and best practices, sharing knowledge and encourage team to continuously improve their skill s",Industry Type: Electronic Components / Semiconductors,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Data analysis', 'ERP', 'Data management', 'Data modeling', 'Data quality', 'Data mining', 'Business intelligence', 'CRM', 'SQL']",2025-06-12 14:02:59
Data Analyst III,Sadup Soft,5 - 8 years,Not Disclosed,['Bengaluru'],"- Minimum of 5 years of experience in data analysis with a strong SQL background.\n\n- Solid experience in creating and extracting metrics, and writing complex SQL scripts.\n\n- Hands-on experience with Tableau, Looker, or any equivalent data visualization tools.\n\n- Strong skills in SQL and Excel, with the ability to quickly learn other analytic tools.\n\n- Knowledge of Python and ML algorithms is a plus.\n\nResponsibilities :\n\n- Perform detailed data analysis and validation to ensure data integrity and accuracy.\n\n- Extract and create meaningful metrics to support business decisions\n\n- Design, develop, and maintain interactive dashboards using Tableau, Looker, or equivalent tools.\n\n- Translate complex data into visually appealing and actionable insights.\n\n- Document queries, reports, and analytical processes clearly and accurately.\n\n- Create detailed reports and presentations to communicate findings to stakeholders.\n\n- Work closely with cross-functional teams to understand data requirements and provide analytical support.\n\n- Communicate findings effectively and provide actionable recommendations.\n\n- Utilize SQL and Excel extensively for data analysis and reporting.\n\n- Apply Python and ML algorithms as needed for advanced analytics (preferred but not mandatory)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Data Integrity', 'Data Analyst', 'Data Visualization Tools', 'Tableau', 'Data Analytics', 'Looker']",2025-06-12 14:03:01
"Data Analytics Fresher , Data Analyst Fresher",Ablycon Global Angalore,0 - 1 years,4.25-6.5 Lacs P.A.,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","NOTE- Please do not call. Apply through Naukri or email your resume at ankit@ablyconglobal.com. or whatsapp on 9821833955 - Don't CALL Please .\n\n\nJob Title: Data Analytics Fresher\nEmployment Type: Full-Time\nExperience: 0 - 1 Year\nQualification- ANY UG , ANY PG\n\n\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented individual to join our Data Analytics team as a Data Analyst Fresher. This position offers a launchpad into the world of data analytics. Youll work on structured and unstructured datasets, assist in building dashboards and models, and get practical exposure to tools like SQL, Python, and BI platforms. Ideal for someone with a strong analytical foundation and a hunger to grow into a full-stack data professional.\n\nKey Responsibilities:\n\nCollect, organize, and analyze large datasets from various internal and external sources.\nAssist in preparing dashboards, reports, and visualizations to present insights and findings.\nSupport the team in identifying trends, anomalies, and patterns that impact business performance.\nWork with different departments (marketing, sales, operations, etc.) to understand data requirements.\nPerform exploratory data analysis (EDA) to help refine business strategies.\nMaintain and ensure data integrity and consistency across databases and reporting tools.\nSupport the automation of repetitive reporting processes using scripting or BI tools.\n\nRequired Skills & Qualifications:\n\nStrong analytical and problem-solving skills.\nProficiency in Excel and a basic understanding of SQL.\nFamiliarity with data visualization tools (e.g., Tableau, Power BI) is a plus.\nKnowledge of programming languages such as Python or R is an advantage.\nStrong communication skills to explain technical results to non-technical audiences.\nAttention to detail and a strong sense of responsibility.\nEagerness to learn new tools, technologies, and business domains.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Data Analytics', 'Business Analytics', 'Power Bi', 'Artificial Intelligence', 'Data Interpretation', 'Data Management', 'Data Extraction', 'Tableau', 'Machine Learning', 'Statistics', 'data analyst', 'SQL', 'Data Science', 'Excel', 'MySQL', 'Data Analysis', 'Data Visualization', 'Data Processing', 'Python']",2025-06-12 14:03:03
"Data Analyst, Staff",Qualcomm,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Miscellaneous Group, Miscellaneous Group > Data Analyst\n \n\nQualcomm Overview: \nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.\n\nGeneral Summary:\n\nAbout the Team\n\nQualcomm's People Analytics team plays a crucial role in transforming data into strategic workforce insights that drive HR and business decisions. As part of this lean but high-impact team, you will have the opportunity to analyze workforce trends, ensure data accuracy, and collaborate with key stakeholders to enhance our data ecosystem. This role is ideal for a generalist who thrives in a fast-paced, evolving environment""”someone who can independently conduct data analyses, communicate insights effectively, and work cross-functionally to enhance our People Analytics infrastructure.\n\nWhy Join Us\n\n\nEnd-to-End ImpactWork on the full analytics cycle""”from data extraction to insight generation""”driving meaningful HR and business decisions.\n\n\nCollaboration at ScalePartner with HR leaders, IT, and other analysts to ensure seamless data integration and analytics excellence.\n\n\nData-Driven CultureBe a key player in refining our data lake, ensuring data integrity, and influencing data governance efforts.\n\n\nProfessional GrowthGain exposure to multiple areas of people analytics, including analytics, storytelling, and stakeholder engagement.\n\n\nKey Responsibilities\n\n\nPeople Analytics & Insights\nAnalyze HR and workforce data to identify trends, generate insights, and provide recommendations to business and HR leaders.\nDevelop thoughtful insights to support ongoing HR and business decision-making.\nPresent findings in a clear and compelling way to stakeholders at various levels, including senior leadership.\n\n\nData Quality & Governance\nEnsure accuracy, consistency, and completeness of data when pulling from the data lake and other sources.\nIdentify and troubleshoot data inconsistencies, collaborating with IT and other teams to resolve issues.\nDocument and maintain data definitions, sources, and reporting standards to drive consistency across analytics initiatives.\n\n\nCollaboration & Stakeholder Management\nWork closely with other analysts on the team to align methodologies, share best practices, and enhance analytical capabilities.\nAct as a bridge between People Analytics, HR, and IT teams to define and communicate data requirements.\nPartner with IT and data engineering teams to improve data infrastructure and expand available datasets.\n\n\nQualifications\n\nRequired4-7 years experience in a People Analytics focused role\n\n\nAnalytical & Technical Skills\nStrong ability to analyze, interpret, and visualize HR and workforce data to drive insights.\nExperience working with large datasets and ensuring data integrity.\nProficiency in Excel and at least one data visualization tool (e.g., Tableau, Power BI).\n\n\nCommunication & Stakeholder Management\nAbility to communicate data insights effectively to both technical and non-technical audiences.\nStrong documentation skills to define and communicate data requirements clearly.\nExperience collaborating with cross-functional teams, including HR, IT, and business stakeholders.\n\n\nPreferred:\n\n\nTechnical Proficiency\nExperience with SQL, Python, or R for data manipulation and analysis.\nFamiliarity with HR systems (e.g., Workday) and cloud-based data platforms.\n\n\nPeople Analytics Expertise\nPrior experience in HR analytics, workforce planning, or related fields.\nUnderstanding of key HR metrics and workforce trends (e.g., turnover, engagement, diversity analytics).\n\n\nAdditional Information\nThis is an office-based position (4 days a week onsite) with possible locations that may include India and Mexico",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'people analytics', 'documentation', 'tableau', 'data integration tools', 'hiring', 'data warehousing', 'data architecture', 'sourcing', 'jquery', 'staffing', 'plsql', 'oracle 10g', 'java', 'etl tool', 'html', 'etl', 'mongodb', 'python', 'oracle', 'power bi', 'hrsd', 'r', 'node.js', 'hr analytics', 'angularjs']",2025-06-12 14:03:06
Analyst - Data Analytics,AMERICAN EXPRESS,0 - 4 years,Not Disclosed,['Gurugram'],The American Express Enterprise Digital Experimentation & Analytics (EDEA) leads the Enterprise Product Analytics and Experimentation charter for Brand & Performance Marketing and Digital Acquisition & Membership experiences as we'll as Enterprise Platforms. The focus of this collaborative team is to drive growth by enabling efficiencies in paid performance channels & evolve our digital experiences with actionable insights & analytics. The team specializes in using data around digital product usage to drive improvements in the acquisition customer experience to deliver higher satisfaction and business value.\n,,,,"['Mining', 'Career development', 'Finance', 'Analytical', 'Data processing', 'Analytics', 'SQL']",2025-06-12 14:03:08
Data Analyst - Odia Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\n\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\n\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\n\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Odia.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['Data Analysis', 'English', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:10
Data Analyst - Urdu Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Urdu.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Urdu', 'Data Analysis', 'Research Analysis', 'Data Interpretation', 'Analytical', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:12
Data Analyst - Marathi Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Marathi.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['English', 'Data Analysis', 'Marathi', 'Research Analysis', 'Data Management', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:14
Data Analyst - Bangla Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\nIdeal Candidate\nFluent in English and Bangla.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Bangla', 'Data Analysis', 'Data Research', 'Research Analysis', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:16
Data Analyst - Gujarati Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Gujarati.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply.\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Freelance/Homebased","['English', 'Gujarati', 'Data Interpretation', 'Data Analysis', 'Research Analysis', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:19
Data Analyst - Marathi Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"O)For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Marathi.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Data Interpretation', 'Data Analysis', 'Marathi', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:21
Data Analyst - Malayalam Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Malayalam.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Malayalam', 'Data Analysis', 'Data Extraction', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:23
Business Data Analyst,CGI,5 - 8 years,Not Disclosed,['Hyderabad'],"Business Data Analyst - HealthCare\n\nJob Summary\nWe are seeking an experienced and results-driven Business Data Analyst with 5+ years of hands-on experience in data analytics, visualization, and business insight generation. This role is ideal for someone who thrives at the intersection of business and datatranslating complex data sets into compelling insights, dashboards, and strategies that support decision-making across the organization.\nYou will collaborate closely with stakeholders across departments to identify business needs, design and build analytical solutions, and tell compelling data stories using advanced visualization tools.\nKey Responsibilities\nData Analytics & Insights Analyze large and complex data sets to identify trends, anomalies, and opportunities that help drive business strategy and operational efficiency.\n• Dashboard Development & Data Visualization Design, develop, and maintain interactive dashboards and visual reports using tools like Power BI, Tableau, or Looker to enable data-driven decisions.\n• Business Stakeholder Engagement Collaborate with cross-functional teams to understand business goals, define metrics, and convert ambiguous requirements into concrete analytical deliverables.\n• KPI Definition & Performance Monitoring Define, track, and report key performance indicators (KPIs), ensuring alignment with business objectives and consistent measurement across teams.\n• Data Modeling & Reporting Automation Work with data engineering and BI teams to create scalable, reusable data models and automate recurring reports and analysis processes.\n• Storytelling with Data Communicate findings through clear narratives supported by data visualizations and actionable recommendations to both technical and non-technical audiences.\n• Data Quality & Governance Ensure accuracy, consistency, and integrity of data through validation, testing, and documentation practices.\nRequired Qualifications\nBachelor’s or Master’s degree in Business, Economics, Statistics, Computer Science, Information Systems, or a related field.\n• 5+ years of professional experience in a data analyst or business analyst role with a focus on data visualization and analytics.\n• Proficiency in data visualization tools: Power BI, Tableau, Looker (at least one).\n• Strong experience in SQL and working with relational databases to extract, manipulate, and analyze data.\n• Deep understanding of business processes, KPIs, and analytical methods.\n• Excellent problem-solving skills with attention to detail and accuracy.\n• Strong communication and stakeholder management skills with the ability to explain technical concepts in a clear and business-friendly manner.\n• Experience working in Agile or fast-paced environments.\nPreferred Qualifications\nExperience working with cloud data platforms (e.g., Snowflake, BigQuery, Redshift).\n• Exposure to Python or R for data manipulation and statistical analysis.\n• Knowledge of data warehousing, dimensional modeling, or ELT/ETL processes.\n• Domain experience in Healthcare is a plus.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Bigquery', 'Snowflake', 'Data Warehousing', 'Redshift', 'Python', 'ETL']",2025-06-12 14:03:25
Business Partner Master Data Analyst Associate,Westlake Epoxy,2 - 7 years,Not Disclosed,['Bengaluru'],"Westlake offers you the potential to enrich your work life and career experience in an entrepreneurial environment. We work together to enhance peoples lives through our products and presence in the communities in which we operate.\nBusiness Partner Master Data Analyst Associate\nBusiness Partner Master Data Analyst is part of a global team who establishes and follows procedures that maintain the integrity of data for Customer and Vendor master data in SAP. These procedures allow business objectives to be met and to be compliant to (regional) Government regulations and Westlake Epoxy regulations. The Customer and Vendor Master Analyst role is the key for setting up a good foundation for further execution of the business processes.\nEssential Functions\nTasks:\nCreate, change, or delete Customer/Supplier records following approval workflows and document verification.\nManage partner functions and ensure compliance with SOPs and Westlake Safety & Integrity policies.\nSystem Skills:\nProficiently use systems like ECC, S4 HANA, and Fiori.\nData Quality:\nMaintain high-quality master data according to KPIs.\nRegularly check and verify system parameters against process updates.\nPerform mass changes to master data under supervision.\nKey Relationships / Collaboration:\nWork closely with Customer Service, Master Data, IT, Procurement Operations, Procurement, and Finance.\nSupport:\nCommunicate with internal customers based on business needs.\nValidate active accounts according to business rules.\nBlock inactive accounts in SAP during Annual block/deletion program.\nBusiness Support:\nProactively address system errors or process gaps by escalating to relevant key users for resolution.\nQualification:\nAny degree with minimum 2 years experience in a functional area.\nFluent language skills in English, both verbal and written.\nProficient in Microsoft Office and Outlook.\nSAP functional knowledge required i.e. Master Data.\nIntermediate skills in Microsoft Excel.\nPositive attitude and strong customer focus.\nGood organizational and communication skills.\nProactive and solution focused.\nAttentive to details, able to work accurately.\nAbility to work under pressure, time sensitive environment showing high level of flexibility.\nTeam player.\nWestlake is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to any characteristics protected by applicable legislation.\nIf you are an active Westlake employee (or an employee of any Westlake affiliates), please do not apply here. You will apply via the Jobs Hub application in Workday.",Industry Type: Chemicals,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Master Analyst', 'SAP', 'Excel', 'IT procurement', 'business rules', 'document verification', 'Data quality', 'Data Analyst', 'Customer service', 'MS Office']",2025-06-12 14:03:27
"Senior Python Developer (Machine Learning,Data Analysis,Visualization)",Synechron,3 - 5 years,Not Disclosed,"['Pune', 'Hinjewadi']","Software Requirements\nRequired Skills:\nProficiency in Python (version 3.6+) with experience in data analysis, manipulation, and scripting\nKnowledge of SQL for data extraction, transformation, and database querying\nExperience with data visualization tools such as PowerBI, Tableau, or QlikView\nFamiliarity with AI and Machine Learning frameworks such as TensorFlow, Keras, PyTorch, or equivalent\nHands-on experience in developing, deploying, and optimizing machine learning models\nPreferred Skills:\nExperience with R for data analysis\nFamiliarity with cloud platforms like AWS, Azure, or GCP for deploying AI solutions\nKnowledge of version control systems such as Git\nOverall Responsibilities\nAnalyze, interpret, and visualize large and complex datasets to extract actionable insights\nDesign, develop, and implement machine learning and AI models for predictive and prescriptive analytics\nCollaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions\nCommunicate findings, insights, and recommendations via reports, dashboards, and presentations to stakeholders\nEvaluate and refine models and algorithms to maximize accuracy, efficiency, and impact\nStay informed on emerging AI, Data Science, and analytics trends and incorporate best practices into projects\nSupport automation efforts, optimize data pipelines, and enhance existing analytical workflows\nContribute to organizational learning by sharing knowledge and mentoring team members\nStrategic objectives:\nDrive innovation through the application of AI and machine learning\nEnable data-driven decision-making across business units\nImprove operational efficiencies and business outcomes\nPerformance outcomes:\nAccurate, robust, and scalable AI models\nHigh-quality insights delivered on time and aligned with business needs\nWell-documented solutions and knowledge-sharing artifacts\nTechnical Skills (By Category)\nProgramming Languages (Essential):\nPython (required); experience with R is a plus\nSQL (required); experience with data manipulation and querying\nData Analysis & Visualization Tools (Essential):\nPowerBI, Tableau, or QlikView\nFrameworks & Libraries (Essential):\nTensorFlow, Keras, PyTorch, or similar frameworks for AI/ML development\nData Management & Databases (Essential):\nRelational databases (e.g., MySQL, PostgreSQL, Oracle)\nData extraction and transformation (ETL processes)\nCloud & Deployment (Preferred):\nExperience deploying models on cloud platforms such as AWS, Azure, GCP\nDevelopment & Version Control (Preferred):\nGit for code versioning\nOther Skills:\nStrong statistical knowledge and experience with data preprocessing, feature engineering\nFamiliarity with agile development methodologies\nExperience Requirements\n3 to 5 years of relevant experience in AI, Data Science, or Data Analytics roles\nProven track record applying machine learning techniques to real-world problems\nExperience working with large datasets and scalable data pipelines\nExperience collaborating with cross-functional teams to deliver analytics-driven solutions\nIndustry experience in finance, healthcare, retail, or similar data-rich sectors is preferred\nAlternative pathways:\nCandidates with extensive AI & ML project experience, strong programming skills, and relevant certifications can be considered with slightly varied years of experience\nDay-to-Day Activities\nCollect, clean, and explore large datasets to identify patterns and insights\nDevelop and tune machine learning models to address business problems\nCollaborate with business analysts, data engineers, and product owners to align technical solutions with organizational goals\nDocument methodologies, code, and analytical findings to ensure reproducibility and knowledge sharing\nCreate dashboards, visualizations, and reports to communicate insights effectively\nEvaluate model performance regularly and optimize models for accuracy and efficiency\nParticipate in team meetings, project planning, and review sessions\nKeep abreast of advancements in AI/ML technologies, tools, and best practices\nQualifications\nBachelors degree in Computer Science, Data Science, Statistics, or related field\nMasters degree or higher in AI, Data Science, or related disciplines is a plus\nProfessional certifications in AI/ML (e.g., TensorFlow Developer, AWS Machine Learning Specialty) are advantageous\nWilling to learn new tools and stay updated with emerging AI trends\nAbility to work independently and collaborate effectively in a dynamic environment\nProfessional Competencies\nAnalytical and problem-solving mindset with a focus on actionable insights\nExcellent verbal and written communication skills for diverse audiences\nStrong interpersonal skills and stakeholder management\nAdaptability to fast-changing technology landscapes\nGrowth mindset with continuous learning enthusiasm\nOrganizational skills to handle multiple projects and priorities simultaneously\nInnovation-driven approach and proactive problem resolution",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'PostgreSQL', 'MySQL', 'Data Analysis', 'Data Visualization', 'Oracle', 'ETL', 'Machine Learning']",2025-06-12 14:03:30
Business Data Analyst,NetApp,8 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary\nWe are seeking a highly skilled and experienced Senior Business Data Analyst to join our Entitlement and Install Base Master team. You will play a crucial role in driving the Install Base (IB) data strategy and vision. Your deep understanding of Install Base and Renewals business processes will be instrumental in ensuring accurate and efficient management of our Install Base Data.\nJob Requirements\nDrive the Install Base data strategy and vision, collaborating with cross-functional teams to define and implement data management processes and standards.\nDevelop a comprehensive understanding of the Install Base and Renewals business, including key metrics, processes, and customer lifecycles.\nDrive Enterprise projects ensuring alignment with organizational goals and objectives.\nCollaborate with stakeholders to gather requirements and translate business needs into technical solutions for Install Base data management.\nCollaborate with cross-functional teams to define and implement data governance policies and procedures.\nPerform in-depth data analysis and validation to identify trends, patterns, and insights that drive business decision-making.\nCollaborate with IT teams to enhance data systems and tools supporting Install Base data management, ensuring data quality and accessibility.\nProvide guidance and support to cross-functional teams on Install Base data-related matters, acting as a subject matter expert.\nIdentify opportunities for process improvements and automation to streamline Install Base data management and enhance operational efficiency.\nStay up-to-date with industry trends and best practices in Install Base and Renewals business processes and data management.\nCoach and mentor team members to foster their professional growth and ensure smooth operations, promoting a collaborative and high-performing environment.\n",,,,"['data analysis', 'data management', 'analytical', 'workflow', 'business requirements', 'install base', 'sql querying', 'renewals', 'relational databases', 'sql', 'data cleansing', 'data quality', 'business process', 'management', 'collaboration', 'business data analysis', 'data governance', 'communication skills']",2025-06-12 14:03:32
MDM Data Analyst / Steward Lead,Gallagher Service Center (GSC),3 - 7 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\n\nThe MDM Analyst / Data Steward works closely with business stakeholders to understand and gather data requirements, develop data models and database designs, and define and implement data standards, policies, and procedures. This role also implements any rules inside of the MDM tool to improve the data, performs deduplication projects to develop golden records, and overall works towards improving the quality of data in the domain assigned.\n\nRequired skills :\nTechnical Skills: Proficiency in MDM tools and technologies such as Informatica MDM, CluedIn, or similar platforms is essential. Familiarity with data modeling, data integration, and data quality control techniques is also important. Experience with data governance platforms like Collibra and Alation can be beneficial1.\nAnalytical Skills: Strong analytical and problem-solving skills are crucial for interpreting and working with large volumes of data. The ability to translate complex business requirements into practical MDM solutions is also necessary.\nData Management: Experience in designing, implementing, and maintaining master data management systems and solutions. This includes conducting data cleansing, data auditing, and data validation activities.\nCommunication and Collaboration: Excellent communication and interpersonal skills to effectively collaborate with business stakeholders, IT teams, and other departments.\nData Governance: In-depth knowledge of data governance, data quality, and data integration principles. The ability to develop and implement data management processes and policies is essential.\nEducational Background: A Bachelor's or Master's degree in Computer Science, Information Systems, Data Science, or a related field is typically required1.\nCertifications: Certification in the MDM domain (e.g., Certified MDM Professional) can be a plus\n\nKey Skills:\nBecome the expert at the assigned domain of data\nUnderstand all source systems feeding into the MDM\nWrite documentation of stewardship for the domain\nDevelop rules and standards for the domain of data\nGenerate measures of improvement to demonstrate to the business the quality of the data\n\nWe are seeking candidates who can join immediately or within a maximum of 30 days' notice.\nMinimum of 3+ years of relevant experience is required.\nCandidates who are willing to relocate to Bangalore or are already based in Bangalore.\nCandidates should be flexible with working UK/US shifts.",Industry Type: Analytics / KPO / Research,Department: Other,"Employment Type: Full Time, Permanent","['Informatica Mdm', 'Data Modeling', 'Data Integration']",2025-06-12 14:03:34
"Senior Data Scientist (AI/ML, Data Analysis, Cloud (AWS), and Model",Synechron,8 - 13 years,Not Disclosed,['Pune'],"job requisition idJR1027352\n\nJob Summary\nSynechron is seeking an analytical and innovative Senior Data Scientist to support and advance our data-driven initiatives. The ideal candidate will have a solid understanding of data science principles, hands-on experience with AI/ML tools and techniques, and the ability to interpret complex data sets to deliver actionable insights. This role contributes to the organizations strategic decision-making and technology innovation by applying advanced analytics and machine learning models in a collaborative environment.\n\nSoftware\n\nRequired\n\nSkills:\nPython (including libraries such as pandas, scikit-learn, TensorFlow, PyTorch) proficiency in developing and deploying models\nR (optional, but preferred)\nData management tools (SQL, NoSQL databases)\nCloud platforms (preferably AWS or Azure) for data storage and ML deployment\nJupyter Notebooks or similar interactive development environments\nVersion control tools such as Git\nPreferred\n\nSkills:\nBig data technologies (Spark, Hadoop)\nModel deployment tools (MLflow, Docker, Kubernetes)\nData visualization tools (Tableau, Power BI)\nOverall Responsibilities\nAnalyze and interpret large and complex data sets to generate insights for business and technology initiatives.\nAssist in designing, developing, and implementing AI/ML models and algorithms to solve real-world problems.\nCollaborate with cross-functional teams including data engineers, software developers, and business analysts to integrate models into production systems.\nStay current with emerging trends, research, and best practices in AI/ML/Data Science and apply them to ongoing projects.\nDocument methodologies, modeling approaches, and insights clearly for technical and non-technical stakeholders.\nSupport model validation, testing, and performance monitoring to ensure accuracy and reliability.\nContribute to the development of data science workflows and standards within the organization.\nPerformance Outcomes:\nAccurate and reliable data models that support strategic decision-making.\nClear documentation and communication of findings and recommendations.\nEffective collaboration with technical teams to deploy scalable models.\nContinuous adoption of best practices in AI/ML and data management.\nTechnical Skills (By Category)\n\nProgramming Languages:\nEssential: Python (best practices in ML development), SQL\nPreferred: R, Java (for integration purposes)\nDatabases/Data Management:\nSQL databases, NoSQL (MongoDB, Cassandra)\nCloud data storage solutions (AWS S3, Azure Blob Storage)\nCloud Technologies:\nAWS (S3, EC2, SageMaker, Lambda)\nAzure Machine Learning (preferred)\nFrameworks & Libraries:\nTensorFlow, PyTorch, scikit-learn, Keras, XGBoost\nDevelopment Tools & Methodologies:\nJupyter Notebooks, Git, CI/CD pipelines\nAgile and Scrum processes\nSecurity Protocols:\nBest practices in data security and privacy, GDPR compliance\nExperience\n8+ years of professional experience in AI, ML, or Data Science roles.\nProven hands-on experience designing and deploying ML models in real-world scenarios.\nDemonstrated ability to analyze complex data sets and translate findings into business insights.\nPrevious experience working with cloud-based data science solutions is preferred.\nStrong portfolio showcasing data science projects, models developed, and practical impact.\nAlternative Pathways:\nCandidates with extensive research or academic experience in AI/ML can be considered, provided they demonstrate practical application of skills.\n\nDay-to-Day Activities\nConduct data exploration, cleaning, feature engineering, and model development.\nCollaborate with data engineers to prepare data pipelines for model training.\nBuild, validate, and refine machine learning models.\nPresent insights, models, and recommendations to technical and business stakeholders.\nSupport deployment of models into production environments.\nMonitor model performance and iterate to improve effectiveness.\nParticipate in team meetings, project planning, and reviewing progress.\nDocument methodologies and maintain version control of codebase.\nQualifications\nBachelors degree in Computer Science, Mathematics, Statistics, Data Science, or a related field; Masters or PhD highly desirable.\nEvidence of relevant coursework, certifications, or professional training in AI/ML.\nProfessional certifications (e.g., AWS Certified Machine Learning Specialty, Microsoft Certified Data Scientist) are a plus.\nCommitment to ongoing professional development in AI/ML methodologies.\nProfessional Competencies\nStrong analytical and critical thinking to solve complex problems.\nEffective communication skills for technical and non-technical audiences.\nDemonstrated ability to work collaboratively in diverse teams.\nAptitude for learning new tools, techniques, and technologies rapidly.\nInnovation mindset with a focus on applying emerging research.\nStrong organizational skills to manage multiple projects and priorities.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['java', 'data science', 'python', 'deploying models', 'aws', 'continuous integration', 'kubernetes', 'scikit-learn', 'ci/cd', 'artificial intelligence', 'sql', 'docker', 'tensorflow', 'spark', 'pytorch', 'keras', 'hadoop', 'big data', 'mongodb', 'microsoft azure', 'nosql', 'pandas', 'amazon ec2', 'r', 'cassandra', 'agile']",2025-06-12 14:03:37
Data Analyst - Kannada Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Kannada.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you.\nAnti-virus solution that is kept up to date, with regular scans performed.\nOnly one member per household may apply.\nNB: All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['English', 'Kannada', 'Data Interpretation', 'Data Analysis', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:39
Data Analyst - Kannada Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Kannada.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Kannada', 'Data Analysis', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:42
"Senior Data Analyst - Power BI, Data Modeling, Data Visualization",IT Services & Consulting,7 - 10 years,Not Disclosed,"['Mumbai', 'Delhi / NCR', 'Bengaluru']","Job Overview:\nYoull design and implement scalable solutions for award-winning platforms like LMX and MAX, automating media transactions and bridging media buyers and sellers. Work in an Agile, POD-based model to revolutionize the role of data and technology in OOH advertising.\n\nWhat Youll Do:\nArchitect scalable solutions aligned with business goals and market needs.\nLead Agile POD teams to deliver iterative, high-impact solutions.\nEnhance products with advanced features like dynamic rate cards and inventory mapping.\nEnsure best practices in security, scalability, and performance.\n\nWhat You Bring:\nStrong expertise in cloud-based architectures, API integrations, and data analytics.\nProven experience in Agile environments and POD-based execution.\nTechnical proficiency in Java, Angular, Python, and AWS.\n\nRequired Skills:\n8+ years of experience as a Solution Architect.\nBachelors/Masters in Computer Science or related field.\nProficiency in Java, Angular, Python, MongoDB, SQL, NoSQL, and AWS.\nStrong understanding of Agile methodologies and POD-based execution.\n\nTech Stack:\nLanguages: Java, Python\nFrontend: Angular\nDatabases: MongoDB, SQL, NoSQL\nCloud: AWS\nLocation-Remote,Delhi NCR, Bangalore, Chennai, Pune, Kolkata, Ahmedabad, Mumbai, Hyderabad",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Visualization', 'Java', 'NoSQL', 'Power BI', 'Data Analysis', 'MongoDB', 'AWS', 'SQL', 'Python']",2025-06-12 14:03:44
Senior Data Analyst-Azure Data Factory,Lumen Technologies,8 - 12 years,Not Disclosed,['Bengaluru'],"Were looking for a Senior Data Analyst with a strong foundation in Azure-based data engineering and Machine Learning to design, develop, and optimize robust data pipelines, applications, and analytics infrastructure. This role demands deep technical expertise, cross-functional collaboration, and the ability to align data solutions with dynamic business needs.\nKey Responsibilities:\nData Pipeline Development:\nDesign and implement efficient data pipelines using Azure Databricks with PySpark to transform and process large datasets.\nOptimize data workflows for scalability, reliability, and performance.\nApplication Integration:\nCollaborate with cross-functional teams to develop APIs using the .NET Framework for Azure Web Application integration.\nEnsure smooth data exchange between applications and downstream systems.\nData Warehousing and Analytics:\nBuild and manage data warehousing solutions using Synapse Analytics and Azure Data Factory (ADF).\nDevelop and maintain reusable and scalable data models to support business intelligence needs.\nAutomation and Orchestration:\nUtilize Azure Logic Apps, Function Apps, and Azure DevOps to automate workflows and streamline deployments.\nImplement CI/CD pipelines for efficient code deployment and testing.\nInfrastructure Management:\nOversee Azure infrastructure management and maintenance, ensuring a secure and optimized environment.\nProvide support for performance tuning and capacity planning.\nBusiness Alignment:\nGain a deep understanding of AMO data sources and their business implications.\nWork closely with stakeholders to provide customized solutions aligning with business needs.\nBAU Support:\nMonitor and support data engineering workflows and application functionality in BAU mode.\nTroubleshoot and resolve production issues promptly to ensure business continuity.\nTechnical Expertise:\nProficiency in Microsoft SQL for complex data queries and database management.\nAdvanced knowledge of Azure Databricks and PySpark for data engineering and ETL processes.\nExperience with Azure Data Factory (ADF) for orchestrating data workflows.\nExpertise in Azure Synapse Analytics for data integration and analytics.\nProficiency in .NET Framework for API development and integration.\nCloud and DevOps Skills:\nStrong experience in Azure Infrastructure Management and optimization.\nHands-on knowledge of Azure Logic Apps, Function Apps, and Azure DevOps for CI/CD automation.\n""We are an equal opportunity employer committed to fair and ethical hiring practices. We do not charge any fees or accept any form of payment from candidates at any stage of the recruitment process. If anyone claims to offer employment opportunities in our company in exchange for money or any other benefit, please treat it as fraudulent and report it immediately.""\n#LI-BS1",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'Automation', 'orchestration', 'Infrastructure management', 'Machine learning', 'Business intelligence', 'Business continuity', 'Analytics', 'Downstream', 'Capacity planning']",2025-06-12 14:03:46
Data Research Analyst (BPO Non-Voice) - Immediate Joiners,Trupp Global Technologies,0 - 4 years,2.5-4.5 Lacs P.A.,[],"Role & responsibilities\nWe're hiring a Data Research Analyst to join our Research & Data Services team. This role involves gathering and analyzing information about companies from the web including crafting short descriptions about companies, tracking investments and funding rounds, mergers & acquisitions, and other key corporate events.\nIf you have a knack for internet research, a love for data accuracy, and an interest in the world of startups, finance, and business, this could be a great fit.\n\nWhat You'll Do\nConduct internet research to collect accurate information about companies across sectors.\nTrack and record business events such as Venture funding(Seed, Series A, B, etc), Mergers and acquisitions, IPOs and executive changes.\nWrite clear and concise company descriptions based on publicly available data. Research online and create relevant content as per style, tone, and requirements.\nOrganize data in spreadsheets or internal databases with precision.\nVerify and validate data from multiple sources for consistency and reliability.\nCollaborate with the quality assurance team to ensure data integrity.\n\n\nPreferred candidate profile\n0 - 4 years of experience in a data research, web research, or business intelligence role.\nExcellent written English and ability to summarize complex information quickly.\nFamiliarity with business and financial terms.\nProficient in tools like Google Search, LinkedIn, Pitchbook, Company Websites, business information sites and Excel/Google Sheets.\nStrong attention to detail and ability to meet deadlines.\n\nNice to Have\nBackground in business, finance, Journalism and content writing\nExperience using tools like PitchBook, Owler, or similar research platforms.\nPrior experience in a BPO/KPO or analytics environment.",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Internet Research', 'Research Analysis', 'Data Mining', 'Content Writing', 'Written Communication', 'Bpo Non Voice']",2025-06-12 14:03:48
Data Analyst /Science executive,Hav2 Apparels,2 - 5 years,1.75-2.5 Lacs P.A.,"['Bengaluru( Kundalahalli, AECS Layout, Munnekollal, Whitefield )']","Build and run scripts to scrape emails, phone numbers, and business data, clean and organize it, analyze insights using Python/Excel, automate workflows, and support lead generation for import-export operations.",Industry Type: Import & Export,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['basic data analysis', 'Attention to Detail', 'Excel proficiency', 'regex knowledge', 'experience extracting emails/phones', 'Email Marketing', 'Numpy', 'and ability to automate and document tasks.', 'Beautiful Soup', 'CRM Management', 'Pandas', 'Data Scraping', 'Selenium', 'Python']",2025-06-12 14:03:50
Financial Data Analyst,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: ROC(ROC)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies:\nBasic knowledge of financial statements and basic understanding of how data fits into methodologies\nAbility to read, understand and interpret financial metrics reported by rated entities\nStrong organizational skills\nAttention to detail\nAbility to work effectively in a collaborative team environment\nIntermediate Microsoft Excel skills\nGood written and verbal communication skills\nGood interpersonal skills, interact with team members, direct managers and limited other stakeholders\nDevelop working knowledge of more than one simple project/deliverable with guidance\nRelevant experience of up to 2 years in credit/financial data analysis and interpretation; experience in structured finance will be an added advantage\n\nEducation\nBachelors/Masters in Finance, Business, Accounting or similar field\n\nResponsibilities\nPerform analysis to support ratings, research, and analytical outreach\nApply Moody s Ratings standards to existing data to produce valuable inputs into the rating and research process, including Moodys adjusted data, key indicators, ratios, charts, and graphs in line with Moody s Ratings methodologies\nPerform various data intake tasks, including scrubbing and validating data for further use in research and ratings\nReview and understand financial reports, official statements, and other documents related to issuers performance\nWork directly with ratings and support analysts to understand data capture requirements, adjustments, and other information needed by the rating team for ratings and research\nPerform simple calculations and apply judgment for other calculations of data\nGather data from various sources (sometimes unstructured), update relevant databases, escalate or resolve issues\nComplete simple deliverables such as newsletters, database maintenance, more complex or high-profile admin or other ad-hoc support with oversight\n\nAbout the team\nOur Data & Analytics team is responsible for performing a range of data, analytical and research services that contribute to the overall credit analysis function carried out by the structured finance rating groups. By joining our team, you will be part of exciting work in financial data analysis.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['remediation', 'Data analysis', 'Financial statements', 'Excel', 'Analytical', 'Finance', 'Structured finance', 'ROC', 'Credit analysis', 'Research']",2025-06-12 14:03:52
Data Analyst - Senior,FedEx,4 - 7 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nAct as a technical expert on complex and specialist subject(s).\nSupport management with the analysis, interpretation and application of complex information, contributing to the achievement of divisional and corporate goals. Supports or leads projects by applying area of expertise.\nLead and implement advanced analytical processes through data/text mining, model development, and prediction to enable informed business decisions.\nApply sound analytical expertise to examine structured and unstructured data from multiple disparate sources to provide insights and recommend high-quality solutions to leadership across levels.\nPlan initiatives from concept to execution with minimal supervision and communicate results to a broad range of audiences. Develops a superior understanding of pricing and revenue management through internal and external sources to creatively solve business problems and lead the team from concept to execution of projects.\nTypically uses data, statistical and quantitative analysis, modeling, and fact-based management to drive decision-making. Provides regular expert consultative advice to senior leadership.\nEffectively shares best practices and fosters knowledge sharing across teams. Provides crossteam and cross-org consultation and supports communities of practice excellence.\n\n\n\nPreferred candidate profile\n\nRelevant experience in analytics/consulting/informatics and statistics\nKey Skills - Data and Business Analytics, Advanced Statistics and Predictive Modelling,\nStakeholder Management, Project Management\nExperience in pricing and revenue management yield management, customer segmentation analytics, revenue impact analytics, etc. is a plus\nExposure to predictive analytics, ML/ AI techniques is an added advantage\nTools - Oracle, SQL Server, Teradata, SAS, Python, Tableau/PowerBI/Spotfire\nGood to have cloud computing, big data, Azure",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Business Insights', 'Python', 'SQL', 'Power Bi', 'Business Acumen', 'Tableau']",2025-06-12 14:03:55
Senior Financial Data Analyst,Moodys Investors Service,1 - 2 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: RRS(RRS)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSolid accounting background with a strong focus on financial analysis\nDemonstrates knowledge of MS Excel, Word, and PowerPoint\nStrong organizational skills and attention to detail\nAbility to work effectively in a team environment with matrix reporting\nSolid verbal, written communication, and interpersonal skills\nAbility to adapt to a changing environment and prioritize tasks accordingly\nEducation:\nMinimum Experience: 1-2 years relevant in Credit Rating Analysis, Financial Statement Analysis\nPreferably a Postgraduate degree in Accounting, Finance, Economics, from a premium institution\nGood to have CFA/FRM certification\nJob Responsibilities:\nThe Senior Financial Data Analyst contributes to the success of the Research and Ratings Support team by providing a range of data and analytic services that support the overall credit analysis functions performed by the MIS analytic teams. This internal-facing role involves working directly with rating and research support analysts, preparing data, and performing various analytical tasks such as spreading, data gathering, and analysis for credit ratings, research, analytical market outreach, and presentations\nKey responsibilities include:\nPreparing a variety of discrete credit process inputs, performing preliminary analyses to identify trends in data, and applying reasoning to the completed work product\nPerforming financial statement analysis using accounting and finance principles to read and understand financial statements and other disclosures related to debt issuers performance\nApplying Moody s relevant methodology standards and requirements to financial data and making appropriate adjustments\nCreating a variety of standard initial work package items that serve as starting points for the ratings and research process, including data, spreadsheets, charts, and tables\nUpdating financial spreadsheets, charts, and tables\nIdentifying trends in data and applying reasoning to work being completed\nInitiating/escalating deeper reviews when necessary\nPreparing presentation materials for outreach activities\nProviding support for RRS and R&R in monitoring/surveillance of Moody s rated issuers\nSupporting monitoring of analyst credit portfolios through news and industry source tracking and highlighting key issues requiring further analysis\nUnderstanding the application of accounting concepts on a particular entity\nCreating documentation and providing guidance to support analysts and outsourcers\nReviewing, adjusting, and publishing data to external market participants\nSupporting the credit administration process and performing other routine administrative and ad hoc tasks as directed by RRS & R&R Teams\nAbout the Team:\nOur Research and Ratings Support (RRS) team is responsible for providing a range of data and analytic services that support the overall credit analysis functions performed by the MIS analytic teams\nBy joining our team, you will be part of exciting work in credit ratings, research, analytical market outreach, and presentations",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Administration', 'Financial statements', 'Publishing', 'Financial analysis', 'MIS', 'Analytical', 'Credit analysis', 'Financial statement analysis', 'Credit rating', 'Monitoring']",2025-06-12 14:03:57
Financial Data Analyst,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: ROC(ROC)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies\nStrong understanding of fundamental finance and financial statements\nBasic understanding of capital markets\nCurious problem solvers who enjoy learning new things, working with others, and continuously growing their interpersonal and technical skills.\nCandidates from diverse backgrounds and academic disciplines with a strong focus on Finance/Technology/Support & Management\nFluency in English with good written and verbal communication skills; good interpersonal skills\nCreate visual representations of data findings through charts, graphs, and dashboards to make the data understandable.\nFamiliarity with Alteryx, SQL and other data visualization tools such as Tableau, PowerBI etc.\nPreferred proficiency in Python for data analysis and scripting.\nRelevant experience of up to 2 years in credit/financial data analysis and interpretation is an added advantage\nEducation\nMasters in Finance, Business, Accounting or similar field. Any knowledge in SQL, Python, PowerBI, Alteryx, etc or any experience related to data science, data analytics will be an added advantage.\nResponsibilities\nPerform analysis to support ratings, research, analytical outreach. Examples of work include:\nPerform various data intake tasks, including scrubbing, validating the data for further use in research and ratings\nApply MIS standards to existing data in order to produce valuable inputs into the rating and research process, including Moodys adjusted data, key indicators, ratios, charts and graphs in line with MISs methodologies\nResponsible for reviewing and understanding financial reports, official statements and other documents related to issuers performance\nWork directly with ratings and support analysts to understand data capture requirements, adjustments and other information needed by the rating team for ratings and research\nTake initiative to participate in projects or process improvements\nComplete simple deliverables such as newsletters, database maintenance, more complex or high profile admin or other ad-hoc support with oversight\nBe able to perform data intake exercises such as resolution of data point or mapping issues\nOur Ratings & Operations Control (ROC) team is responsible for 1) analytic data capture and enrichment, inputs and outputs to support ratings & research, 2) ratings transaction setup and release and rating desk services, 3) regulatory processes and operational controls, 4) product management for regulatory website, 5) center of excellence for process improvement and 6) project management support.\nBy joining our team, you will be part of exciting work in supporting ratings accuracy and timely market impact by delivering high-quality, consistent work product, while driving process excellence.\n\n\n\n\nFor more information on the Securities Trading Program, please refer to the STP Quick Reference guide on ComplianceNet\n\nPlease note: STP categories are assigned by the hiring teams and are subject to change over the course of an employee s tenure with Moody s.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Financial statements', 'MIS', 'Project management', 'Process improvement', 'Analytical', 'Credit analysis', 'Operations', 'SQL']",2025-06-12 14:03:59
urgent requirement For Data Analyst / BI Developer,Quantzig,3 - 6 years,Not Disclosed,[],"Key Responsibilities:\nDevelop, design, and maintain dashboards and reports using Tableau and Power BI to support business decision-making.\nWrite and optimize complex SQL queries to extract, manipulate, and analyze data from multiple sources.\nCollaborate with cross-functional teams to understand business needs and translate them into effective data solutions.\nWork with AWS Redshift and Databricks for data extraction, transformation, and loading (ETL) processes.\nProactively identify and resolve data issues, acting as a solution finder to overcome challenges and drive improvements.\nWork independently, taking ownership of tasks and ensuring high-quality deliverables within deadlines.\nBe a strong team player, contributing to team knowledge sharing and fostering a collaborative environment.\nApply knowledge of US healthcare systems to help build relevant data solutions and insights.\n\nRequired Skills & Qualifications:\nMinimum 3 years of experience in data analysis, business intelligence, or related roles.\nStrong expertise in SQL for data querying and manipulation.\nExtensive experience creating dashboards and reports using Tableau and Power BI.\nHands-on experience working with AWS Redshift and Databricks.\nProven problem-solving skills with a focus on providing actionable data solutions.\nSelf-motivated and able to work independently, while being a proactive team player.\nExperience or strong understanding of US healthcare systems and data-related needs.\nExcellent communication skills with the ability to work across different teams and stakeholders.\nDesired Skills (Nice to Have):\nFamiliarity with other BI tools or cloud platforms.\nExperience in healthcare data analysis or healthcare analytics.",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Power Bi', 'Tableau', 'SQL', 'Redshift Aws', 'databricks']",2025-06-12 14:04:02
Sr. Data Analyst,Icims,4 - 9 years,Not Disclosed,['Hyderabad'],"Overview\nThe Senior Data Analyst is responsible for serving as a subject matter expert who can lead efforts to analyze data with the goal of delivering insights that will influence our products and customers. This position will report into the Data Analytics Manager, and will work closely with members of our product and marketing teams, data engineers, and members of our Customer Success organization supporting client outreach efforts. The chief functions of this role will be finding and sharing data-driven insights to deliver value to less technical audiences, and instilling best practices for analytics in the rest of the team.",,,,"['server', 'data', 'vlookup', 'market data', 'data mapping', 'dashboards', 'research', 'sql', 'analytics', 'tables', 'prep', 'pivot', 'data visualization', 'communication skills', 'python', 'data analytics', 'data analysis', 'insights', 'pivot table', 'data engineering', 'graph', 'excel', 'data quality', 'tableau', 'data governance', 'root cause']",2025-06-12 14:04:05
Optimal Data Analyst : Supply Chain : 12 LPA : Apply Now,Leading ITES Company,3 - 8 years,10-12 Lacs P.A.,"['Bangalore Rural', 'Bengaluru', 'Mumbai (All Areas)']","Hi,\n\nWe are hiring for the ITES Company for the Optimal Data Analyst Role.\nOverview\nThe Optimal Data Analyst is responsible for leveraging data to generate actionable insights that support strategic decision-making, particularly in supplier negotiations and cost forecasting. The role involves working with large data sets, using statistical methods, programming tools (e.g., SQL, R, Python), and business intelligence platforms like Tableau to identify patterns, trends, and financial opportunities. This position requires strong analytical thinking, problem-solving abilities, and collaboration across technical, operational, and supply chain teams. The analyst plays a key role in translating complex data into meaningful business insights, aligning analytical efforts with high-level business objectives, and driving value through data-informed negotiation support.\n\nKey Skills:\n\na) Bachelor's degree in discipline such as Supply Chain, Economic, Manufacturing, Technology, or Data Analytics\nb) Minimum 3 years of experience in data analysis with understanding of statistical methods and strong analytical skills\n\nTo Apply, WhatsApp 'Hi' @ 9151555419\n\nFollow the Steps Below:\n>Click on Start option to Apply and fill the details\n>Select the location as Other (to get multiple location option)\na)To Apply for above Job Role (Bangalore) Type : Job Code # 20\nb)To Apply for above Job Role (Mumbai) Type : Job Code # 21\n\nJob Description\n\nBachelor's degree in discipline such as Supply Chain, Economic, Manufacturing, Technology, or Data Analytics to bring diversity and different perspectives\nMinimum 3 years of experience in data analysis with understanding of statistical methods and strong analytical skills\nExperience with database management, programming, statistical modelling and/or business intelligence (SQL, R, Python, JMP, Tableau, etc.)\nExperienced with and proficient in Microsoft Office Suite\nLateral and logical thinking. The ability to think creatively and outside the box to solve unique and challenging problems\nMotivated self-starter\nStrong problem-solving tendencies\nWilling and able to push boundaries\nGoal-oriented, with a focus on utilizing data for insight\nAble to multi-task, prioritize and project manage independently in an environment with competing priorities\nExperience working in a technical, operational or manufacturing environment with the ability to translate that knowledge into financial opportunities\nDiverse functional experience, with a desire to use data in negotiations\nExcellent communication skills and a proven history of excelling in a collaborative environment as a key team player\nWorking closely with technical teams, and other organizations to understand the product and data\nFinding and interpreting large data sets to help predict costs\nLearning and understanding Boeing's data resources and knowing when, how, and which to use and which not to use.\nIdentifying, analyzing, and solve systematic problems, while maintaining focus on the bigger picture\nWorking together with the team to ensure data analysis and developed algorithms can be appropriately applied for negotiation support\nEnsuring data collected, analyzed and presented result in actionable insights for negotiation support\nEngaging and participating in negotiation support, to bolster the use of data analytics within supplier negotiations\nUnderstanding high-level business objectives and continually align those objectives to meet needs of the business.",Industry Type: BPM / BPO,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Genpact', 'Supply Chain', 'Sutherland', 'Statistical Modeling', 'Data Modeling', 'Wipro', 'Cognizant', 'Business Intelligence', 'Accenture', 'Data Mining', 'Data Extraction', 'Data Collection', 'HCL', 'Optimal Data Analyst', 'Database Management', 'Data Analysis', 'Data Visualization', 'Amazon', 'Hexaware', 'WNS']",2025-06-12 14:04:07
Senior Data Analyst,OnlineSales.ai,2 - 7 years,Not Disclosed,['Pune'],"About OnlineSales.ai\nBuilt by ex-Amazon ad-tech experts, OnlineSales.ai offers a future-proof Retail Media Operating System - boosting Retailer s profitability by 7% of Sales! We are an Enterprise B2B SaaS startup, based out of Pune India. With OnlineSales.ais platform, retailers activate and delight 10x more Brands by offering an omni-channel media buying experience, advanced targeting, analytics & 2x better ROAS. Tier 1 Retailers and Marketplaces globally are accelerating their Monetization strategy with OnlineSales.ai and are innovating ahead of the market by at least 2 years.\n\nAbout the Role\nWe are seeking a talented and motivated individual to join our team as a Senior Data Analyst who will be responsible for extracting insights from complex datasets to drive informed decision-making and enhance business performance. You will collaborate closely with cross-functional teams to identify key metrics, develop data-driven strategies, and provide actionable recommendations. Additional responsibilities may include managing daily regulatory reporting tasks and remediation activities, as well as process improvement.\n\nWhat will you do @OnlineSales?\nData Analysis: Utilize advanced analytical techniques to explore large datasets, identify trends, patterns, and anomalies, and extract actionable insights.\nData Visualization: Create visually compelling dashboards and reports to communicate findings effectively to stakeholders, enabling them to make informed decisions.\nData Extraction: regular extraction of relevant data from internal databases using SQL queries. Design and optimize SQL queries to retrieve specific datasets required for performance analysis and reporting\nIssue Identification: Proactively identify performance-related issues by monitoring key performance indicators (KPIs), analyzing trends, and investigating anomalies reported by internal stakeholders or external clients.\nAddressing Client Exceptions and Issues: Responsively address performance-related exceptions and issues raised by clients, ensuring timely resolution and effective communication throughout the process. Collaborate with client-facing teams to understand client requirements, prioritize tasks, and deliver solutions that meet or exceed client expectations.\nRoot Cause Analysis: Dive deep into data to understand the root causes of performance issues, considering factors such as system architecture, infrastructure, code efficiency, and user behavior.\nHypothesis Testing: Apply hypothesis testing techniques to validate assumptions and identify statistically significant factors impacting performance.\nDocumentation and SOP Creation: Create clear and detailed Standard Operating Procedures (SOPs) outlining the process for diagnosing, troubleshooting, and resolving performance issues. Ensure that documentation is organized, easily accessible, and regularly updated to reflect changes in systems, processes, or configurations.\nCross-Functional Collaboration: Collaborate with teams across the organization, including business development, marketing, product development and operations, to understand their data needs and provide analytical support\n\nYou will be a great fit, if you have :\n2-4 years of relevant experience.\nBachelors or Masters degree in Computer Science, Engineering, or a related technical field.\nProficiency in SQL for data extraction and manipulation from relational databases.\nFamiliarity with programming languages such as Python for Data Analysis and Data modeling is a plus.\nStrong analytical skills with the ability to interpret complex datasets and draw meaningful insights.\nStrong problem-solving abilities with a proactive approach to troubleshooting and issue resolution.\nAdvanced proficiency in Excel and adept data manipulation skills for efficient analysis and visualization of large datasets.\nEffective communication and interpersonal skills for collaboration with cross-functional teams and stakeholders.\nUnderstanding of E-Commerce as a domain.\nExcellent documentation skills with the ability to create clear and comprehensive reports and SOPs.\nAttention to detail and commitment to data accuracy and quality. Willingness to work for a startup.\n\nWhy Online Sales.ai?\nStartup-y . We believe Startup is a mindset. It s about being scrappy, being nimble, solving tough problems with constrained resources, and more. It s about working hard and playing hard\nEnterprise SaaS . Opportunity to work with an Enterprise Product SaaS firm with aspirations of growing 10x across the globe\nAI-led Retail Tech . We are working to digitize & democratize one of the most exciting and growing verticals - Retail Tech leveraging data, machine learning, and automation (culmination of ad-tech, mar-tech, and analytics for Retail vertical)\nMeaningful work . This is not just a job. You can find a job anywhere. This is a place for the bold to get paid who make a real impact on business\nNo red tape . Say goodbye to pointless meetings or political hoops to jump through. We re scrappy, believe in autonomy, and empower our teams to do whatever it takes to do the unthinkable\nProblem Solving . We ignite the best in you. We exist not only to deliver meaningful innovation but to ignite and inspire the creative problem-solver in you\nQuirky & fun . Enjoy new skills and hobbies like being a quiz master, playing board games, trying your hands on percussion, playing Djembe, and spreading love within the org!",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Data modeling', 'Process improvement', 'Online sales', 'Troubleshooting', 'Analytics', 'Monitoring', 'SQL', 'Data extraction']",2025-06-12 14:04:09
Senior Data Management Analyst,Wells Fargo,4 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst in Corporate and Investment Banking ('CIB') to join the Applications Controls Execution & Services team, a subunit of the CIB Data Management organization.\nThe Application Controls Execution & Services team partners and supports CIB's wide network of Application Business Owners (ABO's) with identification, interpretation and/or implementation of governance processes or controls used to mitigate various compliance, operational, or data related risks.",,,,"['Data Management', 'Project Management', 'financial services management', 'operational risk', 'Analytics', 'business support', 'Business Analysis']",2025-06-12 14:04:11
"Senior Manager- Middle and Back Office Data Analyst- ISS,",Fidelity International,10 - 15 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Title: Middle and Back Office Data Analyst - ISS Data (Senior Manager)\nDepartment: Technology\nLocation: Bangalore & Gurgaon (hybrid / flexible working permitted)\nReports To: Middle and Back Office Data Product Owner\nLevel: Senior Manager\nWe re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our [insert name of team/ business area] team and feel like you re part of something bigger.\nAbout your team\nThe Technology function provides IT services that are integral to running an efficient run-the business operating model and providing change-driven solutions to meet outcomes that deliver on our business strategy. These include the development and support of business applications that underpin our revenue, operational, compliance, finance, legal, marketing and customer service functions. The broader organisation incorporates Infrastructure services that the firm relies on to operate on a day-to-day basis including data centre, networks, proximity services, security, voice, incident management and remediation.\nThe ISS Technology group is responsible for providing Technology solutions to the Investment Solutions & Services (ISS) business (which covers Investment Management, Asset Management Operations & Distribution business units globally)\n\nThe ISS Technology team supports and enhances existing applications as well as designs, builds and procures new solutions to meet requirements and enable the evolving business strategy.\nAs part of this group, a dedicated ISS Data Programme team has been mobilised as a key foundational programme to support the execution of the overarching ISS strategy.\nAbout your role\nThe Middle and Back Office Data Analyst role is instrumental in the creation and execution of a future state design for Fund Servicing & Oversight data across Fidelity s key business areas. The successful candidate will have an in- depth knowledge of data domains that represent Middle and Back-office operations and technology.\nThe role will sit within the ISS Delivery Data Analysis chapter and fully aligned to deliver Fidelity s cross functional ISS Data Programme in Technology, and the candidate will leverage their extensive industry knowledge to build a future state platform in collaboration with Business Architecture, Data Architecture, and business stakeholders.\nThe role is to maintain strong relationships with the various business contacts to ensure a superior service to our clients.\nData Product - Requirements Definition and Delivery of Data Outcomes\nAnalysis of data product requirements to enable business outcomes, contributing to the data product roadmap\nCapture both functional and non-functional data requirements considering the data product and consumers perspectives.\nConduct workshops with both the business and tech stakeholders for requirements gathering, elicitation and walk throughs.\nResponsible for the definition of data requirements, epics and stories within the product backlog and providing analysis support throughout the SDLC.\nResponsible for supporting the UAT cycles, attaining business sign off on outcomes being delivered\nData Quality and Integrity:\nDefine data quality use cases for all the required data sets and contribute to the technical frameworks of data quality.\nAlign the functional solution with the best practice data architecture & engineering principles.\nCoordination and Communication:\nExcellent communication skills to influence technology and business stakeholders globally, attaining alignment and sign off on the requirements.\nCoordinate with internal and external stakeholders to communicate data product deliveries and the change impact to the operating model.\nAn advocate for the ISS Data Programme.\nCollaborate closely with Data Governance, Business Architecture, and Data owners etc.\nConduct workshops within the scrum teams and across business teams, effectively document the minutes and drive the actions.\nAbout you\nAt least 10 years of proven experience as a business/technical/data analyst within technology and/or business changes within the financial services /asset management industry.\nMinimum 5 years as a senior business/technical/data analyst adhering to agile methodology, delivering data solutions using industry leading data platforms such as Snowflake, State Street Alpha Data, Refinitiv Eikon, SimCorp Dimension, BlackRock Aladdin, FactSet etc.\nProven experience. of delivering data driven business outcomes using industry leading data platforms such as Snowflake.\nExcellent knowledge of data life cycle that drives Middle and Back Office capabilities such as trade execution, matching, confirmation, trade settlement, record keeping, accounting, fund & cash positions, custody, collaterals/margin movements, corporate actions , derivations and calculations such as holiday handling, portfolio turnover rates, funds of funds look through .\nIn Depth expertise in data and calculations across the investment industry covering the below.\nAsset-specific data: This includes data related to financial instruments reference data like asset specifications, maintenance records, usage history, and depreciation schedules.\nMarket data: This includes data like security prices, exchange rates, index constituents and licensing restrictions on them.\nABOR & IBOR data: This includes calculation engines covering input data sets, calculations and treatment of various instruments for ABOR and IBOR data leveraging platforms such as Simcorp, Neoxam, Invest1, Charles River, Aladdin etc. Knowledge of TPAs, how data can be structured in a unified way from heterogenous structures.\nShould possess Problem Solving, Attention to detail, Critical thinking.\nTechnical Skills: Excellent hands-on SQL, Advanced Excel, Python, ML (optional) and proven experience and knowledge of data solutions.\nKnowledge of data management, data governance, and data engineering practices\nHands on experience on data modelling techniques such as dimensional, data vault etc.\nWillingness to own and drive things, collaboration across business and tech stakeholders.\nFeel rewarded",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['IT services', 'Data analysis', 'Data management', 'Incident management', 'Scrum', 'Customer service', 'Asset management', 'SDLC', 'SQL', 'Python']",2025-06-12 14:04:13
Senior Financial Data Analyst,Simcorp,4 - 5 years,Not Disclosed,['Noida'],"Financial Analyst WHAT MAKES US, US Join some of the most innovative thinkers in FinTech as we lead the evolution of financial technology. If you are an innovative, curious, collaborative person who embraces challenges and wants to grow, learn and pursue outcomes with our prestigious financial clients, say Hello to SimCorp! At its foundation, SimCorp is guided by our values caring, customer success-driven, collaborative, curious, and courageous. Our people-centered organization focuses on skills development, relationship building, and client success. We take pride in cultivating an environment where all team members can grow, feel heard, valued, and empowered. If you like what we re saying, keep reading!\nWHY THIS ROLE IS IMPORTANT TO US\nThe Financial Data Operator is responsible to perform the collection, composition, control and distribution of market and master data for financial instruments (Equities, Funds, Fixed Income, ABTS/MBS, OTS Derivatives, etc.) for various SimCorp clients and in accordance of the effective SLA agreements.\nFurthermore, this role is responsible for answering client questions and conduct all necessary data analyses of financial instruments data to resolve service delivery incidents to continue service delivery. The role is also responsible to adhere to all relevant operational risk as well as data governance and quality frameworks.\nEventually, this role also requires demonstrating very client-focused mindset, substantial know- how of financial instruments (such as Equities, Fixed Income, ABS/MBS, etc.) and provide coaching to other members.\nWHAT YOU WILL BE RESPONSIBLE FOR\nPerforms all daily service deliverables in terms of collecting, composing, controlling, and distributing financial instrument data according to effective client SLAs\nExecution of all quality checks part of the service scope and strict adherence to existing runbook(s) as well as data quality and governance frameworks and conduct first data analysis in case of unexpected data behavior\nResolve all data questions, service requests and requested audit support raised by clients in a timely and professional manner to ensure customer satisfaction and SLA compliance\nPerform all necessary tasks to comply existing operational risk frameworks (e.g., Sarbanes- Oxley Act (SOX), Risk and Control Engine (RACE) etc.)\nEfficiently support and contribute to continuous improvement of operational processes (with predominant focus on manual processes, high-risk areas), data quality checks and system functionality\nWork with local/regional clients to identify specific requirements, special data treatment or any other client demands which need to be delivered as part of the service scope\nExperience working cross-organizationally with both Business and Technology groups.\nPerform continuous know-how exchange between the different Data Operations teams in terms of processes, incidents, documentation, or other open topics to avoid know-how silos/gaps and assure service level consistency\nMonitor and report any kind of issues along the data supply chain including but not limited to interface issues, missing data files or interrupted business processes and trigger the necessary resolution processes to ensure service delivery continuation\nMaintain documentation in terms of business processes, functional descriptions, operational runbooks, or other manuals to ensure information transparency and enable know-how transfers\nWHAT WE VALUE\nFor the Financial Analyst position, we value\nMUST HAVE:\nExperience with data vendor feeds (Bloomberg, IDC, Reuters, etc.) and display products, 4- 5 years\nDeep knowledge of traditional and non-traditional financial instruments and markets including structured securities, Swaps, especially complex instruments like ABS/MBS, index linked bonds, and syndicated loans.\nBachelor s degree or equivalent in finance or engineering\nSolving master and reference data issues based on exception handling, 4-5 years\nExperience of data integration on any EDM platform, 4-5 years\nApplying operational data management and data governance, 2-3 years\nProcess design and engineering experience, 2-3 years\nExperience with service request systems or any other similar ticketing tool, like HPALM, Service Now Salesforce, etc., 4-5 years\nGOOD TO HAVE:\nAbility to troubleshoot technical glitches in existing data process and coordinate with Technology team to resolve.\nExperience in developing process automation, improvements, and streamlining using tools like KNIME, Alteryx, Excel VBA with scripting on programming language such as Python, PowerShell including intermediate knowledge of SQL",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Loans', 'Data analysis', 'Ticketing', 'Data management', 'Operational risk', 'Bloomberg', 'Fixed income', 'SQL', 'Auditing']",2025-06-12 14:04:16
"Sr. Data Analyst – Tableau, SQL, Snowflake",Int9 Solutions,5 - 7 years,Not Disclosed,['Bengaluru'],"We are looking for a skilled Data Analyst with excellent communication skills and deep expertise in SQL, Tableau, and modern data warehousing technologies. This role involves designing data models, building insightful dashboards, ensuring data quality, and extracting meaningful insights from large datasets to support strategic business decisions.\n\nKey Responsibilities:\nWrite advanced SQL queries to retrieve and manipulate data from cloud data warehouses such as Snowflake, Redshift, or BigQuery.\nDesign and develop data models that support analytics and reporting needs.\nBuild dynamic, interactive dashboards and reports using tools like Tableau, Looker, or Domo.\nPerform advanced analytics techniques including cohort analysis, time series analysis, scenario analysis, and predictive analytics.\nValidate data accuracy and perform thorough data QA to ensure high-quality output.\nInvestigate and troubleshoot data issues; perform root cause analysis in collaboration with BI or data engineering teams.\nCommunicate analytical insights clearly and effectively to stakeholders.\n\nRequired Skills & Qualifications:\nExcellent communication skills are mandatory for this role.\n5+ years of experience in data analytics, BI analytics, or BI engineering roles.\nExpert-level skills in SQL, with experience writing complex queries and building views.\nProven experience using data visualization tools like Tableau, Looker, or Domo.\nStrong understanding of data modeling principles and best practices.\nHands-on experience working with cloud data warehouses such as Snowflake, Redshift, BigQuery, SQL Server, or Oracle.\nIntermediate-level proficiency with spreadsheet tools like Excel, Google Sheets, or Power BI, including functions, pivots, and lookups.\nBachelor's or advanced degree in a relevant field such as Data Science, Computer Science, Statistics, Mathematics, or Information Systems.\nAbility to collaborate with cross-functional teams, including BI engineers, to optimize reporting solutions.\nExperience in handling large-scale enterprise data environments.\nFamiliarity with data governance, data cataloging, and metadata management tools (a plus but not required).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Tableau', 'Data Warehousing', 'Data Analytics', 'SQL', 'Scenario Analysis', 'Cohort Analysis', 'Data Modeling', 'Predictive Analysis', 'Redshift']",2025-06-12 14:04:18
"Sr. Data Analyst – Tableau, SQL, Snowflake",Int9 Solutions,5 - 10 years,Not Disclosed,"['Mumbai', 'Delhi / NCR', 'Bengaluru']","We are looking for a skilled Data Analyst with excellent communication skills and deep expertise in SQL, Tableau, and modern data warehousing technologies. This role involves designing data models, building insightful dashboards, ensuring data quality, and extracting meaningful insights from large datasets to support strategic business decisions.\n\nKey Responsibilities:\nWrite advanced SQL queries to retrieve and manipulate data from cloud data warehouses such as Snowflake, Redshift, or BigQuery.\nDesign and develop data models that support analytics and reporting needs.\nBuild dynamic, interactive dashboards and reports using tools like Tableau, Looker, or Domo.\nPerform advanced analytics techniques including cohort analysis, time series analysis, scenario analysis, and predictive analytics.\nValidate data accuracy and perform thorough data QA to ensure high-quality output.\nInvestigate and troubleshoot data issues; perform root cause analysis in collaboration with BI or data engineering teams.\nCommunicate analytical insights clearly and effectively to stakeholders.\n\nRequired Skills & Qualifications:\nExcellent communication skills are mandatory for this role.\n5+ years of experience in data analytics, BI analytics, or BI engineering roles.\nExpert-level skills in SQL, with experience writing complex queries and building views.\nProven experience using data visualization tools like Tableau, Looker, or Domo.\nStrong understanding of data modeling principles and best practices.\nHands-on experience working with cloud data warehouses such as Snowflake, Redshift, BigQuery, SQL Server, or Oracle.\nIntermediate-level proficiency with spreadsheet tools like Excel, Google Sheets, or Power BI, including functions, pivots, and lookups.\nBachelor's or advanced degree in a relevant field such as Data Science, Computer Science, Statistics, Mathematics, or Information Systems.\nAbility to collaborate with cross-functional teams, including BI engineers, to optimize reporting solutions.\nExperience in handling large-scale enterprise data environments.\nFamiliarity with data governance, data cataloging, and metadata management tools (a plus but not required).\nLocation : - Mumbai, Delhi / NCR, Bengaluru , Kolkata, Chennai, Hyderabad, Ahmedabad, Pune, Remote",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Tableau', 'SQL', 'BI Tools', 'Scenario Analysis', 'Cohort Analysis', 'Data Warehousing', 'SQL Server', 'Data Modeling', 'Data Analytics', 'Predictive Analysis', 'Redshift']",2025-06-12 14:04:20
Sr Analyst I Data Engineering,DXC Technology,9 - 12 years,Not Disclosed,['Hyderabad'],"Job Description:\nEssential Job Functions:\nParticipate in data engineering tasks, including data processing and integration activities.\nAssist in the development and maintenance of data pipelines.\nCollaborate with team members to collect, process, and store data.\nContribute to data quality assurance efforts and adherence to data standards.\nUse data engineering tools and techniques to analyze and generate insights from data.\nCollaborate with data engineers and other analysts on data-related projects.\nSeek out opportunities to enhance data engineering skills and domain knowledge.\nStay informed about data engineering trends and best practices.\n\nBasic Qualifications:\nBachelors degree in a relevant field or equivalent combination of education and experience\nTypically, 5+ years of relevant work experience in industry, with a minimum of 2 years in a similar role\nProven experience in data engineering\nProficiencies in data engineering tools and technologies\nA continuous learner that stays abreast with industry knowledge and technology\n\nOther Qualifications:\nAdvanced degree in a relevant field a plus\nRelevant certifications, such as Oracle Certified Professional, MySQL Database Administrator a plus\nRecruitment fraud is a scheme in which fictitious job opportunities are offered to job seekers typically through online services, such as false websites, or through unsolicited emails claiming to be from the company. These emails may request recipients to provide personal information or to make payments as part of their illegitimate recruiting process. DXC does not make offers of employment via social media networks and DXC never asks for any money or payments from applicants at any point in the recruitment process, nor ask a job seeker to purchase IT or other equipment on our behalf. More information on employment scams is available here .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Usage', 'Manager Quality Assurance', 'Senior Analyst', 'Social media', 'Manager Technology', 'Data processing', 'Data quality', 'Oracle', 'mysql database administrator', 'Recruitment']",2025-06-12 14:04:23
Senior Data Engineering Analyst,Optum,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Description\n\nExperience 4 to 7 years.\nExperience in any ETL tools [e.g. DataStage] with implementation experience in large Data Warehouse\nProficiency in programming languages such as Python etc.\nExperience with data warehousing solutions (e.g., Snowflake, Redshift) and big data technologies (e.g., Hadoop, Spark).\nStrong knowledge of SQL and database management systems.\nFamiliarity with cloud platforms (e.g., AWS, Azure, GCP) and data pipeline orchestration tools (e.g. Airflow).\nProven ability to lead and develop high-performing teams, with excellent communication and interpersonal skills.\nStrong analytical and problem-solving abilities, with a focus on delivering actionable insights.\nResponsibilities\nDesign, develop, and maintain advanced data pipelines and ETL processes using niche technologies.\nCollaborate with cross-functional teams to understand complex data requirements and deliver tailored solutions.\nEnsure data quality and integrity by implementing robust data validation and monitoring processes.\nOptimize data systems for performance, scalability, and reliability.\nDevelop comprehensive documentation for data engineering processes and systems.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ETL', 'SQL', 'Python', 'Azure', 'Datastage', 'Snowflake', 'Ab Initio', 'Informatica', 'Teradata', 'AWS']",2025-06-12 14:04:25
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Bengaluru'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nChennai\nData Engineer with Neo4j\nData Science\nIndia\nGurugram\nBusiness Analyst\nData Science\nPoland\nRemote Poland\nBengaluru, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Bengaluru\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:04:27
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Gurugram'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nChennai\nData Engineer with Neo4j\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nGurugram, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:04:29
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Chennai'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nGurugram\nData Engineer with Neo4j\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nChennai, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Chennai\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:04:31
Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures\nIdentify data quality metrics and execute data quality audits to benchmark the state of data quality",,,,"['Data Management', 'Project Management', 'Data Analytics', 'Data Governance', 'Business Analysis']",2025-06-12 14:04:34
Business Analyst - Data Warehouse,Vichara Technologies,6 - 11 years,30-35 Lacs P.A.,"['Coimbatore', 'Bengaluru', 'Delhi / NCR']","Collaborate with business stakeholders to gather and validate requirements\nCreate and manage Jira tickets\nSupport sprint planning, backlog grooming\nCreate clear, structured requirements documentation and user stories\n\nRequired Candidate profile\nExperience in analytics, business intelligence, or data warehouse projects (Snowflake, Power BI, Streamlit\nWorking knowledge of Jira\nknowledge in Alternative Asset Management or Investment Banking.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Investment Banking', 'Power Bi', 'User Stories', 'Business Analysis', 'Snowflake', 'python', 'streamlit', 'JIRA', 'SQL', 'Capital Market', 'Hedge Funds', 'Private Equity', 'Credit', 'Private Debt', 'MDM', 'Asset Management', 'Data Warehousing']",2025-06-12 14:04:36
Associate Data Analyst- Contractual,Windows Consultants Pvt Ltd,4 - 8 years,Not Disclosed,['Gurugram'],"Job Title: Data Analytics Associate Finance Team\nContractual Role- 1 year\nWe are seeking a Data Analytics Associate to join our Finance team. This role is ideal\nfor an analytical thinker with a passion for data-driven insights and business\nperformance analysis.\nKey Responsibilities:\n• Collect, clean, and maintain datasets from multiple sources (sales, operations,\ncustomer data).\n• Ensure data accuracy and integrity across various platforms.\n• Assist in developing dashboards and reports to support business decision-\nmaking.\n• Analyze sales trends, inventory levels, and operational performance to\nprovide actionable insights.\n• Support in monitoring the effectiveness of marketing campaigns,\npromotions, and pricing strategies.\n• Utilize tools like Excel, SQL, Tableau, and Power BI to interpret data.\n• Collaborate with cross-functional teams (Marketing, Operations, Finance) to\nalign analytics initiatives with business objectives.\n• Identify operational inefficiencies and suggest improvements based on data\nanalysis.\n• Assist in automating and optimizing reporting processes to improve efficiency.\nWhat Were Looking For:\n• 1+ year of experience in data analytics, business intelligence, or financial\nanalytics.\n• Proficiency in Excel, SQL, Power BI (knowledge of Python/R is a plus).\n• Strong analytical skills with the ability to interpret complex datasets and\ngenerate insights.\n• A proactive and detail-oriented mindset with a problem-solving approach.\n• Strong communication skills to present findings in a clear and concise manner.\n• Ability to work collaboratively across teams and contribute to data-driven\ndecision-making.",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'R', 'Power Bi', 'Tableau', 'Dashboards', 'Python']",2025-06-12 14:04:38
Data Analyst Rights Management Claims,Straive,1 - 3 years,Not Disclosed,[],"Overview\n\nAs a Conflicts Coordinator, you will oversee the resolution of rights conflicts for the client audio and video catalog on various platforms while adhering to strict project deadlines. You will also aid in the development of new projects and processes to proactively free up revenue for our clients and will be responsible for frequently communicating with stakeholders internally and externally, including label management, 3rd party rightsholders, and platform contacts.",,,,"['Google Sheets', 'Excel', 'Complex Data Management', 'Advanced Excel', 'SQL', 'Spreadsheets', 'Data Management']",2025-06-12 14:04:40
Lead Data Analyst Walk IN - Gurgaon,Mascot E Services,6 - 10 years,12-22 Lacs P.A.,['Gurugram'],"- Python & SQL, Statistical analysis\n- Tableau & Power BI\n- HYBRID - 3 - 4 days in Office\n\nF2F WALK IN DRIVE in Gurgaon - 14-June\n\nConnect with *ANUJ - 8249759636* for further details",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'SQL', 'Power Bi', 'Tableau']",2025-06-12 14:04:42
Client Reference Data Analyst,Quantum Leap Consulting,2 - 3 years,3.5-4.5 Lacs P.A.,['Mumbai'],"Job Title: Client Reference Data Analyst\nWork Location: Mumbai\nEmployment Type: 1-Year Contract\nShift Timing: 12:30 PM 9:30 PM IST\nExperience Required: 2+ years\nNotice Period: Immediate\nLaptop Provided: Yes, if needed\nCompensation: Up to 5 LPA\nAbout the Role:\nWe are hiring a Client Reference Data Analyst to join the operations team of a leading global financial services firm. This role involves managing client data, setting up new accounts, and ensuring documentation and reporting accuracy. The role is ideal for professionals who are organized, detail-oriented, and familiar with financial data operations or client onboarding processes.\nKey Responsibilities:\nOpen and link client accounts on financial platforms such as Prime Brokerage or Portfolio Accounting systems.\nSet up account-level reporting and entitlements for clients and third-party users.\nReview and validate documentation submitted for account and reporting setup.\nPerform quality checks for newly created or modified client accounts.\nRequest and manage secure login credentials (e.g., Secure IDs) for client systems access.\nTrack and resolve issues related to account setup, data integrity, and documentation.\nCoordinate with internal teams for issue escalation and workflow alignment.\nMonitor key metrics and Service Level Agreements (SLAs) to ensure timely and accurate delivery.\nIdentify areas for process improvement and assist in implementing solutions.\nSupport team leads with rollout of new tools, processes, or reporting templates.\nMust-Have Skills:\nMinimum 2 years of experience in client onboarding, client data management, or financial operations.\nStrong knowledge of account creation and entitlements setup in financial or investment platforms.\nExcellent skills in Microsoft Excel including Pivot Tables, VLOOKUP, and data reporting.\nExposure to client documentation handling, preferably in the capital markets or banking domain.\nStrong problem-solving skills and ability to escalate with context and ownership.\nExperience in managing high volumes with precision under tight timelines.\nGood verbal and written communication skills to liaise with internal stakeholders.\nGood-to-Have:\nExposure to prime brokerage, reference data, or investment banking operations.\nFamiliarity with global markets, client reporting, or capital market products.\nPrior experience in a client-facing or middle office support role in BFSI.\nSoft Skills Required:\nHigh attention to detail and accuracy\nAdaptability and willingness to learn\nAbility to prioritize tasks effectively\nCollaborative team player\nClient service orientation and ownership\nProfessional and proactive communication",Industry Type: IT Services & Consulting,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Client onboarding', 'Data Management', 'Stakeholder management', 'reference data', 'Account opening']",2025-06-12 14:04:44
AVP Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Agile Methodology', 'Funds Transfer Pricing', 'Financial Data Mapping', 'Big Data Query Techniques', 'Lineage Tracing', 'Data warehousing', 'Data Governance', 'Jira', 'Market Risks', 'SQL']",2025-06-12 14:04:47
"Senior Analyst, Data and Product Solution",NOVARTIS,1 - 3 years,Not Disclosed,['Hyderabad'],"Summary\nNovartis specialists within Data and Product Solutions are on a data and digital transformation journey, leveraging analytics to generate actionable insights for Novartis medicines impacting more than 799 million patients worldwide. The team is poised to enable easier, faster, and reliable decisions for Novartis divisions across the globe.\nAbout the Role\nLocation - Hyderabad #Hybrid\nAbout the role:",,,,"['Analytical', 'Pharma', 'Diversity and Inclusion', 'Market research', 'Project planning', 'healthcare analytics', 'Stakeholder management', 'digital transformation', 'SQL', 'Python']",2025-06-12 14:04:49
Business Analyst/ Data Scientist - SAS & SQL,Khushboo,3 - 8 years,10-20 Lacs P.A.,['Hyderabad'],"hands on SQL/ SAS programming experience & handling complex/large data\nMust have experience inTableau/Power BI\nExperience in campaign performance measurement, customer targeting framework\nProven ability to design and lead strategic projects\n\nRequired Candidate profile\nMust - SAS , SQL, Python\nGood in Statistical model , Predictive model, Logistic regression, Linear regression\nBFSI Mandatory - Credit risk, Credit Card, Retail Banking",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Decision Tree', 'sas', 'sql', 'Advanced Analytics', 'Strategy Building', 'Predictive Modeling', 'python', 'Logistic Regression', 'Segmentation', 'Random Forest', 'Linear Regression', 'Classification', 'Statistical Modeling', 'Credit Risk']",2025-06-12 14:04:52
"Medical Data Analyst (Pharmacovigilance, Medical Summarization)",Ardem Data Services,1 - 5 years,Not Disclosed,[],"Shift Timings: 10:00 PM to 7:00 AM\nNight Shift experience mandatory\n\nWe are seeking a Medical Data Entry professional with a minimum of 1 year of experience in medical data annotation and document review. The ideal candidate will have a background in medical or pharmaceutical sciences and possess key skills related to medical data management, regulatory guidelines (FDA, EMA, ICH, GCP), and patient report handling. This role requires mandatory night shift experience and is a permanent work-from-home position.\nKey Responsibilities:\nReview and annotate medical documents and patient records accurately.\nApply knowledge of FDA, EMA, ICH, and GCP guidelines to data management tasks.\nPerform clinical data management activities.\nHandle and process patient reports efficiently.\nEnsure data quality and integrity during the entry and annotation process.\nRequirements:\nQualification: B.Sc, M.Sc, B.Pharma, or M.Pharma.\nMinimum 1 year of experience in medical data annotation and medical document review.\nMandatory experience working night shifts (US shift: 10:00 pm to 7:00 am).\nExperience with FDA, EMA, ICH, and GCP guidelines.\nProficiency in Clinical Data Management and handling Patient Reports.\nOnly candidates with a medical background and medical data annotation experience will be considered.\nImmediate joiner preferred.\nTechnical Requirements:\nLaptop or Desktop: Windows (i5 or higher, 8GB RAM minimum)\nScreen: 14 inches, Full HD (19201080)\nInternet Speed: 100 Mbps or higher\nAbout ARDEM\nARDEM is a leading Business Process Outsourcing and Business Process Automation service provider. For over twenty years, ARDEM has successfully delivered business process outsourcing and business process automation services to our clients in the USA and Canada. We are growing rapidly. We are constantly innovating to become a better service provider for our customers. We continuously strive for excellence to become the Best Business Process Outsourcing and Business Process Automation company.\nNOTE!\nARDEM will never ask for any personal information or banking information during the hiring process for any data entry/processing type of work. If you are contacted by any party claiming to represent ARDEM Incorporated offering work from home jobs this is fraud. Please disregard and refer to ARDEMs Careers page for all open job positions. We apologize for any inconvenience caused by such acts.",Industry Type: Miscellaneous,Department: Research & Development,"Employment Type: Full Time, Permanent","['US Healthcare', 'Pharmacovigilance', 'Medical Terminology', 'Summarizing', 'Patient reports', 'Electronic Medical Record', 'CPT', 'Medical Records', 'Medical Scribe', 'Medical Data Analyst', 'ICD', 'Medical Summarization', 'Medical Transcription', 'Medical', 'Clinical Data Management', 'Data Annotation']",2025-06-12 14:04:54
Senior Data Management Analyst,Wells Fargo,4 - 8 years,Not Disclosed,['Hyderabad'],"In this role, you will:\nLead or participate in moderately complex programs and initiatives for data quality, governance, and metadata activities\nDesign and conduct moderately complex analysis to identify and remediate data quality, data integrity, process, and control gaps\nAnalyze, assess, and test data controls and data systems to ensure quality and risk compliance standards are met and adhere to data governance standards and procedures",,,,"['Data Management Analysis', 'Project Management', 'Data Management', 'data governance', 'Business Analysis']",2025-06-12 14:04:57
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst. We believe in the power of working together because great ideas can come from anyone. Through collaboration, any employee can have an impact and make a difference for the entire company. Explore opportunities with us for a career in a supportive environment where you can learn and grow. This role requires a blend of technical expertise, analytical thinking, and strategic decision making to drive impactful insights.\nAt Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do. We are seeking candidates who embrace diversity, equity and inclusion in a workplace where everyone feels valued and inspired. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.",,,,"['Data Management', 'Hive', 'Power BI', 'DB2', 'SQL Server', 'Tableau', 'Oracle', 'Teradata', 'Analytics', 'Python', 'Business Analysis']",2025-06-12 14:04:59
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst\n\nIn this role, you will:\nOrganize and lead complex companywide initiatives to ensure that data quality is maintained so that data can effectively support business processes\nOversee analysis and reporting in support of regulatory requirements",,,,"['Data Management', 'metadata', 'Project Management', 'Teradata', 'Analytics', 'Business Analysis', 'SQL']",2025-06-12 14:05:01
Marketing Data Analyst,Ajni Consulting,5 - 10 years,10-14 Lacs P.A.,['Hyderabad'],"5+ years of experience in data management, marketing operations, sales operations,\n• Familiarity with CRM systems (e.g., Salesforce) and data management tools like\nInterested candidates share on purnima.prometheus@gmail.com or whtsapp 9220927729",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Salesforce', 'tag management', 'Sales Operations', 'Marketing Operations', 'Marketing Analytics', 'Customer Support Operations', 'Adobe Analytics']",2025-06-12 14:05:03
Financial Data Analyst,IPS group,1 - 6 years,3.5-4.5 Lacs P.A.,['Kolkata'],"Qualification: B Com / M.Com /MBA Finance\n\nExperience: Minimum 1 year of experience as a Financial Data Analyst\n\nJob Requirement:\n* Domain / Accounting knowledge and skills\n* Basic understanding of accounting principles and Finance\n* Good verbal and written communication skills\n* Willingness to work in rotational and night shifts\n\nJob Description:-\n* Research, Review, Analyze and Interpret financial statements/Broker reports of large corporates from global markets.\n* Ensure compliance with global policies including US GAAP & IFRS.\n* Capture data points of interest from financial reports and tag the same from Income Statement, Balance Sheet & Cash flow through an application.\n* Transaction based activities, rule-based decision making, verifying for accuracy and completeness, formatting data, posting and preparing output (various types of reconciliations, system to system  reconciliations, balancing, open item management, reports etc)\n* Constant quality check on the finalization of statement.\n* Capture specific figures from Revenue, Net Income, EPS, Weighted Average Shares, Income before tax,\nIncome Tax & One-time charges & provide timely, relevant and accurate information for Earnings.\n* Capture the future estimated data as given in press release, earnings call & company presentation report for Guidance.\n* Number crunching on specific items of the Income Statement, Balance sheet & Cash Flow.\n* Understanding of financial processes and applications",Industry Type: BPM / BPO,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Finance Data Analyst', 'Financial Statements', 'Ifrs Reporting', 'Financial Reporting', 'US GAAP', 'Financial Accounting', 'IFRS']",2025-06-12 14:05:06
EMS Data Analyst (Manual Support),Growexx,3 - 8 years,Not Disclosed,['Ahmedabad'],"EMS Data Analyst (Manual Support) - GrowExx EMS Data Analyst (Manual Support)\nGrowexx is seeking an\nEMS Data Analyst (Manual Support)\nto join our team. The EMS Data Analyst will be responsible for ensuring the accurate and timely import of EMS data into the NEMSIS database. This role involves working with EMS data from various sources, including electronic Patient Care Reports ( ePCRs ) and other EMS data systems. The focus will be on maintaining data quality, troubleshooting issues, and performing manual data entry or manipulation as necessary to ensure data integrity and compliance with NEMSIS standards.\nKey Responsibilities\nMonitor data submissions from EMS agencies and identify any issues with data quality or formatting\nManually review ePCR data to ensure compliance with NEMSIS data standards and identify errors\nPerform data entry and data manipulation tasks as needed to correct errors or format data for import\nWork with EMS agencies to resolve data quality issues and improve data collection practices\nDocument all data entry and quality assurance activities\nImplement and maintain data quality checks and validation processes\nIdentify trends and patterns related to data errors or inconsistencies\nAssist in developing and implementing data quality improvement plans\nAssist in data analysis and generating reports to support quality improvement initiatives and operational decisions\nHelp develop and maintain data dashboards and visualizations\nRespond to data requests from internal and external stakeholders\nMaintain a strong understanding of the NEMSIS data standard and ensure ongoing compliance\nStay updated on NEMSIS changes, updates, and best practices\nAssist with training EMS staff on data collection and NEMSIS requirements\nWork closely with EMS agencies, data managers, and other stakeholders to ensure seamless data flow and data quality\nCommunicate data-related issues and findings effectively to both technical and non-technical audiences\nKey Skills Strong analytical and problem-solving skills Attention to detail and commitment to data accuracy\nProficiency in data manipulation and analysis tools (e.g., Excel, SQL)\nExcellent communication and interpersonal skills\nAbility to work independently and as part of a team\nKnowledge of EMS operations, patient care, and medical terminology is a plus\nEducation and Experience Certification In Healthcare Data Analytics Or Related Field\n3+ years experience With Data Visualization Tools (E.G., Tableau, Power BI)\nExperience In Database Management Analytical and Personal Skills Must have good logical reasoning and analytical skills Ability to break big goals to small incremental actions Excellent Communication and collaboration skills Demonstrate Ownership and Accountability of their work\nGreat attention to details\nDemonstrate ownership of tasks Positive and Cheerful outlook in life Work with the problem solver engineers team (Doc / PDF Only, Max file size 2 MB) By using this form you agree with the storage and handling of your data by this website. *\nYou cannot copy content of this page\nReconciliation Automation Data Sheet\nThis field is for validation purposes and should be left unchanged.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Analytical', 'Reconciliation', 'Data collection', 'Healthcare', 'Troubleshooting', 'Operations', 'Data entry', 'SQL']",2025-06-12 14:05:08
Master Data Analyst Reporting,RK Hr Management,3 - 7 years,8-14 Lacs P.A.,['Ahmedabad'],"3–5 yrs exp in data reconciliations (Catalyst/Keystone to GFIN, GFIN vs HFM), dashboard support (Power BI), audit support, and data governance (MDG). Proactive, Excel-savvy, system-fluent (SAP, HFM, Oracle), with strong analytical and comms skills.",Industry Type: FMCG,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Reconciliation', 'SAP', 'oracle', 'Power BI', 'Data Governance', 'Data Quality', 'Data Management', 'Data Visualization', 'Etl Process', 'Tableau', 'Communication']",2025-06-12 14:05:10
Master Data Analyst- Reporting,Client of RK Hr Management,3 - 8 years,20-30 Lacs P.A.,['Ahmedabad'],"Compare and match data between systems; investigate and fix mismatches.\n\nHelp build dashboards, support audits, and maintain clear documentation.\n\nManage new data entries, ensure accuracy, and oversee smooth data processes.\n\nRequired Candidate profile\n3 to 5 years experience\nExperience of Data Governance and systems related DG\nConfidence in using applications, some systems experience - SAP, HFM, Oracle, Snowflake,\nAutonomy to review and research",Industry Type: FMCG,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Mdg', 'Power BI', 'Master Data Management', 'Data Governance', 'Data Reporting', 'SAP', 'Snowflake', 'Data Cleansing', 'Master data reporting', 'Master Data', 'Oracle', 'HFM']",2025-06-12 14:05:13
Data Science Analyst (Senior),Infogain,6 - 8 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python.\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n- Strong storytelling and communication skills to convey complex analytical findings to both technical and non-technical audiences.\n- Demonstrates ownership and leadership, driving projects from idea to impact with minimal supervision.\nSKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-12 14:05:15
Senior Data Management Analyst,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst.\n\nIn this role, you will:\nMust have strong experience (SME) in JIRA, Assets, Structure, Confluence, Groovy/Python scripting, Linux, Script Runner.\nIn-depth knowledge of Jira Software, JSM and Confluence administration, configuration, customizations and Automations.",,,,"['Data Management', 'Script Runner', 'Linux', 'Confluence', 'JSM', 'Python scripting', 'Groovy', 'Jira', 'REST APIs']",2025-06-12 14:05:17
Data Management Analyst,Wells Fargo,2 - 6 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Project Management', 'data Analysis', 'Data governance', 'Business Analysis']",2025-06-12 14:05:19
Data Scientist,Tesco,1 - 3 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Summary:\n\nEnable data driven decision making across the Tesco business globally by developing analytics solutions using a combination of math, tech and business knowledge\n\nRoles and Responsibilities:\n- Identifying operational improvements and finding solutions by applying CI tools and techniques\n- Responsible for completing tasks and transactions within agreed KPI's",,,,"['Data Science', 'Advanced Excel', 'Data Analytics', 'Python', 'SQL', 'Applied Mathematics', 'Machine Learning', 'Statistics']",2025-06-12 14:05:21
"Data & Analytics Analyst, VP",NatWest Markets,15 - 20 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Join us as a Data & Analytics Analyst\nTake on a new challenge in Data & Analytics and help us shape the future of our business\nYou ll take accountability for the analysis of complex data to identify business issues and opportunities, and supporting the delivery of high quality business solutions\nWere committed to mapping a career path that works for you, with a focus on helping you build new skills and engage with the latest ideas and technologies in data analytics\nWere offering this role at vice president level\nWhat youll do\nAs a Data & Analytics Analyst, you ll be driving the production of high quality analytical input to support the development and implementation of innovative processes and problem resolution. You ll be capturing, validating and documenting business and data requirements, making sure they are in line with key strategic principles.\nWe ll look to you to interrogate, interpret and visualise large volumes of data to identify, support and challenge business opportunities and identify solutions.\nYou ll also be:\nPerforming data extraction, storage, manipulation, processing and analysis\nConducting and supporting options analysis, identifying the most appropriate solution\nAccountable for the full traceability and linkage of business requirements of analytics outputs\nSeeking opportunities to challenge and improve current business processes, ensuring the best result for the customer\nCreating and executing quality assurance at various stages of the project in order to validate the analysis and to ensure data quality, identify data inconsistencies, and resolve as needed\nStrong sense of ownership with a focus on delivering high-quality outcomes\nExceptional attention to detail\nEmphasis on measurable outcomes and impact of work\nExpertise in data analytics and reporting\nThe skills youll need\nYou ll need a background in business analysis tools and techniques, along with the ability to influence through communications tailored to a specific audience. Additionally, you ll need the ability to use core technical skills.\nYou ll also demonstrate:\nClear and effective communication\nProficiency in SQL, and tools such as Excel and Power BI\nExperience in Informatica, Snowflake or others\nResponsible for performance metrics and data solutions across the entire data architecture team\nSkilled in data visualization, report generation and presentation to both technical and business audiences\nOver 15 years of professional experience\nHours\n45\nJob Posting Closing Date:\n23/06/2025",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Manager Quality Assurance', 'Business analysis', 'Analytical', 'Data quality', 'Data analytics', 'Informatica', 'Business solutions', 'SQL', 'Data extraction', 'Data architecture']",2025-06-12 14:05:24
MIS Analyst,Data Marshall,1 - 4 years,Not Disclosed,['Hyderabad'],"Job Description\nThe MIS Analyst plays a crucial role in managing and optimizing the organizations information management system. This position involves pulling up pre-identified reports, validating the content, interpreting and formatting the data into details that provide insight, and sharing it in a timely manner or agreed upon TAT.\nWhat You Will Do: MIS Analyst\nData Management: Pulling, interpreting, processing, reporting, and storing specified data.\nRequirements Translation: Convert business requirements into specifications for reports and dashboards, integrating multiple data sources.\nCollaboration: Work with specialists, leads, and managers to understand reporting needs and develop solutions accordingly.\nStatistical Reporting: Compile, prepare, and present statistical information for both internal and external stakeholders.\nWhat You Will Need:\n\nAdded Advantage\nReporting Tools: Experience with Power BI for reporting and analysis will be an added advantage.\nAutomation: Knowledge of VBA for developing automation scripts using Excel Macros.\nDatabase Development: Familiarity with MS Access for database and application development.\nClient Communication: Ability to communicate effectively with client business lines, leadership teams, and other stakeholders.\nFamiliarity with Python, Power Automate, and Power Apps is a plus. Role & responsibilities\n\n\nPreferred candidate profile\n\nEducation: Bachelors degree\nHealthcare Experience; Minimum 1 year of RCM experience or US Medical Coding Experience.\nMIS Experience: Minimum One year of experience in MIS execution\nTechnical Skills: Proficiency in MS Office applications (Excel, Word, PowerPoint), Proficiency in SQL will be an advantage.\nCommunication: Excellent verbal and written communication skills to facilitate collaboration with internal, external, and customer teams.\nAnalytical Skills: Strong analytical, conceptual, and problem-solving abilities.\nPrioritization: Ability to manage multiple priorities and adapt quickly to changing demands.\nFor more Details Kindly reach out\n\nName: Pagidoju Dhana Laxmi\nContact No: 7995682418\nEmai: dhanalaxmi.pagidoju@datamarshall.com",Industry Type: Analytics / KPO / Research,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent","['Word', 'Excel', 'Excel Powerpoint', 'Power Bi', 'SQL', 'Excel Macros']",2025-06-12 14:05:27
"Data Science Specialist - R/Python, Statistical Analysis, AI/Ml",Cisco,4 - 8 years,Not Disclosed,['Bengaluru'],"Responsibilities:\nAnalysis of cross-customer and customer specific data.\nAnalysis for diagnosis of product and customers specific problems and also to demonstrate value of our data to customers.\nSupport sales and product adoption for data related use-cases (occupancy, captive portal, behavioral metrics, BMS integrations etc)\nHelp design monitoring tools to detect product and customer relative issues around product\nCustomer demonstrations of more sophisticated data products like Firehose. Engineering/Product linkages\nCollaborate with specialist teams to help deliver solutions. (Webex, Meraki etc)\nLeverage on ML based approaches for fault detection tools, for trends and also customer/category analysis\n\nQualifications:\nAdvanced degree or equivalent experience in Engineering, Computer Science, Maths or a related technical field\nProficiency in programming and scripting languagesRand/orPython\nExperience using relational database -SQL\nBasic proficiency withMachine Learning methods and applications\n\nSkills:\nPassion for problem solving.\nHighly driven and customer oriented.\nExcellent communication.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'rest', 'python', 'data analysis', 'natural language processing', 'machine learning', 'relational databases', 'artificial intelligence', 'javascript', 'sql', 'spring', 'r', 'tableau', 'java', 'computer science', 'html', 'mysql', 'data structures', 'data visualization', 'ml', 'statistics']",2025-06-12 14:05:30
Data Management Analyst Mutual Fund & Investment Operations,International IT Companies,3 - 8 years,4.25-6 Lacs P.A.,['Bengaluru'],"Manage process reference data, pricing data, dividends, benchmarks, and fund classification for mutual funds and equity instruments.\nReview key fund-related documents\nFactsheets to extract, validate, and update critical data points.\n\nRequired Candidate profile\nInteract with multiple stakeholders including internal teams and external clients for data quality and operational updates.\nEnsure data accuracy and integrity in all deliverables\n\nPerks and benefits\nPerks and Benefits",Industry Type: BPM / BPO,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Financial Services', 'Mutual Funds', 'Data Management', 'ETFs', 'Investment Operations', 'Fund Documentation', 'Pricing Data', 'Reference Data', 'Investment Management Analyst.', 'Corporate Actions', 'Equity Operations', 'Annual Reports', 'KIIDs', 'Factsheet Review', 'Benchmark Data']",2025-06-12 14:05:32
Scientific Business Analyst (Associate) – ELN,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nThis role involves working closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements scientific software platforms such as Laboratory Information Management Systems (LIMS) that enable the capture of lab workflows & experimental data and Electronic Lab Notebooks (ELN) that act as Amgens System of Record ensuring data integrity and business continuity. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the technology ecosystem for in vivo study data management and ensure that the platform meets their requirements for data analysis and data integrity\nTranslate complex scientific and technological needs into clear, actionable requirements for development teams\nDevelop and maintain a product roadmap that clearly outlines the planned features and enhancements, timelines, and landmarks\nIdentify and manage risks associated with the systems, including technological risks, scientific validation, and user acceptance\nDevelop documentations, communication plans and training plans for end users\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\nCollaborate with geographically dispersed teams, including those in the US and other international locations.\nFoster a culture of collaboration, innovation, and continuous improvement.\n\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nBachelors degree with 0 - 3 years of experience in Life Sciences, Computer Science, IT, Computational Chemistry/Cheminformatics, Computational Biology/Bioinformatics or related field, OR\nDiploma with 4 - 7years of experience in Life Sciences, Computer Science, IT, Computational Chemistry/Cheminformatics, Computational Biology/Bioinformatics or related field, OR\nDemonstrated expertise in a scientific domain area and related technology needs\nExcellent problem-solving skills and a passion for tackling complex challenges in drug discovery with technology and data\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience with Benchling, Revvity, IDBS, or similar LIMS/ELN platforms\nPreferred Qualifications:\nExperience with Agile software development methodologies (Scrum)\nExperience performing or enabling data capture and analysis from instruments in a research laboratory or vivarium\nAbility to communicate technical or complex subject matters in business terms\nKnowledge of business analysis standard processes, DevOps, Continuous Integration, and Continuous Delivery methodology\nExperience with cloud (e.g. AWS) and on-premise infrastructure\nExperience supporting ELN/LIMS platforms in biopharma\n\n\n\nProfessional Certifications:\nSAFe for Teams certification (preferred)\n\n\n\nSoft\n\nSkills:\nAble to work under minimal supervision\nExcellent analytical and gap/fit assessment skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Business Analysis', 'LIMS platforms', 'ELN platforms']",2025-06-12 14:05:34
Analyst - Master Data Management,Danfoss,1 - 3 years,Not Disclosed,"['Oragadam', 'Chennai']","Job Description\nWe are seeking a motivated and detail-oriented Analyst to join our team. The successful candidate will be responsible for material creation/extension in Glasswing, executing mass changes in SAP, improving data quality in collaboration with data stewards, and implementing automation rules to streamline processes.\nJob Responsibilities\n    Material Creation/Extension in Glasswing: Create and extend material records in the Glasswing system, ensuring accuracy and compliance with company standards.\n•    Mass Changes in SAP: Perform mass updates and changes in the SAP system, maintaining data integrity and consistency.\n•    Data Quality Improvement: Collaborate with data stewards to identify and rectify data quality issues, ensuring high standards of data accuracy and reliability.\n•    Automation Rules Implementation: Develop and implement automation rules to enhance efficiency and reduce manual intervention in data management processes.",,,,"['SAP MM', 'MDM', 'Master Data Management', 'SAP MDM']",2025-06-12 14:05:37
Data Science Analyst (Standard),Infogain,3 - 5 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python with minimal supervision\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n  SKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-12 14:05:39
"Sr Business Analyst (Process Modeling, and Stakeholder Collaboration)",Synechron,7 - 12 years,Not Disclosed,"['Pune', 'Hinjewadi']","Job Summary\nSynechron is seeking a highly experienced and detail-oriented Senior Business Analyst to join our dynamic team. In this role, you will serve as a key contributor to our business analysis function, translating complex business needs into effective solutions that support organizational goals. Your expertise will enable our teams to deliver value-driven projects efficiently and effectively, ensuring alignment with strategic objectives and stakeholder expectations.\nSoftware Requirements\nRequired Skills:\nBusiness analysis tools (e.g., Microsoft Visio, (version 2016 or later))\nData analysis and visualization software (e.g., Microsoft Excel - advanced proficiency, tools like Tableau or Power BI)\nRequirement management tools (e.g., Jira, Confluence - recent versions)\nWorkflow and process modeling software (e.g., BPMN tools)\nPreferred Skills:\nBasic understanding of enterprise-level ERP/CRM systems (e.g., SAP, Salesforce)\nKnowledge of project management tools (e.g., Microsoft Project, MS Teams)\nOverall Responsibilities\nGather, analyze, and document business requirements by engaging with stakeholders, ensuring clarity, completeness, and alignment with organizational objectives.\nDevelop detailed functional specifications, use cases, process flows, and user stories to guide development teams and project execution.\nFacilitate communication between business units and technical teams to ensure a mutual understanding of project scope and deliverables.\nSupport project planning, monitoring progress, and ensuring deliverables meet quality standards and deadlines.\nContribute to process improvement initiatives by analyzing current workflows and recommending efficiencies.\nAssist in testing and validating solutions to verify they meet business needs and specifications.\nProvide ongoing support during implementation, including stakeholder training and documentation.\nStrategic Objectives:\nDeliver comprehensive requirements that enable timely and successful project deliveries.\nEnhance stakeholder engagement and satisfaction through clear communication and tailored solutions.\nPromote continuous improvement by identifying opportunities to optimize business processes.\nPerformance Outcomes & Expectations:\nAccurate and comprehensive requirement documentation.\nSuccessful facilitation of collaborative sessions and stakeholder buy-in.\nOn-time delivery of specifications and supporting documentation.\nPositive feedback from stakeholders regarding clarity and usability of deliverables.\nTechnical Skills (By Category)\nProgramming Languages:\nRequired: Basic understanding of scripting or programming concepts (e.g., SQL, Python) is preferred but not mandatory.\nPreferred: None specifically required.\nDatabases/Data Management:\nRequired: Experience with relational databases (e.g., SQL Server, Oracle) and data querying techniques.\nPreferred: Experience with big data tools or NoSQL databases.\nCloud Technologies:\nRequired: Familiarity with cloud platforms (e.g., AWS, Azure) focusing on cloud-based data storage and services.\nPreferred: Certification or practical experience in cloud services.\nFrameworks and Libraries:\nRequired: Understanding of business process frameworks (e.g., BPMN, UML modeling).\nPreferred: Knowledge of agile frameworks like Scrum or Kanban.\nDevelopment Tools & Methodologies:\nRequired: Experience with Agile, Scrum, or Waterfall project methodologies.\nPreferred: Exposure to DevOps practices.\nSecurity Protocols:\nOptional: Basic understanding of data security, compliance, and privacy protocols relevant to business analysis.\nExperience Requirements\nMinimum of 7+ years in business analysis roles within financial services or related industries.\nProven track record of managing complex projects from requirements gathering through implementation.\nExtensive experience in stakeholder engagement, documentation, and process modeling.\nExperience working in diverse regulatory environments and compliance standards is advantageous.\nCandidates with alternative pathways demonstrating equivalent skillssuch as extensive cross-functional project leadershipare encouraged to apply.\nDay-to-Day Activities\nConduct interviews and workshops with stakeholders to elicit detailed business requirements.\nAnalyze existing business processes and document workflows to identify improvement opportunities.\nPrepare functional specifications, use cases, user stories, and process diagrams for project teams.\nCollaborate closely with developers, testers, and project managers in an Agile or traditional setting.\nParticipate in sprint planning, review sessions, and status meetings.\nSupport user acceptance testing (UAT) and assist with issue resolution.\nMaintain clear and organized documentation of requirements, decisions, and project artifacts.\nProvide ongoing communication and updates to stakeholders on project progress.\nDecision-Making Authority & Responsibilities:\nValidate solution approaches against requirements.\nRecommend process improvements and inform implementation strategies.\nEscalate issues related to scope or requirements misalignment to project leadership.\nQualifications\nBachelors degree in Business Administration, Information Systems, Computer Science, or related field.\nRelevant certifications (preferred but not mandatory): CBAP, CCBA, PMI-PBA, or equivalents.\nParticipation in ongoing professional development, such as courses in business analysis, project management, or domain-specific training.\nDemonstrated commitment to continuous learning and adapting industry best practices.\nProfessional Competencies\nStrong analytical and critical thinking skills, with an ability to interpret complex data and business scenarios.\nEffective collaboration and stakeholder management skills across varying levels of the organization.\nExcellent written and verbal communication abilities, ensuring clarity and mutual understanding.\nResilience and adaptability in fast-paced environments, with a proactive approach to problem-solving.\nInnovative mindset, open to leveraging new tools and methods to enhance processes.\nSkilled in prioritizing tasks, managing time efficiently, and meeting deadlines.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Azure', 'Kanban', 'NoSQL', 'Scrum', 'SQL Server', 'Oracle', 'AWS']",2025-06-12 14:05:41
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,8 - 9 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n8 to 9+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-12 14:05:43
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,7 - 9 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n7 to 9+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-12 14:05:45
Data Science Analyst (Lead),Infogain,8 - 11 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python.\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n- Strong storytelling and communication skills to convey complex analytical findings to both technical and non-technical audiences.\n- Demonstrates ownership and leadership, driving projects from idea to impact with minimal supervision.\n  SKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-12 14:05:48
Data Governance & Data Quality Sr Associate Analyst,Amgen Inc,2 - 5 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgen's data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leveragesstate-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. This role involves working closely with business stakeholder and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with Data Product Owners, Data Stewards and technology teams to increase the trust and reuse of data across Amgen.\nRoles & Responsibilities:\nResponsible for the execution of data governance framework for a given domain of expertise (Research, Development, Supply Chain, etc.).\nContribute to the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nContribute to the cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nPartner with business teams to identify compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e.g., MDM, Enterprise Data Fabric, etc.) delivers data foundations.\nBuild strong relationship with key business leads and partners to ensure their needs are met.\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills (Advanced SQL, Python etc) with knowledge of Pharma processes with specialization in a domain (e.g., Research, Clinical Trials, Commercial, etc.)\nExperience of working with or supporting systems used to data governance framework. E.g. Collibra, Alation\nGeneral knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nExperience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nExcellent problem-solving skills and a committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience with Agile software development methodologies (Scrum)\nSoft Skills:\nExcellent analytical skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAbility to build business relationships and understand end-to-end data use and needs.\nStrong verbal and written communication skills\nBasic Qualifications:\nExperience with 5 - 9 years of experience in Business, Engineering, IT or related field",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Governance', 'data quality', 'Collibra', 'data stewardship', 'metadata management', 'Agile software development methodologies', 'Alation', 'data protection', 'master data management', 'SQL', 'Python']",2025-06-12 14:05:50
HIH - Data Science Lead Analyst - Evernorth,ManipalCigna Health Insurance,5 - 8 years,Not Disclosed,['Hyderabad'],"Internal Title: Data Science Lead Analyst\nExternal Title: Data Science Lead Analyst\nRole Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\n\nThe role will support the development and maintenance of machine learning models, with a focus on ensuring that models meet Cigna s requirements for governance and legal compliance. The role will require collaboration with other data scientists and involve work across many lines of business.\nKey Responsibilities:\nAnalyze model performance of new models with specific regards to requirements for legal compliance and governance standards around accuracy and bias;\nPerform periodic analyses of performance of existing models to ensure continued compliance with internal and external standards for accuracy and bias;\nConduct research (i.e. literature review) to understand when bias may be biologically or medically justifiable, and to what degree, for example: finding evidence from literature that heart disease is more prevalent among older populations\nUsing machine learning development tools to mitigate model bias when this is determined to be necessary\nCollaborating with data scientists, business stakeholders, and governance/compliance teams to ensure models meet compliance and governance standards\nQualifications:\nBachelors or Masters/PhD (preferred) in statistics or computer science or equivalent field with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR)\nAbility to promote best coding practices, championing a culture of documentation/logging\nThorough understanding of ML lifecycle, including necessary tradeoffs and associated risks\nLeadership in Data Science\nCan own a project end-to-end e.g., scoping, business value estimation, ideation, dev, prod, timeline\nCollaborates and guides junior team members in completion of projects and career development\nWorks cross functionally with technical (e.g., Data Science, Data Engineering) and business (e.g., clinical, marketing, pricing, business analysts) to implement solutions with measurable value\nScope and Impact\nIndependently delivers clear and well-developed presentations for both technical and business audiences\nCreates data science specific project goals associated with project deliverables\nArticulates timeline changes, rationale, and goals to meet deadlines moving forward\nValues diversity, growth mindset, and improving health outcomes of our customers\n\nLevel of Influence\nCommunicate with stakeholders to identify opportunities and possible solutions based on business need\nDraft project charter, timeline, and features/stories\nInfluence matrix-partner leadership\nAbout Evernorth Health Services",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Version control', 'Claims', 'data science', 'Legal compliance', 'Coding', 'Pharmacy', 'Machine learning', 'SQL', 'Python']",2025-06-12 14:05:52
HIH - Data Science Lead Analyst - Evernorth,Cigna Medical Group,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\nThe role will support the development and maintenance of proprietary advanced neural network (AI) foundation models in support of Cigna business operations.\nKey Responsibilities:\nWrite code using PyTorch and/or Tensorflow to implement, test, and operationalize deep learning models\nCollaborate with data scientists and engineers to improve deep learning models and implement business-facing solutions built on top of those models\nTake responsibility for improving code performance and quality\nFollow developments in deep learning technology to identify opportunities to improve models\nQualifications:\nBachelors or Masters(preferred) in computer science or statistics or any other equivalent discipline with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR), with emphasis on Tensorflow and Pytorch\nKnows and follows best coding and software engineering practices\nSuccessfully completes technical project components with limited guidance\nFamiliarity with deploying machine learning and predictive models to production and cloud environments\nLeadership in Data Science\nUnderstands how assigned work is related to purpose of the overall project\nIndependently identifies project roadblocks, and solutions\nSeeks to understand the health insurance domain\nScope and Impact\nDocuments the business considerations, methodology, process, code, and results associated with their work\nCollaborates to deliver clear and well developed presentations for both technical and business audiences\nConsistently communicates decisions, considerations, and needs for support\nReceives and responds to feedback in a professional and appropriate manner\nLevel of Influence\nPresent technical topics and results to non-technical stakeholders\nCommunicate and gather domain knowledge from non-technical stakeholders",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Health insurance', 'Version control', 'GIT', 'Claims', 'Coding', 'Machine learning', 'SQL', 'Python', 'Business operations']",2025-06-12 14:05:54
HIH - Data Science Lead Analyst - Evernorth,ManipalCigna Health Insurance,5 - 8 years,Not Disclosed,['Hyderabad'],"Internal Title: Data Science Lead Analyst\nExternal Title: Data Science Lead Analyst\nRole Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\nThe role will support the development and maintenance of proprietary advanced neural network ( AI ) foundation models in support of Cigna s business operations.\nKey Responsibilities:\nWrite code using PyTorch and/or Tensorflow to implement, test, and operationalize deep learning models\nCollaborate with data scientists and engineers to improve deep learning models and implement business-facing solutions built on top of those models\nTake responsibility for improving code performance and quality\nFollow developments in deep learning technology to identify opportunities to improve models\nQualifications:\nBachelors or Masters(preferred) in computer science or statistics or any other equivalent discipline with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR), with emphasis on Tensorflow and Pytorch\nKnows and follows best coding and software engineering practices\nSuccessfully completes technical project components with limited guidance\nFamiliarity with deploying machine learning and predictive models to production and cloud environments\nLeadership in Data Science\nUnderstands how assigned work is related to purpose of the overall project\nIndependently identifies project roadblocks, and solutions\nSeeks to understand the health insurance domain\nScope and Impact\nDocuments the business considerations, methodology, process, code, and results associated with their work\nCollaborates to deliver clear and well developed presentations for both technical and business audiences\nConsistently communicates decisions, considerations, and needs for support\nReceives and responds to feedback in a professional and appropriate manner\nLevel of Influence\nPresent technical topics and results to non-technical stakeholders\nCommunicate and gather domain knowledge from non-technical stakeholders\nAbout Evernorth Health Services",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Version control', 'GIT', 'Claims', 'Coding', 'Machine learning', 'Lead Analyst', 'SQL', 'Python', 'Business operations']",2025-06-12 14:05:56
Data Quality Analyst,Yallas Technology Solutions Opc,5 - 10 years,Not Disclosed,[],"Title: Data Quality Analyst/Developer\nDuration: 6 months to 1 year contract\nLocation:  Remote\nNotice period - Immediate to 7 days\nUAN /EPFO Report Required\n\nWork Experience:\n5 + years of this experience - Experience doing Data Emendation\nDesign/Develop Rules, monitoring mechanisms, notification\nDesign/Develop UI, Workflows, security\nDesign/Develop analytics (overall DQ reporting, usage statistics, etc).\nDesign/Develop migration activities to migrate existing DQ assets between our existing DQ platform and new DQ platform.\nDesign integration with MDM & Catalog (as needed)\nMonitor system performance and suggest optimization strategies (as needed).\nWork with DT to maintain system - patches, backups, etc.\nWork with LYB's Data Stewards to support their governance activities.\nTesting\n\nThe DQ Analyst/Developer should have experience with IMDC (for the sake of our example) cloud DQ and observability, JSON (depending on tool) Deep SQL skills, Integration tools/methodologies - API as well as ETL, Data Analysis, Snowflake or Databricks knowledge (for lineage), Power BI (nice to have), SAP ECC knowledge (nice to have), experience with cloud platforms (Azure, AWS, Google).\nIf you are interested please share required details along with resume\nFull Name:\nCurrent or Previous organization:\nCurrent Location:\nTotal Experience:\nRelevant experience as Python Developer:\nhow many years of experience In Azure, AWS, Google\nHow many years of experience in UI, Workflows, security\nWorking as full time or contract:\nReason for job change:\nAny other offers inhand:\nCurrent CTC:\nexpected CTC:\nNotice Period:\nemail id:\ncontact Number :\nDomain name:\nare you ok to work Cotractual role?:\nshare your aadhar or pan card for the verification",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Data quality analyst', 'cloud data quality', 'Azure', 'data quality developer', 'JSON', 'google', 'Informatica', 'AWS']",2025-06-12 14:05:59
Data Governance Process Analyst,K-logix Partnering Solutions,5 - 9 years,Not Disclosed,[],"Key Responsibilities:\n\nAnalyze end-to-end business processes using Celonis Process Mining to identify inefficiencies, root causes, and data quality issues.\nCollaborate with Data Stewards, IT, and business units to ensure data governance policies are aligned with process insights.\nDevelop and maintain dashboards and reports in Celonis to track key performance indicators (KPIs), data lineage, and governance metrics.\nWork with cross-functional teams to define and implement data governance controls and remediation strategies based on process analytics.\nSupport the development of data dictionaries, metadata management, and data cataloging in alignment with enterprise data standards.\nAssist in the rollout of enterprise-wide data governance programs and compliance initiatives (e.g., GDPR, CCPA).\nContinuously monitor and assess data quality metrics and suggest corrective actions to improve data accuracy and reliability.\nProvide training and documentation on Celonis best practices and data governance processes to business stakeholders.\n\nRequired Qualifications:\n\nBachelors degree in Information Systems, Data Analytics, Business Administration, or a related field.\n5+ years of experience in data governance, business process analysis, or data analytics roles.\n2+ years of hands-on experience with Celonis EMS (Execution Management System) or comparable process mining tools.\nStrong understanding of data governance frameworks, data quality principles, and data lifecycle management.\nProficient in SQL and working knowledge of data visualization tools (e.g., Power BI, Tableau).\nExcellent analytical and problem-solving skills, with a keen attention to detail.\nStrong communication and stakeholder engagement skills across technical and non-technical teams.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Celonis', 'Business Process Analysis', 'Data Governance']",2025-06-12 14:06:01
HIH - Data Science Lead Analyst - Evernorth,Cigna Medical Group,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\n\nThe role will support the development and maintenance of machine learning models, with a focus on ensuring that models meet Cigna requirements for governance and legal compliance. The role will require collaboration with other data scientists and involve work across many lines of business.\nKey Responsibilities:\nAnalyze model performance of new models with specific regards to requirements for legal compliance and governance standards around accuracy and bias;\nPerform periodic analyses of performance of existing models to ensure continued compliance with internal and external standards for accuracy and bias;\nConduct research (i.e. literature review) to understand when bias may be biologically or medically justifiable, and to what degree, for example: finding evidence from literature that heart disease is more prevalent among older populations\nUsing machine learning development tools to mitigate model bias when this is determined to be necessary\nCollaborating with data scientists, business stakeholders, and governance/compliance teams to ensure models meet compliance and governance standards\nQualifications:\nBachelors or Masters/PhD (preferred) in statistics or computer science or equivalent field with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR)\nAbility to promote best coding practices, championing a culture of documentation/logging\nThorough understanding of ML lifecycle, including necessary tradeoffs and associated risks\nLeadership in Data Science\nCan own a project end-to-end e.g., scoping, business value estimation, ideation, dev, prod, timeline\nCollaborates and guides junior team members in completion of projects and career development\nWorks cross functionally with technical (e.g., Data Science, Data Engineering) and business (e.g., clinical, marketing, pricing, business analysts) to implement solutions with measurable value\nScope and Impact\nIndependently delivers clear and well-developed presentations for both technical and business audiences\nCreates data science specific project goals associated with project deliverables\nArticulates timeline changes, rationale, and goals to meet deadlines moving forward\nValues diversity, growth mindset, and improving health outcomes of our customers\n\nLevel of Influence\nCommunicate with stakeholders to identify opportunities and possible solutions based on business need\nDraft project charter, timeline, and features/stories\nInfluence matrix-partner leadership",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Version control', 'GIT', 'Claims', 'data science', 'Legal compliance', 'Coding', 'Machine learning', 'SQL', 'Python']",2025-06-12 14:06:03
Data Entry (Fresher),Rapid Care,0 years,1-1.5 Lacs P.A.,['Chennai'],"Greetings from rapid care!!!!!!\n\nHiring Freshers and Experienced !!!!!!!!!\n\nwalkin interview\n\n\nJob Title: Data Analyst (Data Entry)\n\nLocation: Chennai\n\nShift: General and Rotational Shift\n\nGraduation: ( 10th, 12th, OR Any Diploma Qualification)\n\nInterview mode : walkin\n\n\nOffice Address : VLV Complex, 2nd floor, 41, SH 48, Little Mount, Saidapet, Chennai, Tamil Nadu 600015\n\nshare your resume : tag@rapidcare.ai\ncall , whatsapp : 9500170691, 9500170663.",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Typing Speed', 'Data Entry', 'Typing', 'Data Entry Operation']",2025-06-12 14:06:05
Data Entry Operator / Mis Executive,Talentlink Solutions,0 - 4 years,1-4 Lacs P.A.,[],"We Are looking For Computer Operator, Who can Perform defined tasks per documented instructions/process\n\nMale And Female Both Can apply\n\nFresher And Experience Both Can Apply\n\nBasic computer knowledge must\n\nHardworking\n\nWork from Home",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Back Office Processing', 'Non Voice Process', 'Data Entry', 'Back Office', 'Back Office Operations', 'Typing Speed', 'Computer Operating', 'Backend Operations', 'Chat Support', 'Non Voice', 'MS Office', 'Email Process', 'Chat Process', 'Data Processing', 'Data Entry Operation']",2025-06-12 14:06:08
Financial Planning And Analysis Intern,Kinara Capital,6 months duration,"15,000/month",['Bengaluru( Indira Nagar )'],"Job Title: Financial Planning & Analysis Intern\nDepartment : Finance & Accounting\nPurpose of Job: Vendor Management\n\nJob Responsibilities:\n\nSection 1: Vendor Management\n• Formulation & maintenance of Procure to Pay process\n• To check the pricing as per market rate, to negotiate with the\nvendor, save cost and & to select the potential vendor\n• To assess the risk level of the vendors\n• Liaise with various stakeholders to sign off on the contract terms\n• Ensure smooth on boarding of the vendor\n• Liaise with the various stakeholders to ascertain the\nperformance of the vendor\n• To renew the contracts within the due date\n• Support sourcing strategy, negotiations, and performance\nmanagement\n• Researching vendors\n• Improve vendor relationships\n• Establishing vendor management tools & technologies\n• Troubleshooting vendor issues\n• Stakeholder Management\n• Budget Check and analysis\n• Provide Executive Level briefings to Lead & Finance Controller at\nregular intervals to help keep them current with changes and\nperformance against existing agreements with vendors\nSection 2: Data Management\n• Maintaining a central repository of reports\n• Preparation of a monthly data pack that contains all the\noperational & financial parameters\n• Ensuring control checks on the operational reports being\npublished on a monthly basis\n\nQualifications:\n\nEducation: Degree/CA/MBA\nWork Experience:  Fresher\nOther Requirements: • Excellent communication skills\n• An Excel test needs to be undertaken\n• A PowerPoint presentation to be prepared\n\n• Negotiation\n• Problem-solving\n• Knowledge of procurement processes\n• Metrics and data analysis\n• Engage in continuous learning\n• Risk Identification & mitigation\n\nSkills & Competencies\n\nSkills\nTechnical Skills\n• Microsoft Excel Advanced\n• Financial Modeling & Forecasting\n• Budgeting & Variance Analysis\n• Accounting Knowledge\nSoft Skills\n• Communication Skills\n• Analytical Thinking\n• Collaboration & Teamwork\n• Adaptability\nCompetencies\n• Presentation skills\n• Data-Driven Decision Making\n• Business Partnering\n\nPlace of work: Head office, Bangalore.\nJob Type: Full Time",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent",['Vendor Management'],2025-06-12 14:06:10
MIS & Trading Data Coordinator,Abans Finance,0 - 3 years,Not Disclosed,['Ahmedabad'],"Position Summary:\nWe are looking for a meticulous and proactive Data coordinator to manage trading book entries in our in-house software system. This role is critical for ensuring the accurate generation of Management Information System (MIS) outputs and supporting data analysis. The ideal candidate will have a strong eye for detail, an aptitude for software systems, and a basic understanding of trading and financial operations.\n\n\nRole & responsibilities\nAccurately input trading book data into the companys in-house software system.\nEnsure completeness and consistency in all entries, adhering to organizational standards.\nUnderstand the intricacies of the in-house software system and its functionality.\nMonitor system workflows to identify and resolve issues or anomalies.\nStay updated on software enhancements and implement changes as required.\nPerform validation checks to ensure data integrity and accuracy.\nIdentify discrepancies in trading records and rectify them in coordination with relevant teams.\nGenerate MIS reports and ensure timely and accurate delivery to stakeholders.\nMaintain proper documentation of processes, changes, and findings.\nSupport audits by providing accurate and timely records as needed.\n\nPreferred candidate profile\nDegree in finance, commerce, business administration or a related field with 0-3 years of work experience in trading ops domain.\nBasic understanding of trading operations and financial concepts.\nFamiliarity with financial software systems and MIS reporting.\nProficiency in Microsoft Excel and database management tools.\nAbility to quickly learn and navigate proprietary software systems.\n\nWork Location- Gift City, Ahmedabad\n\nFreshers with trading knowledge can also apply at astha.satam@abans.co.in",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Management Information System', 'MIS Reporting', 'Trade Finance Operations', 'Trade Operations', 'MIS', 'MIS Operations', 'Database Management', 'Trading', 'Trade Finance', 'Trade Finance Management', 'Financial Operations']",2025-06-12 14:06:12
Business Analyst II,Conduent,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Track Description \nRequires formal education and relevant expertise in a professional, sales, or technical area.\nPerforms technical-based activities.\nContributes to and manages projects.\nUses deductive reasoning to solve problems and make recommendations.\nInterfaces with and influences key stakeholders.\nLeverages previous knowledge and expertise to achieve results.\nAbility to complete work self-guided.\nCollege or university degree required.\n\n General Profile  \nRequires knowledge and experience in own field.\nWill acquire higher-level knowledge and skills.\nDevelops an understanding of the company, processes, and customers.\nUses existing procedures to solve routine or standard problems.\nReceives moderate guidance and direction from others.\n\n Functional Knowledge  \nRequires expanded conceptual understanding of theories, practices, and procedures.\n\n Business Expertise  \nUses an understanding of key business drivers to accomplish work.\n\n Impact  \nImpacts own team through the quality of the services or information provided.\nFollows standardized procedures and practices to achieve objectives and meet deadlines.\n\n Leadership  \nNo supervisory responsibilities.\nProvides informal guidance to new team members.\n\n Problem Solving  \nUses existing procedures and technical experience to solve problems.\n\n Interpersonal Skills  \nExchanges complex information and ideas effectively.\n\n Responsibility Statements  \nFacilitates working sessions between customers and IT teams to define business requirements.\nCollects data from customers relating to systems and reports issues impacting service delivery.\nWrites detailed business functional requirements documents.\nCompiles cost assessment data for projects for supplier and vendor integration.\nRecommends requirement changes or improvements.\nPrepares business operations reports and develops recommendations.\nDevelops well-rounded knowledge of operating processes, user-based systems, and governing regulations.\nPerforms other duties as assigned.\nComplies with all policies and standards.",Industry Type: BPM / BPO,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'business analysis', 'sales', 'brd', 'business operations', 'data analysis', 'gap analysis', 'us healthcare', 'power bi', 'user stories', 'business intelligence', 'sql', 'claims processing', 'tableau', 'scrum', 'requirement analysis', 'sdlc', 'jira', 'agile methodology']",2025-06-12 14:06:15
Data Input & Management Executive,D&B Italiano,0 - 2 years,1.5-1.75 Lacs P.A.,['Ahmedabad'],"Position Overview:\nWe are seeking a diligent and organized professional to join our operations team. The ideal candidate will be responsible for accurate data entry, system management, and reporting processes that support our project and business workflows.\n\nKey Responsibilities:\nInput and manage project-related and administrative data with precision and consistency\nMaintain internal data systems and ensure regular updates across relevant platforms\nGenerate basic analytical reports to assist in operational decision-making\nCollaborate with design and procurement teams to ensure data accuracy across departments\nAssist in documentation of vendor, inventory.\n\nQualifications & Skills:\nBachelors degree in Business Administration, Information Systems, Statistics, or a related field\nStrong proficiency in Microsoft Excel, Google Sheets, and basic data visualization tools\nExcellent attention to detail, organizational, and time management skills\nAbility to work independently and in a cross-functional team environment\nPrior experience in data handling or operations support is advantageous but not mandatory",Industry Type: Architecture / Interior Design,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data Management', 'Data Analysis', 'Data Maintenance', 'Data Collection', 'Advanced Excel', 'Google Sheets', 'Records Management', 'Excel Sheet', 'Data Reporting', 'Excel Report Preparation']",2025-06-12 14:06:17
"Business Analyst I, AOP - Perfectmile",Amazon,1 - 6 years,Not Disclosed,['Bengaluru'],"AOP FC Analytics team manages a suite of MIS reporting published at a various regular frequency, productivity tools to bridge the current software challenges and serve all analytical needs of leadership team with data & analysis.\n\nThe ideal candidate relishes working with large volumes of data, enjoys the challenge of highly complex business contexts, and, above all else, is passionate about data and analytics. The candidate is an expert with business intelligence tools and passionately partners with the business to identify strategic opportunities where data-backed insights drive value creation. An effective communicator, the candidate crisply translates analysis result into executive-facing business terms. The candidate works aptly with internal and external teams to push the projects across the finishing line. The candidate is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced and global team.\n\n\nInterfacing with business customers, gathering requirements and delivering complete BI solutions to drive insights and inform product, operations, and marketing decisions.\nInterfacing with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL (Redshift, Oracle) and ability to use a programming and/or scripting language to process data for modeling\nEvolve organization wide Self-Service platforms\nBuilding metrics to analyze key inputs to forecasting systems\nRecognizing and adopting best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation\n\nA day in the life\n1) Solve analyses with well-defined inputs and outputs; drive to the heart of the problem and identify root causes\n2) Have the capability to handle large data sets in analysis\n3) Derive recommendations from analysis\n4) Understand the basics of test and control comparison; may provide insights through basic statistical measures such as hypothesis testing\n5) Communicate analytical insights effectively\n\nAbout the team\nAOP (Analytics Operations and Programs) team is missioned to standardize BI and analytics capabilities, and reduce repeat analytics/reporting/BI workload for operations across IN, AU, BR, MX, SG, AE, EG, SA marketplace.\n\nAOP is responsible to provide visibility on operations performance and implement programs to improve network efficiency and defect reduction. The team has a diverse mix of strong engineers, Analysts and Scientists who champion customer obsession.\n\nWe enable operations to make data-driven decisions through developing near real-time dashboards, self-serve dive-deep capabilities and building advanced analytics capabilities.\n\nWe identify and implement data-driven metric improvement programs in collaboration (co-owning) with Operations teams. 1+ years of tax, finance or a related analytical field experience\n2+ years of complex Excel VBA macros writing experience\nBachelors degree or equivalent\nExperience defining requirements and using data and metrics to draw business insights\nExperience with SQL or ETL Experience working with Tableau\nExperience using very large datasets",,,,"['Data analysis', 'Analytical', 'Test design', 'Hypothesis Testing', 'data integrity', 'Oracle', 'Business intelligence', 'Forecasting', 'Macros', 'SQL']",2025-06-12 14:06:19
Associate Analyst,Overture Rede,0 - 1 years,Not Disclosed,['Hyderabad'],"Job Title: Associate Analyst DataLocation: HyderabadExperience:03 YearsQualification: B\nComOpen Position(s):18Job Role:Maintain and update CRM, billing, and project data while supporting content creation and ensuring SLA-based client account management\nMust-Have Skills:-Understanding of advertising sales processes- CRM data entry and account updates-\nContent creation for internal and client-facing use- Invoice processing and account closure- Attention to detail and SLA adherence- Basic financial record management and reporting"",""Work_Experience0-1 year",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Client account management', 'Basic', 'Associate Analyst', 'Sales', 'Invoice processing', 'Finance', 'Billing', 'Advertising', 'Data entry', 'CRM']",2025-06-12 14:06:21
Business Operations Analyst,Qualcomm,3 - 6 years,Not Disclosed,['Bengaluru'],"Job Area: Operations Group, Operations Group > Business Operations\n\nGeneral Summary:\n\nHiring TitleBusiness Operations Analyst, (Compute GTM)\n\nAbout the GBFS TeamThe Global Business and Finance Support (GBFS) team provide support to HQ and the global regional team on Finance & Business Operation activities. This job role is for business operations related activities- Partner Onboarding, Global Channel Incentive and Marketing Development fund claims, fund requests, fund allocation, invoicing support and ad-hoc reporting.\n\nGeneral Job SummaryThis role serves as a key point of contact for both external customers and internal teams, providing essential support to HQ and Sales Teams. Responsibilities include overseeing account onboarding, managing product SKUs, administering partner offerings, and process MDF/GCI claims. Additionally, the role plays a vital part in ensuring precise reporting, smooth payment integration and communication to internal stakeholders/partners. The ideal candidate will be driven by a passion for fostering outstanding internal collaboration across the organization. Responsibilities include, but are not limited to, the following activities:\n\nJob Overview:\nOversee Partner account onboarding, manage product SKUs, and administer partner offerings\nprocessing of Market Development Funds and Global Channel Incentive claims, ensuring compliance with program guidelines and financial accuracy\nHandle marketing budgets, fund allocations, fund requests with accuracy\nEnsure seamless financial tracking, reporting, and billing processes.\nServe as a key contact for external customers and internal HQ and Sales Teams.\nProvide world-class assistance for Qualcomms products and services while fostering strong internal partnerships.\nPerform additional ad hoc business operations activities from time to time.\n\n\n:\n3 to 6 years relevant industry experience in Sales operations activities\nPrior experience in semiconductor industry, OEMs and partner management is desired.\nExcellent Advanced Excel Skills, Salesforce, data analysis and reporting.\nStrong analytical, problem solving and conceptual skills.\nPositive attitude and willingness to learn skills/tools\nFlexible for evening calls (8PM- 11PM IST) for HQ reviews and transition calls on regular basis and/or working in shift (2.30pm to 11.30pm) as needed\nStrong written and verbal communication skills.\n\n\nEducation :\nBachelors in Science / B.Tech / Commerce / Economics and/or,\nDiploma or Masters in business Analytics\nBusiness Administration from a reputed B-school.\n\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Engineering, Finance, Marketing, or related field and 2+ years of business operations or related experience.\nOR\nHigh School Diploma or equivalent and 4+ years of business operations or related experience.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'salesforce', 'sales operations', 'advanced excel', 'business operations', 'channel sales', 'business analytics', 'business development', 'partner management', 'distribution', 'sales', 'oems', 'business administration', 'marketing', 'sales management', 'dealer network']",2025-06-12 14:06:23
Sr. Business Analyst,Merkle B2b,8 - 13 years,Not Disclosed,['Mumbai'],"As a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms\nJob Description:\nSr. Business Analyst\nJob Description:\nAs a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms.\nKey Responsibilities\nUnderstand and identify the business issues / requirements and create a detailed Functional Requirement Document\nDevelop a prototype / framework that meets requirements and addresses the business issue.\nBrief the technical team on the requirements. Address and resolve all doubts/queries of the developer / tester. As and when required, check with stakeholders and seek clarity.\nEnsure smooth deployment of the solution and conduct training for end users as and when required.\nPost project completion; seek for feedback from project stakeholders.\nConduct a thorough impact analysis on system for change requests.\nAssist with solution testing and user acceptance testing plans and execution.\nUpdate and maintain solution documentation including requirements documents, data flows, schema/layout documentation, etc.\nMaintain the solution in production, working with end users, and facilitating change requests with the broader team using a defined change management process.\nQualifications + Skills\nBachelor s Degree or equivalent\n8+ years of experience in gathering and documenting solution requirements for the purposes of scope management, design, development and testing enablement.\nGood problem solving and business acumen\nExperience writing and maintaining solution documentation (requirements documents, data flows, User stories, etc.).\nExperience working within common delivery methodologies (e.g. agile and/or waterfall).\nExperience with business intelligence reporting (e.g. Power BI, Tableau, and/or similar platforms).\nExperience with system and user acceptance testing.\nExperience writing SQL to perform data analysis.\nStrong customer service orientation and collaboration skills.\nEffective communication skills, ability to simplify and structure complex concepts to streamline interactions and highlight key points.\nLocation:\nMumbai\nBrand:\nDentsu\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'Change management', 'Manager Quality Assurance', 'Prototype', 'Schema', 'Agile', 'Scope management', 'User acceptance testing', 'SQL']",2025-06-12 14:06:26
Technical Business Analysis Engineer II,Conduent,2 - 6 years,Not Disclosed,['Noida'],"JOB TITLE Technical Business Analysis Engineer II\n\n\nRESPONSIBILITIES\n\n\n\nMay perform one or more of the following:\n\n\nRequirement/Analysis\nAbility to comprehend Business Requirement Documents (BRD)\nMaintain and Update Data/Vendor Interfaces BRD\nInterprets requirements to create systems specifications documents to build and execute system.\nPerform Data Analysis, Audit, and associated research and provide subsequent resolutions.\nUnderstanding of database/SQL Query Writing\nWork alongside with Sr. members or individually (as required) to assist in smooth integration/transition of processes and create/maintain documentations for the same.\nResponsible for solving the data and Vendor files related issues and preparation of annual calendar, as applicable.\nExecute & Manage the assigned tasks {Data Analysis, Vendor files, Requirement Analysis} specific to your Tower\nHW Domain knowledge is good to have.\n\n  \nProcess\nAbility to think and conceptualize and/or implement ideas of process automation.\nFollow the standard practices and procedures specific to your Tower.\n\n  \nAccountability/Communication\nWork independently on tasks assigned.\nShould be able to Coach & mentor team members.\nDemonstrate ownership on work assigned to self and immediate sub-ordinates.\nManage Offshore/Onshore interaction and stakeholder communication as per the business needs.\nUpdate all documentation with task details and provide regular updates to team.\n\n\nAll other tasks as assigned.",Industry Type: BPM / BPO,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'business analysis', 'sql', 'brd', 'requirement analysis', 'hipaa', 'documentation', 'us healthcare', 'claims adjudication', 'user stories', 'claims processing', 'ar calling', 'denial management', 'claims', 'medical billing', 'process automation', 'rcm', 'revenue cycle management']",2025-06-12 14:06:28
Hiring Business Analyst with MSTR or Dataiku - Bangalore/ Chennai !!!!,Tech Mahindra,8 - 13 years,Not Disclosed,"['Chennai', 'Bengaluru']","A Business Analyst in the Financial Crime Surveillance Operations (FCSO) Data & Reporting PO Team understands the core concepts, principles, processes or procedures of Data & MI.\nExperienced in using MSTR reports & Dataiku. The FCSO Business Analyst gathers requirements from various stakeholders and creates user stories for the squad to understand and take it for delivery. They must have strong analytical skills, understand the strategic framework & make sense of data.\n\n1.Core Business Analysis Skills\nRequirement Gathering\nDocumentation\nGap analysis\n\n2. Data & MI Expertise\nData Analysis\nData mapping & Metrics understanding\nFCSO Process knowledge (Good to have)\n\n3. Technical Skills\nQuery Databases\nFamiliarity with BI Tools like Dataiku, MSTR\n\n4. Agile & Delivery management\n\nUnderstanding of Scrum for collaborating with Squads\nUser Story Creation\nBacklog Management\nStakeholder Management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Microstrategy', 'Business Analytics', 'Dataiku', 'Business Analysis']",2025-06-12 14:06:31
Business Analyst II,Conduent,5 - 8 years,Not Disclosed,['Noida'],"Responsibilities:\nProvide support to plan, organize, and deliver moderate to complex projects prioritized in alignment with the client\\u2019s expectations and business needs.Projects may include multiple disciplines and/or significant business process re-engineering efforts.\nPlan, coordinate and directs schedules.\nOrganizes project activities that may require interdepartmental meetings and communication ensuring completion of the program/project on schedule and within budget constraints.\nAt times directs the activities of project support staff and sub-contractors and is responsible for ensuring appropriate resources are allocated and maintained to facilitate the successful completion of the project.\nAssigns and monitors work of subject matter expert personnel, providing support and interpretation of instructions/objectives.\nManages and coordinates projects priorities that requires critical thinking and complex problem solving.\nLeads and communicates project scope, goals and responsibilities to project team; establish clear stakeholder expectations, and requirements of varying degrees of complexity.\nDevelops and maintains reporting procedures and monitors performance in project control activities; prepares and distributes reports related to project activities, general project management, and financial issues.\n\n\n:\n5 - 8 years of overall experience\nProficient in data analysis and reporting using MS Excel/Power BI (mandatory)\nProficient in creating project status and other presentation using MS PowerPoint (mandatory)\nExperience in communicating with end client (highly desirable)\nPMP Certified (highly desirable)\nProficient in Business Analysis (would be a plus)",Industry Type: BPM / BPO,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'presentation skills', 'power bi', 'business analysis', 'head hunting', 'screening', 'hiring', 'salary negotiation', 'project scheduling', 'bi', 'hrsd', 'sourcing', 'business process re-engineering', 'talent acquisition', 'pmp', 'it recruitment', 'recruitment']",2025-06-12 14:06:33
Data Engineer,Luxoft,5 - 8 years,Not Disclosed,['Pune'],"Help Group Enterprise Architecture team to develop our suite of EA tools and workbenches\nWork in the development team to support the development of portfolio health insights\nBuild data applications from cloud infrastructure to visualization layer\nProduce clear and commented code\nProduce clear and comprehensive documentation\nPlay an active role with technology support teams and ensure deliverables are completed or escalated on time\nProvide support on any related presentations, communications, and trainings\nBe a team player, working across the organization with skills to indirectly manage and influence\nBe a self-starter willing to inform and educate others\nSkills\nMust have\nB.Sc./M.Sc. degree in computing or similar\n5-8+ years experience as a Data Engineer, ideally in a large corporate environment\nIn-depth knowledge of SQL and data modelling/data processing\nStrong experience working with Microsoft Azure\nExperience with visualisation tools like PowerBI (or Tableau, QlikView or similar)\nExperience working with Git, JIRA, GitLab\nStrong flair for data analytics\nStrong flair for IT architecture and IT architecture metrics\nExcellent stakeholder interaction and communication skills\nUnderstanding of performance implications when making design decisions to deliver performant and maintainable software.\nExcellent end-to-end SDLC process understanding.\nProven track record of delivering complex data apps on tight timelines\nFluent in English both written and spoken.\nPassionate about development with focus on data and cloud\nAnalytical and logical, with strong problem solving skills\nA team player, comfortable with taking the lead on complex tasks\nAn excellent communicator who is adept in, handling ambiguity and communicating with both technical and non-technical audiences\nComfortable with working in cross-functional global teams to effect change\nPassionate about learning and developing your hard and soft professional skills\nNice to have\nExperience working in the financial industry\nExperience in complex metrics design and reporting\nExperience in using artificial intelligence for data analytics\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Power BI Developer\nBI Engineering\nIndia\nBengaluru\nSenior Power BI Developer\nBI Engineering\nIndia\nChennai\nSenior Power BI Developer\nBI Engineering\nIndia\nGurugram\nPune, India\nReq. VR-114797\nBI Engineering\nBCM Industry\n02/06/2025\nReq. VR-114797\nApply for Data Engineer in Pune\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['GIT', 'Enterprise architecture', 'Analytical', 'Artificial Intelligence', 'Data processing', 'Data analytics', 'QlikView', 'JIRA', 'SDLC', 'SQL']",2025-06-12 14:06:35
Business Analyst,Global Banking Organization,3 - 8 years,Not Disclosed,['Bengaluru'],"Key Skills: Marketing Analytics, Analytics, SQL, Python, Business Analysis, Predictive Analysis, Statistical Analysis.\nRoles and Responsibilities:\nGathers operational data from various cross-functional stakeholders to examine past business performance.\nIdentifies data patterns and trends, and provides insights to enhance business decision-making capability in business planning, process improvement, solution assessment, etc.\nRecommends actions for future developments and strategic business opportunities, as well as enhancements to operational policies.\nMay be involved in exploratory data analysis, confirmatory data analysis, and/or qualitative analysis.\nTranslates data into consumer or customer behavioral insights to drive targeting and segmentation strategies, and communicates clearly and effectively to business partners and senior leaders all findings.\nContinuously improves processes and strategies by exploring and evaluating new data sources, tools, and capabilities.\nWorks closely with internal and external business partners in building, implementing, tracking, and improving decision strategies.\nAppropriately assesses risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing, and reporting control issues with transparency.\nExperience Requirement:\n3-8 years of relevant experience in business analytics, data analysis, or business intelligence roles.\nProven experience in using analytical tools such as SQL, Excel, Python, or R to extract and analyze data.\nHands-on experience with data visualization tools such as Tableau, Power BI, or similar platforms.\nExperience working in cross-functional teams and supporting decision-making through data-driven insights.\nStrong track record of identifying business trends and providing actionable recommendations based on data analysis.\nDemonstrated ability to handle multiple projects simultaneously with a strong attention to detail.\nEducation: B.Tech M.Tech (Dual), MCA, B.Tech.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Marketing Analytics', 'Analytics', 'SQL', 'Python', 'Business Analysis', 'Statistical Analysis.', 'Predictive Analysis']",2025-06-12 14:06:38
"Business Research Analyst - II, RBS ACCX Program",Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Amazon.com strives to be Earths most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want low prices, vast selection, and convenience Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazons evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the companys DNA. The worlds brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.\n\nOverview of the role\nThe Business Research Analyst will be responsible for Data and Machine learning part of continuous improvement projects across the Discoverability space. This will require collaboration with local and global teams. The Research Analyst should be a self-starter who is passionate about discovering and solving complicated problems, learning complex systems, working with numbers, and organizing and communicating data and reports. The Research Analyst will perform Big data analysis to identify patterns, train model to generate product to product relationship and product to brand & model relationship. The Research Analyst is also expected to continuously improve the ML/LLM solutions in terms of precision & recall, efficiency and scalability. The Research Analyst should be able to write clear and detailed functional specifications based on business requirements.\n\n\nScoping, driving and delivering complex projects across multiple teams.\nPerforms root cause analysis by understanding the data need, get data / pull the data and analyze it to form the hypothesis and validate it using data.\nBuild programs to create a culture of continuous improvement within the business unit, and foster a customer-centric focus on the quality, productivity, and scalability of our services.\nFind the scalable solution for business problem by executing pilots and build Deterministic and ML/LLM models.\nManages meetings, business and technical discussions regarding their part of the projects.\nMakes recommendations and decisions that impact development schedules and the success for a product or project.\nDrives team(s)/partners to meet program and/or product goals.\nCoordinates design effort between internal team and External team to develop optimal solutions.\nPerforms supporting research, conduct analysis of the bigger part of the projects and effectively interpret reports to identify opportunities, optimize processes, and implement changes.\nAbility to convince and interact with stakeholders at all level either to gather data and information or to execute and implement according to the plan.\nAbility to deal with ambiguity and problem solver\nCommunicate ideas effectively and with influence (both verbally and in writing), within and outside the team.\n\nKey Performance Areas:\nSolve large and complex business problems by aligning multiple teams together.\nData analytics and Data Sciences\nMachine learning\nProject/Program Management\nAutomation initiative conceptualization and implementation\nBig Data analytics\nProduct development Scoping and Testing\nDefect Elimination\nAgile Continuous Improvement\n\nAbout the team\nThe RBS group in Chennai/Bangalore is an integral part of Amazon online product lifecycle and buying operations. The team is designed to ensure Amazon remains competitive in the online retail space with the best price, wide selection and good product information. The team s primary role is to create and enhance retail selection on the worldwide Amazon online catalog. The tasks handled by this group have a direct impact on customer buying decisions and online user experience. 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience\nExperience with data visualization using Tableau, Quicksight, or similar tools\nExperience with data modeling, warehousing and building ETL pipelines\nExperience writing complex SQL queries\nExperience in Statistical Analysis packages such as R, SAS and Matlab\nExperience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift\nExperience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets",,,,"['Automation', 'Data analysis', 'SAS', 'Data modeling', 'Machine learning', 'Agile', 'Oracle', 'Data mining', 'MATLAB', 'Python']",2025-06-12 14:06:40
Sr. Business Analyst,Merkle Science,10 - 15 years,Not Disclosed,['Mumbai'],"As a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms\nJob Description:\nSr. Business Analyst\nJob Description:\nAs a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms.\nKey Responsibilities\nUnderstand and identify the business issues / requirements and create a detailed Functional Requirement Document\nDevelop a prototype / framework that meets requirements and addresses the business issue.\nBrief the technical team on the requirements. Address and resolve all doubts/queries of the developer / tester. As and when required, check with stakeholders and seek clarity.\nEnsure smooth deployment of the solution and conduct training for end users as and when required.\nPost project completion; seek for feedback from project stakeholders.\nConduct a thorough impact analysis on system for change requests.\nAssist with solution testing and user acceptance testing plans and execution.\nUpdate and maintain solution documentation including requirements documents, data flows, schema/layout documentation, etc.\nMaintain the solution in production, working with end users, and facilitating change requests with the broader team using a defined change management process.\nQualifications + Skills\nBachelor s Degree or equivalent\n8+ years of experience in gathering and documenting solution requirements for the purposes of scope management, design, development and testing enablement.\nGood problem solving and business acumen\nExperience writing and maintaining solution documentation (requirements documents, data flows, User stories, etc.).\nExperience working within common delivery methodologies (e.g. agile and/or waterfall).\nExperience with business intelligence reporting (e.g. Power BI, Tableau, and/or similar platforms).\nExperience with system and user acceptance testing.\nExperience writing SQL to perform data analysis.\nStrong customer service orientation and collaboration skills.\nEffective communication skills, ability to simplify and structure complex concepts to streamline interactions and highlight key points.\nLocation:\nMumbai\nBrand:\nDentsu\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'Change management', 'Manager Quality Assurance', 'Prototype', 'Schema', 'Agile', 'Scope management', 'User acceptance testing', 'SQL']",2025-06-12 14:06:42
Data Scientist,"Sourced Group, an Amdocs Company",4 - 9 years,Not Disclosed,['Gurugram'],"0px> Who are we?\nIn one sentence\nThis is a hands-on position for a motivated and talented innovator. The Data Scientist performs data mining and develops algorithms that provide insight from data.\nWhat will your job look like?\nYou will be responsible for and perform end-top-end data-based research.\nYou will craft data mining solutions to be implemented and executed with alignment to the planned scope and design coverage and needs/uses, demonstrating knowledge and a broad understanding of E2E business processes and requirements.\nYou will define the data analytics research plan, scope and resources required to meet the objectives of his/her area of ownership.\nYou will identify and analyze new data analytic directions and their potential business impact to determine the accurate prioritization of data analytics activities based on business needs and analytics value.\nYou will identify data sources, supervises the data collection process and crafts the data structure in collaboration with data experts (BI or big-data) and subject matter and business experts. Ensures that data used in the data analysis activities are of the highest quality.\nYou will construct data models (algorithms and formulas) for required business needs and predictions.\nYou will present results, including the preparation of patents and white papers and facilitating presentations during conferences.\nAll you need is...\nPh.D. in Computer Science, Mathematics or Statistics\n4 years experience in tasks related to data analytics\nKnowledge of telecommunications and of the subject area being investigated - advantage\nKnowledge in the product (ACC or other) application knowledge and configuration knowledge\nKnowledge in BSS, billing, Telco and the business processes\nFamiliarity in the Telco Networking - mobile, landline, cable TV, Internet\nknowledge in Oracle SQL\nWhy you will love this job:\nYou will ensure timely resolution or critical issue within the agreed SLA. This includes creating a positive customer support experience and build strong relationships through problem understanding, presenting promptly on progress, and handling customers with a professional demeanour.\nYou will be able to demonstrates an understanding of key business drivers and ensures strategic directions are followed and the organization succeeds\nWe are a dynamic, multi-cultural organization that constantly innovates and empowers our employees to grow. Our people our passionate, daring, and phenomenal teammates that stand by each other with a dedication to creating a diverse, inclusive workplace!\nWe offer a wide range of stellar benefits including health, dental, vision, and life insurance as well as paid time off, sick time, and parental leave!\n",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Bss', 'Networking', 'Billing', 'Data collection', 'Customer handling', 'Customer support', 'Data mining', 'Amdocs']",2025-06-12 14:06:45
Data Engineer - Databricks,KPI Partners,3 - 6 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","About KPI Partners.\nKPI Partners is a leading provider of data analytics solutions, dedicated to helping organizations transform data into actionable insights. Our innovative approach combines advanced technology with expert consulting, allowing businesses to leverage their data for improved performance and decision-making.\n\nJob Description.\nWe are seeking a skilled and motivated Data Engineer with experience in Databricks to join our dynamic team. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and data processing solutions that support our analytics initiatives. You will collaborate closely with data scientists, analysts, and other engineers to ensure the consistent flow of high-quality data across our platforms.",,,,"['python', 'data analytics', 'analytical', 'scala', 'pyspark', 'microsoft azure', 'data warehousing', 'data pipeline', 'data architecture', 'data engineering', 'sql', 'data bricks', 'cloud', 'analytics', 'data quality', 'data modeling', 'gcp', 'teamwork', 'integration', 'aws', 'etl', 'programming', 'communication skills', 'etl scripts']",2025-06-12 14:06:47
Senior Business Analyst Healthcare (FHIR),Happiest Minds Technologies,10 - 15 years,Not Disclosed,['Bengaluru'],"Job Title: Senior Business Analyst Healthcare (FHIR)\nLocation: Bangalore, India\nExperience: 1015 years\nEmployment Type: Full-time\n\nAbout the Role:\nWe are seeking a skilled and experienced Senior Business Analyst Healthcare (FHIR) to drive the design and implementation of FHIR-based solutions that enable seamless interoperability across healthcare systems. This role requires close collaboration with stakeholders, technical teams, and healthcare domain experts to ensure robust, compliant, and scalable data exchange mechanisms.",,,,"['HL7', 'Business Analyst', 'FHIR']",2025-06-12 14:06:49
Data Annotation hiring For Fresher || Excellent communication skills,Multinational Company,0 - 4 years,1-3 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Lead data annotation and collection projects.\nDevelop and implement data annotation guidelines and processes.\nTrain and manage data annotation teams.\nCollaborate with data scientists and engineers to understand data requirements.\n\nHR - 63980 09438\n\nRequired Candidate profile\nQualification - Graduate\nSalary :-\nCTC\n25,000 / experience\n20,000 / fresher\nExperience - Data Annotation only\nTransport:- Both Side\n\n5 Day working / Rotation shift / 2 day Rotation week off",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Object Detection', 'Data Annotation', 'Business Intelligence', 'Digital Image Processing', 'Data Management', 'Image Recognition', 'Image Analysis', 'Annotation', 'Deep Learning', 'Pattern Recognition', 'Image Processing', 'Imaging', 'Content Moderation', 'Data Warehousing', 'Data Analytics']",2025-06-12 14:06:52
Associate Data Engineer,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role We are seeking a Associate Data Engineer to design, build, and maintain scalable data solutions that drive business insights. You will work with large datasets, cloud platforms (AWS preferred), and big data technologies to develop ETL pipelines, ensure data quality, and support data governance initiatives.\nDevelop and maintain data pipelines, ETL/ELT processes, and data integration solutions.\nDesign and implement data models, data dictionaries, and documentation for accuracy and consistency.\nEnsure data security, privacy, and governance standard processes.\nUse Databricks, Apache Spark (PySpark, SparkSQL), AWS, Redshift, for scalable data processing.\nCollaborate with cross-functional teams to understand data needs and deliver actionable insights.\nOptimize data pipeline performance and explore new tools for efficiency.\nFollow best practices in coding, testing, and infrastructure-as-code (CI/CD, version control, automated testing).\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. Strong problem-solving, critical thinking, and communication skills.\nAbility to collaborate effectively in a team setting.\nProficiency in SQL, data analysis tools, and data visualization.\nHands-on experience with big data technologies (Databricks, Apache Spark, AWS, Redshift ).\nExperience with ETL tools, workflow orchestration, and performance tuning for big data.\nBasic Qualifications:\nBachelors degree and 0 to 3 years of experience OR Diploma and 4 to 7 years of experience in Computer science, IT or related field.\nPreferred Qualifications:\nKnowledge of data modeling, warehousing, and graph databases\nExperience with Python, SageMaker, and cloud data platforms.\nAWS Certified Data Engineer or Databricks certification preferred.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'data analysis', 'data modeling', 'data warehousing', 'data visualization', 'Databricks', 'ETL', 'AWS', 'SQL', 'Apache Spark', 'Python']",2025-06-12 14:06:54
Data Annotation // Upto 3 LPA,Skill Seekers Consultants,0 - 5 years,2.25-3 Lacs P.A.,"['Noida', 'New Delhi', 'Gurugram', 'Greater Noida', 'Delhi / NCR']","- Job Profile : Data Annotation\n- Location : Gurugram Sector 18\n- Rotational Shifts and Offs\n- Both side Cabs as per International Process\n- Excellent English speaking candidates\n- Freshers and Experienced candidates\n- Data Annotation Assessment\n\nRequired Candidate profile\nYouTube Channel - Sonu Chaurasiya\n\nInterview Location Video --- https://youtu.be/1AmXOLMEPEw\nGaurav Tower near Bank of Baroda pvr, , Vikaspuri, New Delhi, Delhi, 110018\n4th Floor- Waiting area",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Fluent English', 'Back Office', 'Interpretation', 'Data Annotation', 'BPO', 'Communication Skills', 'Transcription', 'Data Analysis', 'Data Collection', 'English Typing', 'Annotation', 'Strong Communication Skills']",2025-06-12 14:06:56
Data Scientist,Xoom,2 - 4 years,Not Disclosed,['Bengaluru'],"Job Summary\nWhat you need to know about the role\n\nEach Data Scientist on this team has full ownership of a portfolio of a product and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.\n\nMeet our team\n\nPayPals Global Fraud Protection team is responsible for partnering with global business units to manage a variety of risk of various types, including identity fraud, account takeover, stolen financial fraud, and credit issues. This is an exciting department that plays an important role in contributing PayPals bottom line financial savings, ensuring safe and secure global business growth, and delivering the best customer experience.\n\nThis open opportunity is within the Large Merchant and Markets Fraud Risk team. This portfolio is comprised of PayPal s newest leading-edge payments solutions, such as Risk-as-Service, Fastlane, PayPal Complete Payments, etc. as well as customized experiences developed for the company s highest-priority strategic Markets and Partnerships.\nJob Description\nYour way to impact\nYou will be the Data Scientist in the Fraud Risk team , where you will work on leading new projects to build and improve the Risk strategies to prevent fraud using the Risk tooled and custom data & AL/ML models. In this position, you will be partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.\nYour day to day\nIn your day to day role you will -\nIn this role you will have full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates.\nCollaborate with different teams to develop strategies for fraud prevention, loss savings, and optimize transaction declines or improve customer friction.\nYou will work together with cross-functional teams to deliver solutions and providing Risk analytics on frustration trend/ KPIs monitoring or alerting for fraud events.\nThese solutions will adapt PayPal s advanced proprietary fraud prevention tools enabling business growth.\nWhat do you need to bring-\n2-4 years of relevant experience working with large-scale complex dataset.\nStrong analytical mindset, ability to decompose business requirements into an analytical plan, and execute the plan to answer those business questions\nExcellent communication skills, equally adept at working with engineers as well as business leaders\nWant to build new solutions and invent new approaches to big, ambiguous, critical problems\nStrong working knowledge of Excel, SQL and Python/R\nTechnical Proficiency Exploratory Data Analysis and expertise in preparing a clean and structured data for model development. Experience in applying AI/ML techniques for business decisioning including supervised and unsupervised learning (e.g., regression, classification, clustering, decision trees, anomaly detection, etc.). Knowledge of model evaluation techniques such as Precision, Recall, ROC-AUC Curve, etc. along with basic statistical concepts.\nPreferred Qualification\nSubsidiary\nPayPal\nTravel Percent\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https//www.paypalbenefits.com .\nWho We Are\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. .\nBelonging at PayPal\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: Internet,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Risk analytics', 'Analytical', 'Diversity and Inclusion', 'ROC', 'Wellness', 'Risk management', 'Forecasting', 'Monitoring', 'SQL']",2025-06-12 14:06:58
"Program Analyst, Senior",Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Operations Group, Operations Group > Program Analyst\n\nGeneral Summary:\n\nAssists with program development and implementation through managing processes, procedures, and tools that improve efficiencies. A Program Analyst coordinates across teams and monitors timelines, budgets, risks, and priorities to achieve program progress. Typically, a program needing a Program Analyst will be of significant size and will require expertise related to the development of project management mechanisms.\n\nMinimum Qualifications:\n\nBachelors degree in engineering, Computer Science, or related field.\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Management, Computer Science, Engineering, Computer Science, or related field.\nOR\nHigh School Diploma or equivalent and 2+ years of relevant work experience.\n\nPreferred Qualifications:\n\nBachelors degree in electrical, Electronics engineering, Computer Science, or related field.\n\n3+ years of experience creating, scheduling, and maintaining program plans or related experience.\n2+ years of experience with program management tools.\n\nPrincipal Duties and Responsibilities:\nRegularly coordinates with third parties and/or internal customers for large, complex programs to identify and meet needs, track and communicate program status updates, and ensure compliance with processes and guidelines.\nPrepares and discusses agenda for review board meetings under guidance of the Program Manager and documents key discussion points, project plan changes, and stakeholder needs.\nContributes to and updates project plans to support Program Managers or Leads on large programs that include priorities, timelines, critical tasks, stakeholder identification for each task, and forecasted resource allocation.\nCollects, compiles, monitors, and maintains budget data, identifies potential issues, and communicates to the Program Manager.\nTracks the progress and execution of complex deliverables to ensure deadlines are met, and identifies and escalates issues that may impact deadlines.\nCoordinates schedules and task assignments for complex projects by following proper project management practices with some guidance from the Program Manager.\nManages and communicates changes in program timelines, priorities, and deliverables to stakeholders.\nIdentifies risks and issues in limited capacity that occur throughout the program lifecycle, communicates issues to the Program Manager, and identifies team members needed to determine a solution.\nGathers, analyzes, and interprets data and program metrics using advanced tools (e.g., macros, pivot tables, charts, graphs) and resolves inconsistencies.\nMaintains and updates databases using advanced aspects of data management tools (e.g., Excel, agile).\nSynthesizes moderately complex data and metrics into a summary of key trends, risks, and changes, and presents results into a report that can be easily understood by key stakeholders.\nGathers feedback and implements improvements to assigned planning processes, tools, and methods.\n\nLevel of Responsibility:\nWorking under some supervision.\nProviding some supervision/guidance to others.\nMaking decisions that are moderate in impact; errors may have relatively minor financial impact or affect on projects, operations, or customer relationships; errors may require involvement beyond immediate work group to correct.\nUsing verbal and written communication skills to convey information that may be somewhat complex to others who may have limited knowledge of the subject in question. May require basic negotiation and influence, cooperation, tact, and diplomacy, etc.\nCompleting most tasks with multiple steps which can be performed in various orders; some planning and prioritization must occur to complete the tasks effectively; mistakes may result in some rework.\nExercising creativity to draft original documents, imagery, or work products within established guidelines.\nUsing deductive problem solving to solve moderately complex problems; most problems have defined processes of diagnosis/detection; some limited data analysis may be required.\n\nThe responsibilities of this role do not include\nBudgetary accountability.\nInfluence over key organizational decisions.\nRole in strategic planning.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['project management', 'macros', 'program management', 'computer science', 'agile', '3d modeling', 'rest', 'data management', 'production', 'assembly design', 'design engineering', 'autocad', 'catia', 'part modeling', 'sheet metal design', 'solid works', 'drafting', 'creo', 'manufacturing', 'part design']",2025-06-12 14:07:01
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an exceptional Data Scientist to join a team of experts in the field of machine learning, and work together to tackle challenging problems across diverse compliance domains. We leverage risk models (including boosted trees and graph neural networks) as well as vision and large-language-models (LLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for multi-modal classification, intent detection, information retrieval, anomaly and fraud detection, and generative AI.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of image, text and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nExplore and evaluate state-of-the-art algorithms and approaches in risk modeling and vision/language models\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\nEvaluate model performance in production and refresh/implement necessary updates to maintain optimal system performance.\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nContributing to team retrospectives for continuous improvements\nParticipating in science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists building AI/ML solutions to make Amazon Earth s most trusted shopping destination for safe and compliant products. 2+ years of data scientist experience\n3+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience\n3+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\nExperience applying theoretical models in an applied environment\nKnowledge of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Experience in Python, Perl, or another scripting language\nExperience in a ML or data scientist role with a large technology company",,,,"['Data analysis', 'SAS', 'Neural networks', 'risk modeling', 'Machine learning', 'Information retrieval', 'Perl', 'MATLAB', 'Auditing', 'Python']",2025-06-12 14:07:03
Business Analyst,CGI,6 - 11 years,Not Disclosed,['Hyderabad'],"Business Data Analyst - HealthCare\nPosition Description\nJob Summary\nWe are seeking an experienced and results-driven Business Data Analyst with 5+ years of hands-on experience in data analytics, visualization, and business insight generation. This role is ideal for someone who thrives at the intersection of business and datatranslating complex data sets into compelling insights, dashboards, and strategies that support decision-making across the organization.\nYou will collaborate closely with stakeholders across departments to identify business needs, design and build analytical solutions, and tell compelling data stories using advanced visualization tools.\nKey Responsibilities\nData Analytics & Insights Analyze large and complex data sets to identify trends, anomalies, and opportunities that help drive business strategy and operational efficiency.\n• Dashboard Development & Data Visualization Design, develop, and maintain interactive dashboards and visual reports using tools like Power BI, Tableau, or Looker to enable data-driven decisions.\n• Business Stakeholder Engagement Collaborate with cross-functional teams to understand business goals, define metrics, and convert ambiguous requirements into concrete analytical deliverables.\n• KPI Definition & Performance Monitoring Define, track, and report key performance indicators (KPIs), ensuring alignment with business objectives and consistent measurement across teams.\n• Data Modeling & Reporting Automation Work with data engineering and BI teams to create scalable, reusable data models and automate recurring reports and analysis processes.\n• Storytelling with Data Communicate findings through clear narratives supported by data visualizations and actionable recommendations to both technical and non-technical audiences.\n• Data Quality & Governance Ensure accuracy, consistency, and integrity of data through validation, testing, and documentation practices.\nRequired Qualifications\nBachelor’s or Master’s degree in Business, Economics, Statistics, Computer Science, Information Systems, or a related field.\n• 5+ years of professional experience in a data analyst or business analyst role with a focus on data visualization and analytics.\n• Proficiency in data visualization tools: Power BI, Tableau, Looker (at least one).\n• Strong experience in SQL and working with relational databases to extract, manipulate, and analyze data.\n• Deep understanding of business processes, KPIs, and analytical methods.\n• Excellent problem-solving skills with attention to detail and accuracy.\n• Strong communication and stakeholder management skills with the ability to explain technical concepts in a clear and business-friendly manner.\n• Experience working in Agile or fast-paced environments.\nPreferred Qualifications\nExperience working with cloud data platforms (e.g., Snowflake, BigQuery, Redshift).\n• Exposure to Python or R for data manipulation and statistical analysis.\n• Knowledge of data warehousing, dimensional modeling, or ELT/ETL processes.\n• Domain experience in Healthcare is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Healthcare Domain', 'Bigquery', 'Redshift Aws', 'Snowflake', 'Data Analytics', 'Data Visualization', 'Python']",2025-06-12 14:07:05
Financial Data Operator,International Communication Services India Private Limited,0 - 2 years,Not Disclosed,['Pune'],"*Job Description:\n-We are looking for a detail-oriented Financial Data Operator to join our team.\n-Your primary responsibility will be to update, maintain, and record financial information in both Japanese and English using computerized databases.\n-The accuracy of these records will directly support our clients' operations.\n*Responsibilities:\n-Accurately collect and enter data into financial databases.\n-Maintain precise records in Japanese and English.\n-Perform routine data checks to ensure accuracy and consistency.\n-Utilize spreadsheets and online tools efficiently.\n-Collaborate with the team to troubleshoot and solve challenges effectively.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer Proficiency', 'Team Coordination', 'Jlpt N4', 'Data Analysis', 'Typing Skills', 'Teamwork']",2025-06-12 14:07:07
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an exceptional Data Scientist to join a team of experts in the field of machine learning, and work together to tackle challenging problems across diverse compliance domains. We leverage multi-modal and large-language-models (LLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for multi-modal classification, intent detection, information retrieval, anomaly and fraud detection, and generative AI.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of image, text and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nExplore and evaluate state-of-the-art algorithms and approaches in multi-modal classification, large language models (LLMs), intent detection, information retrieval, anomaly and fraud detection, and generative AI\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nContributing to team retrospectives for continuous improvements\nParticipating in science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists building AI/ML solutions to make Amazon Earth s most trusted shopping destination for safe and compliant products. 2+ years of data scientist experience\n2+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience\n2+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\nExperience applying theoretical models in an applied environment\nKnowledge of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Experience in Python, Perl, or another scripting language\nExperience in a ML or data scientist role with a large technology company",,,,"['Data analysis', 'Statistical modeling', 'SAS', 'Machine learning', 'Information retrieval', 'Perl', 'MATLAB', 'Fraud detection', 'Auditing', 'Python']",2025-06-12 14:07:10
Data Scientist,New Relic One,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an experienced and dynamic Senior Data Scientist to join our team. You will be primarily responsible for driving data-oriented projects and transforming ambiguous business problems into clear, actionable insights as well as productionalizing insights. The ideal candidate is adept at understanding the business needs that are often quantitatively ambiguous and using large complex data sets to find opportunities for product and process optimization.\nWhat youll do\nAnalyzing complex datasets, applying advanced statistical methods as necessary (e.g., time series forecasting, classification, linear/logistic regression).\nDesigning and deploying data-science and technology-based algorithmic solutions to address business needs.\nTranslating data findings into actionable business insights and plans.\nCollaborating effectively with internal stakeholders, understanding their needs and being able to communicate data-driven recommendations.\nPresenting information using data visualization techniques and clearly communicating complex findings and ideas to non-technical stakeholders.\nThis role requires\n2+ years of experience\nProven experience as a Data Scientist, or in a similar role.\nPhD or Masters degree in Statistics, Mathematics, Computer Science, or related quantitative field.\nStrong understanding and application of advanced statistical techniques and concepts, including but not limited to machine learning algorithms, classification, regression, and time series analysis.\nProficiency with data analysis tools and languages such as Python, SQL, etc.\nFamiliarity with data visualization tools (e.g., Looker, Tableau, PowerBI, etc.).\nStrong problem-solving abilities, business acumen, and excellent communication skills.\nAbility to work independently and with minimal supervision.Proven ability in managing and delivering on multiple, competing priorities.\nPrior experience with stakeholder management and ability to present complex data in a clear manner to non-technical audience.\nBonus points if you have\nExperience in Observability is a plus.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAN', 'Logistic regression', 'Data analysis', 'Process optimization', 'Machine learning', 'Stakeholder management', 'Forecasting', 'SQL', 'Python']",2025-06-12 14:07:12
Senior Business Analyst,Skillsoft Software Services,2 - 7 years,Not Disclosed,['Hyderabad'],"India-based candidates only. We’re primarily a NYC-based team, but have a growing international team. \n \nROLE OVERVIEW:  \nAs a Senior Data Analyst, you will be pivotal in driving strategic decision-making for the Codecademy consumer and enterprise business lines. Reporting to the senior manager, Strategy and business Operations, this role will work cross-functionally to tackle the business’ highest priorities. You will utilize your technical expertise in data analytics, financial modeling, and executive communication to create actionable business strategies that drive growth.",,,,"['snowflake', 'python', 'data analytics', 'data analysis', 'modeling', 'analytical', 'verbal communication', 'business analysis', 'sql', 'analytics', 'marketing analytics', 'data integration tools', 'looker', 'writing', 'financial modelling', 'data visualization', 'business operations', 'reporting', 'communication skills']",2025-06-12 14:07:15
MDM Associate Data Steward,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\n\nRole Description\n\nWe are seeking an MDM Associate Data Steward who will be responsible for ensuring the accuracy, completeness, and reliability of master data across critical business domains such as Customer, Product, Affiliations, and Payer. This role involves actively managing and curating master data through robust data stewardship processes, comprehensive data cataloging, and data governance frameworks utilizing Informatica or Reltio MDM platforms. Additionally, the incumbent will perform advanced data analysis, data validation, and data transformation tasks through SQL queries and Python scripts to enable informed, data-driven business decisions. The role emphasizes cross-functional collaboration with various teams, including Data Engineering, Commercial, Medical, Compliance, and IT, to align data management activities with organizational goals and compliance standards.\n\nRoles & Responsibilities\nResponsible for master data stewardship, ensuring data accuracy and integrity across key master data domains (e.g., Customer, Product, Affiliations).\nConduct advanced data profiling, cataloging, and reconciliation activities using Informatica or Reltio MDM platforms.\nManage the reconciliation of potential matches, ensuring accurate resolution of data discrepancies and preventing duplicate data entries.\nEffectively manage Data Change Request (DCR) processes, including reviewing, approving, and documenting data updates in compliance with established procedures and SLAs.\nExecute and optimize SQL queries for validation and analysis of master data.\nPerform basic Python for data transformation, quality checks, and automation.\nCollaborate effectively with cross-functional teams including Data Engineering, Commercial, Medical, Compliance, and IT to fulfill data requirements.\nSupport user acceptance testing (UAT) and system integration tests for MDM related system updates.\nImplement data governance processes ensuring compliance with enterprise standards, policies, and frameworks.\nDocument and maintain accurate SOPs, Data Catalogs, Playbooks, and SLAs.\nIdentify and implement process improvements to enhance data stewardship and analytic capabilities.\nPerform regular audits and monitoring to maintain high data quality and integrity.\nBasic Qualifications and Experience\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related fieldOR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related fieldOR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional\n\nSkills:\nMust-Have Skills:\nDirect experience in data stewardship, data profiling, and master data management.\nHands-on experience with Informatica or Reltio MDM platforms.\nProficiency in SQL for data analysis and querying.\nKnowledge of data cataloging techniques and tools.\nBasic proficiency in Python scripting for data processing.\nGood-to-Have\n\nSkills:\nExperience with PySpark and Databricks for large-scale data processing.\nBackground in the pharmaceutical, healthcare, or life sciences industries.\nFamiliarity with AWS or other cloud-based data solutions.\nStrong project management and agile workflow familiarity (e.g., using Jira, Confluence).\nUnderstanding of regulatory compliance related to data protection (GDPR, CCPA).\nProfessional Certifications\nAny ETL certification ( e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nSoft\n\nSkills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data management', 'python', 'project management', 'data analysis', 'data stewardship', 'agile database', 'data processing', 'sql', 'data profiling']",2025-06-12 14:07:17
Senior Functional Business Analyst,Luxoft,5 - 10 years,Not Disclosed,['Gurugram'],"Work closely with business stakeholders to understand, document, and prioritize requirements.\nConduct detailed analysis of current-state processes for client onboarding, credit scoring, lending workflows, and compliance.\nDefine and document user stories, functional specifications, process flows, and data mappings.\nSupport the product owner with backlog refinement, sprint planning, and prioritization.\nFacilitate workshops and walkthroughs with subject matter experts.\nEnsure alignment between business requirements and technical deliverables.\nAssist with UAT planning, test case development, and defect triaging.\nMaintain strong communication with project managers, developers, testers, and stakeholders throughout the SDLC.\nSkills\nMust have\n5+ years of experience as a Functional Business Analyst in the banking or financial services domain.\nProven domain expertise in at least three of the following:\nC&IB Client Onboarding\nCredit and Risk Scoring\nLending Processes\nAML (Anti-Money Laundering)\nKYC\nStrong verbal and written communication skills in English.\nAbility to create structured and well-documented artefacts (resumes will be reviewed for documentation quality).\nExperience working in Agile delivery models (Scrum, SAFe).\nFamiliarity with tools like JIRA, Confluence, and MS Office Suite.\nNice to have\nExposure to regulatory change or transformation programs.\nKnowledge of GRC platforms or tools (e.g., Archer, ServiceNow GRC).\nPrior experience in data analysis or data mapping activities.\nFamiliarity with integration patterns between front-office and back-office systems.\nAwareness of global banking regulations and compliance frameworks.\nOther\nLanguages\nEnglish: B2 Upper Intermediate\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nJunior Implementation Consultant\nOther Vendor specific (Quantum, Coremont etc.)\nSingapore\nSingapore\nFunctional BA (Orchestrade/Murex/Calypso)\nOther Vendor specific (Quantum, Coremont etc.)\nHong Kong\nHong Kong\nJunior Implementation Consultant\nOther Vendor specific (Quantum, Coremont etc.)\nSingapore\nSingapore\nGurugram, India\nReq. VR-114629\nOther Vendor specific (Quantum, Coremont etc.)\nBCM Industry\n27/05/2025\nReq. VR-114629\nApply for Senior Functional Business Analyst in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Front office', 'Agile', 'calypso', 'Back office', 'Scrum', 'JIRA', 'SDLC', 'Murex', 'Financial services']",2025-06-12 14:07:19
Manager-Business Analyst,Jubilant FoodWorks (JFL),8 - 12 years,Not Disclosed,['Noida'],"The IT Business Analyst is responsible for bridging business needs and IT capabilities, ensuring that technology solutions align with strategic objectives. This role involves analysing business processes including SAP, gathering requirements, and collaborating with IT teams to develop effective solutions. The ideal candidate has strong analytical skills, deep understanding of both business processes preferably Finance background along with IT systems including SAP, and experience in project management.\n\nKey Responsibilities:\n\nBusiness Requirements Gathering\nWork with business stakeholders to identify needs, pain points, and opportunities for process improvement.\nDocument business requirements in clear, detailed formats for technical teams.\n\nSolution Design and Analysis\nAnalyze and evaluate technology solutions that best align with business requirements.\nCreate functional specifications, use cases, and workflow diagrams to communicate solutions effectively.\n\nProject Support and Coordination\nCollaborate with project managers to ensure that projects meet business goals and timelines.\nTrack progress and provide updates on requirements, ensuring adherence to project scope and budget.\n\nTesting and Quality Assurance\nDevelop test cases and participate in system testing to validate that requirements are met.\nAssist in User Acceptance Testing (UAT) and ensure successful project delivery.\n\nContinuous Improvement and Documentation\nRecommend improvements to business processes based on data analysis.\nMaintain and update documentation for requirements, processes, and system changes.\n\nPreferred qualification & skills\n\nBachelors degree preferably in Finance Business, IT, or a related field.\n8+ years of experience in business analysis or a similar role. Experience of Finance & HR domain is preferred under QSR Industry.\nStrong analytical and problem-solving skills, with experience in requirements gathering and process improvement.\nExcellent communication skills, with the ability to work cross-functionally.\nFamiliarity with project management methodologies (Agile, Waterfall).\nKnowledge of data analysis and ERP preferably SAP, CRM, or other business applications.",Industry Type: Hotels & Restaurants,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['User Acceptance Testing', 'SAP', 'Digital Transformation', 'Business Transformation', 'Digitization', 'Process Improvement']",2025-06-12 14:07:21
Data Scientist,Neoware Technology Solutions,3 - 7 years,Not Disclosed,"['Chennai', 'Bengaluru']","Data Scientist - Neoware Technology Solutions Private Limited\nRequirements\nDevelop predictive and prescriptive models to optimize business outcomes and drive growth.\nDesign and build Generative AI solutions to enhance business capabilities.\nWork with leading cloud platforms such as AWS, Azure, or GCP.\nProcess and analyze unstructured data using NLP and Computer Vision techniques.\nLead data-driven initiatives and collaborating with stakeholders to understand business needs and develop strategic solutions.\nConduct exploratory data analysis (EDA) to identify patterns, trends and insights in large, complex datasets.\nMentor and coach junior team members, providing technical guidance and fostering a culture of continuous learning and innovation.\nResponsibilities\nB.E. / Masters in Computer Science, Statistics, Applied Mathematics, Economics or a related quantitative field.\n3-7years of experience in data science, with a proven track record of delivering impactful business solutions.\nStrong proficiency in Python/R and SQL; experience with cloud platforms (AWS, Azure or GCP) is a plus.\nSolid understanding of machine learning techniques (classification, regression, clustering) and statistical methods.\nExcellent communication skills, with the ability to convey complex concepts to diverse audiences.\nStrong problem-solving abilities and capability to work both independently and in a team environment\nChennai / Bangalore / Mumbai\nPrincipal Architect (Data and Cloud) Development",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'Data analysis', 'GCP', 'Machine learning', 'Cloud', 'Business solutions', 'AWS', 'SQL', 'Python']",2025-06-12 14:07:23
CPU Performance & Power Analyst/Sr Lead Engineer - 5 Open positions,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 5 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:25
"Senior Data Engineer ( T-SQL & SSIS,Data Warehousing & ETL Specialist)",Synechron,5 - 10 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Job Summary\nSynechron is seeking a highly skilled Senior Data Engineer specializing in T-SQL and SSIS to lead and advance our data integration and warehousing initiatives. In this role, you will design, develop, and optimize complex ETL processes and database solutions to support enterprise data needs. Your expertise will enable efficient data flow, ensure data integrity, and facilitate actionable insights, contributing to our organizations commitment to data-driven decision-making and operational excellence.\nSoftware Requirements\nRequired Skills:\nProficiency in SQL Server, advanced T-SQL querying, stored procedures, functions, and scripting\nExpertise in SQL Server Integration Services (SSIS), including design, deployment, and troubleshooting\nDeep understanding of data warehousing concepts, schema design, and ETL best practices\nExperience in performance tuning, query optimization, and troubleshooting SQL and SSIS packages\nHands-on experience with database security, compliance, and data masking standards\nFamiliarity with source system analysis and complex data migration\nPreferred Skills:\nExperience with cloud platforms (Azure Data Factory, AWS Glue)\nKnowledge of Azure SQL, Amazon RDS or other cloud-based data services\nExperience with scripting languages like PowerShell or Python for automation\nOverall Responsibilities\nDesign, develop, and maintain robust ETL workflows using SSIS to meet diverse data integration requirements\nWrite optimized, scalable T-SQL queries, stored procedures, and functions aligned with data quality standards\nDevelop and manage data warehouse schemas, tables, and relationships to support reporting and analytics\nEnsure data accuracy, security, and compliance across all data processes\nCollaborate closely with business analysts and other stakeholders to understand data requirements and translate them into technical solutions\nTroubleshoot and resolve performance issues in SQL Server and SSIS packages\nDocument data workflows, schemas, and data mappings to support ongoing maintenance and audits\nParticipate in code reviews, performance tuning, and implementing best practices for ETL and database management\nSupport data migration projects and facilitate seamless data transfers between systems\nTechnical Skills (By Category)\nProgramming Languages:\nEssential: T-SQL, SQL\nPreferred: PowerShell, Python, or similar scripting languages for automation and scripting\nDatabases & Data Management:\nEssential: SQL Server (2016 or higher), relational data modeling, ETL processes\nPreferred: Azure SQL, Amazon RDS, or other cloud-based databases\nFrameworks & Libraries:\nEssential: SSIS (SQL Server Integration Services) packages and components\nPreferred: Data analysis libraries (e.g., Pandas, Power BI integrations)\nDevelopment Tools & Methodologies:\nEssential: SQL Server Management Studio (SSMS), Visual Studio, SQL Server Data Tools (SSDT), version control (Git)\nPreferred: Azure Data Factory, DevOps pipelines, automated deployment tools\nDesign & Architecture:\nData warehouse schema design (star schema, snowflake)\nData flow and process automation best practices\nSecurity & Compliance:\nBasic understanding of database security, access control, and data masking standards\nExperience Requirements\nMinimum of 5+ years working in database development, data warehousing, or ETL processing\nProven experience designing and optimizing large-scale ETL workflows in enterprise environments\nDemonstrated proficiency in writing complex T-SQL queries, stored procedures, and functions\nExperience with SSIS, including package development, deployment, and troubleshooting\nBackground in data migration and data governance is preferred\nIndustry experience in financial services, banking, or large enterprise environments is advantageous\nAlternative pathways include extensive hands-on experience or relevant professional training in ETL and database management\nDay-to-Day Activities\nDevelop, test, and deploy robust ETL workflows using SSIS to meet business needs\nBuild and optimize T-SQL queries, stored procedures, and functions for performance and reliability\nAnalyze source system data structures, identify best-fit schemas, and design data warehouse models\nMonitor and troubleshoot ETL processes, resolving performance bottlenecks and errors\nCollaborate with stakeholders to gather requirements and translate them into technical designs\nReview and optimize database performance and security configurations\nDocument data models, mappings, and processes for operational clarity\nEngage in regular team meetings, code reviews, and process improvement initiatives\nQualifications\nBachelors degree or higher in Computer Science, Information Technology, or related field\nRelevant certifications such as Microsoft Certified: Data Engineer or SQL Server certifications (preferred)\nProven track record of designing and maintaining enterprise data warehouses and ETL processes\nProfessional Competencies\nCritical thinking and analytical skills to troubleshoot complex data issues\nStrong communication skills for effective stakeholder engagement and documentation\nAbility to work independently and collaboratively in a fast-paced environment\nAdaptability to evolving data technologies and requirements\nResults-oriented with excellent time and priority management\nCommitment to continuous improvement and learning new data management techniques.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'T-SQL', 'Azure Data Factory', 'query optimization', 'performance tuning', 'database security', 'AWS Glue', 'Data Warehousing', 'SSIS', 'ETL']",2025-06-12 14:07:28
CPU Performance & Power Analyst/Sr Staff Engineer - 3 Open positions,Qualcomm,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 5+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 12 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'uart', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:30
CPU Performance and Power Analyst/Sr Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 4+ years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:33
CPU Performance and Power Analyst/Sr Staff Engineer,Qualcomm,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 5+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 12 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:35
Market Intelligence Associate Analyst,Salesforce,3 - 4 years,Not Disclosed,['Bengaluru'],"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.\nJob Category\nData\nJob Details\nAbout Salesforce\nCustomer & Market Intel Overview:\nWe re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good - you ve come to the right place.\nDo you enjoy a blend of strategy and research? The Customer & Market Intel team partners directly with the Sales team as a trusted advisor, focused on providing strategic insights around our customers, prospects, industries, CXOs, and Competitors. You will collaborate with many cross-functional teams such as Strategy, Marketing Operations, Programs, Enablement, Sales Dev, and others. This is a high-velocity and high-impact role, with constantly evolving priorities and demands.\nImpact:\nAs a Market Intelligence Associate Analyst at Salesforce, you will play a critical role in gathering, analyzing, and synthesizing information to provide strategic insights and support to our business. Your primary responsibility will be to ensure that our company remains informed about key market trends, what s happening in our client s organizations as well as key competitor activities. You will work closely with various departments, including Strategy, Marketing Operations, Programs, Enablement, Sales Dev, to help shape our strategies and initiatives.\nKey Responsibilities:\nCustomer & Persona Insights:\nResearch about the company- Overview, numbers, trends, key leadership & stakeholders, value chain, recent initiatives, strategic & tech priorities, Current Tech landscape, Digital Audit, etc.\nLeveraging the above research to create detailed PoV on how Salesforce can help that customer succeed\nCreate detailed customer profiles for sales understanding - What s top of mind of a persona and how can we support that persona\nIndustry PoVs & Bashos:\nResearch about the industry - numbers, trends, key players, value chain, recent initiatives, strategic & tech priorities\nLeveraging the above research to create emails/Bashos as well as detailed PoV on how Salesforce can help customers of that industry\nCompetitor Insights:\nEvaluating a competitor s focus areas - products, verticals, geographies, etc.\nComparison of Competitor s strengths vs ours\nCreating Win Wires:\nOne-stop solution for sales reps on won deals\nHighlights customer challenges and use cases sold\nWin-loss analysis: Identify and call out the reason for winning a deal and how can we scale it\nRequirements:\nBachelors degree or equivalent experience in Business, Strategy, Marketing or related field. MBA preferred\nCompetence in market research and competitive analysis\nExcellent communication and presentation skills\nKnowledge of industry trends and market dynamics\nDemonstrated business acumen and understanding of sales and research processes.\nStrong analytical skills and proficiency in data analysis\nRelated experience 3-4 years+ in sales research or saas sales.\nAccommodations\nIf you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .\nPosting Statement",Industry Type: Internet,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Data analysis', 'Sales', 'Competitive analysis', 'Market intelligence', 'Market research', 'Marketing operations', 'Business strategy', 'Research', 'Salesforce', 'Auditing']",2025-06-12 14:07:38
Business Analyst - Configuration Management,Moodys Investors Service,3 - 8 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: Technology Services Group(TSG)\nJob Category:\nEngineering & Technology\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nPosition Overview\nWe are looking for a skilled Configuration Management Data Analyst with expertise in ServiceNow to manage, analyze, and optimize configuration data across our organization. The ideal candidate will play a critical role in maintaining the accuracy and integrity of our Configuration Management within ServiceNow, ensuring alignment with ITIL best practices and supporting business decision-making. This role requires a strong background in ServiceNow, analytical capabilities, and a collaborative approach to working with cross-functional teams.\nKey Responsibilities\n1. Configuration Management Administration and Maintenance\no Maintain and enhance the ServiceNow CMDB to ensure data accuracy, completeness, and compliance with organizational standards.\no Regularly audit configuration data to identify inconsistencies, address gaps, and enforce data governance policies.\no Design and implement automated workflows within ServiceNow to streamline data updates and ensure real-time accuracy.\n2. Data Analysis and Reporting\no Analyze configuration data stored in ServiceNow to identify trends, risks, and opportunities for optimization.\no Create and maintain dashboards, reports, and KPIs within ServiceNow to provide actionable insights to stakeholders.\no Provide data-driven recommendations to improve IT infrastructure and configuration management processes.\n3. Collaboration and Process Improvement\no Work closely with IT, operations, and engineering teams to ensure the proper integration of configuration management processes with business objectives.\no Act as a subject matter expert for CMDB best practices and ServiceNow capabilities, providing training and support to teams as needed.\n4. ServiceNow Development and Optimization\no Collaborate with ServiceNow developers to customize CMDB modules, workflows, and scripts based on organizational needs.\no Stay up-to-date with ServiceNow platform updates, features, and releases to identify opportunities for improved functionality.\no Troubleshoot and resolve technical issues related to ServiceNow CMDB operations.\nExperience and Qualification\n* 3+ years of experience in configuration management, data analysis, or CMDB administration, preferably in financial services.\n* Hands-on experience with ServiceNow, including CMDB module administration and customization.\n* Strong understanding of ITIL principles, particularly Configuration Management.\n* Proficiency in creating dashboards, reports, and workflows within ServiceNow.\n* Bachelor s degree in Information Technology, Computer Science, or a related field.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Configuration management', 'Analytical', 'Process improvement', 'data governance', 'IT operations', 'Information technology', 'Financial services', 'Auditing']",2025-06-12 14:07:40
"Finance Analyst, IN Amazon Now Finance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"Amazon seeks a Finance Analyst to be a key member of its Now (Quick Commerce) Finance team. The person would play a pivotal role in driving the business agenda and would work as a copilot in delivering business results while driving the P&L for the Now business. This includes responsibility for financial metrics, reporting, forecasting, and providing decision support through data analysis & business insights.\n\nThe Finance Analyst position is based in Bangalore.\n\n\nThe successful candidate will be strategic, analytical, and will need to demonstrate ability to effectively manage finances of a high-growth business including:Drive financial reporting and analysis for Now business, including daily/weekly business reviews, variance analysis, and real-time operational metrics tracking\nPartner with business teams to analyze and optimize key metrics like order density, delivery speed, catalog availability, and dark store economics\nDevelop and maintain P&L forecasting models, incorporating key business levers across dark stores and delivery network\nProvide controllership support and build scalable processes that enhance transparency and strengthen controls across high-velocity operations\nSupport business reviews with leadership team, focusing on unit economics and network efficiency\nPartner with operations teams to analyze and optimize dark store costs, delivery economics, and inventory holding costs\nWork closely with category teams to analyze and improve product margins and inventory turns\nDrive monthly, quarterly, and annual financial close process in partnership with accounting teams\nPerform ad-hoc analysis and financial modeling to support network expansion and strategic initiatives\nPresent data-driven recommendations to senior management on growth and profitability initiatives ideal candidate should possess good analytical skills, attention to detail, and the ability to work effectively in a dynamic, fast-paced environment while managing multiple stakeholders in real-time operations. 2+ years of finance experience\n2+ years of applying key financial performance indicators (KPIs) to analyses experience\nKnowledge of standard software including Excel, Access, Oracle, Essbase, SQL and VBA skills\nExperience using data to influence business decisions\nExperience in corporate finance including budgeting/planning, forecasting and reporting\nChartered Accountant or MBA (Finance) 2+ years of participating in continuous improvement projects in your team to scale and improve controllership with measurable results experience\nExperience of working in ecommerce/Quick commerce domain",,,,"['Data analysis', 'Financial reporting', 'Corporate finance', 'Budgeting', 'Oracle', 'Continuous improvement', 'Forecasting', 'Variance analysis', 'Operations', 'SQL']",2025-06-12 14:07:43
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"About Amazon Regulatory Intelligence, Safety, and Compliance (RISC).\n\nAmazon RISC s vision is to make Amazon the Earth s most trusted shopping destination for safe and compliant products. Towards this mission, we take a science-first approach to building technology, products and services, that protect customers from unsafe, illegal, controversial, or policy-violating products while offering the optimal selling partner experience.\n\nJob Summary\n\nWe are seeking an exceptional Data Scientist to join a team of experts in the field of AI/ML, and work together to tackle challenging business problems across diverse compliance domains. We leverage and train state-of-the-art multi-modal, large-language-models (LLMs), and vision language models (VLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for generative AI, agentic system, multi-modal classification, intent detection, information retrieval, anomaly and fraud detection.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of images, texts, documents, and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nDesign and evaluate state-of-the-art algorithms and approaches in generative AI, agentic system, multi-modal classification, intent detection, information retrieval, anomaly and fraud detection.\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\nKey author in writing high quality scientific papers in internal and external peer-reviewed conferences.\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nWriting science papers for submission to peer-review venues, and reviewing science papers from other scientists in the team.\nContributing to team retrospectives for continuous improvements\nDriving science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists and engineers building AI/ML solutions to make Amazon the Earth s most trusted shopping destination for safe and compliant products. PhD, or Masters degree with 2+ years of machine learning experience, or bachelor degree with 3+ years of machine learning experience\nExperience programming in Python, Java, C++, or related language\nExperience with neural deep learning methods, LLM, and natural language processing\nExperience with conducting research in a corporate setting Experience with large scale machine learning systems such as profiling and debugging and understanding of system performance and scalability",,,,"['deep learning', 'C++', 'Debugging', 'Machine learning', 'Information retrieval', 'Natural language processing', 'Scientist II', 'Fraud detection', 'Auditing', 'Python']",2025-06-12 14:07:45
AVP - Finance Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Finance Analyst\n\nIn this role, you will:\nParticipate in functions related to financial research and reporting\nForecast analysis of key metrics, as well as other financial consulting related to business performance, operating and strategic reviews",,,,"['financial research', 'Data analysis', 'Project management', 'documentation', 'Gap analysis', 'financial consulting', 'SQL']",2025-06-12 14:07:48
Data Scientist,H3 Technologies,3 - 8 years,Not Disclosed,['Thiruvananthapuram'],"Position: Data Scientist\nLocation: Trivandrum\nJob Description :\nWe are urgently looking for a motivated Data Scientist with a focus on Computer Vision and Machine Learning. The candidate will have a passion for solving complex problems using deep learning, image processing, and AI-driven techniques. He shall work closely with a team of data scientists, engineers, etc and to build, optimize, and deploy machine learning models for real-world applications\nKey Responsibilities :\nDevelop, train, and optimize deep learning models for image classification, object detection, segmentation, and other computer vision tasks.\nImplement and fine-tune machine learning algorithms for structured and unstructured data analysis.\nPreprocess and augment image/video datasets to improve model accuracy and robustness.\nWork with frameworks such as YOLO, TensorFlow, PyTorch, and OpenCV to build scalable models.\nAssist in deploying models to production environments, including cloud and edge computing platforms.\nCollaborate with cross-functional teams to integrate AI solutions into existing workflows and products.\nStay up-to-date with the latest research and trends in AI, computer vision, and machine learning.\nQualifications :\nBachelors or masters degree in computer science, Data Science, AI/ML, or a related field.\nMinimum of 3 year of professional experience in Python programming and AI/ML integrations\nSolid understanding of machine learning concepts, neural networks, and deep learning architectures.\nHands-on experience in training and optimizing computer vision models.\nFamiliarity with data preprocessing techniques, image annotation tools, and model evaluation metrics.\nStrong problem-solving skills and the ability to work in a fast-paced environment.\nJoining: Immediate to less than 30 days\nBudget: 13 - 14 LPA\n"",",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'deep learning', 'Data analysis', 'Image processing', 'data science', 'Neural networks', 'Machine learning', 'Budgeting', 'Python']",2025-06-12 14:07:50
Senior Analyst - Direct Display,Merkle B2b,2 - 8 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-12 14:07:52
Data Scientist For DMAI,Prodapt Solutions,2 - 5 years,Not Disclosed,['Chennai'],"Overview\n\nThe Senior Data Science Engineer will leverage advanced data science techniques to solve complex business problems, guide decision-making processes, and mentor junior team members. This role requires a combination of technical expertise in data analysis, machine learning, and project management skills.\n\nResponsibilities\n\n Data Analysis and Modeling Analyze large-scale telecom datasets to extract actionable insights and build predictive models for network optimization and customer retention.\n Conduct statistical analyses  to validate models and ensure their effectiveness.\n Machine Learning Development Design and implement machine learning algorithms for fraud detection, churn prediction, and network failure analysis.\n Telecom-Specific Analytics Apply domain knowledge to improve customer experience by analyzing usage patterns, optimizing services, and predicting customer lifetime value.\n ETL Processes Develop robust pipelines for extracting, transforming, and loading telecom data from diverse sources.\n Collaboration Work closely with data scientists, software engineers, and telecom experts to deploy solutions that enhance operational efficiency.\n Data Governance :  Ensure data integrity, privacy, security and compliance with industry standards\n\n\nAdvanced degree in Data Science, Statistics, Computer Science, or a related field.\nExtensive experience in data science roles with a strong focus on machine learning and statistical modeling.\nProficiency in programming languages such as Python or R and strong SQL skills.\nFamiliarity with big data technologies (e.g., Hadoop, Spark) is advantageous.\nExpertise in cloud platforms such as AWS or Azure.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'machine learning', 'sql', 'statistical modeling', 'algorithms', 'python', 'big data technologies', 'microsoft azure', 'cloud platforms', 'r', 'data science', 'spark', 'data governance', 'hadoop', 'aws', 'etl', 'machine learning algorithms', 'statistics']",2025-06-12 14:07:54
Project Analyst Senior,Qualcomm,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Area: Operations Group, Operations Group > Project Analyst\n\nGeneral Summary:\n\nJob OverviewQualcomm Customer Engineering team is seeking a highly organized, self-motivated problem solver with exceptional communication skills and expertise as a Salesforce Service Cloud Specialist. The ideal candidate will have\n\nSalesforce administrative experience with\n\na strong knowledge of standard (out-of-the-box) Salesforce administrative functions and features, including but not limited to\n\nreports/dashboards, case assignments, validations, and profiles/permissions sets. This individual will work closely with Operations, Administrators, Customer Engineering, and IT Development teams to\n\nsupport, organize, prioritize, manage and deliver\n\na large variety of support requests and issues by leveraging established processes, solutions, or features and escalating/driving improvements when necessary. This role requires the\n\nability to\n\nextract business needs,\n\nidentify and promote existing solutions/workarounds,\n\nconnect stakeholders, discover answers or data, assess impact,\n\ncollect requirements, write and define user stories, perform user acceptance testing, write/update user trainings,\n\nand promote user adoption of new solutions. Salesforce Admin, Business Analys, and/or Advanced Admin certification is preferred.\n\nResponsibilities include:\nUtilize\n\nbroad knowledge of Salesforce Service Cloud to support internal and external customers as well as the company's programs\n\nthough standard and available custom features.\nCollaborate with Data and Business Analysts, System Administrators, Development teams, and Customer Engineers to\n\ncollect, interpret, analyze, and document use, functional, and technical requirements for new projects and enhancements.\nMust\n\ntriage and share solutions/workarounds/status updates for known system issues, compile and prioritize new issues, and test/QA delivered solutions.\nEnsures\n\neffective\n\nprocessing of internal stakeholder support tickets submitted through JIRA by internal users for support on case team management, customer role/profile changes, attachment visibility, tools licensing, general tech support and use of the system(s), system downtime and case assignment corrections/redirections.\n\n\nBackup of administrative business operations around case support entitlement for contractually licensed customers, case assignment rule and queue, reports and dashboards, and other administratively controlled operational functions.\nEnabling users and supporting business needs through profile changes,\n\nreports type creation, validation analysis, sharing rules evaluation, and\n\nrecord/values configurations.\nExperience with Data Load, Import Wizard, and/or Workbench\n\nfor database management tasks, including defining, preparing, and executing data corrections and alignment tasks.\nCreate and execute user guides and process documentation for end users.\nWork with internal stakeholders (CE team, Finance, Engineering, Sales, etc.) to gather requirements, support, and\n\ndevelop functional work statements as needed.\nExcellent\n\norganizational, prioritization, and time management skills.\nDemonstrate a strong work ethic and ready to execute best practices for supporting the business.\nCustomer support experience maintaining, triaging, and troubleshooting existing programmatic integrations with internal and external systems.\n\nRequired if we take up Case API, otherwise not necessary\nStrong communication abilities and soft skills like organization are essential- Must be capable of addressing a diverse range of audiences.\n\n\nMinimum Qualifications:\n2+ years relevant work experience on Salesforce Lightning administration\nBachelor in one of the following or equivalent experience Business Administration, Business Operations, Data Analysis, Communication or Information Systems, or related field\nExpert level knowledge in MS Excel (current versions) and MS PowerPoint\n\n\nPreferred Qualifications:\nMaster's in Business Administration, Business Operations, Computer Science, Information Systems, or related field\nSalesforce\n\nCertified Administrator, Advanced Administrator, or Business Analyst\nExperience using, interacting and supporting established API or programmatic integrations\n\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Management, Computer Science, Engineering, Computer Science, or related field.\nOR\nHigh School Diploma or equivalent and 2+ years of relevant work experience.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['salesforce lightning', 'prioritization', 'salesforce', 'data loader', 'salesforce service cloud', 'visualforce', 'data analysis', 'import wizard', 'sfdc', 'business analysis', 'triggers', 'javascript', 'apex', 'sales force development', 'salesforce crm', 'project analysis']",2025-06-12 14:07:56
Treasury Analyst,Wells Fargo,2 - 4 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Treasury Analyst\n\nIn this role, you will:\nPlan and set policies and guidelines for managing global treasury activities including funding, liquidity risk management, asset and liability management, capital management, financial performance management, and related activities",,,,"['Treasury', 'capital management', 'liability management', 'Power BI', 'liquidity risk management', 'Alteryx', 'Data Analysis', 'Forecasting', 'Python']",2025-06-12 14:07:58
Analyst - Tax & Transfer Pricing,HARMAN,3 - 8 years,Not Disclosed,['Bengaluru'],"Introduction: Corporate\nWe re a global, multi-disciplinary team that s putting the innovative power of technology to work and transforming tomorrow. At HARMAN Corporate, you are integral to our company s award-winning success.\nEnrich your managerial and organizational talents - from finance, quality, and supply chain to human resources, IT, sales, and strategy",,,,"['Supply chain', 'Data analysis', 'Change management', 'SAP', 'Analytical', 'Transfer pricing', 'International taxation', 'Wellness', 'Corporate taxation', 'Automotive']",2025-06-12 14:08:01
Senior Analyst - Direct Display,Merkle Science,1 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-12 14:08:04
Business Analyst Capital Markets / Fund Accounting,Pro Integrate,10 - 12 years,Not Disclosed,['Bengaluru'],"Job Title: Business Analyst Capital Markets / Fund Accounting\n\nLocation: Bangalore (Hybrid Model)\n\nShift Timing: UK Shift Hours\n\nExperience: 10 12 Years\n\nNotice Period: Immediate to 15 Days Only\n\nIndustry: BFSI / Investment Banking / Capital Markets\n\nEducation: MBA (Finance) Premier Institutes Only\n\nJob Description\n\nWe are looking for a Business Analyst with a strong foundation in software development and deep domain expertise in Capital Markets, Fund Accounting, and Investment Banking. The ideal candidate will be a former developer who has transitioned into a Business Analyst role and brings a unique combination of technical and functional expertise.\n\nKey Responsibilities\n\nAct as a bridge between business and technology teams\nTranslate business requirements into functional specifications\nAnalyze data using SQL and prepare insights for financial reporting\nCollaborate with global stakeholders in Agile delivery environments\nEnsure high-quality documentation and deliverables\nManage multiple priorities with a strong focus on accuracy and detail\nMust-Have Skills\n\nCareer Path: Started as a software developer (Java, .NET, SQL, PL/SQL) and transitioned to Business Analyst\nDomain Expertise:\nCapital Markets (Mandatory)\nFund Accounting & Reporting (Mandatory)\nOTC Derivatives / Investment Banking (Preferred)\nPrivate Equity / Private Credit (Nice to have)\nTechnical Skills:\nSQL for data analysis\nAgile ALM tools: JIRA, Rally, Azure Boards\nExperience working in Agile, distributed teams\nSoft Skills:\nExcellent communication (verbal & written)\nStrong stakeholder management and client interaction\nDetail-oriented with a focus on financial reporting accuracy\nOther Details\n\nJob Type: Full-Time / Permanent\nWork Model: Hybrid (Bangalore-based)\nShift: UK Hours\nNotice Period: Immediate to 15 days only\nApply Now if you meet the above criteria and are ready to make an immediate impact!",Industry Type: Analytics / KPO / Research,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Capital Markets', 'Business Analysis', 'Java', 'Financial Reporting', 'Investment Banking', 'Business Analyst', 'Fund Accounting', 'JIRA', 'SDLC', 'SQL', 'Private Equity', 'Client Communication', 'Azure Boards', 'Otc Derivatives', 'Agile', 'Data Analysis', 'PLSQL', '.Net', 'Private Credit', 'Rally', 'STLC', 'Stakeholder Management']",2025-06-12 14:08:06
"Systems Analyst, Senior",Qualcomm,3 - 8 years,Not Disclosed,['Hyderabad'],"Job Area: Information Technology Group, Information Technology Group > Systems Analysis\n\nGeneral Summary:\n\nWe are seeking a Systems Analyst,Senior to join our growing organization with specialized skills in IBM Planning Analytics/TM1 and functional understanding of Finance budgeting and forecasting. This role involves advanced development, troubleshooting, and implementation of TM1 solutions to meet complex business requirements.The person will be part of Finance Planning and reporting team and will primarily work closely with his/her manager and will be helping in delivering TM1 planning and budgeting roadmap for the global stakeholders.Key Responsibilities:\nAble to design and develop IBM Planning Analytics(TM1) solutions as per standards. Able to write logical, complex, concise, efficient, and well-documented code for both TM1 rules and Turbo Integrator processes. Good to have knowledge of Python and TM1py libraries.\nAble to write business requirement specifications, define level of efforts for Projects/Enhancements and should design and coordinate system tests to ensure solutions meet business requirements\nSQL skills to be able to work with source data and understand source data structures. Good understanding of the SQL and ability to write complex queries.\nUnderstanding cloud technologies especially AWS and Databricks will be an added advantage.\nExperience in client reporting and dashboard tools like Tableau, PA Web,PAFE.\nUnderstanding of ETL processes and data manipulation\nWorking independently with little supervision\nTaking responsibility for own work and making decisions that are moderate in impact; errors may have financial impact or effect on projects, operations, or customer relationships; errors may require involvement beyond immediate work group to correct.\nShould provide ongoing system support, including troubleshooting and resolving issues to ensure optimal system performance and reliability\nUsing verbal and written communication skills to convey information that may be complex to others who may have limited knowledge of the subject in question\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or incomplete; intermediate data analysis/interpretation skills may be required.\nExercising substantial creativity to innovate new processes, procedures, or work products within guidelines or to achieve established objectives.\n\nMinimum Qualifications:\n3+ years of IT-relevant work experience with a Bachelor's degree.\nOR\n5+ years of IT-relevant work experience without a Bachelors degree.\nQualifications:The ideal candidate will have 8-10 years of experience in designing, modeling, and developing enterprise performance management (EPM) applications using IBM Planning Analytics (TM1).Able to design and develop IBM Planning Analytics(TM1) solutions as per standards. Able to write logical, complex, concise, efficient, and well-documented code for both TM1 rules and Turbo Integrator processes.Lead the design, modeling, and development of TM1 applications, including TI scripting, MDX, rules, feeders, and performance tuning.Should able to provide technical expertise in identifying, evaluating, and developing systems and procedures that are efficient, cost effective and meet user requirements.Plans and executes unit, integration and acceptance testingMust be a good team player who can work seamlessly with Global teams and Data teamsExcellent communication and collaboration skills to work with business stakeholdersHaving functional understanding of Finance budgeting and forecasting\n\nUnderstanding cloud technologies especially AWS and Databricks will be an added advantageExperience in Agile methodologies and JIRA user storiesAble to design and develop solutions using python as per standards\n\nwe are seeking a Systems Analyst,Senior to join our growing organization with specialized skills in IBM Planning Analytics/TM1 and functional understanding of Finance budgeting and forecasting.The person will be part of Finance Planning and reporting te\n\nRequired bachelors or masters degree in information science, computer science, business, or equivalent work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'sql', 'tableau', 'enterprise performance management', 'etl', 'rest', 'data analysis', 'performance tuning', 'cloud technologies', 'data bricks', 'system analysis', 'planning analytics', 'computer science', 'tm', 'troubleshooting', 'data structures', 'agile', 'aws', 'jira', 'agile methodology']",2025-06-12 14:08:10
"Sr. Functional App Analyst, FOAA",Amazon,10 - 15 years,Not Disclosed,['Pune'],"Amazons Finance Operations, Accounting & Analysis (FOAA) team is a fast-paced, team-focused, dynamic environment and delivering great experiences for our customers is top priority. FOAA is seeking a Functional App Analyst to support our Accounting Onboarding team.\n\nThe Functional App Analyst will partner with the Accounting Onboarding team (based in the US) to support various Amazon businesses to launch their products and services by automating their accounting use cases. This is an exciting opportunity to join fast-paced businesses at Amazon. The successful candidate will be strategic, analytical, and have a demonstrated ability to support financial systems and architecture. The successful candidate will be comfortable working in cross-functional teams, and demonstrate strong leadership skills.\n\nThe Functional App Analyst manager will independently manage a team of Functional Analysts, establish structures that enable their team to deliver on projects. Partner with customers, team members, and other teams on what projects move forward and in what priority order. A successful candidate will track team level activities in terms of customer engagement, adherence to SLAs, and execution of projects and programs, customer roadmaps and successfully deliver projects that executes that vision of the org.\n\nThe ideal candidate must have superior attention to detail and the ability to manage multiple competing priorities. The position represents an exciting opportunity to be a part of an extremely dynamic and high -paced environment, support a global organization and work with accounting and business teams. The role offers significant opportunities for rapid growth and is a great place to learn about various businesses at Amazon.\n\n\n-Build relationships with stakeholders, earn trust through transparency and alignment.\n-Dive deep into our customers business to understand pain points and future needs.\n-Lead an existing team of Functional App Analyst and System Analysts.\n-Partner with stakeholders to define strategy and roadmaps for the strategic areas your team owns.\n-Represent verbally and in writing complex decisions, tough trade-offs, and potential solutions clearly to leaders up to 2 levels above.\n-Understand system capabilities in order to deliver IT solutions to business users across Amazon.\n-Advise the customers on the financial integration architecture.\n-Acquire deep understanding of one or more lines of businesses and system integration and data flows.\n-Must have a strong knowledge of an application s functionality. They know what functionality is available in their system and how to configure it to work for business processes\n-Help customers author and release accounting configurations using home grown business configuration management solutions.\n-Troubleshoot integration issues by partnering with internal technical teams across the orgs.\n-Work very closely with the technical teams across Amazons lines of businesses to come up with innovative solutions that will accelerate the adoption of technology used for Financial Reporting and reconciliation.\n-Work independently to manage projects and support Amazons global businesses and development teams in the design and implementation of accounting systems.\n-Provide project management update within and across business units to transition new processes and/or permanent solutions to support the Amazon accounting team.\n-Coordinate with the global accounting teams to establish and maintain strong communication channels.\n-Identify, implement, and adhere to best practices across all new project launches -Offering and receiving coaching, support, and guidance to the team.\n-Supporting in User Acceptance Testing (UATs) in close co-ordination with business and accounting teams.\n-Provide inputs for monthly and quarterly business reviews in a timely manner.\n-Facilitate the business reviews with data analysis and follow through with business leaders on actionable items for improving business metrics over a period of time.\n-Measuring and monitoring of metrics for new business initiatives.\n-Present recommendations to senior management on strategic decisions, and planned future initiatives.\n-Demonstrate appropriate understanding / working knowledge of accounting principles and internal controls, and apply them.\n-Ensure appropriate financial policies, procedures, and internal controls are in place, documented, and operating as intended.\n-Drive process improvements required to enhance controls.\n-Actively participate in strategic initiatives and special projects when assigned or required.\n\nA day in the life\nPrioritization, Resource Planning and Stakeholder Management.\n\nGathering requirements from various Amazon businesses integrating with financial automation tools.\n\nCollaborate with engineering teams to come up with optimal solutions for accounting automation.\n\nWork on code review and config review process by following the guidelines.\n\nParticipate in UAT and guide internal customers with troubleshooting.\n\nWork on deployments to production after acquiring UAT sign-off from stakeholders.\n\nAbout the team\nAmazons Finance Operations, Accounting & Analysis (FOAA) team is a fast-paced, team-focused, dynamic environment and delivering great experiences for our customers is top priority. FOAA is seeking a Finance Analyst to support our Accounting Onboarding team. 10+ years of relevant experience in identifying, leading, and executing opportunities to improve, automate, standardize or simplify finance or business tools and processes experience\n5+ years of experience of working in Financial Services implementing solutions.\nHands on experience in ERP implementation along with understanding of modules like GL, AP, AR, CM, FA, Expenses, PPM etc.\nAct as liaison between customers and engineering teams.\nAbility to understand complex business flows and break them into use cases\nExperience using data to influence business decisions\nExcellent verbal and written communication. Good interpersonal skills\nStrong Project Management skills\n-Experience working with large-scale data reporting tools (examples: SQL, MS Access, Essbase, Cognos) and other financial systems (examples: Oracle, PeopleSoft, SAP, Lawson, JD Edwards)\nExperience in a technical consulting or techno-functional consulting role in a customer centric, fast-moving environment.\nProven ability to develop new ideas and creative solutions\nProven ability to work successfully in an ambiguous environment\nProven ability to meet tight deadlines and prioritize workload\nAbility to work in cross-functional teams\nCustomer focus and professional demeanor",,,,"['Data analysis', 'SAP', 'MS Access', 'Cognos', 'Configuration management', 'Consulting', 'PeopleSoft', 'JD Edwards', 'Oracle', 'SQL']",2025-06-12 14:08:12
Data Scientist,Swits Digital,5 - 12 years,Not Disclosed,['Chennai'],"Job Title: Data Scientist\nLocation: Chennai\nExperience: 5-12 Years\nJob Summary:\nWe are seeking a highly analytical and results-driven Data Scientist with a strong background in statistics , machine learning , and data science , combined with domain knowledge in mechanical engineering and cost analysis . The ideal candidate will have experience working with Google Cloud Platform (GCP) and will play a key role in transforming engineering and operational data into actionable insights to drive business decisions.\nRequired Skills & Experience:\nStrong knowledge of statistics , machine learning , and data science principles\nHands-on experience with Google Cloud Platform (GCP) , especially BigQuery , Vertex AI , and Cloud Functions\nProficiency in Python or R for data analysis and modeling\nSolid understanding of mechanical engineering concepts and their application in data analysis\nExperience with cost modeling , cost-benefit analysis , or operational performance analytics\nExcellent problem-solving , analytical thinking , and communication skills\nAbility to work with large datasets and create clear, actionable insights",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'data science', 'GCP', 'Analytical', 'Machine learning', 'Cost benefit analysis', 'Operations', 'Mechanical engineering', 'Analytics', 'Python']",2025-06-12 14:08:15
Senior Data Engineer - Azure,Blend360 India,3 - 6 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n3+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:08:17
Strategic Buying Services Analyst II,Conduent,3 - 6 years,Not Disclosed,['Bengaluru'],"Job Track Description \nRequires formal education and relevant expertise in a professional, sales, or technical area.\nPerforms technical-based activities.\nContributes to and manages projects.\nUses deductive reasoning to solve problems and make recommendations.\nInterfaces with and influences key stakeholders.\nLeverages previous knowledge and expertise to achieve results.\nAbility to complete work self-guided.\nCollege or university degree required.\n\n General Profile  \nRequires knowledge and experience in the field.\nWill acquire higher-level knowledge and skills.\nDevelops an understanding of the company, processes, and customers.\nUses existing procedures to solve routine or standard problems.\nReceives moderate guidance and direction from others.\n\n Functional Knowledge  \nRequires expanded conceptual understanding of theories, practices, and procedures.\n\n Business Expertise  \nUses an understanding of key business drivers to accomplish work.\n\n Impact  \nImpacts a team, by example, through the quality service and information provided.\nWorks within guidelines and policies.\n\n Leadership  \nNo supervisory responsibilities.\nProvides informal guidance to new team members.\n\n Problem Solving  \nUses existing procedures to solve standard problems.\nExamines information and standard practices to make judgments.\n\n Interpersonal Skills  \nClearly and effectively exchanges complex information and ideas.\n\n Responsibility Statements  \nTracks and reports out business-critical project metrics for the client operations.\nResponsible for managing quality cost savings and vendor relations.\nConducts RFQ and limited reverse auctions to verify supplier, pricing, and availability.\nManages supplier performance, identified risks, and developed strategic buying plans.\nPrepares customized reports and dashboards.\nKeeps data updated and readily available to be leveraged for presentations and reporting.\nPerforms other duties as assigned.\nComplies with all policies and standards.",Industry Type: BPM / BPO,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['pivot table', 'vlookup', 'sales', 'sql', 'advanced excel', 'data analysis', 'mis reporting', 'data dictionary', 'business analysis', 'dashboards', 'budgeting', 'plsql', 'salesforce', 'marketing', 'tableau', 'mis', 'smartforms', 'sap abap']",2025-06-12 14:08:19
CPU Performance & Power Analyst/Staff Engineer - 4 Open positions,Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 8 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'uart', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:08:22
CPU Performance and Power Analyst/Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 5 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:08:25
Senior BI Analyst - Tableau Expert,BMC Software,7 - 12 years,Not Disclosed,['Pune'],"BU Description:\nOur Analytics and Automation team is at the forefront of leveraging data-driven insights to enhance business performance across sales, marketing, product development, and VSE. We specialize in harnessing advanced analytics and automation techniques to provide actionable intelligence, drive efficiency, and foster innovation. Our commitment to excellence ensures that we deliver impactful solutions that propel our organization's strategic goals forward.\n\nAbout You:\n\nYou like to develop, design, and deliver data visualization solutions that deliver sustained business value from our and associated solutions\nYou enjoy working cross-functionally across Sales, Marketing, Operations, and IT organizations for supporting the customer success organization\nYou re a team player and believe in building synergies across BMC to create/continually evolve one integrated customer journey.\nYou like to innovate, and have a passion for solving business problems, to continuously improve our quality of service\nYou have a passion for development, and challenge yourself to learn new things\nYou know how to have fun and connect with people.\n\nKey Responsibility/Role Expectations:\n\nThe Senior BI Analyst supports senior leadership by providing data-driven insights and analytics, enabling informed decision-making, and driving strategic initiatives to enhance customer success and align with business objectives. You should be responsible to\n\nDesign, develop, and maintain advanced and interactive Tableau dashboards to provide actionable insights into customer success metrics.\nAnalyze customer behavior, trends, and performance metrics to identify actionable opportunities for improvement.\nMonitor key customer success indicators (e.g., retention, churn, satisfaction) and provide insights to drive enhanced customer engagement and satisfaction.\nCreate visually compelling and interactive reports tailored for senior leadership to support data-driven strategic decision-making.\nCollaborate with cross-functional teams, including Customer Success, Product, and Support, to gather requirements and deliver tailored BI solutions.\nIntegrate data from multiple sources (e.g., CRM systems like Salesforce, support tools, and internal databases) to create a unified view of performance.\nProvide data-driven recommendations to senior leadership to align customer success efforts with organizational objectives.\nIdentify and report on key trends and anomalies in customer success data, proactively addressing potential challenges.\nDevelop and implement automated workflows for reporting and analytics to enhance efficiency and reduce manual effort.\nStay updated on Tableau and broader BI trends, implementing best practices in data visualization and analysis.\n\nProfessional Experience:\n\nMinimum of 7+ years of experience in Business Intelligence and data analysis.\nExpert proficiency in Tableau, with demonstrated ability to build advanced visualizations.\nStrong understanding of relational databases with expertise in advanced SQL writing.\nProven ability to extract and analyze data from sources such as Snowflake, Excel, CSV, and text files.\nProficient knowledge of Salesforce.com, with experience in CRM data analysis and integration.\nAdvanced skills in Excel, PowerPoint, and Word for creating reports and presentations.\nStrong analytical skills to critically evaluate data, reconcile discrepancies, and ensure accuracy.\nAbility to translate user requirements into technical solutions and design effective BI implementations.\nExcellent organizational skills, with the ability to manage multiple complex projects in a fast-paced, dynamic environment.\nSelf-motivated, detail-oriented, and able to deliver quality outcomes under tight deadlines.\nStrong communication and presentation skills to effectively collaborate with stakeholders, including senior leaders such as Sr. Directors and VPs.\nDemonstrated ability to influence and build long-term relationships with cross-functional teams and business partners.\nExperience mentoring and training team members on technical skills and BI best practices.\nQuick learner, adaptable to changing tools, environments, and priorities.\nCustomer-oriented mindset, with a proven ability to partner with stakeholders to achieve shared business goals.\nFamiliarity with programming languages like Python or R, cloud-based platforms like AWS are a plus.\nBasic understanding of machine learning concepts and predictive analytics is a bonus.\n\nEducation\n\nBachelor s or master s degree in computer science, Information Systems, or a related field (Advanced degree preferred).",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Tableau', 'salesforce', 'python', 'data analysis', 'predictive analytics', 'presentation skills', 'relational databases', 'machine learning', 'business intelligence', 'sql']",2025-06-12 14:08:27
Sales Operations & Data Analytics- Sr. Associate,GEP,2 - 6 years,Not Disclosed,['Navi Mumbai'],"Overview\nGEP is a diverse, creative team of people passionate about procurement. We invest ourselves entirely in our client’s success, creating strong collaborative relationships that deliver extraordinary value year after year. Our clients include market global leaders with far-flung international operations, Fortune 500 and Global 2000 enterprises, leading government and public institutions. \n We deliver practical, effective services and software that enable procurement leaders to maximise their impact on business operations, strategy and financial performance. That’s just some of the things that we do in our quest to build a beautiful company, enjoy the journey and make a difference. GEP is a place where individuality is prized, and talent respected. We’re focused on what is real and effective. GEP is where good ideas and great people are recognized, results matter, and ability and hard work drive achievements. We’re a learning organization, actively looking for people to help shape, grow and continually improve us.",,,,"['crm systems', 'project management', 'data analytics', 'oracle', 'data analysis', 'bi', 'power bi', 'business analysis', 'dashboards', 'sql', 'plsql', 'power query', 'sales operations', 'salesforce', 'analytics', 'excel', 'advanced excel', 'collaboration', 'data governance', 'hubspot', 'powerpoint', 'communication skills', 'crm']",2025-06-12 14:08:29
"Associate Director, Data Science/Software Engineering",ATT Communication Services,10 - 15 years,Not Disclosed,['Bengaluru'],"Associate Director, Data Science/Software Engineering:\nAT&T is one of the leading service providers in the telecommunication sector and propelling it into the data and AI driven era is powered by CDO (Chief Data Office) . CDO is empowering AT&T, through execution, self-service, and as a data and AI center of excellence, to unlock transformative insights and actions that drive value for the company and its customers.\nEmployees in CDO imagine, innovate, and unlock data & AI driven insights and actions that create value for our customers and the enterprise. Part of the work, we govern data collection and use, mitigate for potential bias in machine learning models, and encourage an enterprise culture of responsible AI.\nAT&T s Chief Data Office (CDO) is harnessing data and making AT&T s data assets and ground-breaking AI functionality accessible to employees across the firm. In addition, our talented employees are a significant component that contributes to AT&T s place as the U.S. company with the sixth most AI-related patents. CDO also maintains academic and tech partnerships to cultivate the next generation of experts in statistics and machine learning, statistical computing, data visualization, text mining, time series modelling, data stream and database management, data quality and anomaly detection, data privacy, and more.\nWe are looking for an accomplished and visionary professional for the role of Associate Director, Data Science/Software Engineering to join our team and lead the development of cutting-edge software solutions. This is a hands-on leadership position that requires the fine balance of supervising and leading people while providing significant technical contributions to the projects you will be responsible for. As a key technical leader, you will leverage your expertise in full-stack development, DevOps best practices, Data analysis, AI/ML and Generative AI to lead your team in creating scalable, reliable, and efficient systems.\nThis role demands a strategic thinker and hands-on contributor who can work across multiple teams, drive innovation, and ensure technical excellence. You will be instrumental in shaping the technical roadmap, mentoring teams, and delivering transformative solutions that align with business objectives.\nKey Responsibilities:\nTechnical Leadership:\nDefine and drive the technical vision and architecture for scalable, resilient, and secure full-stack applications utilizing data powered insights.\nLead end-to-end software development projects from concept to deployment and maintenance.\nCollaborate with cross-functional teams to translate business requirements into technical solutions.\nServe as a mentor and technical advisor to engineering teams, fostering a culture of innovation and excellence.\nFull-Stack Development:\nDesign and implement scalable and high-performance web applications using modern front-end and back-end frameworks (e.g., React, Angular, Node.js, Python, Java).\nDevelop modular and reusable APIs (RESTful or GraphQL) with an emphasis on maintainability and performance.\nEnsure seamless integration of front-end and back-end systems while maintaining best practices for UI/UX design.\nOptimize database structures and queries for both relational (e.g., MySQL, PostgreSQL) and non-relational (e.g., MongoDB, DynamoDB) databases.\nDevOps and Automation:\nArchitect and implement CI/CD pipelines to streamline build, test, and deployment processes.\nEnsure seamless deployment and scalability of applications through containerization tools (e.g., Docker) and orchestration platforms (e.g., Kubernetes).\nLeverage infrastructure-as-code solutions (e.g., Terraform, Ansible) to automate infrastructure provisioning and management.\nMonitor application performance, troubleshoot issues, and ensure high availability through tools like Prometheus, Grafana, or New Relic.\nShell Scripting and Automation:\nDevelop and maintain shell scripts to automate routine tasks, system monitoring, and application deployments.\nDebug and troubleshoot production issues using scripting techniques to ensure minimal downtime.\nEnhance system efficiency by automating log analysis, error detection, and reporting.\nStrategic Contribution:\nCollaborate with stakeholders to align technical priorities with business goals.\nEvaluate emerging technologies and tools to recommend and implement solutions that advance the organization s technical capabilities.\nEstablish and enforce software engineering best practices, ensuring robust security, scalability, and maintainability.\nQualifications:\nEducation:\nBachelor s or Master s degree in Computer Science, Software Engineering, or a related field. A Ph.D. is a plus.\nExperience:\n13+ years of experience in software engineering, including hands-on experience with full-stack development and DevOps practices.\nProven track record of delivering large-scale, high-impact software solutions in a leadership capacity.\nTechnical Expertise:\nAdvanced proficiency in front-end frameworks (React, Angular, or Vue.js) and back-end technologies (Node.js, Python, Java, Go, etc.).\nStrong experience with DevOps tools (Jenkins, GitLab CI/CD, Docker, Kubernetes).\nDeep understanding of cloud platforms (AWS, Azure, GCP), including architecture and deployment strategies.\nSolid grasp of database technologies (SQL and NoSQL) and optimization techniques.\nProficiency in writing, debugging, and maintaining shell scripts for automation and system monitoring.\nStrong knowledge of microservices architecture, API gateways, and distributed systems.\nSoft Skills:\nExceptional problem-solving and critical-thinking abilities.\nStrong leadership and mentoring skills, with the ability to inspire and guide teams.\nExcellent communication skills, both written and verbal, to collaborate effectively with technical and non-technical stakeholders.\nStrategic mindset, capable of balancing technical depth with business impact.\nPreferred Qualifications:\nExperience with serverless computing frameworks (e.g., AWS Lambda).\nCertifications in cloud platforms (e.g., AWS Certified Solutions Architect, Azure DevOps Engineer Expert).\nKnowledge of security best practices in software development and DevOps.\n#DataEngineering\nLocation:\nIND:KA:Bengaluru / Innovator Building, Itpb, Whitefield Rd - Adm: Intl Tech Park, Innovator Bldg\nJob ID R-66889 Date posted 05/14/2025",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Data analysis', 'Front end', 'Postgresql', 'MySQL', 'Shell scripting', 'Telecommunication', 'SQL', 'Python']",2025-06-12 14:08:31
Data Bricks,PwC India,7 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary:\n\nWe are seeking a talented Data Engineer with strong expertise in Databricks, specifically in Unity Catalog, PySpark, and SQL, to join our data team. Youll play a key role in building secure, scalable data pipelines and implementing robust data governance strategies using Unity Catalog.\n\nKey Responsibilities:",,,,"['DataBricks', 'Data Bricks', 'Pyspark', 'Delta Lake', 'Databricks Engineer', 'Unity Catalog', 'SQL']",2025-06-12 14:08:34
Consultant- Real-World Data (RWD),IQVIA,2 - 7 years,Not Disclosed,"['Pune', 'Gurugram', 'Bengaluru']","Project Role: Consultant- Real-World Data (RWD)\nWork Experience: 2 to 8 Years\nWork location: Bengaluru/Pune/Gurugram\nWork Mode: Hybrid\nMust Have Skills: Real-World Data (RWD), Healthcare, Data analytics, SQL/Python\nJob Overview:\nWe are seeking a highly motivated Associate Consultant to join our Real-World Data (RWD) team. The selected candidate will support data analysis activities using IQVIA Connected Intelligence RWD and clinical data assets across multiple R&D projects. This role involves close collaboration with Therapeutic Analytic Leads to ensure standardized, data-driven decision-making at the indication, program, and study levels.\n\nKey Responsibilities:\nLeverage IQVIA Connected Intelligence datasets to inform and enhance clinical trial strategies (pre- and post-award).\nCollaborate with internal stakeholders to align on data analytics requirements, capabilities, and deliverables.\nLead the development and implementation of analytics methodologies, including:\nCountry evaluation and ranking\nCompetitive landscape assessments\nHistorical recruitment analysis\nPatient density analytics\nGenerate patient insights using RWD to support site targeting strategies.\nCoordinate the collection and analysis of site outreach data to inform country/site strategy development.\n\nQualifications:\nBachelors degree in Life Sciences, Information Technology, Computer Science, Statistics, or a related field.\n2-7 years of experience in data analytics, clinical research, or consulting within the pharmaceutical or healthcare industry.\nExperience working with large-scale electronic data (e.g., medical claims, EMRs/EHRs, prescriptions, sales data).\nFamiliarity with the pharmaceutical and healthcare market and drug development lifecycle.\nPreferred experience working with global, cross-functional teams.\nProficiency in business intelligence tools (e.g., Power BI, Tableau) is a plus.\nHands-on experience with programming/scripting languages (Python, R, Spark, PySpark) and relational databases (SQL Server, Oracle, PostgreSQL) is advantageous.\n\nSkills & Competencies:\nStrong attention to detail and analytical thinking.\nEffective verbal and written communication skills.\nProficiency in MS Excel and PowerPoint.\nLogical problem-solving and task prioritization abilities.\nAdaptability and eagerness to learn new tools and systems.\nStrong presentation and stakeholder engagement skills.",Industry Type: Analytics / KPO / Research,Department: Consulting,"Employment Type: Full Time, Permanent","['Real World Evidence', 'Healthcare', 'Data Analytics', 'Healthcare Analytics', 'Pharma', 'Feasibility Analysis', 'Clinical']",2025-06-12 14:08:36
Graph Engineer- Data Science,HARMAN,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Description\nIntroduction: Digital Transformation Solutions (DTS)\n.\nExtensive experience in defining, developing, and implementing security software, ideally with a strong embedded firmware development background\nAbout the Role\nThis position offers an opportunity to work in a globally distributed team where you will get a unique opportunity of personal development in a multi-cultural environment. You will also get a challenging environment to develop expertise in the technologies useful in the industry.",,,,"['Computer science', 'Product quality', 'UML', 'XML', 'Relationship', 'Javascript', 'HTML', 'Oracle', 'Automotive', 'Python']",2025-06-12 14:08:38
Data Techology Senior Associate,MSCI Services,4 - 7 years,Not Disclosed,['Pune'],"Overview\nThe Data Technology team at MSCI is responsible for meeting the data requirements across various business areas, including Index, Analytics, and Sustainability. Our team collates data from multiple sources such as vendors (e.g., Bloomberg, Reuters), website acquisitions, and web scraping (e.g., financial news sites, company websites, exchange websites, filings). This data can be in structured or semi-structured formats. We normalize the data, perform quality checks, assign internal identifiers, and release it to downstream applications.\nResponsibilities\nAs data engineers, we build scalable systems to process data in various formats and volumes, ranging from megabytes to terabytes. Our systems perform quality checks, match data across various sources, and release it in multiple formats. We leverage the latest technologies, sources, and tools to process the data. Some of the exciting technologies we work with include Snowflake, Databricks, and Apache Spark.\nQualifications\nCore Java, Spring Boot, Apache Spark, Spring Batch, Python. Exposure to sql databases like Oracle, Mysql, Microsoft Sql is a must. Any experience/knowledge/certification on Cloud technology preferrably Microsoft Azure or Google cloud platform is good to have. Exposures to non sql databases like Neo4j or Document database is again good to have.\n What we offer you\nTransparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\nFlexible working arrangements, advanced technology, and collaborative workspaces.\nA culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\nA global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\nGlobal Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\nMulti-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\nWe actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women’s Leadership Forum.\nAt MSCI we are passionate about what we do, and we are inspired by our purpose – to power better investment decisions. You’ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n To all recruitment agencies\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n Note on recruitment scams\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['hive', 'access', 'scala', 'pyspark', 'data warehousing', 'hibernate', 'research', 'sql', 'analytics', 'spring', 'java', 'spring batch', 'spark', 'gcp', 'mysql', 'html', 'hadoop', 'big data', 'etl', 'snowflake', 'python', 'oracle', 'data analysis', 'microsoft azure', 'power bi', 'sql server', 'javascript', 'data bricks', 'spring boot', 'tableau', 'neo4j', 'aws', 'sql database']",2025-06-12 14:08:41
Data Engineer KL-BL,Puresoftware,5 - 12 years,Not Disclosed,['Bengaluru'],"Core Competences Required and Desired Attributes:\nBachelors degree in computer science, Information Technology, or a related field.\nProficiency in Azure Data Factory, Azure Databricks and Unity Catalog, Azure SQL Database, and other Azure data services.\nStrong programming skills in SQL, Python and PySpark languages.\nExperience in the Asset Management domain would be preferable.\nStrong proficiency in data analysis and data modelling, with the ability to extract insights from complex data sets.\nHands-on experience in Power BI, including creating custom visuals, DAX expressions, and data modelling.\nFamiliarity with Azure Analysis Services, data modelling techniques, and optimization.\nExperience with data quality and data governance frameworks with an ability to debug, fine tune and optimise large scale data processing jobs.\nStrong analytical and problem-solving skills, with a keen eye for detail.\nExcellent communication and interpersonal skills, with the ability to work collaboratively in a team environment.\nProactive and self-motivated, with the ability to manage multiple tasks and deliver high-quality results within deadlines.",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Interpersonal skills', 'Data modeling', 'Analytical', 'data governance', 'Data quality', 'Asset management', 'Information technology', 'SQL', 'Python']",2025-06-12 14:08:43
Data Engineer II,Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Amazon strives to be the worlds most customer-centric company, where customers can research and purchase anything they might want online\nWe set big goals and are looking for people who can help us reach and exceed them\nThe CPT Data Engineering & Analytics (DEA) team builds and maintains critical data infrastructure that enhances seller experience and protects the privacy of Amazon business partners throughout their lifecycle\nWe are looking for a strong Data Engineer to join our team\n\nThe Data Engineer I will work with well-defined requirements to develop and maintain data pipelines that help internal teams gather required insights for business decisions timely and accurately\nYou will collaborate with a team of Data Scientists, Business Analysts and other Engineers to build solutions that reduce investigation defects and assess the health of our Operations business while ensuring data quality and regulatory compliance\n\nThe ideal candidate must be passionate about building reliable data infrastructure, detail-oriented, and driven to help protect Amazons customers and business partners\nThey will be an individual contributor who works effectively with guidance from senior team members to successfully implement data solutions\nThe candidate must be proficient in SQL and at least one scripting language (e\ng\nPython, Perl, Scala), with strong understanding of data management fundamentals and distributed systems concepts\n\n\nBuild and optimize physical data models and data pipelines for simple datasets\nWrite secure, stable, testable, maintainable code with minimal defects\nTroubleshoot existing datasets and maintain data quality\nParticipate in team design, scoping, and prioritization discussions\nDocument solutions to ensure ease of use and maintainability\nHandle data in accordance with Amazon policies and security requirements Masters degree in computer science, engineering, analytics, mathematics, statistics, IT or equivalent\n3+ years of data engineering experience\nExperience with SQL\nExperience with data modeling, warehousing and building ETL pipelines\nKnowledge of distributed systems concepts from data storage and compute perspective\nAbility to work effectively in a team environment Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions\nFamiliarity with big data technologies (Hadoop, Spark, etc\n)\nKnowledge of data security and privacy best practices\nStrong problem-solving and analytical skills\nExcellent written and verbal communication skills",Industry Type: Internet,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data management', 'Data modeling', 'data security', 'Perl', 'Data quality', 'Distribution system', 'Analytics', 'SQL', 'Python']",2025-06-12 14:08:45
Senior Data Scientist,Epsilon,6 - 9 years,Not Disclosed,['Bengaluru'],"Responsibilities: -\nContribute and build an internal product library that is focused on solving business problems related to prediction & recommendation.\nResearch unfamiliar methodologies, techniques to fine tune existing models in the product suite and, recommend better solutions and/or technologies.\nImprove features of the product to include newer machine learning algorithms in the likes of product recommendation, real time predictions, fraud detection, offer personalization etc\nCollaborate with client teams to on-board data, build models and score predictions.\nParticipate in building automations and standalone applications around machine learning algorithms to enable a One Click solution to getting predictions and recommendations.\nAnalyze large datasets, perform data wrangling operations, apply statistical treatments to filter and fine tune input data, engineer new features and eventually aid the process of building machine learning models.\nRun test cases to tune existing models for performance, check criteria and define thresholds for success by scaling the input data to multifold.\nDemonstrate a basic understanding of different machine learning concepts such as Regression, Classification, Matrix Factorization, K-fold Validations and different algorithms such as Decision Trees, Random Forrest, K-means clustering.\nDemonstrate working knowledge and contribute to building models using deep learning techniques, ensuring robust, scalable and high-performance solutions\nMinimum Qualifications:\nEducation: Master's or PhD in a quantitative discipline (Statistics, Economics, Mathematics, Computer Science) is highly preferred.\nDeep Learning Mastery: Extensive experience with deep learning frameworks (TensorFlow, PyTorch, or Keras) and advanced deep learning projects across various domains, with a focus on multimodal data applications.\nGenerative AI Expertise: Proven experience with generative AI models and techniques, such as RAG, VAEs, Transformers, and applications at scale in content creation or data augmentation.\nProgramming and Big Data: Expert-level proficiency in Python and big data/cloud technologies (Databricks and Spark) with a minimum of 4-5 years of experience.\nRecommender Systems and Real-time Predictions: Expertise in developing sophisticated recommender systems, including the application of real-time prediction frameworks.\nMachine Learning Algorithms: In-depth experience with complex algorithms such as logistic regression, random forest, XGBoost, advanced neural networks, and ensemble methods.\nExperienced with machine learning algorithms such as logistic regression, random forest, XG boost, KNN, SVM, neural network, linear regression, lasso regression and k-means.\nDesirable Qualifications:\nGenerative AI Tools Knowledge: Proficiency with tools and platforms for generative AI (such as OpenAI, Hugging Face Transformers).\nDatabricks and Unity Catalog: Experience leveraging Databricks and Unity Catalog for robust data management, model deployment, and tracking.\nWorking experience in CI/CD tools such as GIT & BitBucket",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Engineering', 'Pyspark', 'Azure Aws', 'Generative AI', 'Big Data', 'AWS', 'Data Bricks', 'Deep Learning', 'Python', 'SQL']",2025-06-12 14:08:47
Sr. Data Scientist-Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist\n\nLocation: Onsite Bangalore\nExperience: 8+ years\n\nRole Overview\n\nWe are seeking a Senior Data Scientist with a strong foundation in machine learning, deep learning, and statistical modeling, with the ability to translate complex operational problems into scalable AI/ML solutions. In addition to core data science responsibilities, the role involves building production-ready backends in Python and contributing to end-to-end model lifecycle management. Exposure to computer vision is a plus, especially for industrial use cases like identification, intrusion detection, and anomaly detection.\n\nKey Responsibilities\n\nDevelop, validate, and deploy machine learning and deep learning models for forecasting, classification, anomaly detection, and operational optimization\nBuild backend APIs using Python (FastAPI, Flask) to serve ML/DL models in production environments\nApply advanced computer vision models (e.g., YOLO, Faster R-CNN) to object detection, intrusion detection, and visual monitoring tasks\nTranslate business problems into analytical frameworks and data science solutions\nWork with data engineering and DevOps teams to operationalize and monitor models at scale\nCollaborate with product, domain experts, and engineering teams to iterate on solution design\nContribute to technical documentation, model explainability, and reproducibility practices\n\n\nRequired Skills\n\nStrong proficiency in Python for data science and backend development\nExperience with ML/DL libraries such as scikit-learn, TensorFlow, or PyTorch\nSolid knowledge of time-series modeling, forecasting techniques, and anomaly detection\nExperience building and deploying APIs for model serving (FastAPI, Flask)\nFamiliarity with real-time data pipelines using Kafka, Spark, or similar tools\nStrong understanding of model validation, feature engineering, and performance tuning\nAbility to work with SQL and NoSQL databases, and large-scale datasets\nGood communication skills and stakeholder engagement experience\n\n\nGood to Have\n\nExperience with ML model deployment tools (MLflow, Docker, Airflow)\nUnderstanding of MLOps and continuous model delivery practices\nBackground in aviation, logistics, manufacturing, or other industrial domains\nFamiliarity with edge deployment and optimization of vision models\n\n\nQualifications\n\nMasters or PhD in Data Science, Computer Science, Applied Mathematics, or related field\n7+ years of experience in machine learning and data science, including end-to-end deployment of models in production",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scikit-learn', 'time-series modeling', 'ML/DL libraries', 'data science', 'Python', 'Airflow', 'Kafka', 'MLflow', 'logistics', 'anomaly detection', 'aviation', 'SQL', 'PyTorch', 'NoSQL', 'MLOps', 'forecasting techniques', 'Docker', 'manufacturing', 'FastAPI', 'Spark', 'TensorFlow', 'Flask']",2025-06-12 14:08:50
Senior Engineer - Data Science,Sasken Technologies,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Summary\nPerson at this position has gained significant work experience to be able to apply their knowledge effectively and deliver results. Person at this position is also able to demonstrate the ability to analyse and interpret complex problems and improve change or adapt existing methods to solve the problem.\nPerson at this position regularly interacts with interfacing groups / customer on technical issue clarification and resolves the issues. Also participates actively in important project/ work related activities and contributes towards identifying important issues and risks. Reaches out for guidance and advice to ensure high quality of deliverables.\nPerson at this position consistently seek opportunities to enhance their existing skills, acquire more complex skills and work towards enhancing their proficiency level in their field of specialisation.\nWorks under limited supervision of Team Lead/ Project Manager.\n\n\nRoles & Responsibilities\nResponsible for design, coding, testing, bug fixing, documentation and technical support in the assigned area. Responsible for on time delivery while adhering to quality and productivity goals. Responsible for adhering to guidelines and checklists for all deliverable reviews, sending status report to team lead and following relevant organizational processes. Responsible for customer collaboration and interactions and support to customer queries. Expected to enhance technical capabilities by attending trainings, self-study and periodic technical assessments. Expected to participate in technical initiatives related to project and organization and deliver training as per plan and quality.\n\n\nEducation and Experience Required\nEngineering graduate, MCA, etc Experience: 2-5 years\n\nCompetencies Description\nData Science TCB is applicable to one who\n1) Analyses data to arrive at patterns/Insights/models\n2) Come up with models based on the data to provide recommendations, predictive analytics etc\n3) Provides implementation of the models in R, Matlab etc\n4) Can understand and apply machine learning/AI techniques\nPlatforms-\nUnix\nTechnology Standard-\nNA\nTools-\nR, Matlab, Spark Machine Learning, Python-ML, SPSS, SAS\nLanguages-\nR, Perl, Python, Scala\nSpecialization-\nCOGNITIVE ANALYTICS INCLUDING COMPUTER VISION, AI and ML, STATISTICS.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'R', 'SAS', 'Scala', 'Perl', 'SPSS', 'Spark', 'machine learning', 'Python']",2025-06-12 14:08:52
Senior Data Scientist,Toast,6 - 11 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist - S&A\nNow, more than ever, the Toast team is committed to our customers. We re taking steps to help restaurants navigate these unprecedented times with technology, resources, and community. We focus on building the restaurant platform that helps restaurants adapt, take control, and get back to what they do best: building the businesses they love. And because our technology is purpose-built for restaurants, by restaurant people, restaurants can trust that we ll deliver on their needs for today while investing in experiences that will power their restaurant of the future.\nBready*\nto make a change?\n\nAs the Senior Data Scientist in our Bangalore Data Science team, you will contribute to building machine learning algorithms using our huge reservoir of point of sale transaction data. You will work with architects, engineers and product managers to solve business and customer problems and turn machine learning models into business impact across product lines, including financial processing and fraud.\nAbout this\nRoll*\n:\nDesign, build, train and evaluate machine learning models to drive business value for Toast and our restaurant customers\nCollaborate closely with internal and external product stakeholders, both technical and non-technical and help translate deep machine learning knowledge to product applications\nBreak down larger ML initiatives into smaller problems that enables data science to deliver incremental business value and lead the team to execute on them\nWork closely with Production Engineering and Data Platform teams to deploy models to production and regularly monitor for efficiency, key KPIs and enhance them as needed\nWork with incident response and problem resolution teams to check and resolve any problems/challenges as and when identified in the model deployed in the production\nEffectively document all steps and manage code repositories for easy scalability and knowledge sharing with the the team\nIncorporate up-to-date ML technology and DS approach as best practice for the team\nHelp in continuing to build out and expand the Data Science and ML Engineering teams\nWork effectively in a dynamic, changing environment while focusing on key goals and objectives\nDo you have the right\ningredients*\n?\nAdvanced degree in Data Science, Statistics, Applied Math, Computer Science, Engineering or other equivalent quantitative disciplines\n6 + years of industry experience in the field of Data Science and Machine Learning\nExperience in time series modelling. Familiarity with ARIMA, SARIMA, ETS, VAR models. Familiarity with forecasting tools like Facebook Prophet, GluonTS, or NeuralProphet.\nStrong proficiency in Python and SQL; experience with some of the following languages, tools, and frameworks: R, Spark, Scala, scikit-learn, Tensorflow, PyTorch, etc.\nFamiliarity with standard software engineering practices and tools including object-oriented programming, test-driven development, CI/CD, git, shell scripting, task orchestration (Airflow, Luigi, etc.) and preferably AWS tooling (Sagemaker, DynamoDB, ECS, etc.)\nStrong knowledge of underlying mathematical foundations of statistics and machine learning\nPrior success deploying machine learning solutions in large-scale production environments\nExperience collaborating with cross-functional teams and stakeholders to evaluate new Machine Learning opportunities\nProblem solver who loves to dig into different kinds of data and can communicate their findings to cross-functional stakeholders\nBonus\ningredients*\n:\nPassion for research and curiosity that calls you to go beyond good enough to create something innovative and exciting\nDiversity, Equity, and Inclusion is Baked into our Recipe for Success\nAt Toast, our employees are our secret ingredient when they thrive, we thrive. The restaurant industry is one of the most diverse, and we embrace that diversity with authenticity, inclusivity, respect, and humility. By embedding these principles into our culture and design, we create equitable opportunities for all and raise the bar in delivering exceptional experiences.\nWe Thrive Together\nWe embrace a hybrid work model that fosters in-person collaboration while valuing individual needs. Our goal is to build a strong culture of connection as we work together to empower the restaurant community. To learn more about how we work globally and regionally, check out: https: / / careers.toasttab.com / locations-toast .\nApply today!\nToast is committed to creating an accessible and inclusive hiring process. As part of this commitment, we strive to provide reasonable accommodations for persons with disabilities to enable them to access the hiring process. If you need an accommodation to access the job application or interview process, please contact .\n------\nFor roles in the United States, It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'orchestration', 'data science', 'Production engineering', 'Machine learning', 'Shell scripting', 'test driven development', 'Forecasting', 'SQL', 'Python']",2025-06-12 14:08:54
Audit Manager Vice President Data Analytics,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Analytics/Audit Manager, VP to lead audits within a dynamic environment. The person we seek will supervise audits and manage work within our CDO audit team, which is responsible for audit coverage of data management and data risk audit coverage strategy for Internal Audit. This is an individual contributor role.\nIn this role, you will:\nLead execution of the integrated audit process\nParticipate in audits in accordance with Wells Fargo Internal Audit policy",,,,"['Data Analytics', 'data management', 'Project management', 'data governance', 'data quality management', 'Risk management']",2025-06-12 14:08:56
Data Engineer III,Expedia Group,5 - 10 years,Not Disclosed,['Bengaluru'],"Why Join Us?\nTo shape the future of travel, people must come first. Guided by our Values and Leadership Agreements, we foster an open culture where everyone belongs, differences are celebrated and know that when one of us wins, we all win.\nWe provide a full benefits package, including exciting travel perks, generous time-off, parental leave, a flexible work model (with some pretty cool offices), and career development resources, all to fuel our employees passion for travel and ensure a rewarding career journey. We re building a more open world. Join us.\nData Engineer III\nIntroduction to the Team\nExpedia Technology teams partner with our Product teams to create innovative products, services, and tools to deliver high-quality experiences for travelers, partners, and our employees. A singular technology platform powered by data and machine learning provides secure, differentiated, and personalized experiences that drive loyalty and traveler satisfaction.\nExpedia Group is seeking a skilled and motivated Data Engineer III to join our Finance Business Intelligence team supporting the Product & Technology Finance organization. In this role, you will help drive data infrastructure and analytics solutions that support strategic financial planning, reporting, and operational decision-making across the Global Finance community. You ll work closely with Finance and Technology partners to ensure data accuracy, accessibility, and usability in support of Expedia s business objectives.\nAs a Data Engineer III, you have strong experience working with a variety of datasets, data environments, tools, and analytical techniques. You enjoy a fun, collaborative and stimulating team environment. Successful candidates should be able to own projects end-to-end, including identifying problems and solutions, building and maintain data pipelines and dashboards, distilling key insights and communicate to stakeholders.\nIn this role, you will:\nDevelop new and improve existing end to end Business Intelligence products (data pipelines, Tableau dashboards, and Machine Learning predictive forecasting models).\nDrive internal efficiencies through streamline code/documentation/Tableau development to maintain high data integrity.\nTroubleshoot and resolve production issues with the team products (automation opportunities, optimizations, back-end data issues, data reconciliations).\nProactively reach out to subject matter experts /stakeholders and collaborate to solve problems.\nRespond to ad hoc data requests and conduct analysis to provide valuable insights to stakeholders.\nCollaborate and coordinate with team members/stakeholders to translate complex data into meaningful insights, that improve the analytical capabilities of the business.\nApply knowledge of database design to support migration of data pipelines from on prem to cloud environment (including data extraction, ingestion, processing of large data sets)\nSupport dashboard development on cloud environment to enable self-service reporting.\nCommunicate clearly on current work status and design considerations\nThink broadly and comprehend the how, why, and what behind data architecture designs\nExperience & Qualifications:\nBachelor s in Computer Science, Mathematics, Statistics, Information Systems, or related field\n5+ years experience in a Data Analyst, Data Engineer or Business Analyst role\nProven expertise in SQL, with practical experience utilizing query engines including SQL Server, Starburst, Trino, Querybook and data science tools such as Python/R, SparkSQL.\nProficient visualization skills (Tableau, Looker, or similar) and excel modeling/report automation.\nExceptional understanding of relational and dimensional datasets, data warehouse and data mining and applies database design principles to solve data requirements\nExperience building robust data extract, load and transform (ELT) processes, that source data from multiple databases.\nDemonstrated record of defining and executing key analysis and solving problems with minimal supervision.\nDynamic individual contributor who consistently enhances operational playbooks to address business problems.\n3+ year working in a hybrid environment that uses both on-premise and cloud technologies is preferred.\nExperience working in an environment that manipulates large datasets on the cloud platform preferred.\nBackground in analytics, finance or a comparable reporting and analytics role preferred.\nAccommodation requests\nIf you need assistance with any part of the application or recruiting process due to a disability, or other physical or mental health conditions, please reach out to our Recruiting Accommodations Team through the Accommodation Request .\nWe are proud to be named as a Best Place to Work on Glassdoor in 2024 and be recognized for award-winning culture by organizations like Forbes, TIME, Disability:IN, and others.\nExpedia Groups family of brands includes: Brand Expedia , Hotels.com , Expedia Partner Solutions, Vrbo , trivago , Orbitz , Travelocity , Hotwire , Wotif , ebookers , CheapTickets , Expedia Group Media Solutions, Expedia Local Expert , CarRentals.com , and Expedia Cruises . 2024 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. . Never provide sensitive, personal information to someone unless you re confident who the recipient is. Expedia Group does not extend job offers via email or any other messaging tools to individuals with whom we have not made prior contact. Our email domain is @expediagroup.com. The official website to find and apply for job openings at Expedia Group is careers.expediagroup.com/jobs .\nExpedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Database design', 'Machine learning', 'Business intelligence', 'Data mining', 'Analytics', 'SQL', 'Python', 'Data architecture']",2025-06-12 14:08:58
Data Engineer _Technology Lead,Broadridge,6 - 10 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nAnalyzes and solve problems using technical experience, judgment and precedents\nProvides informal guidance to new team members\nExplains complex information to others in straightforward situations\n1. Data Engineering and Modelling:\nDesign & Develop Scalable Data Pipelines: Leverage AWS technologies to design, develop, and manage end-to-end data pipelines with services like .",,,,"['Star Schema', 'Snowflake', 'AWS', 'Apache Airflow']",2025-06-12 14:09:01
Senior Data Scientist - AI/ML,Inumellas Consultancy Services,9 - 14 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Role - Senior Data Scientist / Senior Gen AI Engineer\nExp Range - 8 to 18 yrs\nPosition - Permanent Fulltime\nCompany - Data Analytics & AIML MNC\nLocation - Hyderabad, Pune, Bangalore (Relocation accepted)\nAbout the Role:\n\nWe are seeking a Software Engineer with expertise in Generative AI and Microsoft technologies to design, develop, and deploy AI-powered solutions using the Microsoft ecosystem. You will work with cross-functional teams to build scalable applications leveraging generative AI models and Azure services.\n\nSkills Required:\n\nExperience with Large Language Models (LLMs) like GPT, LLaMA, Claude, etc.\nProficiency in Python for building and fine-tuning AI/ML models\nFamiliarity with LangChain, LLMOps, or RAG (Retrieval-Augmented Generation) pipelines\nExperience with Vector Databases (e.g. FAISS, Pinecone, Weaviate)\nKnowledge of Prompt Engineering and model evaluation techniques\nExposure to cloud platforms (Azure, AWS or GCP) for deploying GenAI solutions\n\nPreferred Skills:\n\nExperience with Azure OpenAI, Databricks or Microsoft Fabric\nHands-on with Hugging Face Transformers, OpenAI APIs or custom model training",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Deep Learning', 'Prompt Engineering', 'Large Language Model', 'Vector Database', 'Retrieval Augmented Generation', 'GenAI', 'Langchain', 'Artificial Intelligence', 'LLMOps', 'LLaMa', 'GPT', 'Azure OpenAI', 'Machine Learning', 'ML Models', 'Model Evaluation', 'Huggingface', 'Aiml', 'OpenAI', 'Azure Machine Learning', 'Python']",2025-06-12 14:09:03
Data Science,Global Banking Organization,5 - 10 years,Not Disclosed,['Bengaluru'],"Key Skills: Machine Learning, Data Science, Azure, Python, Hadoop.\nRoles and Responsibilities:\nStrong understanding of Math, Statistics, and the theoretical foundations of Statistical & Machine Learning, including Parametric and Non-parametric models.\nApply advanced data mining techniques to curate, process, and transform raw data into reliable datasets.\nUse various statistical techniques and ML methods to perform predictive modeling/classification for problems related to clients, distribution, sales, client profiles, and segmentation, and provide actionable insights for business decision-making.\nDemonstrate expertise in the full Machine Learning lifecycle--feature engineering, training, validation, scaling, deployment, scoring, monitoring, and feedback loops.\nProficiency in Python visualization libraries such as matplotlib and seaborn.\nExperience with cloud computing infrastructure like Azure, including Machine Learning Studio, Azure Data Factory, Synapse, Python, and PySpark.\nAbility to develop, test, and deploy models on cloud/web platforms.\nExcellent knowledge of Deep Learning Architectures, including Convolutional Neural Networks and Transformer/LLM Foundation Models.\nStrong expertise in supervised and adversarial learning techniques.\nRobust working knowledge of deep learning frameworks such as TensorFlow, Keras, and PyTorch.\nExcellent Python coding skills.\nExperience with version control tools (Git, GitHub/GitLab) and data version control.\nExperience in end-to-end model deployment and productionization.\nDemonstrated proficiency in deploying, scaling, and optimizing ML models in production environments with low latency, high availability, and cost efficiency.\nSkilled in model interpretability and CI/CD for ML using tools like MLflow and Kubeflow, with the ability to implement automated monitoring, logging, and retraining strategies.\nExperience Requirement:\n5-12 years of experience in designing and deploying deep learning and machine learning solutions.\nProven track record of delivering AI/ML solutions in real-world business applications at scale.\nHands-on experience working in cross-functional teams including data engineers, product managers, and business stakeholders.\nExperience mentoring junior data scientists and providing technical leadership within a data science team.\nExperience working with big data tools and environments such as Hadoop, Spark, or Databricks is a plus.\nPrior experience in managing model lifecycle in enterprise production environments including drift detection and retraining pipelines.\nEducation: B.Tech.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure', 'Hadoop.', 'Machine Learning', 'Python']",2025-06-12 14:09:05
Senior Data Scientist with GCP,TVS Next,5 - 7 years,Not Disclosed,['Bengaluru'],"What you’ll do:\nUtilize advanced mathematical, statistical, and analytical expertise to research, collect, analyze, and interpret large datasets from internal and external sources to provide insight and develop data driven solutions across the company\nBuild and test predictive models including but not limited to credit risk, fraud, response, and offer acceptance propensity\nResponsible for the development, testing, validation, tracking, and performance enhancement of statistical models and other BI reporting tools leading to new innovative origination strategies within marketing, sales, finance, and underwriting",,,,"['analytical', 'scikit-learn', 'searching', 'bi', 'pyspark', 'numpy', 'sql', 'analytics', 'apache', 'automation', 'data science', 'spark', 'gcp', 'bigquery', 'data visualization', 'xgboost', 'programming', 'reporting', 'ml', 'advanced analytics', 'python', 'data processing', 'predictive', 'jupyter notebook', 'bert', 'pandas', 'matplotlib', 'statistics']",2025-06-12 14:09:07
Senior Data Engineer - AWS,Blend360 India,5 - 10 years,Not Disclosed,['Hyderabad'],"Job Description\nWe are looking for an experienced Senior Data Engineer with a strong foundation in Python, SQL, and Spark , and hands-on expertise in AWS, Databricks . In this role, you will build and maintain scalable data pipelines and architecture to support analytics, data science, and business intelligence initiatives. You ll work closely with cross-functional teams to drive data reliability, quality, and performance.\nResponsibilities:\nDesign, develop, and optimize scalable data pipelines using Databricks in AWS such as Glue, S3, Lambda, EMR, Databricks notebooks, workflows and jobs.\nBuilding data lake in WS Databricks.\nBuild and maintain robust ETL/ELT workflows using Python and SQL to handle structured and semi-structured data.\nDevelop distributed data processing solutions using Apache Spark or PySpark .\nPartner with data scientists and analysts to provide high-quality, accessible, and well-structured data.\nEnsure data quality, governance, security, and compliance across pipelines and data stores.\nMonitor, troubleshoot, and improve the performance of data systems and pipelines.\nParticipate in code reviews and help establish engineering best practices.\nMentor junior data engineers and support their technical development.\n\n\nQualifications\nRequirements\nBachelors or masters degree in computer science, Engineering, or a related field.\n5+ years of hands-on experience in data",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Version control', 'GIT', 'Workflow', 'Data quality', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:09:10
BPEX (Business Process Excellence) - Malad,Motilal Oswal Financial Services (MOFSL),0 - 4 years,Not Disclosed,['Mumbai (All Areas)'],"Role & responsibilities\n1. Work full time on improvement projects\n2. Deliver BPEX trainings\n3. Support MBB/BB in projects\n4. Support Organization wide BPEX initiatives\n\nKey Work Relationships:\n\n1.Internal\n\nInvolving project team members including process owners, influencing people and driving process excellence across the organization\n2.External\n\nLimited\n\nPreferred candidate profile\n1.Experience - 0-2 years overall experience\n2.Other Skills - Good analytical and communication skills",Industry Type: Financial Services (Broking),Department: Quality Assurance,"Employment Type: Full Time, Permanent","['Lean Six Sigma', 'Process Excellence', 'Process Automation', 'Project Documentation', 'Six Sigma Certified', 'Process Documentation', 'Green Belt', 'Business Improvement', 'Yellow Belt', 'Data Analysis', 'Process Optimization', 'Business Excellence', 'BPEX']",2025-06-12 14:09:13
Lead Analyst,AMERICAN EXPRESS,5 - 10 years,Not Disclosed,['Gurugram'],"Global Merchant & Network Services (GMNS) brings together American Express merchant-and network-related businesses to enable a sharp focus on using the power of our network to provide unique value to all of our mutual customers. The organization manages the relationships with the millions of merchants around the world that accept American Express and runs the company s payment network and manages bank partnerships globally.\nIn support of GMNS s mission, Global, Strategy, Operations & Processes (GSOP) is focused on delivering a friction free, resilient, and efficient operational core for critical merchant experiences; strengthening monitoring and adherence to network and merchant policies; and leading key operational excellence functions. As part of GSOP, the Merchant Onboarding & Maintenance team prioritizes strengthening governance for merchant account setup, account management, and Know Your Customer (KYC) activities.",,,,"['Career development', 'Operational excellence', 'Data management', 'Account management', 'Information technology', 'Client management', 'Monitoring', 'SQL']",2025-06-12 14:09:15
Business Analyst,Abad Fisheries,3 - 5 years,4-7 Lacs P.A.,['Kochi( Thoppumpady )'],"Collaborate with department heads to define data needs and ensure consistent metric capture. Apply statistical tools to analyze data, identify trends & create clear visualizations using Power BI. Identify bottlenecks and improvement opportunities,\n\nRequired Candidate profile\nWe are looking for candidates from FMCG background with advanced Exel Knowledge and other data analysis tools like power BI, tableau etc..\n\nPerks and benefits\nBest in the industry",Industry Type: Food Processing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'VLOOKUP', 'Data Analysis', 'Advanced Excel', 'MIS Reporting', 'Data Visualizations', 'Excel', 'Dashboards']",2025-06-12 14:09:17
Business Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role we are seeking a Business Systems Analyst with a good background in data and analytics to define and manage product requirements for AI-driven applications.\nPartner with Data Scientists, ML Engineers, and Product Managers to define business processes, product needs, and AI solution requirements.\nCapture and document epics, user stories, acceptance criteria, and data process flows for AI-powered analytics applications.\nWork closely with partners to define scope, priorities, and impact of new AI and data initiatives.\nEnsure non-functional requirements, such as data security, model interpretability, and system performance, are included in product backlogs.\nFacilitate the breakdown of Epics into Features and Sprint-Sized User Stories and lead backlog grooming sessions.\nEnsure alignment of technical requirements and UX for AI-based applications and interactive dashboards.\nCollaborate with engineers to define data ingestion, transformation, and model deployment processes.\nDevelop and implement product demonstrations showcasing AI-driven insights and analytics.\nMaintain detailed documentation of data pipelines, model lifecycle management, and system integrations.\nStay engaged throughout software development, providing proactive feedback to ensure business needs are met\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. This role bridges the gap between business needs and technical execution, ensuring the development of high-quality, scalable AI solutions. You will collaborate with data scientists, engineers, and product managers to shape product roadmaps, refine requirements, and drive alignment between business objectives and technical capabilities.\nBasic Qualifications:\nMasters degree and 1 to 3 years expereince in Computer Science, Data Science, Information Systems, or related field OR\nBachelors degree and 3 to 5 years of in Computer Science, Data Science, Information Systems, or related field OR\nDiploma and 7 to 9 years of in Computer Science, Data Science, Information Systems, or related field\nPreferred Qualifications:\nExperience defining requirements for AI/ML models, data pipelines, or analytics dashboards.\nFamiliarity with cloud platforms (AWS, Azure, GCP) for AI and data applications.\nUnderstanding of data security, governance, and compliance in AI solutions.\nAbility to communicate complex AI concepts and technical constraints to non-technical partners.\nKnowledge of MLOps, model monitoring, and CI/CD for AI applications.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business analysis', 'continuous integration', 'data science', 'gcp', 'ci/cd', 'microsoft azure', 'information systems', 'aws', 'artificial intelligence']",2025-06-12 14:09:19
Data Engineer,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"Role Description:\nAs part of the cybersecurity organization, In this vital role you will be responsible for designing, building, and maintaining data infrastructure to support data-driven decision-making. This role involves working with large datasets, developing reports, executing data governance initiatives, and ensuring data is accessible, reliable, and efficiently managed. The role sits at the intersection of data infrastructure and business insight delivery, requiring the Data Engineer to design and build robust data pipelines while also translating data into meaningful visualizations for stakeholders across the organization. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture, ETL processes, and cybersecurity data frameworks.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in design and development of the data pipeline.\nBuild data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nDevelop and maintain interactive dashboards and reports using tools like Tableau, ensuring data accuracy and usability\nSchedule and manage workflows the ensure pipelines run on schedule and are monitored for failures.\nCollaborate with multi-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nCollaborate with data scientists to develop pipelines that meet dynamic business needs.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\n\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of experience of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience\nPreferred Qualifications:\nHands on experience with data practices, technologies, and platforms, such as Databricks, Python, GitLab, LucidChart, etc.\nHands-on experience with data visualization and dashboarding toolsTableau, Power BI, or similar is a plus\nProficiency in data analysis tools (e.g. SQL) and experience with data sourcing tools\nExcellent problem-solving skills and the ability to work with large, complex datasets\nUnderstanding of data governance frameworks, tools, and best practices\nKnowledge of and experience with data standards (FAIR) and protection regulations and compliance requirements (e.g., GDPR, CCPA)\n\nGood-to-Have Skills:\nExperience with ETL tools and various Python packages related to data processing, machine learning model development\nStrong understanding of data modeling, data warehousing, and data integration concepts\nKnowledge of Python/R, Databricks, cloud data platforms\nExperience working in Product team's environment\nExperience working in an Agile environment\n\nProfessional Certifications:\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\n\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to handle multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data engineering', 'data analysis', 'data modeling', 'analysis tools', 'data warehousing', 'troubleshooting', 'data architecture', 'data integration', 'etl process']",2025-06-12 14:09:21
Business Analyst,WP Translation And Testing Services,1 - 4 years,5-7 Lacs P.A.,['Navi Mumbai'],"Role - Business Analyst Software Testing Products\nExperience 1-3 Years\nLocation Ghansoli, Navi Mumbai\nNotice period – Immediate – 30 days\nJob Type – Contract (6-9 Months)\n\nWP is looking for a results-oriented Business Analyst with 1-2 years of experience in software product development, specializing in quality assurance (QA) and testing solutions. The candidate should have expertise in gathering and analyzing business requirements by coordinating with relevant stakeholders, act as an interface between stakeholders and development teams, and contribute to the development of scalable, user-friendly test management and testing automation products.\n\nResponsibilities:\n• Collaborate with development team, UI/UX engineering and QA, assist on continuous basis to shape product features aligned with product testing workflows.\n• Research and document requirements from stakeholders and product owners.\n• Document detailed functional specifications and write user stories. Prioritize tasks using internal task management tool.\n• Worked closely with developers to validate logic and alignment with product requirements & functionalities.\n• Perform UAT, validate test cases, and coordinate with QA for release signoffs.\n\nKey Skills:\n• Business analysis expertise with software testing experience will be an added advantage\n• Agile Software Development Lifecycle (SDLC) understanding\n• Exposure to various tools like TestRail, Jira, Bugzila, etc.\n• Workflow Design & User Story Creation (Agile/Scrum)\n• Background of API & Integration Requirement Analysis\n• SQL & Basic Data Analysi",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Agile', 'JIRA', 'SDLC Life Cycle', 'SQL', 'Testrail', 'Scrum', 'API', 'Bugzilla']",2025-06-12 14:09:23
Analytics and Modeling Senior Analyst,Overture Rede,2 - 5 years,Not Disclosed,['Bengaluru'],"Lead sales reporting, business analysis, and team development to enable data-driven decision-making and support sales enablement strategies.\n\nJob Summary\nWe are seeking an experienced Analytics and Modeling Senior Analyst to drive insights and reporting for sales enablement initiatives. The role involves managing analytics processes, mentoring teams, and supporting strategic decision-making through accurate data reporting and business intelligence.\n\nRequired Skills\n5+ years in sales operations and data analysis\nAdvanced Excel skills; Power Query, Power Pivot, Power BI preferred\nExperience in Software & Platforms and cloud/data infrastructure\nExcellent communication and stakeholder management\nProficiency in MS Office Suite (Excel, Word, PowerPoint, Outlook)\nExpertise in workflow management, process mapping, and training delivery\nStrong in RCA, collaboration, and team coaching",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MS Office suite', 'RCA', 'Data analysis', 'Sales operations', 'Business analysis', 'Senior Analyst', 'sales enablement', 'Business intelligence', 'Stakeholder management', 'Analytics']",2025-06-12 14:09:25
Hiring For MIS (Senior Analyst)-Chandigarh,Skyway Solution,1 - 4 years,1-4.25 Lacs P.A.,['Chandigarh'],"Hiring For MIS ( Senior Analyst)-Male\nLocation - Chandigarh\n\nGraduate\nExperience - 1year exp in MIS\n\nSalary - Up to 35,000/-\nRotational shift\n5 days working\nCandidate should must have knowledge of Advance Excel\n\nShare cv@9988352892\nHR -Sonali Rana",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Advanced Excel', 'MIS Operations', 'Formulas', 'Charts', 'MIS Reporting', 'Excel Reporting', 'HLOOKUP', 'Macros', 'Pivot Table', 'MIS', 'VLOOKUP', 'Data Analysis', 'Data Reporting']",2025-06-12 14:09:27
Scientific Business Analyst (Specialist) – Biological Studies (LIMS),Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements LIMS platforms that enable the capture, analysis, storage, and report of pre-clinical and clinical studies as well as those that manage biological sample banks. You will collaborate with Product Owners and developers to maintain an efficient and consistent process, ensuring quality work from the team. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\n\nRoles & Responsibilities:\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the technology ecosystem for in vivo study data management and ensure that the platform meets their requirements for data analysis and data integrity\nTranslate complex scientific and technological needs into clear, actionable requirements for development teams\nDevelop and maintain a product roadmap that clearly outlines the planned features and enhancements, timelines, and achievements\nIdentify and manage risks associated with the systems, including technological risks, scientific validation, and user acceptance\nDevelop documentations, communication plans and training plans for end users\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\nCollaborate with geographically dispersed teams, including those in the US and other international locations.\nFoster a culture of collaboration, innovation, and continuous improvement.\nWhat we expect of you\n\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nMasters degree and 4 to 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree and 6 to 8 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma and 10 to 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nMust-Have\n\nSkills:\nDemonstrated expertise in a scientific domain area and related technology needs\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience in configuration and administration of LIMS/ELN platforms such as Benchling, Revvity, IDBS, STARLIMS, Watson, LabVantage, etc.\nExperience using platforms such as Spotfire, Tableau, Power BI, etc., to build dashboards and reports\nPreferred Qualifications:\n5+ years of experience in designing and supporting biopharma scientific software platforms\nExperience leading the implementation of scientific software platforms, Electronic Lab Notebook (ELN), or Laboratory Information Management Systems (LIMS)\nExperience handling GxP data and system validation, and knowledge of regulatory requirements affecting laboratory data (e.g., FDA 21 CFR Part 11, GLP, GCP)\nKnowledge of bioanalytical workflows and/or biospecimen management\nExperience in AI and machine learning for drug discovery research and preclinical development\nExperience with cloud (e.g. AWS) and on-premise infrastructure\nIn-depth knowledge of Agile processes and principles for coordinated solutions and teams via SAFe\nExperience in establishing business partnerships and IS governance practices involving senior business collaborators\nKnowledge of business analysis standard methodologies, DevOps, Continuous Integration, and Continuous Delivery methodology\nProfessional Certifications:\nSAFe for Teams certification (preferred)\nSoft\n\nSkills:\nAble to work under minimal supervision\nExcellent analytical and gap/fit assessment skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills\nAs we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, well support your journey every step of the way.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Biological Studies', 'computational biology', 'FDA 21 CFR Part 11', 'biopharma', 'GCP', 'bioinformatics', 'system validation', 'GLP', 'computational chemistry', 'GxP data']",2025-06-12 14:09:30
Technical Business Analyst,Euclid Innovations,10 - 20 years,Not Disclosed,[],"Hi ,\nGreetings from Euclid Innovations !!!\n\nWe have openings for Technical Business Analyst with one of our Banking based Company as Remote work Mode.\n\nPosition : Technical Business Analyst\nExperience : 10+ Years\nLocation : Remote\nNotice Period: Immediate to 20 Days Max\n\nSkills set: FINANCIAL /CAPITAL MARKET and FIXED INCOME, EQUITY, CREDIT, Bond, Investment Banking any\n\nDuties and Responsibilities\nAssist in the Business Analysis phase including the capture and translation of business requirements turning these into functional requirements, and non-functional requirements (i.e. architectural, infrastructure, security, testing, migration, operational, DR). Ensuring appropriate documentation of requirements is captured and recorded (e.g. 'Requirement Story' in JIRA).\nAnalysing end to end business streams to establish data requirements in line with XML/XSD modelling, specifically FpML, of entities across multiple business areas across multiple geographical regions.\nLogical Data Modelling working closely with both business and IT teams.\nIdentification of common data requirements and helping to drive shared data platforms.\nCleaning, mapping, and extending data sets to improve business processes and tools.\nCoordination and delivery management of solutions across Enterprise Delivery teams in support of end to end testing and production delivery.\nAdherence to existing global, local and department project standards for documentation, security, testing and release management.\nQualifications, Skills and Experience\nBachelors Degree or equivalent.\nExcellent technical analysis and investigatory skills.\nAbility to work with both business and IT staff in a pressured environment.\nBusiness analysis within an Agile development project.\nStrong data analysis skills to ensure accurate system data extracts and reconciliations working with large datasets.\nProven track record of writing structured business requirements and functional specifications.\nWorking knowledge of financial instruments: government bonds, SAS bonds, credit bonds, exchange traded bond futures, interest rate swaps, repos, stock lending and equities.\nWell-structured and logical approach to working.\nGood knowledge of Compliance business processes.\nProven track record of supporting Back/Middle Office systems.\nProven experience of developing mutually beneficial relationships with business stake holders, users, software solution providers, and other IT teams.\nProven experience of full involvement in project life cycles within Investment Banking.\nProven experience performing system testing and guiding users with building their functional plans for user testing.\nAbility to handle multiple work streams and assignments simultaneously.\nProven experience of issue resolution through data mining and investigation\n\nif interested share profile to aruna.c@euclidinnovations.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Capital Market', 'Data Modelling', 'Investment Banking', 'Business Analyst', 'Technical Business Analyst', 'XML', 'XSD', 'Fixed Income', 'EQUITY']",2025-06-12 14:09:32
Budgeting Analyst Cloud & Enterprise ( Immediate Joiner),Hiring for Telecom Client,7 - 10 years,14-22.5 Lacs P.A.,['Hyderabad'],"Key Result Areas/Accountabilities\n\nBudgeting Strategy and forecasting\nFiscal budget forecasting for Core based on inputs from various stakeholders viz. Business, Marketing, COG, Radio Planning and Enterprise.\nLong Range Planning (LRP), annual and quarterly capex budgeting strategies for Core domain.\nCapex budget finalisation for the year, present annual budgets to CXOs.\nReview budget requests for approval. Prioritization and allocations based on criticality across sub domains and circles.\nFinalisation of capacity, coverage targets, KPIs, deliverables for Core.\nForecast future budget needs and quarter-wise refresh cycles. Interfacing with the finance team for available budget and further execution.\nBudget control and cost efficiency\nRegular monitoring of budget release v/s spend.\nPost budget approval, execution of budget - involvement in various stages of execution, resolving issues in the process, managing budget shortfalls.\nEstimate QoQ capex savings due to various cost-effective measures in coordination with cross functional teams.\nMonitoring reusability of inventory\nEnsure cost effective network solution\nCore Competencies, Knowledge, Experience\n\nTechnical Skills\nNetwork Understanding: A solid grasp of telecommunications networks, especially mobility network (2G/4G/5G) Core and cloud networks. A thorough understanding of cloud infrastructure and various enterprise solutions like CPaaS, U/CCaaS, IoT, SIP Trunking, SDWAN, Private 5G etc.\nData Analysis: Proficiency in data analysis tools (e.g., Excel, Python) to extract insights from large datasets.\nTechnical Writing: Ability to create clear and concise documentation, reports, and presentations.\nProblem-Solving: Strong analytical and problem-solving skills to identify and resolve technical issues.\nTechnical Tools: Extensive experience in leveraging MS Office Suite (Excel, PowerPoint, Word) and SAP for data analysis and reporting,\nSoft Skills\nCommunication Skills: Effective written and verbal communication skills to convey complex technical information to both technical and non-technical audiences.\nAttention to Detail: Meticulous attention to detail to ensure accuracy in data analysis and report generation.\nSchedule Management: Ability to prioritize tasks and meet deadlines efficiently.\nAdaptability: Flexibility to adapt to changing business requirements and technological advancements.\nMust have technical / professional qualifications\n\nEngineering Graduate.\nAny industry grade certifications in Telecom Network, SAP are good to have.\nYears of Experience\n\nMin 6 Years",Industry Type: Telecom / ISP,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Budget Analysis', 'Ucaas', 'SDWAN', 'SAP', 'QoQ capex', 'Cost Optimization', 'IoT', 'mobility network', 'Private 5G', 'CPaaS', 'Budgeting Strategy and forecasting', 'SIP Trunking', 'cloud infrastructure', 'Cost Planning', 'Revenue Planning']",2025-06-12 14:09:35
Business Analyst (Capital Markets),Eagle Technology Resources,5 - 10 years,Not Disclosed,[],"Job Title: Business Analyst Capital Markets\nLocation: Bhuvaneswar/Chennai/Remote Work\nSalary: Based on competency\nRequired Skills (Domain):\nCandidate must possess minimum of 5+ years of experience in Banking and Financial services domain with Investment Management experience.\nGood understanding of the systems, workflows and data related to front, middle, and back-office solutions in Asset Servicing/Asset Management.\nStrong grasp of Investment operational processes with respect to Accounting, Pricing, Nav Calculation, Trade Settlement, Reconciliation, Reference Data Management, Corporate Actions etc\nHands-on experience in Eagle suit of products (Accounting, RDC/SRM, Data Management or Performance) is a must.\nClient interfacing skills, Requirements gathering, Data Analysis skills and Test Execution skills are mandatory\nGood understanding of Market Data and operational workflow related to EQ, Fixed Income, Derivatives (Options, Futures, Swaps, etc) and/or Alternatives are a must\nStrong understanding of data integration, meta data management and ability to run SQL queries to perform data analysis are must to have.\nStrong communication and Documentation skills are mandatory Exposure to Third-party data providers such as Bloomberg, Reuters, MSCI, and other rating agencies is a plus.\nThis is what you will do:\nThis position requires a highly motivated individual with the ability to work independently and as part of a project team.\nYou will :\nBe working with the client team to gather requirements, demonstrate product capabilities, define/streamline Business Processes, train the client team on product modules, triage, debug, and fix quality issues through resolution.\nMust rationalize problems and use judgment and innovation to define clear and concise solutions.\nPerform gap analysis or conduct Proof of concepts where necessary\nPrepare Functional Requirements and to articulate them to Client Stakeholders to pursue approvals.\nHandle client expectations and manage the delivery of related interfaces by internally coordinating with teams across the globe.\nPrepare test bed for UAT executions\nBe writing test cases, test plans and preparing detailed test logs with suitable proof of validation.\nBe writing SQL queries to validate voluminous data across systems and performing reconciliation.\nCollaborate across regions (APAC, EMEA, and NA) to effectively and efficiently identify root cause of code/data issues and come up with a permanent solution.\nTeam Overview:\nThe dedicated team of highly skilled professionals at Eagle Technology Resources Pvt Ltd work on ensuring deployment of innovative solutions for the complex world of finance. Our extensive experience helps clients bring to life their business and technology operations, as well as gain the most value from their ongoing investments in technology.\nThis is what you will get:\nCompetitive compensation package.\nA close and informal relation with the client’s team (We are treated as the extension of the project team of our client).\nChallenging product development work with a team of professionals.\nDynamic environment with very low level of bureaucracy.\nFlexible working hours with the option to work from home under certain circumstances.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Data Management', 'Fixed Income Analysis', 'Capital Market', 'Market Data', 'Requirement Gathering', 'Reconciliation', 'Middle Office Operations', 'Derivatives', 'Consulting And Implementation', 'Trade Settlements', 'Investment Management', 'SQL']",2025-06-12 14:09:37
Scientific Business Analyst ( Specialist ) – Large Molecule Discovery,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that they technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role demonstrates scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams.\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the Large Molecule Discovery technology ecosystem and ensure that the platform meets the requirements for data analysis and data integrity\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\nBasic Qualifications:\nMasters degree with 4 - 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 6- 8years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 10 - 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nPreferred Qualifications:\n5+ years of experience in implementing and supporting biopharma scientific software platforms.\n\n\nFunctional Skills:\nMust-Have Skills:\nProven expertise in a scientific domain area and related technology needs\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience in configuration and administration of LIMS/ELN platforms (e.g. Benchling), Discovery software tools (e.g. Geneious, Genedata Screener) and Instrument Automation and Analysis platforms\nExperience using platforms such as Spotfire, Tableau, Power BI, etc., to build dashboards and reports and understanding of basic data querying using SQL, Databricks, etc.\n\n\nGood-to-Have Skills:\nExperience leading the implementation of scientific software platforms, Electronic Lab Notebook (ELN), or Laboratory Information Management Systems (LIMS)\nKnowledge of the antibody discovery design, make, test, and analyze cycle.\nExperience in AI and machine learning for drug discovery research and preclinical development\nExperience with leveraging LLM tools to accelerate software development processes.\nExperience with cloud (e.g. AWS) and on-premise infrastructure.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analysis', 'Spotfire', 'Power BI', 'Tableau', 'Databricks', 'JIRA', 'LLM', 'AWS', 'SQL']",2025-06-12 14:09:39
Data Scientist (Offshore),HTC Global Services,2 - 7 years,Not Disclosed,['Chennai'],"We are seeking a Data Scientist (Offshore) with minimum experience of 3 or more years. The ideal candidate should be familiar with relational or NoSQL databases such as Oracle, Teradata, SQL Server, Hadoop and ELK etc.\nRequirements:\nMinimum 3 or more years working with languages such as R, Python or Java\nAt least 3 or more years working with advanced statistical methods such as regressions, classifiers, recommenders, anomaly detection, optimization algorithms, tree methods and neural nets etc.",,,,"['tableau', 'NoSQL', 'Hadoop', 'Agile', 'Teradata SQL', 'data visualization', 'Oracle', 'Powerpoint', 'SDLC', 'Python']",2025-06-12 14:09:41
Supplier Quality Management Senior Analyst,Vertiv Group Corp,5 - 8 years,Not Disclosed,['Mumbai'],"Vertiv Group Corp is looking for Supplier Quality Management Senior Analyst to join our dynamic team and embark on a rewarding career journey.\nThe Senior Analyst plays a crucial role in driving data-driven decision-making processes within the organization\nThis position involves analyzing complex data sets, generating actionable insights, and providing strategic recommendations to support key business initiatives\nKey Responsibilities:Data Analysis:Conduct in-depth analysis of large and complex datasets to extract meaningful insights",,,,"['inprocess quality', 'sqa', 'data analysis', 'apqp', 'quality control', 'iso', 'control plan', 'spc', '7qc', 'pfmea', 'incoming quality', '8d', 'fmea', 'supplier quality assurance', 'quality assurance', 'qms', 'vendor quality', 'supplier quality', 'msa', 'supplier audit', 'ppap', 'customer quality']",2025-06-12 14:09:44
"Financial Analyst II - AR, FinOps",Amazon,5 - 10 years,Not Disclosed,['Hyderabad'],"Are you an experienced Program Manager interested in an opportunity to help drive Amazon s flywheel and develop your A to Z business understanding? Do you enjoy learning about different Amazon business types and new subsidiaries, and thinking creatively about brand new businesses that Amazon is inventing on behalf of customers? The Global Accounts Receivable (GAR) team is seeking a creative and passionate program manager to help achieve our vision to provide a world-class Order-to-Cash (O2C) onboarding experience to our global business partners in support of Amazon s journey to become earth s most customer-centric company. We love to offer our customers unique world-class experiences, and we invite you to help Amazon make history!\n\nThe Program Manager will have global oversight of the integration of new initiatives onto O2C platforms, driving effective people, processes, and technology to achieve organizational goals and deliver results. This individual will have ownership over new business integration programs while standardizing the global implementation processes and driving efficiency. This role will require engagement and alignment with global business teams, finance teams, operational teams, system developers and product managers. Responsibilities include supporting new business initiatives through designing transactional workflows in line with the business model, defining requirements and testing of the solutions to ensure delivery is as expected and delivering and improving the customer experience. Implementation of mechanisms to monitor and measure performance is essential.\n\nThe ability to thrive in a fast-paced, ambiguous and demanding work environment is critical to success in this role. The ideal candidate will be a self-starter with knowledge of program management, experience with accounts receivable operational processes, demonstrate faster learning and adoptability, demonstrate good relationship and strategic influencing skills, experienced in large scale change management across functions and geographies, and exhibit a relentless pursuit for improvement. This individual must have a proven record of delivering results through good program management skills, problem solving skills, financial process and system knowledge, and a passion for customer experience.\n\nCore Requirements:\n5+ years of Accounts Receivable experience, with at least 2 years in a leadership role( not mandate)\nBachelors degree in Finance, Accounting, Business Administration, or related field\nAdvanced Excel skills and experience with ERP systems\nData Analytics Requirements:\n3+ years experience with data analysis and reporting tools\nProficiency in SQL for data extraction and analysis\nExperience with visualization tools (e.g., Tableau, Power BI)\nDemonstrated ability to translate data insights into actionable recommendations\n\nProgram Management Skills:\n3+ years experience managing complex projects or programs\nTrack record of process improvement initiatives\nExperience leading cross-functional teams\nGood stakeholder management abilities\nTechnical Skills:\nExperience with AR automation tools and systems\nKnowledge of financial control frameworks\nProficiency in Microsoft Office Suite\nExperience with business intelligence platforms\n\nAdditional Desired Qualifications:\nMBA or relevant masters degree\nProfessional certifications (CPA, PMP, or similar)\nExperience with machine learning or predictive analytics\nKnowledge of Python or R for advanced data analysis\n\n\nOwnership and implementation of new businesses and subsidiaries onto AR platforms\nPartner with key counterparts across geographies to launch and support initiatives globally in a scalable manner\nDevelop a solid understanding of Amazon s Finance Operations systems and processes\nDefine and implement global standards for business integration program management\nDefine and describe various business scenarios that can be relevant to New Businesses and convert them into system and operational requirements.\nTranslate complex business requirements into functional designs\nOversee comprehensive testing of systems changes and development of standard operating procedures, process documentation and performance metrics\nManage process transitions/implementations across multiple functions and geographies\nMotivate and influence business, operational and technical teams to ensure that best practices are followed and implemented\nIdentify, assess, track and mitigate risks at multiple levels\nProactively monitor program performance to identify, address and prevent potential issues\nAddress barriers through problem solving, communication and active coordination with stakeholders\nDrive effective teamwork, communication collaboration and commitment across multiple disparate groups with competing priorities\nIdentify gaps and strive constantly for re-engineering of systems and processes\nAmazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability /\nVeteran / Gender Identity / Sexual Orientation\n5+ years of Accounts Receivable (AR) experience 4+ years of participating in continuous improvement projects in your team to scale and improve controllership with measurable results experience\nMBA, or CPA\nKnowledge of Tableau\nExperience working with large-scale data mining and reporting tools (examples: SQL, MS Access, Essbase, Cognos) and other financial systems (examples: Oracle, SAP, Lawson, JD Edwards)",,,,"['Data analysis', 'Change management', 'PMP', 'SAP', 'MS Access', 'Process improvement', 'Oracle', 'Data mining', 'Business intelligence', 'SQL']",2025-06-12 14:09:46
Senior Associate - Data Science,Axtria,3 - 8 years,Not Disclosed,['Noida'],"Job Summary-\nData Scientist with good hands-on experience of 3+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nJob Responsibilities-\n\n1. Hands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\n2. Proficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\n3. Experience of working in large teams and using collaboration tools like GIT, Jira and Confluence\n4. Good understanding of any of the cloud platform - AWS, Azure or GCP\n5. Understanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\n6. Should have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\n7. Should be able to mentor and guide mid to large sized teams under him/her\n\nJob -\n1. Strong experience on Spark with Scala/Python/Java\n2. Strong proficiency in building/training/evaluating state of the art machine learning models and its deployment\n3. Proficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\n4. Proficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'keras', 'spark mllib', 'jira', 'sentiment analysis', 'lingpipe', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-12 14:09:49
Senior Associate - Data Science,Axtria,2 - 5 years,Not Disclosed,['Noida'],"Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT\nSoftware development experience in python is needed as backend for UI based applications\nBe a part of large delivery teams working on advanced projects when expert assistance is required.\nDeliver advanced Data Science capabilities to businesses in a meaningful manner through successful proof-of-concept solutions, and later smoothly transition the proof-of-concept into production.\nCreate Technical documents, develop, test, and deploy data analytics processes using Python, SQL on Azure/AWS platforms\nCan interact with client on GenAI related capabilities and use cases\n\n\nMust have\n\nSkills:\n\n\nMinimum of 3-5years develop, test, and deploy Python based applications on Azure/AWS platforms\nMust have basic knowledge on concepts of Generative AI / LLMs / GPT\nDeep understanding of architecture and work experience on Web Technologies\nPython, SQL hands-on experience\nExpertise in any popular python web frameworks e.g. flask, Django etc.\nFamiliarity with frontend technologies like HTML, JavaScript, REACT",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'software testing', 'gpm', 'microsoft azure', 'python web framework', 'data analytics', 'neural networks', 'aws stack', 'machine learning', 'javascript', 'artificial intelligence', 'sql', 'react.js', 'deep learning', 'django', 'data science', 'html', 'flask', 'aws']",2025-06-12 14:09:51
Sr Tax Analyst,Illuminz,4 - 7 years,Not Disclosed,['Bengaluru'],"What if the work you did every day could impact the lives of people you know? Or all of humanity?\nAt Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients.\nWorking at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world changing projects, you will do more and become more than you ever thought possible.\nJoin us and you can make a difference\nIllumina s mission is to improve human health by unlocking the power of the genome. If that inspires you, let s talk.\nAt Illumina, we push boundaries. We think beyond the conventional. We dream big. With the energy of so many bright and accomplished people, the opportunities are endless. You ll join a culture fueled by innovation, collaboration and openness. We change lives by driving advancements in life sciences, oncology, reproductive health, genetic disease and other emerging markets. We are all deeply passionate about what we do, knowing that our work has the power to improve lives.\nJob Summary\nIllumina is looking for Tax Analyst/Sr Tax Analyst to be part of newly created Tax Center of Excellence in India and reports to Tax Manager in India. This role will be APAC tax compliance focused and primarily responsible in all aspects of data analysis, tax calculation and reconciliation necessary to meet APAC tax filing, tax audit and statutory audit requirements in APAC region. You will support the Tax Manager in fostering seamless collaboration with global/regional Finance and Tax teams, and other business stakeholders to ensure the adherence of tax compliance governance and efficient tax process maintained in the region.\nTasks and Responsibilities:\nJob duties include but not limited to:\nPrepare monthly tax calculation for APAC entities, this includes extracting SAP reports, analyzing and reconciling financial data, and coordinating with finance teams.\nCollation and managing all aspects of information necessary for submission in tax audits, inquiries and notices raised by tax authorities.\nPerform financial data analysis/schedules/reports necessary for internal and external tax reporting for APAC entities\nInvolve in month-end/statutory audit activities, this includes preparing tax provision/deferred tax calculation and reconciliation relating to tax accounts for APAC entities\nIdentify and drive opportunities for process optimization within the tax reporting workflow, which includes collaborating with internal stakeholder to align processes and implementing into the working environment.\nResearch tax regulations to address daily inquiry on TDS/GST/withholding tax/SAC coding\nParticipate in cross-functional projects and tax projects as and when assigned by the Regional Tax Team/Tax Manager\nPreferred Educational Background:\nBachelor s degree or equivalent in Accounting/Finance/Taxation.\nMinimum 4-7 year in accounting with direct and indirect tax from Big 4 or Accounting with taxation experience. APAC region exposure is a plus\nProficiency in Microsoft Office applications especially Microsoft Excel;\nPrior experience in SAP (or equivalent ERP system) is preferred;\nGood organizational skills, highly detailed oriented and ability to work with minimal supervision and independently;\nAbility to work in a dynamic and fast paced environment and a multi-tasker;\nAbility to be flexible and work analytically in a problem-solving environment;\nExcellent communication (written and oral) and interpersonal skills.\n\nWe are a company deeply rooted in belonging, promoting an inclusive environment where employees feel valued and empowered to contribute to our mission. Built on a strong foundation, Illumina has always prioritized openness, collaboration, and seeking alternative perspectives to propel innovation in genomics. We are proud to confirm a zero-net gap in pay, regardless of gender, ethnicity, or race. We also have several Employee Resource Groups (ERG) that deliver career development experiences, increase cultural awareness, and offer opportunities to engage in social responsibility. We are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. Illumina conducts background checks on applicants for whom a conditional offer of employment has been made. Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable local, state, and federal laws. Background check results may potentially result in the withdrawal of a conditional offer of employment. The background check process and any decisions made as a result shall be made in accordance with all applicable local, state, and federal laws. Illumina prohibits the use of generative artificial intelligence (AI) in the application and interview process. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https: / / www.dol.gov / ofccp / regs / compliance / posters / pdf / eeopost.pdf. The position will be posted until a final candidate is selected or the requisition has a sufficient number of qualified applicants. This role is not eligible for visa sponsorship.",Industry Type: Pharmaceutical & Life Sciences,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['TDS', 'Data analysis', 'Process optimization', 'SAP', 'Excel', 'Coding', 'Tax reporting', 'Workflow', 'Taxation', 'Auditing']",2025-06-12 14:09:54
Senior Data Scientist,Straive,5 - 10 years,Not Disclosed,"['Hyderabad', 'Gurugram', 'Bengaluru']","Role & responsibilities\nRequires 5-8 years of proven experience in banking/payments/other domains\nStrong experience in developing Machine Learning models, Python & SQL\nExperience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases\nDetailed oriented with a proactive mindset towards problem-solving\nExcellent communication and presentation skills with the ability to convey complex information clearly and concisely",,,,"['Machine Learning', 'Python', 'SQL', 'Xgboost', 'Neural Networks', 'Random Forest']",2025-06-12 14:09:56
Analyst - Projects,Microland,4 - 6 years,Not Disclosed,['Bengaluru'],"Microland Limited is looking for Analyst - Projects to join our dynamic team and embark on a rewarding career journey.\n\nAs a Project Analyst, you will play a crucial role in supporting project planning, execution, and monitoring activities. Your responsibilities will include data analysis, reporting, and providing valuable insights to ensure the successful completion of projects. Strong analytical skills, attention to detail, and effective communication are essential for this role. Responsibilities : Project Planning Support : Assist in the development of project plans, including timelines, milestones, and resource requirements. Collaborate with project managers to ensure accurate and comprehensive project documentation. Data Analysis : Collect, analyze, and interpret data related to project performance and key metrics. Identify trends, patterns, and areas for improvement based on data analysis. Reporting : Prepare regular project status reports, highlighting key performance indicators and progress against goals. Communicate project updates to stakeholders in a clear and concise manner. Risk Management : Work with the project team to identify and assess risks. Contribute to the development of risk mitigation strategies. Resource Coordination : Collaborate with various teams and departments to ensure resources are allocated effectively. Assist in tracking resource utilization and availability. Quality Assurance : Support the implementation of quality assurance processes to ensure project deliverables meet established standards. Conduct periodic reviews to assess project compliance. Documentation : Maintain accurate and up - to - date project documentation, including meeting minutes, action items, and decision logs. Ensure documentation aligns with organizational standards.",,,,"['Data analysis', 'Master Analyst', 'Project management', 'Agile', 'Manager Technology', 'Scrum', 'Data analytics']",2025-06-12 14:09:58
"Associate Analyst, R Programmer-1",Mastercard,1 - 4 years,Not Disclosed,['Gurugram'],"We are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology.\nAn individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (eg Plotly, Highcharts, D3.js) or front-end frameworks (eg React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, we'll-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (eg roxygen2)\nfamiliar with version control concepts and tools (eg Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:00
Process Executive - B&L,Cognizant,0 - 2 years,Not Disclosed,['Coimbatore'],Job Summary\nThe Process Executive - B&L role is designed for individuals with 0 to 2 years of experience focusing on tasks related to consumer lending cards and payments. This position requires proficiency in MS Excel and offers a hybrid work model with day shifts. The role does not require travel allowing for a balanced work-life integration.,,,,"['cards', 'data analysis', 'analytical', 'workflow', 'lending', 'documentation', 'policies', 'business analysis', 'monitoring', 'process improvements', 'sql', 'plsql', 'excel', 'flexcube', 'operations', 'customer satisfaction', 'service delivery', 'compliance', 'onboarding', 'core banking', 'consumer lending', 'communication skills']",2025-06-12 14:10:03
Data & Analytics Specialist,Hoffmann La Roche,5 - 10 years,Not Disclosed,['Pune'],"At Roche you can show up as yourself, embraced for the unique qualities you bring. Our culture encourages personal expression, open dialogue, and genuine connections, where you are valued, accepted and respected for who you are, allowing you to thrive both personally and professionally. This is how we aim to prevent, stop and cure diseases and ensure everyone has access to healthcare today and for generations to come. Join Roche, where every voice matters.\nThe Position The Position\nWe are looking for a Data & Analytics Specialist/ Business Analyst who will join us in the newly setup Integrated Informatics for a journey to drive transformation with data and foster automated and efficient decision making throughout the organisation\nThe Data and Analytics Specialist must be the big-picture thinker who understands the value of data to the organisation, has a strong focus on delivering high value, connecting the dots, investing in right initiatives with reusability at the heart of it.\nIn this position you will be acting as squad lead, have end to end ownership of Product delivery with setting up teams from multiple teams/areas with focus on Lifecycle management of the product\nResponsibilities\nYou will work on various aspects of Analytics Solution Development, Data Management, Governance and Information Architecture including but not limited to:\nCollaborate with business stakeholders to understand their data and analytics needs and develop a product roadmap that aligns with business goals.\nDefine and prioritise product requirements, user stories, and acceptance criteria for data and analytics products and ensure what was agreed gets delivered.\nWork with data engineers and data scientists to develop data pipelines, analytical models, and visualisations that meet business requirements.\nCollaborate with Infrastructure Teams and software developers to ensure that data and analytics products are integrated into existing systems and platforms in a sustainable way that still meets the needs of business to generate the insights necessary to drive their decisions.\nMonitor data and analytics product performance and identify opportunities for improvement.\nStay up-to-date with industry trends and emerging technologies related to data and analytics in the pharmaceutical industry.\nAct as a subject matter expert for data and analytics products and provide guidance to business stakeholders on how to effectively use these products.\nAccountable to Develop and maintain documentation, training materials, and user guides for data and analytics products.\nThe ideal candidate\nBachelors or Masters degree in computer science, information systems, or a related field.\n5+ years of experience in roles such as Senior Data & Analytics Specialist, Data Solutions Lead, Data Architect, or Data Consultant, with a focus on solution design and implementation. Alternatively, 3-4 years of experience in data streams (e.g., Data Science, Data Engineering, Data Governance) combined with a couple of years in Strategic Data Consultancy / Data Product Ownership. Experience in the pharmaceutical or healthcare industry is highly desirable.\nHigh Level understanding of data engineering, data science, Data governance and analytics concepts and technologies.\nExperience working with cross-functional teams, including data engineers, data scientists, and software developers.\nExcellent communication and interpersonal skills.\nStrong analytical and problem-solving skills.\nExperience with agile development methodologies.\nKnowledge of regulatory requirements related to data and analytics in the pharmaceutical industry.\nKnowledge of working with vendor and customer master data for different divisions - Pharmaceuticals, Diagnostic, & Diabetes care.\nUnderstanding of the transparency reporting landscape.\nHands-on experience of working on applications such as Jira, SQL, Postman, SAP GUI, Monday.com, Trello\nProficient in the knowledge of different CRM/Master Data Management systems such as SFDC, Reltio MDM\nUnderstanding data protection laws and consent processes applicable to healthcare professionals and organizations before transparency disclosure.\nWho we are\n.\nBasel is the headquarters of the Roche Group and one of its most important centres of pharmaceutical research. Over 10,700 employees from over 100 countries come together at our Basel/Kaiseraugst site, which is one of Roche`s largest sites. Read more.\nBesides extensive development and training opportunities, we offer flexible working options, 18 weeks of maternity leave and 10 weeks of gender independent partnership leave. Our employees also benefit from multiple services on site such as child-care facilities, medical services, restaurants and cafeterias, as well as various employee events.\nWe believe in the power of diversity and inclusion, and strive to identify and create opportunities that enable all people to bring their unique selves to Roche.\nRoche is an Equal Opportunity Employer.\nWho we are\nA healthier future drives us to innovate. Together, more than 100 000 employees across the globe are dedicated to advance science, ensuring everyone has access to healthcare today and for generations to come. Our efforts result in more than 26 million people treated with our medicines and over 30 billion tests conducted using our Diagnostics products. We empower each other to explore new possibilities, foster creativity, and keep our ambitions high, so we can deliver life-changing healthcare solutions that make a global impact.\n\nLet s build a healthier future, together.\nRoche is an Equal Opportunity Employer.\n""",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAP', 'Diagnostics', 'HP data protector', 'Analytical', 'Healthcare', 'JIRA', 'Analytics', 'SQL', 'CRM']",2025-06-12 14:10:05
Data & Analytics Specialist,Roche Diagnostics,5 - 10 years,Not Disclosed,['Pune'],"At Roche you can show up as yourself, embraced for the unique qualities you bring. Our culture encourages personal expression, open dialogue, and genuine connections, where you are valued, accepted and respected for who you are, allowing you to thrive both personally and professionally. This is how we aim to prevent, stop and cure diseases and ensure everyone has access to healthcare today and for generations to come. Join Roche, where every voice matters.\nThe Position The Position\nWe are looking for a Data & Analytics Specialist/ Business Analyst who will join us in the newly setup Integrated Informatics for a journey to drive transformation with data and foster automated and efficient decision making throughout the organisation\nThe Data and Analytics Specialist must be the big-picture thinker who understands the value of data to the organisation, has a strong focus on delivering high value, connecting the dots, investing in right initiatives with reusability at the heart of it.\nIn this position you will be acting as squad lead, have end to end ownership of Product delivery with setting up teams from multiple teams/areas with focus on Lifecycle management of the product\nResponsibilities\nYou will work on various aspects of Analytics Solution Development, Data Management, Governance and Information Architecture including but not limited to:\nCollaborate with business stakeholders to understand their data and analytics needs and develop a product roadmap that aligns with business goals.\nDefine and prioritise product requirements, user stories, and acceptance criteria for data and analytics products and ensure what was agreed gets delivered.\nWork with data engineers and data scientists to develop data pipelines, analytical models, and visualisations that meet business requirements.\nCollaborate with Infrastructure Teams and software developers to ensure that data and analytics products are integrated into existing systems and platforms in a sustainable way that still meets the needs of business to generate the insights necessary to drive their decisions.\nMonitor data and analytics product performance and identify opportunities for improvement.\nStay up-to-date with industry trends and emerging technologies related to data and analytics in the pharmaceutical industry.\nAct as a subject matter expert for data and analytics products and provide guidance to business stakeholders on how to effectively use these products.\nAccountable to Develop and maintain documentation, training materials, and user guides for data and analytics products.\nThe ideal candidate\nBachelors or Masters degree in computer science, information systems, or a related field.\n5+ years of experience in roles such as Senior Data & Analytics Specialist, Data Solutions Lead, Data Architect, or Data Consultant, with a focus on solution design and implementation. Alternatively, 3-4 years of experience in data streams (e.g., Data Science, Data Engineering, Data Governance) combined with a couple of years in Strategic Data Consultancy / Data Product Ownership. Experience in the pharmaceutical or healthcare industry is highly desirable.\nHigh Level understanding of data engineering, data science, Data governance and analytics concepts and technologies.\nExperience working with cross-functional teams, including data engineers, data scientists, and software developers.\nExcellent communication and interpersonal skills.\nStrong analytical and problem-solving skills.\nExperience with agile development methodologies.\nKnowledge of regulatory requirements related to data and analytics in the pharmaceutical industry.\nKnowledge of working with vendor and customer master data for different divisions - Pharmaceuticals, Diagnostic, & Diabetes care.\nUnderstanding of the transparency reporting landscape.\nHands-on experience of working on applications such as Jira, SQL, Postman, SAP GUI, Monday.com, Trello\nProficient in the knowledge of different CRM/Master Data Management systems such as SFDC, Reltio MDM\nUnderstanding data protection laws and consent processes applicable to healthcare professionals and organizations before transparency disclosure.\nWho we are\nAt Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we ve become one of the world s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\nBasel is the headquarters of the Roche Group and one of its most important centres of pharmaceutical research. Over 10,700 employees from over 100 countries come together at our Basel/Kaiseraugst site, which is one of Roche`s largest sites. Read more.\nBesides extensive development and training opportunities, we offer flexible working options, 18 weeks of maternity leave and 10 weeks of gender independent partnership leave. Our employees also benefit from multiple services on site such as child-care facilities, medical services, restaurants and cafeterias, as well as various employee events.\nWe believe in the power of diversity and inclusion, and strive to identify and create opportunities that enable all people to bring their unique selves to Roche.\nRoche is an Equal Opportunity Employer.\nWho we are\n.\n\nLet s build a healthier future, together.\nRoche is an Equal Opportunity Employer.\n""",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAP', 'Diagnostics', 'HP data protector', 'Analytical', 'Healthcare', 'JIRA', 'Analytics', 'SQL', 'CRM']",2025-06-12 14:10:07
"Associate Analyst, R Programmer-2",Mastercard,3 - 6 years,Not Disclosed,['Gurugram'],"The Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (eg Plotly, Highcharts, D3.js) or front-end frameworks (eg React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, we'll-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (eg roxygen2)\nfamiliar with version control concepts and tools (eg Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:10
Senior Associate Data Scientist,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will identify trends, root causes, and potential improvements in our products and processes, ensuring that patient voices are heard and addressed with utmost precision.\nAs the Sr Associate Data Scientist at Amgen, you will be responsible for developing and deploying basic machine learning, operational research, semantic analysis, and statistical methods to uncover structure in large data sets. This role involves creating analytics solutions to address customer needs and opportunities.\nCollect, clean, and manage large datasets related to product performance and patient complaints.\nEnsure data integrity, accuracy, and accessibility for further analysis.\nDevelop and maintain databases and data systems for storing patient complaints and product feedback.\nAnalyze data to identify patterns, trends, and correlations in patient complaints and product issues.\nUse advanced statistical methods and machine learning techniques to uncover insights and root causes.\nDevelop analytics or predictive models to foresee potential product issues and patient concerns to address customer needs and opportunities.\nPrepare comprehensive reports and visualizations to communicate findings to key collaborators.\nPresent insights and recommendations to cross-functional teams, including product development, quality assurance, and customer service.\nCollaborate with regulatory and compliance teams to ensure adherence to healthcare standards and regulations.\nFind opportunities for product enhancements and process improvements based on data analysis.\nWork with product complaint teams to implement changes and monitor their impact.\nStay abreast of industry trends, emerging technologies, and standard methodologies in data science and healthcare analytics.\nEvaluate data to support product complaints.\nWork alongside software developers and software engineers to translate algorithms into commercially viable products and services.\nWork in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\nPerform exploratory and targeted data analyses using descriptive statistics and other methods.\nWork with data engineers on data quality assessment, data cleansing and data analytics\nGenerate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience OR\nBachelors degree and 3 to 5 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience OR\nDiploma and 7 to 9 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience\nPreferred Qualifications:\nDemonstrated skill in the use of applied analytics, descriptive statistics, feature extraction and predictive analytics on industrial datasets.\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification.\nExperience in analyzing time-series data for forecasting and trend analysis.\nExperience with Data Bricks platform for data analytics.\nExperience working with healthcare data, including patient complaints, product feedback, and regulatory requirements.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'data bricks', 'hypothesis testing', 'predictive analytics', 'data visualization', 'machine learning', 'statistics']",2025-06-12 14:10:12
"Associate Analyst, R Programmer-3",Mastercard,4 - 7 years,Not Disclosed,['Gurugram'],"The Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology.\n  An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (eg Plotly, Highcharts, D3.js) or front-end frameworks (eg React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, we'll-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (eg roxygen2)\nfamiliar with version control concepts and tools (eg Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:14
Data Engineer,AMERICAN EXPRESS,2 - 4 years,13-17 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Role & responsibilities\nUnderstanding business use cases and be able to convert to technical design\nPart of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners.\nYou will be designing scalable, testable and maintainable data pipelines\nIdentify areas for data governance improvements and help to resolve data quality problems through the appropriate choice of error detection and correction, process control and improvement, or process design changes",,,,"['Spark', 'SQL', 'Python', 'Hadoop', 'Big Data']",2025-06-12 14:10:16
Data Engineer,Luxoft,5 - 10 years,Not Disclosed,['Pune'],"Are you passionate about data and analytics? Are you keen to be part of the journey to modernize a data warehouse/ analytics suite of application(s). Do you take pride in the quality of software delivered for each development iteration?\nWere looking for someone like that to join us and\nbe a part of a high-performing team on a high-profile project.\nsolve challenging problems in an elegant way\nmaster state-of-the-art technologies\nbuild a highly responsive and fast updating application in an Agile & Lean environment\napply best development practices and effectively utilize technologies\nwork across the full delivery cycle to ensure high-quality delivery\nwrite high-quality code and adhere to coding standards\nwork collaboratively with diverse team(s) of technologists\nYou are:\nCurious and collaborative, comfortable working independently, as well as in a team\nFocused on delivery to the business\nStrong in analytical skills. For example, the candidate must understand the key dependencies among existing systems in terms of the flow of data among them. It is essential that the candidate learns to understand the big picture of how IB industry/business functions.\nAble to quickly absorb new terminology and business requirements\nAlready strong in analytical tools, technologies, platforms, etc. The candidate must also demonstrate a strong desire for learning and self-improvement.\nOpen to learning home-grown technologies, support current state infrastructure and help drive future state migrations. imaginative and creative with newer technologies\nAble to accurately and pragmatically estimate the development effort required for specific objectives\nYou will have the opportunity to work under minimal supervision to understand local and global system requirements, design and implement the required functionality/bug fixes/enhancements. You will be responsible for components that are developed across the whole team and deployed globally.\nYou will also have the opportunity to provide third-line support to the applications global user community, which will include assisting dedicated support staff and liaising with the members of other development teams directly, some of which will be local and some remote.\nSkills\nMust have\nA bachelors or masters degree, preferably in Information Technology or a related field (computer science, mathematics, etc.), focusing on data engineering.\n5+ years of relevant experience as a data engineer in Big Data is required.\nStrong Knowledge of programming languages (Python / Scala) and Big Data technologies (Spark, Databricks or equivalent) is required.\nStrong experience in executing complex data analysis and running complex SQL/Spark queries.\nStrong experience in building complex data transformations in SQL/Spark.\nStrong knowledge of Database technologies is required.\nStrong knowledge of Azure Cloud is advantageous.\nGood understanding and experience with Agile methodologies and delivery.\nStrong communication skills with the ability to build partnerships with stakeholders.\nStrong analytical, data management and problem-solving skills.\nNice to have\nExperience working on the QlikView tool\nUnderstanding of QlikView scripting and data model\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nBig Data Engineer (Scala/Java/Python)\nBigData Development\nUnited States of America\nStamford, US\nBig Data Engineer (Scala/Java/Python)\nBigData Development\nUnited States of America\nWeehawken\nData Engineer - PostgreSQL\nBigData Development\nPoland\nRemote Poland\nPune, India\nReq. VR-114879\nBigData Development\nBCM Industry\n05/06/2025\nReq. VR-114879\nApply for Data Engineer in Pune\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data management', 'Coding', 'Postgresql', 'Agile', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-12 14:10:19
Data Science Manager,ZS,10 - 15 years,Not Disclosed,"['Pune', 'Bengaluru']","A key enabler of our services is leveraging data in delivering client solutions. The data available about customers is getting richer and the problems that our customers are trying to answer continue to evolve. In our endeavor to stay ahead in providing solutions to these evolving complex problems, ZS has set up an Advanced Data Science which has three major focus areas:\nResearch the evolving datasets and advanced analytical techniques to develop new offerings/solutions\nDeliver client impact by collaboratively implementing these solutions",,,,"['Team management', 'data science', 'Pharma', 'Analytical', 'Management consulting', 'Financial planning', 'Healthcare', 'Project planning', 'Predictive modeling', 'Financial services']",2025-06-12 14:10:21
"Associate Analyst, R Programmer-3",Dynamic Yield,4 - 7 years,Not Disclosed,['Gurugram'],"Our Purpose\nTitle and Summary\nAssociate Analyst, R Programmer-3\nOverview\nThe Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (e.g. Plotly, Highcharts, D3.js) or front-end frameworks (e.g. React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, well-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (e.g. roxygen2)\nfamiliar with version control concepts and tools (e.g. Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:23
Enterprise Data Operations Manager,Pepsico,12 - 17 years,Not Disclosed,['Hyderabad'],"Overview\n\nDeputy Director - Data Engineering\n\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCos global business scale to enable business insights, advanced analytics, and new product development. PepsiCos Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nIncrease awareness about available data and democratize access to it across the company.\nAs a data engineering lead, you will be the key technical expert overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be empowered to create & lead a strong team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premises data sources as well as cloud and remote systems.\nResponsibilities\n\nData engineering lead role for D&Ai data modernization (MDIP)\n\nIdeally Candidate must be flexible to work an alternative schedule either on tradition work week from Monday to Friday; or Tuesday to Saturday or Sunday to Thursday depending upon coverage requirements of the job. The candidate can work with immediate supervisor to change the work schedule on rotational basis depending on the product and project requirements.\nResponsibilities\nManage a team of data engineers and data analysts by delegating project responsibilities and managing their flow of work as well as empowering them to realize their full potential.\nDesign, structure and store data into unified data models and link them together to make the data reusable for downstream products.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nCreate reusable accelerators and solutions to migrate data from legacy data warehouse platforms such as Teradata to Azure Databricks and Azure SQL.\nEnable and accelerate standards-based development prioritizing reuse of code, adopt test-driven development, unit testing and test automation with end-to-end observability of data\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality, performance and cost.\nCollaborate with internal clients (product teams, sector leads, data science teams) and external partners (SI partners/data providers) to drive solutioning and clarify solution requirements.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects to build and support the right domain architecture for each application following well-architected design standards.\nDefine and manage SLAs for data products and processes running in production.\nCreate documentation for learnings and knowledge transfer to internal associates.\nQualifications\n\n12+ years of engineering and data management experience\n\nQualifications\n12+ years of overall technology experience that includes at least 5+ years of hands-on software development, data engineering, and systems architecture.\n8+ years of experience with Data Lakehouse, Data Warehousing, and Data Analytics tools.\n6+ years of experience in SQL optimization and performance tuning on MS SQL Server, Azure SQL or any other popular RDBMS\n6+ years of experience in Python/Pyspark/Scala programming on big data platforms like Databricks\n4+ years in cloud data engineering experience in Azure or AWS.\nFluent with Azure cloud services. Azure Data Engineering certification is a plus.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modelling, data warehousing, and building high-volume ETL/ELT pipelines.\nExperience with data profiling and data quality tools like Great Expectations.\nExperience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one business intelligence tool such as Power BI or Tableau\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like ADO, Github and CI/CD tools for DevOps automation and deployments.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus.\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nBA/BS in Computer Science, Math, Physics, or other technical fields.\nCandidate must be flexible to work an alternative work schedule either on tradition work week from Monday to Friday; or Tuesday to Saturday or Sunday to Thursday depending upon product and project coverage requirements of the job.\nCandidates are expected to be in the office at the assigned location at least 3 days a week and the days at work needs to be coordinated with immediate supervisor\nSkills, Abilities, Knowledge:\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain/exceed individual and team goals.\nAbility to lead others without direct authority in a matrixed environment.\nComfortable working in a hybrid environment with teams consisting of contractors as well as FTEs spread across multiple PepsiCo locations.\nDomain Knowledge in CPG industry with Supply chain/GTM background is preferred.",Industry Type: Beverage,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Pyspark', 'Azure', 'Power BI', 'Github', 'Azure Databricks', 'Tableau', 'ADO', 'Scala programming', 'SQL', 'Azure Data Factory', 'Azure Machine learning', 'Data Lakehouse', 'Azure Data Engineering', 'CI/CD', 'Data Warehousing', 'Data Analytics', 'AWS', 'Python']",2025-06-12 14:10:26
Manager Data Science,Optum,12 - 17 years,Not Disclosed,['Noida'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together. \n\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.\n\n Primary Responsibilities \nDevelop and implement AI and machine learning strategies for several healthcare domains\nCollaborate with cross-functional teams to identify and prioritize AI and machine learning initiatives\nManage the development and deployment of AI and machine learning solutions\nDevelop and run pipelines for data ingress and model output egress\nDevelop and run scripts for ML model inference\nDesign, implement, and maintain CI/CD pipelines for MLOps and DevOps functions\nIdentify technical problems and develop software updates and fixes\nDevelop scripts or tools to automate repetitive tasks\nAutomate the provisioning and configuration of infrastructure resources\nProvide guidance on the best use of specific tools or technologies to achieve desired results\nCreate documentation for infrastructure design and deployment procedures\nUtilize AI/ML frameworks and tools such as MLFlow, TensorFlow, PyTorch, Keras, Scikit-learn, etc.\nLead and manage AI/ML teams and projects from ideation to delivery and evaluation\nApply expertise in various AI/ML techniques, including deep learning, NLP, computer vision, recommender systems, reinforcement learning, and large language models\nCommunicate complex AI/ML concepts and results to technical and non-technical audiences effectively\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\n Required Qualifications: \nBachelors/master degree in computer science, engineering, mathematics, statistics, or a related discipline\n12+ years of experience in Software Engineering, Data Science, or Analytics with 8+ years of experience in AI/ML engineering or related fields\nExperience with cloud platforms and services, such as AWS, Azure, GCP, etc.\nExperience in developing solutions in the NLP space and relevant projects\nHands on Experience in AI and drive the development of innovative AI and machine learning solutions\nDemonstrated experience in leading and managing AI/ML teams and projects, from ideation to delivery and evaluation\nExperience with Azure development environments\nKnowledge of NLP literature, thrust areas, conference venues, and code repositories\nFamiliarity with both open-source and OpenAI LLMs and RAG architecture\nFamiliarity with UI tools like Streamlit, Flask, FAST APIs, Rest APIs, Docker containers\nUnderstanding of common NLP tasks such as text classification, entity recognition, entity extraction, and question answering\nProficient in Python and one of PySpark or Scala. Familiarity with python tools for data processing\nProficiency in multiple machine learning and AI techniques such as supervised, unsupervised, reinforcement learning, deep learning, and NLP\nProficiency in Python, R, or other programming languages for data analysis and AI/ML development\nProficiency in libraries such as Hugging Face and OpenAI API\nProven ability to develop and deploy data pipelines, machine learning models, or applications on cloud platforms (Azure, Databricks, AzureML)\nProven excellent communication, presentation, and interpersonal skills, with the ability to explain complex AI/ML concepts and results to technical and non-technical audiences\nProven solid analytical, problem-solving, and decision-making skills, with the ability to balance innovation and pragmatism\nProeven passion for learning and staying updated with the latest AI/ML trends and research",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'machine learning', 'artificial intelligence', 'r', 'continuous integration', 'data analysis', 'scala', 'scikit-learn', 'presentation skills', 'ci/cd', 'microsoft azure', 'docker', 'tensorflow', 'data science', 'ai techniques', 'devops', 'pytorch', 'keras', 'software engineering', 'aws']",2025-06-12 14:10:28
Sr Data Engineer,Lowes Services India Private limited,5 - 10 years,Not Disclosed,['Bengaluru'],"We are seeking a seasoned Senior Data Engineer to join our Marketing Data Platform team. This role is pivotal in designing, building, and optimizing scalable data pipelines and infrastructure that support our marketing analytics and customer engagement strategies. The ideal candidate will have extensive experience with big data technologies, cloud platforms, and a strong understanding of marketing data dynamics.\n\nData Pipeline Development & Optimization\nDesign, develop, and maintain robust ETL/ELT pipelines using Apache PySpark on GCP services like Dataproc and Cloud Composer.\nEnsure data pipelines are scalable, efficient, and reliable to handle large volumes of marketing data.\nData Warehousing & Modeling\nImplement and manage data warehousing solutions using BigQuery, ensuring optimal performance and cost-efficiency.\nDevelop and maintain data models that support marketing analytics and reporting needs.\nCollaboration & Stakeholder Engagement\nWork closely with marketing analysts, data scientists, and cross-functional teams to understand data requirements and deliver solutions that drive business insights.\nTranslate complex business requirements into technical specifications and data architecture.\nData Quality & Governance\nImplement data quality checks and monitoring to ensure the accuracy and integrity of marketing data.\nAdhere to data governance policies and ensure compliance with data privacy regulations.\nContinuous Improvement & Innovation\nStay abreast of emerging technologies and industry trends in data engineering and marketing analytics.\nPropose and implement improvements to existing data processes and infrastructure\n  Years of Experience\n5 Years in Data Engineer space\n  Education Qualification & Certifications\nB.Tech or MCA\n  Experience\nProven experience with Apache PySpark, GCP (including Dataproc, BigQuery, Cloud Composer), and data pipeline orchestration.\nTechnical Skills\nProficiency in SQL and Python.\nExperience with data modeling, ETL/ELT processes, and data warehousing concepts.",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['orchestration', 'Data modeling', 'data governance', 'Data quality', 'Apache', 'Continuous improvement', 'Monitoring', 'SQL', 'Python', 'Data architecture']",2025-06-12 14:10:30
Azure Cloud Data Engineering Consultant,Optum,7 - 10 years,17-27.5 Lacs P.A.,['Gurugram'],"Primary Responsibilities:\nDesign and develop applications and services running on Azure, with a strong emphasis on Azure Databricks, ensuring optimal performance, scalability, and security.\nBuild and maintain data pipelines using Azure Databricks and other Azure data integration tools.\nWrite, read, and debug Spark, Scala, and Python code to process and analyze large datasets.\nWrite extensive query in SQL and Snowflake\nImplement security and access control measures and regularly audit Azure platform and infrastructure to ensure compliance.\nCreate, understand, and validate design and estimated effort for given module/task, and be able to justify it.\nPossess solid troubleshooting skills and perform troubleshooting of issues in different technologies and environments.\nImplement and adhere to best engineering practices like design, unit testing, functional testing automation, continuous integration, and delivery.\nMaintain code quality by writing clean, maintainable, and testable code.\nMonitor performance and optimize resources to ensure cost-effectiveness and high availability.\nDefine and document best practices and strategies regarding application deployment and infrastructure maintenance.\nProvide technical support and consultation for infrastructure questions.\nHelp develop, manage, and monitor continuous integration and delivery systems.\nTake accountability and ownership of features and teamwork.\nComply with the terms and conditions of the employment contract, company policies and procedures, and any directives.\nRequired Qualifications:\nB.Tech/MCA (Minimum 16 years of formal education)\nOverall 7+ years of experience.\nMinimum of 3 years of experience in Azure (ADF), Databricks and DevOps.\n5 years of experience in writing advanced level SQL.\n2-3 years of experience in writing, reading, and debugging Spark, Scala, and Python code.\n3 or more years of experience in architecting, designing, developing, and implementing cloud solutions on Azure.\nProficiency in programming languages and scripting tools.\nUnderstanding of cloud data storage and database technologies such as SQL and NoSQL.\nProven ability to collaborate with multidisciplinary teams of business analysts, developers, data scientists, and subject-matter experts.\nFamiliarity with DevOps practices and tools, such as continuous integration and continuous deployment (CI/CD) and Teraform.\nProven proactive approach to spotting problems, areas for improvement, and performance bottlenecks.\nProven excellent communication, writing, and presentation skills.\nExperience in interacting with international customers to gather requirements and convert them into solutions using relevant skills.\nPreferred Qualifications:\nKnowledge of AI/ML or LLM (GenAI).\nKnowledge of US Healthcare domain and experience with healthcare data.\nExperience and skills with Snowflake.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Azure Databricks', 'ETL', 'SQL', 'Python', 'Airflow', 'Pyspark', 'Snowflake', 'SCALA', 'Spark', 'Data Bricks']",2025-06-12 14:10:32
R&D Technologist - Clinical Data Management,ZS,5 - 10 years,Not Disclosed,"['Pune', 'Bengaluru']","Our team has deep understanding of EDC tools like Rave, Veeva, InForm, openClinica, clinical data repositories like SAS LSAF, Oracle LSH, eCS elluminate, Metadata Repositories like Nurocor, Sycamore, Formedix, statistical computing environments like Sycamore, Domino, Sas Viya systems, Clinical data review systems, RBQM systems, and more. With experience as solution architects, business analysts, or techno-functional SMEs in GXP compliant validated environments, they guide the creation of solution, data flows and strategies for building clinical development and data management systems. Their offerings encompass technical advisory, consultancy, developing of clinical data platforms and products, system integration, and intelligent automation. Additionally, the team has created innovative tools through advanced technology and data science, aiding numerous clients in expediting the drug development process.",,,,"['Automation', 'SAS', 'Business analysis', 'Pharma', 'Consulting', 'Financial planning', 'Oracle', 'Risk management', 'Analytics', 'Clinical data management']",2025-06-12 14:10:35
Senior Data Engineer,Talentien Global Solutions,4 - 8 years,12-18 Lacs P.A.,"['Hyderabad', 'Chennai', 'Coimbatore']","We are seeking a skilled and motivated Data Engineer to join our dynamic team. The ideal candidate will have experience in designing, developing, and maintaining scalable data pipelines and architectures using Hadoop, PySpark, ETL processes, and Cloud technologies.\n\nResponsibilities:\nDesign, develop, and maintain data pipelines for processing large-scale datasets.\nBuild efficient ETL workflows to transform and integrate data from multiple sources.\nDevelop and optimize Hadoop and PySpark applications for data processing.\nEnsure data quality, governance, and security standards are met across systems.\nImplement and manage Cloud-based data solutions (AWS, Azure, or GCP).\nCollaborate with data scientists and analysts to support business intelligence initiatives.\nTroubleshoot performance issues and optimize query executions in big data environments.\nStay updated with industry trends and advancements in big data and cloud technologies.\nRequired Skills:\nStrong programming skills in Python, Scala, or Java.\nHands-on experience with Hadoop ecosystem (HDFS, Hive, Spark, etc.).\nExpertise in PySpark for distributed data processing.\nProficiency in ETL tools and workflows (SSIS, Apache Nifi, or custom pipelines).\nExperience with Cloud platforms (AWS, Azure, GCP) and their data-related services.\nKnowledge of SQL and NoSQL databases.\nFamiliarity with data warehousing concepts and data modeling techniques.\nStrong analytical and problem-solving skills.\n\nInterested can reach us at +91 7305206696/ saranyadevib@talentien.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Engineering', 'Hadoop', 'Spark', 'ETL', 'Airflow', 'Etl Pipelines', 'Big Data', 'EMR', 'Gcp Cloud', 'Data Bricks', 'Azure Cloud', 'Data Pipeline', 'SCALA', 'Snowflake', 'Data Lake', 'Data Warehousing', 'Data Modeling', 'AWS', 'Python']",2025-06-12 14:10:37
Lead Data Engineer - Azure,Blend360 India,7 - 12 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Sr Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n7+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:10:39
Senior GCP Data Engineer,Swits Digital,6 - 9 years,Not Disclosed,['Bengaluru'],"Job Title: Senior GCP Data Engineer\nLocation: Chennai, Bangalore, Hyderabad\nExperience: 6-9 Years\nJob Summary:\nWe are seeking a GCP Data & Cloud Engineer with strong expertise in Google Cloud Platform services, including BigQuery, Cloud Run, Cloud Storage , and Pub/Sub . The ideal candidate will have deep experience in SQL coding , data pipeline development, and deploying cloud-native solutions.\nKey Responsibilities:\nDesign, implement, and optimize scalable data pipelines and services using GCP\nBuild and manage cloud-native applications deployed via Cloud Run\nDevelop complex and performance-optimized SQL queries for analytics and data transformation\nManage and automate data storage, retrieval, and archival using Cloud Storage\nImplement event-driven architectures using Google Pub/Sub\nWork with large datasets in BigQuery , including ETL/ELT design and query optimization\nEnsure security, monitoring, and compliance of cloud-based systems\nCollaborate with data analysts, engineers, and product teams to deliver end-to-end cloud solutions\nRequired Skills & Experience:\n3+ years of experience working with Google Cloud Platform (GCP)\nStrong proficiency in SQL coding , query tuning, and handling complex data transformations\nHands-on experience with:\nBigQuery\nCloud Run\nCloud Storage\nPub/Sub\nUnderstanding of data pipeline and ETL/ELT workflows in cloud environments\nFamiliarity with containerized services and CI/CD pipelines\nExperience in scripting languages (e.g., Python, Shell) is a plus\nStrong analytical and problem-solving skills",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SUB', 'query optimization', 'GCP', 'Analytical', 'Cloud', 'query', 'cloud storage', 'Security monitoring', 'SQL coding', 'Python']",2025-06-12 14:10:42
"Associate Scientist, Data Sourcing & Solutions",XL India Business Services Pvt. Ltd,1 - 5 years,Not Disclosed,"['Hyderabad', 'Ahmedabad', 'Bengaluru']","Associate Scientist - Data Sourcing & Solutions Gurgaon/Bangalore, India AXA XL recognises data and information as critical business assets, both in terms of managing risk and enabling new business opportunities\n\nThis data should not only be high quality, but also actionable - enabling AXA XLs executive leadership team to maximise benefits and facilitate sustained enterprise advantage\n\nOur Innovation, Data, and Analytics Office (IDA) is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market\n\nAs we develop an enterprise-wide data and digital strategy that moves us toward a greater focus on the use of data and data-driven insights, we are seeking an Associate Scientist for our Data Sourcing & Solutions team\n\nThe role sits across the IDA Department to make sure customer requirements are properly captured and transformed into actionable data specifications\n\nSuccess in the role will require a focus on proactive management of the sourcing and management of data from source through usage\n\nWhat you ll be DOING What will your essential responsibilities include? Accountable for documenting data requirements (Business and Function Requirements) and assessing the reusability of Axiom assets\n\nBuild processes to simplify and expedite data sourcing to focus on delivering data to AXA XL business stakeholders frequently\n\nDevelops and operationalizes strategic data products, and answers and proactively manages the sourcing and management of data from source through usage (reusable Policy and Claim Domain data assets)\n\nData Validation Testing of the data products in partnership with the AXA XL business to ensure the accuracy of the data and validation of the requirements\n\nAssesses all data required as part of the Data Ecosystem to make sure data has a single version of the truth\n\nRespond to ad-hoc data requests to support AXA XLs business\n\nInstill a customer-first attitude, prioritizing service for our business stakeholders above all else\n\nInternalize and execute IDA and company-wide goals to become a data-driven organization\n\nContribute to best practices and standards to make sure there is a consistent and efficient approach to capturing business requirements and translating them into functional, non-functional, and semantic specifications\n\nDevelop a comprehensive understanding of the data and our customers\n\nDrive root cause analysis for identified data deficiencies within reusable data assets delivered via IDA\n\nIdentify solution options to improve the consistency, accuracy, and quality of data when captured at its source\n\nYou will report to the Team Lead - Data Sourcing & Solutions\n\nWhat you will BRING We re looking for someone who has these abilities and skills: Required Skills and Abilities: Experience in a data role (business analyst, data analyst, analytics) preferably in the Insurance industry and within a data division\n\nA minimum of a bachelor s or masters degree (preferred) in a relevant discipline\n\nRobust SQL knowledge and technical ability to query AXA XL data sources to understand our data\n\nExcellent presentation, communication (oral & written), and relationship-building skills, across all levels of management and customer interaction\n\nInsurance experience in data, underwriting, claims, and/or operations, including influencing, collaborating, and leading efforts in complex, disparate, and interrelated teams with competing priorities\n\nPassion for data and experience working within a data-driven organization\n\nWork together internal data with external industry data to deliver holistic answers\n\nWork with unstructured data to unlock information needed by the business to create unique products for the insurance industry\n\nPossesses robust exploratory analysis skills and high intellectual curiosity\n\nDisplays exceptional organizational skills and is detail-oriented\n\nThe robust conceptual thinker who connects dots, and has critical thinking, and analytical skills\n\nDesired Skills and Abilities: Ability to work with team members across the globe and departments\n\nAbility to take ownership, work under pressure, and meet deadlines\n\nBuilds trust and rapport within and across groups\n\nApplies in-depth knowledge of business and specialized areas to solve business problems and understand integration challenges and long-term impact creatively and strategically\n\nAbility to manage data needs of an individual project(s) while being able to understand the broader enterprise data perspective\n\nExpected to recommend innovation and improvement to policies, and procedures, deploying resources, and performing core activities\n\nExperience with SQL Server, Azure Databricks Notebook, Qlikview, PowerBI, and Jira/Confluence a plus",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data validation', 'Claims', 'Underwriting', 'Agile', 'QlikView', 'Business strategy', 'JIRA', 'Analytics', 'SQL', 'Customer interaction']",2025-06-12 14:10:44
Data Scientist,Ltimindtree,8 - 13 years,Not Disclosed,"['Chennai', 'Bengaluru', 'Mumbai (All Areas)']",We are looking for an experienced AI ML Developers experience in data science specializing in machine learning python statistical modelling and big data technologies pyspark sql.\n\nThe ideal candidate will have a strong background in developing and deploying machine learning models optimizing ML pipelines and handling largescale structured and unstructured data to drive business impact.\n\nDeep understanding of supervised and unsupervised learning including regression classification Multiclass classification clustering and NLP Proficiency in statistical analysis AB testing and causal inference techniques Experience with model deployment and MLOps in cloud environments AWS GCP \n\nKey Responsibilities\n\nDevelop and deploy machine learning models and predictive analytics solutions for business impact\nWork with largescale structured and unstructured data to extract insights and build scalable models\nDesign implement and optimize ML pipelines for realtime and batch processing\nCollaborate with engineering product and business stakeholders to translate business problems into data science solutions\nApply statistical modeling AB testing and causal inference techniques to evaluate business performance\nApply machine learning and statistical techniques for audience segmentation helping to identify patterns and optimise business strategies\nDrive research and innovation by staying updated with cuttingedge MLAI advancements and incorporating them into our solutions\nOptimize data science models for performance scalability and interpretability in production environments\nMentor junior data scientists and contribute to best practices in data science and engineering,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Aiml', 'Ab Testing']",2025-06-12 14:10:47
Data Scientist,Devon Software Services,3 - 7 years,12-19 Lacs P.A.,['Bengaluru'],"What you will do\nBuild end-to-end machine learning models to solve business problems in Marketing\nPerform feature engineering and support data engineering to build robust data pipelines on large marketing datasets from different sources\nCollaborate with ML Engineering to build ML Pipelines to Train, Test, Deploy, Serve and Monitor models, Tune Hyperparameters, detect model and data drift and resolve issues\nPresent machine learning models outcomes, and help interpret model predictions to various stakeholders using standard data visualization tools",,,,"['Tensorflow', 'Ai Algorithms', 'Ml Algorithms', 'Machine Learning', 'Python', 'Pytorch', 'Model Development']",2025-06-12 14:10:49
Data Scientist,Ltimindtree,8 - 13 years,19-34 Lacs P.A.,"['Pune', 'Bengaluru', 'Mumbai (All Areas)']",10 years of experience in Data ScienceML domain\nShould have experience in Python and libraries like pandas numpy scikitlearn etc\nHave worked on building ML models and integrating it with application end to end\nHave knowledge on Recommender engines and the ML models running behind it like ALS and LightFM\nHave experience in Azure Machine Learning and Azure Services\nHave experience in deploying models in cloud environment and exposing it as an API\nGood communication and presentation skill\nAbility to deliver ML projects as an individual contributor,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'Ml']",2025-06-12 14:10:51
ML Engineer/Data Scientist,Altimetrik,6 - 8 years,15-30 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Role & responsibilities\nData Scientist /ML engineers : ML Engineer with Python, SQL, Machine Learning, Azure skills(Good to have)",Industry Type: IT Services & Consulting,,,"['Machine Learning', 'Python', 'SQL', 'Data Science', 'Ml', 'azure']",2025-06-12 14:10:54
It Recruiter,IonIdea,0 - 3 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nTalent Sourcing: Utilize various channels such as job boards, social media, LinkedIn, networking events, and internal databases to source and attract high-quality candidates for a variety of technical positions (software developers, systems engineers, data scientists, etc.).\nCandidate Screening: Review resumes, conduct initial phone screenings, and assess candidates technical skills, experience, and cultural fit.\nInterview Coordination: Schedule and facilitate interviews with hiring managers, ensuring a smooth and efficient process for all parties involved.\nCandidate Engagement: Build relationships with both active and passive candidates to maintain a strong pipeline of qualified talent. Keep candidates informed throughout the hiring process.\nOffer Management: Work with HR and hiring managers to present offers, negotiate terms, and ensure a positive candidate experience during the offer process.\n\nQualifications:\nExperience: Fresher-3years\n\nTechnical Knowledge: A solid understanding of IT roles, including knowledge of programming languages, software development frameworks, network infrastructure, cloud technologies, and emerging IT trends.\nRecruitment Tools: Proficient in using Applicant Tracking Systems (ATS), job boards (e.g., LinkedIn, Indeed), and social media platforms for sourcing candidates.\nCommunication Skills: Excellent written and verbal communication skills with the ability to engage with both technical and non-technical stakeholders.",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['IT Recruitment', 'C2H', 'Contract Hiring']",2025-06-12 14:10:56
"Senior Analyst I, BI Solution Design & Transformation",XL India Business Services Pvt. Ltd,4 - 9 years,Not Disclosed,['Gurugram'],"Senior Analyst, BI Solution Design & Transformation Gurgaon/ Bangalore, India AXA XL recognizes data and information as critical business assets, both in terms of managing risk and enabling new business opportunities\n\nThis data should not only be high quality, but also actionable - enabling AXA XL s executive leadership team to maximize benefits and facilitate sustained advantage\n\nOur Chief Data Office also known as our Innovation, Data Intelligence & Analytics team (IDA) is focused on driving innovation through optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market\n\nAs we develop an enterprise-wide data and digital strategy that moves us toward greater focus on the use of data and data-driven insights, we are seeking an Assistant Manager for our Business Intelligence team\n\nThe role will support the team s efforts towards reporting transformation project (especially for Ceded Re business) and handling customer requests/enhancements\n\nThis role requires a person that is a team player, can work well with team members from other disciplines to deliver data in an efficient and strategic manner\n\nWhat you ll be DOING What will your essential responsibilities include: Business Intelligence Management: Oversee and manage Business Intelligence (BI) and Reporting activities, ensuring smooth operations and effective stakeholder engagement\n\nProduct Support and Management: Support and enhance BI and Reporting products, driving improvements that align with organizational goals and stakeholder needs\n\nModel Integration and Optimization: Energize and synergize various Business Intelligence models and reporting frameworks to enhance data insights and reporting effectiveness\n\nStrategic Initiative Support: Collaborate with the IDA team on various strategic initiatives, facilitating the development of BI and Reporting functions and related capabilities as they arise\n\nTalent Development: Foster the growth of BI and Reporting talent across AXA XL by promoting an inclusive and diverse environment that enhances the utilization and value creation of our digital, data, and analytics assets\n\nCustomer-Centric Culture: Instill a customer-first mentality within the team, prioritizing exceptional service and responsiveness to the needs of business stakeholders\n\nTeam Development and Culture Building: Contribute to the enhancement of the Business Intelligence team s tools, skills, and culture, driving positive impacts on team performance and outcomes\n\nYou will report to the Senior Manager, Business Intelligence & Reporting\n\nWhat you will BRING At AXA XL, we view individuals holistically through their People, Business, and Technical Skills\n\nWe re interested in what you bring, how you think, and your potential for growth\n\nWe value diverse backgrounds and perspectives, recognizing that each person contributes uniquely to our teams success\n\nWe value relevant education and experience in a related field\n\nAdditionally, we encourage candidates with diverse educational backgrounds or equivalent experience to apply\n\nHere are some of the key skills important for the role: PEOPLE Skills Customer Centricity: Brings a collaborative spirit, a can-do attitude, and a Customer First mindset, ensuring that stakeholder needs are prioritized\n\nAgility: Ability to communicate effectively within teams, peers, and across global teams, adapting to changing circumstances and stakeholder needs\n\nGrowth Mindset: Passion for digital, data, and AI, demonstrating a commitment to continuous learning and development in a digital and data-driven organization\n\nResilience: Ability to help and guide team members on technical issues, fostering their development so that the team can Self-directedly manage challenges\n\nPerformance Excellence: Relevant years of experience in a data role (analytics or engineering) supporting multiple specialty areas of Data and Analytics, showcasing a excellent track record of high performance\n\nCross-Functional Collaboration: Ability to effectively manage stakeholders and collaborate across various teams to achieve common goals\n\nBUSINESS Skills Ethical Judgment: Understanding of ethical considerations in data management and business practices, ensuring integrity in decision-making\n\nDigital Literacy: Relevant years of end-user experience with BI tools like Power BI, including the Report Builder tool, demonstrating proficiency in utilizing digital tools for data analysis\n\nBusiness & Insurance Acumen: A foundational understanding of general business concepts and principles, with an openness to learning about the insurance or financial services industry, providing a basis for growth in the role\n\nTECHNICAL Skills Data Analytics: Intermediate proficiency in SQL, Advanced Excel, MS Access, and VBA, enabling effective data manipulation and analysis\n\nReporting Tools: Extensive experience in building and managing data models in Power BI, contributing to effective reporting and insights generation\n\nData Visualization: Proficiency in utilizing BI tools to create meaningful visualizations that drive insights and support decision-making",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'MS Access', 'Agile', 'Business strategy', 'data visualization', 'Product support', 'Financial services', 'Reporting tools', 'SQL']",2025-06-12 14:10:58
"Associate Analyst, R Programmer-1",Dynamic Yield,1 - 4 years,Not Disclosed,['Gurugram'],"Our Purpose\nTitle and Summary\nAssociate Analyst, R Programmer-1\nOverview\nThe Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (e.g. Plotly, Highcharts, D3.js) or front-end frameworks (e.g. React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, well-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (e.g. roxygen2)\nfamiliar with version control concepts and tools (e.g. Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Software Product,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:11:00
"Associate Analyst, R Programmer-2",Dynamic Yield,3 - 6 years,Not Disclosed,['Gurugram'],"Our Purpose\nTitle and Summary\nAssociate Analyst, R Programmer-2\nOverview\nThe Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (e.g. Plotly, Highcharts, D3.js) or front-end frameworks (e.g. React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, well-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (e.g. roxygen2)\nfamiliar with version control concepts and tools (e.g. Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:11:02
Data Scientist,Acesoft,6 - 9 years,18-20 Lacs P.A.,['Bengaluru'],"Hi all,\nWe are hiring for the role Data Scientist AI ML\nExperience: 6 -9 Years\nLocation: Bangalore\nNotice Period: Immediate - 15 Days\nSkills:\nWe are looking for a Data Scientist to lead data-driven solutions across our business, from exploratory analysis, incremental hypothesis validation, model development, deployment and monitoring.\nSkills Needed:\nStrong knowledge of Applied AI ML & Deep Learning Data Science techniques, Hardcore in ANN /Deep Learning /Machine Learning/NLP\nDeep knowledge about machine learning algorithms such as tree-based methods, clustering, regression and classification, dimension reduction techniques, linear regression, Logistic regression, k-means, time series forecasting, Hypothesis testing (ANOVA, t-test, etc.), random forest, SVMs, Naive Bayes, gradient boosting, kNN, Deep learning algorithms like CNN, ANN and Reinforcement learning, Anomaly detection.\nIn-depth understanding of Statistical concepts e.g. Probability distributions, statistical tests, correlation analysis, descriptive statistics, kernels, ROC, F1-Score etc.\nAdvanced coding experience in at least one programming language (Python, Pyspark) & Strong experience in object-oriented concepts.\nGood to have advanced experience in one or more of the following: Spark, Databricks, Azure technical stack\nGood to have experience in model deployment to cloud/on-prem.\nGood Communication & presentation skills.\n\nIf you are interested drop your resume at mojesh.p@acesoftlabs.com\nCall: 9701971793",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Temporary/Contractual","['AI ML', 'Data Scientist', 'Machine Learning', 'Deep Learning', 'ANN', 'EDA', 'ANOVA', 'Hypothesis Testing', 'Model Building']",2025-06-12 14:11:04
Senior Research Analyst,Demandbase,8 - 10 years,Not Disclosed,['Hyderabad'],"Introduction to Demandbase:\nDemandbase is the Smarter GTM company for B2B brands. We help marketing and sales teams overcome the disruptive data and technology fragmentation that inhibits insight and forces them to spam their prospects. We do this by injecting Account Intelligence into every step of the buyer journey, wherever our clients interact with customers, and by helping them orchestrate every action across systems and channels - through advertising, account-based experience, and sales motions. The result? You spot opportunities earlier, engage with them more intelligently, and close deals faster.\nAs a company, we re as committed to growing careers as we are to building world-class technology. We invest heavily in people, our culture, and the community around us. We have offices in the San Francisco Bay Area, New York, Seattle, and teams in the UK and India . We have also been continuously recognized as one of the best places to work in the San Francisco Bay Area.\nWere committed to attracting, developing, retaining, and promoting a diverse workforce. By ensuring that every Demandbase employee is able to bring a diversity of talents to work, were increasingly capable of living out our mission to transform how B2B goes to market. We encourage people from historically underrepresented backgrounds and all walks of life to apply. Come grow with us at Demandbase!\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented Senior Research Analyst to join our dynamic team. This role is crucial for driving informed business decisions through data gathering, analysis, and insightful reporting. The ideal candidate will possess a strong understanding of business research methodologies, data analysis techniques, and a passion for data accuracy and problem-solving.\nKey Responsibilities:\nLead Comprehensive Data Research and Analysis: Source, collect, research, and analyze data from a variety of business information sources and specialized databases to generate actionable insights.\nDrive Data-Driven Decision-Making: Conduct in-depth strategic analysis to identify trends, anomalies, and root causes, translating complex findings into clear, impactful recommendations for product and business growth.\nEnsure Data Quality and Integrity: Apply strong problem-solving skills to resolve data queries, perform rigorous quality checks, and proactively identify and address data coverage gaps.\nProvide Training and Knowledge Transfer: Mentor and train new team members on industry best practices and advanced data analysis techniques.\nLeverage Domain and Product Expertise: Work closely with data engineers, product teams, and business stakeholders to define and deliver technical roadmaps, ensuring sound solutions and maximizing customer value.\nRequired Skills & Experience:\nBachelor s or Master s degree in Business or Commerce\n8-10 years of relevant work experience\nExpertise in sourcing and extracting data from diverse business information sources\nAdvanced proficiency in Microsoft Excel (e.g., pivot tables, VLOOKUP, complex formulas, data validation, charting) for data manipulation, analysis, and reporting\nSkill in translating complex data into visually compelling narratives for various audiences\nAbility to design and create clear, insightful, and actionable dashboards and reports\nExcellent communication and interpersonal skills\nSelf-organized and self-driven, with strong personal integrity\nStrong understanding and application of data quality principles and best practices\nAbility to perform root cause analysis on large datasets and identify underlying business drivers\nProven ability to train and mentor new team members, sharing best practices and advanced techniques and strong knowledge transfer skills.\nA strong passion for data, continuous learning, and staying updated with industry best practices and emerging analytical techniques.\nStrong organizational and time management skills\nAbility to work independently, manage multiple priorities, and meet deadlines in a fast-paced environment.\nOur Commitment to Diversity, Equity, and Inclusion at Demandbase\nAt Demandbase, we believe in creating a workplace culture that values and celebrates diversity in all its forms. We recognize that everyone brings unique experiences, perspectives, and identities to the table, and we are committed to building a community where everyone feels valued, respected, and supported. Discrimination of any kind is not tolerated, and we strive to ensure that every individual has an equal opportunity to succeed and grow, regardless of their gender identity, sexual orientation, disability, race, ethnicity, background, marital status, genetic information, education level, veteran status, national origin, or any other protected status. We do not automatically disqualify applicants with criminal records and will consider each applicant on a case-by-case basis.\nWe recognize that not all candidates will have every skill or qualification listed in this job description. If you feel you have the level of experience to be successful in the role, we encourage you to apply!\nWe acknowledge that true diversity and inclusion require ongoing effort, and we are committed to doing the work required to make our workplace a safe and equitable space for all. Join us in building a community where we can learn from each other, celebrate our differences, and work together.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAN', 'Data analysis', 'Data validation', 'Excel', 'Data research', 'Business research', 'VLOOKUP', 'Analytical', 'Data quality', 'Senior Research Analyst']",2025-06-12 14:11:06
Data Scientist,Ltimindtree,6 - 11 years,Not Disclosed,['Bengaluru'],"F2F Weekend Drive - Bangalore- 14th June - DS Gen AI\n\nJob description\n\nWe are having a F2F weekend drive for the requirement of a Data Scientist + Gen AI at our LTIM Bangalore Whitefield office.\nDate - 14th June 2025\nExperience - 6+ Years\nMandatory Skills - Data Science, Gen AI, Python, RAG and Azure/AWS, AI/ML, NLPt\n\nLocation - LTIMindtree Bangalore Whitefield Office\n\nSecondary - (Any) Machine Learning, Deep Learning, ChatGPT, Langchain, Prompt, vector stores, RAG, llama, Computer vision, Deep learning, Machine learning, OCR, Transformer, regression, forecasting, classification, hyper parameter tunning, MLOps, Inference, Model training, Model Deployment\nGeneric JD-\nMore than 6 years of experience in Data Engineering, Data Science and AI / ML domain\nExcellent understanding of machine learning techniques and algorithms, such as GPTs, CNN, RNN, k-NN, Naive Bayes, SVM, Decision Forests, etc.\nExperience using business intelligence tools (e.g. Tableau, PowerBI) and data frameworks (e.g. Hadoop)\nExperience in Cloud native skills.\nKnowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset\nAnalytical mind and business acumen and Strong math skills (e.g. statistics, algebra)\nExperience with common data science toolkits, such as TensorFlow, KERAs, PyTorch, PANDAs, Microsoft CNTK, NumPy etc. Deep expertise in at least one of these is highly desirable.\nExperience with NLP, NLG and Large Language Models like BERT, LLaMa, LaMDA, GPT, BLOOM, PaLM, DALL-E, etc.\nGreat communication and presentation skills. Should have experience in working in a fast-paced team culture.\nExperience with AIML and Big Data technologies like AWS SageMaker, Azure Cognitive Services, Google Colab, Jupyter Notebook, Hadoop, PySpark, HIVE, AWS EMR etc.\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase, Vector databases\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression, etc.\nShould be a data-oriented person with analytical mind and business acumen.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-12 14:11:08
Data Scientist,Puresoftware Technology,8 - 13 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Title: Data Scientist(5 Positions)/ Lead OR Manager -Data Scientist (3 positions)\n\nExperience: Data scientist (8-10 years) / Lead Data scientist(14+ years)\n\nJob Location: Whitefield, Bangalore\nMode of working: Hybrid\n\nInterview Process: First Round: L1-Internal interview\nSecond Round: Assessment shared by us needs to be completed in 48 hours\nThird Round: Client discussion over the submitted assessment.\nFinal Round: HR Discussion\n\nPreferred Domain: Healthcare Insurance/ Insurance agencies / Health Insurance / Any Insurance\n\nWe are looking for a talented Data Scientist to join our growing team. In this role, you will lead efforts to develop, enhance, and optimize advanced AI and machine learning models with a particular focus on Generative AI, Large Language Models (LLMs), Langchain, and Prompt Engineering. You will oversee the application of statistical modeling techniques to derive insights, build models, and lead research initiatives that push the boundaries of AI technologies.\n\nKey Responsibilities:\nLeadership & Collaboration: Lead a team of data scientists, researchers, and engineers working on high-impact projects related to generative models, NLP, and statistical modeling. Collaborate with cross-functional teams, including engineering, product management, and research, to deliver AI-powered products and solutions.\nGenerative AI Development: Spearhead the development and deployment of Generative AI models and algorithms to address complex problems in areas like content generation, conversational AI, and creative automation.\nLLM Implementation & Optimization: Develop, fine-tune, and optimize large language models (LLMs) for diverse applications, ensuring they are robust, scalable, and accurate in real-world scenarios.\nLangchain Integration: Design and integrate Langchain for managing and deploying sophisticated language models with a focus on complex workflows, multi-agent systems, and real-time applications.\nPrompt Engineering: Lead prompt engineering efforts to optimize AI models' output quality, improve interactions, and enable more effective natural language understanding across a variety of use cases.\nStatistical Modeling: Utilize advanced statistical techniques to analyze and interpret data, build predictive models, and solve business-critical challenges through data-driven insights.\nResearch & Innovation: Stay ahead of trends in AI and ML, particularly in the fields of NLP, LLMs, and generative models. Drive innovation by exploring cutting-edge techniques and methodologies in the AI space.\nMentorship & Knowledge Sharing: Mentor junior team members and promote a collaborative, learning-oriented environment. Share knowledge and foster an atmosphere of continuous improvement within the data science team.\nPerformance Optimization: Ensure model performance meets or exceeds company and client expectations by identifying areas of improvement, testing new methods, and scaling the systems accordingly.\nEthical AI Development: Advocate for and implement ethical considerations in the development and deployment of AI models, including fairness, transparency, and privacy.\n\nQualifications:\nRequired:\nEducation: Ph.D. or Masters degree in Computer Science, Data Science, Mathematics, Statistics, or related field, or equivalent practical experience.\nExperience:\n8+ years of experience in data science, with at least 2-3 years in a leadership role.\nProven expertise in Generative AI, particularly in areas like content generation, deep learning, and language modeling.\nStrong background in Large Language Models (LLMs) such as GPT, T5, BERT, or similar architectures.\nHands-on experience with Langchain for building NLP workflows, pipelines, and integrating external systems with LLMs.\nHands-on experience of Prompt Engineering, including techniques to refine and optimize outputs for various NLP tasks.\nExpertise in statistical modeling and quantitative analysis, with the ability to apply techniques to solve real-world problems.\n\nPreferred:\nExperience working with transformer models and fine-tuning LLMs for specific tasks.\nExpertise in AI model evaluation and metrics (e.g., BLEU, ROUGE, perplexity).\nBackground in developing AI-driven products from concept to deployment.\nStrong publication record in AI research, particularly in NLP and machine learning.\n\nUsed cases( Any of them)\nAutomated Underwriting.\nCustomer experience enhancement.\nFraud detection.\nPredictive analytics.\nAccelerated claims processing.\nRisk assessment and premium calculation.\nCustomer profiling.\ncustomer segmentation.\nCredit Risk Assessment.\nPersonalised marketing .\nAnti-Money Laundering (AML).\nPersonalized patient care.\nMedical training and simulations.\nMedical Data Analysis.\n\nPlease share your updated resume at renuka.rathi@puresoftware.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'data scientist', 'statistical modelling', 'Predictive Modeling', 'Customer profiling', 'Healthcare Insurance', 'Customer Segmentation', 'Automated Underwriting', 'Insurance Domain', 'Credit Risk Assessment', 'insurance agency', 'Fraud detection', 'Healthcare Domain']",2025-06-12 14:11:11
Data Scientist - Immediate Joiners Only,Reyika,5 - 10 years,Not Disclosed,"['Pune', 'Gurugram', 'Bengaluru']","Role: Data Scientist\nExperience: 5+ years\nLocation: Any - Hybrid (Bangalore, Hyderabad, Pune, Chennai and Gurgaon)\nJob Summary:\nWe're seeking a highly skilled NLP Engineer with expertise in Large Language Models (LLMs) and text summarization to join our team. The ideal candidate will have hands-on experience with Amazon Bedrock, OpenAI, or Hugging Face transformers and a strong background in Python programming. This role involves working with unstructured audio-to-text data, such as call transcripts, and developing innovative solutions using LLMs.\n\nRequirements:\nStrong expertise in NLP, text summarization, semantic search, and LLM APIs.\nPractical experience with Amazon Bedrock, OpenAI, or Hugging Face transformers.\nFamiliar with prompt tuning and few-shot learning.\nPython (pandas, langchain, boto3, NumPy, etc.)\nExperience working with unstructured audio-to-text data (e.g., call transcripts).\n\nKey Responsibilities:\nDesign and Development: Design, develop, and deploy LLM-based solutions for text summarization, semantic search, and other NLP tasks\nLLM APIs: Integrate LLM APIs from Amazon Bedrock, OpenAI, or Hugging Face transformers into existing applications\nPrompt Tuning and Few-Shot Learning: Implement prompt tuning and few-shot learning techniques to improve LLM performance\nUnstructured Audio-to-Text Data: Work with unstructured audio-to-text data, such as call transcripts, to develop accurate and efficient NLP models\nPython Programming: Utilize Python libraries like pandas, LangChain, boto3, and NumPy for data processing and model development.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Large Language Model', 'Natural Language Processing', 'Python']",2025-06-12 14:11:13
Senior Programmer Analyst,Tira Consulting,3 - 5 years,12-15 Lacs P.A.,['Gurugram'],"Role & responsibilities\n• Proficiency in designing and constructing SQL procedures.\n• Advanced knowledge of SQL queries and scripts for data validation.\n• Experience working with Scrum and agile methodologies.\n• Ability to collaborate effectively in a team with members from various backgrounds.\n• Hands-on experience in deploying code frequently across multiple environments.\n• Expertise in developing cloud-native applications using serverless and/or containerized technologies.\n• Capability to work independently with minimal supervision in a fast-paced environment with shifting priorities and tight deadlines. Additionally, the candidate should be able to lead small-scale projects with a team of 3-4 developers.\n• Strong communication skills to interact with stakeholders at different levels in application delivery, QA, and business departments.\n• Proficiency in creating new tables, views, and accessing stored procedures in SQL Server.\n• Continuous awareness of key business systems and upcoming developments.\n• Ability to quickly analyze issues, identify bug trends, log defects accurately, escalate issues, and provide precise management reports.\n• Deliver tasks according to agreed schedules and quality standards.\n• Collaboration with Business Analysts to grasp requirements and implement solutions accordingly.\n• Working closely with the development team, architects, and leads.\n• Willingness to experiment, evaluate, and adopt new technologies.\n• Hands-on experience in unit testing and data analysis.\n• Good understanding of multiple software development methodologies such as Waterfall and Agile.\n\nEssential Skills\nExcellent experience in MS SQL Server and ETL tools.\nUnderstanding of Snaplogic will be preferable.\nMust understand Cloud development (AWS/Azure).\nGood exposure on PowerShell\nExperience in CI/CD, TDD, DevOps, CI/CD tools - Jenkins/SonarQube\nGood Understanding of RDBMS and Data Warehousing concepts.\nProficiency in SQL and SQL programming using Oracle & MSSQL Server\nMust have SQL Tuning experience.\nExperience of Source Control Tools like Subversion/SVN\nWilling to learn and adapt to new opportunities and challenges",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Database Warehouse', 'Azure Cloud', 'Oracle Database', 'Ci/Cd', 'ETL Tool', 'Jenkins', 'Aws Cloud', 'Snaplogic', 'SQL Database', 'SVN', 'Sonarqube', 'Devops']",2025-06-12 14:11:15
Senior Analyst - IO - Investment Reporting Services,M&G plc,2 - 5 years,Not Disclosed,['Mumbai'],"We are M&G Global Services Private Limited (formerly known as 10FA India Private Limited, and prior to that Prudential Global Services Private Limited) . We are a fully owned subsidiary of the M&G plc group of companies, operating as a Global Capability Centre providing a range of value adding services to the Group since 2003. At M&G our purpose is to give everyone real confidence to put their money to work. As an international savings and investments business with roots stretching back more than 170 years, we offer a range of financial products and services through Asset Management, Life and Wealth. All three operating segments work together to deliver attractive financial outcomes for our clients, and superior shareholder returns.\nSupport Sales channels in providing accurate and efficient fund data to clients\nCarrying out appropriate levels of data quality assurance / validation\nEnsuring Daily, Weekly, Monthly and Quarterly reports are distributed to the Client and Custodians.\nExtracting and producing Performance reports using Power BI\nPreparation for distribution of client data files under direction of UK Institutional Client Service team\nInvestigation into issues identified with accuracy of externally presented data\nProvision of data to the relevant team for database maintenance\nSupport Investment Teams with data analysis and data report production\nEnsure own work is completed to a high level of accuracy within service level agreements, to achieve regulatory targets\nMaintain and implement personal development plan in partnership with immediate manager\nIdentify, facilitate and implement process improvement ideas to improve efficiency\nKeep own knowledge up to date in relation to client servicing and data management\nTo demonstrate a positive risk, compliance and control culture through the identification, assessment, monitoring and management of risks and issues within the business area, alongside ensuring timely and appropriate resolution of control weaknesses, actions and failures that arise\nTo achieve and maintain required level of competency as per the training and competency framework.\nWe have a diverse workforce and an inclusive culture at M&G Global Services, regardless of gender, ethnicity, age, sexual orientation, nationality, disability or long term condition, we are looking to attract, promote and retain exceptional people. We also welcome those who take part in military service and those returning from career breaks.",Industry Type: Banking,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Business transformation', 'Data management', 'Process improvement', 'Actuarial', 'Customer service', 'Asset management', 'Monitoring', 'Auditing']",2025-06-12 14:11:18
Senior Analyst - Survey Programming (Healthcare),Omnicom Media Group,3 - 6 years,Not Disclosed,['Gurugram'],"Overview\nShift time - 06:30 PM - 03:30 AM (IST)\nLocation - Gurugram / Mumbai\nHybrid Mode - 3 Days work from office / week\nSkills - Survey programming + Confirmit (survey scripting tools ) + healthcare domain\n About Role - \nThis role requires you to be an active team player for multiple clients and OMC agencies, being responsible for quality delivery of research templates, objectives, and overall solutions. You will get an opportunity to demonstrate your skills and inspire various stakeholders to realize the goals and visions of the Market Research function at Annalect India. \nAbout Us - \nOmnicom Global Solutions is an integral part of Omnicom Group, a leading global marketing and corporate communications company. Omnicom’s branded networks and numerous specialty firms provide advertising, strategic media planning and buying, digital and interactive marketing, direct and promotional marketing, public relations, and other specialty communications services to over 5,000 clients in more than 70 countries.\n Omnicom Global Solutions India plays a key role for our group companies and global agencies by providing stellar products, solutions, and services in the areas of Creative Services, Technology, Marketing Science (Data & Analytics), Advanced Analytics, Market Research, Business Support Services, Media Services, and Project Management.\n We currently have 4000+ awesome colleagues in Omnicom Global Solutions India who are committed to solving our clients’ pressing business issues. We are growing rapidly and looking for talented professionals like you to be part of this journey.\n Let us build this, together!\nResponsibilities\nUnderstand the requirements of projects, design and formulate the questionnaire programming, sampling, and data layouts\nWork with Data Ops teams and project managers to understand and align on post survey analysis objectives\nRecommend a solution design and template suite of survey programming\nCoordinate with field teams\nIntegrate graphics, logos and relevant creatives, banners, or other multimedia assets with the survey\n User testing, quality assurance of functionalities, click through options, radio buttons and other UI features of survey landing pages\nSupport the team in various tasks like ongoing development, Proof of Concept, and troubleshooting the issues faced with maintenance projects \n You will be working closely with\nGlobal clients with a strong presence in Market Research space\nQualifications\n4-6 years’ experience in Market Research Operations in healthcare domain\nExpertise in one or more prominent survey scripting tools like, Confirmit, Qualtrics, Dimensions, Decipher, Askia, CMix\nExperience of working with international clients in multi-cultural environment\nDrive and flexibility to adapt to new platforms\nAbility to exhibit reliable independent decision making\nAbility to receive and act on constructive feedback provided by supervisors\nAbility to work in and adapt to a high-paced environment",Industry Type: Film / Music / Entertainment,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['providing', 'css', 'spss', 'manual testing', 'healthcare domain', 'market research', 'tools', 'research', 'jquery', 'healthcare', 'radio', 'sql', 'scripting', 'operations', 'java', 'survey design', 'html', 'advanced analytics', 'python', 'data analysis', 'software testing', 'javascript', 'excel', 'marketing', 'tableau', 'survey', 'confirmit', 'decipher']",2025-06-12 14:11:20
Big Data Developer/Data Engineer,Grid Dynamics,5 - 10 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\nExperience: 5 - 8 years\nEmployment Type: Full-Time\n\nJob Summary:\nWe are looking for a highly skilled Scala and Spark Developer to join our data engineering team. The ideal candidate will have strong experience in building scalable data processing solutions using Apache Spark and writing robust, high-performance applications in Scala. You will work closely with data scientists, data analysts, and product teams to design, develop, and optimize large-scale data pipelines and ETL workflows.\n\nKey Responsibilities:\nDevelop and maintain scalable data processing pipelines using Apache Spark and Scala.\nWork on batch and real-time data processing using Spark (RDD/DataFrame/Dataset).\nWrite efficient and maintainable code following best practices and coding standards.\nCollaborate with cross-functional teams to understand data requirements and implement solutions.\nOptimize performance of Spark jobs and troubleshoot data-related issues.\nIntegrate data from multiple sources and ensure data quality and consistency.\nParticipate in design reviews, code reviews, and provide technical leadership when needed.\nContribute to data modeling, schema design, and architecture discussions.\nRequired Skills:\nStrong programming skills in Scala.\nExpertise in Apache Spark (Core, SQL, Streaming).\nHands-on experience with distributed computing and large-scale data processing.\nExperience with data formats like Parquet, Avro, ORC, and JSON.\nGood understanding of functional programming concepts.\nFamiliarity with data ingestion tools (Kafka, Flume, Sqoop, etc.).\nExperience working with Hadoop ecosystem (HDFS, Hive, YARN, etc.) is a plus.\nStrong SQL skills and experience working with relational and NoSQL databases.\nExperience with version control tools like Git.\nPreferred Qualifications:\nBachelor's or Masters degree in Computer Science, Engineering, or related field.\nExperience with cloud platforms like AWS, Azure, or GCP (especially EMR, Databricks, etc.).\nKnowledge of containerization (Docker, Kubernetes) is a plus.\nFamiliarity with CI/CD tools and DevOps practices.ndidate profile",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Scala', 'Pyspark', 'Spark']",2025-06-12 14:11:22
Senior Analyst - SAP QM,Solenis,3 - 6 years,Not Disclosed,['Hyderabad'],"Solenis is a leading global provider of water and hygiene solutions. The company s product portfolio includes a broad array of water treatment chemistries, process aids, functional additives, cleaners, disinfectants, and state-of-the-art monitoring, control and delivery systems. These technologies are used by customers to improve operational efficiencies, enhance product quality, protect plant assets, minimize environmental impact, and create cleaner and safer environments. Headquartered in Wilmington, Delaware, the company has 70 manufacturing facilities strategically located around the globe and employs a team of over 16, 500 professionals in 130 countries across six continents. Solenis is a 2025 Best Managed Company Gold Standard honoree. For more information about Solenis, please visit www. solenis. com .",,,,"['Data analysis', 'Analytical', 'Biochemistry', 'Project planning', 'Maintenance Manager', 'Customer service', 'Operations', 'Analytics', 'Monitoring', 'Business operations']",2025-06-12 14:11:25
Data Scientist,Grid Dynamics,10 - 20 years,Not Disclosed,['Hyderabad'],"Role & responsibilitiMes\n\nCandiate needs to be 8+ Years of Experience\n\nDetails on tech stack\nPython\nPrompt engineering\nBest practices for prompt engineering\nHow LLM can be used in applications for a variety of tasks\nNLP\nUnderstanding of typical NLP problems: classification, NER, summarization, question answering, sentiment analysis, etc.\nTheoretical intuitive understanding of how Transformers work (tokenization, attention, etc).\nWord and sentence embeddings\nVector search\nVector databases, performance tuning\nDocument chunking techniques\nLLM applications development\nLangChain, LlamaIndex\nChain of Thoughts, DSP, and other techniques\nAgents and tools\nGoogle cloud (GCP)\nNice to have requirements to the candidate\nPreferable, the engineers are expected to have IT services/consulting experience.\nProficient in developing LLM-powered systems using advanced prompt engineering techniques, RAG and agentic design patterns. Experienced with frameworks like LangChain, LlamaIndex, and DSPy.\nFamiliar with evaluation approaches and metrics for different types of LLM-based systems.\nExperienced with keyword and vector search methods, including understanding of their underlying algorithms. Familiar with popular vector search engines.\nCompetent in various document understanding models and techniques to parse complex documents and implement effective chunking strategies for RAG systems.\nFamiliar with LLM and embedding models fine-tuning techniques.\nCompetent in using joint vision-language and generative models to solve various problems related to image generation, visual question answering, and multi-modal search. Familiar with diffusion models and associated techniques like LoRA, Dreambooth, and ControlNet.\nUnderstanding of the challenges and risks associated with the development of Generative AI systems and how to mitigate them.\nFamiliar with various architecture design patterns for different types of LLM-based applications such as chatbots, text2sql, document understanding, etc. Familiar with various approaches to scalability and cost reduction in Generative AI systems.\nAbility to stay updated with the latest advancements in Generative AI and integrate emerging technologies to drive innovation and improve the performance of AI systems.\nFamiliar with Responsible AI principles and Human-AI interaction design best practices.\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Lora', 'Natural Language Processing', 'Deep Learning', 'Python']",2025-06-12 14:11:26
Hiring Fresher - Back office - MS Excel - Night shift -Mumbai,Trigent Software,0 years,1-2 Lacs P.A.,['Mumbai'],"Hi,\n\nGreetings from Trigent!!!\n\nHiring for fresher with good excel knowledge.\nJob Summary:\nWe are seeking a detail-oriented and analytical professional with strong communication skills and expertise in Microsoft Excel. The ideal candidate will be responsible for handling data analysis, generating reports, and effectively communicating insights.\nKey Responsibilities:\nWork with large data sets to clean, analyze, and present insights.\nPrepare and maintain reports using Excel (pivot tables, VLOOKUP, charts, etc.).\nCommunicate findings effectively with stakeholders.\nCollaborate with teams to optimize processes and improve efficiency.\nAdhere to rotational evening shift schedules as required.\nRequired Skills & Qualifications:\nProficiency in Microsoft Excel (advanced formulas, pivot tables, data visualization).\nStrong verbal and written communication skills.\nAnalytical mindset with attention to detail.\nAbility to work independently and as part of a team.\n\nWork location: Airoli\nOnly Immediate joiners are preferred.\nBoth pick & drop cab facility is provided.\nOnly graduates can apply (Bcom/ BBA/ BBI, BMS, BA).",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['ms excel', 'VLOOKUP', 'MIS Reporting']",2025-06-12 14:11:28
Document Controller,Larsen & Toubro (L&T),0 - 2 years,3.5-4 Lacs P.A.,['Vadodara'],"Technical Expertise\nProficient in Document Management Systems and Engineering Data Warehouses.\nKnowledge of Document Numbering, Receipt Formatting, Filing Structure, and Registration.\nUnderstanding of Tagging Specification and Philosophy.\nExpertise in Document Distribution, including distribution matrices, electronic/hard copies, and transmittals.\nSkilled in Revision Management, Comment Handling, and Status Reporting.\nExperience in Correspondence, Technical Queries, Action Tracking, and Data Management.\nEngineering & Data Interpretation\nAbility to interpret engineering drawings such as P&IDs, PEFS, and PFDs.\nProficient in technical data extraction from:\nMachine drawings\nPEFS (Process Engineering Flow Scheme)\nSeal gas, lube oil, and instrument P&IDs\nVibration & temperature P&IDs\nAlarm/trip matrices, performance curves, and data sheets.\nExperience in Building Asset Registers and Equipment Record Cards.\nComprehensive knowledge of plant equipment and systems.\nIndustry Experience & Technical Tools\nExtensive experience in the Oil & Gas (O&G) industry.\nStrong interpersonal skills for effective communication and collaboration.\nProficient in MS Access and Advanced Excel for data analysis and reporting.",Industry Type: Engineering & Construction,Department: Project & Program Management,"Employment Type: Full Time, Temporary/Contractual","['Document Control', 'Document controller', 'Document Management System', 'Data Control', 'EDMS', 'Aconex', 'Dms', 'Document Management']",2025-06-12 14:11:30
Analyst Programmer,Fidelity International,2 - 4 years,Not Disclosed,"['Gurugram', 'Bengaluru']","We re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our Non-Financial Risk Policy team and feel like you re part of something bigger.\nDepartment Description:\nAMO (ISS) production support consists of applications like Global Fund Data Repository (GFDR), Product hub, Performance Hub, Product (FRD), Reference Data Service, Transaction Service, Position Service, Frontier, Fund Distribution Service etc. architecture and engineering services that comprises of various Fidelity s Business Units in the UK and other parts of Europe, Asia and is a strategic area targeted for growth over the coming years. Various key systems have been acting as the key enablers for the business in achieving their goals. The Enterprise portfolio of projects will include a large collection of strategic initiatives as well as tactical ones to support day-to-day operations and strengthen the environment. The support team aims at supporting & maintaining global data warehouse acting as the single source of data for various line of business s to help them in the MI reporting requirements and data analysis. This source of data is considered as the golden source for distribution data and helps various business groups across organization to take knowledge based decisions.\nPurpose of the Role:\nThe position is for an Application Programmer in AMO production Support team. The role involves supporting key AMO - Enterprise applications and data marts involving strong PL/SQL and stored procedure knowledge on Oracle database platform. The candidate should have high expertise and core skills of Informatica and UNIX shell script. In addition, hands-on experience with Control-M technologies would be a plus. The successful candidate will be responsible to support for consumption of downstream feeds and applications in varied technologies. This would also involve intensive interaction with the business and other systems groups, so good communications skills and the ability to work under pressure are absolute must.\nKey Responsibilities:\nThe candidate is expected to display professional ethics in his/her approach to work and exhibit a high level ownership within a demanding working environment.\nProviding first line of technical support for business critical applications (Principal technologies / applications used include Oracle, UNIX , PaaS, Python, Java and Control-M).\nWork in the support team alongside data analysts, business analysts, database administrators and business project teams in enhancing and supporting the production services.\nHelp maintain Control-M schedules.\nConduct analysis and do bug fixes for production incidents. Carry out technical enhancements as desired.\nCarry out daily health-check activities involving application checks, system checks, and database checks and related on production systems / servers.\nThe scope of responsibility also covers monitoring business critical batch workloads, real-time / interactive processing, data transfer services, application on-boarding and upgrades, and recovery procedures.\nReport root cause of the incidents and present ideas on how to prevent the incidents from occurring in future.\nEnsure adherence to incident and change management processes. Regular engagement with Business & Systems Teams looking to adopt and apply the best practice of Service Support.\nPrepares and maintains documentation related application support like SOM, Service Card, Support Rota, Knowledge base, etc.\nDemonstrates continuous effort to improve operations, decrease turnaround times, streamline work processes, and work cooperatively and jointly to provide quality seamless customer service.\nResponsible for servicing 24x7 support as per support rosters.\nFlexibility to work in shifts ( on-demand & short-term basis), and/or on weekends.\nExperience and Qualifications Required:\nAround 2 - 4 years of technical experience in Software / IT industry in Development and Support functions\nMinimum 2 - 4 years of support experience in Production Support roles\nEssential Technical skills:\nAt least 2-4 years of Oracle experience with strong focus on SQL. PL/SQL knowledge is good to have.\nBasic understanding of PaaS technology, Python, Core Java and web services/ REST API.\nShould have core skills of UNIX shell script.\nEssential behavioural/operational skills:\nAbility to apply new skills / additional information acquired in relation to role.\nAbility to interact with end users/business users.\nAbility to work closely with cross functional teams including Infrastructure teams/Architects/Business Analysts.\nAbility to prioritise own activities, work under hard deadlines.\nTeam player with commitment to achieve team goals.\nMotivated, flexible and with a can do approach.\nKeen to learn and develop proficiency\nGood communication skills both verbal and written.\nDelivery and results focused.\nGood to have technical skills:\nHands-on experience with scheduling tools - Control-M would be a definite plus.\nExperience in informatica is good to have.\nExperience of any source control tool - SVN would be a plus.\nGood Operating Systems knowledge and associated commands (UNIX [Linux/AIX], MS Windows).\nFamiliarity in Data Warehouse, Datamart and ODS concepts.\nKnowledge of essential Software Engineering principles.\nKnowledge of ITIL practices.\nFeel rewarded",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Unix', 'Aix', 'Core Java', 'Linux', 'Production support', 'PLSQL', 'Informatica', 'Oracle', 'Technical support', 'Python']",2025-06-12 14:11:33
Hiring MBA/PGDM graduates For Retail Operations,MALABAR GOLD & DIAMONDS,0 - 5 years,3.75-4.75 Lacs P.A.,"['Ernakulam', 'Kannur', 'Malappuram']","Contact HR:- Anjitha CM\nSenior HR Executive\n8714506916\nMALABAR GROUP HEAD QUARTERS\n\nJob Description\nTo effectively manage the sales, operations, marketing & administration of the Showroom &",,,,"['Communication Skills', 'Presentation Skills', 'Management Skills', 'Interpersonal Skills', 'Team Skills', 'Convincing Power', 'Leadership Skills']",2025-06-12 14:11:35
MIS Executive-Enrollment Department,Medi Assist,0 - 2 years,3.5-5 Lacs P.A.,['Mumbai (All Areas)( Marol )'],"JOB DESCRIPTION\n\nAbility to speak, write and read both English\nGood numerical ability\nDemonstrated proficiency in computer skills.\nMust have expertise in MS Excel, Pivot Table, Vlookup, tabulation, formatting etc.\nKnowledge of Insurance Industry or TPA Background will be a plus.\n\nADMINISTRATIVE\n\nTo ensure TAT is met from receipt of policies till card dispatch through TAT report.\nTo ensure smooth Vendor co-ordination & stock movement to vendor.\nSending required reports to HO\nTo ensure storing of policy documents/data in retrievable manner .\nE-card generation\n\nInterested candidates can share resumes on varsha.kumari@mediassist.in",Industry Type: Insurance,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['advance Excel', 'Pivot Table', 'MIS reporting', 'SUMIF', 'Tabulation', 'VLOOKUP', 'MIS', 'Conditional Formatting', 'Formulas', 'Enrollment', 'HLOOKUP', 'Management Information System']",2025-06-12 14:11:37
Data Scientist,Jsg. Consulting. Pvt.Ltd.,3 - 5 years,9.6-10.8 Lacs P.A.,['Jaipur'],"Familiarity with MDM (Meter Data Management), HES, and utility billing systems.\nExposure to AMI events analysis, load curves, and customer behavior analytics.\nKnowledge of regulatory requirements, data retention, and data .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['billing exceptions', 'load profiling', 'Machine Learning', 'Meter Data Management', 'Smart Metering', 'Hes']",2025-06-12 14:11:39
Senior Data Manager/ Lead,Codeforce 360,6 - 8 years,Not Disclosed,['Hyderabad'],"Job Description:\nWe are looking for a highly experienced and dynamic Senior Data Manager / Lead to oversee a team of Data Engineers and Data Scientists. This role demands a strong background in data platforms such as Snowflake and proficiency in Python, combined with excellent people management and project leadership skills. While hands-on experience in the technologies is beneficial, the primary focus of this role is on team leadership, strategic planning, and project delivery .\n\nJob Title : Senior Data Manager / Lead\nLocation: Hyderabad (Work From Office)\nShift Timing: 10AM-7PM\nKey Responsibilities:\nLead, mentor, and manage a team of Data Engineers and Data Scientists.\nOversee the design and implementation of data pipelines and analytics solutions using Snowflake and Python.\nCollaborate with cross-functional teams (product, business, engineering) to align data solutions with business goals.\nEnsure timely delivery of projects, with high quality and performance.\nConduct performance reviews, training plans, and support career development for the team.\nSet priorities, allocate resources, and manage workloads within the data team.\nDrive adoption of best practices in data management, governance, and documentation.\nEvaluate new tools and technologies relevant to data engineering and data science.\n\nRequired Skills & Qualifications:\n6+ years of experience in data-related roles, with at least 23 years in a leadership or management position.\nStrong understanding of Snowflake architecture, performance tuning, data sharing, security, etc.\nSolid knowledge of Python for data engineering or data science tasks.\nExperience in leading data migration, ETL/ELT, and analytics projects.\nAbility to translate business requirements into technical solutions.\nExcellent leadership, communication, and stakeholder management skills.\nExposure to tools like Databricks, Dataiku, Airflow, or similar platforms is a plus.\nBachelors or Master’s degree in Computer Science, Engineering, Mathematics, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Data Bricks', 'Python', 'Airflow', 'Data Migration', 'Dataiku', 'Data Warehousing', 'ETL', 'ELT', 'SQL']",2025-06-12 14:11:42
"Principal Analyst, Insights",Zeta Global,3 - 4 years,Not Disclosed,['Bengaluru'],"Description: Principal Data Analyst will be responsible for analyzing complex datasets, identifying opportunities for process improvements, and implementing automation solutions to streamline workflows. This role requires a deep understanding of data analytics, process automation tools, and excellent problem-solving skills. The ideal candidate will be proactive, detail-oriented, and able to work collaboratively with cross-functional teams to drive data-driven initiatives.\nWhat you ll do:\nAnalyze large and complex datasets to identify trends, patterns, and insights that drive business decisions.\nDevelop, implement, and maintain automated processes to improve data accuracy, efficiency,and reporting capabilities.\nCollaborate with stakeholders to understand business requirements and translate them into technical solutions.\nDesign and build automated dashboards and reports to provide real-time insights to various departments.\nUtilize data visualization tools to present findings in a clear and actionable manner.\nContinuously monitor and refine automated processes to ensure optimal performance and scalability.\nStay updated with industry trends and best practices in data analytics and process automation.\nMentor and provide guidance to junior data analysts on best practices and technical skills.\nWho you are:\nA great communicator who can convey complex technical features in simple terms.\nAble to multitask and prioritize among several high-profile clients.\nHave a high degree of creativity, self-motivation, and drive.\nEagerness to work in a startup team environment that will be rapidly changing.\nEnthusiastic team player with a penchant for collaboration and knowledge sharing.\nWillingness to do whatever it takes to get the job done.\nNerdy but loveable.\nData driven, technical, self-starting and curious.\nWhat you need:\nBachelor s or Master s degree in data science, Computer Science, Statistics, or a related field.\nMinimum of 3-4 years of experience in data analysis, with a focus on process automation.\nA minimum of 2 years of work experience in analytics (minimum of 1 year with a Ph.D.)\nExperience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Experience with combining and consolidating disparate datasets in apps such as Big Query, Data Bricks\nProficiency in programming languages such as Python, R, or SQL.\nExtensive experience with data visualization tools such as Tableau, Power BI or similar.\nStrong knowledge of process automation tools and platforms (e.g., Alteryx, UiPath, Microsoft Power Automate).\nExperience with database management systems (e.g., SQL Server, MySQL, PostgreSQL).\nExcellent analytical and problem-solving skills.\nAbility to work effectively in a fast-paced, collaborative environment.\nStrong communication skills, with the ability to convey complex data insights to non-technical stakeholders.\nExperience with machine learning and predictive analytics is a plus.\nBonus if you have:\nMaster s or Ph.D. Degree in a quantitative field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL', 'UiPath', 'R', 'Power BI', 'PostgreSQL', 'MySQL', 'Alteryx', 'Tableau', 'Python']",2025-06-12 14:11:44
Procurement Analyst,Verizon Media Group,2 - 5 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","We are seeking a motivated Procurement Analyst to analyze procurement processes, ensure policy compliance, and drive cost efficiencies. This role requires strong analytical and problem-solving skills, a process improvement mindset, and the ability to collaborate effectively across various teams.\nRelationship Management: Actively build and maintain strong, collaborative relationships with various internal departments (such as Finance, Legal, and Business units) and external suppliers. This includes effective communication, actively listening to stakeholder needs, and proactively resolving issues to ensure smooth collaboration and positive partnerships.\nData Analysis: Analyze detailed procurement data, including spending patterns, supplier performance metrics, and contract terms, to identify trends, anomalies, and cost-saving opportunities. Utilize tools like Excel, data analysis software, and Oracle applications to generate insightful reports and drive data-driven decisions that optimize procurement activities.\nProcess Development and Improvement: Create, review, and continuously improve procurement processes to enhance efficiency, accuracy, and compliance. Document procedures, identify potential bottlenecks or areas for improvement, and implement changes to streamline operations, reduce errors, and ensure best practices are followe'd.\nReporting: Prepare regular and ad-hoc reports on key procurement metrics, such as spending, supplier performance, and key performance indicators (KPIs). Provide clear and concise insights to stakeholders, track progress towards procurement goals, and highlight areas requiring attention or further action.\nCross-Functional Collaboration: Work closely and effectively with cross-functional teams, including Finance, Legal, and Business teams, to align procurement activities with broader organizational objectives. Coordinate efforts, communicate updates, and ensure successful collaboration to achieve shared goals.\nCompliance: Ensure that all procurement activities adhere strictly to company policies, procedures, and relevant regulations. Stay updated on any changes to policies or regulations and implement necessary adjustments to ensure ongoing compliance.\nPurchase Order Management: Manage the creation, modification, and tracking of purchase orders to ensure the timely and accurate procurement of goods and services. This includes monitoring order fulfillment, addressing any discrepancies, and maintaining accurate records.\nIssue Resolution: Handle and resolve any escalations, disputes, or discrepancies that arise within the procurement process. Utilize strong problem-solving skills, attention to detail, and effective communication to find solutions and prevent future issues.\nProject Assistance: Assist with other finance-related projects as needed, providing support, contributing to project tasks, and helping to achieve overall organizational goals and objectives.\nRequired Qualifications:\nbachelors degree in Business Administration, Supply Chain Management, or Finance.\n2+ years of experience in procurement or a related role.\nStrong analytical and problem-solving skills with proficiency in Excel and data analysis tools.\nFamiliarity with procurement software and ERP systems (eg, Oracle).\nExcellent communication and interpersonal skills.\nStrong organizational skills and attention to detail.\nAbility to manage multiple priorities in a fast-paced environment.\nPreferred Qualifications:\nProfessional certifications (CPP, CSCP).\nExperience with supplier performance evaluation and contract management.\nAbility to work various shifts, including early morning and late evening/night shifts.",Industry Type: Internet,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Order management', 'ERP', 'Data analysis', 'General accounting', 'Contract management', 'Process improvement', 'Analytical', 'Oracle', 'Monitoring', 'Auditing']",2025-06-12 14:11:47
Associate- Referral - Decision Science / Data Science,Axtria,3 - 5 years,Not Disclosed,['Gurugram'],"Position Summary \n\nThis Requisition is for the Employee Referral Campaign.\n\nWe are seeking high-energy, driven, and innovative Data Scientists to join our Data Science Practice to develop new, specialized capabilities for Axtria, and to accelerate the company’s growth by supporting our clients’ commercial & clinical strategies.\n\n Job Responsibilities \n\nBe an Individual Contributor tothe Data Science team and solve real-world problems using cutting-edge capabilities and emerging technologies.\n\nHelp clients translate the business use cases they are trying to crack into data science solutions. Provide genuine assistance to users by advising them on how to leverage Dataiku DSS to implement data science projects, from design to production.\n\nData Source Configuration, Maintenance, Document and maintain work-instructions.\n\nDeep working onmachine learning frameworks such as TensorFlow, Caffe, Keras, SparkML\n\nExpert knowledge in Statistical and Probabilistic methods such as SVM, Decision-Trees, Clustering\n\nExpert knowledge of python data-science and math packages such as NumPy , Pandas, Sklearn\n\nProficiency in object-oriented languages (Java and/or Kotlin),Python and common machine learning frameworks(TensorFlow, NLTK, Stanford NLP, Ling Pipe etc\n\n\n Education \n\nBachelor Equivalent - Engineering\nMaster's Equivalent - Engineering\n\n Work Experience \n\nData Scientist 3-5 years of relevant experience in advanced statistical and mathematical models and predictive modeling using Python. Experience in the data science space prior relevant experience in Artificial intelligence and machine Learning algorithms for developing scalable models supervised and unsupervised techniques likeNLP and deep Learning Algorithms. Ability to build scalable models using Python, R-Studio, R Shiny, PySpark, Keras, and TensorFlow. Experience in delivering data science projects leveraging cloud infrastructure. Familiarity with cloud technology such as AWS / Azure and knowledge of AWS tools such as S3, EMR, EC2, Redshift, and Glue; viz tools like Tableau and Power BI. Relevant experience in Feature Engineering, Feature Selection, and Model Validation on Big Data. Knowledge of self-service analytics platforms such as Dataiku/ KNIME/ Alteryx will be an added advantage.\n\nML Ops Engineering 3-5 years of experience with MLOps Frameworks like Kubeflow, MLFlow, Data Robot, Airflow, etc., experience with Docker and Kubernetes, OpenShift. Prior experience in end-to-end automated ecosystems including, but not limited to, building data pipelines, developing & deploying scalable models, orchestration, scheduling, automation, and ML operations. Ability to design and implement cloud solutions and ability to build MLOps pipelines on cloud solutions (AWS, MS Azure, or GCP). Programming languages like Python, Go, Ruby, or Bash, a good understanding of Linux, knowledge of frameworks such as Keras, PyTorch, TensorFlow, etc. Ability to understand tools used by data scientists and experience with software development and test automation. Good understanding of advanced AI/ML algorithms & their applications.\n\nGen AI :Minimum of 4-6 years develop, test, and deploy Python based applications on Azure/AWS platforms.Must have basic knowledge on concepts of Generative AI / LLMs / GPT.Deep understanding of architecture and work experience on Web Technologies.Python, SQL hands-on experience.Expertise in any popular python web frameworks e.g. flask, Django etc. Familiarity with frontend technologies like HTML, JavaScript, REACT.Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT.Can interact with client on GenAI related capabilities and use cases.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'gpm', 'machine learning', 'python data', 'statistics', 'kubernetes', 'microsoft azure', 'numpy', 'javascript', 'sql', 'docker', 'pandas', 'tensorflow', 'java', 'django', 'predictive modeling', 'python web framework', 'mathematical modeling', 'pytorch', 'keras', 'aws', 'flask', 'advanced statistical']",2025-06-12 14:11:49
Manager - Data Science,Axtria,6 - 11 years,Not Disclosed,['Noida'],"Job Summary-\n\nData Scientist with good hands-on experience of 6+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nJob Responsibilities-\n\nHands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\nProficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\nExperience of working in large teams and using collaboration tools like GIT, Jira and Confluence\nGood understanding of any of the cloud platform – AWS, Azure or GCP\nUnderstanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\nShould have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\nShould be able to mentor and guide mid to large sized teams under him/her\n\n\nJob -\nStrong experience on Spark with Scala/Python/Java\nStrong proficiency in building/training/evaluating state of the art machine learning models and its deployment\nProficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\nProficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'keras', 'spark mllib', 'jira', 'sentiment analysis', 'lingpipe', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-12 14:11:52
"Sr. Data Engineer, R&D Data Catalyst Team",Amgen Inc,7 - 9 years,Not Disclosed,['Hyderabad'],"The R&D Data Catalyst Team is responsible for buildingData Searching, Cohort Building, and Knowledge Management tools that provide the Amgen scientific community with visibility to Amgens wealth of human datasets, projects and study histories, and knowledge over various scientific findings. These solutions are pivotal tools in Amgens goal to accelerate the speed of discovery, and speed to market of advanced precision medications.\nThe Data Engineer will be responsible for the end-to-end development of an enterprise analytics and data mastering solution leveraging Databricks and Power BI. This role requiresexpertise in both data architecture and analytics, with the ability to create scalable, reliable, and high-performing enterprise solutions that research cohort-building and advanced research pipeline.The ideal candidate will have experience creating and surfacing large unifiedrepositories of human data, based on integrations from multiple repositories and solutions, and be exceptionally skilled with data analysis and profiling.\nYou will collaborate closely with stakeholders, product team members, and related IT teams, to design and implement data models, integrate data from various sources, and ensure best practices for data governance and security. The ideal candidate will have a strong background in data warehousing, ETL, Databricks, Power BI, and enterprise data mastering.\nRoles & Responsibilities:\nDesign and build scalable enterprise analytics solutions using Databricks, Power BI, and other modern data tools.\nLeverage data virtualization, ETL, and semantic layers to balance need for unification, performance, and data transformation with goal to reduce data proliferation\nBreak down features into work that aligns with the architectural direction runway\nParticipate hands-on in pilots and proofs-of-concept for new patterns\nCreate robust documentation from data analysis and profiling, and proposed designs and data logic\nDevelop advanced sql queries to profile, and unify data\nDevelop data processing code in sql, along with semantic views to prepare data for reporting\nDevelop PowerBI Models and reporting packages\nDesign robust data models, and processing layers, that support both analytical processing and operational reporting needs.\nDesign and develop solutions based on best practices for data governance, security, and compliance within Databricks and Power BI environments.\nEnsure the integration of data systems with other enterprise applications, creating seamless data flows across platforms.\nDevelop and maintain Power BI solutions, ensuring data models and reports are optimized for performance and scalability.\nCollaborate with stakeholders to define data requirements, functional specifications, and project goals.\nContinuously evaluate and adopt new technologies and methodologies to enhance the architecture and performance of data solutions.\nBasic Qualifications and Experience:\nMasters degree with 1 to 3years of experience in Data Engineering OR\nBachelors degree with 4 to 5 years of experience in Data Engineering\nDiploma and 7 to 9 years of experience in Data Engineering.\nFunctional Skills:\nMust-Have Skills:\nMinimum of 3 years of hands-on experience with BI solutions (Preferrable Power BI or Business Objects) including report development, dashboard creation, and optimization.\nMinimum of 3years of hands-on experience building Change-data-capture (CDC) ETL pipelines, data warehouse design and build, and enterprise-level data management.\nHands-on experience with Databricks, including data engineering, optimization, and analytics workloads.\nDeep understanding of Power BI, including model design, DAX, and Power Query.\nProven experience designing and implementing data mastering solutions and data governance frameworks.\nExpertise in cloud platforms (AWS), data lakes, and data warehouses.\nStrong knowledge of ETL processes, data pipelines, and integration technologies.\nStrong communication and collaboration skills to work with cross-functional teams and senior leadership.\nAbility to assess business needs and design solutions that align with organizational goals.\nExceptional hands-on capabilities with data profiling, data transformation, data mastering\nSuccess in mentoring and training team members\nGood-to-Have Skills:\nExperience in developing differentiated and deliverable solutions\nExperience with human data, ideally human healthcare data\nFamiliarity with laboratory testing, patient data from clinical care, HL7, FHIR, and/or clinical trial data management\nProfessional Certifications (please mention if the certification is preferred or mandatory for the role):\nITIL Foundation or other relevant certifications (preferred)\nSAFe Agile Practitioner (6.0)\nMicrosoft Certified: Data Analyst Associate (Power BI) or related certification.\nDatabricks Certified Professional or similar certification.\nSoft Skills:\nExcellent analytical and troubleshooting skills\nDeep intellectual curiosity\nHighest degree of initiative and self-motivation\nStrong verbal and written communication skills, including presentation to varied audiences of complex technical/business topics\nConfidence technical leader\nAbility to work effectively with global, virtual teams, specifically including leveraging of tools and artifacts to assure clear and efficient collaboration across time zones\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong problem solving, analytical skills;\nAbility to learn quickly and retain and synthesize complex information from diverse sources",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'data analysis', 'ETL processes', 'DAX', 'Business Objects', 'data warehouse design', 'ETL', 'PowerBI Models', 'AWS', 'Power Query']",2025-06-12 14:11:54
"Senior data engineer - Python, Pyspark, AWS - 5+ years Gurgaon",One of the largest insurance providers.,5 - 10 years,Not Disclosed,['Gurugram'],"Senior data engineer - Python, Pyspark, AWS - 5+ years Gurgaon\n\nSummary: An excellent opportunity for someone having a minimum of five years of experience with expertise in building data pipelines. A person must have experience in Python, Pyspark and AWS.\n\nLocation- Gurgaon (Hybrid)\n\nYour Future Employer- One of the largest insurance providers.\n\nResponsibilities-\nTo design, develop, and maintain large-scale data pipelines that can handle large datasets from multiple sources.\nReal-time data replication and batch processing of data using distributed computing platforms like Spark, Kafka, etc.\nTo optimize the performance of data processing jobs and ensure system scalability and reliability.\nTo collaborate with DevOps teams to manage infrastructure, including cloud environments like AWS.\nTo collaborate with data scientists, analysts, and business stakeholders to develop tools and platforms that enable advanced analytics and reporting.\n\nRequirements-\nHands-on experience with AWS services such as S3, DMS, Lambda, EMR, Glue, Redshift, RDS (Postgres) Athena, Kinesics, etc.\nExpertise in data modeling and knowledge of modern file and table formats.\nProficiency in programming languages such as Python, PySpark, and SQL/PLSQL for implementing data pipelines and ETL processes.\nExperience data architecting or deploying Cloud/Virtualization solutions (Like Data Lake, EDW, Mart ) in the enterprise.\nCloud/hybrid cloud (preferably AWS) solution for data strategy for Data lake, BI and Analytics.\nWhat is in for you-\nA stimulating working environment with equal employment opportunities.\nGrowing of skills while working with industry leaders and top brands.\nA meritocratic culture with great career progression.\n\nReach us- If you feel that you are the right fit for the role please share your updated CV at randhawa.harmeen@crescendogroup.in\n\nDisclaimer- Crescendo Global specializes in Senior to C-level niche recruitment. We are passionate about empowering job seekers and employers with an engaging memorable job search and leadership hiring experience. Crescendo Global does not discriminate on the basis of race, religion, color, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Pipeline', 'AWS', 'Data Ingestion', 'Data Engineering', 'Data Processing']",2025-06-12 14:11:57
Director - Data Science,Axtria,12 - 17 years,Not Disclosed,['Noida'],"Minimum 12+ years of relevant experience in building software applications in data and analytics field\nEnhance the go-to-market strategy by designing new and relevant solution frameworks to accelerate our clients’ journeys for impacting patient outcomes. Pitch for these opportunities and craft winning proposals to grow the Data Science Practice.\nBuild and lead a team of data scientists and analysts, fostering a collaborative and innovative environment.\nOversee the design and delivery of the models, ensuring projects are completed on time and meet business objectives.\nEngaging in consultative selling with clients to grow/deliver business.\nDevelop and operationalize scalable processes to deliver on large & complex client engagements.\nExtensive hands-on experience with Python, R, or Julia, focusing on data science and generative AI frameworks.\nExpertise in working with generative models such as GPT, DALL-E, Stable Diffusion, Codex, and MidJourney for various applications.\nProficiency in fine-tuning and deploying generative models using libraries like Hugging Face Transformers, Diffusers, or PyTorch Lightning.\nStrong understanding of generative techniques, including GANs, VAEs, diffusion models, and autoregressive models.\nExperience in prompt engineering, zero-shot, and few-shot learning for optimizing generative AI outputs across different use cases.\nExpertise in managing generative AI data pipelines, including preprocessing large-scale multimodal datasets for text, image, or code generation.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['application software', 'python', 'artificial intelligence', 'r', 'julia', 'hive', 'natural language processing', 'neural networks', 'predictive analytics', 'machine learning', 'sql', 'deep learning', 'java', 'data science', 'spark', 'predictive modeling', 'pytorch', 'hadoop', 'statistics']",2025-06-12 14:11:59
Tax Analyst,Illuminz,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Summary\nIllumina is looking for Tax Analyst/Sr Tax Analyst to be part of newly created Tax Center of Excellence in India and reports to Tax Manager in India. This role will be APAC tax compliance focused and primarily responsible in all aspects of data analysis, tax calculation and reconciliation necessary to meet APAC tax filing, tax audit and statutory audit requirements in APAC region. You will support the Tax Manager in fostering seamless collaboration with global/regional Finance and Tax teams, and other business stakeholders to ensure the adherence of tax compliance governance and efficient tax process maintained in the region.\nTasks and Responsibilities:\nJob duties include but not limited to:\nPrepare monthly tax calculation for APAC entities, this includes extracting SAP reports, analyzing and reconciling financial data, and coordinating with finance teams.\nCollation and managing all aspects of information necessary for submission in tax audits, inquiries and notices raised by tax authorities.\nPerform financial data analysis/schedules/reports necessary for internal and external tax reporting for APAC entities\nInvolve in month-end/statutory audit activities, this includes preparing tax provision/deferred tax calculation and reconciliation relating to tax accounts for APAC entities\nIdentify and drive opportunities for process optimization within the tax reporting workflow, which includes collaborating with internal stakeholder to align processes and implementing into the working environment.\nResearch tax regulations to address daily inquiry on TDS/GST/withholding tax/SAC coding\nParticipate in cross-functional projects and tax projects as and when assigned by the Regional Tax Team/Tax Manager\nPreferred Educational Background:\nBachelor s degree or equivalent in Accounting/Finance/Taxation.\nMinimum 4-7 year in accounting with direct and indirect tax from Big 4 or Accounting with taxation experience. APAC region exposure is a plus\nProficiency in Microsoft Office applications especially Microsoft Excel;\nPrior experience in SAP (or equivalent ERP system) is preferred;\nGood organizational skills, highly detailed oriented and ability to work with minimal supervision and independently;\nAbility to work in a dynamic and fast paced environment and a multi-tasker;\nAbility to be flexible and work analytically in a problem-solving environment;\nExcellent communication (written and oral) and interpersonal skills.\n",Industry Type: Pharmaceutical & Life Sciences,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['TDS', 'Data analysis', 'Process optimization', 'SAP', 'Excel', 'Coding', 'Tax reporting', 'Workflow', 'Taxation', 'Auditing']",2025-06-12 14:12:02
Decarbonisation Data Manager,ISS India,8 - 13 years,Not Disclosed,['Chennai'],"Select with space bar to view the full contents of the job information. Decarbonisation Data Manager Job Details | ISS\nWe use cookies to offer you the best possible website experience. Your cookie preferences will be stored in your browser s local storage. This includes cookies necessary for the websites operation. Additionally, you can freely decide and change any time whether you accept cookies or choose to opt out of cookies to improve websites performance, as well as cookies used to display content tailored to your interests. Your experience of the site and the services we are able to offer may be impacted if you do not accept all cookies.\nModify Cookie Preferences\nAccept All Cookies\nSearch by Keyword Search by location (e.g. ZIP code, city) Full Time/ Part Time Select how often (in days) to receive an alert: Select how often (in days) to receive an alert: Decarbonisation Data Manager Published 1 day ago\nAs a global leader in facilities services we connect people and places to make the world work better. Whether directly or indirectly, you ll play a vital role in supporting our placemakers in delivering exceptional workplace experiences for our customers. Together, we make space for people and businesses to thrive.\nLocation: Chennai, India\nLanguage: English\nMain purpose of the position :\nThe Supply Chain Decarbonization Manager will play a key role in shaping and executing ISS s global supply chain sustainability agenda. With ISS committed to reaching net-zero carbon emissions by 2040, this role will be pivotal in translating procurement spend into carbon intelligence. You will lead the design and implementation of carbon transparency strategies, develop a data-driven emissions tracking framework, and engage internal and external stakeholders to drive measurable Scope 3 emission reductions.\nWhat you ll do:\nLead a team of two competent Supply Chain & Procurement decarbonisation data analysts\nLead the global emissions data strategy for Supply Chain & Procurement, including methodology and governance\nManage the mapping and enhancement of carbon emission factors across supplier categories\nOversee data improvement initiatives in procurement systems (e.g. Sievo)\nLead supplier sustainability engagement programme\nSupport ISS s Science-Based Target roadmap by tracking progress and advising on supplier impact\nDrive global decarbonisation agenda across Supply Chain & Procurement in the countries\nWho you ll work with:\nGroup Digital Procurement Your core team, responsible for global procurement transformation and analytics. You ll work closely with them to embed CO tracking into procurement systems and processes.\nGroup Sustainability Teams Lead collaborators on ISS s overarching climate strategy. You ll align carbon tracking initiatives with enterprise-level ESG targets and disclosures (e.g., CSRD, SBTi).\nGroup & Country Procurement Teams Key internal clients whom you will support in localising decarbonisation strategies, identifying high-impact categories, and operationalising carbon insights in supplier decisions.\nExternal Suppliers & Data Providers You will manage regular engagement with suppliers and data sources to ensure accurate emissions data, compliance with ISS sustainability criteria, and continuous improvement.\nTechnology Partners & Platform Owners (e.g. Sievo) You ll collaborate with system stakeholders to design, test, and calibrate platforms for effective CO data capture, analysis, and reporting at scale.\nKey qualifications:\nMaster s degree in Business, IT, Supply Chain Management, Environmental Management or a related field.\n8+ years of experience in supply chain, sustainability, or carbon data management\nStrong knowledge of GHG Protocol, SBTi, CDP, DEFRA, or other reporting standards\nSolid understanding of procurement systems and spend analysis platforms\nProven expertise in Scope 3 emissions tracking\nNice to have: sustainability data modelling, experience with data visualization tools (e.g., Power BI), programming (e.g. Python) and application-building tools (e.g. PowerApps, PowerAutomate)\nPersonal skills you excel:\nStrong problem-solving and analytical thinking to identify actionable carbon insights\nExcellent communication and stakeholder engagement skills\nA strong change management mindset enabling you to show resilience and adapt and change priorities and approach based on market conditions and organizational needs\nAbility to manage complexity and drive clarity in global, cross-functional settings\nAttention to detail and a high level of ownership for data quality and reporting integrity\nAbility to prioritise and drive own and team activities\nWhy ISS\nAt ISS, we are more than just a service provider of cleaning, food, workplace and technical services, we are a partner in our customers success. By creating exceptional service moments and transforming workplaces into spaces where employees feel valued, engaged and productive, we enhance productivity and help our customers to attract talent and grow their businesses. This begins with our own people through training, career development, and a supportive culture empowering them to deliver outstanding service. We know that when our people thrive, they create spaces where our customers employees and businesses thrive too.\nISS is a Place to Be You.\nBe who you are. Become what you want. Be part of something bigger.\nBecome more. Become ISS.\nHow you ll apply\nApply directly via the link on this page by submitting a cover letter, CV and other relevant documents for the position you are applying for.\nWe look forward to receiving your application as soon as possible.\nISS seeks to BE a place of belonging and CREATE places where every person is welcomed, embraced, and valued for exactly who they are. Places where people feel safe, respected, represented, and supported as their authentic selves.\n#LI-Hybrid\nThe Recruitment Process 1. Job search 4. Interview(s) 5. Job offer Browse the ISS Career Site and find your next job Click ""Apply now"" and follow the steps to complete your application Our Recruiting team reviews your application We get to know you better and answer any questions you may have Congratulations! We are excited to offer you a job and look forward to onboarding you soon The Recruitment Process\n1. Job search\nBrowse the ISS Career Site and find your next job\nOur Recruiting team reviews your application\n4. Interview(s)\nWe get to know you better and answer any questions you may have\n5. Job offer\nCongratulations! We are excited to offer you a job and look forward to onboarding you soon\nWhy ISS\nSince our founding in 1901, ISS has been a people-first company. We recognise the power of diversity, inclusion and belonging and celebrate the differences that make us unique. When everyone is free to be themselves, everyone benefits.\nOur people feel safe, respected, represented, and supported as their authentic selves, allowing them to seize opportunities and reach their full potential. We take seriously our obligation to improve lives, make a difference in our communities, and protect our planet - because when we get things right, the world works better. And that is what drives us.\nISS is a Place to Be You.\nBe who you are. Become what you want. Be part of something bigger.\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. Because we respect your right to privacy, you can choose not to allow some types of cookies. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.\nThese cookies are required to use this website and cant be turned off.\nProvider Description Enabled SAP as service provider\nWe use the following session cookies, which are all required to enable the website to function:\n""route"" is used for session stickiness\n""careerSiteCompanyId"" is used to send the request to the correct data center\n""JSESSIONID"" is placed on the visitors device during the session so the server can identify the visitor\n""Load balancer cookie"" (actual cookie name may vary) prevents a visitor from bouncing from one instance to another\nAdvertising Cookies\nThese cookies serve ads that are relevant to your interests. You may freely choose to accept or decline these cookies at any time. Note that certain functionality that these third parties make available may be impacted if you do not accept these cookies.",Industry Type: Facility Management Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Procurement', 'Change management', 'Supply chain management', 'SAP', 'Data management', 'Web analytics', 'Analytical', 'Continuous improvement', 'Analytics']",2025-06-12 14:12:04
Senior Azure Data Engineer,Cloud Angles Digital Transformation,8 - 12 years,Not Disclosed,['Hyderabad'],"Job Summary:\nWe are seeking a highly skilled Data Engineer with expertise in leveraging Data Lake architecture and the Azure cloud platform to develop, deploy, and optimise data-driven solutions. . You will play a pivotal role in transforming raw data into actionable insights, supporting strategic decision-making across the organisation.\nResponsibilities\nDesign and implement scalable data science solutions using Azure Data Lake, Azure Data Bricks, Azure Data Factory and related Azure services.\nDevelop, train, and deploy machine learning models to address business challenges.\nCollaborate with data engineering teams to optimise data pipelines and ensure seamless data integration within Azure cloud infrastructure.\nConduct exploratory data analysis (EDA) to identify trends, patterns, and insights.\nBuild predictive and prescriptive models to support decision-making processes.\nExpertise in developing end-to-end Machine learning lifecycle utilizing crisp-DM which includes of data collection, cleansing, visualization, preprocessing, model development, model validation and model retraining\nProficient in building and implementing RAG systems that enhance the accuracy and relevance of model outputs by integrating retrieval mechanisms with generative models.\nEnsure data security, compliance, and governance within the Azure cloud ecosystem.\nMonitor and optimise model performance and scalability in production environments.\nPrepare clear and concise documentation for developed models and workflows.\nSkills Required:\nGood experience in using Pyspark, Python, MLops (Optional), ML flow (Optional), Azure Data Lake Storage. Unity Catalog\nWorked and utilized data from various RDBMS like MYSQL, SQL Server, Postgres and NoSQL databases like MongoDB, Cassandra, Redis and graph DB like Neo4j, Grakn.\nProven experience as a Data Engineer with a strong focus on Azure cloud platform and Data Lake architecture.\nProficiency in Python, Pyspark,\nHands-on experience with Azure services such as Azure Data Lake, Azure Synapse Analytics, Azure Machine Learning, Azure Databricks, and Azure Functions.\nStrong knowledge of SQL and experience in querying large datasets from Data Lakes.\nFamiliarity with data engineering tools and frameworks for data ingestion and transformation in Azure.\nExperience with version control systems (e.g., Git) and CI/CD pipelines for machine learning projects.\nExcellent problem-solving skills and the ability to work collaboratively in a team environment.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Azure Data Engineering', 'Azure Databricks', 'Pyspark', 'Azure Data Lake', 'Python']",2025-06-12 14:12:07
Senior Data Engineer - Azure,Blend360 India,6 - 11 years,Not Disclosed,['Hyderabad'],"As a Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\n3+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar field\nMust have experience e",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:12:09
Senior Data Engineer,Amgen Inc,3 - 7 years,Not Disclosed,['Hyderabad'],"What you will do\nRole Description:\nWe are seeking a Senior Data Engineer with expertise in Graph Data technologies to join our data engineering team and contribute to the development of scalable, high-performance data pipelines and advanced data models that power next-generation applications and analytics. This role combines core data engineering skills with specialized knowledge in graph data structures, graph databases, and relationship-centric data modeling, enabling the organization to leverage connected data for deep insights, pattern detection, and advanced analytics use cases. The ideal candidate will have a strong background in data architecture, big data processing, and Graph technologies and will work closely with data scientists, analysts, architects, and business stakeholders to design and deliver graph-based data engineering solutions.\nRoles & Responsibilities:\nDesign, build, and maintain robust data pipelines using Databricks (Spark, Delta Lake, PySpark) for complex graph data processing workflows.\nOwn the implementation of graph-based data models, capturing complex relationships and hierarchies across domains.\nBuild and optimize Graph Databases such as Stardog, Neo4j, Marklogic or similar to support query performance, scalability, and reliability.\nImplement graph query logic using SPARQL, Cypher, Gremlin, or GSQL, depending on platform requirements.\nCollaborate with data architects to integrate graph data with existing data lakes, warehouses, and lakehouse architectures.\nWork closely with data scientists and analysts to enable graph analytics, link analysis, recommendation systems, and fraud detection use cases.\nDevelop metadata-driven pipelines and lineage tracking for graph and relational data processing.\nEnsure data quality, governance, and security standards are met across all graph data initiatives.\nMentor junior engineers and contribute to data engineering best practices, especially around graph-centric patterns and technologies.\nStay up to date with the latest developments in graph technology, graph ML, and network analytics.\nWhat we expect of you\nMust-Have Skills:\nHands-on experience in Databricks, including PySpark, Delta Lake, and notebook-based development.\nHands-on experience with graph database platforms such as Stardog, Neo4j, Marklogic etc.\nStrong understanding of graph theory, graph modeling, and traversal algorithms\nProficiency in workflow orchestration, performance tuning on big data processing\nStrong understanding of AWS services\nAbility to quickly learn, adapt and apply new technologies with strong problem-solving and analytical skills\nExcellent collaboration and communication skills, with experience working with Scaled Agile Framework (SAFe), Agile delivery practices, and DevOps practices.\nGood-to-Have Skills:\nGood to have deep expertise in Biotech & Pharma industries\nExperience in writing APIs to make the data available to the consumers\nExperienced with SQL/NOSQL database, vector database for large language models\nExperienced with data modeling and performance tuning for both OLAP and OLTP databases\nExperienced with software engineering best-practices, including but not limited to version control (Git, Subversion, etc.), CI/CD (Jenkins, Maven etc.), automated unit testing, and Dev Ops\nEducation and Professional Certifications\nMasters degree and 3 to 4 + years of Computer Science, IT or related field experience\nBachelors degree and 5 to 8 + years of Computer Science, IT or related field experience\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\nScaled Agile SAFe certification preferred\nSoft Skills:\nExcellent analytical and troubleshooting skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals.\nAbility to learn quickly, be organized and detail oriented.\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'SPARQL', 'Maven', 'PySpark', 'GSQL', 'Subversion', 'AWS services', 'Stardog', 'Cypher', 'SAFe', 'Jenkins', 'DevOps', 'Git', 'Neo4j', 'Delta Lake', 'Graph Databases', 'Spark', 'Marklogic', 'Gremlin']",2025-06-12 14:12:11
Senior Data Engineer - AWS,Blend360 India,6 - 10 years,Not Disclosed,['Hyderabad'],"We are looking for an experienced Senior Data Engineer with a strong foundation in Python, SQL, and Spark , and hands-on expertise in AWS, Databricks . In this role, you will build and maintain scalable data pipelines and architecture to support analytics, data science, and business intelligence initiatives. You ll work closely with cross-functional teams to drive data reliability, quality, and performance.\nResponsibilities:\nDesign, develop, and optimize scalable data pipelines using Databricks in AWS such as Glue, S3, Lambda, EMR, Databricks notebooks, workflows and jobs.\nBuilding data lake in WS Databricks.\nBuild and maintain robust ETL/ELT workflows using Python and SQL to handle structured and semi-structured data.\nDevelop distributed data processing solutions using Apache Spark or PySpark .\nPartner with data scientists and analysts to provide high-quality, accessible, and well-structured data.\nEnsure data quality, governance, security, and compliance across pipelines and data stores.\nMonitor, troubleshoot, and improve the performance of data systems and pipelines.\nParticipate in code reviews and help establish engineering best practices.\nMentor junior data engineers and support their technical development.\n\n\nRequirements\nBachelors or masters degree in computer science, Engineering, or a related field.\n5+ years of hands-on experience in data engineering , with at lea",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Version control', 'GIT', 'Workflow', 'Data quality', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:12:13
Associate - Founder's Office,Healthkart,0 - 2 years,4-6.5 Lacs P.A.,['Gurugram'],"Get an opportunity to work directly with leadership on high-impact business strategy, financial modeling & data-driven decision-making in the Founder's Office team.\n\nKey Responsibilities:\nData Analysis and Reporting: Gather, consolidate, and analyze financial data from various sources to generate reports, dashboards, and presentations that provide actionable insights to the leadership team. Present findings in a clear and concise manner.\nFinancial Modeling: Develop and maintain financial models to evaluate business performance, scenario planning, and investment opportunities. Ensure accuracy and integrity of the models by incorporating relevant data and updating assumptions as needed.\nForecasting and Budgeting: Collaborate with key stakeholders to develop annual budgets and periodic forecasting processes. Track actual performance against budget and provide insightful analysis on variances.\nCommunication and Collaboration: Communicate financial insights, forecasts, and recommendations effectively to the leadership team, influencing strategic discussions and supporting key business initiatives. Collaborate with cross-functional teams to align financial goals with operational objectives.\n\nRequirements:\nBachelor's degree in Eco (Hons), B.Com (Hons) and Math (Hons) or related fields is preferred\nStrong analytical and problem-solving skills, with a high attention to detail\nAdvanced proficiency in Microsoft Excel and financial modeling\nSolid understanding of financial statements, key financial metrics, and financial analysis techniques\nExcellent written and verbal communication skills, with the ability to present complex data in a clear and concise manner\nProactive and self-motivated individuals who can work both independently and collaboratively.\nAbility to manage multiple priorities and meet deadlines in a fast-paced environment\nPrior experience in financial analysis, forecasting, or strategic planning is preferred\nKnowledge of the sports nutrition or consumer goods industry is a plus.",Industry Type: Internet (E-Commerce),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Financial Analysis', 'Financial Modelling', 'Financial Reporting', 'Financial Strategy', 'Budgeting', 'Forecasting', 'Stakeholder Management']",2025-06-12 14:12:16
Data Scientist,Ltimindtree,7 - 12 years,Not Disclosed,['Hyderabad'],Data Scientist\n\nJob Description\n\nResponsibilities\n\nWork with team members across multiple disciplines to understand the data behind product features user behaviors the security landscape and our goals\nAnalyze data from several large sources then automate solutions using scheduled processes models and alerts\nWork with partners to design and improve metrics that guide our decisions for the product\nDetect patterns associated with fraudulent accounts and anomalous behavior\nSolve scientific problems and create new methods independently\nTranslate requirements and security questions into data insights\nSet up alerting mechanisms so our leadership is always aware of the security posture\n\nQualifications\n\nPostgraduate degree with specialization in machine learning artificial intelligence statistics or related fields or 2 years of equivalent work experience in applied machine learning and analytics\nExperience with SQL Snowflake and NoSQL databases\nProficiency in Python programming\nFamiliarity with statistics modeling and data visualization\n\nExperience\n\nExperience building statistical and machine learning models applying techniques such as regression classification clustering and anomaly detection Time series and Classical ML modeling\nFamiliarity with Snowflake SQL\nFamiliarity with cloud platforms such as AWS\nSome experience to software development or data engineering\nAnalyze business problems or research questions identify relevant data points and extract meaningful insights,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Snowflake Sql', 'AWS']",2025-06-12 14:12:18
MIS Analyst,Credgenics,3 - 5 years,3-4 Lacs P.A.,['New Delhi'],"Requirement:\n1. Ability to work with Data Management & BI platforms.\n2. Good data analytical & problem-solving skills.\n3. Understand and analyze Business requirements\n4. Demonstrate ability to work in a team environment.\n\nMust have skills:\n5. Advance Excel, python,SQL (All Three are mandatory)",,,,['Advanced Excel'],2025-06-12 14:12:20
Full Stack Data Scientist,Vimo Getinsured,2 - 7 years,Not Disclosed,['Gurugram( Sector 61 Gurgaon )'],"About the Role\nAs a Data Science Engineer, you will need strong technical skills in data modeling, machine learning, data engineering, and software development. You will have the ability to conduct literature reviews and critically evaluate research papers to identify applicable techniques. Additionally, you should be able to design and implement efficient and scalable data processing pipelines, perform exploratory data analysis, and collaborate with other teams to integrate data science models into production systems. Passion for conversational AI and a desire to solve some of the most complex problems in the Natural Language Processing space are essential. You will work on highly scalable, stable, and automated deployments, aiming for high performance. Taking on the challenge of building and scaling a truly remarkable AI platform to impact the lives of millions of customers will be part of your responsibilities. Working in a challenging yet enjoyable environment, where learning new things is the norm, you should think of solutions beyond boundaries. You should also drive outcomes with full ownership, deeply believe in customer obsession, and thrive in a fast-paced environment of learning and innovation.\nYou will work in a challenging, consumer-facing problem space, where you can make an immediate impact. You will get to work with the latest technologies, learn to use new tools and get the opportunity to have your say in the final product. Youll work alongside a great team in an open, collaborative environment. We are part of Vimo, a well-funded, stable mid-size company with excellent salaries, medical/dental/vision coverage, and perks. Vimo is an Equal Opportunity Employer.",,,,"['python', 'Langchain', 'Neural Networks', 'LLM', 'Linux', 'Data Structures', 'Natural Language Processing', 'Jupyter Notebook', 'Machine Learning', 'Deep Learning', 'Numpy', 'Data Science', 'pandas', 'Nltk', 'Langgraph', 'Transformers', 'BERT', 'langsmith']",2025-06-12 14:12:22
Technical Specialist - Data Scientist,Fidelity International,8 - 9 years,Not Disclosed,['Gurugram'],"Application Deadline: 21 June 2025\nTitle Senior Analyst- Data Scientist\nDepartment Data Value\nLocation Gurgaon\nReports To Suman Kaur\nLevel 3\nWe re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our Data Value team and feel like you re part of something bigger.\nAbout your team\nData Value team drives the renewed focus of extracting value from Fidelity s data for business and client insights and working as one voice with the business, technology, and data teams. The team s vision is to create measurable business impact by leveraging technology and utilising the skills to generate valuable insights and streamline engagements. The Data Science function within Data Value supports Fidelity International s Sales, Marketing, Propositions, Risk, Finance, Customer Service and HR teams across the globe. The key objectives of the function are:\nTo develop deep customer insights for our businesses helping them segment and target customers more effectively\nTo develop a fact-based understanding of sales trends and identify actionable sales growth opportunities for each of our sales channels\nTo understand customer preferences in terms of products, service attributes and marketing activity to help refine each of these\nTo help develop new services lines e.g. develop customer analytics for key IFAs, DC Clients, Individual clients etc.\nTo develop market and competitive intelligence in our key markets to help shape our business planning in those markets\nThe function works directly with business heads and other senior stakeholder s stakeholders to identify areas of analytics, define problem statements and develop key insights.\nAbout your role\nYou will be expected to take a leading role in developing the Data Science and Advanced Analytics solutions for our business. This will involve:\nEngaging with the key stakeholders to understand Fidelity s sales, marketing, client services and propositions context\nImplement advanced analytics solutions on On-Premises/Cloud platforms, develop proof-of-concepts and engage with internal and external ecosystem to progress the proof of concepts to production.\nEngaging and collaborating with different other internal teams like Data engineering, DevOps, technology team etc for development of new tools, capabilities, and solutions.\nMaximize Adoption of Cloud Based advanced analytics solutions: Build out sandbox analytics environments using Snowflake, AWS, Adobe, Salesforce.\nAbout you\nKey Responsibilities\nDeveloping and Delivering Data Science solutions for business (40%)\nPartner with internal (FIL teams) & external ecosystem to design and deliver advanced analytics enabled Data Science solutions\nCreate advanced analytics solution on quantitative and text data using Artificial Intelligence, Machine Learning and NLP techniques.\nCreate compelling visualisations that enable the smooth consumption of predictions and insights for customer benefit\n. Stakeholder Management (30%)\nWorks with channel heads/stakeholders and other sponsors understand the business problem and translate it into appropriate analytics solution.\nEngages with key stakeholders for smooth execution, delivery, and implementation of solutions\nAdoption of Cloud enabled Data Science solutions: (20%)\nMaximize Adoption of Cloud Based advanced analytics solution\nBuild out sandbox analytics environments using Snowflake, AWS, Adobe, Salesforce\nDeploy solutions in productions while adhering to best practices involving Model Explainability, MLOps, Feature Stores, Model Management, Responsible AI etc\nCollaboration and Ownership (10%)\nSharing of knowledge, best practices with the team including coaching or training in some of deep learning/machine learning methodologies. Provides mentoring, coaching, and consulting advice and guidance to staff, e.g. analytic methodologies, data recommendations\nTakes complete independent ownership of the projects and the initiatives in the team with the minimal support\nExperience and Qualifications Required\nQualifications:\nEngineer from IIT/Master s in field related to Data Science/Economics/Mathematics (Tie1 Institutions like ISI, Delhi School of Economics)/M.B.A from tier 1 institutions\nMust have Skills & Experience Required:\nOverall, 8+ years of experience in Data Science and Analytics\n5+ years of hands-on experience in - Statistical Modelling /Machine Learning Techniques/Natural Language Processing/Deep Learning\n5+ years of experience in Python/Machine Learning/Deep Learning\nExcellent problem-solving skills\nShould be able to run analytics applications such as Python, SAS and interpret statistical results\nImplementation of models with clear measurable outcomes\nGood to have Skills & Experience Required:\nAbility to engage in discussion with senior stakeholders on defining business problems, designing analyses projects, and articulating analytical insights to stakeholders.\nExperience on SPARK/Hadoop/Big Data Platforms is a plus\nExperience with unstructured data and big data\nExperience with secondary data and knowledge of primary market research is a plus.\nAbility to independently own and manage the projects with minimal support.\nExcellent analytical skills and a strong sense for structure and logic\nAbility to develop, test and validate hypotheses.\nFeel rewarded",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAS', 'Senior Analyst', 'Consulting', 'Machine learning', 'Business planning', 'Competitive intelligence', 'Customer service', 'Adobe', 'Stakeholder management', 'Salesforce']",2025-06-12 14:12:24
Data Scientist,Callaway Digital Technologies,6 - 9 years,Not Disclosed,['Hyderabad'],"JOB OVERVIEW\nThe ideal candidate will be responsible for analyzing and interpreting large data sets related to finance, sales and supply chain operations to optimize business processes, identify opportunities for improvement, and provide strategic insights to support decision-making. The Data Scientist will work closely with cross-functional teams to identify key business questions, design and implement statistical models, and develop innovative data-driven solutions.\nKey Responsibilities:",,,,"['Statistical Modeling', 'Machine Learning', 'Python', 'Data Visualization', 'Azzure', 'R Program', 'SQL']",2025-06-12 14:12:26
Data Scientist,Celebal Technologies,4 - 9 years,20-35 Lacs P.A.,"['Mumbai', 'Navi Mumbai', 'Pune']","Job Summary: We are looking for a highly skilled Data Scientist with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus. Key Responsibilities • Develop, deploy, and maintain time series forecasting models (Prophet, ARIMA, etc.) for demand forecasting and customer behavior modeling. • Design and implement Customer Lifetime Value (CLV) models to drive customer retention and engagement strategies. • Process and analyze large datasets using PySpark or Python (Pandas). • Partner with cross-functional teams to identify business needs and translate them into data science solutions. • Leverage classic ML techniques (classification, regression) and boosting algorithms (e.g., XGBoost, LightGBM) to support broader analytics use cases. • Use Databricks for collaborative development, data pipelines, and model orchestration. • Apply optimization techniques where relevant to improve forecast accuracy and business decision-making. • Present actionable insights and communicate model results effectively to technical and non-technical stakeholders. Required Qualifications • Strong experience in Time Series Forecasting, with hands-on knowledge of Prophet, ARIMA, or equivalent Mandatory. • Proven track record in Demand Forecasting Highly Preferred. • Experience in modeling Customer Lifecycle Value (CLV) or similar customer analytics use cases – Highly Preferred. • Proficiency in Python (Pandas) or PySpark – Mandatory. • Experience with Databricks – Mandatory. • Solid foundation in statistics, predictive modeling, and machine learning",,,,"['Machine Learning', 'Data Bricks', 'Optimization', 'Pricing', 'Time Series', 'Pyspark', 'Arima', 'Classic ML', 'Artificial Intelligence', 'Regression', 'Customer Lifecycle', 'Manufacturing Industry', 'Regression Modeling', 'Forecasting', 'Data Science', 'Xgboost', 'Time Series Analysis', 'Pandas', 'Classical', 'Python', 'Prophet']",2025-06-12 14:12:29
Data Scientist,Apcfss,2 - 6 years,Not Disclosed,"['Vijayawada', 'Guntur', 'Mangalagiri']","Location: Vijayawada, Andhra Pradesh\nExperience: 2 to 6 years\nEmployment Type: Full-Time\n\nJob Opening: Data Scientist\nWe are seeking a data-driven problem solver to join our team as a Data Scientist. You will play a key role in transforming data into actionable insights and building models that support strategic decisions across the organization. Collaborating with cross-functional teams, youll help turn complex data into clear value.\nKey Responsibilities\nAnalyze large and complex datasets to uncover trends, patterns, and insights\nBuild, validate, and deploy predictive and statistical models\nWork closely with engineering and product teams to integrate models into production systems\nCommunicate analytical findings and insights clearly to both technical and non-technical stakeholders\nRequirements\nProficiency in Python or R, and strong command of SQL\nHands-on experience with machine learning and statistical modeling\nStrong analytical and problem-solving skills\nExperience with cloud platforms such as AWS, GCP, or Azure\nNice to Have\nExperience in Natural Language Processing (NLP), deep learning, or time-series forecasting\nPrior work in [industry-specific domain, e.g., fintech, healthcare, e-commerce]",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'GCP', 'Machine Learning', 'AWS', 'Deep Learning', 'SQL']",2025-06-12 14:12:31
Data Scientist,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nThe Data Scientist is responsible for developing and implementing AI-driven solutions to enhance cybersecurity measures within the organization. This role involves leveraging data science techniques to analyze security data, detect threats, and automate security processes. The Data Scientist will work closely with cybersecurity teams to identify data-driven automation opportunities, strengthening the organizations security posture.\nRoles & Responsibilities:\nDevelop analytics to address security concerns, enhancements, and capabilities to improve the organization's security posture.\nCollaborate with Data Engineers to translate security-focused algorithms into effective solutions.\nWork in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\nPerform exploratory and targeted data analyses using descriptive statistics and other methods to identify security patterns and anomalies.\nDesign and implement security-focused analytics pipelines leveraging MLOps practices.\nCollaborate with data engineers on data quality assessment, data cleansing, and the development of security-related data pipelines.\nContribute to data engineering efforts to refine data infrastructure and ensure scalable, efficient security analytics.\nGenerate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\nFunctional Skills:\nBasic Qualifications:\nMasters degree and 1 to 3 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python) OR\nBachelors degree and 3 to 5 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python) OR\nDiploma and 7 to 9 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python)\nPreferred Qualifications:\nExperience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python)\nDemonstrated skill in the use of applied analytics, descriptive statistics, feature extraction and predictive analytics on industrial datasets\nStrong foundation in machine learning algorithms and techniques\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification\nGood-to-Have Skills:\nProficiency in Python and relevant ML libraries (e.g., TensorFlow, PyTorch, Scikit-learn)\nOutstanding analytical and problem-solving skills; Ability to learn quickly; Excellent communication and interpersonal skills\nExperience with data engineering and pipeline development\nExperience in analyzing time-series data for forecasting and trend analysis\nExperience with AWS, Azure, or Google Cloud\nExperience with Databricks platform for data analytics and MLOps\nExperience with Generative AI models (e.g., GPT, DALLE, Stable Diffusion) and their applications in cybersecurity and data analysis\nExperience working in Product team's environment\nExperience working in an Agile environment\nProfessional Certifications:\nAny AWS Developer certification (preferred)\nAny Python and ML certification (preferred)\nAny SAFe Agile certification (preferred)\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'R', 'PyTorch', 'SAS', 'predictive analytics', 'Scikit-learn', 'SPSS', 'machine learning', 'data engineering', 'Python', 'TensorFlow']",2025-06-12 14:12:33
Data Scientist,Celebal Technologies,3 - 6 years,Not Disclosed,"['Navi Mumbai', 'Mumbai (All Areas)']","Job Title: Data Scientists\nLocation: Navi Mumbai\nDuration: Fulltime\nPositions: Multiple\n\nWe are looking for a highly skilled Data Scientists with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus.",,,,"['Demand Forecasting', 'Data Bricks', 'Time Series', 'Pyspark', 'Arima', 'Customer Lifecycle', 'Forecasting', 'Machine Learning', 'Optimization', 'Data Science', 'Xgboost', 'Time Series Analysis', 'Prophet', 'Python']",2025-06-12 14:12:35
Data Scientist,An Indian NBFC,3 - 8 years,Not Disclosed,['Chennai'],"Responsibilities:\nCollect, clean, and analyze large sets of structured and unstructured data to extract meaningful insights and trends\nDevelop and implement advanced machine learning algorithms to solve complex business problems\nSupport moving models to production, by creating high quality code modules that can be seamlessly integrated into existing systems (both on-prem and cloud)\nCommunicate complex findings to both technical and non-technical audiences through effective data visualization and storytelling.\nCollaborate with cross-functional teams to identify data-driven opportunities and translate business requirements into actionable data solutions.\nSupport the development and maintenance of data pipelines and infrastructure\nStay up-to-date with industry trends and advancements in Data Science and Machine Learning technologies.\n\nSkills Required:\nStrong foundation in statistics, and machine learning algorithms\nStrong proficiency in programming languages like Python and SQL.\nExcellent problem-solving and analytical skills.\nAbility to work independently and as part of a team.\nShould have built production models using at least 2 of the ML techniques: Clustering, Regression, Classification\nExperience in Banking & Financial Services is preferred.\nExperience working on cloud platforms (e.g., AWS, GCP) is preferred.\nA passion for data and a curiosity to explore new trends and technologies",Industry Type: NBFC,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Pipeline', 'Data Extraction', 'Model Building', 'Artificial Intelligence', 'Cloud', 'Machine Learning']",2025-06-12 14:12:37
Data Scientist,Celebal Technologies,3 - 6 years,Not Disclosed,"['Mumbai', 'Navi Mumbai']","About Us: Celebal Technologies is a leading Solution Service company that provide Services the field of Data Science, Big Data, Enterprise Cloud & Automation. We are at the forefront of leveraging cuttingedge technologies to drive innovation and enhance our business processes. As part of our commitment to staying ahead in the industry, we are seeking a talented and experienced Data & AI Engineer with strong Azure cloud competencies to join our dynamic team.\n\nJob Summary: We are looking for a highly skilled Data Scientist with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus.\n\nKey Responsibilities\n• Develop, deploy, and maintain time series forecasting models (Prophet, ARIMA, etc.) for demand forecasting and customer behavior modeling.\n• Design and implement Customer Lifetime Value (CLV) models to drive customer retention and engagement strategies.\n• Process and analyze large datasets using PySpark or Python (Pandas).\n• Partner with cross-functional teams to identify business needs and translate them into data science solutions.\n• Leverage classic ML techniques (classification, regression) and boosting algorithms (e.g., XGBoost, LightGBM) to support broader analytics use cases.\n• Use Databricks for collaborative development, data pipelines, and model orchestration.\n• Apply optimization techniques where relevant to improve forecast accuracy and business decision-making.\n• Present actionable insights and communicate model results effectively to technical and non-technical stakeholders.\n\nRequired Qualifications\n• Strong experience in Time Series Forecasting, with hands-on knowledge of Prophet, ARIMA, or equivalent Mandatory.\n• Proven track record in Demand Forecasting Highly Preferred.\n• Experience in modeling Customer Lifecycle Value (CLV) or similar customer analytics use cases Highly Preferred.\n• Proficiency in Python (Pandas) or PySpark Mandatory.\n• Experience with Databricks Mandatory.\n• Solid foundation in statistics, predictive modeling, and machine learning",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning Operations', 'Demand Forecasting', 'Data Bricks', 'Pyspark', 'Large Language Model', 'Time Series', 'Spark', 'Machine Learning', 'Python']",2025-06-12 14:12:39
Data Scientist,Mindpro Technologies,4 - 9 years,5-12 Lacs P.A.,"['Karur', 'Dharwad']","Greetings From Mind Pro Technologies Pvt ltd (www.mindprotech.com)\n\nJob Title : Data Scientist\nWork Location : Karur (Tamil Nadu) or Dharwad (Karnataka )\nNp : 15days or Less\n\n\nJOB DESCRIPTION:\n Must have At least 4+ Years of experience in Python with Data Science.\n Must have worked on at least one Live project.\nExperience in relevant field such as Statistics, Computer Science or Applied Math or Operational Research.\nMust have Masters in (Maths/Statistics or Applied Mathematics/Machine Learning etc.)\nHistory of successfully performing customer implementations\nStrong customer facing skills, and previous consulting experience.\nExperience of handling high frequency streaming data for real time analysis and reporting.\nFamiliarity with - Natural Language Processing, Statistical Analysis (distribution analysis, correlation, variance, deep learning.\nExperience in tools like AWS, IBM Watson is a plus.\nExperience with open source technologies is a must.\nExcellent communication\nAbility to lead & build strong teams\nAbility to work in an ambiguous environment\n\nDesired Skills and Experience\nLanguages/Tools: Python/R.\nApproaches: Machine Learning\nConcepts: Supervised ANN, Bayesian, Gaussian, Vector Quantization, Logistic Model, Statistical, Predictive Modeling, Minimum Message Length, SVM, Random Forest, Ensembles, ANOVA, Decision Trees, Hidden Markov Models\nUnsupervised ANN, ARL, Clustering Hierarchical, Cluster Analysis\nReinforcement\nGen AI, LLM, LSTM, RNN, CNN, KNN\nBig Data (Good to have): Hadoop /Kafka / Storm / Spark streaming\nOS: Linux, Windows 32/64 bits.\n\nNote:  should know supervised and unsupervised learning,   semi-supervised learning, neural networks concepts, and how ML algorithms works with training and testing data. Experience on particular data set to train, test and roll-out for production use\n\nTool sets : Python, R, MATLAB or  any AI frame work, Neural network, Gen AI, LLM\nContact Details:\n\nRecruitment Team\nMindpro Technologies Pvt Ltd (www.mindprotech.com)\n+91-04324-240904 / +91-9600672304",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Gen AI', 'Statistical Modeling', 'LLM', 'Predictive Modeling', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Machine Learning', 'Deep Learning', 'Python']",2025-06-12 14:12:41
Data Scientist,Big Oh Tech,4 - 6 years,Not Disclosed,['Noida'],"Key Responsibilities:\n\nDesign, build, and maintain robust and scalable data pipelines to support analytics and reporting needs.\nManage and optimize data lake architectures, with a focus on Apache Atlas for metadata management, data lineage, and governance.\nIntegrate and curate data from multiple structured and unstructured sources to enable advanced analytics.\nCollaborate with data scientists and business analysts to ensure availability of clean, well-structured data.\nImplement data quality, validation, and monitoring processes across data pipelines.\nDevelop and manage Power BI datasets and data models, supporting dashboard and report creation.\nSupport data cataloging and classification using Apache Atlas for enterprise-wide discoverability and compliance.\nEnsure adherence to data security, privacy, and compliance policies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['advanced analytics', 'metadata', 'Compliance', 'Business Analyst', 'data security', 'power bi', 'Data quality', 'Management', 'Apache', 'Monitoring']",2025-06-12 14:12:43
Senior BUSINESS INTELLIGENCE CONSULTANT II,Lumen Technologies,8 - 12 years,Not Disclosed,['Bengaluru'],"The Senior Business Intelligence Consultant will be a member of the Enterprise Operations Team at Lumen and will be responsible for designing, developing, and deploying interactive and automated reports and dashboards using Power BI, analyzing data to identify trends, and translating business needs into effective data visualizations. He or she will be leading data analysis, developing BI solutions, mentoring junior analysts, and ensuring data quality, ultimately driving data-driven decision-making and business insights.\nRequired skills:\n8 to 12+ years of hands-on experience in PowerBI, writing SQL queries and MSOffice tools like Excel and PowerPoint\nShould have worked closely with stakeholders to understand their business problems and translate them into actionable data requirements\nPossess a strong understanding of data warehousing, data modeling, and BI technologies.\nDevelop and maintain SQL queries and ETL processes to extract, transform, and load data\nProficient in Data Collection from various sources and cleaning and repairing them for accurate and relevant analysis.\nShould be very good at applying statistical methods and data analysis techniques to identify trends, patterns and helpful insights, providing data-driven insights to support business decisions.\nCreating clear, concise and actionable reports and presenting findings and recommendations to stakeholders in a clear and concise manner.\nVery proficient in the usage of PowerBI to create reports and dashboards that effectively communicate findings, identify potential issues and opportunities.\nStrong communication skills and customer focus\nSelf-motivated, detail orientated, highly organized and able to handle a variety of tasks and responsibilities in an efficient manner with a high level of quality\nExperience of working in a Managed Services organization\n\n""We are an equal opportunity employer committed to fair and ethical hiring practices. We do not charge any fees or accept any form of payment from candidates at any stage of the recruitment process. If anyone claims to offer employment opportunities in our company in exchange for money or any other benefit, please treat it as fraudulent and report it immediately.""",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL queries', 'Usage', 'Claims', 'Managed services', 'Data modeling', 'Data collection', 'power bi', 'Data quality', 'Business intelligence', 'Recruitment']",2025-06-12 14:12:46
MDM Data Scientist,Amgen Inc,4 - 9 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nWe are seeking an accomplished and visionary Data Scientist/ GenAIdeveloper to join Amgens Enterprise Data Management team. As part of MDM team, you will be responsible for designing, developing, and deploying Generative AI and ML models to power data-driven decisions across business domains. This role is ideal for an AI practitioner who thrives in a collaborative environment and brings a strategic mindset to applying advanced AI techniques to solve real-world problems.\nTo succeed in this role, the candidate must have strong AI/ML, Data Science, GenAI experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have AI/ML, data science and GenAI experience on technologies like (PySpark/PyTorch, TensorFlow, LLM, Autogen, Hugging FaceVectorDB,Embeddings, RAGsetc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nDevelop enterprise-level GenAI applications using LLM frameworks such as Langchain, Autogen, and Hugging Face.\nDesign and develop intelligent pipelines using PySpark, TensorFlow, and PyTorch within Databricks and AWS environments.\nImplement embedding models andmanage VectorStores for retrieval-augmented generation (RAG) solutions.\nIntegrate and leverage MDM platforms like Informatica and Reltio to supply high-quality structured data to ML systems.\nUtilize SQL and Python for data engineering, data wrangling, and pipeline automation.\nBuild scalable APIs and services to serve GenAI models in production.\nLead cross-functional collaboration with data scientists, engineers, and product teams to scope, design, and deploy AI-powered systems.\nEnsure model governance, version control, and auditability aligned with regulatory and compliance expectations.\nBasic Qualifications and Experience:\nMasters degree with 4 - 6 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 6 - 9 years of experience in Business, Engineering, IT or related field OR\nDiploma with 10 - 12 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n6+ years of experience working in AI/ML or Data Science roles, including designing and implementing GenAI solutions.\nExtensive hands-on experience with LLM frameworks and tools such as Langchain, Autogen, Hugging Face, OpenAI APIs, and embedding models.\nStrong programming background with Python, PySpark, and experience in building scalable solutions using TensorFlow, PyTorch, and SK-Learn.\nProven track record of building and deploying AI/ML applications in cloud environments such as AWS.\nExpertise in developing APIs, automation pipelines, and serving GenAI models using frameworks like Django, FastAPI, and DataBricks.\nSolid experience integrating and managing MDM tools (Informatica/Reltio) and applying data governance best practices.\nGuide the team on development activities and lead the solution discussions\nMust have core technical capabilities in GenAI, Data Science space\nGood-to-Have Skills:\nPrior experience in Data Modeling, ETL development, and data profiling to support AI/ML workflows.\nWorking knowledge of Life Sciences or Pharma industry standards and regulatory considerations.\nProficiency in tools like JIRA and Confluence for Agile delivery and project collaboration.\nFamiliarity with MongoDB, VectorStores, and modern architecture principles for scalable GenAI applications.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nData Science and ML Certification\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'GenAI', 'Langchain', 'PySpark', 'Hugging Face', 'OpenAI API', 'Autogen', 'PyTorch', 'Django', 'MDM', 'FastAPI', 'Data Modeling', 'ETL', 'TensorFlow', 'Python']",2025-06-12 14:12:48
MDM Data Scientist,Amgen Inc,3 - 8 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nWe are seeking an accomplished and visionary Data Scientist/ GenAIdeveloper to join Amgens Enterprise Data Management team. As part of MDM team, you will be responsible for designing, developing, and deploying Generative AI and ML models to power data-driven decisions across business domains. This role is ideal for an AI practitioner who thrives in a collaborative environment and brings a strategic mindset to applying advanced AI techniques to solve real-world problems.To succeed in this role, the candidate must have strong AI/ML, Data Science, GenAI experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have AI/ML, data science and GenAI experience on technologies like (PySpark/PyTorch, TensorFlow, LLM, Autogen, Hugging FaceVectorDB,Embeddings, RAGsetc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nDevelop enterprise-level GenAI applications using LLM frameworks such as Langchain, Autogen, and Hugging Face.\nDesign and develop intelligent pipelines using PySpark, TensorFlow, and PyTorch within Databricks and AWS environments.\nImplement embedding models andmanage VectorStores for retrieval-augmented generation (RAG) solutions.\nIntegrate and leverage MDM platforms like Informatica and Reltio to supply high-quality structured data to ML systems.\nUtilize SQL and Python for data engineering, data wrangling, and pipeline automation.\nBuild scalable APIs and services to serve GenAI models in production.\nLead cross-functional collaboration with data scientists, engineers, and product teams to scope, design, and deploy AI-powered systems.\nEnsure model governance, version control, and auditability aligned with regulatory and compliance expectations.\nBasic Qualifications and Experience:\nMasters degree with 4 - 6 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 6 - 9 years of experience in Business, Engineering, IT or related field OR\nDiploma with 10 - 12 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n6+ years of experience working in AI/ML or Data Science roles, including designing and implementing GenAI solutions.\nExtensive hands-on experience with LLM frameworks and tools such as Langchain, Autogen, Hugging Face, OpenAI APIs, and embedding models.\nStrong programming background with Python, PySpark, and experience in building scalable solutions using TensorFlow, PyTorch, and SK-Learn.\nProven track record of building and deploying AI/ML applications in cloud environments such as AWS.\nExpertise in developing APIs, automation pipelines, and serving GenAI models using frameworks like Django, FastAPI, and DataBricks.\nSolid experience integrating and managing MDM tools (Informatica/Reltio) and applying data governance best practices.\nGuide the team on development activities and lead the solution discussions\nMust have core technical capabilities in GenAI, Data Science space\nGood-to-Have Skills:\nPrior experience in Data Modeling, ETL development, and data profiling to support AI/ML workflows.\nWorking knowledge of Life Sciences or Pharma industry standards and regulatory considerations.\nProficiency in tools like JIRA and Confluence for Agile delivery and project collaboration.\nFamiliarity with MongoDB, VectorStores, and modern architecture principles for scalable GenAI applications.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nData Science and ML Certification\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams\nWe will ensure that individuals with disabilities are provided with reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MDM', 'GenAI', 'Langchain', 'PySpark', 'VectorStores', 'Hugging Face', 'LLM', 'Data Science', 'DataBricks', 'SK-Learn', 'AI/ML', 'Autogen', 'PyTorch', 'Django', 'OpenAI APIs', 'FastAPI', 'MongoDB', 'Data Modeling', 'PySpark/PyTorch', 'TensorFlow', 'Python']",2025-06-12 14:12:50
Senior Data Engineer : 7+ Years,Jayam Solutions Pvt Ltd - CMMI Level III Company,5 - 9 years,Not Disclosed,['Hyderabad( Madhapur )'],"Job Description:\nPosition: Sr.Data Engineer\nExperience: Minimum 7 years\nLocation: Hyderabad\nJob Summary:\n\nWhat Youll Do\n\nDesign and build efficient, reusable, and reliable data architecture leveraging technologies like Apache Flink, Spark, Beam and Redis to support large-scale, real-time, and batch data processing.\nParticipate in architecture and system design discussions, ensuring alignment with business objectives and technology strategy, and advocating for best practices in distributed data systems.\nIndependently perform hands-on development and coding of data applications and pipelines using Java, Scala, and Python, including unit testing and code reviews.\nMonitor key product and data pipeline metrics, identify root causes of anomalies, and provide actionable insights to senior management on data and business health.\nMaintain and optimize existing datalake infrastructure, lead migrations to lakehouse architectures, and automate deployment of data pipelines and machine learning feature engineering requests.\nAcquire and integrate data from primary and secondary sources, maintaining robust databases and data systems to support operational and exploratory analytics.\nEngage with internal stakeholders (business teams, product owners, data scientists) to define priorities, refine processes, and act as a point of contact for resolving stakeholder issues.\nDrive continuous improvement by establishing and promoting technical standards, enhancing productivity, monitoring, tooling, and adopting industry best practices.\n\nWhat Youll Bring\n\nBachelors degree or higher in Computer Science, Engineering, or a quantitative discipline, or equivalent professional experience demonstrating exceptional ability.\n7+ years of work experience in data engineering and platform engineering, with a proven track record in designing and building scalable data architectures.\nExtensive hands-on experience with modern data stacks, including datalake, lakehouse, streaming data (Flink, Spark), and AWS or equivalent cloud platforms.\nCloud - AWS\nApache Flink/Spark , Redis\nDatabase platform- Databricks.\nProficiency in programming languages such as Java, Scala, and Python(Good to have) for data engineering and pipeline development.\nExpertise in distributed data processing and caching technologies, including Apache Flink, Spark, and Redis.\nExperience with workflow orchestration, automation, and DevOps tools (Kubernetes,git,Terraform, CI/CD).\nAbility to perform under pressure, managing competing demands and tight deadlines while maintaining high-quality deliverables.\nStrong passion and curiosity for data, with a commitment to data-driven decision making and continuous learning.\nExceptional attention to detail and professionalism in report and dashboard creation.\nExcellent team player, able to collaborate across diverse functional groups and communicate complex technical concepts clearly.\nOutstanding verbal and written communication skills to effectively manage and articulate the health and integrity of data and systems to stakeholders.\n\nPlease feel free to contact us: 9440806850\nEmail ID : careers@jayamsolutions.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Apache Flink', 'Redis', 'Spark', 'Python', 'SCALA', 'Ci/Cd', 'Devops', 'AWS']",2025-06-12 14:12:52
Data Scientist IV - Python / LLM,Sadup Soft,6 - 8 years,Not Disclosed,['Hyderabad'],"Must have skills :\n\n- 6+ Years of Experience.\n\n- Statics, SQL, Big query, LLM, AI, Python\n\n- Work experience in the payments, ecommerce, or financial services industry is a plus .\n\nResponsibilities :\n\n- At least 6 years of experience analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions\n\n- Bachelor's/Master's degree in a quantitative field (such as Analytics, Statistics, Mathematics, Economics or Engineering) or equivalent field experience\n\n- Advanced SQL experience, preferable with Big Query analytics (Google Cloud) on Jupyter Notebooks and experience analyzing very large, complex, multi-dimensional data sets.\n\n- Understanding of statistics (e.g hypothesis testing, statistical inference, regression) and experience designing and evaluating complex experiments-\n\n- Ability to solve problems analytically and create actionable recommendations\n\n- Advanced ability to use reporting tools like Tableau and/or Excel to share analysis\n\n- Strong written and verbal communication skills with the ability to translate complex problems into simpler terms, expertise in stitching together findings to convey coherent insights and effectively influence both peers and senior leadership\n\n- Prior work experience in a product analytics space would be highly valued\n\n- A passion for problem-solving and comfort with ambiguity\n\n- Work experience in the payments, ecommerce, or financial services industry is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Data Science', 'BigQuery', 'Data Management', 'Jupyter', 'LLM', 'Statistics']",2025-06-12 14:12:54
Specialist Data Scientist,Atlasrtx,3 - 7 years,Not Disclosed,['Pune'],"So, what s the role all about\n\nNICE provides state-of-the-art enterprise level AI and analytics for all forms of business communications between speech and digital. We are a world class research team developing new algorithms and approaches to help companies with solving critical issues such as identifying their best performing agents, preventing fraud, categorizing customer issues, and determining overall customer satisfaction. If you have interacted with a major contact center in the last decade, it is very likely we have processed your call.\n\nThe research group partners with all areas of NICE s business to scale out the delivery of new technology and AI models to customers around the world that are tailored to their company, industry, and language needs.\n\n\nHow will you make an impact\n\nConduct cutting-edge research and develop advanced NLP algorithms and models.\n\nBuild and fine-tune deep learning and machine learning models, with a focus on large language models.\n\nWork closely with internal stakeholders to define model requirements and ensure alignment with business objectives.\n\nDevelop AI predictive models and perform data and model accuracy analyses.\n\nProduce and present findings, technical concepts, and model recommendations to both technical and non-technical stakeholders.\n\nDevelop and maintain scripts/tools to automate both new model production and updates to existing model packages.\n\nStay abreast of the latest advancements in data science research and contribute to the development of our knowledge base.\n\nCollaborate with developers to design automation and tool improvements for model building.\n\nMaintain documentation of processes and projects across all supported languages and environments.\n\n\nHave you got what it takes\n\nMasters degree in the field of Computer Science, Technology, Engineering, Math, or equivalent practical experience\n\nMinimum of 8 years of data science work experience, including implementing machine learning and NLP models using real-life data.\n\nExperience with Retrieval-Augmented Generation (RAG) pipelines or LLMOps.\n\nAdvanced knowledge of statistics and machine learning algorithms.\n\nProficiency in Python programming and familiarity with R.\n\nExperience with deep learning models and libraries such as PyTorch, TensorFlow, and JAX.\n\nFamiliarity with relational databases and query languages (e. g. , MSSQL) and basic SQL knowledge.\n\nHands-on experience with transformer models (BERT, FlanT5, Llama, etc. ) and GenAI frameworks (HuggingFace, LangChain, Ollama, etc. ).\n\nExperience deploying NLP models in production environments, ensuring scalability and performance using AWS/GCP/Azure\n\nStrong verbal and written communication skills, including effective presentation abilities.\n\nAbility to work independently and as part of a team, demonstrating analytical thinking and problem-solving skills.\n\n\n\nYou will have an advantage if you also have:\n\nExpertise with Big Data technologies (e. g. , PySpark).\n\nBackground in knowledge graphs, graph databases, or GraphRAG architectures.\n\nUnderstanding of multimodal models (text, audio, vision).\n\nExperience in Customer Experience domains.\n\nExperience with package development and technical writing.\n\nFamiliarity with tools like Jira, Confluence, and source control packages and methodology.\n\nKnowledge and interest in foreign languages and linguistics.\n\nExperience working on international, globe-spanning teams and with AWS.\n\nPast participation in a formal research setting.\n\nExperience as part of a software organization.\n\n\n\nWhat s in it for you\n\n\n\nEnjoy NICE-FLEX!\n\n\n\nRequisition ID : 7481\nReporting into : Tech Manager\nRole Type : Individual Contributor\n\nAbout NICE",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Technical writing', 'GCP', 'Analytical', 'Machine learning', 'Flex', 'Analytics', 'SQL', 'Python']",2025-06-12 14:12:57
Financial Data Specialist,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: RRS(RRS)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies:\nStrong understanding of fundamental finance and financial statements.\nGood understanding of capital markets.\nStrong organizational skills and attention to detail.\nAbility to work effectively in a collaborative team environment.\nProficient in technical and operational aspects of assigned deliverables.\nExcellent Microsoft Office skills, particularly advanced Microsoft Excel skills.\nFluency in English with advanced written and verbal communication skills; advanced interpersonal skills.\nEducation:\nBachelors/masters in engineering, Finance, Economics, or Business/Accounting.\nExperience Required:\nRelevant experience of 2+ years in credit/financial data analysis and interpretation\nExperience in fundamental finance or accounting or previous experience analyzing financial statements is an advantage\nResponsibilities:\nPerform analysis to support ratings, research, and analytical outreach.\nWork independently on complex deliverables such as loss given default, speculative grade liquidity information, or basic credit estimates.\nApply Moodys Investors Service standards to complex deliverables to produce valuable inputs into the rating and research process, including adjusted data, key indicators, ratios, charts, and graphs.\nPerform complex data intake tasks, including scrubbing and validating data for further use in research and ratings.\nReview and understand financial reports, official statements, and other documents related to issuers performance.\nLiaise with analysts and accounting specialists to understand the application of accounting concepts on a particular entity.\nWork directly with ratings and support analysts to understand data capture requirements, adjustments, and other information needed by the rating team for ratings and research.\nTake initiative to lead projects or process improvements.\nUndertake review of more junior team members work for straightforward tasks.\nAbout the team: Our Fundamental Rating Group team is responsible for performing a range of data, analytical, and research services that contribute to the overall credit analysis function. By joining our team, you will be part of exciting work in enhancing Moodys digital presence and improving customer engagement.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['remediation', 'Data analysis', 'Excel', 'Financial reporting', 'Accounting', 'Analytical', 'Credit analysis', 'Financial statement analysis', 'Customer engagement', 'Operations']",2025-06-12 14:12:59
Provider Data Management (US Healthcare),Careerguideline,1 - 5 years,1-5 Lacs P.A.,['Bengaluru'],Currently we are looking for *Provider Data Management* to join our team!\nBangalore\n\n*Provider Data Management*\n* 2 - 4 years of experience\n* Package is up to 5LPA\n* Work from office\n* US shift timing\n* 2 way cab provided\n* Immediate joiners (15days notice period considerable)\n\n**Requirements for SPE:**\n* 2 to 4 years of Provider Data Management.\n* Any Graduate.\n* Must have all respective documents.\n\n\nInterested candidates Contact HR Nikkitha @ 8655884774/ nikkitha@careeerguideline.com and also refer to the people who are seeking for job,Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Provider Data Management', 'provider data analyst', 'provider data asscociate', 'provider', 'PDM', 'US Healthcare']",2025-06-12 14:13:01
Data Visualization Expert - Manager,_VOIS,7 - 12 years,Not Disclosed,"['Pune', 'Bengaluru']","Data Visualization & UI/UX Designer (PowerBI & Power Solutions)\n\nAbout VOIS\n\nVOIS (Vodafone Intelligent Solutions) is a strategic arm of Vodafone Group Plc, creating value and enhancing quality and efficiency across 28 countries, and operating from 7 locations: Albania, Egypt, Hungary, India, Romania, Spain and the UK.\nOver 29,000 highly skilled individuals are dedicated to being Vodafone Groups partner of choice for talent, technology, and transformation. We deliver the best services across IT, Business Intelligence Services, Customer Operations, Business Operations, HR, Finance, Supply Chain, HR Operations, and many more.\nEstablished in 2006, _VOIS has evolved into a global, multi-functional organisation, a Centre of Excellence for Intelligent Solutions focused on adding value and delivering business outcomes for Vodafone.\n\nVOIS India\nIn 2009, VOIS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 14,500 employees, _VOIS India supports global markets and group functions of Vodafone and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Business), Intelligent Operations, Finance Operations, Supply Chain Operations and HR Operations and more.\n\nLocation: Pune / Bangalore\nWorking Persona: Hybrid\n\nRole Purpose:\nTalented and experienced Data Visualization and UI/UX Expert to join our dynamic team. In this role, you will play a pivotal role in creating compelling, user-friendly data visualizations and ensuring an exceptional user experience across our digital platforms. As a key member of our team, you will collaborate with various stakeholders to translate complex data into visually engaging and informative designs.\n\nKey Responsibilities:\nData Visualization:\no Create interactive and visually appealing data visualizations using tools such as PowerBI,\nPower BI, Power Solutions, or other relevant platforms.o Transform complex data sets into\neasy-to-understand charts, graphs, and dashboards.\no Ensure data accuracy, consistency, and integrity in visualizations.\nUI/UX Design:\no Design and implement user interfaces for web and mobile applications that prioritize user\nexperience and usability.\no Conduct user research, usability testing, and gather feedback to iterate on designs.\no Collaborate with front-end developers to ensure seamless integration of UI/UX designs.\nCollaboration:\no Work closely with cross-functional teams, including data analysts, developers, and product managers, to understand project requirements and objectives.\no Communicate design concepts and rationale effectively to both technical and non-technical stakeholders.\nContinuous Improvement:\no Stay updated with industry trends and best practices in data visualization and UI/UX design.\no Propose and implement improvements to existing visualizations and designs.\n\nQualifications:\nBachelor's degree in Graphic Design, HCI, Computer Science, or related field (Master's\ndegree preferred).\nProven experience in data visualization and UI/UX design, with a strong portfolio\nshowcasing your work.\nProficiency in data visualization tools (e.g., Power BI) and design tools (e.g., Adobe Creative\nSuite, Sketch, Figma).\nStrong understanding of usability principles, user-centered design, and information\narchitecture.\nFamiliarity with HTML, CSS, and JavaScript for UI implementation.\nExcellent communication and collaboration skills.\n\nVOIS Equal Opportunity Employer Commitment\nVOIS is proud to be an Equal Employment Opportunity Employer. We celebrate differences and we welcome and value diverse people and insights. We believe that being authentically human and inclusive powers our employees growth and enables them to create a positive impact on themselves and society. We do not discriminate based on age, colour, gender (including pregnancy, childbirth, or related medical conditions), gender identity, gender expression, national origin, race, religion, sexual orientation, status as an individual with a disability, or other applicable legally protected characteristics.\nAs a result of living and breathing our commitment, our employees have helped us get certified as a Great Place to Work in India for four years running. We have been also highlighted among the Top 5 Best Workplaces for Diversity, Equity, and Inclusion, Top 10 Best Workplaces for Women, Top 25 Best Workplaces in IT & IT-BPM and 14th Overall Best Workplaces in India by the Great Place to Work Institute in 2023. These achievements position us among a select group of trustworthy and high-performing companies which put their employees at the heart of everything they do.\n\nBy joining us, you are part of our commitment. We look forward to welcoming you into our family which represents a variety of cultures, backgrounds, perspectives, and skills!\n\nApply now, and well be in touch!",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Visualization', 'SQL', 'Figma', 'Tableau', 'Qlik', 'Dashboard Development', 'Adobe Creative Suite']",2025-06-12 14:13:04
Snowflake Data Engineer,Tredence,3 - 8 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\n\nDesign, build, and maintain scalable data pipelines using DBT and Airflow.\nDevelop and optimize SQL queries and data models in Snowflake.\nImplement ETL/ELT workflows, ensuring data quality, performance, and reliability.\nWork with Python for data processing, automation, and integration tasks.\nHandle JSON data structures for data ingestion, transformation, and APIs.\nLeverage AWS services (e.g., S3, Lambda, Glue, Redshift) for cloud-based data solutions. Collaborate with data analysts, engineers, and business teams to deliver high-quality data products.",,,,"['Snowflake', 'DBT', 'SQL']",2025-06-12 14:13:07
Immediate Opening For Data Science,Happiest Minds Technologies,8 - 13 years,Not Disclosed,['Bengaluru( Madiwala )'],"Machine Learning, Deep Learning models, Data Science. (Important);-R / python programming (mandatory) ;- Fast API development ;- deployment of models experience ; - any cloud Azure (good to have - for this requirement); - basics of Generative AI , NLP (optional - Good to have)\n\nGIS data, Geospatial data, Google Maps, ArcGIS, Demand pattern analysis\n\n5 to 15 Yrs",,,,"['Data Science', 'Machine Learning', 'Deep Learning', 'Python', 'GenAi', 'Natural Language Processing']",2025-06-12 14:13:09
Data Science Lead,Protiviti India,9 - 14 years,25-40 Lacs P.A.,['Mumbai (All Areas)'],"Role & responsibilities\n8+ year bachelors or master’s degree from reputed University with concentration on finance, economics or other quantitative field such as statistics or engineering.\nManage multiple client engagements in Financial Services locally in India\nActively drive pre-sales, sales activities primarily for FS clients locally in Data Science Domain\nUnderstand client requirements in detail and create technical & commercial proposal\nDrive client conversations specifically for business development activities",,,,"['Data Science', 'Natural Language Processing', 'Presales', 'Machine Learning', 'AWS', 'GCP', 'Cloud Platform', 'Python']",2025-06-12 14:13:11
Data Engineer II - Marketplace (Experimentation Track),Booking Holdings,5 - 10 years,Not Disclosed,['Bengaluru'],"We are looking for a Data Engineer to join our team and help us to improve the platform that supports one of the best experimentation tools in the world.\nYou will work side by side with other data engineers and site reliability engineers to improve the reliability, scalability, maintenance and operations of all the data products that are part of the experimentation tool at Booking.com.\nYour day to day work includes but is not limited to: maintenance and operations of data pipelines and products that handles data at big scale; the development of capabilities for monitoring, alerting, testing and troubleshooting of the data ecosystem of the experiment platform; and the delivery of data products that produce metrics for experimentation at scale. You will collaborate with colleagues in Amsterdam to achieve results the right way. This will include engineering managers, product managers, engineers and data scientists.\nKey Responsibilities and Duties\nTake ownership of multiple data pipelines and products and provide innovative solutions to reduce the operational workload required to maintain them\nRapidly developing next-generation scalable, flexible, and high-performance data pipelines.\nContribute to the development of data platform capabilities such as testing, monitoring, debugging and alerting to improve the development environment of data products\nSolve issues with data and data pipelines, prioritizing based on customer impact.\nEnd-to-end ownership of data quality in complex datasets and data pipelines.\nExperiment with new tools and technologies, driving innovative engineering solutions to meet business requirements regarding performance, scaling, and data quality.\nProvide self-organizing tools that help the analytics community discover data, assess quality, explore usage, and find peers with relevant expertise.\nServe as the main point of contact for technical and business stakeholders regarding data engineering issues, such as pipeline failures and data quality concerns\nRole requirements\nMinimum 5 years of hands-on experience in data engineering as a Data Engineer or as a Software Engineer developing data pipelines and products.\nBachelors degree in Computer Science, Computer or Electrical Engineering, Mathematics, or a related field or 5 years of progressively responsible experience in the specialty as equivalent\nSolid experience in at least one programming language. We use Java and Python\nExperience building production data pipelines in the cloud, setting up data-lakes and server-less solutions\nHands-on experience with schema design and data modeling\nExperience designing systems E2E and knowledge of basic concepts (lb, db, caching, NoSQL, etc)\nKnowledge of Flink, CDC, Kafka, Airflow, Snowflake, DBT or equivalent tools\nPractical experience building data platform capabilities like testing, alerting, monitoring, debugging, security\nExperience working with big data.\nExperience working with teams located in different timezones is a plus\nExperience with experimentation, statistics and A/B testing is a plus",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Airflow', 'Java', 'CDC', 'NoSQL', 'Snowflake', 'DBT', 'Kafka', 'Python']",2025-06-12 14:13:13
Tech. PM - Data Engineering-Data Analytics@ Gurgaon/Blore_Urgent,A global leader in delivering innovative...,5 - 10 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Job Title - Technical Project Manager\n\nLocation - Gurgaon/ Bangalore\n\nNature of Job - Permanent\n\nDepartment - data analytics\n\nWhat you will be doing\n\n\nDemonstrated client servicing and business analytics skills with at least 5 - 9 years of experience as data engineer, BI developer, data analyst, technical project manager, program manager etc.\nTechnical project management- drive BRD, project scope, resource allocation, team\ncoordination, stakeholder communication, UAT, Prod fix, change requests, project governance\nSound knowledge of banking industry (payments, retail operations, fraud etc.)\nStrong ETL experience or experienced Teradata developer\nManaging team of business analysts, BI developers, ETL developers to ensure that projects are completed on time\nResponsible for providing thought leadership and technical advice on business issues\nDesign methodological frameworks and solutions.\n\n\nWhat were looking for\n\n\nBachelors/masters degree in computer science/data science/AI/statistics, Certification in Gen AI. Masters degree Preferred.\nManage multiple projects, at a time, from inception to delivery\nSuperior problem-solving, analytical, and quantitative skills\nEntrepreneurial mindset, coupled with a “can do” attitude\nDemonstrated ability to collaborate with cross-functional, cross-border teams and coach / mentor colleagues.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Technical Project Manager', 'Data Engineering', 'multiple projects', 'Technical project management', 'Data Analytics', 'project scope', 'ETL Pipeline', 'team coordination', 'resource allocation', 'Prod fix', 'drive BRD', 'program manager', 'Big data']",2025-06-12 14:13:16
Anonymized Patient Level Data (APLD),Product & Service,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Description\nFunctional Responsibilities\nDevelop and execute approaches to analyze variety of Healthcare and Life sciences datasets, primarily creating reports on exploratory data analysis and statistical reports\nStrong proficiency with manipulating data with PL-SQL ( ORACLE 11g)\nA high comfort level with data manipulation and extraction of meaningful insights from large data and prior experience of working with IMS Health data assets or Patient level data (APLD) data is a plus.\nExperience with SQL/SAS/WPS is acceptable.\nMinimum 3 to 5 years of experience of working with pharmaceutical databases, including patient level transactional data, Claim analytics is preferred.\nBeing creative in identifying new techniques and processes to streamline and increase efficiency and effectiveness of current work-streams is a plus.\nHigh level of attention to detail and problem solving\nExposure on various Healthcare data sources like SHS, IQVIA, DRG , Labcorp, Flatiron Experion etc\nHave strong experience claims data and worked on various patient level data analytics like Adherence Studites, Line of therapy and Treatment Path analysis.\nExperienced on HEOR studies.\nPreference will be given to applicants with a demonstrated ability to work independently, take initiative, and manage responsibilities on multiple projects simultaneously.\nProfessional requirement\nPost graduate degree in Economics, MBA, Statistics, Mathematics, Operations Research, Quantitative Analysis, or related field\nWell-organized, capable of handling several projects at a time while meeting deadlines\n3-5 years of consolidated work experience in Analytic Industry.\nStrong statistical and quantitative analysis skills. Knowledge of Statistical Analysis for\nAdvanced knowledge of PL/SQL and experience with statistical packages such as R/SAS Strong problem solving skills\nExcellent data interpretation skills. Experience in using charting/reporting\nSkilled in MS-Office, specifically Excel and Powerpoint\nShould have strong knowledge of Healthcare domain OR any specific knowledge on Retail and FMCG/CPG industry will be an added advantage.\nKnowledge on Pharmaceutical Rx claims/ Medical claims will be an added advantage\nIntermediate to advanced proficiency in Excel and VBA\nAutomate data analysis in support of the client offices principals and consultants\nUtilize SAS/WPS/R to create and automate analytical and modeling processes\nPreference will be given to applicants with a demonstrated ability to work independently, take initiative, and manage responsibilities on multiple projects simultaneously",Industry Type: Software Product,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['SAS', 'Apld', 'SQL', 'Python', 'R']",2025-06-12 14:13:18
Data Engineer-Having Stratup-Mid-Size company Exp.@ Bangalore_Urgent,"As a leader in this space, we deliver wo...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Engineer\n\nLocation: Bangalore - Onsite\nExperience: 8 - 15 years\nType: Full-time\n\nRole Overview\n\nWe are seeking an experienced Data Engineer to build and maintain scalable, high-performance data pipelines and infrastructure for our next-generation data platform. The platform ingests and processes real-time and historical data from diverse industrial sources such as airport systems, sensors, cameras, and APIs. You will work closely with AI/ML engineers, data scientists, and DevOps to enable reliable analytics, forecasting, and anomaly detection use cases.\nKey Responsibilities\nDesign and implement real-time (Kafka, Spark/Flink) and batch (Airflow, Spark) pipelines for high-throughput data ingestion, processing, and transformation.\nDevelop data models and manage data lakes and warehouses (Delta Lake, Iceberg, etc) to support both analytical and ML workloads.\nIntegrate data from diverse sources: IoT sensors, databases (SQL/NoSQL), REST APIs, and flat files.\nEnsure pipeline scalability, observability, and data quality through monitoring, alerting, validation, and lineage tracking.\nCollaborate with AI/ML teams to provision clean and ML-ready datasets for training and inference.\nDeploy, optimize, and manage pipelines and data infrastructure across on-premise and hybrid environments.\nParticipate in architectural decisions to ensure resilient, cost-effective, and secure data flows.\nContribute to infrastructure-as-code and automation for data deployment using Terraform, Ansible, or similar tools.\n\n\nQualifications & Required Skills\n\nBachelors or Master’s in Computer Science, Engineering, or related field.\n6+ years in data engineering roles, with at least 2 years handling real-time or streaming pipelines.\nStrong programming skills in Python/Java and SQL.\nExperience with Apache Kafka, Apache Spark, or Apache Flink for real-time and batch processing.\nHands-on with Airflow, dbt, or other orchestration tools.\nFamiliarity with data modeling (OLAP/OLTP), schema evolution, and format handling (Parquet, Avro, ORC).\nExperience with hybrid/on-prem and cloud platforms (AWS/GCP/Azure) deployments.\nProficient in working with data lakes/warehouses like Snowflake, BigQuery, Redshift, or Delta Lake.\nKnowledge of DevOps practices, Docker/Kubernetes, Terraform or Ansible.\nExposure to data observability, data cataloging, and quality tools (e.g., Great Expectations, OpenMetadata).\nGood-to-Have\nExperience with time-series databases (e.g., InfluxDB, TimescaleDB) and sensor data.\nPrior experience in domains such as aviation, manufacturing, or logistics is a plus.\n\nRole & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['aviation', 'Data Modeling', 'Python', 'OLAP', 'Cloud', 'ORC', 'logistics', 'Avro', 'Terraform', 'Snowflake', 'manufacturing', 'AWS', 'Parquet', 'Java', 'Azure', 'BigQuery', 'Data', 'Redshift', 'SQL', 'TimescaleDB', 'GCP', 'InfluxDB', 'dbt', 'Ansible', 'OLTP', 'Kubernetes']",2025-06-12 14:13:20
Data Engineer,Talent Aspire,2 - 7 years,Not Disclosed,"['Chandigarh', 'Bengaluru']","As the Data Engineer, you will play a pivotal role in shaping our data infrastructure and\nexecuting against our strategy. You will ideate alongside engineering, data and our clients to\ndeploy data products with an innovative and meaningful impact to clients. You will design, build, and maintain scalable data pipelines and workflows on AWS. Additionally, your expertise in AI and machine learning will enhance our ability to deliver smarter, more predictive solutions.\n\nKey Responsibilities\nCollaborate with other engineers, customers to brainstorm and develop impactful data\nproducts tailored to our clients.\nLeverage AI and machine learning techniques to integrate intelligent features into our\nofferings.\nDevelop, and optimize end-to-end data pipelines on AWS\nFollow best practices in software architecture and development.\nImplement effective cost management and performance optimization strategies.\nDevelop and maintain systems using Python, SQL, PySpark, and Django for front-end\ndevelopment.\nWork directly with clients and end-users and address their data needs\nUtilize databases and tools including and not limited to, Postgres, Redshift, Airflow, and\nMongoDB to support our data ecosystem.\nLeverage AI frameworks and libraries to integrate advanced analytics into our solutions.\nQualifications\n\nExperience:\nMinimum of 3 years of experience in data engineering, software development, or\nrelated roles.\nProven track record in designing and deploying AWS cloud infrastructure\nsolutions\nAt least 2 years in data analysis and mining techniques to aid in descriptive and\ndiagnostic insights\nExtensive hands-on experience with Postgres, Redshift, Airflow, MongoDB, and\nreal-time data workflows.\n\nTechnical Skills:\nExpertise in Python, SQL, and PySpark\nStrong background in software architecture and scalable development practices.\nTableau, Metabase or similar viz tools experience\nWorking knowledge of AI frameworks and libraries is a plus.\nLeadership & Communication:\nDemonstrates ownership and accountability for delivery with a strong\ncommitment to quality.\nExcellent communication skills with a history of effective client and end-user\nengagement.\nStartup & Fintech Mindset:\nAdaptability and agility to thrive in a fast-paced, early-stage startup environment.\nPassion for fintech innovation and a strong desire to make a meaningful impact\non the future of finance.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'performance optimization strategies', 'PySpark', 'Django', 'cost management', 'AWS', 'AI frameworks', 'Python', 'SQL']",2025-06-12 14:13:22
Data Engineering Manager,NOVARTIS,6 - 8 years,Not Disclosed,['Hyderabad'],"Summary\nWe are seeking a highly skilled and motivated GCP Data Engineering Manager to join our dynamic team. As a Data Engineering manager specializing in Google Cloud Platform (GCP), you will play a crucial role in designing, implementing, and maintaining scalable data pipelines and\nsystems. You will leverage your expertise in Google Big Query, SQL, Python, and analytical skills to drive data-driven decision-making processes and support various business functions.\nAbout the Role\nKey Responsibilities:\nData Pipeline Development: Design, develop, and maintain robust data pipelines using GCP services like Dataflow, Dataproc, ensuring high performance and scalability.\nGoogle Big Query Expertise: Utilize your hands-on experience with Google Big Query to manage and optimize data storage, retrieval, and processing.\nSQL Proficiency: Write and optimize complex SQL queries to transform and analyze large datasets, ensuring data accuracy and integrity.\nPython Programming: Develop and maintain Python scripts for data processing, automation, and integration with other systems and tools.\nData Integration: Collaborate with data analysts, and other stakeholders to integrate data from various sources, ensuring seamless data flow and consistency.\nData Quality and Governance: Implement data quality checks, validation processes, and governance frameworks to maintain high data standards.\nPerformance Tuning: Monitor and optimize the performance of data pipelines, queries, and storage solutions to ensure efficient data processing.\nDocumentation: Create comprehensive documentation for data pipelines, processes, and best practices to facilitate knowledge sharing and team collaboration.\nMinimum Qualifications:\nProven experience (minimum 6 - 8 yrs) in Data Engineer, with significant hands-on experience in Google Cloud Platform (GCP) and Google Big Query.\nProficiency in SQL for data transformation, analysis and performance optimization.\nStrong programming skills in Python, with experience in developing data processing scripts and automation.\nProven analytical skills with the ability to interpret complex data and provide actionable insights.\nExcellent problem-solving abilities and attention to detail.\nStrong communication and collaboration skills, with the ability to work effectively in a team enviro\nDesired Skills :\nExperience with Google Analytics data and understanding of digital marketing data.\nFamiliarity with other GCP services such as Cloud Storage, Dataflow, Pub/Sub, and Dataproc.\nKnowledge of data visualization tools such as Looker, Tableau, or Data Studio.\nExperience with machine learning frameworks and libraries.\nWhy Novartis: Helping people with disease and their families takes more than innovative science. It takes a community of smart, passionate people like you. Collaborating, supporting and inspiring each other. Combining to achieve breakthroughs that change patients lives. Ready to create a brighter future together? https://www. novartis. com / about / strategy / people-and-culture\nJoin our Novartis Network: Not the right Novartis role for you? Sign up to our talent community to stay connected and learn about suitable career opportunities as soon as they come up: https://talentnetwork. novartis. com/network\nBenefits and Rewards: Read our handbook to learn about all the ways we ll help you thrive personally and professionally:",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Performance tuning', 'Automation', 'Google Analytics', 'Machine learning', 'Data processing', 'Data quality', 'data visualization', 'Digital marketing', 'SQL', 'Python']",2025-06-12 14:13:24
Data Engineer - Databricks,Inorg,2 - 5 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']",InOrg Global is looking for Data Engineer - Databricks to join our dynamic team and embark on a rewarding career journey.\n\nLiaising with coworkers and clients to elucidate the requirements for each task.\nConceptualizing and generating infrastructure that allows big data to be accessed and analyzed.\nReformulating existing frameworks to optimize their functioning.\nTesting such structures to ensure that they are fit for use.\nPreparing raw data for manipulation by data scientists.\nDetecting and correcting errors in your work.\nEnsuring that your work remains backed up and readily accessible to relevant coworkers.\nRemaining up - to - date with industry standards and technological advancements that will improve the quality of your outputs.,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent",['Data Engineer - Databricks'],2025-06-12 14:13:26
Senior Data Engineer,Conviction HR,8 - 10 years,Not Disclosed,"['Kolkata', 'Hyderabad', 'Pune( Malad )']","Must have -Azure Data Factory (Mandatory). Azure Databricks, Pyspark and Python and advance SQL Azure eco-system. 1) Advanced SQL Skills. 2)Data Analysis. 3) Data Models. 4) Python (Desired). 5) Automation - Experience required : 8 to 10 years.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Data Engineering', 'Python', 'Azure Databricks', 'Data Modeling', 'Data Bricks', 'SQL']",2025-06-12 14:13:28
GCP Data Engineer,Swits Digital,4 - 6 years,Not Disclosed,['Bengaluru'],"Job Title: GCP Data Engineer\nLocation: Chennai, Bangalore, Hyderabad\nExperience: 4-6 Years\nJob Summary:\nWe are seeking a GCP Data & Cloud Engineer with strong expertise in Google Cloud Platform services, including BigQuery, Cloud Run, Cloud Storage , and Pub/Sub . The ideal candidate will have deep experience in SQL coding , data pipeline development, and deploying cloud-native solutions.\nKey Responsibilities:\nDesign, implement, and optimize scalable data pipelines and services using GCP\nBuild and manage cloud-native applications deployed via Cloud Run\nDevelop complex and performance-optimized SQL queries for analytics and data transformation\nManage and automate data storage, retrieval, and archival using Cloud Storage\nImplement event-driven architectures using Google Pub/Sub\nWork with large datasets in BigQuery , including ETL/ELT design and query optimization\nEnsure security, monitoring, and compliance of cloud-based systems\nCollaborate with data analysts, engineers, and product teams to deliver end-to-end cloud solutions\nRequired Skills & Experience:\n4 years of experience working with Google Cloud Platform (GCP)\nStrong proficiency in SQL coding , query tuning, and handling complex data transformations\nHands-on experience with:\nBigQuery\nCloud Run\nCloud Storage\nPub/Sub\nUnderstanding of data pipeline and ETL/ELT workflows in cloud environments\nFamiliarity with containerized services and CI/CD pipelines\nExperience in scripting languages (e.g., Python, Shell) is a plus\nStrong analytical and problem-solving skills",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SUB', 'query optimization', 'GCP', 'Analytical', 'Cloud', 'query', 'cloud storage', 'Analytics', 'SQL coding', 'Python']",2025-06-12 14:13:31
Gcp Data Engineer,Saama Technologies,3 - 8 years,Not Disclosed,"['Pune', 'Chennai', 'Coimbatore']","We are looking for immediate joiners only.\nPosition: GCP Data Engineer\nWe are seeking a skilled and experienced GCP Data Engineer to join our dynamic team. The ideal candidate will have a strong background in Google Cloud Platform (GCP), BigQuery, Dataform, and data warehouse concepts. Experience with Airflow/Cloud Composer and cloud computing knowledge will be a significant advantage.\nResponsibilities:\n- Designing, developing, and maintaining data pipelines and workflows on the Google Cloud Platform.",,,,"['Pyspark', 'GCP', 'Python', 'SQL', 'Google Cloud Platforms']",2025-06-12 14:13:33
Azure Data Engineer ( Azure Databricks),Apex One,4 - 8 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Job Summary\nWe are seeking a skilled Azure Data Engineer with 4 years of overall experience, including at least 2 years of hands-on experience with Azure Databricks (Must). The ideal candidate will have strong expertise in building and maintaining scalable data pipelines and working across cloud-based data platforms.\nKey Responsibilities\nDesign, develop, and optimize large-scale data pipelines using Azure Data Factory, Azure Databricks, and Azure Synapse.\nImplement data lake solutions and work with structured and unstructured datasets in Azure Data Lake Storage (ADLS).\nCollaborate with data scientists, analysts, and engineering teams to design and deliver end-to-end data solutions.\nDevelop ETL/ELT processes and integrate data from multiple sources.\nMonitor, debug, and optimize workflows for performance and cost-efficiency.\nEnsure data governance, quality, and security best practices are maintained.\nMust-Have Skills\n4+ years of total experience in data engineering.\n2+ years of experience with Azure Databricks (PySpark, Notebooks, Delta Lake).\nStrong experience with Azure Data Factory, Azure SQL, and ADLS.\nProficient in writing SQL queries and Python/Scala scripting.\nUnderstanding of CI/CD pipelines and version control systems (e.g., Git).\nSolid grasp of data modeling and warehousing concepts.",Industry Type: Management Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure', 'Azure Data Factory', 'SQL queries', 'PySpark', 'Delta Lake', 'Azure Databricks', 'Notebooks', 'Azure SQL']",2025-06-12 14:13:36
Data Engineer with Neo4j,Luxoft,3 - 5 years,Not Disclosed,['Gurugram'],"Graph Data Modeling & Implementation.\nDesign and implement complex graph data models using Cypher and Neo4j best practices.\nLeverage APOC procedures, custom plugins, and advanced graph algorithms to solve domain-specific problems.\nOversee integration of Neo4j with other enterprise systems, microservices, and data platforms.\nDevelop and maintain APIs and services in Java, Python, or JavaScript to interact with the graph database.\nMentor junior developers and review code to maintain high-quality standards.\nEstablish guidelines for performance tuning, scalability, security, and disaster recovery in Neo4j environments.\nWork with data scientists, analysts, and business stakeholders to translate complex requirements into graph-based solutions.\nSkills\nMust have\n12+ years in software/data engineering, with at least 3-5 years hands-on experience with Neo4j.\nLead the technical strategy, architecture, and delivery of Neo4j-based solutions.\nDesign, model, and implement complex graph data structures using Cypher and Neo4j best practices.\nGuide the integration of Neo4j with other data platforms and microservices.\nCollaborate with cross-functional teams to understand business needs and translate them into graph-based models.\nMentor junior developers and ensure code quality through reviews and best practices.\nDefine and enforce performance tuning, security standards, and disaster recovery strategies for Neo4j.\nStay up-to-date with emerging technologies in the graph database and data engineering space.\nStrong proficiency in Cypher query language, graph modeling, and data visualization tools (e.g., Bloom, Neo4j Browser).\nSolid background in Java, Python, or JavaScript and experience integrating Neo4j with these languages.\nExperience with APOC procedures, Neo4j plugins, and query optimization.\nFamiliarity with cloud platforms (AWS) and containerization tools (Docker, Kubernetes).\nProven experience leading engineering teams or projects.\nExcellent problem-solving and communication skills.\nNice to have\nN/A\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Flexera Data Analyst\nData Science\nIndia\nBengaluru\nSenior Flexera Data Analyst\nData Science\nIndia\nChennai\nData Scientist\nData Science\nIndia\nBengaluru\nGurugram, India\nReq. VR-114556\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114556\nApply for Data Engineer with Neo4j in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'query optimization', 'neo4j', 'data science', 'Data modeling', 'Disaster recovery', 'Javascript', 'Data structures', 'data visualization', 'Python']",2025-06-12 14:13:38
Data Engineer with Neo4j,Luxoft,3 - 5 years,Not Disclosed,['Bengaluru'],"Graph Data Modeling & Implementation.\nDesign and implement complex graph data models using Cypher and Neo4j best practices.\nLeverage APOC procedures, custom plugins, and advanced graph algorithms to solve domain-specific problems.\nOversee integration of Neo4j with other enterprise systems, microservices, and data platforms.\nDevelop and maintain APIs and services in Java, Python, or JavaScript to interact with the graph database.\nMentor junior developers and review code to maintain high-quality standards.\nEstablish guidelines for performance tuning, scalability, security, and disaster recovery in Neo4j environments.\nWork with data scientists, analysts, and business stakeholders to translate complex requirements into graph-based solutions.\nSkills\nMust have\n12+ years in software/data engineering, with at least 3-5 years hands-on experience with Neo4j.\nLead the technical strategy, architecture, and delivery of Neo4j-based solutions.\nDesign, model, and implement complex graph data structures using Cypher and Neo4j best practices.\nGuide the integration of Neo4j with other data platforms and microservices.\nCollaborate with cross-functional teams to understand business needs and translate them into graph-based models.\nMentor junior developers and ensure code quality through reviews and best practices.\nDefine and enforce performance tuning, security standards, and disaster recovery strategies for Neo4j.\nStay up-to-date with emerging technologies in the graph database and data engineering space.\nStrong proficiency in Cypher query language, graph modeling, and data visualization tools (e.g., Bloom, Neo4j Browser).\nSolid background in Java, Python, or JavaScript and experience integrating Neo4j with these languages.\nExperience with APOC procedures, Neo4j plugins, and query optimization.\nFamiliarity with cloud platforms (AWS) and containerization tools (Docker, Kubernetes).\nProven experience leading engineering teams or projects.\nExcellent problem-solving and communication skills.\nNice to have\nN/A\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Flexera Data Analyst\nData Science\nIndia\nGurugram\nSenior Flexera Data Analyst\nData Science\nIndia\nChennai\nBusiness Analyst\nData Science\nPoland\nRemote Poland\nBengaluru, India\nReq. VR-114556\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114556\nApply for Data Engineer with Neo4j in Bengaluru\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'query optimization', 'neo4j', 'data science', 'Data modeling', 'Disaster recovery', 'Javascript', 'Data structures', 'data visualization', 'Python']",2025-06-12 14:13:40
Data Engineer with Neo4j,Luxoft,3 - 5 years,Not Disclosed,['Chennai'],"Graph Data Modeling & Implementation.\nDesign and implement complex graph data models using Cypher and Neo4j best practices.\nLeverage APOC procedures, custom plugins, and advanced graph algorithms to solve domain-specific problems.\nOversee integration of Neo4j with other enterprise systems, microservices, and data platforms.\nDevelop and maintain APIs and services in Java, Python, or JavaScript to interact with the graph database.\nMentor junior developers and review code to maintain high-quality standards.\nEstablish guidelines for performance tuning, scalability, security, and disaster recovery in Neo4j environments.\nWork with data scientists, analysts, and business stakeholders to translate complex requirements into graph-based solutions.\nSkills\nMust have\n12+ years in software/data engineering, with at least 3-5 years hands-on experience with Neo4j.\nLead the technical strategy, architecture, and delivery of Neo4j-based solutions.\nDesign, model, and implement complex graph data structures using Cypher and Neo4j best practices.\nGuide the integration of Neo4j with other data platforms and microservices.\nCollaborate with cross-functional teams to understand business needs and translate them into graph-based models.\nMentor junior developers and ensure code quality through reviews and best practices.\nDefine and enforce performance tuning, security standards, and disaster recovery strategies for Neo4j.\nStay up-to-date with emerging technologies in the graph database and data engineering space.\nStrong proficiency in Cypher query language, graph modeling, and data visualization tools (e.g., Bloom, Neo4j Browser).\nSolid background in Java, Python, or JavaScript and experience integrating Neo4j with these languages.\nExperience with APOC procedures, Neo4j plugins, and query optimization.\nFamiliarity with cloud platforms (AWS) and containerization tools (Docker, Kubernetes).\nProven experience leading engineering teams or projects.\nExcellent problem-solving and communication skills.\nNice to have\nN/A\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Flexera Data Analyst\nData Science\nIndia\nGurugram\nSenior Flexera Data Analyst\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nChennai, India\nReq. VR-114556\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114556\nApply for Data Engineer with Neo4j in Chennai\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'query optimization', 'neo4j', 'data science', 'Data modeling', 'Disaster recovery', 'Javascript', 'Data structures', 'data visualization', 'Python']",2025-06-12 14:13:42
Mis Executive (Goregaon - Mumbai) Fresher Also Can apply,Rigved Technologies,0 - 4 years,1.25-3 Lacs P.A.,['Mumbai (All Areas)'],"Dear Candidates,\n\nWe are hiring for the position of  ""MIS Executive"", Kindly find below details.\n\nPayroll Company Name                   : Rigved Technologies  (https://www.rigvedtech.com/)\n\nClient                                                   : Bank  \n\nJob Location                                      : Goregaon, Mumbai \n\nExperience Required                         : 0 - 2Years \n\nDesignation                                       : MIS Executive\n\nRequired Skills:\nAdvanced proficiency in Microsoft Excel (Pivot Tables, VLOOKUP/XLOOKUP, INDEX-MATCH, Charts, Conditional Formatting, etc.)\nExperience with data visualization and dashboard creation\nGood understanding of data analysis techniques\nStrong attention to detail and accuracy\nAbility to handle confidential data responsibly\nBasic knowledge of Excel.\nKnowledge of Power Query and Power BI is an added advantage\n\n\nINTEERSTED CANDIDATE CAN SHARE RESUME ON anshu.baranwal@rigvedtech.com",Industry Type: Recruitment / Staffing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Excel', 'MIS', 'VLOOKUP']",2025-06-12 14:13:44
E-Commerce Analyst,Exotic Mile,1 - 5 years,Not Disclosed,['Gurugram'],"Role & responsibilities\n\nMonitor and analyze daily, weekly, and monthly performance of e-commerce platforms (e.g., website, marketplaces).\nProvide insights into customer behavior, conversion rates, and key funnel metrics.\nTrack and report KPIs such as sales performance, traffic sources, bounce rates, cart abandonment, AOV, etc.\nIdentify trends, gaps, and opportunities to optimize performance and user experience.\nSupport marketing teams with campaign analysis, ROI tracking, and audience segmentation.\nCollaborate with product and UX teams to test hypotheses and recommend data-backed improvements.\nDevelop and maintain dashboards and automated reports using tools like Excel, Google Analytics,\nEnsure data accuracy and integrity across various platforms",Industry Type: Internet (E-Commerce),"Department: Merchandising, Retail & eCommerce","Employment Type: Full Time, Permanent","['Ecommerce', 'Analyst', 'Pricing Analysis', 'forecasting', 'Trend analysis', 'p&l', 'Data Analysis', 'Advanced Excel']",2025-06-12 14:13:46
Research Analyst - Writer,Panacorp Software Solutions,1 - 3 years,Not Disclosed,['Nagercoil'],"The Research Analyst in PhD Assistance supports academic research by gathering and analyzing data, conducting literature reviews, and preparing reports. This role helps PhD candidates and faculty members by ensuring high-quality, evidence-based research work.\n\nRoles & Responsibilities:\n\nLiterature Reviews & Data Collection:\nConduct thorough literature reviews to gather relevant academic resources.\nCollect and organize research data from various sources.\n\nData Analysis:\nAnalyze quantitative and qualitative data using research tools and software.\nSummarize findings to support research projects.\n\nReport Preparation:\nCreate detailed research reports, summaries, and presentations.\nAssist in preparing materials for academic publications and grant proposals.\n\nResearch Support:\nCollaborate with PhD candidates and faculty to refine research methodologies.\nProvide technical assistance and guidance in research best practices.\n\nDatabase & Documentation Management:\nMaintain organized records and databases of research materials.\nEnsure all research processes meet academic standards and documentation practices.",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['research analysis', 'research writing', 'Research Support', 'Documentation Management', 'research reports']",2025-06-12 14:13:48
Commercial Business Systems Manager,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"In this role, you will:\nEvaluate moderately complex business problems and provide technical assistance in identifying automated systems and related procedures that are cost effective and meet business requirements\nReview and evaluate moderately complex technical business problems that can be resolved through internet or intranet based solutions\nPresent recommendations for resolving business problems",,,,"['Business Systems Data', 'system analysis', 'project management', 'data analysis', 'business system', 'business analysis']",2025-06-12 14:13:51
Analyst Programmer,Fidelity International,2 - 4 years,Not Disclosed,['Gurugram'],"Title Analyst Programmer\nDepartment AMO (ISS) Production Support\nLocation Gurugram\nLevel 2\nAbout Fidelity International:\nFidelity International offers investment solutions and services and retirement expertise to more than 2.56 million customers globally. As a privately-held, purpose-driven company with a 50-year heritage, we think generationally and invest for the long term. Operating in more than 25 locations and with $783.6 billion in total assets, our clients range from central banks, sovereign wealth funds, large corporates, financial institutions, insurers and wealth managers, to private individuals.\nOur Workplace & Personal Financial Health business provides individuals, advisers and employers with access to world-class investment choices, third-party solutions, administration services and pension guidance. Together with our Investment Solutions & Services business, we invest $567 billion on behalf of our clients. By combining our asset management expertise with our solutions for workplace and personal investing, we work together to build better financial futures.\nOur clients come from all walks of life and so do we. We are proud of our inclusive culture and encourage applications from the widest mix of talent, whatever your age, gender, ethnicity, sexual orientation, gender identity, social background and more. We are a disability-friendly company and would welcome a conversation with you if you feel you might benefit from any reasonable adjustments to perform to the best of your ability during the recruitment process and beyond.\nWe are committed to being a truly flexible employer, encouraging and trusting our people to perform their role in the way that works best for them, our business, our colleagues and our clients. We offer the maximum possible flexibility over where and when you work for all, considering your role and any local regulations. We call this new approach dynamic working .\nDepartment Description:\nAMO (ISS) production support consists of applications like Global Fund Data Repository (GFDR), Product hub, Performance Hub, Product (FRD), Reference Data Service, Transaction Service, Position Service, Frontier, Fund Distribution Service etc. architecture and engineering services that comprises of various Fidelity s Business Units in the UK and other parts of Europe, Asia and is a strategic area targeted for growth over the coming years. Various key systems have been acting as the key enablers for the business in achieving their goals. The Enterprise portfolio of projects will include a large collection of strategic initiatives as well as tactical ones to support day-to-day operations and strengthen the environment. The support team aims at supporting & maintaining global data warehouse acting as the single source of data for various line of business s to help them in the MI reporting requirements and data analysis. This source of data is considered as the golden source for distribution data and helps various business groups across organization to take knowledge based decisions.\nPurpose of the Role:\nThe position is for an Application Programmer in AMO production Support team. The role involves supporting key AMO - Enterprise applications and data marts involving strong PL/SQL and stored procedure knowledge on Oracle database platform. The candidate should have high expertise and core skills of Informatica and UNIX shell script. In addition, hands-on experience with Control-M technologies would be a plus. The successful candidate will be responsible to support for consumption of downstream feeds and applications in varied technologies. This would also involve intensive interaction with the business and other systems groups, so good communications skills and the ability to work under pressure are absolute must.\nKey Responsibilities:\nThe candidate is expected to display professional ethics in his/her approach to work and exhibit a high level ownership within a demanding working environment.\nProviding first line of technical support for business critical applications (Principal technologies / applications used include Oracle, UNIX , PaaS, Python, Java and Control-M).\nWork in the support team alongside data analysts, business analysts, database administrators and business project teams in enhancing and supporting the production services.\nHelp maintain Control-M schedules.\nConduct analysis and do bug fixes for production incidents. Carry out technical enhancements as desired.\nCarry out daily health-check activities involving application checks, system checks, and database checks and related on production systems / servers.\nThe scope of responsibility also covers monitoring business critical batch workloads, real-time / interactive processing, data transfer services, application on-boarding and upgrades, and recovery procedures.\nReport root cause of the incidents and present ideas on how to prevent the incidents from occurring in future.\nEnsure adherence to incident and change management processes. Regular engagement with Business & Systems Teams looking to adopt and apply the best practice of Service Support.\nPrepares and maintains documentation related application support like SOM, Service Card, Support Rota, Knowledge base, etc.\nDemonstrates continuous effort to improve operations, decrease turnaround times, streamline work processes, and work cooperatively and jointly to provide quality seamless customer service.\nResponsible for servicing 24x7 support as per support rosters.\nFlexibility to work in shifts ( on-demand & short-term basis), and/or on weekends.\nExperience and Qualifications Required:\nAround 2 - 4 years of technical experience in Software / IT industry in Development and Support functions\nMinimum 2 - 4 years of support experience in Production Support roles\nEssential Technical skills:\nAt least 2-4 years of Oracle experience with strong focus on SQL. PL/SQL knowledge is good to have.\nBasic understanding of PaaS technology, Python, Core Java and web services/ REST API.\nShould have core skills of UNIX shell script.\nEssential behavioural/operational skills:\nAbility to apply new skills / additional information acquired in relation to role.\nAbility to interact with end users/business users.\nAbility to work closely with cross functional teams including Infrastructure teams/Architects/Business Analysts.\nAbility to prioritise own activities, work under hard deadlines.\nTeam player with commitment to achieve team goals.\nMotivated, flexible and with a can do approach.\nKeen to learn and develop proficiency\nGood communication skills both verbal and written.\nDelivery and results focused.\nGood to have technical skills:\nHands-on experience with scheduling tools - Control-M would be a definite plus.\nExperience in informatica is good to have.\nExperience of any source control tool - SVN would be a plus.\nGood Operating Systems knowledge and associated commands (UNIX [Linux/AIX], MS Windows).\nFamiliarity in Data Warehouse, Datamart and ODS concepts.\nKnowledge of essential Software Engineering principles.\nKnowledge of ITIL practices.",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Unix', 'Aix', 'Core Java', 'Linux', 'Production support', 'PLSQL', 'Informatica', 'Oracle', 'Technical support', 'Python']",2025-06-12 14:13:53
Research Analyst 2,Demandbase,4 - 7 years,Not Disclosed,['Hyderabad'],"Introduction to Demandbase:\nDemandbase is the Smarter GTM company for B2B brands. We help marketing and sales teams overcome the disruptive data and technology fragmentation that inhibits insight and forces them to spam their prospects. We do this by injecting Account Intelligence into every step of the buyer journey, wherever our clients interact with customers, and by helping them orchestrate every action across systems and channels - through advertising, account-based experience, and sales motions. The result? You spot opportunities earlier, engage with them more intelligently, and close deals faster.\nAs a company, we re as committed to growing careers as we are to building world-class technology. We invest heavily in people, our culture, and the community around us. We have offices in the San Francisco Bay Area, New York, Seattle, and teams in the UK and India . We have also been continuously recognized as one of the best places to work in the San Francisco Bay Area.\nWere committed to attracting, developing, retaining, and promoting a diverse workforce. By ensuring that every Demandbase employee is able to bring a diversity of talents to work, were increasingly capable of living out our mission to transform how B2B goes to market. We encourage people from historically underrepresented backgrounds and all walks of life to apply. Come grow with us at Demandbase!\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented Research Analyst 2 to join our dynamic team. This role is crucial for driving informed business decisions through data gathering, analysis, and insightful reporting. The ideal candidate will possess a strong understanding of business research methodologies, data analysis techniques, and a passion for data accuracy and problem-solving.\nKey Responsibilities:\nConduct Comprehensive Data Research and Analysis: Source, collate, research, and analyze data from diverse business information sources and specialized databases to generate actionable insights.\nDrive Data-Driven Decision Making: Experienced in performing in-depth analysis to identify trends, anomalies, and root causes. Translate findings into recommendations that enhance product value and business growth.\nEnsure Data Quality and Integrity: Apply problem-solving skills to resolve data queries, conduct rigorous quality checks, and identify and address data coverage gaps.\nDocument and Strategically Analyze: Understand and document business requirements and KPIs, create functional specifications, and conduct competitor and vendor analysis for strategic insights.Convert complex data and findings into easily understandable tables, graphs, and well-structured written reports.\nRequired Skills & Experience:\nBachelor s or Master s degree in Business or Commerce\n4-7 years of relevant work experience\nProven experience in business/secondary research\nProficiency in MS Office, particularly Excel\nExperience in using data visualization tools and generating insightful reports.\nExcellent reporting writing skills\nExcellent communication skills, both written and verbal, with the ability to articulate thoughts clearly and understand others effectively (a portion of this job may be customer-facing)\nSelf-organized and self-driven, with strong personal integrity\nDetail-oriented and highly analytical approach to problem-solving\nGreat interpersonal skills\nPassion for content accuracy and data integrity\nAbility to work in a fast-paced, high-scale data environment.\nOur Commitment to Diversity, Equity, and Inclusion at Demandbase\nAt Demandbase, we believe in creating a workplace culture that values and celebrates diversity in all its forms. We recognize that everyone brings unique experiences, perspectives, and identities to the table, and we are committed to building a community where everyone feels valued, respected, and supported. Discrimination of any kind is not tolerated, and we strive to ensure that every individual has an equal opportunity to succeed and grow, regardless of their gender identity, sexual orientation, disability, race, ethnicity, background, marital status, genetic information, education level, veteran status, national origin, or any other protected status. We do not automatically disqualify applicants with criminal records and will consider each applicant on a case-by-case basis.\nWe recognize that not all candidates will have every skill or qualification listed in this job description. If you feel you have the level of experience to be successful in the role, we encourage you to apply!\nWe acknowledge that true diversity and inclusion require ongoing effort, and we are committed to doing the work required to make our workplace a safe and equitable space for all. Join us in building a community where we can learn from each other, celebrate our differences, and work together.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.",Industry Type: Advertising & Marketing,Department: Research & Development,"Employment Type: Full Time, Permanent","['SAN', 'Data analysis', 'Business research', 'Analytical', 'Diversity and Inclusion', 'Data quality', 'MS Office', 'Research Analyst', 'Analyst 2', 'Secondary research']",2025-06-12 14:13:55
"Analyst - Metrics, Analytics & Reporting",Oliver Wyman,3 - 6 years,Not Disclosed,['Noida'],"1: The main responsibility is to track and co-ordinate Client employee benefits insurance policy renewals and broking implementations across the different client locations\nManage the timeliness and quality of Client deliverables - before, during and after renewal or implementation Work with the consultants to develop reporting and presentations for Client meetings based on client requirements Perform quality checks (by more experienced colleagues) Lead Implementation and Onboarding processes\nData entry and high level analysis - assist the Consulting team in gathering, organizing, validating, entering and analyzing data using GBM Analytics (Mercer proprietary software) for the various clients\nProvide high level data analysis including sanity check for employee headcount movement, related premium change by line of coverage, etc. Liaise with local brokers on renewal strategy if needed, to ensure the Rules of the Road are followed Manage ad-hoc client requests including problem-solving on administrative and operations issues - source the details from System Admin Team and local brokers, when needed Route enquiries to the correct point of contact and provide timely follow up and responses for the Clients Liaising with local brokers to gather information not captured by GBM Analytics including the nature of local discussions impacting the insurance placement or plan design strategy Provide reporting from GBM Analytics or excel for clients as required.\nMaintain relationship with MCG team and ensure client expectations are met.\n*Note that this role will work with the GBM/Consulting team, System Admin Team, local brokers and in some cases regional (RBM) teams and might have direct Client contact in the future.\n70%\n2 : GBMA and Mercer Gold+ Platform Management Support for System Admin Team.\nComplete assigned tasks in GBM Analytics and data entry as required into that tool. This includes initiating renewals in the application and following up with local brokers to ensure they complete their GBM Analytics tasks in an accurate and timely manner Update relevant Insurance financial and plan design data on MG+ based on policy documents and reports supplied by local broking teams. Clarify information with local brokers when necessary and ensure broker peer review is obtained.\n20%\n3 : Assistance with overall GBM intellectual capital (projects).\nTo include assistance building a qualitative assessment of insurers, hot topics by country, and other items as needed.\n10%",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Administration', 'analytics reporting', 'Data analysis', 'Finance', 'Consulting', 'Management', 'Analytics', 'System Administrator', 'Data entry', 'Investment']",2025-06-12 14:13:58
Research Analyst - Writer,Panacorp Software Solutions,1 - 3 years,2-3 Lacs P.A.,['Kanyakumari'],"The Research Analyst in PhD Assistance supports academic research by gathering and analyzing data, conducting literature reviews, and preparing reports. This role helps PhD candidates and faculty members by ensuring high-quality, evidence-based research work.\n\nRoles & Responsibilities:\n\nLiterature Reviews & Data Collection:\nConduct thorough literature reviews to gather relevant academic resources.\nCollect and organize research data from various sources.\n\nData Analysis:\nAnalyze quantitative and qualitative data using research tools and software.\nSummarize findings to support research projects.\n\nReport Preparation:\nCreate detailed research reports, summaries, and presentations.\nAssist in preparing materials for academic publications and grant proposals.\n\nResearch Support:\nCollaborate with PhD candidates and faculty to refine research methodologies.\nProvide technical assistance and guidance in research best practices.\n\nDatabase & Documentation Management:\nMaintain organized records and databases of research materials.\nEnsure all research processes meet academic standards and documentation practices.",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['Research Analysis', 'creative writing', 'blog writing', 'content development', 'technical writing', 'research writing', 'article writing', 'academic writing', 'content writing', 'content editing', 'proofreading', 'copy editing']",2025-06-12 14:14:00
Analytics and Modeling Analyst,Overture Rede,1 - 3 years,Not Disclosed,['Hyderabad'],"Job Role ( 20 Words)Enable data-driven sales operations by creating reports, supporting communication, and tracking opportunities to drive sales performance.\n\nKey Responsibilities\nGenerate actionable sales insights and dashboardsSupport communication between teams and track sales KPIsWork cross-functionally to improve data accuracy and reporting workflowsRespond to queries and assist in driving sales enablement strategies\n\nRequired Skills\n3+ years in data analysis and sales operations\nProficient in Excel (functions, Power Query, Power Pivot); Power BI preferred\nStrong communication and client support skills\nExperience in Software & Platforms industry a plus\nUnderstanding of data/cloud infrastructure products\nFlexible with working hours, strong stakeholder management\nStrong in collaboration, problem-solving, and process orientation\n",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Sales operations', 'Process orientation', 'Senior Analyst', 'sales enablement', 'Client support', 'Infrastructure', 'power bi', 'Stakeholder management', 'Analytics']",2025-06-12 14:14:02
Analytics and Modeling Analyst,Overture Rede,1 - 3 years,Not Disclosed,['New Delhi'],"\nWere hiring an Analytics and Modeling Analyst to support B2B sales enablement with actionable insights, custom reporting, and data-driven recommendations that fuel revenue growth.Key ResponsibilitiesGenerate insightful sales reports and analyticsCustomize dashboards for strategic decision-makingTrack sales opportunities and highlight risksSupport sales meetings and document insightsAddress data queries and recommend improvements\n\nRequired Skills\n3+ years in data analysis or sales operations\nStrong in Excel, Power Query, Power Pivot, Power BI\nUnderstanding of Software & Platforms, cloud/data products\nExcellent communication and stakeholder management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Excel', 'Sales operations', 'Senior Analyst', 'sales enablement', 'query', 'power bi', 'B2B Sales', 'Stakeholder management', 'Analytics']",2025-06-12 14:14:05
Senior Officer,Max Life Insurance,0 - 5 years,Not Disclosed,['Hyderabad'],"Max Life Insurance Company Limited is looking for Senior Officer to join our dynamic team and embark on a rewarding career journey\nLeadershipProvide leadership and guidance to team members, fostering a positive work environment\nLead by example, demonstrating professionalism, integrity, and dedication to the organization's goals and values\nProject ManagementManage and coordinate projects from initiation to completion, ensuring adherence to timelines and budget constraints\nDevelop project plans, allocate resources, and monitor progress to achieve project objectives\nIdentify and mitigate risks to project success, implementing appropriate solutions as needed\nOperational EfficiencyStreamline processes and procedures to improve operational efficiency and effectiveness\nIdentify opportunities for automation or technological enhancements to optimize workflow and productivity\nCollaborate with cross-functional teams to implement process improvements and best practices\nData Analysis and ReportingAnalyze data to identify trends, patterns, and insights relevant to the organization's objectives\nGenerate reports and presentations to communicate findings and recommendations to key stakeholders\nUtilize data-driven insights to inform decision-making and drive continuous improvement initiatives\nStakeholder EngagementBuild and maintain relationships with internal and external stakeholders, including clients, partners, and vendors\nCollaborate with stakeholders to understand their needs and requirements, ensuring alignment with organizational objectives\nEffectively communicate project updates, issues, and resolutions to stakeholders, fostering transparency and trust\nCompliance and Risk ManagementEnsure compliance with relevant laws, regulations, and internal policies and procedures\nProactively identify and address potential risks and compliance issues, implementing appropriate controls and safeguards\nKeep abreast of industry developments and best practices to inform risk management strategies",Industry Type: Insurance,Department: Other,"Employment Type: Full Time, Permanent","['insurance', 'vendor management', 'visualforce', 'project management', 'sap', 'sfdc', 'purchase', 'triggers', 'javascript', 'apex', 'kaizen', 'salesforce', 'salesforce crm', 'sales force development', 'data loader', 'operations', 'compliance', 'procurement', 'quality assurance', 'html']",2025-06-12 14:14:07
Senior Officer,Max Life Insurance,0 - 5 years,Not Disclosed,['Chennai'],"Max Life Insurance Company Limited is looking for Senior Officer to join our dynamic team and embark on a rewarding career journey\nLeadershipProvide leadership and guidance to team members, fostering a positive work environment\nLead by example, demonstrating professionalism, integrity, and dedication to the organization's goals and values\nProject ManagementManage and coordinate projects from initiation to completion, ensuring adherence to timelines and budget constraints\nDevelop project plans, allocate resources, and monitor progress to achieve project objectives\nIdentify and mitigate risks to project success, implementing appropriate solutions as needed\nOperational EfficiencyStreamline processes and procedures to improve operational efficiency and effectiveness\nIdentify opportunities for automation or technological enhancements to optimize workflow and productivity\nCollaborate with cross-functional teams to implement process improvements and best practices\nData Analysis and ReportingAnalyze data to identify trends, patterns, and insights relevant to the organization's objectives\nGenerate reports and presentations to communicate findings and recommendations to key stakeholders\nUtilize data-driven insights to inform decision-making and drive continuous improvement initiatives\nStakeholder EngagementBuild and maintain relationships with internal and external stakeholders, including clients, partners, and vendors\nCollaborate with stakeholders to understand their needs and requirements, ensuring alignment with organizational objectives\nEffectively communicate project updates, issues, and resolutions to stakeholders, fostering transparency and trust\nCompliance and Risk ManagementEnsure compliance with relevant laws, regulations, and internal policies and procedures\nProactively identify and address potential risks and compliance issues, implementing appropriate controls and safeguards\nKeep abreast of industry developments and best practices to inform risk management strategies",Industry Type: Insurance,Department: Other,"Employment Type: Full Time, Permanent","['insurance', 'vendor management', 'visualforce', 'project management', 'sap', 'sfdc', 'purchase', 'triggers', 'javascript', 'apex', 'kaizen', 'salesforce', 'salesforce crm', 'sales force development', 'data loader', 'operations', 'compliance', 'procurement', 'quality assurance', 'html']",2025-06-12 14:14:10
Data Visualization Expert - Deputy Manager,_VOIS,5 - 9 years,Not Disclosed,"['Pune', 'Bengaluru']","Data Visualization & UI/UX Designer (PowerBI & Power Solutions)\n\nAbout VOIS\n\nVOIS (Vodafone Intelligent Solutions) is a strategic arm of Vodafone Group Plc, creating value and enhancing quality and efficiency across 28 countries, and operating from 7 locations: Albania, Egypt, Hungary, India, Romania, Spain and the UK.\nOver 29,000 highly skilled individuals are dedicated to being Vodafone Groups partner of choice for talent, technology, and transformation. We deliver the best services across IT, Business Intelligence Services, Customer Operations, Business Operations, HR, Finance, Supply Chain, HR Operations, and many more.\nEstablished in 2006, _VOIS has evolved into a global, multi-functional organisation, a Centre of Excellence for Intelligent Solutions focused on adding value and delivering business outcomes for Vodafone.\n\nVOIS India\nIn 2009, VOIS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 14,500 employees, _VOIS India supports global markets and group functions of Vodafone and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Business), Intelligent Operations, Finance Operations, Supply Chain Operations and HR Operations and more.\n\nLocation: Pune / Bangalore\nWorking Persona: Hybrid\n\nRole Purpose:\nTalented and experienced Data Visualization and UI/UX Expert to join our dynamic team. In this role, you will play a pivotal role in creating compelling, user-friendly data visualizations and ensuring an exceptional user experience across our digital platforms. As a key member of our team, you will collaborate with various stakeholders to translate complex data into visually engaging and informative designs.\n\nKey Responsibilities:\nData Visualization:\no Create interactive and visually appealing data visualizations using tools such as PowerBI,\nPower BI, Power Solutions, or other relevant platforms.o Transform complex data sets into\neasy-to-understand charts, graphs, and dashboards.\no Ensure data accuracy, consistency, and integrity in visualizations.\nUI/UX Design:\no Design and implement user interfaces for web and mobile applications that prioritize user\nexperience and usability.\no Conduct user research, usability testing, and gather feedback to iterate on designs.\no Collaborate with front-end developers to ensure seamless integration of UI/UX designs.\nCollaboration:\no Work closely with cross-functional teams, including data analysts, developers, and product managers, to understand project requirements and objectives.\no Communicate design concepts and rationale effectively to both technical and non-technical stakeholders.\nContinuous Improvement:\no Stay updated with industry trends and best practices in data visualization and UI/UX design.\no Propose and implement improvements to existing visualizations and designs.\n\nQualifications:\nBachelor's degree in Graphic Design, HCI, Computer Science, or related field (Master's\ndegree preferred).\nProven experience in data visualization and UI/UX design, with a strong portfolio\nshowcasing your work.\nProficiency in data visualization tools (e.g., Power BI) and design tools (e.g., Adobe Creative\nSuite, Sketch, Figma).\nStrong understanding of usability principles, user-centered design, and information\narchitecture.\nFamiliarity with HTML, CSS, and JavaScript for UI implementation.\nExcellent communication and collaboration skills.\n\nVOIS Equal Opportunity Employer Commitment\nVOIS is proud to be an Equal Employment Opportunity Employer. We celebrate differences and we welcome and value diverse people and insights. We believe that being authentically human and inclusive powers our employees growth and enables them to create a positive impact on themselves and society. We do not discriminate based on age, colour, gender (including pregnancy, childbirth, or related medical conditions), gender identity, gender expression, national origin, race, religion, sexual orientation, status as an individual with a disability, or other applicable legally protected characteristics.\nAs a result of living and breathing our commitment, our employees have helped us get certified as a Great Place to Work in India for four years running. We have been also highlighted among the Top 5 Best Workplaces for Diversity, Equity, and Inclusion, Top 10 Best Workplaces for Women, Top 25 Best Workplaces in IT & IT-BPM and 14th Overall Best Workplaces in India by the Great Place to Work Institute in 2023. These achievements position us among a select group of trustworthy and high-performing companies which put their employees at the heart of everything they do.\n\nBy joining us, you are part of our commitment. We look forward to welcoming you into our family which represents a variety of cultures, backgrounds, perspectives, and skills!\n\nApply now, and well be in touch!",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Visualization', 'SQL', 'Figma', 'Tableau', 'Qlik', 'Dashboard Development', 'Adobe Creative Suite']",2025-06-12 14:14:12
MDM Associate Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\n\nRole Description\n\nWe are seeking an MDM Associate Analyst with 2 5 years of development experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability. The ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.\n\nTo succeed in this role, the candidate must have strong experience on MDM (Master Data Management) on configuration (L3 Configuration, Assets creati on, Data modeling etc ) , ETL and data mappings (CAI, CDI ) , data mastering (Match/Merge and Survivorship rules) , source and target integrations ( RestAPI , Batch integration, Integration with Databricks tables etc )\n\nRoles & Responsibilities\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark , and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional\n\nSkills:\nMust-Have Skills:\nStrong experience with Informatica or Reltio MDM platforms in building configurations from scratch (Like L3 configuration or Data modeling, Assets creations, Setting up API integrations, Orchestration)\nStrong experience in building data mappings, data profiling, creating and implementation business rules for data quality and data transformation\nStrong experience in implementing match and merge rules and survivorship of golden records\nExpertise in integrating master data records with downstream systems\nVery good understanding of DWH basics and good knowledge on data modeling\nExperience with IDQ, data modeling and approval workflow/DCR.\nAdvanced SQL expertise and data wrangling.\nExposure to Python and PySpark for data transformation workflows.\nKnowledge of MDM, data governance, stewardship, and profiling practices.\nGood-to-Have\n\nSkills:\nFamiliarity with Databricks and AWS architecture.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nBasics of data engineering concepts.\nProfessional Certifications\nAny ETL certification ( e.g. Informatica)\nAny Data Analysis certification (SQL , Python, Databricks )\nAny cloud certification (AWS or AZURE)\nSoft\n\nSkills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM', 'advance sql', 'master data', 'reltio', 'data mapping', 'informatica', 'sql', 'data profiling']",2025-06-12 14:14:14
MDM Associate Analyst,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"Role Description:\nWe are seeking an MDM Associate Analystwith 25 years of development experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability. The ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.To succeed in this role, the candidate must have strong experience on MDM (Master Data Management) on configuration (L3 Configuration, Assets creation, Data modeling etc), ETL and data mappings (CAI, CDI) , data mastering (Match/Merge and Survivorship rules), source and target integrations (RestAPI, Batch integration, Integration with Databricks tables etc)\nRoles & Responsibilities:\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark, and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\nStrong experience with Informatica or Reltio MDM platforms in building configurations from scratch (Like L3 configuration or Data modeling, Assets creations, Setting up API integrations, Orchestration)\nStrong experience in building data mappings, data profiling, creating and implementation business rules for data quality and data transformation\nStrong experience in implementing match and merge rules and survivorship of golden records\nExpertise in integrating master data records with downstream systems\nVery good understanding of DWH basics and good knowledge on data modeling\nExperience with IDQ, data modeling and approval workflow/DCR.\nAdvanced SQL expertise and data wrangling.\nExposure to Python and PySpark for data transformation workflows.\nKnowledge of MDM, data governance, stewardship, and profiling practices.\nGood-to-Have Skills:\nFamiliarity with Databricks and AWS architecture.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nBasics of data engineering concepts.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL, Python, Databricks)\nAny cloud certification (AWS or AZURE)\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM', 'configuration', 'Data modeling', 'data governance', 'API integrations', 'Databricks', 'data mappings']",2025-06-12 14:14:16
Lead Data Scientist,Trion Consultancy Services,10 - 18 years,20-35 Lacs P.A.,['Chennai'],"LD Scientist with 12 yrs of industry exp, including at least 5 yrs of hands-on exp in data science & a proven track record of delivering impactful data science solutions.\nData Analysis &Exploration\nTime Series Analysis\nModel Deployment & Integration\n\nRequired Candidate profile\n12+ yrs/including 5+ yrs in data science\nExp in Python and SQL for data extraction, manipulation & analysis\nDS & Model Development: Demonstrated exp in performing exploratory data analysis (EDA)",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Lead Data science', 'Machine Learning', 'Python']",2025-06-12 14:14:19
Lead Data Scientist,Bizopp Management Consultants,11 - 18 years,25-35 Lacs P.A.,['Chennai'],"• Proficiency in Python and SQL for data extraction, manipulation, and analysis\n\n• Exploratory data analysis (EDA), developing, and deploying machine learning models\n\n• Expertise in deploying ML models on cloud platforms such as AWS or Azure",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['EDA', 'Data Scientist', 'Python', 'SQL', 'Azure', 'Exploratory data analysis', 'Machine Learning', 'AWS', 'ML']",2025-06-12 14:14:21
Financial Analyst,Icreon Communications,4 - 5 years,Not Disclosed,['Noida'],"Looking for a well-rounded Financial Analyst who can provide critical business partner support to our IT / ITes Services Business units. The candidate will be responsible for supporting Executive and Finance team members with data insights, budgets, and forecasts and other ad-hoc analyses.\nWhat you ll do:\nProvide finance support to the business teams regarding productivity, demand planning, reporting, and financial metrics\nAssist in the preparation of annual budgets and forecasts, variance analyses, long--range financial plans, risk/opportunity assessments, and periodic/ad hoc reporting",,,,"['Data analysis', 'Excel', 'Demand planning', 'Finance', 'ITES', 'data visualization', 'Continuous improvement', 'Operations', 'Analytics', 'SQL']",2025-06-12 14:14:23
MDM Testing - Associate Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"Role Description:\nWe are looking for a skilled MDM Testing Associate Analyst who will responsible for ensuring the quality and integrity of Master Data Management (MDM) applications through rigorous testing processes. This role involves collaborating with cross-functional teams to define testing objectives, scope, and deliverables, and to ensure that master data is accurate, consistent, and reliable. and comply with Amgens standard operating procedures, policies, and guidelines. Your expertise will be instrumental in ensuring quality and adherence to required standards so that the engineering teams can build and deploy products that are compliant.\nRoles & Responsibilities:\nTest Planning: Develop and implement comprehensive testing strategies for MDM applications, including defining test objectives, scope, and deliverables. This includes creating detailed test plans, test cases, and test scripts.\nTest Execution: Execute test cases, report defects, and ensure that all issues are resolved before deployment. This involves performing functional, integration, regression, and performance testing.\nData Analysis: Analyze data to identify trends, patterns, and insights that can be used to improve business processes and decision-making. This includes validating data accuracy, completeness, and consistency.\nCollaboration: Work closely with the MDM, RefData and DQDG team and other departments to ensure that the organizations data needs are met. This includes coordinating with data stewards, data architects, and business analysts.\nDocumentation: Maintain detailed documentation of test cases, test results, and any issues encountered during testing. This includes creating test summary reports and defect logs.\nQuality Assurance: Develop and implement data quality metrics to ensure the accuracy and consistency of master data. This includes conducting regular data audits and implementing data cleansing processes.\nCompliance: Ensure that all master data is compliant with data privacy and protection regulations. This includes adhering to industry standards and best practices for data management.\nTraining and Support: Provide training and support to end-users to ensure proper use of MDM systems. This includes creating user manuals and conducting training sessions\nStay current on new technologies, validation trends, and industry best practices to improve validation efficiencies.\nCollaborate and communicate effectively with the product teams.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n2+ years of experience in MDM implementations, primarily with testing (pharmaceutical, biotech, medical devices, etc.)\nExtensive experience on ETL/ELT and MDM testing (Creating test plan, test scripts and execution of test scripts and bugs tracking/reporting in JIRA)\nInformatica MDM: Proficiency in Informatica MDM Hub console, configuration, IDD (Informatica Data Director), IDQ, and data modeling\nor\nReltio MDM: Experience with Reltio components, including data modeling, integration, validation, cleansing, and unification.\nAdvanced SQL: Ability to write and optimize complex SQL queries, including subqueries, joins, and window functions.\nData Manipulation: Skills in data transformation techniques like pivoting and unpivoting.\nStored Procedures and Triggers: Proficiency in creating and managing stored procedures and triggers for automation.\nPython: Strong skills in using Python for data analysis, including libraries like Pandas and NumPy etc.\nAutomation: Experience in automating tasks using Python scripts.\nMachine Learning: Basic understanding of machine learning concepts and libraries like scikit-learn.\nStrong problem-solving and analytical skills\nExcellent communication and teamwork skills\nGood-to-Have Skills:\nETL Processes: Knowledge of ETL processes for extracting, transforming, and loading data from various sources.\nData Quality Management: Skills in data profiling and cleansing using tools like Informatica.\nData Governance: Understanding of data governance frameworks and implementation.\nData Stewardship: Ability to work with data stewards to enforce data policies and standards.\nSelenium: Experience with Selenium for automated testing of web applications.\nJIRA: Familiarity with JIRA for issue tracking and test case management.\nPostman: Skills in using Postman for API testing.\nUnderstanding of compliance and regulatory considerations in master data.\nIn depth knowledge of GDPR and HIPPA guidelines.\nProfessional Certifications:\nMDM certification (Informatica or Reltio)\nSQL Certified\nAgile or SAFe certified\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM Testing', 'ETL Processes', 'Data Stewardship', 'MDM', 'Agile', 'Data Quality Management', 'Data Governance', 'SQL']",2025-06-12 14:14:26
MDM Associate Analyst,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nWe are seeking an MDM Associate Analystwith 25 years of development experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability.\nThe ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.To succeed in this role, the candidate must have strong experience on MDM (Master Data Management) on configuration (L3 Configuration, Assets creation, Data modeling etc), ETL and data mappings (CAI, CDI) , data mastering (Match/Merge and Survivorship rules), source and target integrations (RestAPI, Batch integration, Integration with Databricks tables etc)\nRoles & Responsibilities:\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark, and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\nStrong experience with Informatica or Reltio MDM platforms in building configurations from scratch (Like L3 configuration or Data modeling, Assets creations, Setting up API integrations, Orchestration)\nStrong experience in building data mappings, data profiling, creating and implementation business rules for data quality and data transformation\nStrong experience in implementing match and merge rules and survivorship of golden records\nExpertise in integrating master data records with downstream systems\nVery good understanding of DWH basics and good knowledge on data modeling\nExperience with IDQ, data modeling and approval workflow/DCR.\nAdvanced SQL expertise and data wrangling.\nExposure to Python and PySpark for data transformation workflows.\nKnowledge of MDM, data governance, stewardship, and profiling practices.\nGood-to-Have Skills:\nFamiliarity with Databricks and AWS architecture.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nBasics of data engineering concepts.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL, Python, Databricks)\nAny cloud certification (AWS or AZURE)\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Reltio MDM', 'Data modeling', 'PySpark', 'data governance', 'Informatica', 'API integration', 'AWS', 'data profiling', 'SQL', 'Python']",2025-06-12 14:14:28
Technical Intern,Siemens Healthcare,3 months duration,Unpaid,['Bengaluru'],"Siemens Healthcare is looking for Technical Intern to join our dynamic team and embark on a rewarding career journey Learning and Shadowing: You'll spend a significant portion of your time observing and learning from experienced professionals in your field\n\nThis might involve shadowing software engineers, data analysts, network administrators, or other technical specialists to understand their workflows and best practices\n\nAssisting with Projects: You may have the opportunity to assist with ongoing projects or initiatives within your organization\n\nThis could include tasks such as coding, testing software applications, analyzing data, configuring systems, or troubleshooting technical issues\n\nTraining and Development: Many internships offer formal training sessions or workshops to help you develop your technical skills\n\nTake advantage of these opportunities to deepen your understanding of relevant programming languages, software tools, or methodologies\n\nProblem-Solving: Technical internships often provide opportunities to tackle real-world problems and challenges\n\nYou'll learn how to apply your technical knowledge to solve practical problems and improve processes within the organization\n\nCommunication Skills: Effective communication is crucial in any technical role\n\nAs an intern, you'll have opportunities to communicate with colleagues, present your work, and ask questions\n\nPractice conveying technical information clearly and concisely, both orally and in writing\n\nNetworking: Take advantage of networking opportunities during your internship to connect with professionals in your field\n\nAttend company events, join professional organizations, and reach out to colleagues for informational interviews or mentorship",Industry Type: Medical Services / Hospital,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Technical Intern', 'Internship']",2025-06-12 14:14:30
Supply Chain Analyst,Rhythm Placement,5 - 6 years,5.5-8 Lacs P.A.,['Pune'],"• Communicate with Planners/Buyers on Po creation requirements.\n• Monitor and collect data on Supplier KPI (Extra)\n• Purchase order creation, Amendment and follow ups on weekly basis\n• Quantitative analysis expertise\n• Critical thinking skills",Industry Type: Electronics Manufacturing (Electronic Manufacturing Services (EMS)),Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Management', 'MIS Reporting', 'Data Analysis', 'Dashboards', 'Data Interpretation', 'Advanced Excel', 'Data Collection', 'Dashboarding', 'Powerpoint', 'Business Reporting', 'Excel', 'VLOOKUP', 'Data Visualization', 'Data Reporting']",2025-06-12 14:14:32
MIS Executive (Fresher / Exp) B.SC Statistics / Math,Sarika Consultant Services,0 - 2 years,1.8-2.4 Lacs P.A.,['Kolkata( Gariahat )'],B.Sc Math or Stat must be needed\nFresher & experienced both can apply\nResponsibilities:\n* Analyze data using advanced Excel & Google Sheets skills.\n* Prepare monthly reports with statistical insights.\nCALL - 8697666885 or WhatsApp any queries\n\n\nHealth insurance\nProvident fund\nAnnual bonus,Industry Type: Industrial Equipment / Machinery,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Google Sheets', 'MIS', 'Advanced Excel', 'Mathematics', 'Statistics']",2025-06-12 14:14:34
E-commerce Executive,Wishkey Retail,0 - 5 years,1-3 Lacs P.A.,['Kolkata( Burrabazar )'],"Roles and Responsibilities\nManage and update product listings with accurate information and pricing.\nDevelop and adjust pricing strategies to stay competitive.\nPerform bulk uploads and data corrections using Excel/Google Sheets.\nEnsure listings comply with platform guidelines and maintain quality.\nUse AI tools to improve catalog and pricing processes.\nCollaborate with teams to support business growth via AI solutions.\nPrepare regular reports on sales and listing performance.\nCoordinate with teams for timely updates and issue resolution.\n\n\nDesired Candidate Profile\n0-5 years experience in e-commerce (freshers welcome).\nSkilled in product listing on Amazon, Flipkart, Blinkit, etc.\nDetail-oriented with knowledge of pricing strategies.\nComfortable using AI tools and basic Excel/Google Sheets.\nGood communication and teamwork skills.\nComfortable working on the 4th floor (no lift) in a busy commercial area (Burrabazar, Kolkata)",Industry Type: Internet (E-Commerce),"Department: Merchandising, Retail & eCommerce","Employment Type: Full Time, Permanent","['Data Analysis', 'E-commerce', 'Online Sales', 'Excel Sheet', 'Product Listing', 'Communication Skills', 'Ai Solutions', 'Adaptability', 'Catalog Management', 'Ecommerce Operations', 'Pricing Strategy', 'Content Optimization']",2025-06-12 14:14:36
Analytics and Modeling Associate,Overture Rede,0 - 1 years,Not Disclosed,['Bengaluru'],"Job Title: Analytics and Modeling AssociateLocation: Bengaluru Experience: 02 Years Education: 15 Years Full-TimeJob SummaryWe are seeking a motivated Analytics and Modeling Associate to support data-driven decision-making through insightful analysis, statistical modeling, and reporting\nIdeal for early-career professionals with a passion for data and problem-solving\nKey ResponsibilitiesCollect, clean, and analyze data to support business goalsBuild and maintain statistical models and dashboards\nCollaborate with stakeholders to define analytical needsPresent findings and provide actionable insightsSupport continuous improvement through data innovationMust-Have Skills Strong\nknowledge of Excel, SQL, and Python/R Understanding of statistical modeling and data visualization Familiarity with tools like Power BI / Tableau Excellent analytical and communication skills",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Statistical modeling', 'tableau', 'Excel', 'Analytical', 'power bi', 'data visualization', 'Continuous improvement', 'Analytics', 'SQL', 'Python']",2025-06-12 14:14:38
Mis Executive Bhubneswar,Talentpull And Infrastructure,0 - 3 years,"50,000-1.25 Lacs P.A.",['Bhubaneswar'],Role: MIS Infra\nLocation: Bhubneswar\nLocal candidates are preferred\nSalary: 18000 CTC\nQualification: 12th/Graduate\nSkills required:\n1. Expert in Advanced Excel\n2. Data Management\n3. Good communication skills\nInterested candidates can apply 7743003736,Industry Type: Telecom / ISP,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Pivot Table', 'VLOOKUP', 'Advanced Excel']",2025-06-12 14:14:40
Management Trainee - Hindi Speaking,Zebronics,0 - 5 years,Not Disclosed,['Chennai'],"Key Responsibilities:\n\nAssist in business planning, operations, and market analysis.\nSupport the team in day-to-day functions across departments.\nParticipate in negotiations and vendor/client meetings.\nDevelop insights based on data analysis and industry trends.\nCreate and deliver impactful presentations and reports.\nEngage in strategic decision-making and contribute ideas.\nCoordinate with internal teams to ensure smooth workflow.\nRepresent the brand with professionalism and presentability.\nRequired Skills:\n\nStrong communication and interpersonal abilities\nExcellent presentation and negotiation skills\nBusiness-oriented mindset with a problem-solving attitude\nAnalytical thinking and decision-making capabilities\nConvincing power and stakeholder handling",Industry Type: Consumer Electronics & Appliances,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Strategic Thinking', 'Hindi', 'Business Development', 'Communication Skills', 'Presentation Skills', 'Management Skills']",2025-06-12 14:14:42
Junior Accountant Executive,Singhi Chugh & Kumar,0 - 3 years,Not Disclosed,"['New Delhi', 'Gurugram', 'Greater Noida']","Role & responsibilities\nAssist in the preparation and filing of GST returns (GSTR-1, GSTR-3B) and ensure timely TDS deductions and filings.\nSupport in preparing monthly and quarterly financial reports, balance sheets, and profit & loss statements.\nUtilize Excel for data analysis, reporting, and maintaining financial records.\nMaintain accurate financial records using Tally ERP, recording daily transactions, and reconciling bank statements.\n\nPreferred candidate profile\n\nBachelor's degree in Commerce (B.Com) or equivalent.\nProficiency in Tally ERP and Microsoft Excel.\nBasic understanding of GST, TDS, and accounting principles.\nStrong attention to detail, analytical skills, and good communication abilities.",Industry Type: Accounting / Auditing,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Gst Reconciliation', 'Bank Reconciliation', 'Communication Skills', 'Excel', 'Tally ERP', 'Book Keeping']",2025-06-12 14:14:44
Executive Risk Advisory Services ( Internal Audit),Dpnc Global,0 - 3 years,Not Disclosed,"['Noida', 'New Delhi']","DPNC Global is looking for Executive Risk Advisory Services ( Internal Audit) to join our dynamic team and embark on a rewarding career journey.\n\nInternal Auditing : Conducting internal audits to evaluate the effectiveness of internal controls, risk management, and governance processes. Reviewing financial statements, operations, and various business processes. Risk Advisory : Providing advisory services related to risk management, helping the organization identify and mitigate potential risks. Developing strategies for risk avoidance, acceptance, reduction, or transfer. Compliance Assessment : Assessing and ensuring compliance with relevant laws, regulations, and internal policies. Identifying areas of non - compliance and recommending corrective actions. Audit Planning : Participating in the planning of audit projects, including defining the scope, objectives, and methodologies. Developing risk - based audit plans. Audit Execution : Performing audit procedures, including testing controls, reviewing documentation, and conducting interviews. Analyzing and interpreting data to draw meaningful conclusions. Report Generation : Preparing detailed and insightful audit reports outlining findings, recommendations, and action plans. Presenting audit reports to management and stakeholders. Continuous Monitoring : Implementing continuous monitoring processes to stay abreast of changes in risk factors and internal control environments. Recommending adjustments to audit plans as needed. Process Improvement : Identifying opportunities for process improvements and operational efficiencies based on audit findings. Collaborating with relevant departments to implement recommended changes. Training and Awareness : Conducting training sessions and awareness programs on risk management and internal controls for employees. Promoting a culture of risk awareness and compliance within the organization. Stakeholder Communication : Communicating with key stakeholders, including senior management and the audit committee. Providing updates on audit progress, findings, and recommendations. Technology Utilization : Leveraging technology tools for data analysis, audit automation, and risk assessment. Keeping up to date with advancements in audit technologies. Fraud Detection : Participating in fraud risk assessments and implementing measures to detect and prevent fraudulent activities.",Industry Type: Management Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Risk advisory', 'Manager Internal Audit', 'Senior Executive', 'Internal Audit Executive']",2025-06-12 14:14:46
Mis Executive,Harjai Computers,0 - 4 years,"50,000-2.75 Lacs P.A.","['Mumbai Suburban', 'Navi Mumbai', 'Mumbai (All Areas)']","Opening for MIS Executive Role.\nSkills - Excel, Advance Excel, Vlookup,Hlookup\nThane GB\nNotice Period - Immedite to 7 Days\nInterested candidate can share their updated resume at sangita@harjai.com",Industry Type: Banking,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Advanced Excel', 'Pivot Table', 'SUMIF', 'Countif', 'VLOOKUP', 'Formulas', 'Lookup', 'Pivot', 'HLOOKUP']",2025-06-12 14:14:48
Mis Executive,Cafyo Management Solution,0 - 5 years,1.75-2.5 Lacs P.A.,['Delhi / NCR( Sector-16 Dwarka )'],"We are seeking a detail-oriented and technically proficient MIS Executive to manage and streamline the organization’s data reporting systems. The candidate will be responsible for designing, maintaining, and analyzing data reports andsupport business",Industry Type: Furniture & Furnishing,Department: Other,"Employment Type: Full Time, Permanent","['Advanced Excel', 'MIS Reporting', 'SQL', 'ERP', 'Power Bi', 'MIS']",2025-06-12 14:14:50
Research Analyst,Super Scholar,3 - 10 years,Not Disclosed,['Mumbai'],"Role Responsibilities:\n\nConduct thorough market research and data analysis to support company objectives.\n\nCollect and evaluate data from primary and secondary sources.\n\nDevelop and manage research projects, ensuring timelines and budget compliance.\n\nProvide actionable insights that inform strategic decision-making.\n\nPrepare detailed reports and presentations to communicate findings.\n\nCollaborate with cross-functional teams to identify research needs.\n\nAssist in the formulation of research methodologies and strategies.\n\nMonitor industry trends and competitive landscape.\n\nPresent research outcomes to stakeholders clearly and concisely.\n\nSupport the analysis of data sets using statistical software.\n\nIdentify opportunities for process improvements in research methodologies.\n\nEnsure data integrity and accuracy throughout research processes.\n\nFacilitate workshops and discussions to gather qualitative data.\n\nEngage with external vendors and partners for specialized research activities.\n\nMaintain a comprehensive research database and archives.\n\nContribute to brainstorming sessions to shape future research initiatives.\n\n\nQualifications:\n\nBachelors degree in Business, Economics, Statistics, or related field.\n\nProven experience as a Research Analyst or in a similar role.\n\nStrong knowledge of statistical tools and software.\n\nExcellent analytical and critical thinking skills.\n\nHands-on experience with quantitative and qualitative research methods.\n\nAbility to work independently and manage multiple projects simultaneously.\n\nExceptional communication skills, both oral and written.\n\nProficiency in Microsoft Office Suite, particularly Excel and PowerPoint.\n\nDetail-oriented with a strong focus on accuracy.\n\nAbility to synthesize complex information and present it in an understandable format.\n\nFamiliarity with market research techniques and methodologies.\n\nProactive, creative, and solution-focused mindset.\n\nStrong organizational and time management abilities.\n\nExperience working in a team-oriented, collaborative environment.\n\nWillingness to adapt and learn in a fast-paced setting.",Industry Type: E-Learning / EdTech,Department: Research & Development,"Employment Type: Full Time, Permanent","['Qualitative research', 'Data analysis', 'Time management', 'Analytical', 'Formulation', 'Market research', 'data integrity', 'Management', 'Research Analyst', 'MS Office']",2025-06-12 14:14:53
Quality Systems Analyst,PNG Air,3 - 5 years,Not Disclosed,['Papua New Guinea'],"Role & responsibilities\nMonitoring, analyzing and reporting of the performance and effectiveness of the Safety Management System (SMS)\nUsing analytical skills, to identify key issues and trends impacting on the risk level of the organization and escalate to the General Manager Safety, Aviation Security & Risk directly of any adverse trend involving high risk\nProviding quality reports to management on a weekly and monthly basis as specified in the QMS and as otherwise directed by the General Manager Safety, Aviation Security & Risk\nProducing data for inclusion in SQAG and SQRB reports with appropriate commentary on trends, including analysis of flight data management reports.\nBefore the end of each year, conducting an evaluation of investigation findings, assessment outcomes and audit findings to assist in validating the future risk based audit schedule.\nDeveloping and maintaining customized reports in the Quality Database against identified needs.\nProviding trend advice to various management forums as requested by the General Manager Safety, Aviation Security & Risk, including a quarterly analysis of Logged for Stats data.\nMonitor the audit schedule, ensuring that the requirements specified in the risk-based audit program are achieved.\nConducting Audits as a Lead Auditor as allocated in the audit schedule.\nEscalating to the General Manager Safety, Aviation Security & Risk directly of any deficiencies in the QMS which affect, or may affect, the safety of aircraft, clients or staff, or the achievement of corporate objective\nPreferred candidate profile\nLead Auditor Certificate\nSafety Investigator Certificate*\nFormal qualification in analytics*\nManagement System Training Level 3*\n5 years of experience in an aviation in an organizational role\n3 Years of experience within an SMS or QMS\nRelevant tertiary qualification of a Diploma or above\nAnalytical Skills in Analyzing data\nIT competency in using and developing customize reports through databases and quality software platforms\nProficiency in data analysis tools and techniques relevant to Quality and Safety reporting (Excel, Databases, Specialize software)",Industry Type: Aviation,Department: Aviation & Aerospace,"Employment Type: Full Time, Permanent","['Safety Management Systems', 'Analyzing Data', 'analytical skills', 'report writing', 'Auditing']",2025-06-12 14:14:55
Inventory/Product Listing Executive,Just Wines,0 - 5 years,Not Disclosed,['Faridabad'],"Job Title: Inventory/Product Listing Executive\nLocation: Faridabad\nJob Type: Full-Time\nReports To: Manager Inventory\nAbout Just Wines:\nJust Wines is a leading eCommerce company specializing in wines. We are committed to delivering high-quality products and seamless shopping experiences to our customers. As we continue to grow, we are looking for a detail-oriented Inventory Executive to optimize stock management, enhance product listings, and ensure smooth inventory operations.\nJob Summary:\nThe Inventory Executive will be responsible for managing stock levels, product listings, and\ndemand forecasting across our eCommerce platforms. The ideal candidate should have strong\nexpertise in Microsoft Excel, Shopify, and inventory forecasting techniques, ensuring optimal stock availability and operational efficiency.\nKey Responsibilities:\nInventory Management & Forecasting:\nMonitor and manage inventory levels across warehouses and eCommerce sales channels.\nUtilize advanced Excel skills (Pivot Tables, VLOOKUP, Macros, etc.) to track stock\nmovement, analyze data, and generate inventory reports.\nForecast demand trends using historical sales data and seasonal trends to optimize stock\nreplenishment.\nImplement and maintain inventory control procedures to minimize stock discrepancies.\nProduct Listing & Shopify Management:\nManage and update product listings on Shopify and other platforms to ensure accuracy in\ndescriptions, pricing, and stock availability.\n\nReporting & Data Analysis:\nGenerate detailed inventory reports, stock movement analysis, and sales trend insights.\nIdentify slow-moving or excess stock and propose strategies for liquidation or promotions.\nInvestigate stock discrepancies\nWork closely with finance and warehouse teams to ensure accurate stock valuation and\nreporting.\n\nRequired Skills & Qualifications:\nBachelors degree in Business Administration, Supply Chain, or a related field.\nProficiency in Microsoft Excel (Advanced Formulas, Pivot Tables, Macros, VLOOKUP,\netc.).\nGood Communications Skills",Industry Type: Internet (E-Commerce),"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Good Communication In English', 'Advanced Excel', 'Data Entry']",2025-06-12 14:14:57
Quality Analyst (Field Audit),Navi Technologies,2 - 6 years,3-6 Lacs P.A.,"['Thane', 'Mumbai (All Areas)( Borivali, Borivali East, Borivali West, Andheri, Andheri East, Andheri West, Thane East, Thane West )']","About Navi\nNavi is one of the fastest-growing financial services companies in India providing Personal & Home Loans, UPI, Insurance, Mutual Funds, and Gold. Navi's mission is to deliver digital-first financial products that are simple, accessible, and affordable. Drawing on our in-house AI/ML capabilities, technology, and product expertise, Navi is dedicated to building delightful customer experiences.\nFounders: Sachin Bansal & Ankit Agarwal\n\nKnow what makes you a Navi_ite :",,,,"['field sale', 'Credit Card Sales', 'Field Work', 'Field Collections', 'Interpersonal Skills', 'Communication Skills', 'B2C Sales', 'Microfinance', 'Credit Cards']",2025-06-12 14:14:59
Data Engineer,Xenonstack,2 - 5 years,Not Disclosed,['Mohali( Phase 8B Mohali )'],"At XenonStack, We committed to become the Most Value Driven Cloud Native, Platform Engineering and Decision Driven Analytics Company. Our Consulting Services and Solutions towards the Neural Company and its Key Drivers.\nXenonStacks DataOps team is looking for a Data Engineer who will be responsible for employing techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field.\nYou should demonstrate flexibility, creativity, and the capacity to receive and utilize constructive criticism. The ideal candidate should be highly skilled in all aspects of Python, Java/Scala, SQL and analytical skills.\nJob Responsibilities:\nDevelop, construct, test and maintain Data Platform Architectures\nAlign Data Architecture with business requirements\nLiaising with co-workers and clients to elucidate the requirements for each task.\nScalable and High Performant Data Platform Infrastructure that allows big data to be accessed and analysed quickly by BI & AI Teams.\nReformulating existing frameworks to optimize their functioning.\nTransforming Raw Data into InSights for manipulation by Data Scientists.\nEnsuring that your work remains backed up and readily accessible to relevant co-workers.\nRemaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.\nRequirements:\nTechnical Requirements\nExperience of Python, Java/Scala\nGreat Statistical / SQL based Analytical Skills\nExperience of Data Analytics Architectural Design Patterns for Batch, Event Driven and Real-Time Analytics Use Cases\nUnderstanding of Data warehousing, ETL tools, machine learning, Data EPIs\nExcellent in Algorithms and Data Systems\nUnderstanding of Distributed System for Data Processing and Analytics\nFamiliarity with Popular Data Analytics Framework like Hadoop , Spark , Delta Lake , Time Series / Analytical Stores Stores.\nProfessional Attributes:\nExcellent communication skills & Attention to detail.\nAnalytical mind and problem-solving Aptitude with Strong Organizational skills & Visual Thinking.\nBenefits:\nDiscover the benefits of joining our team:\nDynamic and purposeful work culture in a people-oriented organization contributing to multi-million-dollar projects with guaranteed job security.\nOpen, authentic, and transparent communication fostering a warm work environment.\nRegular constructive feedback and exposure to diverse technologies.\nRecognition and rewards for exceptional performance achievements.\nAccess to certification courses & Skill Sessions to develop continually and refine your skills.\nAdditional allowances for team members assigned to specific projects.\nSpecial skill allowances to acknowledge and compensate for unique expertise.\nComprehensive medical insurance policy for your health and well-being.\nTo Learn more about the company -\nWebsite - http://www.xenonstack.com/",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Hadoop', 'Spark', 'ETL', 'Python', 'SQL', 'Java', 'Data Processing', 'Machine Learning']",2025-06-12 14:15:01
Marketing Intern,Streamoid,No fixed duration,"40,000/month",['Bengaluru'],"About Us\nWere revolutionizing fashion photography by making professional-quality shoots accessible to every budget-conscious fashion business and content creator. Our AI-powered platform transforms basic product photos into stunning fashion campaigns with AI models and backgrounds - no photoshoot required.\nIf youre excited about AI technology, passionate about photography and fashion, and great at marketing we would like to meet you!\n\nThe Role\nThe Role\nWere looking for a creative marketing intern to help us spread the word about our game-changing AI photo studio. Youll work to create content, engage with fashion and photography communities, and help build our brand as the go-to solution for budget-smart visual content creation.\nThis is perfect for someone who wants hands-on experience in AI/tech marketing, content creation, and community building while supporting innovative small businesses.\n\nWhat Youll Do\nContent Creation & Storytelling\nCreate engaging social media content showcasing product transformations\nWrite blog posts about fashion photography trends, small business tips, and AI innovation\nDevelop case studies highlighting customer success stories\nScript and create short-form video content (Instagram Reels, YouTube Shorts)\nDesign simple graphics and visual content using Canva or similar tools\n\nCommunity Engagement\nEngage with fashion entrepreneurs and other potential customers on social media platforms\nMonitor and respond to comments, messages, and community discussions\nIdentify and connect with potential brand ambassadors and user-generated content creators\nParticipate in relevant online communities (Reddit, Facebook groups, industry forums)\nHelp manage our social media presence across Instagram, TikTok, LinkedIn, and Twitter\n\nMarket Research & Analysis\nResearch fashion industry trends and competitor activities\nIdentify potential partnership opportunities with fashion influencers and small business communities\nAnalyze social media performance and engagement metrics\nSurvey customers for feedback and testimonials\nResearch new platforms and marketing channels for our target audience\n\nCampaign Support\nAssist with email marketing campaigns\nHelp coordinate influencer partnerships and collaborations\nSupport product launch campaigns and promotional activities\nContribute to marketing materials and presentation development\nIdeal Profile\nWhat Were Looking For\nMust-Haves\nCurrently pursuing or recently completed degree in Marketing, Communications, Business, Fashion, or related field\nStrong written communication skills with a knack for engaging, conversational content\nSocial media native with understanding of platform-specific content strategies\nBasic design skills (Canva, Adobe Creative Suite, or similar)\nBasic video editing skills\nGenuine interest in fashion, small business, and/or AI technology\nSelf-motivated with ability to work independently and meet deadlines\nComfortable with data analysis and using analytics tools\n\nNice-to-Haves\nExperience with content creation (blogging, social media, video)\nFamiliarity with marketing tools (Mailchimp, Hootsuite, Google Analytics)\nUnderstanding of e-commerce and online fashion retail\nExperience with AI tools or tech startups\nPhotography or visual content creation background\n\nWhat Youll Gain\nProfessional Experience\nHands-on experience with AI/tech product marketing\nPortfolio of content creation and campaign work\nUnderstanding of startup marketing from strategy to execution\nExperience with multiple marketing channels and platforms\nData analysis and performance measurement skills\n\nCompensation & Benefits\n1. Internship fee will be Rs 30,000 to 40,000 per month.\n2. Lunch and snacks will be provided at office.\nWhats on Offer?\nOpportunity within a company with a solid track record of performance\nWork alongside & learn from best in class talent\nFlexible working options",Industry Type: Internet,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Graphics', 'Data analysis', 'Google Analytics', 'Email marketing', 'adobe creative suite', 'Social media', 'Market research', 'Video editing', 'Internship', 'Product marketing']",2025-06-12 14:15:04
Hiring MBA For Telesales Executive || CTC Up To 4.75 LPA ||,Multiple Clients,0 - 2 years,2.25-4.75 Lacs P.A.,['Gurugram'],"Applicants can call or WhatsApp to Ms.Zoya Shamsi-+91-7251000195 (11am-5pm) Only\n\nClient Overview:\nWe are a leading Recruitment company serving multiple prestigious clients across various industries, including Policy bazaar, Paisa Bazaar, Lenskart, Niva Bupa, Indiabulls, Globiva, Tech Mahindra, Research & Ranking,Fynocrat,Ebixcash, Hike Education, Indialends,Frankfinn,Teleperformance and more.\n\nAs an MBA Sales Associate or Customer Support Associate, you will have the opportunity to kickstart your career with these esteemed clients and contribute to their business growth.\nJob Profile:\nWe are seeking ambitious MBA freshers to join our team as Sales Associates and Customer Support Associates. Your primary responsibilities will include handling outbound/inbound/regional/e-mail/chat processes based on the assigned client and process. You will engage with customers, promote products/services, and provide exceptional customer support, applying the business acumen developed during your MBA studies.\nKey Responsibilities:\nHandle outbound/inbound/regional/e-mail/chat processes as assigned by the client.\nFor Sales Associates: Utilize MBA-level strategic thinking to contact potential customers, present products/services, and explain their features and benefits.\nApply advanced sales techniques and business strategies to follow scripts, engage with customers, and overcome objections.\nMeet or exceed sales/customer satisfaction targets, contributing to the growth of the client's business through data-driven decision-making.\nBuild and maintain customer relationships by providing exceptional service, leveraging your understanding of customer relationship management.\nMaintain accurate records of customer interactions, sales, and support tickets in the CRM system, applying data analysis skills.\n\nKey Skills and Requirements:\nMBA degree (freshers)\nExcellent verbal and written communication skills in English; additional regional languages are a plus.\nStrong analytical and problem-solving skills developed through MBA coursework.\nAbility to understand customer needs and effectively present solutions using business strategy principles.\nProficiency in data analysis and interpretation, with familiarity in using CRM systems.\nCapability to work in a target-driven environment and achieve sales/customer satisfaction goals.\nProactive and self-motivated with a positive attitude and entrepreneurial spirit.\nStrong leadership potential and ability to work effectively in team settings.\nFlexibility to adapt to changing processes and client requirements, demonstrating business agility.\nUnderstanding of market research, consumer behavior, and customer service principles.\n\nLocation: Delhi/Noida/Gurugram\nCTC: The salary range for MBA fresher Sales Associates and Customer Support Associates is 3.00 LPA to 5.00 LPA, depending on academic performance, interview results, and the assigned client.\nShift Type: The shift type may vary based on the client and process. We offer day shifts, night shifts, and rotational shifts to accommodate the preferences of our employees.",Industry Type: BPM / BPO,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['B2C Sales', 'Telesales', 'Sales', 'Inbound Sales', 'Insurance Sales', 'Inside Sales', 'Banking Sales', 'International Sales', 'Sales Process', 'Outbound Sales', 'Telecalling', 'Domestic BPO', 'Cold Calling', 'Domestic Calling', 'Bpo Sales', 'Domestic Sales', 'International Calling', 'International BPO']",2025-06-12 14:15:06
Data Engineer,Konrad Group,3 - 7 years,15-30 Lacs P.A.,['Gurugram( Sector 42 Gurgaon )'],"Who We Are\n\nKonrad is a next generation digital consultancy. We are dedicated to solving complex business problems for our global clients with creative and forward-thinking solutions. Our employees enjoy a culture built on innovation and a commitment to creating best-in-class digital products in use by hundreds of millions of consumers around the world. We hire exceptionally smart, analytical, and hard working people who are lifelong learners.\nAbout The Role\nAs a Data Engineer youll be tasked with designing, building, and maintaining scalable data platforms and pipelines. Your deep knowledge of data platforms such as Azure Fabric, Databricks, and Snowflake will be essential as you collaborate closely with data analysts, scientists, and other engineers to ensure reliable, secure, and efficient data solutions.\n\nWhat Youll Do\n\nDesign, build, and manage robust data pipelines and data architectures.\nImplement solutions leveraging platforms such as Azure Fabric, Databricks, and Snowflake.\nOptimize data workflows, ensuring reliability, scalability, and performance.\nCollaborate with internal stakeholders to understand data needs and deliver tailored solutions.\nEnsure data security and compliance with industry standards and best practices.\nPerform data modelling, data extraction, transformation, and loading (ETL/ELT).\nIdentify and recommend innovative solutions to enhance data quality and analytics capabilities.\n\nQualifications\n\nBachelors degree or higher in Computer Science, Data Engineering, Information Technology, or a related field.\nAt least 3 years of professional experience as a Data Engineer or similar role.\nProficiency in data platforms such as Azure Fabric, Databricks, and Snowflake.\nHands-on experience with data pipeline tools, cloud services, and storage solutions.\nStrong programming skills in SQL, Python, or related languages.\nExperience with big data technologies and concepts (Spark, Hadoop, Kafka).\nExcellent analytical, troubleshooting, and problem-solving skills.\nAbility to effectively communicate technical concepts clearly to non-technical stakeholders.\nAdvanced English\n\nNice to have\n\nCertifications related to Azure Data Engineering, Databricks, or Snowflake.\nFamiliarity with DevOps practices and CI/CD pipelines.\n\nPerks and Benefits\n\nComprehensive Health & Wellness Benefits Package \nSocials, Outings & Retreats\nCulture of Learning & Development\nFlexible Working Hours\nWork from Home Flexibility\nService Recognition Programs\n\nKonrad is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.\nWhile we sincerely appreciate all applications, only those candidates selected for an interview will be contacted.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Hadoop', 'Azure Data Factory', 'Azure Databricks', 'Spark', 'Fabric', 'Python']",2025-06-12 14:15:09
Azure Data Engineer,Arges Global,2 - 5 years,8-18 Lacs P.A.,['Pune( Baner )'],"Scope of Work:\nCollaborate with the lead Business / Data Analyst to gather and analyse business requirements for data processing and reporting solutions.\nMaintain and run existing Python code, ensuring smooth execution and troubleshooting any issues that arise.\nDevelop new features and enhancements for data processing, ingestion, transformation, and report building.\nImplement best coding practices to improve code quality, maintainability, and efficiency.\nWork within Microsoft Fabric to manage data integration, warehousing, and analytics, ensuring optimal performance and reliability.\nSupport and maintain CI/CD workflows using Git-based deployments or other automated deployment tools, preferably in Fabric.\nDevelop complex business rules and logic in Python to meet functional specifications and reporting needs.\nParticipate in an agile development environment, providing feedback, iterating on improvements, and supporting continuous integration and delivery processes.\nRequirements:\nThis person will be an individual contributor responsible for programming, maintenance support, and troubleshooting tasks related to data movement, processing, ingestion, transformation, and report building.\nAdvanced-level Python developer.\nModerate-level experience in working in Microsoft Fabric environment (at least one and preferably two or more client projects in Fabric).\nWell-versed with understanding of modelling, databases, data warehousing, data integration, and technical elements of business intelligence technologies.\nAbility to understand business requirements and translate them into functional specifications for reporting applications.\nExperience in GIT-based deployments or other CI/CD workflow options, preferably in Fabric.\nStrong verbal and written communication skills.\nAbility to perform in an agile environment where continual development is prioritized.\nWorking experience in the financial industry domain and familiarity with financial accounting terms and statements like general ledger, balance sheet, and profit & loss statements would be a plus.\nAbility to create Power BI dashboards, KPI scorecards, and visual reports would be a plus.\nDegree in Computer Science or Information Systems, along with a good understanding of financial terms or working experience in banking/financial institutions, is preferred.",Industry Type: Financial Services (Asset Management),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Microsoft Azure', 'Python', 'Azure Data Factory', 'Microsoft Fabric', 'Azure Databricks', 'Azure Data Lake']",2025-06-12 14:15:11
"Associate Specialist, Data Delivery & Operations",XL India Business Services Pvt. Ltd,2 - 6 years,Not Disclosed,['Gurugram'],"Associate Specialist - Data Delivery & Operations Gurgaon/Bangalore, India AXA XL recognizes data and information as critical business assets, both in terms of managing risk and enabling new business opportunities\n\nThis data should not only be high quality, but also actionable - enabling AXA XLs executive leadership team to maximize benefits and facilitate sustained enterprise advantage\n\nOur Innovation, Data, and Analytics Office (IDA) is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market\n\nAs we develop an enterprise-wide data and digital strategy that moves us toward a greater focus on the use of data and data-driven insights, we are seeking an Associate Scientist for our Data Sourcing & Solutions team\n\nThe role sits across the IDA Department to make sure customer requirements are properly captured and transformed into actionable data specifications\n\nSuccess in the role will require a focus on proactive management of the sourcing and management of data from source through usage\n\nWhat you ll be DOING What will your essential responsibilities include? Accountable for documenting data requirements (Business and Function Requirements) and assessing the reusability of Axiom assets\n\nBuild processes to simplify and expedite data sourcing to focus on delivering data to AXA XL business stakeholders frequently\n\nDevelops and operationalizes strategic data products and answers and proactively manages the sourcing and management of data from source through usage (reusable Policy and Claim Domain data assets)\n\nData Validation Testing of the data products in partnership with the AXA XL business to ensure the accuracy of the data and validation of the requirements\n\nAssesses all data required as part of the Data Ecosystem to make sure data has a single version of the truth\n\nRespond to ad-hoc data requests to support AXA XLs business\n\nInstill a customer-first attitude, prioritizing service for our business stakeholders above all else\n\nInternalize and execute IDA and company-wide goals to become a data-driven organization\n\nContribute to best practices and standards to make sure there is a consistent and efficient approach to capturing business requirements and translating them into functional, non-functional, and semantic specifications\n\nDevelop a comprehensive understanding of the data and our customers\n\nDrive root cause analysis for identified data deficiencies within reusable data assets delivered via IDA\n\nIdentify solution options to improve the consistency, accuracy, and quality of data when captured at its source\n\nYou will report to the Senior Scientist- Data Sourcing & Delivery & Operations\n\nWhat you will BRING We re looking for someone who has these abilities and skills: Required Skills and Abilities: A minimum of a bachelor s or masters degree (preferred) in a relevant discipline\n\nExperience in a data role (business analyst, data analyst, analytics) preferably in the Insurance industry and within a data division\n\nRobust SQL knowledge and technical ability to query AXA XL data sources to understand our data\n\nExcellent presentation, communication (oral & written), and relationship-building skills, across all levels of management and customer interaction\n\nInsurance experience in data, underwriting, claims, and/or operations, including influencing, collaborating, and leading efforts in complex, disparate, and interrelated teams with competing priorities\n\nPassion for data and experience working within a data-driven organization\n\nWork together internal data with external industry data to deliver holistic answers\n\nWork with unstructured data to unlock information needed by the business to create unique products for the insurance industry\n\nPossesses robust exploratory analysis skills and high intellectual curiosity\n\nDisplays exceptional organizational skills and is detail oriented\n\nThe robust conceptual thinker who connects dots, and has critical thinking, and analytical skills\n\nDesired Skills and Abilities: Ability to work with team members across the globe and departments\n\nAbility to take ownership, work under pressure, and meet deadlines\n\nBuilds trust and rapport within and across groups\n\nApplies in-depth knowledge of business and specialized areas to solve business problems and understand integration challenges and long-term impact creatively and strategically\n\nAbility to manage data needs of an individual project(s) while being able to understand the broader enterprise data perspective\n\nExpected to recommend innovation and improvement to policies, and procedures, deploying resources, and performing core activities\n\nExperience with SQL Server, Azure Databricks Notebook, QlikView, Power BI, and Jira/Confluence a plus",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data validation', 'Claims', 'Underwriting', 'Agile', 'QlikView', 'Business strategy', 'JIRA', 'Analytics', 'SQL', 'Customer interaction']",2025-06-12 14:15:13
Senior Executive,Flipkart,1 - 3 years,Not Disclosed,['Bengaluru'],"Skills Required :\nAnticorruption Policy , Critical and logical Thinking , Risk taking & Innovation\nRole :\nLaw Graduate, Commerce Graduate, MBA, Certified Fraud Investigator with 1 - 3 years of relevant experience working on vendor due diligence, reviewing due diligence reports, identifying red flags in due diligence and resolving red flags through logical conclusion.\nA strong commitment to integrity and professionalism, and passion for excellence.\nStrong interpersonal skills with ability to interface with cross -functional teams and front-line associates.\nDemonstrable computer literacy with specific ability to use Microsoft Word, PowerPoint, Excel, internet and internet-based applications.\nEducation/Qualification :\nLaw Graduate, Commerce Graduate, MBA, Certified Fraud Investigator.",Industry Type: Courier / Logistics,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Vendor Due Diligence', 'Critical Thinking', 'Fraud Investigation', 'anticorruption policy', 'team collaboration']",2025-06-12 14:15:15
Data Engineer,Infoobjects Inc.,3 - 6 years,Not Disclosed,['Jaipur'],"Role & responsibilities:\nDesign, develop, and maintain robust ETL/ELT pipelines to ingest and process data from multiple sources.\nBuild and maintain scalable and reliable data warehouses, data lakes, and data marts.\nCollaborate with data scientists, analysts, and business stakeholders to understand data needs and deliver solutions.\nEnsure data quality, integrity, and security across all data systems.\nOptimize data pipeline performance and troubleshoot issues in a timely manner.\nImplement data governance and best practices in data management.\nAutomate data validation, monitoring, and reporting processes.\n\n\n\nPreferred candidate profile:\nBachelor's or Masters degree in Computer Science, Engineering, Information Systems, or related field.\nProven experience (X+ years) as a Data Engineer or similar role.\nStrong programming skills in Python, Java, or Scala.\nProficiency with SQL and working knowledge of relational databases (e.g., PostgreSQL, MySQL).\nHands-on experience with big data technologies (e.g., Spark, Hadoop).\nFamiliarity with cloud platforms such as AWS, GCP, or Azure (e.g., S3, Redshift, BigQuery, Data Factory).\nExperience with orchestration tools like Airflow or Prefect.\nKnowledge of data modeling, warehousing, and architecture design principles.\nStrong problem-solving skills and attention to detail.\n\nPerks and benefits\nFree Meals\nPF and Gratuity\nMedical and Term Insurance",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SCALA', 'Kafka', 'AWS', 'Python', 'Pyspark', 'Java', 'Postgresql', 'Hadoop', 'Spark', 'ETL', 'SQL']",2025-06-12 14:15:17
DBA DATA Engineer || 12 Lakhs CTC,Robotics Technologies,6 - 10 years,12 Lacs P.A.,['Hyderabad( Banjara hills )'],"Dear Candidate,\nWe are seeking a skilled and experienced DBA Data Engineer to join our growing data team. The ideal candidate will play a key role in designing, implementing, and maintaining our databases and data pipeline architecture. You will collaborate with software engineers, data analysts, and DevOps teams to ensure efficient data flow, data integrity, and optimal database performance across all systems. This role requires a strong foundation in database administration, SQL performance tuning, data modeling, and experience with both on-prem and cloud-based environments.\n\nRequirements:\nBachelors degree in Computer Science, Information Systems, or a related field.\n6+ years of experience in database administration and data engineering.\nProven expertise in RDBMS (Oracle, MySQL, and PostgreSQL) and NoSQL systems (MongoDB, Cassandra).\nExperience managing databases in cloud environments (AWS, Azure, or GCP).\nProficiency in ETL processes and tools (e.g., Apache NiFi, Talend, Informatica, AWS Glue).\nStrong experience with scripting languages such as Python, Bash, or PowerShell.\n\nDBA Data Engineer Roles & Responsibilities:\nDesign and maintain scalable and high-performance database architectures.\nMonitor and optimize database performance using tools like CloudWatch, Oracle Enterprise Manager, pgAdmin, Mongo Compass, or Dynatrace.\nDevelop and manage ETL/ELT pipelines to support business intelligence and analytics.\nEnsure data integrity and security through best practices in backup, recovery, and encryption.\nAutomate regular database maintenance tasks using scripting and scheduled jobs.\nImplement high availability, failover, and disaster recovery strategies.\nConduct performance tuning of queries, stored procedures, indexes, and table structures.\nCollaborate with DevOps to automate database deployments using CI/CD and IaC tools (e.g., Terraform, AWS CloudFormation).\nDesign and implement data models, including star/snowflake schemas for data warehousing.\nDocument data flows, data dictionaries, and database configurations.\nManage user access and security policies using IAM roles or database-native permissions.\nAnalyze existing data systems and propose modernization or migration plans (on-prem to cloud, SQL to NoSQL, etc.).\nUse AWS RDS, Amazon Redshift, Azure SQL Database, or Google BigQuery as needed.\nStay up-to-date with emerging database technologies and make recommendations.\n\nMust-Have Skills:\nDeep knowledge of SQL and database performance tuning.\nHands-on experience with database migrations and replication strategies.\nFamiliarity with data governance, data quality, and compliance frameworks (GDPR, HIPAA, etc.).\nStrong problem-solving and troubleshooting skills.\nExperience with data streaming platforms such as Apache Kafka, AWS Kinesis, or Apache Flink is a plus.\nExperience with data lake and data warehouse architectures.\nExcellent communication and documentation skills.\n\nSoft Skills:\nProblem-Solving: Ability to analyze complex problems and develop effective solutions.\nCommunication Skills: Strong verbal and written communication skills to effectively collaborate with cross-functional teams.\nAnalytical Thinking: Ability to think critically and analytically to solve technical challenges.\nTime Management: Capable of managing multiple tasks and deadlines in a fast-paced environment.\nAdaptability: Ability to quickly learn and adapt to new technologies and methodologies.\n\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Database Administration', 'Database Migration', 'Dba Skills', 'High Availability', 'Db Administration', 'Hadr', 'Database Security', 'Disaster Recovery', 'Dr Testing', 'DR', 'Luw', 'Db Upgrade', 'Brtools', 'UDDI', 'Os Migration', 'Dbase', 'DBMS', 'IBM DB2', 'Db Migration', 'Disaster Recovery Planning', 'Db Dba', 'Backup And Recovery']",2025-06-12 14:15:20
Data Analytics Mgr,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will report to the Organizational Planning Analytics & Insights Procurement & Sourcing Lead, you will support Amgens Tech & Workforce Strategy by applying business analytics and change leadership skills to drive insights that impact resource allocation and sourcing strategy.\n\nYour responsibilities include dashboard development, ad-hoc reporting, business partnering & engagement, and financial baselining. This role supports organizational change and enables the development of an integrated approach to global sourcing and financial planning.\n\nReporting to the Organizational Planning Analytics & Insights Procurement & Sourcing Lead, you will support Amgens Tech & Workforce Strategy by applying business analytics and change management skills to drive insights that impact resource allocation and sourcing strategy.\n\nYour responsibilities include dashboard development, ad-hoc reporting, business partnering & engagement, and financial baselining. This role supports change management and enables the development of an integrated approach to global sourcing and financial planning.\n\nRoles & Responsibilities:\nAddressing business challenges through process evaluation and insight generation.\nDevelop insights with a strong focus on Tableau and Power BI dashboard creation, as well as PowerPoint presentations.\nGuide data analysts and data engineers on standard methodologies for building data pipelines to support dashboards and other business objectives.\nConduct ad hoc analyses of FP&A and sourcing/procurement data.\nAddressing business challenges through process evaluation and insight generation.\nDevelop insights with a strong focus on Tableau and Power BI dashboard creation, as well as PowerPoint presentations.\nGuide data analysts and data engineers on standard methodologies for building data pipelines to support dashboards and other business objectives.\nConduct ad hoc analyses of FP&A and sourcing/procurement data.\nWhat we expect of you\n\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nMasters degree and 4 to 6 years of applicable experience in business analysis (finance analysis, data analysis, sourcing analysis, or similar experience OR\nBachelors degree and 6 to 8 years of applicable experience in business analysis (finance analysis, data analysis, sourcing analysis, or similar experience OR\nDiploma and 10 to 12 years of applicable experience in business analysis (finance analysis, data analysis, sourcing analysis, or similar experience\nPreferred Qualifications:\nMasters degree in data science, business, statistics, data mining, applied mathematics, business analytics, engineering, computer science, or a related field\n4 years of relevant experience in data science, data analytics, consulting, and/or financial planning & analysis.\nA keen eye for design, with the ability to craft engaging PowerPoint decks and develop compelling Power BI and Tableau dashboards.\nProven expertise in statistical/mathematical modeling and working with structured/unstructured data.\nExperience with procurement, sourcing, and/or financial planning data.\nSkilled in automating data workflows using tools like Tableau, Python, R, Alteryx, and PowerApps.\nKnowledge of global finance systems, Procurement, and sourcing operations.\nExperience with data analysis, budgeting, forecasting, and strategic planning in the Bio-Pharmaceutical or biotech industry.\nGrowing in a start-up environment, building a data-driven transformation capability.\nUnderstanding of the Bio-Pharmaceutical and biotech industry trends and operations.\nProven ability to engage with cross-functional business leaders to align data strategies with corporate objectives, redefining complex data insights into actionable strategies.\nFlexible work models, including remote work arrangements, where possible\n\nAs we work to develop treatments that deal with others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, well support your journey every step of the way.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'data analytics', 'data science', 'mathematical modeling', 'financial planning', 'financial planning and analysis', 'statistics']",2025-06-12 14:15:22
"Data Engineer, AVP",NatWest Markets,16 - 18 years,Not Disclosed,['Gurugram'],"Join us as a Data Engineer\nWe re looking for someone to build effortless, digital first customer experiences to help simplify our organisation and keep our data safe and secure\nDay-to-day, you ll develop innovative, data-driven solutions through data pipelines, modelling and ETL design while inspiring to be commercially successful through insights\nIf you re ready for a new challenge, and want to bring a competitive edge to your career profile by delivering streaming data ingestions, this could be the role for you\nWere offering this role at assistant vice president level\nWhat you ll do\nYour daily responsibilities will include you developing a comprehensive knowledge of our data structures and metrics, advocating for change when needed for product development. You ll also provide transformation solutions and carry out complex data extractions.\nWe ll expect you to develop a clear understanding of data platform cost levels to build cost-effective and strategic solutions. You ll also source new data by using the most appropriate tooling before integrating it into the overall solution to deliver it to our customers.\nYou ll also be responsible for:\nDriving customer value by understanding complex business problems and requirements to correctly apply the most appropriate and reusable tools to build data solutions\nParticipating in the data engineering community to deliver opportunities to support our strategic direction\nCarrying out complex data engineering tasks to build a scalable data architecture and the transformation of data to make it usable to analysts and data scientists\nBuilding advanced automation of data engineering pipelines through the removal of manual stages\nLeading on the planning and design of complex products and providing guidance to colleagues and the wider team when required\nThe skills you ll need\nTo be successful in this role, you ll have an understanding of data usage and dependencies with wider teams and the end customer. You ll also have experience of extracting value and features from large scale data.\nWe ll expect you to have experience of ETL technical design, data quality testing, cleansing and monitoring, data sourcing, exploration and analysis, and data warehousing and data modelling capabilities.\nYou ll also need:\nExperience of using programming languages alongside knowledge of data and software engineering fundamentals\nGood knowledge of modern code development practices\nGreat communication skills with the ability to proactively engage with a range of stakeholders\nHours\n45\nJob Posting Closing Date:\n16/06/2025",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Usage', 'Technical design', 'Programming', 'Data structures', 'Data quality', 'Assistant Vice President', 'Data warehousing', 'Monitoring', 'Data architecture']",2025-06-12 14:15:25
Data Engineer - R&D Data Catalyst Team,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role, you will be responsible for the end-to-end development of an enterprise analytics and data mastering solution using Databricks and Power BI. This role requires expertise in both data architecture and analytics, with the ability to create scalable, reliable, and impactful enterprise solutions that research cohort-building and advanced research pipeline. The ideal candidate will have experience creating and surfacing large unified repositories of human data, based on integrations from multiple repositories and solutions, and be extraordinarily skilled with data analysis and profiling.\nYou will collaborate closely with key customers, product team members, and related IT teams, to design and implement data models, integrate data from various sources, and ensure best practices for data governance and security. The ideal candidate will have a good background in data warehousing, ETL, Databricks, Power BI, and enterprise data mastering.\nDesign and build scalable enterprise analytics solutions using Databricks, Power BI, and other modern data tools.\nLeverage data virtualization, ETL, and semantic layers to balance need for unification, performance, and data transformation with goal to reduce data proliferation\nBreak down features into work that aligns with the architectural direction runway\nParticipate hands-on in pilots and proofs-of-concept for new patterns\nCreate robust documentation from data analysis and profiling, and proposed designs and data logic\nDevelop advanced sql queries to profile, and unify data\nDevelop data processing code in sql, along with semantic views to prepare data for reporting\nDevelop PowerBI Models and reporting packages\nDesign robust data models, and processing layers, that support both analytical processing and operational reporting needs.\nDesign and develop solutions based on best practices for data governance, security, and compliance within Databricks and Power BI environments.\nEnsure the integration of data systems with other enterprise applications, creating seamless data flows across platforms.\nDevelop and maintain Power BI solutions, ensuring data models and reports are optimized for performance and scalability.\nCollaborate with key customers to define data requirements, functional specifications, and project goals.\nContinuously evaluate and adopt new technologies and methodologies to enhance the architecture and performance of data solutions.\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The R&D Data Catalyst Team is responsible for building Data Searching, Cohort Building, and Knowledge Management tools that provide the Amgen scientific community with visibility to Amgens wealth of human datasets, projects and study histories, and knowledge over various scientific findings. These solutions are pivotal tools in Amgens goal to accelerate the speed of discovery, and speed to market of advanced precision medications.\nBasic Qualifications:\nMasters degree and 1 to 3 years of Data Engineering experience OR\nBachelors degree and 3 to 5 years of Data Engineering experience OR\nDiploma and 7 to 9 years of Data Engineering experience\nMust Have Skills:\nMinimum of 3 years of hands-on experience with BI solutions (Preferable Power BI or Business Objects) including report development, dashboard creation, and optimization.\nMinimum of 3 years of hands-on experience building Change-data-capture (CDC) ETL pipelines, data warehouse design and build, and enterprise-level data management.\nHands-on experience with Databricks, including data engineering, optimization, and analytics workloads.\nDeep understanding of Power BI, including model design, DAX, and Power Query.\nProven experience designing and implementing data mastering solutions and data governance frameworks.\nExpertise in cloud platforms (AWS), data lakes, and data warehouses.\nStrong knowledge of ETL processes, data pipelines, and integration technologies.\nGood communication and collaboration skills to work with cross-functional teams and senior leadership.\nAbility to assess business needs and design solutions that align with organizational goals.\nExceptional hands-on capabilities with data profiling, data transformation, data mastering\nSuccess in mentoring and training team members\nGood to Have Skills:\nITIL Foundation or other relevant certifications (preferred)\nSAFe Agile Practitioner (6.0)\nMicrosoft Certified: Data Analyst Associate (Power BI) or related certification.\nDatabricks Certified Professional or similar certification.\nSoft Skills:\nExcellent analytical and troubleshooting skills\nDeep intellectual curiosity\nThe highest degree of initiative and self-motivation\nStrong verbal and written communication skills, including presentation to varied audiences of complex technical/business topics\nConfidence technical leader\nAbility to work effectively with global, remote teams, specifically including using of tools and artifacts to assure clear and efficient collaboration across time zones\nAbility to handle multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong problem solving, analytical skills;\nAbility to learn quickly and retain and synthesize complex information from diverse sources.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'data management', 'Power BI', 'data governance', 'data warehousing', 'Databricks', 'ETL', 'AWS']",2025-06-12 14:15:27
Data Engineer,Atyeti,2 - 4 years,Not Disclosed,['Pune'],"Role & responsibilities\n\nDevelop and Maintain Data Pipelines: Design, develop, and manage scalable ETL pipelines to process large datasets using PySpark, Databricks, and other big data technologies.\nData Integration and Transformation: Work with various structured and unstructured data sources to build efficient data workflows and integrate them into a central data warehouse.\nCollaborate with Data Scientists & Analysts: Work closely with the data science and business intelligence teams to ensure the right data is available for advanced analytics, machine learning, and reporting.",,,,"['Azure Synapse', 'Pyspark', 'ETL', 'Python']",2025-06-12 14:15:30
Data Science Lead,Algoleap Technologies,10 - 15 years,Not Disclosed,['Hyderabad'],"As we build our Data Science Center of Excellence (CoE), we are looking for an entrepreneurial and technically strong Data Science Lead who can lay the foundation for a high-performing team. You will work directly with stakeholders across multiple business units to define use cases, lead model development, and ensure successful deployment and value realization.\n\nKey Responsibilities:\nServe as the technical and strategic lead for the Data Science CoE.",,,,"['customer analytics', 'Usage', 'data science', 'GCP', 'Machine learning', 'model development', 'Deployment', 'Stakeholder management', 'SQL', 'Python']",2025-06-12 14:15:32
Assoc. Data Engineer - R&D Precision Medicine Team,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nThe R&D Precision Medicine team is responsible for Data Standardization, Data Searching, Cohort Building, and Knowledge Management tools that provide the Amgen scientific community with access to Amgens wealth of human datasets, projects and study histories, and knowledge over various scientific findings. These data include clinical data, omics, and images. These solutions are pivotal tools in Amgens goal to accelerate the speed of discovery, and speed to market of advanced precision medications.\n\nThe Data Engineer will be responsible for full stack development of enterprise analytics and data mastering solutions leveraging Databricks and Power BI. This role requires expertise in both data architecture and analytics, with the ability to create scalable, reliable, and high-performing enterprise solutions that support research cohort-building and advanced AI pipelines. The ideal candidate will have experience creating and surfacing large unified repositories of human data, based on integrations from multiple repositories and solutions, and be exceptionally skilled with data analysis and profiling.\n\nYou will collaborate closely with partners, product team members, and related IT teams, to design and implement data models, integrate data from various sources, and ensure best practices for data governance and security. The ideal candidate will have a solid background in data warehousing, ETL, Databricks, Power BI, and enterprise data mastering.\n\nRoles & Responsibilities\nDesign and build scalable enterprise analytics solutions using Databricks, Power BI, and other modern data management tools.\nLeverage data virtualization, ETL, and semantic layers to balance need for unification, performance, and data transformation with goal to reduce data proliferation\nBreak down features into work that aligns with the architectural direction runway\nParticipate hands-on in pilots and proofs-of-concept for new patterns\nCreate robust documentation from data analysis and profiling, and proposed designs and data logic\nDevelop advanced sql queries to profile, and unify data\nDevelop data processing code in sql, along with semantic views to prepare data for reporting\nDevelop PowerBI Models and reporting packages\nDesign robust data models, and processing layers, that support both analytical processing and operational reporting needs.\nDesign and develop solutions based on best practices for data governance, security, and compliance within Databricks and Power BI environments.\nEnsure the integration of data systems with other enterprise applications, creating seamless data flows across platforms.\nDevelop and maintain Power BI solutions, ensuring data models and reports are optimized for performance and scalability.\nCollaborate with partners to define data requirements, functional specifications, and project goals.\nContinuously evaluate and adopt new technologies and methodologies to enhance the architecture and performance of data solutions.\n\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The professional we seek is someone with these qualifications.\n\nBasic Qualifications:\nMasters degree with 1 to 3 years of experience in Data Engineering OR\nBachelors degree with 1 to 3 years of experience in Data Engineering\nMust-Have\n\nSkills:\nMinimum of 1 year of hands-on experience with BI solutions (Preferrable Power BI or Business Objects) including report development, dashboard creation, and optimization.\nMinimum of 1 year of hands-on experience building Change-data-capture (CDC) ETL pipelines, data warehouse design and build, and enterprise-level data management.\nHands-on experience with Databricks, including data engineering, optimization, and analytics workloads.\nExperience using cloud platforms (AWS), data lakes, and data warehouses.\nWorking knowledge of ETL processes, data pipelines, and integration technologies.\nGood communication and collaboration skills to work with cross-functional teams and senior leadership.\nAbility to assess business needs and design solutions that align with organizational goals.\nExceptional hands-on capabilities with data profiling and data anlysis\nGood-to-Have\n\nSkills:\nExperience with human data, ideally human healthcare data\nFamiliarity with laboratory testing, patient data from clinical care, HL7, FHIR, and/or clinical trial data management\nProfessional Certifications:\nITIL Foundation or other relevant certifications (preferred)\nSAFe Agile Practitioner (6.0)\nMicrosoft CertifiedData Analyst Associate (Power BI) or related certification.\nDatabricks Certified Professional or similar certification.\nSoft\n\nSkills:\nExcellent analytical and troubleshooting skills\nDeep intellectual curiosity\nHighest degree of initiative and self-motivation\nStrong verbal and written communication skills, including presentation to varied audiences of complex technical/business topics\nConfidence technical leader\nAbility to work effectively with global, virtual teams, specifically including using of tools and artifacts to assure clear and efficient collaboration across time zones\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong problem solving, analytical skills;\nAbility to learn quickly and retain and synthesize complex information from diverse sources",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'data lakes', 'data pipelines', 'ETL processes', 'AWS', 'data warehouses', 'BI solutions']",2025-06-12 14:15:34
Data Engineer,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nAs part of the cybersecurity organization, the Data Engineer is responsible for designing, building, and maintaining data infrastructure to support data-driven decision-making. This role involves working with large datasets, developing reports, executing data governance initiatives, and ensuring data is accessible, reliable, and efficiently managed. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture, ETL processes, and cybersecurity data frameworks.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in design and development of the data pipeline.\nCreate data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nSchedule and manage workflows the ensure pipelines run on schedule and are monitored for failures.\nCollaborate with cross-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nCollaborate with data scientists to develop pipelines that meet dynamic business needs.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\nFunctional Skills:\nBasic Qualifications:\nMasters degree and 1 to 3 years of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience\nPreferred Qualifications:\nHands on experience with data practices, technologies, and platforms, such as Databricks, Python, Gitlab, LucidChart,etc.\nProficiency in data analysis tools (e.g. SQL) and experience with data sourcing tools\nExcellent problem-solving skills and the ability to work with large, complex datasets\nUnderstanding of data governance frameworks, tools, and best practices\nKnowledge of and experience with data standards (FAIR) and protection regulations and compliance requirements (e.g., GDPR, CCPA)\nGood-to-Have Skills:\nExperience with ETL tools and various Python packages related to data processing, machine learning model development\nStrong understanding of data modeling, data warehousing, and data integration concepts\nKnowledge of Python/R, Databricks, cloud data platforms\nExperience working in Product team's environment\nExperience working in an Agile environment\nProfessional Certifications:\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data engineering', 'data security', 'Agile', 'cloud data platforms', 'Databricks', 'data governance frameworks', 'ETL', 'AWS', 'SQL', 'Python']",2025-06-12 14:15:36
"Quant Data Specialist, Aladdin Financial Engineering - Associate",Primetrace Technologies,3 - 6 years,Not Disclosed,['Gurugram'],"About this role\nAbout Aladdin Financial Engineering (AFE):\nJoin a diverse and collaborative team of over 3 00 modelers and technologists in Aladdin Financial Engineering (AFE) within BlackRock Solutions, the business responsible for the research and development of Aladdin s financial models. This group is also accountable for analytics production, enhancing the infrastructure platform and delivering analytics content to portfolio and risk management professionals (both within BlackRock and across the Aladdin client community). The models developed and supported by AFE span a wide array of financial products covering equities, fixed income, commodities, derivatives, and private markets. AFE provides investment insights that range from an analysis of cash flows on a single bond, to the overall financial risk associated with an entire portfolio, balance sheet, or enterprise.\nRole Description:\nWe are looking for a person to join the Advanced Data Analytics team with AFE Single Security . Advanced Data Analytics is a team of Quantitative Data and Product Specialists, focused on delivering Single Security Data Content, Governance and Product Solutions and Research Platform. The team leverages data, cloud, and emerging technologies in building an innovative data platform, with the focus on business and research use cases in the S ingle S ecurity space. The team uses various statistical/mathematical methodologies to derive insights and generate content to help develop predictive models, clustering, and classification solutions and enable Governance . The team works on Mortgage, Structured & Credit Products.\nWe are looking for a person to help build and expand Data & Analytics Content in the Credit space . The person will be responsible for building, enhancing, and maintaining the Credit Content Suite . The person will work on the below -\nCredit Derived Data Content\nModel & Data Governance\nCredit Model & Analytics\nExperience\nExperience on Scala\nKnowledge of ETL, data curation and analytical jobs using distributed computing framework with Spark\nKnowledge and Experience of working with large enterprise databases like Snowflake, Cassandra & Cloud manged services like Dataproc , Databricks\nKnowledge of financial instruments like Corporate Bonds, Derivatives etc.\nKnowledge of regression methodologies\nAptitude for design and building tools for D ata Governance\nPython knowledge is a plus\nQualifications\nBachelors / masters in computer science with a major in Math, Econ, or related field\n3 - 6 years of relevant experience\nOur benefits\n\n.\nOur hybrid work model\n.\nAbout BlackRock\n.\nThis mission would not be possible without our smartest investment - the one we make in our employees. It s why we re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.\nFor additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com / company / blackrock\nBlackRock is proud to be an Equal Opportunity Employer. We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analytical', 'Fixed income', 'Financial risk', 'Finance', 'Healthcare', 'Data analytics', 'Risk management', 'Analytics', 'Balance Sheet', 'Financial engineering']",2025-06-12 14:15:39
Manager Data Engineer – Research Data and Analytics,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will create and develop data lake solutions for scientific data that drive business decisions for Research. You will build scalable and high-performance data engineering solutions for large scientific datasets and collaborate with Research collaborators. You will also provide technical leadership to junior team members. The ideal candidate possesses experience in the pharmaceutical or biotech industry, demonstrates deep technical skills, is proficient with big data technologies, and has a deep understanding of data architecture and ETL processes.\nRoles & Responsibilities:\nLead, manage, and mentor a high-performing team of data engineers\nDesign, develop, and implement data pipelines, ETL processes, and data integration solutions\nTake ownership of data pipeline projects from inception to deployment, manage scope, timelines, and risks\nDevelop and maintain data models for biopharma scientific data, data dictionaries, and other documentation to ensure data accuracy and consistency\nOptimize large datasets for query performance\nCollaborate with global multi-functional teams including research scientists to understand data requirements and design solutions that meet business needs\nImplement data security and privacy measures to protect sensitive data\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions\nCollaborate with Data Architects, Business SMEs, Software Engineers and Data Scientists to design and develop end-to-end data pipelines to meet fast paced business needs across geographic regions\nIdentify and resolve data-related challenges\nAdhere to best practices for coding, testing, and designing reusable code/component\nExplore new tools and technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The [vital attribute] professional we seek is a [type of person] with these qualifications.\nBasic Qualifications:\nDoctorate Degree OR\nMasters degree with 4 - 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 6 - 8 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 10 - 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nPreferred Qualifications:\n3+ years of experience in implementing and supporting biopharma scientific research data analytics (software platforms)\n\n\nFunctional Skills:\nMust-Have Skills:\nProficiency in SQL and Python for data engineering, test automation frameworks (pytest), and scripting tasks\nHands on experience with big data technologies and platforms, such as Databricks, Apache Spark (PySpark, SparkSQL), workflow orchestration, performance tuning on big data processing\nExcellent problem-solving skills and the ability to work with large, complex datasets\nAble to engage with business collaborators and mentor team to develop data pipelines and data models\n\n\nGood-to-Have Skills:\nA passion for tackling complex challenges in drug discovery with technology and data\nGood understanding of data modeling, data warehousing, and data integration concepts\nGood experience using RDBMS (e.g. Oracle, MySQL, SQL server, PostgreSQL)\nKnowledge of cloud data platforms (AWS preferred)\nExperience with data visualization tools (e.g. Dash, Plotly, Spotfire)\nExperience with diagramming and collaboration tools such as Miro, Lucidchart or similar tools for process mapping and brainstorming\nExperience writing and maintaining technical documentation in Confluence\nUnderstanding of data governance frameworks, tools, and best practices\n\n\nProfessional Certifications:\nDatabricks Certified Data Engineer Professional preferred\n\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nDemonstrated presentation skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Spotfire', 'PySpark', 'PostgreSQL', 'Plotly', 'SparkSQL', 'SQL server', 'SQL', 'process mapping', 'Dash', 'MySQL', 'ETL', 'Oracle', 'data governance frameworks', 'Python']",2025-06-12 14:15:41
Data Science Professional,Algoleap Technologies,6 - 11 years,Not Disclosed,['Hyderabad'],"Job_Description"":""\nJob Title: Data Science CoE\nLocation: Hyderabad, India (Hybrid)\nExperience: 6+ years\nRole Type: Full-time\nStart Date : Immediate\nAbout the Role:\nAs we build our Data Science Center of Excellence (CoE), we are looking for an entrepreneurial and technically strong Data Science Lead who can lay the foundation for a high-performing team. You will work directly with stakeholders across multiple business units to define use cases, lead model development, and ensure successful deployment and value realization.",,,,"['customer analytics', 'Usage', 'data science', 'GCP', 'Machine learning', 'model development', 'Deployment', 'Stakeholder management', 'SQL', 'Python']",2025-06-12 14:15:44
Big Data Developer,Techstar Group,7 - 10 years,Not Disclosed,['Hyderabad'],"Responsibilities of the Candidate :\n\n- Be responsible for the design and development of big data solutions. Partner with domain experts, product managers, analysts, and data scientists to develop Big Data pipelines in Hadoop\n\n- Be responsible for moving all legacy workloads to a cloud platform\n\n- Work with data scientists to build Client pipelines using heterogeneous sources and provide engineering services for data PySpark science applications\n\n- Ensure automation through CI/CD across platforms both in cloud and on-premises\n\n- Define needs around maintainability, testability, performance, security, quality, and usability for the data platform\n\n- Drive implementation, consistent patterns, reusable components, and coding standards for data engineering processes\n\n- Convert SAS-based pipelines into languages like PySpark, and Scala to execute on Hadoop and non-Hadoop ecosystems\n\n- Tune Big data applications on Hadoop and non-Hadoop platforms for optimal performance\n\n- Apply an in-depth understanding of how data analytics collectively integrate within the sub-function as well as coordinate and contribute to the objectives of the entire function.\n\n- Produce a detailed analysis of issues where the best course of action is not evident from the information available, but actions must be recommended/taken.\n\n- Assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients, and assets, by driving compliance with applicable laws, rules, and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct, and business practices, and escalating, managing and reporting control issues with transparency\n\nRequirements :\n\n- 6+ years of total IT experience\n\n- 3+ years of experience with Hadoop (Cloudera)/big data technologies\n\n- Knowledge of the Hadoop ecosystem and Big Data technologies Hands-on experience with the Hadoop eco-system (HDFS, MapReduce, Hive, Pig, Impala, Spark, Kafka, Kudu, Solr)\n\n- Experience in designing and developing Data Pipelines for Data Ingestion or Transformation using Java Scala or Python.\n\n- Experience with Spark programming (Pyspark, Scala, or Java)\n\n- Hands-on experience with Python/Pyspark/Scala and basic libraries for machine learning is required.\n\n- Proficient in programming in Java or Python with prior Apache Beam/Spark experience a plus.\n\n- Hand on experience in CI/CD, Scheduling and Scripting\n\n- Ensure automation through CI/CD across platforms both in cloud and on-premises\n\n- System level understanding - Data structures, algorithms, distributed storage & compute\n\n- Can-do attitude on solving complex business problems, good interpersonal and teamwork skills",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Big Data', 'Hive', 'Data Engineering', 'Data Pipeline', 'PySpark', 'Hadoop', 'Kafka', 'HDFS', 'Spark', 'Python']",2025-06-12 14:15:46
Data Engineer,Databeat,3 - 7 years,Not Disclosed,['Hyderabad( Rai Durg )'],"Experience Required: 3+ years\n\nTechnical knowledge: AWS, Python, SQL, S3, EC2, Glue, Athena, Lambda, DynamoDB, RedShift, Step Functions, Cloud Formation, CI/CD Pipelines, Github, EMR, RDS,AWS Lake Formation, GitLab, Jenkins and AWS CodePipeline.\n\n\n\nRole Summary: As a Senior Data Engineer,with over 3 years of expertise in Python, PySpark, SQL to design, develop and optimize complex data pipelines, support data modeling, and contribute to the architecture that supports big data processing and analytics to cutting-edge cloud solutions that drive business growth. You will lead the design and implementation of scalable, high-performance data solutions on AWS and mentor junior team members.This role demands a deep understanding of AWS services, big data tools, and complex architectures to support large-scale data processing and advanced analytics.\nKey Responsibilities:\nDesign and develop robust, scalable data pipelines using AWS services, Python, PySpark, and SQL that integrate seamlessly with the broader data and product ecosystem.\nLead the migration of legacy data warehouses and data marts to AWS cloud-based data lake and data warehouse solutions.\nOptimize data processing and storage for performance and cost.\nImplement data security and compliance best practices, in collaboration with the IT security team.\nBuild flexible and scalable systems to handle the growing demands of real-time analytics and big data processing.\nWork closely with data scientists and analysts to support their data needs and assist in building complex queries and data analysis pipelines.\nCollaborate with cross-functional teams to understand their data needs and translate them into technical requirements.\nContinuously evaluate new technologies and AWS services to enhance data capabilities and performance.\nCreate and maintain comprehensive documentation of data pipelines, architectures, and workflows.\nParticipate in code reviews and ensure that all solutions are aligned to pre-defined architectural specifications.\nPresent findings to executive leadership and recommend data-driven strategies for business growth.\nCommunicate effectively with different levels of management to gather use cases/requirements and provide designs that cater to those stakeholders.\nHandle clients in multiple industries at the same time, balancing their unique needs.\nProvide mentoring and guidance to junior data engineers and team members.\n\n\n\nRequirements:\n3+ years of experience in a data engineering role with a strong focus on AWS, Python, PySpark, Hive, and SQL.\nProven experience in designing and delivering large-scale data warehousing and data processing solutions.\nLead the design and implementation of complex, scalable data pipelines using AWS services such as S3, EC2, EMR, RDS, Redshift, Glue, Lambda, Athena, and AWS Lake Formation.\nBachelor's or Masters degree in Computer Science, Engineering, or a related technical field.\nDeep knowledge of big data technologies and ETL tools, such as Apache Spark, PySpark, Hadoop, Kafka, and Spark Streaming.\nImplement data architecture patterns, including event-driven pipelines, Lambda architectures, and data lakes.\nIncorporate modern tools like Databricks, Airflow, and Terraform for orchestration and infrastructure as code.\nImplement CI/CD using GitLab, Jenkins, and AWS CodePipeline.\nEnsure data security, governance, and compliance by leveraging tools such as IAM, KMS, and AWS CloudTrail.\nMentor junior engineers, fostering a culture of continuous learning and improvement.\nExcellent problem-solving and analytical skills, with a strategic mindset.\nStrong communication and leadership skills, with the ability to influence stakeholders at all levels.\nAbility to work independently as well as part of a team in a fast-paced environment.\nAdvanced data visualization skills and the ability to present complex data in a clear and concise manner.\nExcellent communication skills, both written and verbal, to collaborate effectively across teams and levels.\n\nPreferred Skills:\nExperience with Databricks, Snowflake, and machine learning pipelines.\nExposure to real-time data streaming technologies and architectures.\nFamiliarity with containerization and serverless computing (Docker, Kubernetes, AWS Lambda).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Aws Glue', 'SQL', 'Data Pipeline', 'Python', 'Amazon Ec2', 'Data Engineering', 'Data Bricks', 'Aws Lambda', 'Amazon Redshift', 'Azure Cloud', 'Data Lake', 'Data Modeling', 'Athena']",2025-06-12 14:15:48
Job opening For Data Warehouse + ADF + ETL,bct,3 - 6 years,Not Disclosed,['Pune'],"Greetings of the Day !!!\n\nWe have job opening for Data Warehouse + ADF + ETL with one of our Client .If you are interested for this role , kindly share update resume along with below details in this email id : shaswati.m@bct-consulting.com\n\nJob Description:\nSenior Data Engineer\nAs a Senior Data Engineer, you will support the European World Area using the Windows & Azure suite of Analytics & Data platforms. The focus of the role is on the technical aspects and implementation of data gathering, integration and database design.\nWe look forward to seeing your application!\nIn This Role, Your Responsibilities Will Be:\nData Ingestion and Integration: Collaborate with Product Owners and analysts to understand data requirements & design, develop, and maintain data pipelines for ingesting, transforming, and integrating data from various sources into Azure Data Services.\nMigration of existing ETL packages: Migrate existing SSIS packages to Synapse pipelines\nData Modelling: Assist in designing and implementing data models, data warehouses, and databases in Azure Synapse Analytics, Azure Data Lake Storage, and other Azure services.\nData Transformation: Develop ETL (Extract, Transform, Load) processes using SQL Server Integration Services (SSIS), Azure Synapse Pipelines, or other relevant tools to prepare data for analysis and reporting.\nData Quality and Governance: Implement data quality checks and data governance practices to ensure the accuracy, consistency, and security of data assets.\nMonitoring and Optimization: Monitor and optimize data pipelines and workflows for performance, scalability, and cost efficiency.\nDocumentation: Maintain comprehensive documentation of processes, including data lineage, data dictionaries, and pipeline schedules.\nCollaboration: Work closely with cross-functional teams, including data analysts, data scientists, and business stakeholders, to understand their data needs and deliver solutions accordingly.\nAzure Services: Stay updated on Azure data services and best practices to recommend and implement improvements in our data architecture and processes\nFor This Role, You Will Need:\n3-5 years of experience in Data Warehousing with On-Premises or Cloud technologies\nStrong practical experience of Synapse pipelines / ADF.\nStrong practical experience of developing ETL packages using SSIS.\nStrong practical experience with T-SQL or any variant from other RDBMS.\nGraduate degree educated in computer science or a relevant subject.\nStrong analytical and problem-solving skills.\nStrong communication skills in dealing with internal customers from a range of functional areas.\nWillingness to work flexible working hours according to project requirements.\nTechnical documentation skills.\nFluent in English.\nPreferred Qualifications that Set You Apart:\nOracle PL/SQL.\nExperience in working on Azure Services like Azure Synapse Analytics, Azure Data Lake.\nWorking experience with Azure DevOps paired with knowledge of Agile and/or Scrum methods of delivery.\nLanguages: French, Italian, or Spanish would be an advantage.\nAgile certification.\nThanks,\nShaswati",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['ADF', 'ETL', 'SSIS', 'Data ware house']",2025-06-12 14:15:51
MDM Associate Data Engineer,Amgen Inc,1 - 4 years,Not Disclosed,['Hyderabad'],"We are seeking an MDM Associate Data Engineerwith 25 years of experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability. The ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.To succeed in this role, the candidate must have strong data engineering experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have data engineering experience on technologies like (SQL, Python, PySpark, Databricks, AWS etc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark, and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\nAdvanced SQL expertise and data wrangling.\nStrong experience in Python and PySpark for data transformation workflows.\nStrong experience with Databricks and AWS architecture.\nMust have knowledge of MDM, data governance, stewardship, and profiling practices.\nIn addition to above, candidates having experience with Informatica or Reltio MDM platforms will be preferred.\nGood-to-Have Skills:\nExperience with IDQ, data modeling and approval workflow/DCR.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nStrong grip on data engineering concepts.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL, Python, Databricks)\nAny cloud certification (AWS or AZURE)\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM', 'PySpark', 'AWS architecture', 'Jira', 'Reltio', 'SQL', 'Informatica MDM', 'data modeling', 'Confluence', 'IDQ', 'Databricks', 'data stewardship processes', 'Python']",2025-06-12 14:15:53
Lead Data Engineer - Azure,Blend360 India,7 - 12 years,Not Disclosed,['Hyderabad'],"As a Sr Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\n7+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar field\nMust have experience e",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:15:55
Data Engineer IV - Big Data / Spark,Sadup Soft,5 - 7 years,Not Disclosed,['Chennai'],"Must have skills :\n\n- Minimum of 5-7 years of experience in software development, with a focus on Java and infrastructure tools.\n\n- Min 6+ years of experience as a Data Engineer.\n\n- Good Experience in handling Big Data Spark, Hive SQL, BigQuery, SQL.\n\n- Candidate worked on cloud platforms and GCP would be an added advantage.\n\n- Good understanding of Hadoop based ecosystem including hard sequel, HDFS would be very essential.\n\n- Very good professional knowledge of PySpark or using Scala\n\nResponsibilities :\n\n- Collaborate with cross-functional teams such as Data Scientists, Product Partners and Partner Team Developers to identify opportunities for Big Data, Query ( Spark, Hive SQL, BigQuery, SQL ) tuning opportunities that can be solved using machine learning and generative AI.\n\n- Write clean, high-performance, high-quality, maintainable code.\n\n- Design and develop Big Data Engineering Solutions Applications for above ensuring scalability, efficiency, and maintainability of such solutions.\n\nRequirements :\n\n- A Bachelor or Master's degree in Computer Science or a related field.\n\n- Proven experience working as a Big Data & MLOps Engineer, with a focus on Spark, Scala Spark or PySpark, Spark SQL, BigQuery, Python, Google Cloud,.\n\n- Deep understanding and experience in tuning Dataproc, BigQuery, Spark Applications.\n\n- Solid knowledge of software engineering best practices, including version control systems (e.g Git), code reviews, and testing methodologies.\n\n- Strong communication skills to effectively collaborate and present findings to both technical and non-technical stakeholders.\n\n- Proven ability to adapt and learn new technologies and frameworks quickly.\n\n- A proactive mindset with a passion for continuous learning and research.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Big Data', 'Data Engineering', 'BigQuery', 'GCP', 'Spark', 'Machine Learning', 'Python', 'SQL']",2025-06-12 14:15:58
Trainee Risk Advisory Services (Internal Audit),Dpnc Global,0 - 1 years,Not Disclosed,['Noida'],"DPNC Global is looking for Trainee Risk Advisory Services (Internal Audit) to join our dynamic team and embark on a rewarding career journey.\n\nInternal Auditing : Conducting internal audits to evaluate the effectiveness of internal controls, risk management, and governance processes. Reviewing financial statements, operations, and various business processes. Risk Advisory : Providing advisory services related to risk management, helping the organization identify and mitigate potential risks. Developing strategies for risk avoidance, acceptance, reduction, or transfer. Compliance Assessment : Assessing and ensuring compliance with relevant laws, regulations, and internal policies. Identifying areas of non - compliance and recommending corrective actions. Audit Planning : Participating in the planning of audit projects, including defining the scope, objectives, and methodologies. Developing risk - based audit plans. Audit Execution : Performing audit procedures, including testing controls, reviewing documentation, and conducting interviews. Analyzing and interpreting data to draw meaningful conclusions. Report Generation : Preparing detailed and insightful audit reports outlining findings, recommendations, and action plans. Presenting audit reports to management and stakeholders. Continuous Monitoring : Implementing continuous monitoring processes to stay abreast of changes in risk factors and internal control environments. Recommending adjustments to audit plans as needed. Process Improvement : Identifying opportunities for process improvements and operational efficiencies based on audit findings. Collaborating with relevant departments to implement recommended changes. Training and Awareness : Conducting training sessions and awareness programs on risk management and internal controls for employees. Promoting a culture of risk awareness and compliance within the organization. Stakeholder Communication : Communicating with key stakeholders, including senior management and the audit committee. Providing updates on audit progress, findings, and recommendations. Technology Utilization : Leveraging technology tools for data analysis, audit automation, and risk assessment. Keeping up to date with advancements in audit technologies. Fraud Detection : Participating in fraud risk assessments and implementing measures to detect and prevent fraudulent activities.",Industry Type: Management Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Risk advisory', 'Manager Internal Audit', 'IPCC']",2025-06-12 14:16:00
CMA fresher,JTEKT India,0 - 3 years,Not Disclosed,['Gurugram'],"Role & responsibilities\nEnsuring accuracy and timeliness in financial reporting\nSupporting compliance with Ind AS, Companies Act, and other regulations\nAssisting in internal control processes and audit preparedness\nPreparing financial statements and conducting data analysis\nEnsure timely and correct data for Audit\nAssisting and doing internal and Statutory audits\n\n\nPreferred candidate profile\nCMA qualified (mandatory)\nBasic knowledge of Ind AS and regulatory compliance\nProficiency in Oracle ERP\nStrong Excel and analytical skills\nGood communication and attention to detail",Industry Type: Auto Components,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Auditing', 'Statutory Audit', 'Internal Audit', 'Communication Skills', 'Compliance', 'Reporting']",2025-06-12 14:16:02
Research Assistant,Panacorp Software Solutions,0 - 1 years,Not Disclosed,"['Nagercoil', 'Kanyakumari']","Key Responsibilities:\nAssist with the design and execution of research projects\nCollect, organize, and analyze data using various research methodologies\nPrepare and review research documents, reports, and presentations\nConduct literature reviews and summarize relevant research articles\nCollaborate with other team members and researchers to facilitate research activities\nEnsure the quality and accuracy of research data and findings\nSupport researchers in experimental tasks and lab work (if applicable)\nQualifications:\nEducation: BE/B.Tech (Recent Graduates) or relevant degree\nExperience: 0-1+ year(s) of experience in research projects\nSkills:\nStrong analytical and problem-solving skills\nFamiliarity with data analysis software (e.g., MS Excel, MATLAB, Python, or R)\nExcellent communication skills (both verbal and written)\nAbility to work independently as well as part of a collaborative team\nAttention to detail and ability to manage time effectively",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['Python', 'MS Excel', 'R Programming', 'Data Analysis', 'MATLAB', 'research projects']",2025-06-12 14:16:04
Growth Intern,The Peak View Stories,0 - 3 years,Not Disclosed,[],"Assist in developing and implementing growth strategies for the organization.\nConduct market research and analyze data to identify growth opportunities.\nSupport marketing and sales efforts to acquire new customers.\nCollaborate with cross-functional teams to execute growth initiatives.\nMonitor and report on the performance of growth strategies.\nProvide administrative support for growth projects and campaigns.\nStay updated on industry trends and best practices in growth marketing.\n\n\nAnalytics, headlines, SEOif these make your eyes light up, we need you.",Industry Type: Miscellaneous,Department: Research & Development,"Employment Type: Full Time, Permanent","['data analysis', 'business analysis', 'business development', 'teaching', 'market research', 'analysis', 'research', 'sales', 'market analysis', 'brand management', 'marketing', 'secondary research', 'key account management', 'research and development', 'communication skills']",2025-06-12 14:16:06
"Business Intelligence Engineer, RBS ARTS",Amazon,5 - 10 years,Not Disclosed,['Chennai'],"An candidate will be a self-starter who is passionate about discovering and solving complicated problems, learning complex systems, working with numbers, and organizing and communicating data and reports. You will be detail-oriented and organized, capable of handling multiple projects at once, and capable of dealing with ambiguity and rapidly changing priorities. You will have expertise in process optimizations and systems thinking and will be required to engage directly with multiple internal teams to drive business projects/automation for the RBS team. Candidates must be successful both as individual contributors and in a team environment, and must be customer-centric. Our environment is fast-paced and requires someone who is flexible, detail-oriented, and comfortable working in a deadline-driven work environment. Responsibilities Include Works across team(s) and Ops organization at country, regional and/or cross regional level to drive improvements and enables to implement solutions for customer, cost savings in process workflow, systems configuration and performance metrics.\n\nBasic Qualifications\nBachelors degree in Computer Science, Information Technology, or a related field\nProficiency in automation using Python\nExcellent oral and written communication skills\nExperience with SQL, ETL processes, or data transformation\n\nPreferred Qualifications\nExperience with scripting and automation tools\nFamiliarity with Infrastructure as Code (IaC) tools such as AWS CDK\nKnowledge of AWS services such as SQS, SNS, CloudWatch and DynamoDB\nUnderstanding of DevOps practices, including CI/CD pipelines and monitoring solutions\nUnderstanding of cloud services, serverless architecture, and systems integration\n\n\nAs a Business Intelligence Engineer in the team, you will collaborate closely with business partners, architect, design, implement, and BI projects & Automations.\n\nResponsibilities:\n\nDesign, development and ongoing operations of scalable, performant data warehouse (Redshift) tables, data pipelines, reports and dashboards.\nDevelopment of moderately to highly complex data processing jobs using appropriate technologies (eg SQL, Python, Spark, AWS Lambda, etc)\nDevelopment of dashboards and reports.\nCollaborating with stakeholders to understand business domains, requirements, and expectations. Additionally, working with owners of data source systems to understand capabilities and limitations.\nDeliver minimally to moderately complex data analysis; collaborating as needed with Data Science as complexity increases.\nActively manage the timeline and deliverables of projects, anticipate risks and resolve issues.\nAdopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.\nInternal job description\n\nRetail Business Service, ARTS is a growing team that supports the Retail Efficiency and Paid Services business and tech teams. There is ample growth opportunity in this role for someone who exhibits Ownership and Insist on the Highest Standards, and has strong engineering and operational best practices experience.\n\nBasic qualifications:\n\n5+ years of relevant professional experience in business intelligence, analytics, statistics, data engineering, data science or related field.\nExperience with Data modeling, SQL, ETL, Data Warehousing and Data Lakes.\nStrong experience with engineering and operations best practices (version control, data quality/testing, monitoring, etc)\nExpert-level SQL.\nProficiency with one or more general purpose programming languages (eg Python, Java, Scala, etc)\nKnowledge of AWS products such as Redshift, Quicksight, and Lambda.\nExcellent verbal/written communication & data presentation skills, including ability to succinctly summarize key findings and effectively communicate with both business and technical teams.\n\nPreferred qualifications:\n\nExperience with data-specific programming languages/packages such as R or Python Pandas.\nExperience with AWS solutions such as EC2, DynamoDB, S3, and EMR.\nKnowledge of machine learning techniques and concepts. 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc experience\nExperience with data visualization using Tableau, Quicksight, or similar tools\nExperience with data modeling, warehousing and building ETL pipelines\nExperience in Statistical Analysis packages such as R, SAS and Matlab\nExperience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift\nExperience in data mining, ETL, etc and using databases in a business environment with large-scale, complex datasets",,,,"['SAS', 'Data modeling', 'Oracle', 'Business intelligence', 'MATLAB', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-12 14:16:09
Senior Mis Executive,Thyrocare,2 - 6 years,2.5-5 Lacs P.A.,['Mumbai (All Areas)'],"Roles and Responsibilities\nAnalyse, extract, and review relevant data from various client and proprietary systems to create spreadsheet reports for use of management, efficiency, quality, and productivity analysis, employee stack-ranking, cost analysis, billing/invoicing\nAnalyse data and publish daily, weekly and monthly reports as per the pre-defined timelines\nBuild and manage the tools to collect raw data that is not available from current software and systems.\nCreate multi-level reports from the same data to serve multiple stakeholders with minimum manual re-work\nSuch other activities as may be assigned by your manager\nParticipate in cross-functional meetings to resolve recurring customer issues.\nAnalyze current business processes and make recommendations for improvements\nMaintain thorough understanding of data and information resources\nMaintain a status on all projects and proactively communicate with management\n\nDesired Candidate Profile\nCandidates with 3+ Years of experience in creating and maintaining MIS reports for Banking, Financial Services, BPO/KPO/LPO, or Back-office Operations.\nAdvanced Excel Knowledge including but not limited to: Creating Impressive Dashboards, working with large excel data running into lakhs of rows and several hundred columns, use of excel tools and formulas: pivot, xlookup, vlookup, index, sumifs, countifs, maxifs, sumproduct, offset, string and date related formulas, multiple layer nested if loops, rank, use of array formulas such as unique, filter, sort, sortby.\nAnd Knowledge of Big Data analysis tools such as SQL, Python etc\nKnowledge of Power Suite: Power Query, Power Automate and Power BI would be an added advantage\nProficiency with macros and VBA coding would be an added advantage\nHigh attention to detail\nMust have an analytical bent of mind\nShould be able to build tools with high scalability and agility\nQualifications/ Requirements:\nUG- Any Graduate\nHigh producer with attention to quality\nStrong PC skills, with demonstrated proficiency with Microsoft Office\nWilling to work in shifts as per business requirements\nWillingness to learn and invest time and effort for career development.",Industry Type: Pharmaceutical & Life Sciences,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Purchase', 'MIS', 'Advanced Excel', 'MIS Preparation', 'MIS Operations', 'Supply Chain Management', 'MIS Reporting', 'Management Information System', 'Inventory', 'Excel Report Preparation']",2025-06-12 14:16:11
Data Specialist - Research,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Research domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Research domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Agile', 'Data quality', 'SQL']",2025-06-12 14:16:13
DBA DATA Engineer || 12 Lakhs CTC,Robotics Technologies,8 - 9 years,12 Lacs P.A.,['Hyderabad( Banjara hills )'],"Dear Candidate,\nWe are seeking a skilled and experienced DBA Data Engineer to join our growing data team. The ideal candidate will play a key role in designing, implementing, and maintaining our databases and data pipeline architecture. You will collaborate with software engineers, data analysts, and DevOps teams to ensure efficient data flow, data integrity, and optimal database performance across all systems. This role requires a strong foundation in database administration, SQL performance tuning, data modeling, and experience with both on-prem and cloud-based environments.\n\nRequirements:\nBachelors degree in Computer Science, Information Systems, or a related field.\n8+ years of experience in database administration and data engineering.\nProven expertise in RDBMS (Oracle, MySQL, and PostgreSQL) and NoSQL systems (MongoDB, Cassandra).\nExperience managing databases in cloud environments (AWS, Azure, or GCP).\nProficiency in ETL processes and tools (e.g., Apache NiFi, Talend, Informatica, AWS Glue).\nStrong experience with scripting languages such as Python, Bash, or PowerShell.\n\nDBA Data Engineer Roles & Responsibilities:\nDesign and maintain scalable and high-performance database architectures.\nMonitor and optimize database performance using tools like CloudWatch, Oracle Enterprise Manager, pgAdmin, Mongo Compass, or Dynatrace.\nDevelop and manage ETL/ELT pipelines to support business intelligence and analytics.\nEnsure data integrity and security through best practices in backup, recovery, and encryption.\nAutomate regular database maintenance tasks using scripting and scheduled jobs.\nImplement high availability, failover, and disaster recovery strategies.\nConduct performance tuning of queries, stored procedures, indexes, and table structures.\nCollaborate with DevOps to automate database deployments using CI/CD and IaC tools (e.g., Terraform, AWS CloudFormation).\nDesign and implement data models, including star/snowflake schemas for data warehousing.\nDocument data flows, data dictionaries, and database configurations.\nManage user access and security policies using IAM roles or database-native permissions.\nAnalyze existing data systems and propose modernization or migration plans (on-prem to cloud, SQL to NoSQL, etc.).\nUse AWS RDS, Amazon Redshift, Azure SQL Database, or Google BigQuery as needed.\nStay up-to-date with emerging database technologies and make recommendations.\n\nMust-Have Skills:\nDeep knowledge of SQL and database performance tuning.\nHands-on experience with database migrations and replication strategies.\nFamiliarity with data governance, data quality, and compliance frameworks (GDPR, HIPAA, etc.).\nStrong problem-solving and troubleshooting skills.\nExperience with data streaming platforms such as Apache Kafka, AWS Kinesis, or Apache Flink is a plus.\nExperience with data lake and data warehouse architectures.\nExcellent communication and documentation skills.\n\nSoft Skills:\nProblem-Solving: Ability to analyze complex problems and develop effective solutions.\nCommunication Skills: Strong verbal and written communication skills to effectively collaborate with cross-functional teams.\nAnalytical Thinking: Ability to think critically and analytically to solve technical challenges.\nTime Management: Capable of managing multiple tasks and deadlines in a fast-paced environment.\nAdaptability: Ability to quickly learn and adapt to new technologies and methodologies.\n\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Database Administration', 'Database Migration', 'Dba Skills', 'High Availability', 'Db Administration', 'Hadr', 'Database Security', 'Disaster Recovery', 'Dr Testing', 'DR', 'Luw', 'Db Upgrade', 'Brtools', 'UDDI', 'Os Migration', 'Dbase', 'DBMS', 'IBM DB2', 'Db Migration', 'Disaster Recovery Planning', 'Db Dba', 'Backup And Recovery']",2025-06-12 14:16:16
"Delivery Head - Infrastructure Engineering, Data Center",Bajaj Allianz General Insurance Company Limited,15 - 20 years,Not Disclosed,['Pune'],"The role requires strong leadership, strategic thinking, and the ability to drive innovation and efficiency within the technology department. It demands extensive experience in leading complex data center infrastructures, focusing on servers, SAN storage, high availability, disaster recovery, and hybrid environments, including data center operations and physical servers (blade and rack). Responsibilities include designing and testing backup strategies, maintaining documentation, ensuring compliance with regulations, and conducting product and vendor evaluations. Collaboration with various IT teams, the security team, and business stakeholders is essential\n",,,,"['process setting', 'document management', 'vmware', 'center', 'microsoft azure', 'itil service management', 'storage', 'shuttering', 'analysis', 'problem management', 'change management', 'cloud', 'data center', 'operations', 'service delivery', 'incident management', 'leadership', 'it infrastructure management', 'itil']",2025-06-12 14:16:18
Data Science Lead,Algoleap Technologies,10 - 15 years,Not Disclosed,['Hyderabad'],"As we build our Data Science Center of Excellence (CoE), we are looking for an entrepreneurial and technically strong Data Science Lead who can lay the foundation for a high-performing team. You will work directly with stakeholders across multiple business units to define use cases, lead model development, and ensure successful deployment and value realization.\n\nKey Responsibilities:\nServe as the technical and strategic lead for the Data Science CoE.",,,,"['customer analytics', 'Usage', 'data science', 'GCP', 'Machine learning', 'model development', 'Deployment', 'Stakeholder management', 'SQL', 'Python']",2025-06-12 14:16:21
Data Specialist - G&A,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the General and Administrative operations (GA) domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the General and Administrative operations (GA) domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 Years of Experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Administration', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Data quality', 'SQL']",2025-06-12 14:16:23
Data Specialist - Supply Chain,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Supply Chain domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Supply Chain domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Data quality', 'SQL']",2025-06-12 14:16:25
Data Specialist - Development,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Development domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Development domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Agile', 'Data quality', 'SQL']",2025-06-12 14:16:27
Data Specialist - Commercial,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Commercialization domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Commercialization domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Agile', 'Data quality', 'SQL']",2025-06-12 14:16:30
Data Quality Lead by Domain,Horizon Therapeutics,3 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for a given domain of expertise (Research, Development, Supply Chain, etc. ).\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles. Develop and implement data quality frameworks. Design and enforce standards for data quality and governance to ensure consistent, accurate, and reliable data.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. data quality best practices and tools for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains. Collaborate with stakeholders and work closely with data stewards, analysts, IT, and business units to understand data requirements and address quality concerns.\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leaders and partners to ensure their needs are being met. Lead data quality initiatives aimed at improving data quality, including data cleansing, enrichment, and validation processes.\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in a domain (e. g. , Research, Clinical Trials, Commercial, etc. ).\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions. Proficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\n3-5 years of experience in data quality management, data governance, or related roles.\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business process', 'Data analysis', 'Change management', 'SAS', 'Pharma', 'Analytical', 'Clinical trials', 'Data quality', 'SQL']",2025-06-12 14:16:32
Data Privacy Specialist,Horizon Therapeutics,3 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for a given domain of expertise (Research, Development, Supply Chain, etc. ).\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles. Create and maintain privacy policies and procedures to protect sensitive data and ensure compliance.\nConduct regular privacy risk assessments and audits to identify and mitigate potential risks as required\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains including GDPR, CCPA, and other relevant legislations.\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in a domain (e. g. , Research, Clinical Trials, Commercial, etc. )\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc. Strong understanding of data protection laws and regulations, including GDPR, CCPA, and other relevant legislations.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\n3-5 years of experience in data privacy, compliance, or a related field.\nSoft Skills:\nIntegrity: Commitment to maintaining the highest ethical standards and protecting confidential information.\nAdaptability: Ability to adapt to changing regulations and emerging privacy challenges.\nProactivity: Self-motivated with a proactive approach to identifying and addressing privacy issues.\nLeadership: Strong leadership skills and the ability to influence and drive change within the organization.\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business process', 'Data analysis', 'Change management', 'SAS', 'Pharma', 'Analytical', 'Clinical trials', 'Data quality', 'SQL']",2025-06-12 14:16:34
Senior Applied AI Scientist,ZS,4 - 9 years,Not Disclosed,['Bengaluru'],"Write complex SQL queries for data extraction, perform exploratory data analysis (EDA) to uncover insights.\nStrong proficiency in Python and Py Spark for scalable data processing and analytics.\nCreate, transform, and optimize features to enhance model performance.\nTrain, evaluate, and maintain machine learning models in production.\nWrite efficient, maintainable, and version-controlled code that handles large datasets.\nRegularly update internal teams and clients on project progress, results, and insights.\nConduct hypothesis testing and experiment analysis to drive data-driven decisions using AB testing.",,,,"['Data analysis', 'data security', 'Financial planning', 'Management consulting', 'Machine learning', 'Data processing', 'Analytics', 'Data extraction', 'Python']",2025-06-12 14:16:37
Data Stage Developer,Anblicks Solutions,6 - 11 years,Not Disclosed,['Chennai'],"Job Summary:\nWe are looking for a seasoned ETL Engineer with hands-on experience in Talend or IBM DataStage, preferably both, to lead data integration efforts in the mortgage domain. The ideal candidate will play a key role in designing, developing, and managing scalable ETL solutions that support critical mortgage data processing and analytics workloads.\n\nKey Responsibilities:\nEnd-to-end ETL solution development using Talend or DataStage.Design and implement robust data pipelines for mortgage origination, servicing, and compliance data.Collaborate with business stakeholders and data analysts to gather requirements and deliver optimized solutions.Perform code reviews, mentor junior team members, and ensure adherence to data quality and performance standards.Manage job orchestration, scheduling, and error handling mechanisms.Document ETL workflows, data dictionaries, and system processes.Ensure data privacy and compliance requirements are embedded in all solutions.\n\nRequired Skills:\nStrong experience in ETL tools Talend (preferred) or IBM DataStage.Solid understanding of mortgage lifecycle and related data domains.Proficiency in SQL and experience with relational databases (e.g., Oracle, SQL Server, Snowflake).Familiarity with job scheduling tools, version control, and CI/CD pipelines.Excellent problem-solving, leadership, and communication skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Datastage', 'Ibm Datastage', 'Etl Datastage']",2025-06-12 14:16:39
Intern - Influencer Marketing,Team Pumpkin,No fixed duration,Unpaid,['Gurugram'],"We are seeking a motivated and detail-oriented Intern - Influencer Marketing to join our dynamic team. In this role, you will support the influencer marketing process by assisting with influencer outreach, campaign coordination, and reporting.\nKey Responsibilities:\n\nInfluencer Database Management:\nCompile and maintain an up-to-date list of influencers, categorizing them by type (Mega, Micro, Macro) to ensure effective outreach.\n\nInfluencer Outreach:\nReach out to identified influencers for potential collaboration opportunities on brand campaigns.\n\nCampaign Coordination:\nAssist in coordinating with influencers throughout the execution of campaigns, ensuring clear communication and adherence to timelines.\n\nCampaign Reporting:\nPrepare and present reports on campaign performance, capturing key metrics and insights for further analysis.\n\nMarket Research:\nConduct research on influencers and social media platforms to identify trends and opportunities for future collaborations.\n\nRelationship Management:\nBuild and maintain positive relationships with influencers and vendors to facilitate smooth campaign execution.\n\nCompetitive Analysis:\nGather and analyze competitive commercial offers from influencers to inform negotiation strategies.\n\nQualifications:\nBachelors degree in Marketing, Communications, or a related field.\nStrong understanding of social media platforms and influencer dynamics.\nExcellent communication and interpersonal skills.\nProficiency in data analysis and report generation.\nAbility to manage multiple tasks and work efficiently in a fast-paced environment.",Industry Type: Advertising & Marketing,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Relationship management', 'Report generation', 'Marketing Manager', 'Data analysis', 'Interpersonal skills', 'Intern', 'Competitive analysis', 'Social media', 'Market research', 'Marketing communication']",2025-06-12 14:16:41
Azure Data Engineer (Azure Databricks must),Fortune India 500 IT Services Firm,5 - 8 years,Not Disclosed,['Hyderabad'],"We are looking for an experienced Azure Data Engineer with strong expertise in Azure Databricks to join our data engineering team.\n\nMandatory skill- Azure Databricks\nExperience- 5 to 8 years\nLocation- Hyderabad\nKey Responsibilities:\nDesign and build data pipelines and ETL/ELT workflows using Azure Databricks and Azure Data Factory\nIngest, clean, transform, and process large datasets from diverse sources (structured and unstructured)\nImplement Delta Lake solutions and optimize Spark jobs for performance and reliability\nIntegrate Azure Databricks with other Azure services including Data Lake Storage, Synapse Analytics, and Event Hubs\n\n\n\nInterested candidates share your CV at himani.girnar@alikethoughts.com with below details\n\nCandidate's name-\nEmail and Alternate Email ID-\nContact and Alternate Contact no-\nTotal exp-\nRelevant experience-\nCurrent Org-\nNotice period-\nCCTC-\nECTC-\nCurrent Location-\nPreferred Location-\nPancard No-",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure Databricks', 'Azure Data Factory', 'Pyspark', 'Azure Data Lake', 'SQL']",2025-06-12 14:16:43
Artificial Intelligence Intern,Kumaran Systems,0 - 1 years,4.5-5 Lacs P.A.,['Chennai( Siruseri Sipcot IT Park )'],"We are looking for a passionate and motivated AI Developer Fresher to join our growing AI team. This role will focus on Generative AI (GenAI) technologies such as large language models (LLMs), diffusion models, and other cutting-edge machine learning techniques.\n\nAs a fresher, youll work closely with senior AI engineers and data scientists to build and fine-tune generative models, contribute to prompt engineering, and support model integration into real-world applications.",,,,"['Data Science', 'Mechine Learning', 'Artificial Intelligence', 'GEN AI', 'Python']",2025-06-12 14:16:46
Supply Chain Intern,Azelis India,6 months duration,"20,000/month",['Navi Mumbai'],Job Description: -\nWork from Office:\nLocation: Airoli Navi Mumbai\ncontact person: tushar.shete@azelis.com\nQualifications: - Graduate from any stream\nBasic knowledge of purchase to pay.\nknowledge of Incoterm,,,,"['Communication Skills', 'MS Office']",2025-06-12 14:16:48
Research Assistant,Panacorp Software Solutions,0 - 1 years,Not Disclosed,"['Nagercoil', 'Kanyakumari']","Key Responsibilities:\nAssist with the design and execution of research projects\nCollect, organize, and analyze data using various research methodologies\nPrepare and review research documents, reports, and presentations\nConduct literature reviews and summarize relevant research articles\nCollaborate with other team members and researchers to facilitate research activities\nEnsure the quality and accuracy of research data and findings\nSupport researchers in experimental tasks and lab work (if applicable)\nQualifications:\nEducation: BE/B.Tech (Recent Graduates) or relevant degree\nExperience: 0-1+ year(s) of experience in research projects\nSkills:\nStrong analytical and problem-solving skills\nFamiliarity with data analysis software (e.g., MS Excel, MATLAB, Python, or R)\nExcellent communication skills (both verbal and written)\nAbility to work independently as well as part of a collaborative team\nAttention to detail and ability to manage time effectively",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['Research Development', 'R', 'data analysis', 'MATLAB', 'Python']",2025-06-12 14:16:50
B-Tech Internship Trainee,ADA Tech Solutions,3 months duration,"15,000/month",['Pune'],"Roles & Responsibilities:\nAssist in project execution under the guidance of senior team members.\nSupport in research, development, testing, documentation, or data analysis based on the assigned domain.\nCollaborate with cross-functional teams to understand business and technical requirements.\nParticipate in team meetings and contribute to idea generation and problem-solving.\nMaintain project documentation, reports, and presentations.\nComplete assigned tasks within deadlines while maintaining quality and accuracy.\nLearn and use tools, platforms, or frameworks relevant to the tteam'seams work.\nEligibility Criteria:\nCurrently pursuing B.Tech / B.E. in [Computer Science, IT, ECE, Mechanical, Civil, etc.].\nStrong academic background and willingness to learn.\nGood communication and teamwork skills.\nBasic knowledge in domain-related tools or technologies is a plus (e.g., Python, Java, CAD, SQL, AutoCAD, etc.)\nSkills Required (customize as needed):\nAnalytical and problem-solving abilities\nBasic technical or engineering knowledge\nMS Office / Google Workspace proficiency\nEagerness to learn and adapt in a fast-paced environment\nTime management and accountability",Industry Type: BPM / BPO,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['IT Support', 'LAN Troubleshooting', 'Desktop Support', 'Laptop Support', 'Network Support', 'Hardware Support', 'System Support', 'LAN Support', 'Hardware Installation']",2025-06-12 14:16:52
Office Assistant & Accountant,Swami Associates,0 - 5 years,"72,000-1.8 Lacs P.A.",['Ahmedabad( Naroda Road )'],Responsibilities:\n* Maintain financial records using accounting software\n* Manage office supplies inventory\n* Prepare monthly reports with data analysis\n* Coordinate meetings and travel arrangements\n* Prepare Documents and Scan and Upload download\n\n\nAnnual bonus\nAccessible workspace,Industry Type: Accounting / Auditing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Computer Knowledge of MS Office', 'Communication Skills', 'Multitasking', 'workaholic', 'English', 'Gujarati', 'Clerical work', 'Hindi']",2025-06-12 14:16:54
Accounts and Audit Assistant,MAG Finserv Company Ltd,0 - 3 years,2.4-4.2 Lacs P.A.,['Pune'],"Bachelors/Master’s degree in Commerce, Finance, Accounting,and a CA Inter who has completed articleship of 3 years preferred).\n\nAccounting and finance\nAudit & Compliance\nData Analysis & Reporting\nTaxation & Regulatory Reporting",Industry Type: NBFC,Department: Finance & Accounting,"Employment Type: Full Time, Permanent",['Analytical'],2025-06-12 14:16:56
Trainee Solution Engineer,Qualitykiosk Technologies,0 - 1 years,Not Disclosed,"['Mumbai', 'Navi Mumbai']","Key ResponsibilitiesLearning and Development: Engage in training sessions and workshops to enhance your skills and knowledge relevant to your role\nAssisting Senior Staff: Support senior team members in their tasks, which may include research, data analysis, and project management\nProject Participation: Contribute to team projects, providing fresh perspectives and innovative ideas to foster collaboration and creativity\nProblem-Solving: Participate in problem-solving activities, making decisions based on available information and seeking guidance when necessary\nCollaboration: Work with cross-functional teams to gain a holistic understanding of the company s operations and contribute to multidisciplinary projects",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['project management', 'python', 'data analysis', 'data analytics', 'data management', 'c', 'mis reporting', 'business analysis', 'pivot table', 'vlookup', 'machine learning', 'presales', 'javascript', 'sql', 'excel', 'react.js', 'tableau', 'node.js', 'advanced excel', 'data visualization', 'pega', 'powerpoint']",2025-06-12 14:16:58
Machine Learning Engineer,Panacorp Software Solutions,0 - 5 years,Not Disclosed,"['Nagercoil', 'Kanyakumari']","Research Programmer (Python/ MATLAB) Fresher & Experienced\nAbout Panacorp Software Solutions\nPanacorp Software Solutions is a research-driven organization specializing in providing technical assistance for PhD research projects. Our focus is on supporting research scholars with programming, simulations, and computational analysis in various domains, including AI, Machine Learning, and numerical computing.\n\nJob Role & Responsibilities\nAssist in research-based projects related to PhD studies.\nPerform simulations, numerical computing, and data analysis using Python, MATLAB, and Simulink.\nSupport research scholars in implementing Machine Learning (ML) and Deep Learning (DL) models.\nAutomate processes and optimize research workflows through scripting.\nDocument research methodologies, findings, and technical reports.\nWork closely with scholars to analyze and interpret computational results.\nEligibility Criteria\nQualification: BE/B.Tech/MCA\nExperience: 0 5+ years (Freshers with strong academic knowledge can apply).\nStrong understanding of research methodologies and computational tools.\nPreferred Skills\nProficiency in Python, MATLAB, and Simulink.\nKnowledge of data analysis, AI/ML techniques, and numerical simulations.\nAbility to interpret and validate research outcomes.\nStrong analytical and problem-solving skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Machine Learning', 'matlab', 'simulink', 'python', 'data analysis', 'research methodology', 'artificial intelligence']",2025-06-12 14:17:00
Python Senior Developer,Infosys,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title\nPython Senior Developer\n\nResponsibilities\nSolid development experience in Data Science Arch.\nExperience in Application Architecture & Design of Java Based Applications\nGood Knowledge of Architecture and related technologies\nExperience in Integration Technologies and Architecture\nWorking knowledge of frontend and database technologies\nExcellent Analytical and Debugging Skills\nFamiliarity with Agile & DevSecOps, Log Analytics, APM\nExperience in leading the teams technically\nExperience in requirements gathering, analysis & design and estimation\nGood communication and articulation skills Technical and Professional :\nWe are seeking a skilled Python and SQL Developer to join our dynamic team. The ideal candidate will have a strong background in Python programming and SQL database management.\nDevelop and maintain Python-based applications and scripts.\nWrite efficient SQL queries for data extraction and manipulation.\nCollaborate with cross-functional teams to gather requirements and deliver solutions.\nFamiliarity with Linux operating systems.\nBasic understanding of cloud platforms (e.g., AWS, Azure, Google Cloud).\nKnowledge of Model Quantization and Pruning\nExperience playing a Data Scientist role Preferred Skills:\nPython Technology-Open System-Open System- ALL-Python Technology-Full stack-Java Full stack-Frontend(Vue.js)+Enterprise layer(Python)+DB Additional Responsibilities:\nIn-depth knowledge of design issues and best practices\nSolid understanding of object-oriented programming\nFamiliar with various design, architectural patterns and software development process.\nExperience with both external and embedded databases\nCreating database schemas that represent and support business processes\nImplementing automated testing platforms and unit tests\nGood verbal and written communication skills\nAbility to communicate with remote teams in effective manner\nHigh flexibility to travelSoft Skills\nGood verbal & written communication skills articulate value of AI to business, project managers & other team members\nAbility to break complex problem into smaller problems and create hypothesis\nInnovation and experimentation Educational Master of Computer Science,Master Of Science,Master Of Technology,MCA,Bachelor Of Comp. Applications,Bachelor Of Computer Science,Bachelor of Engineering,Bachelor Of Technology Service LineApplication Development and Maintenance* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Enterprise layer', 'software development', 'report generation', 'MIS', 'CI/CD', 'Java Full stack-Frontend', 'SDLC']",2025-06-12 14:17:02
Medical Coder Trainee,Resolve Medicode,0 - 2 years,1.25-3 Lacs P.A.,"['Pollachi', 'Mettupalayam', 'Coimbatore']","Medical coders translate detailed patient information from clinical records into standardized numerical and alphabetical codes. These codes are essential for billing, data analysis, research, and other healthcare functions.\n\nRegards,\nDeepika\n9880650498",Industry Type: Pharmaceutical & Life Sciences,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent",['Medical Coding'],2025-06-12 14:17:04
Assistant Manager - FP&A,Mahansaria Group,0 - 2 years,5-6.5 Lacs P.A.,['Mumbai (All Areas)'],"Job description\nSupport and assists in the budgeting process. This involves collaborating with different departments to create detailed budgets that align with the company's overall financial strategy.\nProduces monthly Key Performance Indicator (KPI) analysis. These KPIs offer valuable insights into the company's financial performance and help identify areas for improvement. Develop, Maintain, and enhance MIS reports to support decision making.\nSupports the creation and distribution of monthly board packs. These packs typically contain key financial and operational information that is presented to the company's board of directors.\nResponsible for preparing regular and insightful reports on revenue and client-related metrics. These reports assist in tracking performance, identifying trends, and highlighting areas for improvement.\nCollaborates with various departments within the organization to provide valuable insights and data-driven analysis. They use financial data to help stakeholders make informed decisions that align with the company's goals and objectives.\nFinancial Review and Analysis of Group companies.\nBenchmarking, Ratio analysis, Trend analysis, Variance Analysis etc.\nPerforming ad-hoc analysis where required to assist in management decision making.\nPreparation of comparison of P&L and Balance Sheet with respect to budget/MIS along with variance.\nBuilding/developing and maintaining of data analysis, data visualization and presenting business insight thru BI Tools.\nOther work to be assigned time to time.",Industry Type: Auto Components (Tyre),Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Budgeting And Forecasting', 'Financial Planning And Analysis', 'Margin Analysis', 'ERP', 'Financial Reporting', 'Revenue Analysis', 'Bi Tools', 'Variance Analysis', 'MIS Reporting', 'Balance Sheet Analysis', 'Material Management', 'KPI Analysis', 'Ad Hoc Reporting', 'Trend Analysis', 'Ratio Analysis']",2025-06-12 14:17:06
Senior Engineer,A Large Global Organization,5 - 10 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Key Skills: Data Analysis, Project Management, PMP\nRoles and Responsibilities:\nLead and manage projects involving analytics, reporting, and process improvements across departments\nConduct data analysis to identify performance trends, root causes, and actionable insights\nAutomate routine business processes and reporting tasks to drive operational efficiency\nPrepare clear, impactful presentations and documentation for stakeholders at all levels\nMonitor project timelines, deliverables, and risks while ensuring alignment with business goals\nCollaborate cross-functionally to gather requirements, develop project plans, and drive execution\nSupport strategic initiatives by providing analytical input and business insights\nServe as a liaison between technical and business teams to ensure effective solution delivery\nContinuously identify and implement improvements in workflow, reporting, and stakeholder engagement\nSkills Required:\nStrong verbal and written communication skills\nAbility to simplify and present complex data and concepts to varied audiences, including senior leadership\nDetail-oriented with excellent organizational skills to manage multiple projects concurrently\nHands-on experience in project management and data analytics\nTechnological proficiency to automate tasks and streamline documentation (e.g., scripting, dashboards, data querying tools)\nCreative problem-solving abilities, with a proven track record of developing innovative solutions\nComfortable working with senior professionals and stakeholders on complex or sensitive topics\nAbility to analyze similar but varied issues, requiring data gathering and applying defined procedures or best practices to resolve\nEducation: Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field",Industry Type: Medical Services / Hospital,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['PMP', 'Project Management', 'Data Analysis']",2025-06-12 14:17:08
"Sr Software Eng: Generative AI, Go/Python, AWS, Kubernetes 7-12 Yrs",Cisco,7 - 12 years,Not Disclosed,['Bengaluru'],"Meet The Team\nThe Cisco AI Software & Platform Group drives the development of groundbreaking generative AI applications. We empower Cisco's diverse product portfolio, spanning networking and security, with intelligent assistants and agents. We work on pioneering technologies that proactively defend against threats, safeguard critical business assets, and simplify security operations. Fueled by a passion for AI/ML, we strive to create a secure future for businesses. Our collaborative and passionate team thrives with tackling sophisticated challenges and delivering innovative solutions.",,,,"['Golang', 'Generative Ai', 'AWS', 'Python', 'Kubernetes', 'Java']",2025-06-12 14:17:11
Senior Murex Front Office & Risk Support Engineer,Synechron,5 - 10 years,Not Disclosed,"['Pune', 'Bengaluru', 'Hinjewadi']","Job Summary\nSynechron is seeking an experienced Murex FO & Risk Support Specialist to join our dynamic team. This role is central to maintaining and supporting Murex platform functionalities related to front-office operations and risk management, with a focus on production support.\nThe individual will collaborate closely with business users and IT teams to resolve complex issues, optimize configurations, and ensure the stability of critical trading and risk systems. By providing expert-level support, this role contributes directly to the organizations ability to manage market and credit risks effectively, deliver timely business insights, and uphold operational resilience.\nSoftware Requirements\nRequired Software Proficiency:\nMurex platform (version 3.1 or later) extensive experience in FO & Risk modules from a production support perspective\nSQL and Database querying tools (Oracle, SQL Server) strong experience in data analysis and troubleshooting\nMarket data management tools and configurations within Murex\nIssue tracking and collaboration tools (e.g., JIRA, ServiceNow)\nPreferred Software Skills:\nFamiliarity with scripting languages (Python, Shell scripting) for automation\nVersion control systems (e.g., Git)\nCloud platforms (if applicable to client environment)\nOverall Responsibilities\nProvide second-line support for Murex front-office and risk modules, ensuring operational stability and performance\nAnalyze and troubleshoot issues related to P&L, market risk, credit risk, pricing, simulations, and market data, collaborating with business users to identify root causes\nManage Murex configurations, including GOM (Global Object Model) setups, static data configurations, and cross-asset class risk settings\nLiaise with business stakeholders and IT teams to resolve complex incidents, queries, and configuration challenges\nCollaborate on incident resolution, change management, and service improvement initiatives\nDocument technical procedures, resolutions, and configuration changes for knowledge sharing and audit compliance\nContinuously monitor platform health, performance, and data integrity, proposing proactive solutions for operational risks\nTechnical Skills (By Category)\nProgramming Languages:\nEssential: Murex editing languages, SQL\nPreferred: Python, Shell scripting for automation tasks\nDatabases / Data Management:\nEssential: Oracle, SQL Server experience with schema design, data queries, and performance tuning\nPreferred: Understand market data integration and static data management in Murex\nCloud Technologies:\nOptional/Preferred: Basic understanding of cloud integrations related to trading platforms, if applicable\nFrameworks and Libraries:\nNot applicable, focus on Murex platform and related tools\nDevelopment Tools and Methodologies:\nFamiliarity with ITSM processes, incident & problem management, Agile/Scrum methodologies\nSecurity Protocols:\nUnderstanding of access controls, data confidentiality, and system compliance relevant to financial platforms\nExperience Requirements\nMinimum of 5+ years experience supporting Murex FO & Risk modules in a production environment\nProven experience in analyzing issues related to P&L, market risk, credit risk, and pricing in a trading systems context\nStrong understanding of GOM configurations, static data setups, and cross-asset risk configurations\nExperience working directly with business lines, traders, risk managers, and IT teams\nIndustry background within banking, financial services, or capital markets preferred but not mandatory\nDay-to-Day Activities\nMonitor and support Murex FO & Risk modules, identifying and resolving operational issues\nPerform root-cause analysis on incidents related to market data, P&L, and risk calculations\nFine-tune GOM and static data configurations to optimize system performance and accuracy\nEngage in daily stand-ups, incident reviews, and change implementation meetings\nCollaborate with business users and technical teams to clarify issues and implement fixes\nConduct system audits and maintain detailed logs of support activities and configuration changes\nContribute to continuous improvement initiatives for system stability and efficiency\nQualifications\nBachelors degree or higher in Computer Science, Finance, Information Technology, or related field\nCertifications in Murex support, risk management, or related disciplines are a plus\nPrior experience with Murex platform support in financial markets, trading, or risk management environments\nKnowledge of market practices, instruments, and risk concepts across multiple asset classes\nWillingness to engage in ongoing professional development and staying current with Murex updates and industry trends\nProfessional Competencies\nStrong analytical and problem-solving skills, with a focus on root cause identification\nEffective communication skills to interact clearly with technical and business stakeholders\nAbility to work collaboratively within cross-functional teams and under pressure\nAdaptability to evolving systems, processes, and technology landscapes\nCustomer-centric approach, ensuring timely and quality support delivery\nDemonstrated organizational skills for managing multiple issues and priorities efficiently.",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['Murex support', 'risk management', 'Risk Support', 'credit risk', 'market risk', 'pricing']",2025-06-12 14:17:13
CPU Full Stack Python Developer (Staff/Sr. Staff),Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nWe are seeking a highly skilled Full Stack Python Developer to join our dynamic team. The ideal candidate should have a strong background in tool development, data science, and automation of complex tasks. You will be responsible for developing high volume regression dashboard, parametric and power tools and contributing to both front-end and back-end development.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\n\nTechnical\n\nSkills:\n\n\n\nPythonProficiency in Python programming, including libraries like Pandas, NumPy, and SciPy for data science.\n\n\nFull Stack DevelopmentExperience with both front-end (HTML, CSS, JavaScript, React, Vue.js) and back-end (Django, Flask) technologies.\n\n\nTool DevelopmentAbility to develop parametric and power tools, possibly using frameworks like Vue.js , PyQt or Tkinter for GUI development.\n\n\nData ScienceStrong understanding of data analysis, machine learning (using libraries like scikit-learn, TensorFlow), and data visualization (using Matplotlib, Seaborn).\n\n\nAutomationExperience in automating complex tasks using scripting and tools like Selenium, Airflow, or custom automation scripts.\n\n\nSoft\n\nSkills:\n\n\n\nProblem-SolvingAbility to tackle complex problems and develop innovative solutions.\n\n\nCommunicationStrong communication skills to effectively collaborate with team members and stakeholders.\n\n\nAdaptabilityFlexibility to adapt to new technologies and methodologies.\n\n\nExperience:\n\n\nProjectsPrevious experience in developing tools and automation solutions.\n\n\nIndustry KnowledgeFamiliarity with the specific industry or domain you're working in can be a plus.\n\n\nKey Responsibilities:\n\nDevelop and maintain parametric and power tools using Python.\n\nDesign and implement automation solutions for complex tasks.\n\nCollaborate with data scientists to analyze and visualize data.\n\nBuild and maintain web applications using Django or Flask.\n\nDevelop front-end components using HTML, CSS, JavaScript, and React.\n\nIntegrate third-party APIs and services.\n\nOptimize applications for maximum speed and scalability.\n\nWrite clean, maintainable, and efficient code.\n\nTroubleshoot and debug applications.\n\nStay updated with the latest industry trends and technologies.\n\n\nPreferred Qualifications:\n\nBachelor's degree in Computer Science, Engineering, or related field.\n\nPrevious experience in tool development and automation.\n\nFamiliarity with industry-specific tools and technologies.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['tool development', 'data science', 'python', 'data analysis', 'machine learning', 'css', 'hiring', 'scikit-learn', 'vue.js', 'numpy', 'staffing', 'react.js', 'tensorflow', 'seaborn', 'selenium', 'pyqt', 'html', 'data visualization', 'scipy', 'hardware engineering', 'javascript', 'pandas', 'django', 'matplotlib', 'flask']",2025-06-12 14:17:15
"Wireless Technology Hardware Program Manager, Senior",Qualcomm,5 - 10 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Services Group, Engineering Services Group > Program Management\n\nGeneral Summary:\n\nDevelops, defines, and executes plans of record, includingschedules, budgets, resources, deliverables, and risks. Monitors and drives the program from initiation through delivery, interfacing with internal and external stakeholders across functions on technical matters, as needed. Monitors budget/spending, on-time delivery, and achievement of program milestones. Represents the program and drives alignment across stakeholders.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Computer Science, or related field.\n5+ years of Program Management or related work experience.\n\nPreferred Qualifications:\n\nMaster's degree in Engineering, Computer Science, or related field.\n\nPMP Certification.\n\n10+ years of Program Management or related work experience.\n\n5+ years of work experience in a role requiring interaction with senior leadership (e.g., Director level and above).\n\n3+ years of experience working in a large matrixed organization.\n\n2+ years of experience with program management tools such as dashboards, Gantt charts, etc.\n\nPrincipal Duties and Responsibilities:\nCollaborates with key stakeholders and program sponsors to develop program goals, set the prioritization of deliverables, discuss involvement of business processes (e.g., program change management, communication) and drives decisions necessary for on time delivery.\nManages and takes responsibility for multiple medium sized programs/technology with moderate complexity by applying up-to-date program management knowledge to meet deadlines.\nDevelops and manages the execution of the program Plan of Record (e.g., on time, on budget, within scope) for multiple medium sized programs which include schedule and resource forecasting, stakeholders identification, method and frequency of communication, scope, and prioritization.\nEstablishes key program metrics and manages team to take action outside their comfort zone to ensure program success when metrics deviate from Plan of Record.\nIdentifies and secures resources to ensure alignment of team with program/technology demand for multiple medium sized programs with moderate complexity.\nDrives teams to identify program issues/risks, and create a risk mitigation plan for multiple medium sized or a single complex program(s). Maintains and updates the risk tracker.\nPromotes program vision and objectives within the team, ensures program objectives are met or exceeded, presents program vision to management, and gains buy-in from stakeholders.\nPromotes adoption of processes by applying best practices and identifying and executing process improvement initiatives across the Program Management team.\n\nLevel of Responsibility:\nWorking independently with little supervision.\nMaking decisions that are significant in impact; errors are not readily apparent due to the complexity of work process/product or time between decisions and results; errors typically result in significant expenditure of time, resources, and funds to correct.\nUsing verbal and written communication skills to convey complex and/or detailed information to multiple individuals/audiences with differing knowledge levels. May require strong negotiation and influence, communication to large groups or high-level constituents.\nHaving a moderate amount of influence over key organizational decisions (e.g., is consulted by senior leadership to provide input on key decisions).\nCompleting tasks that require multiple steps that can be performed in various orders; tasks require simultaneously executing multiple cognitive abilities and maintaining information in short- or long-term memory.\nExercising exceptional creativity to innovate new ideas and develop innovative products/processes without established objectives or known parameters.\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or conflicting; advanced data analysis and interpretation skills are required.\nOccasionally participates in strategic planning within own area affecting immediate operations.\n\nThe responsibilities of this role do not include:\nFinancial accountability (e.g., does not involve budgeting responsibility).",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['data analysis', 'program management', 'pmi', 'pmp', 'computer science', 'project management', 'project scheduling', 'ms project', 'business analysis', 'pmo', 'delivery management', 'scrum', 'project execution', 'agile', 'pmbok', 'csm', 'project coordination', 'project planning', 'agile methodology']",2025-06-12 14:17:17
Senior System Software Engineer,Nvidia,4 - 12 years,Not Disclosed,['Bengaluru'],"NVIDIAs Deep Learning GPUs have ignited modern AI the next era of computing with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world. Today, we are increasingly known as the AI computing company . We are growing our company and the team with the smartest people in the world.\nWe are looking for extraordinary Software Engineers to develop and productize NVIDIAs DRIVE OS software. As a member of NVIDIAs Solution Engineering team, you will adapt DRIVE OS solutions to various car platforms equipped with different sensors. We are looking for a Senior System Software Engineer with strong experience in Linux/QNX/Android operating system, Device Drivers development, virtualization, and ARM architecture\nWhat you will be doing:\nArchitecture, development, and enhancement of native/para-virtualized Linux/QNX device drivers\nSolve complex system issues on Linux/Android/QNX OS\nLead the architecture discussions for SW components and interface with customers to support DRIVE software solutions.\nContinuously evolve and support requirements gathering process and traceability flow.\nActively coordinate with cross-functional engineering teams to meet customers requirements and to drive complex issues to closure.\nParticipate in architectural explorations which include feasibility studies, safety evaluations and data analysis.\nPerformance tuning of customer use-cases and functions on Drive OS software\nWhat we need to see:\nBS/MS or equivalent experience.\n5+ years of overall experience and preferably with 2+ years of automotive industry experience.\nStrong understanding of QNX/Linux/Android operating system and hands-on experience with QNX/Linux device driver development\nStrong C/C++ programming and debugging skills\nIn-depth understanding of ARM processor architecture fundamentals\nBackground in embedded software development and deep knowledge of product development lifecycle.\nExposure to functional safety architecture to meet ISO26262 standard would be a plus\nEffective written and verbal communication regardless of audience or issue complexity.\nWays to stand out from the crowd:\nIn-depth device driver development experience on Linux and/or QNX OS\nStrong kernel/OS debugging skills\nNVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'Data analysis', 'Linux', 'Architecture', 'Debugging', 'QNX', 'System software', 'Virtualization', 'Automotive', 'Android']",2025-06-12 14:17:20
Senior Murex Front Office & Risk Support Engineer,Synechron,5 - 10 years,Not Disclosed,"['Pune', 'Bengaluru']","Software Requirements\nRequired Skills:\nProficiency with Murex (version 3.1 or higher) focusing on Front Office and Risk modules\nExperience in analyzing issues related to P&L, market risk, credit risk, pricing, simulations, and market data\nKnowledge of GOM configurations and static data (e.g., instruments, reference data)\nHands-on experience in troubleshooting and resolving system issues in a production environment\nGood understanding of cross-asset class configurations and risk management concepts\nStrong communication skills for engaging with business users, IT teams, and Murex vendors\nPreferred Skills:\nFamiliarity with other risk management and trading systems\nKnowledge of automation tools or scripting (e.g., Python, VBA) is advantageous\nOverall Responsibilities\nSupport daily operations of Murex Front Office and Risk modules, ensuring system stability\nInvestigate and resolve issues related to P&L calculations, risk metrics, pricing models, and data discrepancies\nCollaborate with business stakeholders to address queries and resolve configuration or data issues\nAssist in managing GOM configurations, static data, and cross-asset class setup\nParticipate in system upgrades, change management, and testing activities\nDocument issues, solutions, process changes, and configuration details for team knowledge\nMonitor system performance, identify risks, and recommend improvements\nMaintain effective communication with stakeholders regarding incident status, risk issues, and ongoing support requirements\nContribute to continuous improvement initiatives in procedures and configurations\nStrategic objectives:\nEnhance system stability and accuracy of risk calculations\nReduce incident resolution time and improve user satisfaction\nSupport effective risk and trading operations aligned with compliance\nPerformance outcomes:\nMinimal system downtime and accurate risk results\nTimely resolution of user queries and configuration issues\nClear, comprehensive documentation supporting ongoing support and audits\nTechnical Skills (By Category)\nProgramming Languages (Essential):\nBasic scripting (e.g., VBA, Python) for automation and data analysis (preferred)\nApplications & Modules (Essential):\nMurex Front Office and Risk modules (version 3.1 or above)\nExperience in P&L analysis, risk metrics, and market data management\nDatabases & Data Management (Essential):\nSQL for data retrieval, validation, and troubleshooting\nConfiguration & Static Data (Essential):\nManaging GOM templates, instrument data, and reference data configurations\nTrade & Risk Management Concepts (Essential):\nCross-asset class risk concepts, valuation techniques, and pricing methodologies\nTools & Integration (Preferred):\nFamiliarity with risk and trading system integrations\nMonitoring and troubleshooting tools specific to Murex environment\nExperience Requirements\nMinimum 5+ years supporting Murex Front Office and Risk modules from a production support perspective\nHands-on experience resolving issues related to P&L, market risk, credit risk, and pricing\nPrior experience in a support organization within financial institutionstrading desks, risk teams, or similarpreferred\nSupporting support in 24x5 or 24x7 environments, handling urgent incident escalations\nIndustry experience in banking, trading, or risk management sectors is advantageous\nAlternative experience pathways:\nCandidates with extensive support experience in related trading/risk systems demonstrating deep understanding of Murex modules may be considered\nDay-to-Day Activities\nMonitor daily Murex Front Office and Risk modules for issues or alerts\nInvestigate and troubleshoot discrepancies in P&L, risk metrics, and data quality\nCollaborate with traders, risk managers, IT team, and vendors to resolve incidents and support requests\nAssist in static data management, GOM configurations, and risk setup for multiple asset classes\nSupport system upgrades, configuration adjustments, and testing activities\nDocument incidents, solutions, and best practices for team knowledge base\nParticipate in change management, incident reviews, and process improvements\nProvide timely updates and communicate issues clearly to stakeholders\nQualifications\nBachelors degree in Finance, Computer Science, Information Technology, or related field\nStrong understanding of risk management, trading workflows, and modelling\nExperience with GOM configuration and static data setup\nGood SQL and scripting skills for troubleshooting and data analysis\nProven ability to work effectively under pressure and manage multiple priorities\nWillingness to support shifts, including non-core hours, as needed\nProfessional Competencies\nCritical thinking and strong problem-solving skills for complex issues\nEffective communication with technical teams, business users, and vendors\nStakeholder management and customer service orientation\nAbility to work autonomously, prioritize tasks, and manage incidents efficiently\nFlexible and adaptable to changing business and technological needs\nCommitment to continuous learning and process enhancement",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['Risk management', 'GOM configurations', 'VBA', 'configurations', 'troubleshooting', 'pricing', 'Python', 'SQL']",2025-06-12 14:17:22
Senior Staff Engineer - AI-IOT Product,Infineon,6 - 8 years,Not Disclosed,['Bengaluru'],"We are seeking an experienced AI-IOT Product Engineer to design and develop AI and IoT products, with a focus on technical product management and product design. This role requires a strong technical background, excellent problem-solving skills, and the ability to collaborate with cross-functional teams to deliver innovative solutions.\n\nJob Description\nProduct Design: Design and develop AI and IoT product concepts, including hardware, firmware, and software components. This includes:\nDeveloping product requirements and technical specifications.\nCollaborating with engineering teams to design and develop product architectures.\nEnsuring product designs meet technical and business requirements.\nTechnical Product Management: Manage the technical aspects of AI and IoT products, including:\nDefining and prioritizing product features and requirements.\nCollaborating with engineering teams to develop and deploy products.\nEnsuring products meet quality and reliability standards.\nSensor Algorithm Development: Collaborate with engineering teams to develop and implement sensor algorithms that enable accurate and efficient data collection and processing. This includes:\nProviding technical guidance on sensor fusion algorithms and machine learning models.\nCollaborating with engineering teams to integrate sensor algorithms with IoT devices and platforms.\nLLM RAG Systems: Collaborate with engineering teams to design and develop Large Language Model (LLM) Retrieval-Augmented Generation (RAG) systems that enable efficient and effective natural language processing. This includes:\nProviding technical guidance on LLM models and RAG systems.\nCollaborating with engineering teams to integrate LLM RAG systems with IoT devices and platforms.\nApplied Deep Learning: Collaborate with engineering teams to develop and implement deep learning models that enable accurate and efficient data analysis and processing. This includes:\nProviding technical guidance on deep learning models and architectures.\nCollaborating with engineering teams to integrate deep learning models with IoT devices and platforms.\nTechnical Road mapping: Develop and maintain technical roadmaps for AI and IoT products, including:\nIdentifying and prioritizing technical requirements and features.\nCollaborating with engineering teams to develop and deploy products.\nYou are best equipped for this task if you have:\n6-8 years of experience in AI, IoT, or related fields.\nBachelors or Masters degree in Computer Science, Electrical/Electronics Engineering, or a related field.\nExcellent problem-solving skills and attention to detail.\nExperience with AI and IoT technologies, such as AWS or Azure.\nStrong technical knowledge of sensor algorithms, LLM RAG systems, and applied deep learning.\nExperience with technical product management and product design.\nExperience with agile development methodologies.\nKnowledge of IoT protocols and technologies (eg, MQTT, CoAP, BLE, Zigbee, LoRa, NB-IoT).\nExperience with data analytics and machine learning.\nCertifications in AI or IoT technologies (eg, AWS Certified IoT Architect, Microsoft Certified Azure AI Engineer).\nExperience with DevOps tools and practices.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Semiconductor', 'Data analysis', 'Machine learning', 'Data collection', 'Product design', 'Natural language processing', 'Firmware', 'microsoft']",2025-06-12 14:17:24
Senior Staff - Embedded Linux,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nJob Overview:\n\nDevelops, creates, and modifies general computer applications software or specialized utility programs. Analyzes user needs and develops software solutions. Designs software or customizes software for client use with the aim of optimizing operational efficiency. Modifies existing software to correct errors, allow it to adapt to new hardware, or to improve its performance. Analyzes user needs and software requirements to determine feasibility of design within time and cost constraints. Confers with systems analysts, engineers, programmers and others to design system and to obtain information on project limitations and capabilities, performance requirements and interfaces. Stores, retrieves, and manipulates data for analysis of system capabilities and requirements. Designs, develops, and modifies software systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design.\n\nThe responsibilities of this role include\nWorking independently with no supervision.\nMaking decisions that are significant in impact, influencing overall program or project success, finances, and/or the ability to meet objectives; errors are not readily apparent due to the complexity of work process/product or time between decisions and results; errors typically result in significant expenditure of time, resources, and funds to correct.\nUsing verbal and written communication skills to convey complex and/or detailed information to multiple individuals/audiences with differing knowledge levels. May require strong negotiation and influence, communication to large groups or high-level constituents.\nHaving a great degree of influence over key organizational decisions (e.g., is making or directly making key decisions that have substantial impact on the organization).\nCompleting tasks that require multiple steps that can be performed in various orders; tasks require simultaneously executing multiple cognitive abilities and maintaining information in short or long-term memory.\nRegularly determines what needs to be done and is involved with sharing innovative solutions to achieve broad policies and objectives.\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or conflicting; advanced data analysis and interpretation skills are required.\nOccasionally participates in strategic planning within own area affecting immediate operations.\nPRINCIPAL DUTIES AND RESPONSIBILITIES\nSeeks information within and outside of team to identify and manage overarching technical issues and wide-ranging solutions.\nResolves design and technical issues related to technical area of expertise.\nServes as a technical expert for technology related to an overall large system.\nDetermines best strategies to solve current and future technical challenges associated with area of expertise.\nCollaborates with others inside and outside of project team to accomplish project objectives.\nSolves highly complex technical problems that affect multiple software layers or teams.\nMakes significant decisions as it pertains to the approach in coding large features or modules.\nActs as a tech lead and on major projects to ensure they are driven to completion.\nConsults with other large project team leaders to determine how best to address a new or unique problem.\nAnalyzes project requirements to determine time and resources required.\nReviews and advises on coding efforts to ensure that projects are completed to specification.\nWorks with high-level representatives from other functions (e.g., testing group, product group, customers) to integrate plan for software design of large initiative.\nNetworks with customers and colleagues within and outside of Qualcomm to gain insight, ideas, and connections.\n\nDiscusses state of software solution, approach, or other information with customers and others outside of Qualcomm.\n\nREQUIRED COMPETENCIES\n\n(All competencies are required upon entry)\nAnalyzing Complex Information - The ability to collect information from a variety of different sources (e.g., platform level performance, resource constraints, performance dashboards, etc.), and identify fundamental patterns/trends across sets of highly complex data. This includes the ability to gather, integrate, and interpret high level information from multiple sources.\nBuilding Trusting Relationships - The ability to build trusting, collaborative relationships and rapport with different types of people and businesses. This includes delivering on commitments and maintaining confidential information, as well as being approachable, showing interest in the other person, and relating well to people regardless of personality or background.\nCommunicating Effectively - The ability to compellingly communicate one's perspectives and ideas to all levels of the organization. This includes the ability to convey complex information in an engaging way, adapt the message, delivery, and point-of-view based on the audience's real-time or anticipated reactions. This also includes active listening, and eliciting questions, participation, and buy-in from the audience.\nCommunication - The ability to convey information clearly and accurately, as well as choosing the most effective method of delivery (e.g., email, phone, face-to-face). This includes using a technically sound communication style both verbally and in writing.\nCreating the New and Different - The ability to be creative. This includes the ability to produce breakthrough ideas, being a visionary, managing innovation, seeing multiple futures, having broad interests and knowledge, and gaining support in order to translate new ideas into solutions. This also includes the ability to plan and implement unconventional ideas and speculate about alternative futures without all of the data.\nDealing with Conflict - The ability to quickly and directly address problems, find common ground, and persevere on tough assignments. This includes having the willingness to be centrally involved in debates and facilitating conflict discussion and resolution.\nDecision Making - The ability to make quick, accurate decisions. This includes the ability to weigh alternatives and take into account the impact of the decisions on people, equipment, or other resources.\nDemonstrating Personal Flexibility - The ability to demonstrate resourcefulness and resilience in the face of change, obstacles, and adversity. This includes adapting to competing demands and shifting priorities. This also includes improving adaptability, pursuing new skills and knowledge, and regularly seeking feedback from others.\nGetting Organized - The ability to be organized, resourceful, and planful. This includes the ability to leverage multiple resources to get things done and lay out tasks in sufficient detail. This also includes the ability to get things done with fewer resources and in less time, work on multiple tasks at once without losing track, and foresee and plan around obstacles.\nMentoring and Coaching - The ability to develop, coach, and mentor associates. This includes the ability to provide development experiences and network opportunities, advise, and teach to prepare associates for effective job performance.\nSoftware Engineering - Knowledge of the overall process for developing new software. This includes knowledge of the roles and responsibilities of software engineering and other functions, major phases, checkpoints and deliverables. This also includes the ability to identify common issues and considerations for bringing a new product to the marketplace.\nSoftware Optimization - Knowledge of techniques and approaches to optimize software for specific hardware platforms. This includes basic practices in software optimization and the interaction between software and the hardware platform.\nTaking Initiative - The ability to attack work activities with drive and energy, understanding the impact of work on key metrics, and making decisions that are in the company's best interest. This includes not being afraid to initiate action before all the facts are known, and driving value-added work tasks to completion.\nTechnical Troubleshooting - Knowledge of systematic approaches to solving common technical problems (e.g., hardware, software, application, operational). This includes the ability to identify problems and report and escalate problems according to established procedures. This also includes the ability to identify available resources for troubleshooting.\nTime Management - The ability to quickly prioritize mission-critical from less important or trivial work activities. This includes sensing what the next most useful thing is to work on, and focusing on the critical few tasks that add value while putting aside or delaying the rest.\nMinimum Qualifications\nBachelor's degree in Engineering, Electronics and Communication Engineering, Information Systems, Computer Science/Engineering or related field.\n8+ years Software Engineering or related work experience.\n4+ years experience with Programming Language such as C, C++, Java, Python, etc.\nPreferred Qualifications\nStrong knowledge and hands-on experience with the OS concepts, Linux Device Driver, and other RTOS, Hypervisors, Containers etc\nExperience with the wireless Modem technologies such as 4G/5G, DSDA, DSRC/CV2X, Antenna & Compensator SW design and Validation.\nExperience with the Telematics Modules architecture, SW Design and Development and commercialization.\nKnowledge on the Automotive systems and experience with the SW development according to ASPICE and other agile methodologies.\n4+ years experience with Programming Language such as C, C++, Java, Python, etc.\n15+ years Software Engineering or related work experience.\n5+ years experience working in a large matrixed organization.\n3+ years of work experience in a role requiring interaction with executive leadership (e.g., Director/ Sr Director or Vice President level and above).\nMaster's Degree in Engineering, Electronics and Communication Engineering, Information Systems, Computer Science/Engineering or related field.\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 8+ years of Software Engineering or related work experience.\nORMaster's degree in Engineering, Information Systems, Computer Science, or related field and 7+ years of Software Engineering or related work experience.\nORPhD in Engineering, Information Systems, Computer Science, or related field and 6+ years of Software Engineering or related work experience.\n4+ years of work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['container', 'mac', 'rtos', 'hypervisor', 'linux device drivers', 'c++', 'hiring', 'networking', 'staffing', 'apex', 'salesforce', 'java', 'data loader', 'recruitment', 'linux', 'software engineering', 'visualforce', 'python', 'c', 'data analysis', 'sfdc', 'vmware', 'microsoft azure', 'triggers', 'salesforce crm', 'aws']",2025-06-12 14:17:27
Computer Operator,Sai Space Engg.,0 - 5 years,"36,000-1.2 Lacs P.A.",['Jamshedpur( Telco Colony )'],Responsibilities:\n* Enter data into computer systems accurately using MS Office software\n* Manage email correspondence and calendar scheduling\n* Maintain database integrity through regular backups and updates\n\n\nFlexi working\nOver time allowance\nAnnual bonus\nReferral bonus,Industry Type: Electronics Manufacturing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Computer Operating', 'Word Processing', 'Typing', 'Excel Powerpoint', 'Computer', 'English Typing', 'Internet', 'Data Entry', 'MS Office', 'MS Office Word', 'Data Entry Operation']",2025-06-12 14:17:29
"Software Developer , Software Testing Fresher &Experience- 0 To 4 yrs",Prime Time Solutions Pune,0 - 4 years,3-8 Lacs P.A.,"['Navi Mumbai', 'Pune']","Urgent Job Opening - Multiple\n\n1) Designation - Software Developer ,Java, . Net , Python, PHP, SQL, Data science ,Data Analyst\n\n2) Designation - Manual Testing & Automation Testing\n\nExperience- 0 to 4 yrs\n\nSalary - 4 to 9 Lakh\n\nJob Location - Pune",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Java', 'Manual Testing', 'SQL', 'Software Developer', 'Python', 'C++', 'Data science', 'Data Analyst', 'Linux', 'Automation Testing', 'PHP', '. Net', 'Python Development', 'AWS']",2025-06-12 14:17:31
In-Business Control - Operations,Crisil,1 - 2 years,Not Disclosed,['Pune'],"Role Overview:\nThe IBCOO Group is seeking a Retainer to provide operational support for the Ratings line of Business within the In-Business Control Group. This role focuses on access control activities, including conducting periodic and non-periodic access reviews, managing access control certifications and overseeing governance for transfers and leavers.\nKey Responsibilities:\nFunctional Responsibilities:\nExecute access control, ensuring timely reviews of user access and effective resolution of discrepancies.\nAnalyze system data to identify trends and share insights with stakeholders, developing targeted action plans based on findings.\nConduct independent research to enhance data understanding and inform decision-making.\nApply troubleshooting skills, including Root Cause Analysis, to identify issues and implement corrective actions.\nAdhere to strict deadlines, maintaining accurate records in compliance with internal procedures.\nRespond promptly to access-related inquiries via email or calls.\nBalance effective operational execution with a commitment to continuous improvement. - Support process stakeholders (e. g., requestors, approvers, IT application teams, compliance) through training, expertise, and clear communication.\nClient and Stakeholder Management:\nTake ownership of all deliverables, ensuring timely and high-quality execution of tasks.\nBuild and maintain strong relationships with client counterparts.\nCommunicate effectively with clients regarding task guidance, progress updates, and any challenges encountered during execution.\nCandidate Profile:\nGood communication (written and oral), interpersonal, and organizational skills.\nBasic understanding of data analysis principles.\nProficiency in Basic Excel is required; familiarity with Power BI and Python is preferred but not mandatory.\nProfessional demeanor with a collaborative mindset, capable of interfacing effectively with internal and external stakeholders.\nDiligent, intellectually curious self-starter with a strong work ethic and a drive for success.\nEssential Qualifications:\nBachelor s degree with 1-2 years of experience in operational processes, preferably in Risk & Control processes.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Access control', 'Root cause analysis', 'Basic', 'Data analysis', 'Risk control', 'power bi', 'Stakeholder management', 'Troubleshooting', 'Operations', 'Python']",2025-06-12 14:17:33
"Applied Scientist, Amazon Autos",Amazon,3 - 8 years,Not Disclosed,['Gurugram'],"Interested in building something new? Join the Amazon Autos team on an exhilarating journey to redefine the vehicle shopping experience.\nThis is an opportunity to be part of the Amazons new business ventures. Our goal is to create innovative automotive discovery and shopping experiences on Amazon, providing customers with greater convenience and a wider selection.\nYoull work in a creative, fast-paced, and entrepreneurial environment at the center of Amazons innovation. As a key member, youll play a pivotal role in helping us achieve our mission. We are looking for a highly accomplished Applied Science professional drive our science strategy, foster a culture of data-driven decision-making, and drive impactful business outcomes through advanced state-of-the-art science methodologies.\nIf youre enthusiastic about innovating and delivering exceptional shopping experiences to customers, thrive on new challenges, and excel at solving complex problems using top-notch ML models, LLM and GenAI techniques, then youre the perfect candidate for this role. Strong business acumen and interpersonal skills are a must, as youll work closely with business owners to understand customer needs and design scalable solutions.\nJoin us on this exhilarating journey and be part of redefining the vehicle shopping experience.\n\n\nAs an Applied Scientist in Amazon Autos, you will:\n\nShape the roadmap and strategy for applying science to solve customer problems in the Amazon AutoStore domain.\nDrive big picture innovations with clear roadmaps for intermediate delivery.\nApply your skills in areas such as deep learning and reinforcement learning while building scalable solutions for business problems.\nProduce and deliver models that help build best-in-class customer experiences and build systems that allow us to deploy these models to production with low latency and high throughput.\nUtilize your Generative AI, time series and predictive modeling skills, and creative problem-solving skills to drive new projects from ideation to implementation.\nInterface with business customers, gathering requirements and delivering science solutions.\nCollaborate with cross-functional teams, including software engineers, data scientists, and product managers, to define project requirements, establish success metrics, and deliver high-quality solutions.\nEffectively communicate complicated machine learning concepts to multiple partners.\nResearch new and innovative machine learning approaches.\n\nA day in the life\nIn this role, you will be part of a multidisciplinary team working on one of Amazons newest business ventures. As a key member, you will collaborate closely with engineering, product, design, operations, and business development to bring innovative solutions to our customers.\nYour science expertise will be leveraged to research and deliver novel solutions to existing problems, explore emerging problem spaces, and create new knowledge. You will invent and apply state-of-the-art technologies, such as large language models, machine learning, natural language processing, and computer vision, to build next-generation solutions for Amazon.\nYoull publish papers, file patents, and work closely with engineers to bring your ideas to production.\n\nAbout the team\nThis is a critical role for Amazon Autos team with a vision to create innovative automotive discovery and shopping experiences on Amazon, providing customers better convenience and more selection. We re collaborating with other experienced teams at Amazon to define the future of how customers research and shop for cars online. 3+ years of building models for business application experience\nPhD, or Masters degree and 4+ years of CS, CE, ML or related field experience\nExperience in patents or publications at top-tier peer-reviewed conferences or journals\nExperience programming in Java, C++, Python or related language\nExperience in any of the following areas: algorithms and data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing Experience using Unix/Linux\nExperience in professional software development\nExperience building complex software systems, especially involving deep learning, machine learning and computer vision, that have been successfully delivered to customers",,,,"['Unix', 'Computer vision', 'C++', 'Linux', 'Machine learning', 'Data structures', 'Product design', 'Data mining', 'Automotive', 'Python']",2025-06-12 14:17:35
Mis Executive,Export Company,3 - 5 years,2.5-3.5 Lacs P.A.,['Mumbai (All Areas)( Bhiwandi )'],"Perform in-depth data analysis using Excel formulas (e.g., VLOOKUP, HLOOKUP, SUMIFS, INDEX/MATCH), Pivot Tables, & other analytical tools to identify trends, patterns, anomalies, & opportunities for improvement.will be responsible for managing, analy\n\nRequired Candidate profile\nTranslate complex data into clear, concise, and visually appealing presentations and charts within Excel.Provide actionable insights and recommendations based on data analysis to support business",Industry Type: Textile & Apparel (Fashion),"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Mis Excel', 'Google Sheets', 'MIS Preparation', 'Textile', 'MIS Operations', 'Formulas', 'Advanced Excel', 'Excel Sheet', 'Data Entry', 'HLOOKUP', 'MIS Reporting', 'Excel Reporting', 'Computer Skills', 'Excel Report Preparation', 'Pivot Table', 'SUMIF', 'Google Drive', 'VLOOKUP', 'Mis', 'Mis Analysis', 'Data Analysis', 'Lookup', 'Pivot']",2025-06-12 14:17:38
Senior Analytics Consultant,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Analytics Consultant with a proven track record of success preferably in the banking industry.\n\nIn this role, you will:\nConsult, review and research moderately complex business, operational, and technical challenges that require an in-depth evaluation of variable data factors",,,,"['data manipulation', 'Data Engineering', 'data analysis', 'data management', 'SQL']",2025-06-12 14:17:40
Mis Executive,apply for more details,2 - 5 years,2.5-3.5 Lacs P.A.,"['Mumbai', 'Mumbai Suburban', 'Mumbai (All Areas)']","Mini 2 yrs of exp in MIS or data reporting roles; background in insurance domain is preferred,Advanced Excel skills-VLOOKUP, HLOOKUP, SUMIF, COUNTIF, Pivot Tables,Power Pivot.\nHandle large data sets with accuracy and ensure timely report delivery.\n\nRequired Candidate profile\nResponsible for creating,maintaining MIS reports, dashboards,data analysis to support business decisions.\nStrong analytical mindset with attention to detail,ability to troubleshoot data-related issues\n\nPerks and benefits\nTo be disclosed post interview",Industry Type: Financial Services,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['MS Excel', 'MIS Operations', 'Insurance Domain', 'MIS Reporting', 'MIS Executive', 'data analysis', 'Conditional Formatting', 'Advanced Excel', 'Troubleshooting', 'dashboards', 'HLOOKUP', 'COUNTIF', 'Pivot Table', 'SUMIF', 'report delivery', 'MIS', 'VLOOKUP', 'Power Pivot', 'MIS reports', 'Management Information System']",2025-06-12 14:17:42
Senior Manager- Hub Operations - Rajpura Chandigarh,Delhivery,4 - 9 years,12-15 Lacs P.A.,"['Chandigarh', 'Rajpura']","Hi,\n\nPFB the key responsibilities:\n\nPlanning, Organizing & Monitoring end to end line haul operations which includes all modes of transportation (Air, Road, and Rail)\nManage the weekly creation and daily management of the linehaul schedule and associated systems\nProper implementation of the policies and is a part of audit team to find gaps and provide time to time solutions\nMonitoring commercial connections, vehicles availability and daily follow up for the held back shipments\nMaintain the shipment records for each client\nMaintain the SLA for each shipment to be received at customer premises within scheduled time.\nWork with forecasting team to drive improvement of the base forecast\nManage and perform ongoing analysis to work with appropriate teams to develop and improve scheduling methodologies and systems\nManage and improve scheduling metrics to identify trends and shortcomings and drive scheduling accuracy\nFacilitate communication and coordination with different teams and coordinate for the creation of a schedule that meets all stakeholders expectations and concerns.\n*Candidate should be flexible to work in shifts* *6 days working*",Industry Type: Courier / Logistics (Logistics Tech),Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Supply Chain Operations', 'Reverse Logistics', 'Inbound Logistics', 'Outbound Logistics', 'Data Analysis', 'Hub Operations', 'Logistics Operations', 'People Management', 'Transport Operations', 'Warehouse Operations', '3Pl']",2025-06-12 14:17:44
Data Science Consultant,Techf Solutions,8 - 13 years,22.5-30 Lacs P.A.,['Indore'],"As a Senior AI Developer/ AI Architect in the AI team, you will work and mentor a team of developers, working on the Fusion AI Team and its AI engine AI Talos alongside research in the space, such as large language models, simulations, & agentic AI.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['RAG architecture', 'Python', 'full-stack developer', 'GitHub', 'Hugging Face', 'Jira', 'Pytorch', 'Gen AI', 'Llama2', 'Docker', 'Pandas', 'Pydantic', 'Pyarrow', 'Scikit', 'Mistral AI']",2025-06-12 14:17:47
Business Development Manager,MakeMyTrip,3 - 8 years,Not Disclosed,['Ludhiana'],"About the Opportunity:\nRole: Business Development Manager\nReporting To: Zonal Manager\nLocation: Ludhiana\nLevel: Senior Executive/Assistant Manager\n\nAbout the Function The Independent Hotels team is part of the Domestic Hotel Supply Function and this team manages supply from Independent hotels based across India and has about 70,000+ Hotels contracted on our platforms.\n\nAbout the Role The incumbent will be tasked with establishing and fostering connections with independent hotels. Oversee comprehensive key account management from start to finish, ensuring the sustainable performance of the region. This role necessitates travel to various hotels within the portfolio, delivering expert guidance, metrics analysis and recommendations based on industry best practices to our hotel partners.\n\nWhat will you be doing\n1. Relationship and Account Management :\nResponsible for connecting and engaging with independent hotels.\nEnd to end account management and driving sustainable performance of the region.\nSourcing & onboarding new hotels.\nThe role involves traveling to different hotels in the portfolio and providing expertise, metrics analysis and recommendations based on the industry's best practices to the hotel partners.\n2. Portfolio Management and Driving Growth :\nGrowing net revenue in the market by developing business plans to achieve revenue goals, ensuring inventory levels exceed demand throughout the market, and maintaining rate competitiveness across multiple available platforms.\n3. Data Analysis and Reporting:\nEstablishing and maintaining supplier relationships, training partner hotels on our extranet and wholesale business, reviewing monthly production reports, providing feedback to top-producing hotels, and planning and executing market site visits.\nBuilding MIS & market intelligence reports, preparing geography wise and service wise sales plans and achieving them. Sharing insights on market and industry with the clients and internal stake holders.\n4. Negotiating:\nNetworking, Deal initiating, negotiation & closing deal with the clients.\nStrategizing in order to market the hotel in a better way. It helps hotel partners to serve the needs of their customers and at the same time grow their businesses.\n\nQualification & Experience\nMasters degree from a reputed institute with 2- 6 years of experience in sales/Travel\nTrade/ Key Account Management/ Contracting/B2B Sales\nExperience in handling multiple accounts as a partner is preferred.\nProficiency in MS Excel and MS Power-point\n\nKey Success Factors for the Role\nStrong communication skills, Influencing skills, great interpersonal & stakeholder management skills.\nHigh on energy, team player coupled with a great attitude.\nProficiency in MS Excel and MS PowerPoint is essential.",Industry Type: Internet,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Business Development', 'Client Onboarding', 'Client Acquisition', 'New Business Development', 'Revenue Generation']",2025-06-12 14:17:50
Sr. Technology Auditor,AMERICAN EXPRESS,2 - 4 years,13-18 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Role & responsibilities\n•       Translate business risks, controls and supporting data into analytic requirements and partners with colleagues to build effective analytics and insights\n•       Responsible for multiple simultaneous audit projects of all sizes and complexity across multiple business areas within and outside of local region, in unfamiliar areas, and for different audit leaders\n•       Link analytics and insights to ongoing strategic initiatives\n•       Apply proven/ advanced data algorithms, advanced analytic and modeling techniques to draw insights essential to driving improvement initiatives",,,,"['Natural Language Processing', 'Tableau', 'Machine Learning', 'SQL', 'Python']",2025-06-12 14:17:52
Mis Executive,Hire Best Recruitment Company,3 - 5 years,3-4 Lacs P.A.,['Panaji'],"1. Practical experience with a variety of software applications like Excel/Advanced Excel/MS Access VBA/ Macros are an additional advantage.\n2. Attention to details.\n3. Proficiency in Microsoft Office and writing emails,\n\nRequired Candidate profile\nManage students related information including absenteeism, fee submission and processing, timetable/teacher’s updates etc\n.\nJob Location - Panaji Goa\nWeek Off - Rotational\n\nPlease call on\n9560477391",Industry Type: E-Learning / EdTech,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['MIS', 'Data Validation', 'Countif', 'MIS Operations', 'Formulas', 'Conditional Formatting', 'Charts', 'Advanced Excel', 'HLOOKUP', 'Macros', 'MIS Reporting', 'Pivot Table', 'SUMIF', 'Filters', 'Pivots', 'Excel', 'VBA', 'MS Access', 'VLOOKUP', 'Data Analysis', 'Lookup', 'Pivot', 'Dashboards', 'Management Information System']",2025-06-12 14:17:54
BD MIS Executive,Nuvoco Vistas Corporation (Nuvoco),2 - 5 years,3-6 Lacs P.A.,['Kolkata'],"Role & responsibilities Preferred candidate profile\nInteract with State BD Team to drive below mentioned key objective:\nBudgeting, Provisioning & Monitoring of sales Vs cost / MT as a monitoring tools at State level.\nTeam KPI Vs Actual compliance analysis, publishing State Performance Dash Board\nBudget control & collaboration with state BD team, raising PR in accordance with HO requirement.\nPerformance Monitoring, Checking, Circulation, Ranking, Review with State BD Team\nGift Stock reconciliation, BD MIS, IC, MRM data preparation at State Level.\nMonitoring State BD Team productivity increase by 10% Month on Month\nReporting and monitoring BD Dashboard data of State BD team.\nFlash report on Shubharambh, Utkarsh,Baat-Cheet & MayDay programs at State level.\nDetailed reporting and analysis on sales promotional activities. Reconciliation of BD Gifts and Stock.\nAnalysis of contractor lifting through Vriddhi Loyalty program\nAnalysis on enrollments of influencers & activation\nTracking of Enrollment in Nuvo Nirman App & Usage.\nSharing lead generated report by Nuvo Nirman App.\nClose coordination with State Sales data to achieve BD specific goals.\nFlash quality complaints report weekly basis.\nRaising PR at State level for BD Activity and follow up with Vendor\nTimely clearance of payment and bills follow up with accounts & finance team.\nImplementation of innovative ideas to increase maximum utilization of State BD Dashboard.\nCost optimization on services and State BD activities expenditure.\nBudget planning, analysis and execution (Cost/MT)\nPreparing of Special reports & Presentation for Sales & BD review.\n\n\nPreferred candidate profile\n\n2-3 years of experience in a similar organisation",Industry Type: Miscellaneous,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['MIS', 'Sales Mis', 'Advanced Excel']",2025-06-12 14:17:56
Senior AI Camera Systems Engineer,Qualcomm,2 - 4 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n2-4 years of experiences in image processing/computer vision/camera domain.\nWorking experience with machine learning framework/packages (e.g, PyTorch, TensorFlow, Keras etc.)\nStrong hands on experience on developing object detection, tracking or face detection algorithms.\nStrong background in image and signal processing, statistics, and data analysis.\nDeveloping machine learning algorithms for advanced imaging features\nStrong programming skills and working experience in C/C++\\ assembly programming skills, multithreading and RTOS/OS concepts\\fundamentals and Python.\nStrong debugging skills to debug complex system level issues.\nCollaborate with cross-functional teams to design, implement and debug camera\\multimedia features for mobiles.\nGood analytical and problem-solving skills.\n\n\nResponsibilities:\nDevelopment and productize camera essential features on Qualcomm chipsets for mobile\nInfluence camera HW architecture in Qualcomm chipsets\nCollaborate with systems, software, hardware teams at various stages of chipset life in design/validation/commercialization.\nCustomer interaction to commercialize Qualcomm camera solutions.\nIndividual contributions and working with cross functional teams on camera essential features design/planning/execution/commercialization for future Snapdragon chipsets\n\n\nEducation requirements:\nRequiredBachelor's/Masters/PHd Computer Engineering and/or Electrical / Electronic Engineering\nPreferred Masters\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['algorithms', 'data analysis', 'signal processing', 'debugging', 'statistics', 'image processing', 'python', 'c++', 'c', 'object detection', 'machine learning', 'imaging', 'mac', 'hw', 'tensorflow', 'rtos', 'computer science', 'computer vision', 'pytorch', 'keras', 'multithreading', 'system engineering']",2025-06-12 14:17:59
Senior Business Project Manager,Thryve Digital,9 - 14 years,Not Disclosed,"['Hyderabad', 'Chennai']","Job Summary:\n\nThis role collaborates across client teams to uncover, synthesize, analyze, and present critical information, supporting the team to identify insights and shape recommendations. The consultant will translate data analysis into a cohesive narrative, presenting findings clearly to both the team and clients. This position provides analytical support to the Enterprise Effectiveness team and requires excellent customer service and a proactive, problem-solving approach. The ideal candidate possesses a strong analytical mindset with the intuition to ask clarifying questions to uncover deeper insights.\nEssential Responsibilities:\n\nManage the entire analysis process from inception to completion, including advising on data nuances, providing suggestions on methodology, and preserving data security and integrity.\nDefine the design and layout of each analysis, working with clients to ensure data accuracy and quality. This includes conducting market research and performing rigorous data analysis. Develop compelling visualizations within PowerPoint and Excel.\nConduct research, data analysis, and benchmarking to inform decision-making. Support the development of strategic recommendations for internal business challenges. Assist in preparing executive-level presentations and reports.\nAnalyze workflows, identify inefficiencies, and propose process enhancements. Support implementation of leading practices to improve business performance.\nAssist in financial/business modeling, business case development, and cost-benefit analysis. Use data analytics to generate insights and support internal projects. Monitor trends and provide actionable insights to leadership.\nSupport client and customer immersion activities, including stakeholder interviews and market research.\nDevelop compelling presentations with a clear point of view, using formats such as PowerPoint. Clearly articulate findings and recommendations in a concise and impactful manner.\nWork effectively with teams across multiple departments to execute strategic initiatives. Assist in project management, including tracking deliverables and coordinating stakeholders. Support project teams in driving change management.\nEducation:\nBachelors degree in business, Engineering, or a related field (or equivalent experience).\n\nExperience:\nOverall Experience looking for 10 -15 Years with project management role.\nRequired: 2 years in strategy, operations, M&A, organizational development, general management, or a related field within a consulting firm or other professional environment.\n\nPreferred: Experience working in complex, matrixed environments or in the US Healthcare, Insurance industry.\n\nSkills:\n\nAbility to synthesize analysis, recommend actions, and prioritize next steps.\nDemonstrated ability to exercise initiative, independent judgment, and be a self-starter.\nAdvanced knowledge of Excel and PowerPoint, including data visualization techniques.\nStrong written and oral communication skills.\nSolid organizational skills and meticulous attention to detail.\nDemonstrated ability to use complex and interrelated data to generate insights.\nStrong analytical and problem-solving skills; intuition to ask clarifying questions where ambiguity exists.\nAbility to translate data analysis into a cohesive story via presentations.\nAbility to work independently while collaborating with global teams.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Project management', 'data analytics', 'data analysis', 'business modeling', 'customer service', 'business case development', 'business analysis', 'business analytics', 'data visualization', 'market research', 'organizational development']",2025-06-12 14:18:02
Senior Operational Risk Specialist,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Operational Risk Specialist\n\nIn this role, you will:\nManage the development, implementation, and monitoring of a risk-based program for a business or large functional area with moderate to high risk to identify, assess and mitigate operational risk that arises from inadequate or failed internal processes, people, systems, or external events",,,,"['Operational Risk', 'data analysis', 'SAS', 'Risk & Control', 'SQL']",2025-06-12 14:18:04
Senior Consultanr - AI Cloud Engineer,AstraZeneca India Pvt. Ltd,5 - 10 years,Not Disclosed,['Chennai'],"Job Title: Senior Consultant - AI Cloud Engineer Career Level: D2 Introduction to role:\nAre you ready to tackle some of the most exciting machine-learning challenges in drug discovery? We are seeking a Senior AI Platform Engineer to join our innovative AI platform team, IGNITE. With your expertise in AWS cloud environments, youll design and deploy large-scale production infrastructure that will redefine healthcare and improve the lives of millions worldwide. As part of a close-knit team of technical specialists, youll create tools that support major AI initiatives, from clinical trial data analysis to imaging and Omics. Your role will be pivotal in providing frameworks for data scientists to develop scalable machine learning models safely and robustly. Are you prepared to bridge the gap between science and engineering with your deep expertise?\nAccountabilities:\nDesign, implement, and manage cloud infrastructure on AWS using Infrastructure as Code (IaC) tools such as Terraform or AWS CloudFormation.\nMaintain and enhance CI/CD pipelines using tools like GitHub Actions, AWS CodePipeline, Jenkins, or ArgoCD.\nEnsure platform reliability, scalability, and high availability across development, staging, and production environments.\nAutomate operational tasks, environment provisioning, and deployments using scripting languages such as Python, Bash, or PowerShell.\nEnable and maintain Amazon SageMaker environments for scalable ML model training, hosting, and pipelines.\nIntegrate AWS Bedrock to provide foundation model access for generative AI applications, ensuring security and cost control.\nLead and publish curated infrastructure templates through AWS Service Catalogue to enable consistent and compliant provisioning.\nCollaborate with security and compliance teams to implement best practices around IAM, encryption, logging, monitoring, and cost optimization.\nImplement and manage observability tools like Amazon CloudWatch, Prometheus/Grafana, or ELK for monitoring and alerting.\nSupport container orchestration environments using EKS (Kubernetes), ECS, or Fargate.\nContribute to incident response, post-mortems, and continuous improvement of the platform s operational excellence.\nEssential Skills/Experience:\nBachelor s degree in Computer Science, Engineering, or related field (or equivalent experience).\n5+ years of hands-on experience with AWS cloud services.\nStrong experience with Terraform, AWS CDK, or CloudFormation.\nProficiency in Linux system administration and networking fundamentals.\nSolid understanding of IAM policies, VPC design, security groups, and encryption.\nExperience with Docker and container orchestration using Kubernetes (EKS preferred).\nHands-on experience with CI/CD tools and version control (Git).\nExperience with monitoring, logging, and alerting systems.\nStrong solving skills and ability to work independently or in a team.\nDesirable Skills/Experience:\nAWS Certification (e.g., AWS Certified DevOps Engineer, Solutions Architect - Associate/Professional).\nExperience with serverless technologies like AWS Lambda, Step Functions, and EventBridge.\nExperience supporting machine learning or big data workloads on AWS.\nExperience with SAFe agile principles and practices.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Version control', 'Networking', 'Machine learning', 'Agile', 'Healthcare', 'Monitoring', 'Python', 'Recruitment']",2025-06-12 14:18:06
Senior Software Engineer - Adobe Experience Platform ( AEP ),Wells Fargo,4 - 7 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a senior Software Engineer - Adobe Experience Platform (AEP)\nIn this role, you will:\nLead moderately complex initiatives and deliverables within technical domain environments\nContribute to large scale planning of strategies\nDesign, code, test, debug, and document for projects and programs associated with technology domain, including upgrades and deployments",,,,"['Software Engineering', 'Data Science', 'data model', 'data analysis', 'data modeling', 'configuration', 'APIs', 'AEP', 'CDP']",2025-06-12 14:18:08
Senior .Net Full stack Developer,Conduent,4 - 9 years,Not Disclosed,['Noida'],Job Track Description: \n\n Responsibilities \nDesign and develop highly scalable web based applications based on business needs.\nAnalyze user needs and develop software solutions using agile methodology.\nPerform data analysis using SQL Server.\nDevelop and maintain a thorough understanding of business needs from both technical and business perspectives\nAssist and mentor junior team members to enforce development guidelines.\nEffectively prioritize and execute tasks in a high-pressure environment\n\n\n Qualifications / Experience \nBachelor\\u2019s/Master\\u2019s degree in Computer Science / Computer Engineering\nMinimum of 4+ years\\u2019 experience in building enterprise scale N-tier web application using Microsoft .NET technologies.\n3+ years of experience in ASP.NET MVC\n2+ years\\u2019 experience on WCF Services or Microsoft Web API\n1+ years of experience in Angular 2 or higher is mandatory\nExperience with Agile application development.\nStrong knowledge of HTML5 and CSS3\nSQL server performance tuning (SQL Server 2008/2012/2014)\nWorking knowledge of SSRS and SSIS is plus\nAbility to work with a sense of urgency and attention to detail\nExcellent oral and written communication skills.,Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['css', 'html', 'web api', 'angular', 'asp', 'web application', 'devexpress', 'jquery', 'sql', 'ssrs', 'asp.net', 'mvc', 'wcf', 'api', 'microsoft net', 'agile methodology', 'c#', 'asp.net mvc', 'net mvc', 'sql server', 'wcf services', 'application development', 'asp.net core mvc', 'winforms', 'full stack', '.net', 'agile', 'ssis']",2025-06-12 14:18:10
Senior SailPoint Developer,Synechron,7 - 10 years,Not Disclosed,['Gurugram'],"Required Skills:\nExtensive hands-on experience with SailPoint IdentityIQ (IIQ) including onboarding, rule creation, object configuration, and application integration\nProficiency in core Java development for customization and extension of SailPoint functionalities\nStrong understanding of IAM concepts, including RBAC, SODs, role mining, and access provisioning\nExperience with API integrations via SCIM, web services, and REST APIs\nKnowledge of scripting languages to develop or customize workflows (e.g., Java, Groovy, or similar)\nFamiliarity with version control tools such as Git\nBasic understanding of enterprise ticketing platforms like Remedy or JIRA for provisioning and workflow integration\nPreferred Skills:\nUnderstanding of cloud IAM solutions or cloud migration considerations\nKnowledge of LDAP, Active Directory, or other directory services\nExperience with SailPoint out-of-the-box connectors and customizing them\nOverall Responsibilities\nLead design, implementation, and support of SailPoint IdentityIQ solutions, including onboarding applications, roles, certifications, reports, and workflows\nSupport the full SDLC (requirements, design, development, testing, deployment, and support) in line with organizational standards and Agile practices\nTroubleshoot, debug, and resolve IAM issues to minimize orphan accounts and access anomalies\nDevelop and deploy automation utilities and enhancements to improve operational efficiency of IAM processes\nCollaborate with vendors and internal teams to incorporate new features, perform upgrades, and resolve platform issues\nConduct regular performance reviews of IAM processes post-change deployment to ensure stability and security compliance\nDocument technical solutions, process workflows, and support artifacts for knowledge sharing and audits\nDrive continuous improvement initiatives and assist in feasibility analysis for cloud migrations and emerging IAM technologies\nTechnical Skills (By Category)\nProgramming Languages:\nEssential: Java, Groovy (for customization and workflow development)\nPreferred: Python, JavaScript for automation scripting\nDatabases & Data Management:\nBasic understanding of relational databases (e.g., Oracle, SQL Server) for audit reports and data analysis\nCloud Technologies:\nPreferred: Knowledge of cloud platforms (AWS, Azure) with focus on IAM aspects\nFrameworks & Libraries:\nFamiliarity with API standards (SCIM, REST) and integration protocols\nDevelopment Tools & Methodologies:\nEssential: Git, Agile/Scrum practices, version control, DevOps methodologies\nPreferred: CI/CD pipelines (Jenkins, Bitbucket pipelines)\nSecurity Protocols:\nUnderstanding of SAML, OAuth, LDAP, and other security standards\nExperience Requirements\n7 to 10 years of professional experience in IAM, with deep focus on SailPoint IdentityIQ implementations\nProven success managing complex identity management projects, including onboarding, provisioning, and role management\nDemonstrated ability to analyze and translate business requirements into technical IAM solutions\nExperience supporting identity security policies, SOD, and role mining workflows\nPrior experience with enterprise IT environments and vendor support collaborations preferred\nDay-to-Day Activities\nImplement and customize SailPoint IdentityIQ applications and components to meet project requirements\nConduct system configuration, testing, and deployment activities, ensuring compliance with organizational standards\nTroubleshoot identity and access issues, providing timely resolutions and root cause analysis\nDevelop scripts and utilities to automate manual processes, enhancing operational efficiency\nLiaise with vendors (like Cloudera or other platform providers) for platform support and feature enhancements\nPerform regular system performance reviews and capacity planning exercises\nProvide technical guidance and knowledge transfer to team members and stakeholders\nMaintain documentation of configurations, workflows, and system changes\nQualifications\nEducational Requirements:\nBachelors degree in Computer Science, Information Technology, or related field\nEquivalent professional experience in IAM or identity management\nCertifications (Preferred):\nSailPoint Certified IdentityIQ Engineer or similar IAM certifications\nTraining & Professional Development:\nCommitment to ongoing learning related to identity security, cloud IAM solutions, and emerging technologies\nProfessional Competencies\nCritical thinker with strong problem-solving skills\nEffective communicator with clarity in technical and non-technical language\nCollaborative team player able to work across geographically dispersed teams\nAbility to prioritize, manage time effectively, and adapt to changing project scopes\nProactive with a focus on continuous process improvement and innovation\nAnalytical mindset for identifying risks and implementing mitigation strategies",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SailPoint', 'Git', 'IAM', 'LDAP', 'CI/CD', 'Agile', 'Scrum', 'cloud IAM', 'SAML', 'OAuth']",2025-06-12 14:18:13
MIS Executive,Wipro,1 - 3 years,Not Disclosed,['Kolkata'],"Role Purpose\n\nThe purpose of the role is to provide timely, accurate and quality MIS reports, dashboards to the external & internal stakeholders of account(s) as per the defined process and standards of security and compliance\n\n\n\nDo\nPrepare timely and accurate MIS reports and dashboards as required by the stakeholders\nInteract and work closely with management, internal stakeholders & clients to understand the business information needs\nEnsuring all reports & dashboards are prepared as per stakeholder requirements as per the desired frequency (weekly/ monthly/ quarterly)\nEnsure regular review with the MIS Team Lead for 100% accuracy before populating any customized dashboard or generating any customized report\nTrack and follow up with relevant stakeholder for timely updation and data management of parameters (key SLA metrics such as run-rate etc.)\nGenerate account level reports (billable and non-billable) on forecasting, scheduling (both onshore and offshore) and performance against SLAs, CSAT, Quality etc.\nEnsure zero non-compliances on process audit on data security and compliance\nSupport and adopt tools and systems for efficient MIS generation and reporting system\nContinuous support to the manager in rolling out new techniques and initiatives to increase productivity\nProviding update to the manager on the progress of any new MIS initiatives\nPerform periodic maintenance and servicing of MIS system to improve operational efficiency\nAdopt new tools, technology solutions and develop capability through training to improve own productivity.\nDevelop analytical skills and understanding of statistical analysis to suggest improvement in the quality of analysis\nDeliver\nNo.Performance ParameterMeasure\n1. MIS Management and Reporting Quality of Analysis\nZero errors in reports\nZero non-conformance on timelines with respect to the client/ stakeholder requirements\n2.Stakeholder Management Customised dashboards as per client and functional requirements\nZero escalations on data reporting\nZero non-conformance on security or compliance requirements\n3.Team Management Team attrition %, Employee satisfaction score\nMandatory Skills: MIS.",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['MIS', 'data management', 'data reporting', 'advanced excel', 'dashboards']",2025-06-12 14:18:15
Adobe Analytics Specialist,Ltimindtree,5 - 7 years,Not Disclosed,['Bengaluru'],Reporting Dashboarding Data Analysis Insights\nStrong handson experience of Adobe Analytics Workspace in generating differentall types of CustomStandard Reports like Funnel Performance Path Analysis Fallout and End to End Customer Journey Analysis\nMust have working knowledge of AA dashboards designing and ad hoc reports to showcase trends progressspikefall rate across business KPIs and goals which provide stakeholders a clear understanding of digital performance\nSound functional knowledge on building segmentscrosssegmentation and calculated metrics to better understand user experience conversion based on data factors like source channel visitor frequency CLV and Demography etc\nAbility connect data from different data sources Media Campaign Web Analytics CRM First Party and Third Party etc Performance to design selfexplanatory dashboards\nGood understanding of AA OOB AddonsPlugins APIs to derive Automation Anomaly Detection and ReportingTagging Process Optimization\nMust have ability of story telling out of the data analysis for key business decision making for marketing leaders\nWell versed in conducting indepth analysis to identify improvement opportunities and provide actionable recommendations for data monetization and marketing strategies\nAbility to stich data across customer touch points within 1st Party website and later if user navigates to 3rd Party Partner Site and make it meaningful to leverage customer targeting as well as for personalization\nWeb Campaign TaggingData Collection\nGood experience in developing designing measurement frameworks across CLEs to stitch customer journeys\nCross Collaborate with DevelopmentIT Teams to ensure proper data collection and implementation of the required tags\nHands on experience in implementation of Thirdparty media pixels Creation of Campaign Tags and Custom Tracking codes as well as first party tags on site\nShould have sharp IQ for Data Validation Verification of website and campaign tagging which required QA across all stages of tagpixel implementation\nIdentify issues proactively and work closely with cross functional teams to recommend resolutions and enhancements\nOthers\nStay updated on industry trends and best practices in Web Analytics space recommending and implementing updates and optimizations\nShould have understanding of personalized customer targeting out of web and campaign performance analytics to derive the better ROI\nTraining and Support Provide training and support to internal teams on Adobe Analytics tools and methodologies\nTechnoFunctional Skills\nAdobe Analytics and Adobe Launch\nCampaign and Web Tagging Media Pixel Implementation\nCrossDevice Analytics Predictive Analytics Attribution Modeling RealTime Reporting Advance Segmentation MultiChannel Data Collection\nWorkspace Data Warehouse Reporting\nBasic understanding of htmljavascript,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Data validation', 'Process optimization', 'adobe analytics', 'Web analytics', 'Javascript', 'Data collection', 'HTML', 'CRM']",2025-06-12 14:18:18
Mis Executive / Edp Officer,Aakash Educational Services (AESL),1 - 6 years,3-5 Lacs P.A.,['Mumbai (All Areas)( Shanti Nagar Borivali )'],"Job Title: EDP Officer / MIS\nDepartment: Branch Operations\nReporting To: ABM Operations\nLocation: Borivali\n\nWhy Join AESL?\nPan-India Presence: Over 300 branches, offering vast growth opportunities.\nStudent-Centric Culture: Join 10,000+ professionals working with expert faculty to mentor and guide students.\nInnovative Environment: Work with cutting-edge digital learning tools in a fully digitized and hybrid classroom setup.\nProven Track Record: Join a team that helped produce 1,15,000+ NEET & JEE qualifiers in a single year, including 8 NEET AIR 1 ranks and 50+ top JEE ranks.\nJob Responsibilities:\nProcess admission forms, test results, and other academic documents.\nMaintain accurate student data (both historical and current) at the branch level.\nAnalyze student data and generate reports as needed.\nEnsure timely and accurate information delivery to relevant stakeholders.\nQualifications & Skills:\nGraduate in any discipline with relevant experience in desktop publishing.\nProficiency in Advanced Excel (Pivot Tables, VLOOKUP, HLOOKUP, Filters, Logical Formulas, VBA Macros).\nBasic working knowledge of MS Word and PowerPoint.\nWorking experience with the following tools is preferred:\nAdobe PageMaker\nCorelDRAW\nAdobe Photoshop\nMathType / Equation Editor\nMicrosoft Access\nKey Competencies:\nStrong attention to detail and organizational skills\nEffective planning and prioritization abilities\nAccuracy in data handling and reporting\n\nIndustry: Education / Training / Teaching\nFunctional Area: Branch Operations / EDP\nRole Type: Full-Time, Permanent",Industry Type: Education / Training,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Advanced Excel', 'Pivot Table', 'MIS Operations', 'VLOOKUP', 'Macros', 'HLOOKUP']",2025-06-12 14:18:20
Applied Research Center (ARC),Infosys,5 - 10 years,Not Disclosed,['Bengaluru'],"Responsibilities\n1. Emerging Tech Trends Research - Research on emerging tech trends, ecosystem of players, use cases and their applicability and impact to client businesses. Scan & curate startups, universities and tech partnerships needed and create innovation ecosystem. Rapidly design and develop PoCs in Emerging tech areas. Share design specifications with other team members, get the components developed, integrate and test. Build reusable components and develop PoCs using relevant startups and Open-source solutions.\n2. Thought Leadership - Develop showcases that demonstrate how emerging technologies can be applied in a business context, demo scenarios for the IP. Contribute towards patents, tier-1 publications, whitepapers, blogs in the relevant emerging tech area Get certified on the emerging technology, frameworks\n3. Applied Research Center Activities - Contribute to high level design development, testing and implementation of new proof of concepts in emerging tech areas.\n4. Problem Definition, Requirements - Understand technical requirements and define detailed design. Analyze the reusable components to map the given requirement to existing implementation and identify needs for enhancements\n5. IP Development - Develop program level design, modular components to implement the proposed design. Design and develop reusable components. Ensure compliance with coding standards, secure coding, KM guidelines while developing the IP\n6. Innovation Consulting - Understand client requirements and implement first of kind solutions using emerging tech expertise. Customize and extend IP for client specific features\n7. Talent Management - Mentor the team and help them acquire the identified emerging tech skill. Participate in demo sessions, hackathons8. Emerging Tech Startup Ecosystem Work with startups in providing innovative solutions to client problems and augmenting Infosys offerings\nTechnical and Professional Requirements:\nApplied Research Center [Emerging Areas]Advanced AI [SLM, Inference Scaling, Synthetic Data, Distributed Learning, Agentic AI, ANI]New Interaction Models [Spatial computing, Mixed Reality, 3D visualizations, New Experiences]Platforms and Protocols [Architecting and engineering for Performance, Uptime, Low-latency, Scalability, Efficiency, Data, Interoperability and Low cost, Beckn, CDPI]Cybersecurity [Ethical hacking, Threat Mgmt, Supply chain security & risk, Cyber Resilience]Quantum [Quantum AI, Stack, Simulation & Optimization, Cryptography, Valued use cases]Autonomous Machines [Humanoids, Industrial Robots, Drones, Smart Products]Emerging Research [Brain, AGI, Space, Semicon ]\nPreferred Skills:\nDomain->User Experience Design->Usability Principles->HCI\nFoundational->Learning Experience Design->Learning design Management->IP Management\nTechnology->X Reality (XR)->Augmented Reality\nTechnology->X Reality (XR)->Virtual Reality\nTechnology->Blockchain->Blockchain as a Service (BaaS)->AWS Blockchain\nTechnology->Robotic Process Automation->Intelligent Process Automation\nFoundational->Cybersecurity Competency Management->Cyber Competency Strategy Planning\nFoundational ->Data privacy->Privacy by design\nTechnology->Machine Learning->Generative AI\nAdditional Responsibilities:\nTechnical Competencies\nAdvanced theoretical knowledge in specific domain\nExperimental design and methodology expertise\nData analysis and interpretation skills\nPrototype development capabilities\nResearch tool proficiency relevant to domainSoft Skills and Attributes\nCollaborative mindset for cross-disciplinary research\nCommunication skills for knowledge dissemination\nCreative problem-solving approach\nIntellectual curiosity and innovation focus\nCommercial awareness for translational research\nEducational Requirements\nPhD of Computer Science,Bachelor of Engineering\nService Line\nGlobal Delivery\n* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['User Experience Design', 'Agentic AI', '3D visualizations', 'SLM', 'Distributed Learning', 'Inference Scaling', 'Spatial computing', 'ANI', 'Mixed Reality', 'Synthetic Data', 'New Experiences']",2025-06-12 14:18:22
MIS Executive,2coms,1 - 6 years,Not Disclosed,['Kolkata'],"SUMMARY\nWe are seeking a detail-oriented and skilled MIS Executive to join our team in New Alipore, Kolkata. The ideal candidate must be proficient in MS Excel, possess solid knowledge of accounting processes, and be experienced in generating accurate and insightful MIS reports. You will play a key role in managing data, tracking operational metrics, and supporting financial functions including TDS deductions, vendor payouts, and attendance reports.\n\nJob Title: MIS Executive\nLocation: New Alipore, Kolkata\nJob Type: Full-Time Work from Office\nIndustry:  Recruitment & Staffing\nKey Responsibilities:\nCreate, update, and manage daily/weekly/monthly MIS reports using MS Excel.\nMaintain and analyze data related to finance, operations, and HR (attendance, payroll, etc.).\nAssist in preparation of accounting statements including TDS deductions and vendor payments.\nCoordinate with finance and HR departments for timely collection and validation of data.\nHandle large data sets with accuracy and present it in a user-friendly format.\nEnsure timely and error-free report submissions to management and relevant stakeholders.\nCreate dashboards, pivot tables, VLOOKUPs, and other Excel tools for automation and reporting.\nMonitor and track key business performance indicators and operational KPIs.\nMaintain confidentiality and integrity of all financial and operational data.\n\n\nRequirementsRequired Qualifications:\nGraduate in B.Com / MBA (Finance preferred).\n1 3 years of experience in MIS reporting, accounting, or finance operations.\nStrong knowledge of MS Excel (Pivot Tables, VLOOKUP, Charts, Formulas, etc.).\nGood understanding of TDS, vendor payouts, and other accounting principles.\nAbility to analyze data and provide actionable insights.\nExcellent attention to detail, organizational skills, and time management.\nGood communication skills in English and Hindi/Bengali.\n\nBenefits\nCompetitive salary + performance incentives\n PF + ESIC\nWork Timings: 9:30 AM to 6:30 PM\nWeekly Offs: 2nd & 4th Saturdays\nInterested? Apply Now!\nInterested candidate kindly share your CV on 843684365",Industry Type: Recruitment / Staffing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['charts', 'tds', 'formulas', 'vlookup', 'accounting', 'dashboards', 'tables', 'operations', 'recruitment', 'mis', 'vendor', 'english', 'bengali', 'pivot', 'reporting', 'communication skills', 'process', 'mis reporting', 'time management', 'pivot table', 'monitoring', 'vendor payments', 'excel', 'financial operations', 'hindi', 'payroll']",2025-06-12 14:18:25
Manufacturing Engineering,Exide,8 - 13 years,Not Disclosed,['Bengaluru'],"Manufacturing Engineering Roles at Exide Energy Bengaluru\nExide Energy Solutions Ltd is actively recruiting for Manager, Deputy Manager, and Assistant Manager positions within its Manufacturing Engineering team at the Bengaluru Gigafactory. These roles are integral to the development, ramp-up, and optimization of lithium-ion cell manufacturing processes, encompassing areas such as electrode making, cell assembly, formation, and automated material handling systems\n\nKey Responsibilities:\nEquipment Specification & Vendor Management: Collaborate with technology providers to define equipment specifications, ensuring alignment with critical process control requirements. Lead interactions with project facilities teams to finalize plant design and equipment layout.\nProcurement & Installation Oversight: Create Request for Proposals (RFPs) for equipment, conduct technical evaluations, and provide recommendations. Manage the procurement process, ensuring timely release of Purchase Orders (POs) and adherence to project timelines.\nCommissioning & Stabilization: Oversee installation and commissioning activities, ensuring equipment meets specifications. Participate in Factory Acceptance Testing (FAT) and Site Acceptance Testing (SAT), validating equipment performance post-installation.\nProcess Optimization & Performance Monitoring: Analyze production data to identify bottlenecks and implement corrective actions. Utilize Manufacturing Execution System (MES) reports to track tool performance and improve metrics such as Overall Equipment Efficiency (OEE), yield, and cycle time.\nTraining & Documentation: Develop and deliver training programs for operations and maintenance teams. Maintain comprehensive documentation, including machine specifications, drawings, Bills of Materials (BOM), spare parts lists, and process flow charts.\nQualifications & Experience:\nEducational Background: Bachelor’s degree in Mechanical, Electrical, or Manufacturing Engineering.\nProfessional Experience: 5–8 years of experience in manufacturing engineering, with a focus on high-volume production environments.\nTechnical Skills: Proficiency in process optimization, equipment troubleshooting, and data analysis. Familiarity with Lean Six Sigma principles is advantageous.\nSoft Skills: Strong analytical abilities, attention to detail, and effective communication skills. Ability to work collaboratively in a cross-functional team setting.",Industry Type: Auto Components,"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['Installation And Commissioning', 'Manufacturing Engineering', 'Equipment Installation', 'Line Balancing', 'Assembly Line']",2025-06-12 14:18:27
Software Engineer Lab Test Automation,Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nRoleThe BDC Post Silicon Engineering group has an opening for a RF and Mixed-Signal Bench Characterization Engineer. This group develops Test solutions for design verification of highly integrated Receivers/Transmitters/Transceivers, Power management, Analog and Mixed signal ASICs designed by QCT. Job responsibilities for this position include New Test methodology implementation, Device Verification and Characterization, Design and debug of Test interface hardware, Test automation, and Data analysis.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field.\nRoleThe BDC Post Silicon Engineering group has an opening for a Lab Test Automation Framework Developer. This group develops Test solutions for design verification of highly integrated Receivers/Transmitters/Transceivers, Power management, Analog and Mixed signal ASICs designed by QCT. Job responsibilities for this position include developing robust, reliable automation framework and Software solutions to interface with RF Hardware and Instruments, ensuring seamless integration and functionality.\n\nSkills/Experience:\n\nSolid software skills for writing and debugging Test Automation code. Competency in automation development using at least 1 automation tool (C# / Python).\n\nDevelop software solutions using OOPs principles to interface with RF hardware, instruments, ensuring seamless integration and functionality.\n\nConduct rigorous testing and validation of automation framework to ensure compliance with industry standards and performance requirements.\n\nWork closely with cross-functional teams, to ensure cohesive system design and implementation.\n\nFamiliarity with AI/ML algorithms, understanding of deep learning concepts is a plus.\n\nKnowledge of RF fundamentals and System level knowledge is a plus.\n\nAble to work independently with initiative through challenges, Technical or otherwise.\n\nAble to communicate clearly, organize effectively and document work thoroughly while working with local and global teams.\n\nEducation :\n\nB.E, M.E or equivalent.\n\n4 years plus experience.\n\nKey Terms to Find on Resumes:\n\nC#, Framework, Object Oriented Programming(OOPs), Python, Test Automation, Software, AI, ML, Deep Learning, RF",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c#', 'hardware engineering', 'oops', 'debugging', 'object oriented programming', 'python', 'software test automation', 'bdd', 'software testing', 'automation testing', 'cucumber', 'manual testing', 'rest assured', 'deep learning', 'java', 'rf', 'selenium', 'test automation framework', 'testng']",2025-06-12 14:18:29
"Software Development Engineer II, International Emerging Stores",Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Shaping the Future of Global E-commerce!!\n\nAt Amazons International Emerging Stores (IES), were reinventing how millions of customers discover and shop online. Our team is architecting foundational platforms and mechanisms that will power Amazons next generation of shopping experiences globally. Were tackling intrinsically hard problems at the intersection of AI, personalization, and scalable systems challenges that require innovative solutions while maintaining our commitment to operational excellence. Our charter extends beyond traditional e-commerce boundaries, focusing on creating competitive advantages through technical innovation. Were building solutions that not only serve immediate business needs but establish new patterns and practices that can be adopted across Amazon. Our work demands deep technical judgment, cross-organizational collaboration, and the ability to influence at the highest levels of the organization.\n\nThe Opportunity: Software Development Engineer\n\nAt IES, were building the future of retail, and were looking for a talented Software Development Engineer to join our innovative team. As an SDE, youll be instrumental in revolutionizing how customers make purchase decisions across our retail platform by developing next-generation shopping experiences powered by artificial intelligence and adaptive technologies.\n\nIn this role, youll design and implement intelligent systems that deliver personalized shopping experiences, working with cutting-edge generative AI and ML models to create innovative visual experiences. Youll develop sophisticated algorithms for adaptive layout optimization, product visualization features, theme-based recommendation systems, and customer behavior analysis. Your work will span multiple customer touchpoints, requiring you to write high-quality, scalable code while collaborating with product managers, designers, and data scientists to drive technical solutions.\n\nWere seeking someone with strong programming skills and software design expertise, particularly in distributed systems and scalable architectures. Knowledge of AI/ML technologies and their practical applications is essential, as is the ability to translate complex business requirements into technical solutions. Youll participate in architecture discussions, technical design reviews, and contribute to the continuous improvement of customer experience metrics while debugging complex production issues and optimizing system performance.\n\nThis position offers an exciting opportunity to work on cutting-edge technologies while solving complex engineering challenges that impact millions of customers globally. Youll be part of a team that values technical excellence and innovation, with the chance to shape the future of e-commerce through technological advancement.\n\n3+ years of non-internship professional software development experience\n2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience\nExperience programming with at least one software programming language 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience\nBachelors degree in computer science or equivalent",,,,"['Computer science', 'Software design', 'Operational excellence', 'Software Development Engineer II', 'Coding', 'Artificial Intelligence', 'Debugging', 'Continuous improvement', 'Internship', 'Distribution system']",2025-06-12 14:18:31
AI/ML framework Staff Engineer,Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nLooking for ""ML framework and AI compiler Engineer"" responsible for\nDesigning, implementing, and deploying machine learning models using PyTorch\nFocusing on backend infrastructure and system architecture.\nResponsibilities often include developing framework, integrating with other AI tools, and ensuring scalability and reliability.\n\nHere's a more detailed breakdown of what you might see in such a job description:\n\nKey Responsibilities:\n\n\nModel Development and DeploymentDesigning, building, and deploying AI models, particularly those leveraging PyTorch for deep learning.\n\n\nBackend InfrastructureDeveloping and maintaining the backend systems that power AI applications, including data ingestion, processing, and storage.\n\n\nSystem ArchitectureDesigning scalable and high-performance backend architectures to handle AI workloads.\n\n\nModel OptimizationOptimizing model performance for speed, accuracy, and resource efficiency.\n\n\nIntegrationIntegrating AI models with other systems and applications.\n\n\nAPI DevelopmentCreating and maintaining APIs for communication between frontend and backend components.\n\n\nData HandlingManaging data ingestion, preprocessing, and storage for AI training and inference.\n\n\nCollaborationWorking with data scientists, product managers, and other engineers to bring AI solutions to life.\n\nTools, Technologies, Skills and Programming:\n\n\nC, C++: Strong programming capability using advanced techniques to design and develop AI compilers and backends.\n\n\nScripting: Strong expertise in Python with design, develop, release and maintain projects.\n\n\nAI Frameworks: Familiarity with other AI frameworks like PyTorch, TensorFlow, Hugging Face, etc.\n\n\nMachine Learning Knowledge: Understanding of machine learning principles and algorithms starting Computer vision to large language models and continuously update to new trends.\nExpertise to deep learning accelerator programming (GPU, NPU). Any parallel programming experience (Like CUDA, OpenCL, MKLDNN ..etc) is a plus.\nExperience with deep leaning compilers like Glow, TVM ""etc is a plus.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'system engineering', 'c#', 'cuda', 'algorithms', 'c++', 'parallel programming', 'artificial intelligence', 'opencl', 'deep learning', 'java', 'product management', 'computer vision', 'asp.net', 'multithreading', 'mvc', 'ml']",2025-06-12 14:18:33
"Manager, Vendor Consultant, AVS-NOP",Amazon,6 - 11 years,Not Disclosed,['Bengaluru'],"About Amazon.com\nAmazon.com strives to be Earths most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want low prices, vast selection, and convenience Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazons evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the companys DNA. The worlds brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.\n\n\nAbout the Role\nTeam Manager, Vendor Consultants Team RBS AVS\nAs a Vendor Consultants Manager in Retail Business Services (RBS), you will have the exciting opportunity to help shape and deliver on the strategy for managing Amazon vendors.\nRBS team is looking for a customer centric, driven, and creative people leader to join our team. The role leads a team of Vendor Consultants responsible for managing business growth for some of the most influential Selling Partners (vendors) on Amazon, ensuring Selling Partner satisfaction with the program through a high level of service and operational standards. In this role, you will manage strategic joint business plans for Selling Partners across your team by collaborating with them to explore innovative ways to identify and execute new operational improvement opportunities. You will interface internally with leaders from our Retail and Vendor Services teams and will be responsible for all operational aspects of the vendor s business with Amazon. Your team will engage directly with multiple internal teams to optimize the product line for key manufacturers (vendors) on Amazon. The candidate thrives in an ambiguous environment where they must develop, implement and iterate data, processes, mechanisms and guardrails to improve the customer experience. Further, the candidate is a business owner who understands the key levers to drive business growth and can operationalize those levers across their team. They have a passion for people leadership and are at their best when they re building, developing and managing high-performing teams. Your team will utilize a wide range of skills and work across major functional areas such as site merchandising, buying, inventory management, finance, operations and online marketing, to drive the performance of strategic vendor partners at Amazon. In this role you will be focused on the strategic and operational aspects of managing the customer relationships.\nYou will lead the team that looks into strategic and operational aspects of vendors business with Amazon, root cause analysis of issues and opportunities affecting the vendor s business.\n\nA day in the life\nResponsibilities Include:\nLead a team of Vendor Consultants, prioritizing strategic initiatives and provide escalation support as needed.\nSuccess will be measured by the performance of your internal teams on input metrics and impact of vendors on creating a great customer experience.\nIdentify, action and/or provide advice on how to improve business input metrics that drive growth and improve end customer experience, in collaboration with other Amazon programs and teams.\nManage end to end goal setting for team to align with organizational goals.\nBuild relationships with stakeholders across the portfolio; proactively build joint business plan action items and act as a point of escalation for issues, questions, and concerns.\nAct as a thought leader in defining success criteria and understand business needs of Selling Partners in an ever-changing business environment. Contributes to and leads strategic plans and documents for the organization.\nLeads recruiting and hiring efforts across direct team and broader organization.\nManage stakeholders needs and monitor complexity through efficient resource allocation of Vendor Consultants.\nMonitor stakeholders satisfaction survey results to analyze both positive and negative feedback trends. Establish improvement plans and mange expectations with Vendor Consultants as appropriate. 6+ years of digital advertising and client facing roles with a focus on data analysis experience\nBachelors degree\nExperience analyzing data and best practices to assess performance drivers\nExperience influencing internal and external stakeholders\nExperience with sales CRM tools such as Salesforce or similar software 2+ years of mentoring, leading and coaching experience",,,,"['Business services', 'Root cause analysis', 'Data analysis', 'Operations improvement', 'Online marketing', 'Resource allocation', 'Inventory management', 'Merchandising', 'CRM', 'Salesforce']",2025-06-12 14:18:36
Senior/Lead MLops Engineer,Tiger Analytics,7 - 10 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","JOB DESCRIPTION\n\nSenior MLE / Architect MLE (ML Ops) Chennai / Bangalore / Hyderabad (Hybrid)\n\nWho we are Tiger Analytics is a global leader in AI and analytics, helping Fortune 1000 companies solve their toughest challenges. We offer fullstack AI and analytics services & solutions to empower businesses to achieve real outcomes and value at scale. We are on a mission to push the boundaries of what AI and analytics can do to help enterprises navigate uncertainty and move forward decisively. Our purpose is to provide certainty to shape a better tomorrow. Our team of 4000+ technologists and consultants are based in the US, Canada, the UK, India, Singapore and Australia, working closely with clients across CPG, Retail, Insurance, BFS, Manufacturing, Life Sciences, and Healthcare. Many of our team leaders rank in Top 10 and 40 Under 40 lists, exemplifying our dedication to innovation and excellence. We are a Great Place to Work-Certified (2022-24), recognized by analyst firms such as Forrester, Gartner, HFS, Everest, ISG and others. We have been ranked among the Best and Fastest Growing analytics firms lists by Inc., Financial Times, Economic Times and Analytics India Magazine.",,,,"['MLops', 'Azure', 'Snowflake', 'Deployment', 'Ci/Cd', 'Machine Learning']",2025-06-12 14:18:38
HW Program Manager - Staff,Qualcomm,5 - 10 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Services Group, Engineering Services Group > Program Management\n\nGeneral Summary:\n\nDevelops, defines, and executes plans of record, includingschedules, budgets, resources, deliverables, and risks. Monitors and drives the program from initiation through delivery, interfacing with internal and external stakeholders across functions on technical matters, as needed. Monitors budget/spending, on-time delivery, and achievement of program milestones. Represents the program and drives alignment across stakeholders.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Computer Science, or related field.\n5+ years of Program Management or related work experience.\n\nPreferred Qualifications:\n\nMaster's degree in Engineering, Computer Science, or related field.\n\nPMP Certification.\n\n10+ years of Program Management or related work experience.\n\n5+ years of work experience in a role requiring interaction with senior leadership (e.g., Director level and above).\n\n3+ years of experience working in a large matrixed organization.\n\n2+ years of experience with program management tools such as dashboards, Gantt charts, etc.\n\nPrincipal Duties and Responsibilities:\nCollaborates with key stakeholders and program sponsors to develop program goals, set the prioritization of deliverables, discuss involvement of business processes (e.g., program change management, communication) and drives decisions necessary for on time delivery.\nManages and takes responsibility for multiple medium sized programs/technology with moderate complexity by applying up-to-date program management knowledge to meet deadlines.\nDevelops and manages the execution of the program Plan of Record (e.g., on time, on budget, within scope) for multiple medium sized programs which include schedule and resource forecasting, stakeholders identification, method and frequency of communication, scope, and prioritization.\nEstablishes key program metrics and manages team to take action outside their comfort zone to ensure program success when metrics deviate from Plan of Record.\nIdentifies and secures resources to ensure alignment of team with program/technology demand for multiple medium sized programs with moderate complexity.\nDrives teams to identify program issues/risks, and create a risk mitigation plan for multiple medium sized or a single complex program(s). Maintains and updates the risk tracker.\nPromotes program vision and objectives within the team, ensures program objectives are met or exceeded, presents program vision to management, and gains buy-in from stakeholders.\nPromotes adoption of processes by applying best practices and identifying and executing process improvement initiatives across the Program Management team.\n\nLevel of Responsibility:\nWorking independently with little supervision.\nMaking decisions that are significant in impact; errors are not readily apparent due to the complexity of work process/product or time between decisions and results; errors typically result in significant expenditure of time, resources, and funds to correct.\nUsing verbal and written communication skills to convey complex and/or detailed information to multiple individuals/audiences with differing knowledge levels. May require strong negotiation and influence, communication to large groups or high-level constituents.\nHaving a moderate amount of influence over key organizational decisions (e.g., is consulted by senior leadership to provide input on key decisions).\nCompleting tasks that require multiple steps that can be performed in various orders; tasks require simultaneously executing multiple cognitive abilities and maintaining information in short- or long-term memory.\nExercising exceptional creativity to innovate new ideas and develop innovative products/processes without established objectives or known parameters.\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or conflicting; advanced data analysis and interpretation skills are required.\nOccasionally participates in strategic planning within own area affecting immediate operations.\n\nThe responsibilities of this role do not include:\nFinancial accountability (e.g., does not involve budgeting responsibility).",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['data analysis', 'training and development', 'staff management', 'program management', 'training', 'employee relations', 'customer service', 'presentation skills', 'human resource management', 'employee engagement', 'recruitment', 'compensation', 'payroll', 'performance management']",2025-06-12 14:18:40
Engineer-Command Centre,ANZ,3 - 5 years,Not Disclosed,['Bengaluru'],"About Us\n\nAt ANZ, were applying new ways technology and data can be harnessed as we work towards a common goal: to improve the financial wellbeing and sustainability of our millions of customers.\nOur community of over 5,000 engineers is key to making this happen, because technology underpins every part of our business - from delivering tools, apps and services for our customers, to building a bank for the future.\nAbout the Role\nAs an Engineer in our Command Centre - Global Shift Operations, you ll play a key role in helping to monitor all the applications system, tasks and supervise the shift assigned to the operator through tools and provide first level support in case of any issues and proactively monitor the applications and systems to avoid critical impacts to the production.\nBanking is changing and we re changing with it, giving our people great opportunities to try new things, learn and grow. Whatever your role at ANZ, you ll be building your future, while helping to build ours.\nRole Type:Permanent\nRole Location:Bengaluru\nWork Hours:24*7\nWhat will your day look like?\nOversee and manage Tandem/Mainframe shift operations to ensure smooth and efficient functioning of the mainframe systems.\nLead a team of mainframe operators/Tandem, providing guidance, support, and direction to ensure tasks are completed effectively and efficiently.\nMonitor system performance, identify issues or anomalies, and take corrective actions to maintain system stability and availability.\nManage the allocated responsibilities as defined in the Incident Management Process for its effective and efficient operation.\nHandle and escalate incidents or problems that arise during the shift, coordinating with technical teams to resolve issues in a timely manner.\nOperate assigned platform(s) to provide reliable, secure and effective first level support to users/ customers.\nUndertake remedial action independently under limited guidance and keep internal users/ customers informed of progress.\nControl, monitor and maintain service availability according to defined standards and procedures.\nAnalyse, evaluate and prioritise incidents, changes and work requests and actions to resolve conflict or escalate to next level of support to ensure agreed service levels of performance are met.\nMaintain accurate records, logs, and documentation of operations activities, incidents, and changes for reference and audit purposes.\nTroubleshoot mainframe hardware, software, and network issues, working with technical teams to resolve complex problems and implement solutions.\nWhat will you bring?\n\nTo grow and be successful in this role, you will ideally bring the following:\nSignificant experience in computer operations, with approximately 6 years in multi-vendor system environments (IBM Mainframe and/ or Tandem and/ or systems management).\nComprehensive knowledge of Job Control Language (JCL) and /or systems operation and/or systems management, and on-line transaction processing systems (such as IMS, CICS, BASE24).\nHands-on experience working in Control-M GUI (IBM tool) for batch job monitoring.\nA proven track record in an operational environment with approximately 5 years experience in at least two of the following platforms - competent in one and adequate in another. Platforms include -\nMainframe - Control M, ISPF, $avers, Console, Netview.\nControl-M\nTandem (NonStop/Authentic)\nUnderstand infrastructure and application issues to a level that allows escalate or fix decisions.\nWell-developed data analysis skills with the ability to work independently or as part of a team. 3-5 years experience in a first level support type role with technical knowledge to train others.\nUnderstanding of operational/technical people management in a multi-platform environment.\nUnderstand support team functions and structures to allow correct second-level escalation decisions to occur.\nExcellent written and oral communication skills, and, demonstrated ability to liaise with all levels of management and external parties.",Industry Type: Banking,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Data analysis', 'JCL', 'ISPF', 'Cics', 'Control-M', 'Incident management', 'Operations', 'Financial services', 'IMS', 'Auditing']",2025-06-12 14:18:43
Wealth Management-Bengaluru-Associate-Software Engineering,Goldman Sachs,3 - 5 years,Not Disclosed,['Bengaluru'],"Associate GenAI Developer\nWe are seeking a highly skilled GenAI Developer to join our dynamic, global team. The ideal candidate will have a strong background in applied generative AI. This role will involve developing and implementing AI solutions, working with various technologies, and collaborating with cross-functional teams to drive innovation. The GenAI Developer will play a crucial role in advancing our GenAI capabilities and contributing to the success of our Wealth Management division.\nKey Responsibilities:\nWork with stakeholders to understand requirements and deliver AI solutions across several domains in Wealth Management.\nStay updated with the latest advancements in AI and machine learning technologies.\nConduct research and experiments to improve AI capabilities within the division.\nRequired Competencies:\nRetrieval-Augmented Generation (RAG): Experience in developing and implementing RAG models to enhance information retrieval and generation tasks.\nVector Stores: Knowledge of Vector Stores for efficient data storage and retrieval.\nPrompt Engineering: Skills in designing and optimizing prompts for AI models to improve accuracy and relevance.\nLarge Language Model APIs (LLM APIs): Understanding of different LLMs, both commercial and open source, and their capabilities (e.g., OpenAI, Gemini, Llama, Claude).\nProgramming Languages: Proficiency in Python, Java, or other relevant programming languages.\nData Analysis: Strong analytical skills and experience with data analysis tools.\nProblem-Solving: Excellent problem-solving abilities and attention to detail.\nCommunication: Strong verbal and written communication skills.\nPreferred Competencies:\nGraph RAG: Proficiency in using Graph RAG for complex data relationships and insights.\nKnowledge Graphs: Expertise in building and managing Knowledge Graphs to represent and query complex data structures.\nMachine Learning Frameworks: Experience with TensorFlow, PyTorch, or similar frameworks.\nExperience with cloud platforms such as AWS, Google Cloud, or Azure.\nFamiliarity with natural language processing (NLP) and computer vision technologies.\nPrevious experience in a similar role or industry.\nMaster s or Ph.D. in Computer Science, Data Science, or a related field.\nYears of experience: 3-5",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'Data analysis', 'Wealth management', 'Machine learning', 'Data structures', 'HTML', 'Investment banking', 'Open source', 'Python']",2025-06-12 14:18:45
Associate/ Senior Associate - Retail Sales,Delhivery,3 - 8 years,Not Disclosed,"['Pune', 'Tiruppur']","Roles and Responsibilities\n\nAbility to identify customers LTL/PTL requirements and clearly communicate the product\nofferings to match their needs.\nService a geographical area/client segment to generate leads & sign new customers. Responsible for negotiation & pricing closure.\nManage a portfolio of customers and potential customers via personal sales visits, using face to face contact to provide a personal service.\nBuild a strong client relationship to ensure that the account performs and grows to its maximum potential, reducing attrition rate and minimizing opportunities for competitors to gain business.\nConversion of qualified leads into customers (First Time Buyers) across Major, Small and Medium Business Accounts and develop and penetrate existing accounts (Retention and Development).\nAct as the customers main point of contact, by liaising closely with the relevant departments\nwithin Delhivery to ensure that their queries, problems or issues are dealt with appropriately.\nMonitor the health of accounts, service levels and enhace SOW growth. Prepare and present\nweekly/monthly reports detailing sales achieved and those predicted against targets.\nTo continually develop knowledge of Deliverys products/services and general commercial\nawareness to provide the best possible solutions to the customers.\n\nDesired Skills and Experience\n\nCandidate should have 2-7 yrs. experience in Logistics / SCM BD Role\nCandidate should have excellent communication skills, good negotiation & co-ordination, market intelligence, generate business inquiries, expanding sales & ensure the profitability of the\ncompany\nNew acquisition skills required\nAnalytical bent of mind and good data analysis skills\nWilling to travel and are ready to visit as per the company ask\nA positive attitude and a desire to promptly resolve potential customer issues or complaints to\nsupport business growth.\nGo getter and responsibility taker who will ensure that we hit monthly targets with given margins",Industry Type: Courier / Logistics (Logistics Tech),Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Retail Sales', 'Channel Sales', 'Sales', 'B2C Sales', 'Direct Sales', 'Field Sales', 'Business Development', 'B2B Sales', 'Corporate Sales']",2025-06-12 14:18:48
Wealth Management - Vice President-Software Engineering,Goldman Sachs,6 - 10 years,Not Disclosed,['Bengaluru'],"We are seeking a highly skilled GenAI Developer to join our dynamic, global team. The ideal candidate will have a strong background in applied generative AI. This role will involve developing and implementing AI solutions, working with various technologies, and collaborating with cross-functional teams to drive innovation. The GenAI Developer will play a crucial role in advancing our GenAI capabilities and contributing to the success of our Wealth Management division.\n  Key Responsibilities:\nWork with stakeholders to understand requirements and deliver AI solutions across several domains in Wealth Management.\nStay updated with the latest advancements in AI and machine learning technologies.\nConduct research and experiments to improve AI capabilities within the division.\nRequired Competencies:\nRetrieval-Augmented Generation (RAG): Experience in developing and implementing RAG models to enhance information retrieval and generation tasks.\nVector Stores: Knowledge of Vector Stores for efficient data storage and retrieval.\nPrompt Engineering: Skills in designing and optimizing prompts for AI models to improve accuracy and relevance.\nLarge Language Model APIs (LLM APIs): Understanding of different LLMs, both commercial and open source, and their capabilities (eg, OpenAI, Gemini, Llama, Claude).\nProgramming Languages: Proficiency in Python, Java, or other relevant programming languages.\nData Analysis: Strong analytical skills and experience with data analysis tools.\nProblem-Solving: Excellent problem-solving abilities and attention to detail.\nCommunication: Strong verbal and written communication skills.\nPreferred Competencies:\nGraph RAG: Proficiency in using Graph RAG for complex data relationships and insights.\nKnowledge Graphs: Expertise in building and managing Knowledge Graphs to represent and query complex data structures.\nMachine Learning Frameworks: Experience with TensorFlow, PyTorch, or similar frameworks.\nExperience with cloud platforms such as AWS, Google Cloud, or Azure.\nFamiliarity with natural language processing (NLP) and computer vision technologies.\nPrevious experience in a similar role or industry.\nmasters or Ph.D. in Computer Science, Data Science, or a related field.",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer vision', 'Data analysis', 'Wealth management', 'Machine learning', 'Data structures', 'HTML', 'Investment banking', 'Open source', 'Python']",2025-06-12 14:18:50
AutoIT Solutioning Engineer-Staff,Qualcomm,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n \n\nQualcomm Overview: \nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.\n\nGeneral Summary:\n\nAs a Site Reliability Engineer (SRE), youll be part of a highly collaborative team focused on provisioning and maintaining infrastructure and services with stability, sustainability, and security always on your mind. You will work in a self-guided, cross-functional team responsible for everything from modernizing traditional services and applications to deploying new technology. You'll collaborate closely with software engineers, data scientists, and product managers to maintain and optimize our systems. If you're passionate about automotive technology, software reliability, and continuous improvement, this role is perfect for you.\n\nYour Guiding Principles:\n\n\nAutomationYou understand the power of automation and ""infrastructure as code"" concepts. Automation is your primary consideration in problem-solving.\n\n\nCollaboration: You share a common language with fellow engineers, understand their needs, and thrive working in a high trust collaborate culture in which people are rewarded for taking risks.\n\n\nData-drivenYou understand why decisions are supported by facts and not opinions. You have experience applying logical approach to decision making. Skilled at metric collection and using that data to drive change.\n\n\nDebuggingYou understand debugging principles and are adept at applying them routinely and successfully.\n\n\nDevSecOps: You understand that DevSecOps is a culture which needs to be cultivated and you can help nurture those philosophies.\n\n\nSecurityYou know how to layer appropriate security within solutions across the lifecycle. You understand the security implications and consequences of any deployment.\n\n\nSelf-Driven: You understand how to prioritize work and time allocation at a personal and team level.\n\n\nStability: You know what it means to deliver a service with a high degree of reliability and are intimately familiar with how disruptions impact consumers.\n\n\nSustainability: You avoid one off solutions which are challenging to support. Instead, your solutions are aligned with team goals and strategic vision. You routinely dedicate cycles to reducing technical debt.\n\n\nWhat you have:\nExtensive Linux experience with servers and workstations. You can easily navigate the CLI, knowledgeable with typical Linux troubleshooting tools, and have a broad understanding of Ubuntu and RedHat.\nThe ability to automate through scripting languages such as Python, Bash, Go, etc.\nThe skill to provide sufficient automated test coverage of various implementations.\nYou have familiarity with Jenkins, Puppet, Splunk, JIRA, Vault, Docker, AWS, Cloud services, etc.\nAbility to respond rapidly to changing landscapes while providing stable, reliable, and secure services to customers.\nYou have a passion for continuous learning and leverage the scientific method to ensure nothing is taken for granted.\n\n\nResponsibilities:\nSystem Monitoring and Incident Response:\nMonitor system health, detect anomalies, and respond promptly to incidents.\nInvestigate and troubleshoot issues related to services.\nImplement proactive measures to prevent service disruptions.\nInfrastructure Automation:\nDevelop and maintain infrastructure-as-code (IaC) scripts for deployment and scaling.\nAutomate routine tasks to improve efficiency and reduce manual intervention.\nPerformance Optimization:\nCollaborate with development teams to optimize software performance.\nIdentify bottlenecks and implement solutions to enhance system speed and reliability.\nCapacity Planning:\nForecast resource requirements based on traffic patterns and business growth.\nScale infrastructure to accommodate increasing demand.\nSecurity and Compliance:\nEnsure compliance with industry standards and best practices.\nImplement security controls and participate in security audits.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['docker', 'linux', 'python', 'puppet', 'aws', 'kubernetes', 'owasp', 'golang', 'redhat linux', 'vulnerability assessment', 'ansible', 'microservices', 'java', 'devops', 'jenkins', 'debugging', 'penetration testing', 'vault', 'jira', 'cloud services', 'ubuntu', 'microsoft azure', 'splunk', 'bash', 'devsecops', 'terraform']",2025-06-12 14:18:52
RAG Architect,Qualcomm,13 - 18 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Test Engineering\n\nGeneral Summary:\n\nJob description\n\nWe are seeking an experienced AI Architect to design, develop, and deploy Retrieval-Augmented Generation (RAG) solutions for Qualcomm Cloud AI Platforms.\n\nRoles and Responsibilities\nLead the design and development of applications for RAG AI models and provide APIs for frontend consumption. Manage the interaction between retrieval-augmented techniques and generative models.\nBuild services that connect AI models (e.g., transformers, embeddings, and vector search) to handle tasks such as query retrieval, model inference, and generating responses. Leverage frameworks like Flask, FastAPI, or Django for API development.\nDesign pipelines to preprocess, clean, and prepare data for AI model training, as well as for serving the models in production environments. Optimize these pipelines to support both batch and real-time data processing. Implement RESTful APIs or GraphQL endpoints for seamless frontend-backend interaction.\nImplement cloud solutions to host Python-based services, ensuring that AI models are scalable and that the infrastructure can handle high traffic. Leverage containerization (Docker) and orchestration (Kubernetes) for model deployment and management.\nSet up monitoring, logging, and alerting for Python backend services, ensuring smooth operation of AI features. Use tools like Prometheus, Grafana, and ELK stack for real-time performance tracking.\nContinuously optimize model performance by fine-tuning and adapting Python-based AI models for real-time use cases. Manage trade-offs between computation load, response time, and quality of generated content.\nPartner with data scientists, machine learning engineers, and mobile/web developers to ensure tight integration between AI models, mobile/web front-end, and backend infrastructure.\n\n- Experience:\n13+ years of overall SW development experience\n10+ years Strong experience in working with technologies (e.g., React, React Native, Flutter, Django, Flask, FastAPI).\n5+ years of experience in building AI applications with a focus on NLP, machine learning, generative models, and retrieval-augmented systems.\nProven experience in designing and deploying AI systems that integrate retrieval-based techniques (e.g., FAISS, Weaviate) and generative models (e.g., GPT, BERT). - Expertise in cloud platforms (e.g., AWS, GCP, Azure) and deployment of Python-based microservices.\nBuilding RESTful APIs or GraphQL services (using frameworks like Flask, FastAPI, or Django).\nHandling AI model inference and data processing (using libraries like NumPy, Pandas, TensorFlow, PyTorch, and Hugging Face Transformers).\nIntegrating vector search solutions (e.g., FAISS, Pinecone, Weaviate) with the AI models for efficient retrieval-augmented generation. - Experience with containerization (Docker) and Kubernetes for deploying scalable Python-based services.\nProficient in cloud infrastructure management, with a focus on managing Python services in the cloud.\nExperience in End-to-End product development and Software Lifecycle\n\n\nKey\n\nSkills:\n\nAdvanced proficiency in Python for building backend services and data processing pipelines. Familiarity with frameworks like Flask, Django, and FastAPI. Experience with AI libraries and frameworks (TensorFlow, PyTorch, Hugging Face Transformers).\nFamiliarity with vector databases (e.g., Pinecone, FAISS, Weaviate) and integration with retrieval-augmented systems.\nStrong knowledge of RESTful API design, GraphQL, and API security best practices (e.g., OAuth, JWT).\nExcellent problem-solving abilities and a strong focus on creating highly scalable and performant solutions.\nStrong communication skills, with the ability to collaborate across different teams and geography\nAbility to mentor junior team members and lead technical discussions.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Software Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Software Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Test Engineering or related work experience.\n\n2+ year of work experience with Software Test or System Test, developing and automating test plans, and/or tools (e.g., Source Code Control Systems, Continuous Integration Tools, and Bug Tracking Tools).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data processing', 'cloud platforms', 'api', 'graphql', 'natural language processing', 's w development', 'rest api design', 'system testing', 'react native', 'machine learning', 'pipeline', 'react.js', 'flutter', 'test engineering', 'django', 'cloud infrastructure management', 'flask']",2025-06-12 14:18:55
AI Technical Architect,Care Allianz,7 - 11 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","Care Allianz is looking for AI Technical Architect_ to join our dynamic team and embark on a rewarding career journey\n\nDesigns AI-based system architectures for scalable solutions\n\nCollaborates with data scientists and engineers for model integration\n\nEnsures performance, scalability, and security of AI platforms\n\nGuides development teams in implementing AI strategies",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Technical Architect', 'Manager Technology']",2025-06-12 14:18:57
Staff System Test Engineer,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Test Engineering\n\nGeneral Summary:\n\n\n\nWe are seeking a Senior Staff AI System-Level Test Engineer to lead end-to-end testing of Retrieval-Augmented Generation (RAG) AI systems for Hybrid, Edge-AI Inference solutions. This role will focus on designing, developing, and executing comprehensive test strategies for evaluating the reliability, accuracy, usability and scalability of large-scale AI models integrated with external knowledge retrieval systems.\n\nThe ideal candidate needs to have deep expertise in AI testing methodologies, experience with large language models (LLMs), expertise in building test solutions for AI Inference stacks, RAG, search/retrieval architecture, and a strong background in automation frameworks, performance validation, and building E2E automation architecture.\n\nExperience testing large-scale generative AI applications, familiarity with LangChain, LlamaIndex, or other RAG-specific frameworks, and knowledge of adversarial testing techniques for AI robustness are preferred qualifications\n\nKey Responsibilities:\n\nTest Strategy & Planning\nDefine end-to-end test strategies for RAG, retrieval, generation, response coherence, and knowledge correctness\nDevelop test plans & automation frameworks to validate system performance across real-world scenarios.\nHands-on experience in benchmarking and optimizing Deep Learning Models on AI Accelerators/GPUs\nImplement E2E solutions to integrate Inference systems with customer software workflows\nIdentify and implement metrics to measure retrieval accuracy, LLM response quality\n\n\nTest Automation\nBuild automated pipelines for regression, integration, and adversarial testing of RAG workflows.\nValidate search relevance, document ranking, and context injection into LLMs using rigorous test cases.\nCollaborate with ML engineers and data scientists to debug model failures and identify areas for improvement.\nConduct scalability and latency tests for retrieval-heavy applications. Analyze failure patterns, drift detection, and robustness against hallucinations and misinformation.\n\n\nCollaboration\nWork closely with AI research, engineering teams & customer teams to align testing with business requirements.\nGenerate test reports, dashboards, and insights to drive model improvements.\nStay up to date with the latest AI testing frameworks, LLM evaluation benchmarks, and retrieval models.\n\n\nRequired Qualifications:\n8+ years of experience in AI/ML system testing, software quality engineering, or related fields.\nBachelors or masters degree in computer science engineering/ data science / AI/ML\nHands-on experience with test automation frameworks (e.g., PyTest, Robot Framework, JMeter).\nProficiency in Python, SQL, API testing, vector databases (e.g., FAISS, Weaviate, Pinecone) and retrieval pipelines.\nExperience with ML model validation metrics (e.g., BLEU, ROUGE, MRR, NDCG).\nExpertise in CI/CD pipelines, cloud platforms (AWS/GCP/Azure), and containerization (Docker, Kubernetes).\n\n\nWhy Join Us\nWork on cutting-edge AI retrieval-augmented generation technologies\nCollaborate with world-class AI researchers and engineers.\n\nIf you are passionate about AI system testing and ensuring the reliability of next-generation generative models, apply now!\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Systems Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Systems Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Test Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['automation framework', 'continuous integration', 'python', 'sql', 'ci cd pipeline', 'kubernetes', 'ci/cd', 'cloud platforms', 'software quality', 'artificial intelligence', 'docker', 'test engineering', 'quality engineering', 'e2e', 'testing methodologies', 'vector', 'aws', 'api testing']",2025-06-12 14:19:00
6 months Contract- HR Operations/Generalist/HR background,EY,1 - 5 years,Not Disclosed,"['Kochi', 'Bengaluru']","The opportunity\nProvide operation support for various administrative projects including but not limited mailbox management, managing databases, creation and release of periodic reports, work MS-excel reporting, Content Management, web based publication support, working on dashboard creations and data analysis.\nYour key responsibilities\nThe role requires someone who can manage a number of concurrent activities, with strong multi-tasking, prioritization, organizational and time management skills.\nVery good understanding of business functions and operations\nAbility to prioritize and co-ordinate with multiple people on various variables\nAbility to liaise with POC's in different regions/offices and work as a team\nDemonstrated proficiency and experience in MS Office Suite especially in Excel\nFlexible with working hours\nObservant with an eye for detail\nAbility to make sound decisions fast\nMethodical and systematic approach\nAnalytical and problem solving ability\nHigh energy level, confident and assertive\nSolid research and analytical skills\nThe ability to simplify complex analytical issues and communicate them to a variety of audiences.\nStrong interpersonal skills\nSkills and attributes for success\nExcellent written and oral communication skills in English language\nExcellent critical thinking skills to decipher the complex business requirements\nStrong presentational skills; ability to clearly communicate complex messages to a variety of audiences\nPossess high standard of integrity\nThe ability to work and team effectively with clients and other management personnel.\nTo qualify for the role, you must have\n2 to 4 Years in / BPO services/Project Co-Ordination.\nExperience in multiple systems and applications\nPrior work experience in a large professional services or financial services company\nExperience working with clients from different countries (Desirable)\nExperience working in an business where the primary spoken language is English",Industry Type: Management Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['HR Operations', 'Hr Ops', 'HR Generalist Activities', 'HR Coordination', 'HR Administration']",2025-06-12 14:19:02
Bill,Robert Bosch Engineering and Business Solutions Private Limited,2 - 5 years,Not Disclosed,['Bengaluru'],"Roles Responsibilities :\nActing as a billing and eInvoicing expert in the Bosch Digital Backbone Project, implementing S/4 HANA on the horizontal layer\nDriving Billing forms and templates for different countries and ensure standardization as much as possible\nDefine / align / facilitate requirements on functional process level\nSupport in definition of scenarios and template process design\nContribute to definition of IT requirements and acceptance criteria\nContribute to create user documentation for template processes\nSupport process documentation in Signavio and testing results in SolMan system\nSupport in definition of test cases\nConduct functional and component testing for template billing processes and eInvoicing\nBring in best practices / solutions from your area of expertise (e. g. from shared services) into the Order-to-Cash table work\nTake part in backlog creation and refinement, prioritization and sprint planning\nCoordinate with cross-functional departments (BD, C/FI, Tax)",Industry Type: Automobile,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Process design', 'O2C', 'Data analysis', 'Project management', 'Billing', 'Agile', 'Scrum', 'Test cases', 'Stakeholder management', 'Information technology']",2025-06-12 14:19:04
OMNI Channel Manager,Titan Company,7 - 10 years,17-20 Lacs P.A.,['Bengaluru'],"OMNI Channel Manager\nBusiness IBD Job Description: We are seeking a highly skilled and dynamic Omni-Channel Manager to join our growing international business division. This individual will be responsible for overseeing, optimizing the customer journey across all online, and offline touchpoints. The role will focus on integrating e-commerce platforms, brick-and-mortar stores, and other sales channels to deliver a seamless, efficient, and personalized experience for our global customer base.\nKey Responsibilities:\n1. Omni-Channel Strategy Development & Execution:\nDevelop and implement a comprehensive Omni-channel strategy for IBD, ensuring an integrated and consistent customer journey across all touchpoints (online, offline, social media, customer service) etc. Drive the seamless integration of the brand’s e-commerce platform with retail stores, improving both online and in-store customer experience",,,,"['Channel Growth', 'E-Com & OMNI sales', 'Omni-Channel Strategy Development & Execution', 'Lead Management', 'Sales Optimization', 'Business Strategy']",2025-06-12 14:19:06
Team Leader - Key Accounts Manager,Startek,3 - 6 years,5-7 Lacs P.A.,['Bengaluru'],"Location: Bangalore\nProcess: Key Account Management (E-commerce)\nExperience: 4+ years (including 1+ year in team handling)\nEducation: Any Graduate (10+2+3)\n\nJob Overview\nWe are looking for a dynamic and experienced Team Leader Operations to manage a team of Key Account Managers. The role requires driving seller performance on an ecommerce platform through strategic relationship management, sales enablement, and data-driven insights.\n\nKey Responsibilities\nLead and manage a team of Key Account Managers (KAMs) handling e-commerce sellers\nMonitor and drive team performance to achieve sales, revenue, and growth targets\nAnalyze seller performance and provide strategic inputs to enhance business outcomes\nCoordinate with internal stakeholders to ensure seamless seller support and resolution\nConduct regular reviews, coaching, and training sessions for the team\nMaintain team motivation and discipline while ensuring performance benchmarks are met\nManage dashboards, track KPIs, and generate performance reports using Excel\n\nDesired Candidate Profile\n• Graduate in any discipline (10+2+3)\n• Minimum 4 years of experience in KAM/RE (Relationship Executive) processes\n• Minimum 1 year of team handling experience\n• Proficient in MS Excel and comfortable with data analysis\n• Strong communication skills in Hindi and English\n• Proven leadership skills with ability to drive results through team\n• E-commerce domain experience preferred",Industry Type: Analytics / KPO / Research,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['key account manager', 'team leader', 'Ecommerce Marketing', 'Seller Onboarding', 'E-commerce']",2025-06-12 14:19:08
Assistant Manager,Genpact,3 - 8 years,Not Disclosed,['Bengaluru'],"Genpact (NYSE: G) is a global professional services and solutions firm delivering outcomes that shape the future. Our 125,000+ people across 30+ countries are driven by our innate curiosity, entrepreneurial agility, and desire to create lasting value for clients. Powered by our purpose the relentless pursuit of a world that works better for people – we serve and transform leading enterprises, including the Fortune Global 500, with our deep business and industry knowledge, digital operations services, and expertise in data, technology, and AI.\nInviting applications for the role of Data Analyst!\nWe are seeking a detail-oriented and analytical Data Analyst to join our team. The ideal candidate will be responsible for collecting, processing, and analyzing large datasets to provide insights that will help drive business decisions. You will collaborate with cross-functional teams to translate data into actionable recommendations, improving operational efficiency and enhancing strategic decision-making.",,,,"['Aviation', 'Aerospace', 'Data Analysis']",2025-06-12 14:19:11
Associate - Accounts Receivable,upGrad,1 - 6 years,5-6 Lacs P.A.,"['Bengaluru', 'Mumbai (All Areas)']","Job description - Associate - Accounts Receivable\n\nDaily Receipt Bookings: Accurately record and process all receipts, ensuring timely and correct\nupdates in the system.\nReconciliation: Perform daily and monthly reconciliation of accounts to ensure all discrepancies are\nidentified and resolved promptly.\nData Entry & Maintenance (Excel): Maintain and update accurate AR records, ensuring consistency",,,,"['Reconciliation', 'Accounts Receivable', 'AR']",2025-06-12 14:19:13
Cognizant hiring For Veeva CRM developer,Cognizant,4 - 9 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Location - Bangalore & Hyderabad\nExperience - 4 to 12 Years\nJob Summary\nExperience working in IT projects for Healthcare, Life sciences or Biopharma industry .\nExpertise in system administration, configurations, maintenance or Support of Salesforce CRM, VEEVA CRM projects\nDomain Admin and Configuration specialization on different Veeva OOB modules. Well-versed in all aspects of the and applications, including the application functions, system and business administration settings",,,,"['Veeva Crm', 'controller', 'Triggers', 'Apex']",2025-06-12 14:19:16
Senior Software Engineer,Dynamic Yield,5 - 10 years,Not Disclosed,"['Pune', 'Gurugram']","Our Purpose\nTitle and Summary\nSenior Software Engineer\nWhat is Mastercard?\n\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOur Team:\n\nThe AI & DPE team is responsible for product decisioning management and innovative product development under services business unit to address the evolving risk and security needs of all of Mastercard s various customer segments. AI & DPE team focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services to drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on driving actionable insights and build innovative solutions out of multiple data sources using analytics, machine learning and reporting capabilities.\n\nThe Role:\n\nWe are seeking a Senior Software Engineer who will:\nPartner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on requirement gathering in order to deliver analytics solutions that generate business value\n\nPerform data preparation by ingestion, aggregation, processing to drive and enable relevant insights from available data sets\n\nIdentify and code the best suited data algorithm model for the relevant insights\n\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions\n\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements\n\nAll about You\n\nStrong SQL knowledge for data preparation and mining\nStrong knowledge of writing data/machine learning algorithm in Python or R\nExperience in doing data analysis and extraction on Hadoop\nExperience of working on at least one reporting tool - Tableau and PowerBI is a plus\nExperience in data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies\nStrong understanding of the application of analytical methods and data visualization to support business decisions\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Data modeling', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:19:18
Project Support Officer / Engineer - Planisware,Quest Global,4 - 9 years,10-20 Lacs P.A.,['Bengaluru'],"Work Experience\n            Hands-on experience with various tools such as Planisware, Qlik Sense, Windchill, data spreadsheets, word processing software, PowerPoint, and Power BI\n            Proficient in data analysis, creating dashboards, summarizing information, and using pivot tables with spreadsheets\n            Strong analytical skills, with the ability to interpret complex project data.\n            Experience in project management or project support roles, ideally with a focus on cost planning, budgeting, or time tracking.\n            Proficiency in MS Excel (including advanced functions) and other data analysis tools.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Planisware', 'Power Bi', 'Powerpoint']",2025-06-12 14:19:20
Snowflake - Senior Technical Lead,Sopra Steria,2 - 11 years,Not Disclosed,['Noida'],"Position: Snowflake - Senior Technical Lead\nExperience: 8-11 years\nLocation: Noida/ Bangalore\nEducation: B.E./ B.Tech./ MCA\nPrimary Skills: Snowflake, Snowpipe, SQL, Data Modelling, DV 2.0, Data Quality, AWS, Snowflake Security\nGood to have Skills: Snowpark, Data Build Tool, Finance Domain\nPreferred Skills",,,,"['Performance tuning', 'Schema', 'HIPAA', 'Javascript', 'Data quality', 'Informatica', 'Analytics', 'SQL', 'Python', 'Auditing']",2025-06-12 14:19:22
Lead Digital Product Manager - Lending,Wells Fargo,5 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nThe CB CIB Digital team is looking for a dynamic individual to focus on building and evolving new digital lending experiences for ""Wells Fargo Vantage"", while partnering with multiple product teams across the organization. This individual will support the strategic roadmap, product vision and end-to-end execution in creating and delivering transformational experiences for specific product(s) within the individual journeys on Vantage such as Lending on the Digital Channels Team. The successful candidate will be able to build new experiences, leverage their well-rounded analytical, business, and communication skills, leadership capabilities, and must be a team player.",,,,"['digital product management', 'data analysis', 'business transformation', 'Agile', 'digital strategy', 'Tableau', 'product development lifecycle']",2025-06-12 14:19:24
"Manager, Account Management, AVS EU",Amazon,6 - 11 years,Not Disclosed,['Bengaluru'],"About Amazon.com\nAmazon.com strives to be Earths most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want low prices, vast selection, and convenience Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazons evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the companys DNA. The worlds brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.\nAbout the Role\nTeam Manager, Account Management\nAs a Manager, Account Management as part of Amazon Vendor Services (AVS) Team of Retail Business Services, you will have the exciting opportunity to help shape and deliver on a strategy for managing Amazon AVS vendors.\nAVS team is looking for a bright, customer centric, driven, and creative people leader to join our team. The role leads a team of Account Managers responsible for managing business growth for some of the most influential Selling Partners (vendors) on Amazon, ensuring Selling Partner satisfaction with the program through a high level of service and operational standards. In this role, you will manage strategic joint business plans for Selling Partners across your team by collaborating with them to explore innovative ways to identify and execute new selection, merchandising, and operational improvement opportunities. You will interface internally with leaders from our Retail and Vendor Services teams and will be responsible for all aspects of the vendor s business with Amazon. Your team will engage directly with multiple internal teams to optimize the product line for key manufacturers (vendors) on Amazon. The candidate thrives in an ambiguous environment where they must develop, implement and iterate data, processes, mechanisms and guardrails to improve the customer experience. Further, the candidate is a business owner who understands the key levers to drive business growth and can operationalize those levers across their team. They have a passion for people leadership and are at their best when they re building, developing and managing high-performing teams. Your team will utilize a wide range of skills and work across major functional areas such as site merchandising, buying, inventory management, finance, operations and online marketing, to drive the performance of strategic vendor partners at Amazon. In this role you will be focused on the strategic and operational aspects of managing the customer relationships with our vendors.\nYou will lead the team to conceive, create and analyze a wide range of marketing and site merchandising efforts, to include marketing campaigns to grow the vendor s traffic, brand awareness, customer conversion, and revenue on Amazon. Also you will look into strategic and operational aspects of their business with Amazon, root cause analysis of issues and opportunities affecting the vendor s business.\nResponsibilities Include\nLead a team of Account Managers, prioritizing strategic initiatives and provide escalation support as needed.\nSuccess will be measured by the performance of your internal teams on input metrics and impact of vendors on creating a great customer experience for buying consumers\nIdentify, action and/or provide advice on how to improve business input metrics that drive growth and improve end customer experience, in collaboration with other Amazon programs and teams.\nManage end to end goal setting for team to align with organizational goals.\nBuild relationships with Selling Partners across the portfolio; proactively build joint business plan action items and act as a point of escalation for outstanding issues, questions, and concerns.\nAct as a thought leader in defining success criteria and understand business needs of Selling Partners in an ever-changing business environment. Contributes to and leads strategic plans and documents for the organization.\nLeads recruiting and hiring efforts across direct team and broader organization.\nManage Selling Partner needs and monitor complexity through efficient resource allocation of Account Managers.\nMonitor Selling Partner satisfaction survey results to analyze both positive and negative feedback trends. Establish improvement plans and mange expectations with Account Managers as appropriate.\n\n\nLead a team of Account Managers, prioritizing strategic initiatives and provide escalation support as needed.\nManage end to end goal setting for team to align with organizational goals.\n\nBuild relationships with Selling Partners across the portfolio; proactively build joint business plan action items and act as a point of escalation for outstanding issues, questions, and concerns.\n\nAct as a thought leader in defining success criteria and understand business needs of Selling Partners in an ever-changing business environment. Contributes to and leads strategic plans and documents for the organization.\n\nLeads recruiting and hiring efforts across direct team and broader organization.\n\nManage Selling Partner needs and monitor complexity through efficient resource allocation of Account Managers.\n\nMonitor Selling Partner satisfaction survey results to analyze both positive and negative feedback trends. Establish improvement plans and mange expectations with Account Managers as appropriate.\n\nothers 6+ years of digital advertising and client facing roles with a focus on data analysis experience\nBachelors degree\nExperience analyzing data and best practices to assess performance drivers\nExperience influencing internal and external stakeholders 3+ years of mentoring, leading and coaching experience",Industry Type: Internet,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Business services', 'Root cause analysis', 'Data analysis', 'Operations improvement', 'Online marketing', 'Resource allocation', 'Inventory management', 'Brand awareness', 'Account management', 'Merchandising']",2025-06-12 14:19:27
Senior Software Engineer,Mastercard,10 - 15 years,Not Disclosed,"['Pune', 'Gurugram']","The AI & DPE team is responsible for product decisioning management and innovative product development under services business unit to address the evolving risk and security needs of all of Mastercard s various customer segments. AI & DPE team focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services to drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on driving actionable insights and build innovative solutions out of multiple data sources using analytics, machine learning and reporting capabilities.\n\nThe Role:\n\nWe are seeking a Senior Software Engineer who will:\nPartner with various teams (ie, Product Manager, Data Science, Platform Strategy, Technology) on requirement gathering in order to deliver analytics solutions that generate business value\n\nPerform data preparation by ingestion, aggregation, processing to drive and enable relevant insights from available data sets\n\nIdentify and code the best suited data algorithm model for the relevant insights\n\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions\n\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements\n\nAll about You\n\nStrong SQL knowledge for data preparation and mining\nStrong knowledge of writing data/machine learning algorithm in Python or R\nExperience in doing data analysis and extraction on Hadoop\nExperience of working on at least one reporting tool - Tableau and PowerBI is a plus\nExperience in data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies\nStrong understanding of the application of analytical methods and data visualization to support business decisions\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group\n",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Data modeling', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:19:29
Supply Chain Specialist Staff,Juniper Networks,10 - 15 years,Not Disclosed,['Bengaluru'],".\nPosition : Supply Planner\nLocation: Bangalore\nExperience: 10+ years\nJob description\nIn this role, We are looking for a proactive and analytical Supply & Inventory Planner with a strong foundation in data analysis and exposure to AI/ML . This hybrid role ensures supply continuity, optimal inventory levels, and improved forecast accuracy through a mix of traditional planning and next-gen analytics. The ideal candidate brings a blend of operational planning expertise, a data-savvy mindset, and a passion for using emerging technologies to transform supply chain performance.\nKey Responsibilities:\nSupply Planning:\nCreate and maintain short- and long-term supply plans based on demand forecasts, capacity, and lead time constraints.\nEnsure product availability by managing supply across multiple nodes (e.g., suppliers, factories, distribution centers).\nCollaborate cross-functionally with Demand Planning, Procurement, Manufacturing, Logistics , and commercial teams.\nMonitor supplier performance and track on-time delivery, lead times, and shortages to inform planning decisions.\nUse scenario modeling and simulations to assess plan sensitivity and enable rapid decision-making.\nParticipate in S&OP and IBP processes , contributing insights and aligning operational plans with business strategy.\nInventory Planning:\nOptimize inventory levels, Safety Stock targets and mix across the network to meet service targets while minimizing excess and obsolescence.\nPerform inventory health reviews , flag aging or slow-moving stock, and collaborate with stakeholders to reduce working capital.\nLead E&O forecasting and contribute to proactive mitigation plans.\nPartner with finance, operations, and commercial teams to align inventory with business goals and budget constraints.\nBuild inventory projection models to assess future inventory trends based on current supply/demand dynamics.\nAnalytics & AI/ML Enablement:\nUse tools such as Excel, SQL, Python, Power BI, Tableau for reporting, diagnostics, and automation.\nLeverage AI/ML models for demand sensing, inventory optimization, and supply risk prediction .\nCollaborate with data science and engineering teams to translate business needs into modeling requirements.\nChampion digital transformation by identifying manual processes that can be automated or enhanced using intelligent solutions.\nRequirements\nBachelor s degree in Supply Chain, Engineering, Business, or related discipline (Master s a plus).\n10 years of experience in supply planning, demand planning, or end-to-end supply chain roles.\nStrong expertise in planning systems (e.g., SAP, Kinaxis, Oracle, O9) and advanced Excel or data analysis tools.\nProven ability to lead cross-functional projects and influence without authority.\nDetail oriented, Strategic thinker with a hands-on mindset, comfortable navigating ambiguity and fast-changing environments.\nStrong communication skills, with the ability to tailor messaging to technical teams and senior leaders.\nExperience in inventory optimization, scenario planning, and supplier collaboration is a strong plus.",Industry Type: IT Services & Consulting,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Procurement', 'Supply chain', 'Automation', 'Data analysis', 'SAP', 'Networking', 'Oracle', 'Analytics', 'SQL', 'Python']",2025-06-12 14:19:31
Senior Software Engineer,Mastercard,5 - 8 years,Not Disclosed,['Pune'],"Senior Software Engineer\n?\n\n\n\n\nThe AI & DPE team is responsible for product management and innovative product development of products and services to address the evolving risk and security needs of all of Mastercard s various customer segments. Platform Services team in AI & DPE focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services across AI & DPE and drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven cyber products, services and actionable insights.\n\nThe Role:\nWe are seeking a Senior Software Engineer who will:\n\nPerform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\nPartner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\nIdentify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\nIntegrate & Unify new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\nAnalyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nMinimum 5-8 years of relevant experience.\nGood understanding of programming language preferably PySpark and Big Data technologies.\nExperience with Enterprise Business Intelligence Platform/Data platform.\nStrong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\nExperience with data integration tools - ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Databricks)\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\nStrong understanding of the application of analytical methods and data visualization to support business decisions.\nAbility to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Operations', 'Analytics', 'SQL']",2025-06-12 14:19:33
Lead Quantitative Analytics Specialist ALM Modeling,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"Lead Quantitative Analytics Specialist ALM Modeling Balance sheet modeling IRRBB EVE FTP Deposit models Liquidity Risk models-\nCorporate Risk helps Wells Fargo businesses identify and manage risk. The team focuses on three key risk areas: credit risk, operational risk and market risk. As the company's second line of defense, Corporate Risk or Independent Risk Management provides independent oversight of risk-taking activities. Independent Risk Management establishes and maintains Wells Fargo's risk management program and provides oversight, including challenges to and independent assessment of the frontline's execution of its risk management responsibilities. Corporate Risk roles depend on a variety of skills, viz. data analysis and synthesis, root cause analysis, change management, process management & execution, risk governance, risk strategy, risk identification & assessment, risk prevention, controls & mitigation, risk monitoring, reporting & escalation, risk systems & technology.",,,,"['ALM Modeling', 'R', 'Basel', 'CECL', 'SAS', 'Risk Modeling', 'CCAR models', 'Python']",2025-06-12 14:19:35
Abinitio Developer,Hexaware Technologies,6 - 9 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']",Experience - 6 years - 9 years\nLocation - Pune / Chennai / Mumbai / Bangalore\n\nStrong in-depth knowledge of databases and database concepts to support\nDesign/development of Datawarehouse/Datalake application\nAnalyze the business requirements and work with the business and data modeler to support dataflow from source to target destination,,,,"['Unix', 'DWH', 'Ab Initio', 'ETL', 'SQL']",2025-06-12 14:19:38
Senior Enterprise Operations Engineer,Mastercard,4 - 11 years,Not Disclosed,['Pune'],"Senior Enterprise Operations Engineer\nOverview\nThis position involves providing comprehensive support to internal teams through the delivery of detailed analysis, reports, and inventory insights. The role is integral to supporting various internal teams, with a specific focus on the Asia Pacific and LAC (Latin American) region.\nRole\nThe Operations Support Analyst is an individual contributor role requiring advanced expertise in the discipline. The analyst will lead several initiatives within the Operations Support team to support the Asia Pacific region.\nAssist team in supporting Operations Support activities: Collaborate with various internal teammjms to ensure smooth execution of operations support activities, providing guidance and expertise as needed.\nEngage in Post Incident Management, Problem Management, and Root Cause Analysis: Investigate incidents to identify their root causes and facilitate the resolution of underlying problems, ensuring continuous improvement in operational processes.\nProvide Daily Incident Review and Post-Incident Analysis: Conduct daily reviews of incidents and analyse post-incident data to derive actionable insights that inform strategic decision-making.\nDeliver Data Analysis and Custom-Made Reports: Generate and present tailored reports based on comprehensive data analysis, addressing specific needs and requirements of internal teams.\nPerform support functions for internal teams within the Operations & Technology team: Offer operational support to various internal teams, facilitating the seamless integration and implementation of technology solutions.\nResponsibilities\nPost Incident Management, Problem Management, and Root Cause Analysis: Lead efforts to manage incidents and problems effectively, employing root cause analysis techniques to prevent future occurrences.\nConduct Daily Incident Review and Post-Incident Analysis: Systematically review incidents daily and perform thorough post-incident analyses to enhance operational efficiency.\nExecute Data Analysis and deliver Custom-Made Reports: Perform in-depth data analysis and produce customized reports that cater to the specific needs of internal stakeholders.\nEnsure regional coverage and support for the Asia Pacific region and LAC region: Provide comprehensive support to the Asia Pacific/LAC region, ensuring that all operations support activities are effectively managed and executed.\nAll about you\nWe are seeking a dedicated IT Specialist with comprehensive experience in IT projects, particularly in networking, security technologies, and data analysis. The ideal candidate will have a strong background in Cisco, Splunk, and Netscout products, and possess knowledge of network diagnostics and various network technologies.\nQualifications\nIT experience, including full-time involvement in IT projects\nNetworking experience, including LAN/WAN, wireless, and security technologies\nKnowledge of Cisco, Splunk, Netscout, and other relevant technology product portfolios\nKnowledge of network diagnostics, PfR, BGP, SNMP, IPVPN, SSH, MPLS technologies\nBasic knowledge of Data Center standards\nProficiency in Excel, with the ability to create reports using macros preferred\nCCNA or equivalent certification preferred\nTeam Overview\nThe primary role of the AP-OS team is to deliver operational support to internal teams by analysing incidents, conducting both post-incident and recurring incident analyses, managing problems, and providing regular summary reports with detailed analysis on incident and network performance. Additionally, the team produces ad hoc reports tailored to the requirements of various internal teams.",Industry Type: Financial Services,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Wireless', 'Data analysis', 'WAN', 'Information security', 'LAN', 'Incident management', 'CCNA', 'Continuous improvement', 'Macros', 'cisco']",2025-06-12 14:19:40
Senior Software Quality Engineer,Mastercard,4 - 9 years,Not Disclosed,['Pune'],"Senior Software Quality Engineer\n?\n\nMastercard is a global technology company in the payments industry. We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\n\n\n\nOverview:\n\nTransfer Solutions is responsible for driving Mastercard s expansion into new payment flows such as Disbursements & Remittances. The team is working on creating a market-leading money transfer proposition, Mastercard Move, to power the next generation of payments between people and businesses, whether money is moving domestically or across borders, by delivering the ability to pay and get paid with choice, transparency, and flexibility.\n\nThe Product & Engineering teams within Transfer Solutions are responsible for designing, developing, launching, and maintaining products and services designed to capture these flows from a wide range of customer segments. By addressing customer pain points for domestic and cross-border transfers, the goal is to scale Mastercard s Disbursements & Remittances business, trebling volume over the next 4 years.\n\nThe Role:\narticipate in requirements discussion, test planning, test data creation and execution of testing Plan in adherence with MasterCard standards, processes and best practices.\nWork with project teams to meet scheduled due dates, while identifying emerging issues and recommending solutions for problems and independently perform assigned tasks.\nDesign and develop test automation frameworks to validate system to system interfaces and complete software solutions (for Database/ETL, API and UI tests)\nInteract with business and development stakeholders to define test plans and schedules\nTranslate complex system requirements into test requirements and testing methods\nIdentify and implement complex automation efforts, including refactoring of automation code where needed\nDevelop test scripts and perform automated and manual exploratory testing to ensure software meets business and security requirements and established practices.\nDesign and develop test data management for defined test cases, recognize test environment preparation needs, and execute existing test plans and report results\nOwn responsibility for defect management and oversight and escalation of issues discovered during the testing phase\nDocument as per Software Development Best Practices and follow MasterCard Quality Assurance and Quality Control processes.\nDocument performance test strategies and test plans, and execute performance validation\nCollect quality metric data and communicate test status/risks to stakeholders\nAct as first-review for project-level reviews, walkthroughs and inspections\nProvide technical support and mentoring to junior team members\nPerform demos of new product functionality to stakeholders\nDevelop business and product knowledge over time.\nIdentify opportunities to improve effectiveness and time-to-market\nProvide training and guidance to team members on quality best practices and principles\nFacilitate knowledge sharing sessions to promote a culture of quality awareness\nBe a strong individual contributor to the implementation efforts of product solutions\n\nAll About You:\n\nBachelors degree in Information Technology, Computer Science or Management Information Systems or equivalent work experience\n8+ years of experience in the Software Engineering with a focus on Quality Engineering methodologies\nTechnical skills in Java, Selenium, Cucumber, Soap UI, Spring framework, REST, JSON, Eclipse, GIT, Jmeter/Blazemeter\nExcellent SQL skills to work on large and complex data sources and capability of comprehending and writing complex queries\nExperience testing APIs (REST and SOAP), web user interface, and/or reports\nExperience in implementing CI/CD build pipelines with tools like Git/Bit Bucket, Jenkins and Maven\nSuccessfully validated one or more application codebases via automation, for new feature functionality and regression testing\nExperience working in Agile teams and conversant with Agile/SAFe tenets and ceremonies. Strong analytical and problem-solving abilities, with quick adaptation to new technologies, methodologies, and systems\nExcellent English communication skills (both written and verbal) to effectively interact with multiple technical teams and other stakeholders\nHigh-energy, detail-oriented and proactive, with ability to function under pressure in an independent environment along with a high degree of initiative and self-motivation to drive results\nEager to experiment with new team processes and innovate on testing approach\nPrior experience with Data Analysis and Data Engineering is a plus\nStrong collaboration skills and ability to work effectively in a cross-functional, interdependent team environment",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Maven', 'Manager Quality Assurance', 'Eclipse', 'Information security', 'Agile', 'JSON', 'Selenium', 'Information technology', 'Technical support', 'SQL']",2025-06-12 14:19:42
Senior Enterprise Operations Engineer,Dynamic Yield,2 - 7 years,Not Disclosed,['Pune'],"Our Purpose\nTitle and Summary\nSenior Enterprise Operations Engineer\nOverview\nThis position involves providing comprehensive support to internal teams through the delivery of detailed analysis, reports, and inventory insights. The role is integral to supporting various internal teams, with a specific focus on the Asia Pacific and LAC (Latin American) region.\nRole\nThe Operations Support Analyst is an individual contributor role requiring advanced expertise in the discipline. The analyst will lead several initiatives within the Operations Support team to support the Asia Pacific region.\nAssist team in supporting Operations Support activities: Collaborate with various internal teammjms to ensure smooth execution of operations support activities, providing guidance and expertise as needed.\nEngage in Post Incident Management, Problem Management, and Root Cause Analysis: Investigate incidents to identify their root causes and facilitate the resolution of underlying problems, ensuring continuous improvement in operational processes.\nProvide Daily Incident Review and Post-Incident Analysis: Conduct daily reviews of incidents and analyse post-incident data to derive actionable insights that inform strategic decision-making.\nDeliver Data Analysis and Custom-Made Reports: Generate and present tailored reports based on comprehensive data analysis, addressing specific needs and requirements of internal teams.\nPerform support functions for internal teams within the Operations & Technology team: Offer operational support to various internal teams, facilitating the seamless integration and implementation of technology solutions.\nResponsibilities\nPost Incident Management, Problem Management, and Root Cause Analysis: Lead efforts to manage incidents and problems effectively, employing root cause analysis techniques to prevent future occurrences.\nConduct Daily Incident Review and Post-Incident Analysis: Systematically review incidents daily and perform thorough post-incident analyses to enhance operational efficiency.\nExecute Data Analysis and deliver Custom-Made Reports: Perform in-depth data analysis and produce customized reports that cater to the specific needs of internal stakeholders.\nEnsure regional coverage and support for the Asia Pacific region and LAC region: Provide comprehensive support to the Asia Pacific/LAC region, ensuring that all operations support activities are effectively managed and executed.\nAll about you\nWe are seeking a dedicated IT Specialist with comprehensive experience in IT projects, particularly in networking, security technologies, and data analysis. The ideal candidate will have a strong background in Cisco, Splunk, and Netscout products, and possess knowledge of network diagnostics and various network technologies.\nQualifications\nIT experience, including full-time involvement in IT projects\nNetworking experience, including LAN/WAN, wireless, and security technologies\nKnowledge of Cisco, Splunk, Netscout, and other relevant technology product portfolios\nKnowledge of network diagnostics, PfR, BGP, SNMP, IPVPN, SSH, MPLS technologies\nBasic knowledge of Data Center standards\nProficiency in Excel, with the ability to create reports using macros preferred\nCCNA or equivalent certification preferred\nTeam Overview\nThe primary role of the AP-OS team is to deliver operational support to internal teams by analysing incidents, conducting both post-incident and recurring incident analyses, managing problems, and providing regular summary reports with detailed analysis on incident and network performance. Additionally, the team produces ad hoc reports tailored to the requirements of various internal teams.",Industry Type: Software Product,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Wireless', 'Data analysis', 'WAN', 'Information security', 'LAN', 'Incident management', 'CCNA', 'Continuous improvement', 'Macros', 'cisco']",2025-06-12 14:19:44
Officer - MIS,Relaxo,2 - 7 years,4-7.5 Lacs P.A.,['Delhi / NCR'],"Officer-MIS\nFunction:\n\nSales & Marketing\n\nWork Location:\n\nDelhi HO\nCompensation:\n\n3.0 Lacs to 7.0 Lacs\n\nExperience in years:\n\n3-8\nReporting to:\n\nAVP-New Channel\n\nNumber of Employees Reporting to Position and Designations:\n\nNil\nAmount of travel required:\n\nNil\n\nWork-Level:\n\nOfficer/ Senior Officer(O1-O2)\nAcademic/Trade Qualifications\nEssential:\n\nAny Graduation\nDesirable:\n\nMBA\nTechnical/Functional Certifications Required:\n\nYes No\nIf Yes, please specify:\nPurpose of the Position (Job Summary)\nTo Report AVP New Channel and support by co-ordination and administering the sales information system. To Prepare daily, weekly, monthly sales related MIS reports including Daily sales tracking/ forecasting report, market share analysis, gross margin analysis by market. Provide all other administration services for the regional sales department and staff. Make a positive contribution to Sales Department.\nKey Roles and Responsibilities\nBusiness\n\nPrepare and Produce daily, weekly, monthly sales reports for Sales team, within required deadlines.\nGeneration MIS and Sales reports through SAP System and SAP (BI).\nCreate power point presentations as per business requirements\nManaging in various office utilities and other administrative work of the Regional Office.\nFinancial\n\nTracking and clearance all Utilitie bills etc.\nCoordinate with sales teams for daily orders, collections, UTR No and submission of scheme documents.\nCustomer Oriented\n\nManaging Distributor Relationship, handling their grievances.\nAssist Sales Team in providing all relevant data / MIS support.\nPeople Oriented\n\nManaging internal & external stakeholders basis business needs\nCompetencies\nTechnical/Functional\n\nBehavioral\n1.Advanced Microsoft Office (especially Excel spreadsheets)\n2.SAP System and SAP (BI)\n3.Decent communication skills (English - Written & Spoken)\n\n1. Organized, analytical and methodical approach\n2. Self-motivated\n3. Team player\n4. Ability to communicate to staff of all levels\nPerformance Measures\nQuantitative\n\nQualitative\n1. Sales Reporting & Analysis\n2. Cost reduction & Maintenance (Cleaning, supply, etc.)\n3. Coordination with distributors and vendors\n\n1. Accuracy to Data\n2. Taking care of House Keeping\n3. Infrastructure Management\nKey Stakeholder Management\nInternal\n\nExternal\nGM, AGM, Sr. Manager, KAMs, SO/SR, HO-MIS\n\nDistributors/Retailers/Venders",Industry Type: Textile & Apparel (Fashion),"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Sales MIS', 'MIS', 'Management Information System', 'MIS Operations', 'VLOOKUP', 'Advanced Excel', 'Excel Report Preparation']",2025-06-12 14:19:46
HR Business Partner Sales,Condor Footwear,10 - 20 years,Not Disclosed,['Surat( Sachin )'],"Role & responsibilities\nPosition Overview:\n\nThe HR Business Partner for Sales at Condor Footwear India Limited plays a critical role in aligning business objectives with employees and management in the sales department. This position is responsible for implementing HR strategies and initiatives that support the overall growth of the sales team and enhance employee engagement and performance.\nKey Responsibilities:\n1. Strategic HR Partnership:\n- Collaborate with sales leadership to understand business goals and challenges.\n- Participate in developing and executing HR strategies that support sales objectives.\n2. Talent Management:\n- Oversee recruitment efforts for sales roles, ensuring the selection of high-quality candidates.\n- Conduct workforce planning and succession planning activities to develop sales talent.\n3. Performance Management:\n- Support the performance appraisal process, providing guidance to managers on evaluation and feedback.\n- Implement performance improvement plans for underperforming employees.\n4. Employee Engagement:\n- Foster a positive work environment by promoting employee engagement initiatives.\n- Conduct employee surveys and analyze feedback to identify areas for improvement.\n5. Training and Development:\n- Identify training needs for the sales team and coordinate training programs to enhance skills.\n- Support career development programs to nurture talent within the sales department.\n6. Policy Implementation:\n- Ensure compliance with company policies and labor laws within the sales function.\n- Communicate HR policies and support managers in understanding and applying these policies effectively.\n7. Employee Relations:\n- Act as a point of contact for employee concerns within the sales team, addressing issues promptly and fairly.\n- Mediate conflicts and promote effective resolution strategies.\n8. Data Analysis and Reporting:\n- Analyze HR metrics related to the sales workforce to inform decision-making.\n- Prepare reports for management on HR initiatives and their impact on sales performance.\nQualifications:\n- Bachelors degree in Human Resources, Business Administration, or related field (Masters preferred).\n- 8+ years of HR experience, with a focus on sales or commercial environments.\n- Strong interpersonal and communication skills.\n- Proven capability in talent management, employee engagement, and conflict resolution.\n- Familiarity with HR software and data analytics tools.\nSkills:\n- Strong business acumen with the ability to align HR strategies to business needs.\n- Excellent organizational and project management skills.\n- Ability to work collaboratively with diverse teams and drive change.\n\n\nPreferred candidate profile",Industry Type: Textile & Apparel,Department: Human Resources,"Employment Type: Full Time, Permanent","['HRBP', 'Business Partnering', 'Sales HR', 'Performance Management System', 'Strategic HR', 'Competency Mapping', 'Corporate HR', 'HR Strategy', 'Business HR', 'Talent Management']",2025-06-12 14:19:48
Business System Specialist,Global Payments,4 - 9 years,Not Disclosed,['Pune'],".\nSummary of This Role\nWorks throughout the software development life cycle and performs in a utility capacity to create, design, code, debug, maintain, test, implement and validate applications with a broad understanding of a variety of languages and architectures. Analyzes existing applications or formulate logic for new applications, procedures, flowcharting, coding and debugging programs. Maintains and utilizes application and programming documents in the development of code. Recommends changes in development, maintenance and system standards. Creates appropriate deliverables and develops application implementation plans throughout the life cycle in a flexible development environment.\nWhat Part Will You Play?\nDevelops basic to moderately complex code using front and / or back end programming languages within multiple platforms as needed in collaboration with business and technology teams for internal and external client software solutions. Designs, creates, and delivers routine to moderately complex program specifications for code development and support on multiple projects/issues with a wide understanding of the application / database to better align interactions and technologies.\nAnalyzes, modifies, and develops moderately complex code/unit testing in order to develop concise application documentation. Performs testing and validation requirements for moderately complex code changes. Performs corrective measures for moderately complex code deficiencies and escalates alternative proposals.\nParticipates in client facing meetings, joint venture discussions, vendor partnership teams to determine solution approaches.\nProvides support to leadership for the design, development and enforcement of business / infrastructure application standards to include associated controls, procedures and monitoring to ensure compliance and accuracy of data. Applies a full understanding of procedures, methodology and application standards to include Payment Card Industry (PCI) security compliance.\nConducts and provides basic billable hours and resource estimates on initiatives, projects and issues.\nAssists with on-the-job training and provides guidance to other software engineers.\nWhat Are We Looking For in This Role? Minimum Qualifications\nBS in Computer Science, Information Technology, Business / Management Information Systems or related field\nTypically minimum of 4 years - Professional Experience In Coding, Designing, Developing And Analyzing Data. Typically has an advanced knowledge and use of one or more front / back end languages / technologies and a moderate understanding of the other corresponding end language / technology from the following but not limited to; t wo or more modern programming languages used in the enterprise, e xperience working with various APIs, external Services, e xperience with both relational and NoSQL Databases.\nPreferred Qualifications\nBS in Computer Science, Information Technology, Business / Management Information Systems or related field\n6+ years professional Experience In Coding, Designing, Developing And Analyzing Data and experience with IBM Rational Tools\nWhat Are Our Desired Skills and Capabilities?\nSkills / Knowledge - A seasoned, experienced professional with a full understanding of area of specialization; resolves a wide range of issues in creative ways. This job is the fully qualified, career-oriented, journey-level position.\nJob Complexity - Works on problems of diverse scope where analysis of data requires evaluation of identifiable factors. Demonstrates good judgment in selecting methods and techniques for obtaining solutions. Networks with senior internal and external personnel in own area of expertise.\nSupervision - Normally receives little instruction on day-to-day work, general instructions on new assignments.\n\nOperating Systems:\nLinux distributions including one or more for the following: Ubuntu, CentOS/RHEL, Amazon Linux\nMicrosoft Windows\nz/OS\nTandem/HP-Nonstop\nDatabase - Design, familiarity with DDL and DML for one or more of the following databases Oracle, MySQL, MS SQL Server, IMS, DB2, Hadoop\nBack-end technologies - Java, Python, .NET, Ruby, Mainframe COBOL, Mainframe Assembler\nFront-end technologies - HTML, JavaScript, jQuery, CICS\nWeb Frameworks - Web technologies like Node.js, React.js, Angular, Redux\nDevelopment Tools - Eclipse, Visual Studio, Webpack, Babel, Gulp\nMobile Development - iOS, Android\nMachine Learning - Python, R, Matlab, Tensorflow, DMTK\n.",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['redux', 'dml', 'unit testing', 'ios', 'jquery', 'coding', 'software development life cycle', 'react.js', 'tensorflow', 'java', 'webpack', 'design', 'debugging', 'mysql', 'matlab', 'mainframes', 'python', 'data analysis', 'oracle', 'ubuntu', 'rhel', 'javascript', 'sql server', 'nosql', 'angular', 'r', 'babel', '.net', 'centos']",2025-06-12 14:19:51
Senior Executive / Manager - Ecommerce Operations,Zebronics,4 - 6 years,Not Disclosed,['Chennai'],"Overview\nWe are looking for a dynamic and detail-oriented Senior Executive / Manager E-commerce Operations to join our growing E-commerce team.\n\n\nRequired Skills\nE-commerce operations, Order management, Marketplace coordination, Inventory management, Listing management, Pricing control, Return and refund handling, Dispatch coordination, Data analysis, Excel proficiency, Vendor communication, Logistics coordination, SLA management, Problem-solving, Team coordination\n\n\nDetailed Description\nJob Summary:\nWe are seeking a highly driven and detail-oriented Senior Executive / Manager E-commerce Operations to join our fast-growing team at Zebronics. The ideal candidate will be responsible for handling the day-to-day operations across various e-commerce and quick commerce platforms. This includes order processing, inventory coordination, returns, and ensuring seamless backend execution to support our online sales.\nKey Responsibilities:\nManage end-to-end order processing for online marketplaces (Amazon, Flipkart, Zepto, Blinkit, etc.)\nCoordinate with internal warehouse and logistics teams for timely dispatches\nMonitor and update product listings, stock availability, pricing, and offers\nResolve operational issues such as order delays, return disputes, and escalations\nMaintain accurate reporting for returns, sales performance, and stock reconciliation\nCollaborate with marketplace account managers and internal stakeholders\nDrive process improvement and operational efficiency\nEnsure adherence to platform SLAs and compliance standards\nKey Skills Required:\nE-commerce operations, Order management, Marketplace coordination, Inventory management, Listing management, Pricing control, Return and refund handling, Dispatch coordination, Data analysis, Excel proficiency, Vendor communication, Logistics coordination, SLA management, Problem-solving, Team coordination, Quick commerce platforms, Hindi communication, Attention to detail, Process improvement, Platform compliance\nRequirements:\nBachelor's degree or above (preferred in Business, Supply Chain, or related field)\n4 to 6 years of experience in e-commerce or supply chain operations\nStrong working knowledge of e-commerce platforms (Amazon, Flipkart, Blinkit, Zepto, etc.)\nExcellent communication and coordination skills\nProficiency in MS Excel and reporting tools\nFluency in Hindi is mandatory\nFemale candidates are preferred .",Industry Type: Consumer Electronics & Appliances,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Ecommerce Operations', 'Order management', 'supply chain operations', 'Data analysis', 'Logistics coordination', 'Excel', 'Pricing control', 'Listing management', 'Inventory management', 'Dispatch coordination', 'Marketplace coordination', 'SLA management']",2025-06-12 14:19:53
Product Specialist,MNC,5 - 10 years,5.5-12 Lacs P.A.,"['Mumbai', 'Gurugram', 'Bengaluru']",Customer research for insights and pain points\nMarket analysis to identify trends and opportunities\nData analysis to support product decisions\nProduct design and pilot execution\nCross-functional strategic planning,Industry Type: Automobile (Automobile Dealers),Department: Product Management,"Employment Type: Full Time, Permanent","['Product Specialist', 'Markert research', 'Innovation', 'Product Design', 'Data Analysis', 'Strategic Planning', 'Performance Monitoring']",2025-06-12 14:19:55
Performance Marketing/Customer Success | Shiksha.com | Bangalore,Info Edge,3 - 6 years,Not Disclosed,['Bengaluru'],Role & Responsibilities\nPost-Sale Campaign Management of top clients to reach pre-defined delivery & performance commitment\nRegular monitoring of delivery from campaigns and strategizing/planning activities to meet delivery gaps\nAnalyzing & preparing regular reports w.r.t delivery performance from various products/sources,,,,"['Performance Marketing', 'Client Success', 'customer success', 'Digital Campaigns', 'Campaign Execution', 'Marketing Analytics', 'Digital Analytics', 'client marketing', 'Client Servicing', 'Campaign Analytics', 'Data Analysis', 'Client Engagement', 'Campaign Management', 'Data Analytics']",2025-06-12 14:19:58
Business Development Manager (Hotels - Bangalore/Hyderabad/Chennai),Easemytrip,2 - 7 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","About the Role:\nThe Business Development Manager (Hotels - Bangalore) will play a crucial role in establishing and maintaining robust partnerships with hotels in the Bangalore region. This role involves strategic negotiations, active market analysis, and engagement with hotel partners to ensure competitive pricing, optimal availability, and excellent service standards.\n\nRole & responsibilities:\nStrategic Partner Acquisition: Proactively identify and engage potential hotel partners, expanding our network in the region.\nContract Negotiation: Skillfully negotiate terms and conditions with both new and existing hotel partners to secure advantageous agreements.\nPerformance Optimization: Monitor and enhance partner performance through regular analysis and strategic advice.\nMarket and Competitive Analysis: Keep abreast of market trends and competitor strategies to inform and adjust our approach.\nStakeholder Communication: Ensure effective communication with both internal teams and external partners to align strategies and expectations.\nPartner Training and Support: Provide ongoing training and support to hotel partners, ensuring they are proficient in using our platform and tools.\nQuality Control: Maintain high standards of partner compliance with our service quality and guest experience expectations.\nRegular Visits and Relationship Building: Conduct regular visits to partner hotels to strengthen relationships and gather insights.\nRevenue Growth Strategies: Develop and implement strategies aimed at maximizing revenue for both the partners and EaseMyTrip.com.\nPerformance Reporting: Generate detailed reports and provide constructive feedback to partners based on performance metrics.\n\nPreferred candidate profile:\nEducational Background: Masters degree in Business Administration or a related field from a recognized institution.\nProfessional Experience: 3-5 years of relevant experience in hotel contracting, business development, or B2B sales in the travel and hospitality industry.\nSector Expertise: Comprehensive understanding of the hotel and travel industry, particularly in the Bangalore market.\nNegotiation Proficiency: Exceptional negotiation skills with a successful track record in deal-making.\nAnalytical Skills: Strong capability in data analysis and decision-making based on market insights.\nCommunication and Interpersonal Skills: Outstanding communication skills for effective partnership management.\nProblem-Solving: Quick and effective problem-solving with innovative solutions.\nTech Savviness: Proficiency in MS Excel and CRM systems to manage data and relationships efficiently.\nTeam Collaboration: Proven ability to collaborate within a team to meet collective goals.\nAdaptability: Flexibility to adapt strategies in dynamic market conditions.",Industry Type: Travel & Tourism,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Negotiation', 'Hotel Contracting', 'Negotiation Skills', 'Revenue Management', 'Onboarding', 'Hospitality', 'Performance Metrics', 'Contract Management', 'Sales Strategy', 'Partnerships', 'Alliances', 'Contract Negotiations', 'Tourism', 'Hotel Accounts', 'Market Analysis', 'Stakeholder Management', 'CRM']",2025-06-12 14:20:00
Job Opportunity For Trainee/Jr.Engineer/Asst.Engineer/Engineer/Sr.Eng,Foxconn,2 - 4 years,Not Disclosed,['Chennai'],"Job description\n\nWe are thrilled to announce the foxconn Hon Hai Technology India Mega Development Private Limited Is Hiring For a Variety Positions across different functions and levels at Our TN Location\n\nLocation: Foxconn Hon Hai Technology India Mega Development Pvt Ltd (6th Gate)\nSipcot Hi-Tech Sez, Sipcot Industrial Park, Phase-II Chennai-Bangalore National Highway(NH-4) Suguvarchatiram, Sriperumbadur",,,,"['Procurement Executive', 'Security Auditor', 'Cctv Monitoring', 'CCTV Technician & Operator', 'Security Officer']",2025-06-12 14:20:03
Business Intelligence Lead,Trantor,8 - 10 years,Not Disclosed,[],"We are seeking a highly skilled Lead BI Developer with deep expertise in Tableau and Business\nIntelligence solutions to join our growing team. In this role, you will design and develop end-to-end BI solutions that empower data-driven decisions across the organization. You will collaborate closely with cross-functional teams, manage complex BI environments, and ensure seamless data visualization and reporting.\n1. Key Responsibilities\n\nBI Development & Data Visualization",,,,"['Business Intelligence', 'Tableau', 'ETL', 'Domo', 'SQL', 'Data Visualization']",2025-06-12 14:20:05
Senior Product Manager- Bangalore,Alice Blue Financial Services,6 - 10 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\n\nResponsibilities:\n• Define, understand, and identify key success metrics.\n• Develop insights on customer segments, personas, and pain points to refine GTM strategies\nand ensure product-market fit.\n• Track and analyze performance and constantly identify improvements to drive maximum\nusage and achieve business objectives.",,,,"['Product Strategy', 'Api Integration', 'Product Life Cycle Management', 'Go-to-market Strategy', 'Product Roadmap', 'User Research']",2025-06-12 14:20:07
Senior Software Engineer,Xoom,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Summary\nWhat you need to know about the role\nAs a Software Engineer in our Risk department, you will play a critical role in developing and maintaining cutting-edge risk detection and prevention systems that protect PayPals users and merchants from financial loss. You will work closely with cross-functional teams to design, build, and deploy scalable and efficient solutions that leverage machine learning, data analytics, and automation to identify and mitigate potential risks, ensuring the integrity of our platform and driving business growth.\n\nMeet our team\nAs an engineer in Global Fraud Risk - Automation team, You will work closely with data scientists, engineering, and analytical teams, understand the requirements and drive full development lifecycle of the teams products, transforming research work to real products. We are looking for strong technologists who are passionate about technology and able to continuously deliver state of the art software solutions in scalable way.\nJob Description\nYour way to impact\nAt PayPal, Backend Software Engineers are the architects of our global payment platform. Youll design, develop, and optimize core systems that power millions of transactions daily, directly impacting our customers experiences and our companys success.\nYour day-to-day\nAs a Senior Software Engineer - Backend, youll design and implement backend solutions. Youll collaborate with cross-functional teams to deliver high-quality products.\nDesign and develop scalable backend systems.\nOptimize system performance and reliability.\nMentor junior engineers.\nWhat do you need to bring\nBachelors degree in Computer Science or related field.\n3-5 years of backend development experience.\nProficiency in at least one backend language (Python, Java, Ruby on Rails)\nAdvanced proficiency in backend development with either Java EE frameworks, including experience with Spring MVC, or Hibernate.\nExperience designing and implementing RESTful services, focusing on scalability and reliability, using Java.\nProven ability to mentor junior engineers and contribute to code reviews and design discussions.\nExperience with cloud platforms (AWS, GCP, Azure)\nExperience with databases (SQL, NoSQL)\nStrong understanding of database design, including SQL and NoSQL databases, and experience with ORM tools.\nPreferred Qualifications\nExperience with large-scale, high-performance systems.\nKnowledge of the payment processing industry and relevant regulations.\nExperience with cloud platforms (AWS, GCP, Azure).\nContributions to open-source projects .\n**We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please dont hesitate to apply.\nPreferred Qualification\nSubsidiary\nPayPal\nTravel Percent\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https//www.paypalbenefits.com .\nWho We Are\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. .\nBelonging at PayPal\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: Internet,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Hibernate', 'Automation', 'Backend', 'Database design', 'Analytical', 'Machine learning', 'Open source', 'SQL', 'Python']",2025-06-12 14:20:10
Sr. Executive- MSP Coordinator,Movin Express,5 - 10 years,5-8 Lacs P.A.,"['Bengaluru', 'Mumbai (All Areas)']","Job descriptionJOB ROLE & RESPONSIBILITIES:\n\nIdentify suitable MSPs for Last Mile and First Mile operations across the country.2. Monitors Existing Movin Service Providers (MSP) Maintains customer relationships to improve service and identify growth opportunities.3. Coordinates with departments to setup MSPs to monitor services on a daily basis.4. Audits MSP processes to ensure compliance and identify possible optimization.5. Implements safety procedures and policies with MSPs to provide a safe, proficient work environment.6. Implements New MSPs Initiates and performs training for MSP representatives to ensure UPS policies and procedures are communicated to the MSP.7. Works with the region functions to develop new MSP contracts, reporting templates, tools and service agreements.8. Coordinates day to day business, reports, BSC, Volume growth, Vehicle appearance.9. Creates strong contact with relevant MSPs to identify potential strategic MSPs.10. Negotiates with MSPs to represent the MOVIN position to get best service for best rates.11. Sets up Business Plan for relevant MSP businesses to support the MOVIN Business Planning process.12. Trains the MSP in using MOVIN Operations process to ensure consistency to MOVIN and customer systems.13. Trains the MSPs on MOVIN services and shares MOVIN methodology and best practices to lead the MSP to become an efficient strategic MOVIN partner who provides best service for best rates.14. Maintains quality control documents to maintain standards.15. Creates standard operating procedures for the training group to promote consistency and improve performance.16. Works with others throughout the district to troubleshoot system, operational, and service inefficiencies and create new processes that result in improved performance.17. Assists in monthly business plan reviews with MSPs to identify and address performance issues. Implements solution support of effective, practical plans to minimize cost/mile and maximize performance by meeting service commitments.18. Supervises and Develops Others Determines employees training needs to produce continuous development plans.19. Provides on-going feedback and support to improve performance. Conducts performance evaluations in a consistent, fair, and objective manner to encourage continuous performance improvement.20. Holds others accountable to established performance levels to achieve individual and group goals. Resolves individual and group performance issues in accordance with company's policies and procedures in a timely manner to motivate and foster teamwork.Educational Qualifications:\nBachelors Degree or equivalentRole & responsibilities\nPreferred candidate profile Role & responsibilities\n\n\nPreferred candidate profile\n\n\nPerks and benefits",Industry Type: Courier / Logistics (Logistics Tech),Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Transportation Operations', 'Last Mile', 'Vehicle Tracking', 'Route Planning', 'Gps Tracking', 'Fleet Operations', 'Tracking', 'Shipment Tracking', 'Data Analysis', 'Vendor Coordination', 'Logistics Operations']",2025-06-12 14:20:12
AI Test Lead,Naukri,8 - 13 years,20-32.5 Lacs P.A.,['Bengaluru'],"Role & responsibilities\nKey Responsibilities:\nAI Testing Strategy and Planning\nCollaborate with cross-functional teams to develop comprehensive AI testing strategies and plans for AI-powered applications.\nWork closely with product managers, data scientists, and developers to understand AI model requirements, use cases, and project goals.\nDefine the scope and objectives of AI testing efforts, including performance, accuracy, bias detection, and robustness of AI models. Test Execution for AI Models and Algorithms\nDesign, develop, and execute test cases for AI systems and models (including machine learning and deep learning algorithms).\nTest and validate AI solutions across various stages of the development lifecycle, including model training, testing, and deployment.\nEnsure that AI models meet business requirements and perform accurately under various real-world conditions.\nEvaluate the performance of AI models by assessing speed, efficiency, scalability, and resource utilization.\nPerform manual and automated testing on AI-based applications, platforms, and solutions.\nAI Model Accuracy and Validation\nTest AI models for accuracy, precision, recall, F1 score, and other performance metrics.\nEnsure AI models' fairness by conducting tests for potential bias in decisionmaking processes, especially in clinical or medical applications.\nValidate AI model predictions against real-world data, ensuring that results are consistent, reliable, and actionable. Also, need to look the test results from a business perspective and help evaluate the balance between risks and benefits.\nCollaboration and Knowledge Sharing\nWork with data scientists, AI engineers and Test Manager to improve testing methodologies and continuously optimize AI model testing processes.\nProvide feedback on AI models, pointing out any potential improvements in testing coverage or areas for model retraining.\nCommunicate findings, bugs, and issues related to AI models to technical teams, ensuring prompt resolution.\nHelp the team set up AI Testing standards, make informed decisions, and build knowledge across projects\nHelp the team in decision-making processes, such as whether to continue or stop investments based on testing results. Test Automation for AI Projects\nDevelop and implement automated testing scripts and frameworks specifically designed for AI applications.\nUtilize AI testing tools and frameworks (RAGAS etc.) to automate the validation of AI models and algorithms.\nIntegrate automated AI testing within continuous integration and continuous deployment (CI/CD) pipelines.\nCompliance and Regulatory Testing\nEnsure that AI applications comply with industry-specific regulations, especially in the pharma and healthcare sectors (e.g., FDA regulations, HIPAA compliance).\nVerify that all AI-driven processes adhere to ethical standards and data privacy laws.\nContinuous Improvement and Research\nStay up-to-date with the latest trends, tools, and techniques in AI testing and apply these advancements to optimize the testing process.\nParticipate in AI testing forums and workshops, contributing insights to improve best practices within the team. Reporting and Documentation\nDocument test results, methodologies, and issues clearly, providing insights into test coverage, risk analysis, and performance benchmarks.\nPrepare detailed reports for both technical and non-technical stakeholders, summarizing testing outcomes and potential risks associated with AI implementations.\nAssist in the creation and maintenance of knowledge-sharing platforms related to AI testing best practices.\nKey Skills and Qualifications:\nTechnical Expertise\nStrong knowledge of AI/ML testing methodologies and best practices.\nExperience with any AI development frameworks and libraries such as TensorFlow, Keras, PyTorch, scikit-learn, RAGAS and MLlib.\nExperience in testing tools and environments for AI-based systems (e.g., Jupyter Notebooks, Apache Spark, and DataRobot).\nExperience with performance testing tools like Grafana K6 and JMeter for AI solutions.\nKnowledge of Python (Must to have), R, JavaScript or other programming languages frequently used in AI/ML.\nKnowledge of cloud technologies like Microsoft Azure / AWS.\nUnderstanding of test automation frameworks and experience in tools like Cypress, Playwright and Pytest for automating AI tests. AI Model Evaluation\nSolid understanding of machine learning and deep learning models, including supervised and unsupervised learning techniques.\nFamiliarity with evaluating AI models on metrics such as accuracy, precision, recall, F1 score, confusion matrices, and AUC.\nAbility to identify and test for model biases, fairness, and ethical implications, especially in sensitive applications like healthcare and pharma. Analytical and Problem-Solving Skills\nStrong problem-solving abilities and keen attention to detail, with a systematic approach to diagnosing and resolving AI-related issues.\nAbility to perform root cause analysis of issues in AI algorithms and suggest actionable fixes.\nCollaboration and Communication\nExcellent teamwork and communication skills, with the ability to collaborate with cross-functional teams, including data scientists, engineers, and product managers.\nStrong verbal and written communication skills to convey technical information clearly and concisely to both technical and non-technical stakeholders.\nExperience\nMinimum of 8+ years experience in software testing, with at least 2 years focused on testing AI/ML models or AI-based applications.\nProven experience in testing AI/ML algorithms in production or staging environments.\nExperience in testing Visual AI Assistant Applications is good to have.\nExperience working in a regulated industry (such as pharmaceuticals or healthcare) is a plus.\nPreferred Qualifications:\nExperience with cloud platforms (e.g., AWS, Azure) for deploying AI applications and models. Certification in AWS/Azure will be good to have.\nFamiliarity with DevOps practices and integrating AI testing into CI/CD pipelines.\nCertification in AI/ML or related testing frameworks (e.g. ISTQB AI Tester)\nThis AI Tester role is a unique opportunity to shape the future of AI in the pharmaceutical industry. If youre passionate about AI, testing, and making a difference in healthcare, we encourage you to apply.\n\nPreferred candidate profile",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation Testing', 'AI/ ML', 'Python', 'Performance Testing', 'Automation Strategy', 'AI Framework', 'AI testing']",2025-06-12 14:20:14
Senior Project Manager with Scrum Master,Luxoft,8 - 10 years,Not Disclosed,['Bengaluru'],"Lead end-to-end project delivery for treasury initiatives, including planning, execution, monitoring, and closure, ensuring alignment with business objectives.\nManage the full project lifecycle using Agile (Scrum/Kanban) or Waterfall methodologies, depending on project requirements.\nFacilitate Scrum ceremonies (Sprint Planning, Daily Stand-ups, Sprint Reviews, and Retrospectives) and ensure effective collaboration among team members.\nDevelop and maintain detailed project plans, timelines, risk registers, and stakeholder management plans.\nConduct stakeholder analysis and maintain clear communication channels with senior management, business teams, technology teams, and external vendors.\nEnsure project scope, objectives, and deliverables are well-defined, documented, and agreed upon by stakeholders.\nProactively identify project risks, issues, and dependencies, and develop mitigation strategies.\nMonitor and manage project budgets, forecasts, and resource allocations.\nImplement change management best practices to ensure smooth transition and adoption of new solutions by end-users.\nPrepare and present project status reports, executive dashboards, and other communication materials to stakeholders.\nFoster a culture of continuous improvement by identifying and implementing process enhancements.\nCoach and mentor team members, ensuring adherence to best practices in project management and Agile principles.\nSkills\nMust have\nProven experience 8+ years as a Project Manager and Scrum Master, with experience in treasury or financial services domain.\nStrong understanding of treasury processes, including liquidity management, cash management, risk management, and regulatory compliance.\nProficiency in Agile (Scrum/Kanban) and Waterfall methodologies with hands-on experience in leading Scrum ceremonies and managing Agile teams.\nExcellent stakeholder management skills, with the ability to communicate effectively with senior executives, business teams, and technical teams.\nDemonstrated ability to manage complex, cross-functional projects with multiple stakeholders.\nStrong problem-solving skills with the ability to identify, analyze, and resolve issues in a fast-paced environment.\nProficiency in project management tools (JIRA, Confluence, MS Project, Trello, etc.) and Agile collaboration tools.\nSolid understanding of project financial management, including budgeting and forecasting.\nProfessional certifications such as PMP, CSM, or Agile Coach.\nExcellent written and verbal communication skills.\nNice to have\nExperience with treasury management systems (TMS) such as Murex, Calypso, Wallstreet Suite (WSS), or Kyriba.\nUnderstanding of regulatory frameworks impacting treasury operations (e.g., Basel III/IV, IFRS, local regulatory guidelines).\nPrior experience working in a large financial institution or global bank.\nExposure to DevOps practices and tools for continuous integration and deployment in treasury projects.\nKnowledge of cloud technologies (AWS, Azure, or Google Cloud) and their application in financial services.\nExperience in leading cross-regional teams in a distributed environment.\nAdvanced data analysis skills, including experience with BI tools (Power BI, Tableau) for treasury reporting.\nFamiliarity with Lean or Six Sigma methodologies for process optimization.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['PMP', 'Data analysis', 'Change management', 'Project management', 'calypso', 'Scrum', 'Risk management', 'JIRA', 'Monitoring', 'Six sigma']",2025-06-12 14:20:16
Senior Software Engineer - Python Developer,FactSet,5 - 10 years,Not Disclosed,['Hyderabad'],"FactSet creates flexible, open data and software solutions for over 200,000 investment professionals worldwide, providing instant access to financial data and analytics that investors use to make crucial decisions.\nAt FactSet, our values are the foundation of everything we do. They express how we act and operate , serve as a compass in our decision-making, and play a big role in how we treat each other, our clients, and our communities. We believe that the best ideas can come from anyone, anywhere, at any time, and that curiosity is the key to anticipating our clients needs and exceeding their expectations.",,,,"['Computer science', 'C++', 'Data analysis', 'GCP', 'Analytical', 'Machine learning', 'Technical leadership', 'Monitoring', 'SQL', 'Python']",2025-06-12 14:20:19
Python/Pyspark developer,Zensar,4 - 5 years,Not Disclosed,"['Pune', 'Bengaluru']","Job Description:\nWe are seeking a highly skilled and motivated Python/PySpark Developer to join our growing team. In this role, you will be responsible for designing, developing, and maintaining high-performance data processing pipelines using Python and the PySpark framework. You will work closely with data engineers, data scientists, and other stakeholders to deliver impactful data-driven solutions.\nResponsibilities:\n- Design, develop, and implement scalable and efficient data pipelines using PySpark.\n- Write clean, well-documented, and maintainable Python code.\n- Optimize data processing performance and resource utilization.\n- Implement ETL (Extract, Transform, Load) processes to migrate and transform data across various systems.\n- Collaborate with data scientists and analysts to understand data requirements and translate them into technical solutions.\n- Troubleshoot and debug data processing issues.\n- Stay up-to-date with the latest advancements in big data technologies and best practices.\nQualifications:\n- Bachelor's degree in Computer Science, Engineering, or a related field.\n- 3+ years of experience in Python development.\n- 2+ years of experience with PySpark and Spark ecosystem.\n- Strong understanding of data structures, algorithms, and object-oriented programming.\n- Experience with SQL and relational databases.\n- Familiarity with cloud platforms such as AWS, Azure, or GCP (preferred).\n- Excellent problem-solving and analytical skills.\n- Strong communication and teamwork skills.\nBonus Points:\n- Experience with data visualization tools (e.g., Tableau, Power BI).\n- Knowledge of machine learning and data science concepts.\n- Experience with containerization technologies (e.g., Docker, Kubernetes).\n- Contributions to open-source projects.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Cloud Technologies', 'SQL', 'Python']",2025-06-12 14:20:21
Senior Software Engineer,Dynamic Yield,5 - 8 years,Not Disclosed,['Pune'],"Our Purpose\nTitle and Summary\nSenior Software Engineer\nWho is Mastercard?\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOur Team:\n\nThe AI & DPE team is responsible for product management and innovative product development of products and services to address the evolving risk and security needs of all of Mastercard s various customer segments. Platform Services team in AI & DPE focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services across AI & DPE and drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven cyber products, services and actionable insights.\n\nThe Role:\nWe are seeking a Senior Software Engineer who will:\n\nPerform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\nPartner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\nIdentify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\nIntegrate & Unify new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\nAnalyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nMinimum 5-8 years of relevant experience.\nGood understanding of programming language preferably PySpark and Big Data technologies.\nExperience with Enterprise Business Intelligence Platform/Data platform.\nStrong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\nExperience with data integration tools - ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Databricks)\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\nStrong understanding of the application of analytical methods and data visualization to support business decisions.\nAbility to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Operations', 'Analytics', 'SQL']",2025-06-12 14:20:23
Oracle/ Informatica/ PLSQL/ ETL/ Snaplogic,Photon,5 - 10 years,Not Disclosed,"['Chennai', 'Bengaluru']","Job Description:\n\nRole: Orcale, Informatica, PLSQL, ETL\nLocation: Chennai/ Bangalore\nExperience: 5+ Years\nMust have: Orcale, Informatica, PLSQL, ETL\n\nLooking for a candidate with expertise on Oracle Database,  Snaplogic and Oracle PL/SQL with knowledge on AWS cloud.",,,,"['Snaplogic', 'PLSQL', 'Informatica', 'ETL', 'ORACE']",2025-06-12 14:20:26
Senior Generative AI Engineer - Python Programming,Zettamine Labs,7 - 8 years,Not Disclosed,['Bengaluru'],"We are looking for a Senior Generative AI Engineer who is passionate about cutting-edge AI innovation and has significant hands-on experience in building and deploying Generative AI models. In this role, you will be responsible for designing, fine-tuning, and optimizing large language models (LLMs), implementing innovative GenAI solutions, and contributing to the architecture of AI-driven platforms that deliver real business value.\n\nYou will collaborate with cross-functional teams including data scientists, machine learning engineers, product managers, and cloud infrastructure teams to build scalable, reliable, and secure AI systems. This is a high-impact position where you will directly influence the AI roadmap and innovation strategy.\n\nKey Responsibilities :\n\n- Design, develop, and fine-tune state-of-the-art Generative AI and LLM models tailored for various business use cases.\n\n- Build, integrate, and optimize solutions using transformer-based architectures (e.g., GPT, BERT, T5, LLaMA, Mistral).\n\n- Apply techniques such as fine-tuning, prompt engineering, RLHF (Reinforcement Learning from Human Feedback), and knowledge distillation to improve model performance.\n\n- Work with vector databases (e.g., FAISS, Pinecone, Weaviate) for implementing retrieval-augmented generation (RAG) pipelines.\n\n- Develop and deploy embedding models and integrate them into LLM pipelines.\n\n- Collaborate with engineering and product teams to deploy scalable AI systems using MLOps practices and CI/CD pipelines.\n\n- Leverage LangChain, Hugging Face Transformers, OpenAI APIs, and similar frameworks/tools to accelerate development.\n\n- Optimize model performance across different environments (cloud/on-premise).\n\n- Develop end-to-end pipelines, from data preprocessing to real-time inference and monitoring.\n\n- Ensure high standards of software quality, including testing, version control, code reviews, and documentation.\n\n- Stay up to date with the latest research in Generative AI and translate breakthroughs into production-ready solutions.\n\nRequired Skills & Qualifications :\n\n- Experience : 7+ years in AI/ML, data science, or software engineering; at least 3 - 4 years in Generative AI/LLMs.\n\n- Advanced Python programming skills, including familiarity with object-oriented design and software engineering best practices.\n\n- Deep expertise in PyTorch, TensorFlow, Transformers (Hugging Face), LangChain, and OpenAI or Anthropic APIs.\n\n- Experience in LLM fine-tuning, parameter-efficient tuning methods (LoRA, PEFT), RLHF, and model evaluation.\n\n- Experience with embeddings, vector stores (FAISS, Pinecone), semantic search, and RAG systems.\n\n- Hands-on experience with AWS, GCP, or Azure; knowledge of MLOps tools (SageMaker, Vertex AI, MLflow, Kubeflow) for training, deploying, and monitoring models.\n\n- Familiarity with structured/unstructured data handling and integrating AI systems with SQL/NoSQL databases.\n\n- Strong analytical thinking, problem-solving ability, and a keen interest in research and innovation.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Tensorflow', 'PyTorch', 'Generative AI', 'MLOps', 'NoSQL', 'ChatGPT', 'Artificial Intelligence', 'Data Modeling', 'LLM', 'Python', 'SQL']",2025-06-12 14:20:28
Senior System Testing QA Engineer - Enterprise Switching,Cisco,8 - 13 years,Not Disclosed,['Bengaluru'],"We are looking for a passionate and experienced System QA Engineer to join our Cisco Meraki team, passionate about testing our enterprise switching products. In this role, you will be responsible for validating the quality and adaptability of our switching platforms through comprehensive system-level testing. Your work will directly impact the stability, scalability, and performance of our networking solutions deployed in real-world customer environments.\nYou are an ideal candidate if you have:\n8+ years of experience in software or system quality assurance, with a strong focus on system-level testing of enterprise switches.\nHands-on experience crafting and driving solution tests, scale/stress tests, and performance tests that simulate realistic deployment and traffic conditions.\nDeep understanding and strong knowledge of standard Layer 2 and Layer 3 networking protocols, including but not limited to STP, RSTP, MSTP, VLAN, Link Aggregation (LAG), OSPF, BGP, VRRP, DHCP, and multicast, ipv4, ipv6, security features and other related technologies..\nAttention to detail, proven ability to build and maintain high-quality test plans that ensure end-to-end system validation and uncover edge cases early.\nStrong experience in debugging sophisticated system-level issues, analyzing test results, and collaborating closely with development and product teams.\nFamiliarity with Cisco Meraki or other enterprise-class switches, and confidence working in Cloud-based configuration environments.\nCisco Confidential\nProficiency in working with Linux systems and using command-line tools for test execution and log analysis.\nStrong proficiency in configuring and using traffic generators such as IXIA for performance, scale, RFC testing is required.\nA strong team player mindset, with a can-do attitude and a willingness to take ownership and jump in wherever needed.\nExcellent written and verbal communication skills.\nA Bachelors or Masters degree in Computer Science, Electrical Engineering, or a related technical field, or equivalent hands-on experience.\nBonus points for:\nScripting or automation experience using Python or Ruby for test setup, Orchestration, or data analysis.\nFamiliarity with CI/CD pipelines or automated test frameworks.\nFamiliarity with SIFOs and PoE related testing experience\nExperience with Cisco IOS, Catalyst Switch",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['System Testing', 'RFC testing', 'CI/CD', 'Cisco IOS', 'Quality Assurance', 'log analysis', 'Catalyst Switch']",2025-06-12 14:20:30
Sr Product Manager,Ennoventure Technologies,5 - 10 years,Not Disclosed,['Bengaluru'],"Job_Description"":""\nAt Ennoventure, we are redefining the fight against counterfeit goods with our groundbreaking technology. Backed by key investors like Fenice Investment Group and Tanglin Venture Partners, we are ready to embark on the next phase of our journey.\n\nOur aim? To build a world where authenticity reigns, ensuring every product and experience is genuine. Here, innovation moves fast, collaboration fuels success, and your growth isn\\u2019t just encouraged\\u2014it\\u2019s inevitable.\n\nAs a Lead Product Manager, you will drive exponential business growth by shaping product strategy, delivering exceptional user\nexperiences, and leading cross-functional collaboration. You will work closely with data science, engineering, design, and commercial teams to build scalable, cutting-edge products that deliver significant value to a global customer base.\n\n\nProduct Strategy & Vision\n- Define and evolve product strategy aligned with company goals and AI capabilities.\n- Translate AI advancements into differentiated product features with clear value for end-users.\n- Work with senior leadership to articulate product vision, business value, and a scalable roadmap.\n\nCustomer Discovery & Market Analysis\n- Conduct in-depth customer research to understand user pain points, workflows, and unmet needs.\n- Analyze competitive landscape, market trends, and regulatory considerations in AI SaaS.\n\nRoadmap Ownership\n- Define product requirements and maintain a clear, prioritized roadmap.\n- Lead the product lifecycle from ideation to delivery and post-launch iterations.\n\nCross-functional Leadership\n- Collaborate with engineering, design, and data science teams to build scalable, ethical, and user-centric AI products.\n- Partner with GTM teams (Sales, Marketing, Customer Success) to ensure successful product launches and feedback\nloops.\n\nExecution Excellence\n- Write detailed product specs, define OKRs, and drive sprint planning with agile teams.\n- Ensure timely delivery without compromising on quality or customer impact.\n\nAI-Product Interface\n- Work closely with machine learning engineers and data scientists to understand model capabilities and constraints.\n- Translate AI research and experiments into real-world applications and intuitive user experiences.\n\nBe the P&L Owner\n- Demonstrate strong business judgment and data obsession.\n- Own long-term growth strategies and drive measurable impact on the product P&L.\n\nBe the Product Evangelist\n- Engage in customer discovery to unlock more value and read market evolution that ensure the product evolves to\nmeet new customer needs and market trends.\n- Be fearless and drive Product thought process across the organization.\n\n\nRequirements\n- 5+ years of product management experience, with at least 2 years in B2B SaaS.\n- Proven experience in delivering AI/ML-powered products (preferably in Computer Vision, predictive analytics, or\nintelligent automation).\n- Strong technical foundation \\u2013 able to collaborate effectively with engineering and data science teams.\n- Demonstrated ability to drive product vision, strategy, and roadmap in a fast-growing environment.\n- Has owned and delivered successful product outcomes from opportunity identification to launch\n- Strong product sense \\u2013 highly analytical, with the ability to identify the right problems, think big and long term, and\nmake data-informed decisions.\n- Well-rounded solutioning skills \\u2013 human-centered, business-focused, and technology-driven.\n- Builds lasting peer relationships and has the ability to motivate and inspire teams to perform at their best.\n- Excellent written and verbal communication skills, with the ability to influence stakeholders at all levels.\n- Strong user empathy and a passion for creating delightful user experiences with complex technology.\n- Familiarity with tools like JIRA, Figma, Product board, or similar.\n\nNice to Have\n- Experience with AI model lifecycle (training, evaluation, deployment, retraining).\n- Understanding of data privacy, security, and ethical AI frameworks.\n- Prior startup experience or having scaled AI products in early-stage environments.\n\n\n\nBenefits\nWe believe that our people are the driving force behind our success, fueling big ambitions with bigger impact. We\\u2019re building more than just a workplace, we\\u2019re crafting a space where everyone feels seen, heard, and unstoppable. Here, you don\\u2019t just thrive, you grow, innovate, and leave a mark that matters.\n\nThat\\u2019s why we\\u2019re committed to equipping you with the best: a Total Rewards Policy that integrates-\n\n- Pay: A Competitive Salary that reflects your talent and drive!\n- Financial Reward: Performance-based Rewards that recognize your impact.\n- Well-being: Comprehensive Health Insurance & Mental Health Programs to keep you at your best!\n- Learning: An ongoing investment in you and your skills.\n- Personalized Development: Self-growth plans crafted to match your performance and career aspirations.\n- Compensation Reviews: Regular reviews to ensure your value aligns with market trends.\n\n"",""",Industry Type: IT Services & Consulting,Department: Product Management,"Employment Type: Full Time, Permanent","['Product management', 'Computer vision', 'Market analysis', 'Automation', 'data science', 'Analytical', 'Machine learning', 'Agile', 'Engineering Design', 'Product strategy']",2025-06-12 14:20:33
Senior Program Manager,Kalvi Career Education,10 - 20 years,Not Disclosed,['Bengaluru'],"Senior Program Manager @ Kalvium\nLocation: Bangalore (Karnataka)\nWork Timings: Monday to Saturday, 8:45AM-6:15PM\n\nAbout Kalvium\nKalvium is an exceptional startup with a mission to make the world's education more relevant and engaging. Our flagship offering is India's BEST Undergrad program in Computer Science Engineering which is offered across 20+ Universities in India.\n\nWe are backed by 30+ industry stalwarts like top executives from Google, Microsoft, Flipkart, and PhonePe, as well as luminaries of India's unicorn ecosystem like Anupam Mittal, Kunal Shah, Rahul Chari, and Ankit Bhati.\n\nWe are on the lookout for passionate minds to champion our vision and join us on a journey to redefine the global tech education landscape.\n\nResponsibilities\n\n1. Program Management\nEnsure smooth execution of the Kalvium program on the assigned campus.\nMonitor and improve student learning progress, outcomes and experience through data analysis and dashboards.\nCollaborate with internal and external stakeholders to ensure effective program operations.\nManage student / parent / university stakeholder interactions.\nManage on-ground operations for assessments, events and other program-related activities.\nTake up and drive execution of various initiatives from time to time.\n\n2. Mentorship\nFacilitate professional development and career outcomes of a cohort of Kalvium students, ensuring successful placements and optimal performance reviews from recruiting tech companies.\nProvide counselling, guidance and support to students to help them overcome challenges during their learning journey and at work.\n\n3. Team Management\nManage a team of Academic Mentors and Campus Managers on campus to deliver and drive the necessary outcomes.\n\n4. Travel Readiness\nThis role entails frequent travel, with approximately half of the workdays spent at various Kalvium campuses, overseeing campus operations and connecting with diverse stakeholders.\n\nQualification: Masters degree in any related Engineering or Management field with a minimum of 10+ Years of relevant experience.\n\nA Kalvium Senior Program Manager serves as the glue that ties the program together and acts as a role model for our future Software Engineers. Before applying, consider the following questions:\nAre you interested in helping students succeed in their careers?\nDo you enjoy mentoring students?\nDo you possess good communication and presentation skills?\nAre you a good listener?\nAre you proficient in working with data?\nAre you obsessed with productivity?\n\nLocation: Bangalore (Karnataka)\nWork Timings: Monday to Saturday, 8:45AM-6:15PM\nCTC: Offered CTC will be based on (1) Your Current CTC and (2) Your Interview Performance\n\nInterview Process:\n1st Round:- HR Discussion.\n2nd Round:- Technical Interview with Head of Program Delivery, With An Assignment(Assignment will be shared to you if you pass the 1st Round).\n3rd Round:- With One of Our Co-Founder.\n4th Round:- Culture Round/CTC Discussion With Head of HR.\n\nKalvium Benefits:\nOpportunity to be part of an impactful movement to transform higher education for the better, with a competitive salary.\nChallenging role designed to significantly enhance your professional profile and skills.\nWork closely with the founders and the founding team.\nEnjoy an awesome work culture that helps you thrive with the team.\n\nKalvium's Core Values:\nWe obsess about student experience and outcomes above all.\nWe embrace extreme ownership, focusing on outcomes over tasks.\nWe respect and trust each other.\nWe disagree with candour and courtesy.\nWe improve things regularly, rather than chase perfection.\nWe learn continuously and seek discovery.\n\nIf you resonated with the description and answered 'Oh, that's so me' while reading along, this role is an ideal fit for you.",Industry Type: Education / Training,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Program Management', 'Senior Program Manager', 'Stakeholder Management']",2025-06-12 14:20:35
Consultant - Sr. Power BI Developer,Affine Analytics,5 - 8 years,Not Disclosed,['Bengaluru'],"Design, develop, and deploy Power BI reports and dashboards that provide key insights into business performance.\nCreate and maintain complex Power BI data models, integrating data from multiple sources.\nWrite and optimize SQL queries to extract, manipulate, and analyze data from various databases.\nCollaborate with cross-functional teams to understand business requirements and translate them into effective BI solutions.\nPerform data analysis using Excel, Power Query, and other tools to support reporting and analytics needs.",,,,"['Power BI', 'Excel', 'Power BI Online Services', 'Power Query', 'SQL', 'Power BI Dax']",2025-06-12 14:20:37
Senior Designer UI UX,The Printers Mysore,5 - 10 years,12-18 Lacs P.A.,['Bengaluru'],"Digital Division of Deccan Herald/Prajavani\n\nJob Description for Senior Designer UI UX\n\nLocation Bangalore (Head Office)\n\nReporting to: Digital Business Head\n\nJob Description:\nWe are looking for a passionate and highly skilled Senior UI/UX Designer to join our dynamic digital team. You will be instrumental in creating intuitive, engaging, and user-centered designs for our digital products (Web+App+Epaper - www.deccanherald.com & www.prajavani.net) and potentially future digital products. You will be responsible for the end-to-end design process, from user research and concept development to detailed UI specifications and visual design. You will collaborate closely with product managers, developers, editorial teams, and other stakeholders to ensure our digital platforms meet user needs and business objectives.\n\nKey Responsibilities:\nLead and execute the full UI/UX design process for our digital products, including user research, information architecture, wireframing, prototyping, visual design, and usability testing.\nDevelop a deep understanding of our users through various research methods, including user interviews, surveys, and analytics analysis.\nTranslate user needs, business requirements, and technical constraints into effective and innovative design solutions.\n¢ Create user flows, wireframes, prototypes, and high-fidelity mockups to effectively communicate design ideas and concepts.\n¢ Develop and maintain UI style guides, design systems, and component libraries to ensure consistency and scalability across our digital platforms.\n¢ Collaborate closely with front-end developers to ensure accurate and efficient implementation of designs.\n¢ Work iteratively based on user feedback, data analysis, and technical feasibility.\n¢ Conduct usability testing and gather feedback to identify areas for improvement and iterate on designs.\n¢ Stay up-to-date with the latest UI/UX trends, best practices, and emerging technologies.\n¢ Present design concepts and rationale to stakeholders effectively.\n¢ Mentor and guide junior designers (if applicable).\n¢ Contribute to the overall digital strategy and product roadmap.\n\n\nQualifications & Experience\n\n¢ Bachelor's or Master's degree in Design, Human-Computer Interaction (HCI), or a related field.\n¢ Proven experience (typically 5+ years) as a UI/UX Designer, with a strong portfolio showcasing user-centered design solutions for web and mobile platforms.\n¢ Deep understanding of user-centered design principles, interaction design, information architecture, and usability best practices.\n¢ Proficiency in industry-standard design and prototyping tools such as Figma, Sketch, Adobe XD, InVision, etc.\n¢ Experience with user research methodologies and usability testing.\n¢ Solid understanding of web development technologies (HTML, CSS, JavaScript) and their impact on design feasibility.\n¢ Excellent visual design skills with a strong understanding of typography, color theory, and layout principles.\n¢ Strong communication, presentation, and interpersonal skills, with the ability to articulate design rationale clearly and persuasively.\n¢ Ability to work independently, manage multiple projects, and meet deadlines in a fast-paced environment.\n¢ Experience working in an agile development environment is a plus.\n¢ Familiarity with the media industry and content-heavy websites is a plus.\n¢ Experience with data analytics tools (e.g., Google Analytics) and using data to inform design decisions is a plus.\n\nAbout Us\nThe Printers Mysore limited is a leading Media Company in India with iconic media brands like Deccan Herald and Prajavani. The Printers Mysore is going from being an integral part of the print media ecosystem to a diversified media group.\nCapitalizing on the strength of its media brands, it has embarked on a journey to develop a digital media business for the 21st century media consumer.\nCurrently Deccan Herald and Prajavani are available across various digital products such as desktop and mobile sites, mobile apps and e-papers. The brands have incrementally increased their focus on digital and social media, by creating specialized content in this area.\nKnow more about us -\nhttps://printersmysore.com| https://www.deccanherald.com | https://www.prajavani.net/\nhttps://www.facebook.com/deccanherald | https://www.facebook.com/prajavani.net\nManagement Council & Executive Leadership info: https://printersmysore.com/Team -----------------------------------------------------------------------------------------------------------",Industry Type: Printing & Publishing,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent",['UI/UX Designer'],2025-06-12 14:20:39
Junior Executive MIS - HR (No B.tech Applicants),GMR Airports Infrastructure,3 - 7 years,4.25-5 Lacs P.A.,['Hyderabad'],"Job Title: Junior Executive - Talent Acquisition- (LJ- Grade)\nJOB PURPOSE\nExecute all transactions related to gratuity policies and superannuation settlements for all employees across the\nGroup to ensure compliance to statutory policies.\nYou will play a vital role in supporting data-driven decision-making and providing valuable insights to the Human\nResources (HR) function. Your primary focus will be on collecting, analysing, and interpreting HR /TA data to\nidentify trends, patterns, and opportunities for improving HR processes and initiatives. This role requires a strong\nanalytical mindset, proficiency in data analysis tools, and the ability to translate complex HR data into meaningful\nreports and presentations.\nORGANISATION CHART\nKEY ACCOUNTABILITIES\nTo work on all the MIS tracker/data of HR like recruitment, joining, employee database, YTD etc and update\nthe record accordingly\nUpdate various HR MIS on daily, weekly, monthly , quarterly and annually\nResponsible for maintaining and updating data within TAT\nGenerate and share reports/dashboards in an accurate and timely manner\nProvide strong reporting and analytical information supporting to the HR team\nProvide recommendation to update current MIS to improve reporting efficiency and consistency\nManaging the HR business MIS in excel for all the relevant records of employees\nWill be responsible for transformation of all documents in digital platforms\nAny other task as assigned by Head-HR/HOD\nKEY ACCOUNTABILITIES - Additional Details\nEXTERNAL INTERACTIONS\nRecruitment Consultants, Background Verification\nVendor, Pre-Employment Medical Vendor, Thomas\nAssessment, Naukri Portal etc.\nINTERNAL INTERACTIONS\nAll Business HR, TA SPOC, Hiring Managers, CHROs, FMS, IT, MAG Department and other stake holders.\nFINANCIAL DIMENSIONS\nThe funds in both Gratuity & Superannuation Trusts appox. Rs.85 crores\nOTHER DIMENSIONS\nNo.of employees covered under both the Trusts - About 9000\nEDUCATION QUALIFICATIONS\n¢Any Graduation\nRELEVANT EXPERIENCE\n3-5 years of similar HR data experience\nIn-depth knowledge of HR processes, metrics, and KPIs.\nStrong analytical and problem-solving skills, with the ability to extract insights from complex HR data sets.\nProficiency in using data analysis tools and programming languages such as advanced excel",,,,"['HR MIS', 'Excel', 'Hr Reporting', 'Dashboards', 'Pivot Table', 'VLOOKUP']",2025-06-12 14:20:41
Sr ETL/SSIS developer,Sagility India,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Summary\nWe are seeking a highly skilled and self-driven SSIS with strong communication and client-facing skills to join our healthcare analytics team. This role requires a combination of deep technical expertise in SSIS and data integration along with the ability to consult and collaborate directly with clients to understand and address their data needs.\nThe ideal candidate will be experienced in building and maintaining scalable data pipelines, working with diverse healthcare data sources, and ensuring data quality and availability for downstream analytics. You will play a key role in delivering clean, trusted, and timely data for insights and reporting.\nKey Responsibilities\nDesign, develop, and maintain robust and scalable SSIS to support healthcare analytics and reporting platforms.\nEngage directly with clients to gather requirements, provide consultation, and translate business needs into technical solutions.\nIntegrate and normalize data from diverse healthcare data sources, including claims, EMR, lab, pharmacy, and eligibility systems.\nEnsure data accuracy, completeness, and consistency throughout ingestion and transformation processes.\nOptimize and tune data workflows for performance and scalability in a cloud or on-premise data platform.\nTroubleshoot and resolve data issues in a timely and proactive manner to support high data availability.\nCollaborate with analysts, data scientists, and business stakeholders to ensure data pipelines meet analytical needs.\nCreate and maintain comprehensive technical documentation for data pipelines, data dictionaries, and workflows.\nStay informed on healthcare compliance requirements (e.g., HIPAA), and ensure data handling practices follow regulatory standards.\nRequired Skills and Qualifications\n6+ years of experience in SSIS development and data engineering\nProven ability to interact directly with clients and translate business problems into data solutions\nStrong experience with SQL, SSIS, or PySpark for data processing\nDeep understanding of data warehousing concepts and dimensional modeling\nExperience working with healthcare datasets (e.g., claims, eligibility, clinical data)\nFamiliarity with cloud platforms (Azure, AWS, or GCP) and data lakes\nStrong troubleshooting, problem-solving, and performance tuning skills\nExcellent verbal and written communication skills\nBachelor's or Masters degree in Computer Science, Engineering, Information Systems, or a related field\nPreferred Qualifications\nProficiency in building data pipelines using tools such as Azure Data Factory, Informatica, Databricks, or equivalent\nExperience with FHIR, HL7, or other healthcare data standards\nFamiliarity with HIPAA and healthcare compliance requirements\nKnowledge of reporting tools like Power BI or Tableau\nExposure to CI/CD and data pipeline automation\nWhy Join Us?\nWork on high-impact healthcare projects with meaningful outcomes\nEngage directly with clients and make a tangible difference in their data strategy\nCollaborative team culture and continuous learning opportunities\nFlexible work arrangements and competitive compensation\n\nLocation - Bangalore\nShit Timing - 2 Pm to 11 PM\nWork - Hybrid\n\nRegards,\nnaveen.vediyappan@sagility.com",Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SSIS', 'SQL', 'ETL']",2025-06-12 14:20:43
SQL Developer- Healthcare Provider Experience Required,Optum,2 - 6 years,Not Disclosed,['Hyderabad'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together \n\n  \n\n Primary Responsibilities: \n\nGather and analyze requirements for clinical data conversion projects\nCollaborate with clients and vendors to define project scope, timelines, and deliverables\nPrepare and transform clinical data for conversion activities\nAddress and resolve data-related issues reported by clients\nDevelop and maintain documentation and specifications for data conversion processes\nMonitor project progress and ensure timely completion of milestones\nTroubleshoot common database issues and provide technical support\nEnsure compliance with US healthcare regulations and standards\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\n Required Qualifications: \nFamiliarity with US healthcare systems and regulations\nKnowledge of standard EHR/EMR clinical data workflows\nUnderstanding of healthcare clinical dictionaries\nProficiency in EHR database architecture and data extraction/transformation using MS SQL Server\nSolid knowledge of stored procedures, triggers, and functions\nProven excellent problem-solving and troubleshooting skills\nSolid communication and collaboration abilities",Industry Type: Retail,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent","['stored procedures', 'data extraction', 'triggers', 'ehr', 'troubleshooting', 'hipaa', 'us healthcare', 'emr', 'icd', 'sql', 'spark', 'hims', 'medical billing', 'rcm', 'python', 'project management', 'data analysis', 'business analysis', 'epic', 'sql server', 'hl7', 'pharmacy', 'agile', 'aws', 'revenue cycle management']",2025-06-12 14:20:45
Software Engineer II,Chegg,3 - 8 years,Not Disclosed,['New Delhi'],"About the Team\nChegg's engineering team is a group of passionate engineers who, in close collaboration with data scientists, product managers, designers, and other backend developers, build the future of the online education industry. We develop our products to scale and to last, we dont take shortcuts (hello unit tests and documentation), and we take pride in delivering high-quality solutions on time. We are cloud native.\nRole\nWe are looking for software engineers passionate about solving real-world problems for students in online education using technology. The ideal candidate can think outside the box, is passionate about technology, is adaptable, thinks big, and is passionate about making an impact. Chegg is evolving very fast, and we are constantly redefining our offerings to match the requirements of our student community; the candidate should have the appetite to pivot fast and be interested in continuous improvement and learning. Chegg has a very open and vibrant engineering culture where the candidate will get the opportunity to work with the best in the industry; the role demands ideating and sharing creative ideas as you never know the next big thing Chegg works on can come from you !! If you have dreamt of leveraging your skills and knowledge to impact something big enough to matter, Chegg provides those opportunities, and the candidate should make the best use of them.\nResponsibilities\nDetermine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions;\nCross-team collaboration in driving the end-to-end delivery of SDN on Edge;\nParticipating in the code reviews and design discussions of other engineers;\nHave a strong sense of end-to-end ownership;\nAdhere to key principles: Code and design for best performance, scalability, and resiliency;\nParticipate in daily SCRUM meetings;\nParticipates in the testing process through test review and analysis, test witnessing, and certification of software;\nBe a self-starter, capable of solving ambiguous and challenging technical problems with wide scope;\nFull stack development of new features/tools, including design, documentation, implementation, and testing;\nWork alongside other engineers on the team to elevate technology and consistently apply best practices.\nSkills and Qualifications [Must Have]\nB.E., B.Tech, . degree in Computer Science or a related technical field\n3+ years of product lifecycle experience (from customer requirements -> functional spec -> design -> development/testing -> deployment and monitoring);\nStrong interpersonal and communication skills;\nStrong hands-on development/scripting experience with Python and shell.\nUse tools and methodologies to create representations of workflows, user interfaces, data schemas, etc;\nSolid understanding of software design and development;\nExperience with third-party libraries and APIs;\nExcellent design and problem-solving skills.\nStrong experience with Cloud technologies such as AWS\nExperience with Unit testing frameworks for TDD (Test Driven Development) methodology\nSkills and Qualifications [Good To Have]\nSolid understanding of Agile methodologies and experience working in Agile teams.\nHands-on experience with CI/CD pipelines, preferably using GitLab.\nDevelopment knowledge of mobile apps (android/iOS)",Industry Type: E-Learning / EdTech,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'schema', 'continuous integration', 'software testing', 'software design', 'unit testing', 'android', 'ci/cd', 'solution development', 'ios', 'cloud technologies', 'tdd', 'full stack', 'scrum', 'gitlab', 'shell scripting', 'software engineering', 'code review', 'agile', 'api', 'agile methodology']",2025-06-12 14:20:48
Specialist - Performance Marketing,Chegg,5 - 10 years,Not Disclosed,['New Delhi'],"Responsibilities\nLeverage your channel expertise to identify opportunities and provide strategic recommendations to optimize and drive performance marketing channel growth.\nCollaborate with internal stakeholders to gather campaign requirements, set up campaigns, and ensure accurate implementation across multiple ad platforms (Google Ads & Meta primarily).\nUpdate channel performance reports and provide actionable insights through timely commentary.\nCarry out regular health checks on the accounts to ensure they are set up and running as per best practice.\nDesign & implement optimisation best practices for ad platforms.\nConduct keyword research, expansion, and refinement to enhance campaign relevancy and performance.\nProactively troubleshoot and resolve issues to ensure seamless campaign delivery and accurate reporting.\nSupport in Q&A of testing documentation and implementation of experiments.\nDevelop, document & implement relevant workflow processes.\nWork closely with the UK team and external partners on strategic projects and make recommendations for market or campaign expansion.\nStay updated with industry trends, best practices, beta offerings and emerging technologies in ad operations. Apply new insights and knowledge to improve channel strategies and campaign tactics.\nRequirements\nDemonstrable expertise managing Google Ads campaigns with a track record of driving successful results. Candidates should have at least 5 years hands-on performance marketing experience.\nPreferred: knowledge of Meta or other paid social advertising platforms.\nStrong written and verbal communication skills are critical in this role, as it involves close collaboration with UK-based teams.\nData analysis and reporting skills, with advanced Google Sheets / Excel skills required, and Tableau data visualization and GA4 experience beneficial.\nA bachelor's degree in marketing, communications, or similar.\nBias towards action: quickly actioning opportunities, communicating effectively with stakeholders, and adapting approach in a fast-paced environment.",Industry Type: E-Learning / EdTech,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Marketing', 'marketing Planning', 'Google Ads campaigns', 'Tableau data visualization', 'Performance Marketing']",2025-06-12 14:20:50
"Specialist, Technical Professional Services",Fiserv,5 - 7 years,Not Disclosed,['Noida'],"The Setup and Config specialist is responsible to Analyse current system setup (Account Processing), configure, and verify it on new system based on discussions with clients in close collaboration with the team. This is a full-time position with career growth opportunities and a competitive benefits package. If you want to in financial institutions and businesses worldwide solve complex business challenges every day, this is the right opportunity for you.\nWhat you will do\nMust take complete ownership of setup/configuration for the assigned conversion/implementation.\nManages multiple clients and adhere to project timelines.\nMonitors project progress by tracking activity, resolving problems, publishing progress reports, recommending actions in accordance with stated procedure.\nAssists management with the planning and design of improvements to business processes.\nUtilizes system and data to resolve business issues in the most effective manner.\nAnalyse and identifies root cause; providing input to solutions that lead to success of the project.\nCommunicate progress and any potential problems to Project Manager for awareness and/or resolution.\nMaintain the tools used to ensure the efficiency and effectiveness of the conversion process (system studies, timelines, and questionnaires).\nWork in late night shift (up to 11 PM IST) to provide overlap with US working hours.\nProvide post implementation support for 2 weeks. (US shift timing will depend on time zone of client)\nWhat you will need to have\nB.Tech/MCA/MSC (IT/CS)/BCA/BBA\n5 to 7 years of experience in IT Industry.\nExcellent knowledge of Account Processing applications (US)\nGood understanding of Excel\nShould have good understanding of activities performed in conversion/implementation of core Banking application.\nKnowledge of Banking domain.\nExperienced problem solving and data analysis skills.\nExcellent verbal and written communication and interpersonal skills\nWhat would be great to have\nExperience supporting Banking Core Conversions.\nExperience on Account Processing core is a plus.\nExposure to Banking and Financial Services industry with a good understanding of Banking Products, Services & Procedures.\nUnderstanding of Mainframe.\nStrong analytical skills, good verbal and written communication skills and the ability to interact professionally with a diverse group. .",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data analysis', 'Publishing', 'Finance', 'Diversity and Inclusion', 'Revenue generation', 'Financial services', 'Technical Professional', 'Core banking']",2025-06-12 14:20:52
Mechatronics Technician,FORVIA HELLA,3 - 5 years,Not Disclosed,['Gurugram'],"FORVIA HELLA is a listed international automotive supplier. As a company of the FORVIA Group, FORVIA HELLA stands for high-performance lighting technology and vehicle electronics and, with the Lifecycle Solutions Business Group, also covers a broad service and product portfolio for the spare parts and workshop business as well as for manufacturers of special vehicles. With currently around 36,500 employees at over 125 locations, the Company is active worldwide and generated adjusted sales of 8.1 billion in fiscal year 2024.\nYOUR TASKS\nKey Responsibilities/ Job Description\n1. Utility System Operation & Maintenance:\nEnsure uninterrupted operation of air compressors, water chillers, and nitrogen generation plant.\nManage daily operations and maintenance of HT VCBs, LT ACBs, panels, and all plant electrical and pneumatic systems.\nOversee the fire pump house operations, including equipment readiness and testing.\nSupervise and manage the operation and upkeep of the STP (Sewage Treatment Plant).\n\n2. Preventive and Predictive Maintenance:\nPlan and execute preventive maintenance schedules for all utility equipment.\nMonitor equipment performance and implement predictive maintenance techniques to avoid unplanned downtime.\nMaintain equipment history records and service reports.\n\n3. Energy Monitoring and Optimization:\nMonitor, record, and analyze energy data, including electricity, air, water, and nitrogen consumption.\nIdentify areas for energy savings and implement energy efficiency initiatives.\n\n4. Documentation & Reporting:\nMaintain daily logs and reports for all utility systems.\nPrepare and share weekly/monthly utility performance and maintenance reports with the management and global teams.\nMaintain documentation for audits, safety compliance, and standard procedures.\n\n5. Team Management & Coordination:\nLead and guide a team of technicians and operators in day-to-day activities.\nCoordinate with production, maintenance, and safety teams for seamless plant operations.\nCommunicate and collaborate with global teams for reporting, data sharing, and implementation of best practices.\n\n6. Safety & Compliance:\nEnsure adherence to safety protocols and statutory compliance related to utility operations.\nConduct risk assessments and implement corrective actions for identified hazards.\nYOUR QUALIFICATIONS\nKey Skills and Competencies:\nStrong knowledge of utility systems and maintenance practices.\nUnderstanding of electrical systems, HT/LT panels, pneumatic systems, and water treatment operations.\nFamiliarity with energy monitoring and reporting tools.\nGood communication and interpersonal skills.\nProficiency in MS Excel, Word, and basic data analysis tools.\nAdditional Requirements:\nWillingness to respond to emergencies, if needed.\nStrong commitment to safety, reliability, and continuous improvement",Industry Type: Automobile,"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['Plant operations', 'Water treatment', 'Mechatronics', 'Data analysis', 'Team management', 'Spare parts', 'Continuous improvement', 'Automotive', 'STP', 'Preventive maintenance']",2025-06-12 14:20:54
Hiring ER Escalation Investigator-work place investigation-Gurugram,Amazon,5 - 10 years,20-30 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","We are hiring Escalation Investigator ( Work place investigations,mandatory ) based of Gurugram location.\n\nIf interested please apply on our portal\nhttps://www.amazon.jobs/en/jobs/3003294/er-escalation-investigator-india-ops-er-investigations\n\n\nKey skils:Work place investigations,mandatory",,,,"['investigation', 'Industrial Relations', 'employment laws', 'Employee Relations', 'labour laws']",2025-06-12 14:20:56
Biomedical Engineer (BME),Sodexo,5 - 10 years,3.5-4.5 Lacs P.A.,['Prayagraj'],"1. Assist in design, development, and testing of medical devices/equipment\n2. Conduct data analysis, research, and experimentation\n3. Collaborate with cross-functional teams (engineering, clinical, research)\n4. Support documentation, reporting, and regulatory compliance\n5. Troubleshoot and resolve technical issues\n\nRequirements:",,,,"['Biomedical', 'Biomedical Engineering', 'Health Care Services', 'Healthcare Management', 'Hospital equipments', 'Medical Services', 'Hospital Management', 'Medical Devices', 'BME', 'Medical Equipment']",2025-06-12 14:20:58
Ai Ml Engineer,Optum,5 - 10 years,Not Disclosed,['Noida'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.  \nAI Engineer is tasked with the design, development, and deployment of advanced generative AI models and systems. This position requires close collaboration with data scientists, product managers, and other stakeholders to integrate generative AI solutions into existing products and develop new innovative features. Proficiency in the Agentic AI framework is vital for coordinating multiple autonomous AI agents to accomplish complex tasks.\n\nPrimary Responsibilities:\nImplement Generative AI Models: Develop sophisticated generative AI algorithms and models to create new data samples, patterns, or content based on existing data or inputs\nData Processing: Collaborate with stakeholders to preprocess, analyze, and interpret extensive datasets\nModel Deployment: Deploy generative AI models into production environments, ensuring scalability and robustness\nOptimization: Conduct model testing, validation, and optimization to enhance performance\nIntegration: Work with cross-functional teams to seamlessly integrate generative AI solutions into products\nResearch: Stay current with the latest advancements in generative AI technologies and practices\nAgentic AI Framework: Utilize the Agentic AI framework to coordinate multiple AI agents for the completion of complex tasks\nMentorship: Provide mentorship to junior team members and offer technical guidance\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\nRequired Qualifications:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field\n5+ years of experience in software engineering with a focus on AI/ML\nExperience with data preprocessing and analysis\nKnowledge of the Agentic AI framework and its application in AI systems\nProficiency in machine learning frameworks such as TensorFlow and PyTorch\nSolid programming skills in Python, Java, or C++\nFamiliarity with cloud platforms (e.g., AWS, Google Cloud, Azure)\nProven excellent problem-solving abilities and algorithmic thinking\nProven solid communication and teamwork skills\n\nPreferred Qualifications:\nExperience with data processing\nKnowledge of version control systems like Git\nUnderstanding of Generative AI, associated technologies and frameworks like RAG, agents etc.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Agentic Ai', 'Gen AI', 'Cloud', 'RAG', 'LLM']",2025-06-12 14:21:00
Finance & Accounts Consultant,JSW Steel,3 - 8 years,Not Disclosed,"['karnataka', 'Vijayanagara']","About us: The Inspire Institute of Sport is a cutting-edge environment founded to craft champions in India with an eye on success at the Olympic Games. Located in Vijayanagara, Karnataka, the IIS has been stitched together with state-of-the-art facilities and sports science, and has some of the finest coaching minds from across the world to guide our athletes towards the Indian Olympic dream.\n\nOur Vision: To position India at the forefront of Olympic and Paralympic sports, cultivating a legacy of champions through exemplary dedication to sports and para-sports excellence.\n\nOur Mission: To develop and sustain a nationwide network of world-class high-performance Centres and development programs across multiple sports, including dedicated support for para-athletes. To provide holistic and interdisciplinary training environments that empower all athletes to maximize their potential and significantly contribute to India's Olympic and Para-Olympic medal achievements.\nPosition: Finance & Accounts Consultant\nDepartment: Finance and Account\nJob Location: Vijayanagara, Karnataka\nNature of Work\n\nOnsite\nWe are looking for a dedicated and detail-oriented Finance & Accounts Consultant to join our dynamic team. The ideal candidate will have strong accounting knowledge, excellent analytical skills, and experience in financial reporting, taxation, and banking operations. This role requires a proactive professional who can manage multiple finance-related responsibilities while ensuring compliance with statutory requirements.\n\nKey Responsibilities:\nAccounting & Bookkeeping:\nEnsure accurate and timely entries in the books of accounts.\nAssist in month-end, quarter-end, and year-end book closures.\nConduct thorough document and invoice verification before passing entries\nFinancial Reporting & Compliance:\nGenerate and analyze relevant MIS reports as required.\nCompile accurate data for TDS and GST return filings.\nAssist in statutory, internal, and donor audits.\nAssist in the preparation of budgets.\nBanking & Reconciliation:\nPerform bank reconciliations regularly.\nHandle sundry creditors/debtors reconciliation and ageing analysis\nObtain statements of accounts from vendors and customers.\nManage day-to-day banking operations and coordination.\nPayroll & Invoicing:\nAssist in payroll processing from the finance and accounts perspective.\nPrepare invoices and ensure accurate financial documentation\nRequirements:\nAccounting Knowledge: Strong understanding of fundamental accounting principles\nTaxation: Working knowledge of GST and TDS regulations.\nBanking Operations: Experience in handling day-to-day banking transactions and coordination.\nCost Centres: Good understanding of Cost Centre accounting.\nStrong analytical and problem-solving skills.\nEffective communication and interpersonal skills.\nAbility to work under tight deadlines and manage multiple tasks.\nAttention to detail and accuracy in financial reporting.\nTechnical Financial Software:\nTally Prime (Version 3 and above): Proficiency in ledger configuration, statutory adjustments, and financial reporting.\nMicrosoft Office Suite: Advanced proficiency in Excel (including formulas, pivot tables, and data analysis), Word, and PowerPoint.\nPower BI: Working knowledge preferred.\nPreferred Qualifications and Experience:\nCA Intermediate having completed article ship with a CA Firm with 3 years of experience.\nMasters (Finance): Minimum of 3 years of experience in finance and accounts.\nBachelors (Finance): Minimum of 6 years of relevant experience\nCandidate Requirements & Professional Expectations:\nIndustry Preference: Experience in the Non-Profit Organization sector is preferred.\nWork Attitude: Must exhibit an enabling attitude towards work and have a reasonable understanding of the dynamics of a fast-paced corporate environment.\nHow to Apply:\nPlease submit your resume and cover letter detailing your qualifications and experience with mary.appospet@inspireinstituteofsport.com",Industry Type: Sports / Leisure & Recreation,Department: Finance & Accounting,"Employment Type: Full Time, Temporary/Contractual","['TDS', 'Financial Reporting', 'GST', 'Bank Reconciliation', 'Internal Audit', 'creditors', 'Accounting', 'Donor Management', 'statement of Accounts', 'Trust Accounting', 'payroll processing', 'MIS', 'Book Keeping', 'Sundry Debtors', 'Cost Center Accounting']",2025-06-12 14:21:03
Wipro Hiring For Inventory Planner- Retail,Wipro,2 - 4 years,5-8.5 Lacs P.A.,['Pune'],Job description\nRole & responsibilities\nCollaboration for product life cycle within functions\nDemand Forecasting: Read and analysis and updating of demand forecasts\nInventory Management: Understand concept and make business decision on inventory management for seasons\nData Interpretation: Utilize Tableau to generate and interpret exception reports for inventory management,,,,"['Stock Replenishment', 'Purchase Order', 'Communication Skills', 'Retail Sales', 'Pricing Analysis', 'Retail Merchandising', 'Power Bi', 'Sales Forecasting', 'Data Analysis']",2025-06-12 14:21:05
Windchill Support Consultant,Cognizant,2 - 3 years,Not Disclosed,['Pune'],Job Summary\nWe are seeking a dedicated Product Analyst with 2 to 3 years of experience to join our team. The ideal candidate will have expertise in Windchill and a strong understanding of the Provider domain. This hybrid role requires a proactive individual who can work effectively in a day shift. The position does not require travel allowing you to focus on delivering impactful solutions that align with our companys goals.,,,,"['product documentation', 'data analysis', 'life cycle', 'analytical', 'product analysis', 'continuous improvement', 'customer satisfaction', 'strong communication skills', 'product development', 'analysis tools', 'technical specifications', 'windchill', 'product testing', 'communication skills']",2025-06-12 14:21:07
AI--Content Expert-Amazon Hiring!!--Chennai,Amazon,3 - 8 years,8-10 Lacs P.A.,['Chennai'],"External job description\n\nAmazon is looking for an AI Content Expert II to help with annotations, content generation, and data analysis. As part of the Data Team, you will be responsible for delivering high-quality training data to improve and expand AGI's Large Language Models' (LLMs) capabilities.Key job responsibilities As an AI Content Expert, you will be responsible for creating training data that are complex in nature and will require you to make informed and high judgement decisions in each case. You will be working closely with scientists and engineers to review and update guidelines, identify tooling improvement opportunities, and engage in conversations regarding the quality of data.",,,,"['Content Writing', 'Strong Communication Skills', 'SEO Writing', 'Content Creation', 'Business Writing', 'Script Writing', 'Blog Posting', 'Creative Writing', 'Content Editing', 'Research Writing', 'Content Development', 'Web Content Writing', 'Copy Writing', 'Article Writing', 'Content Research']",2025-06-12 14:21:10
AI--Content Expert-Amazon Hiring!!--Hyderabad,Amazon,3 - 8 years,8-10 Lacs P.A.,['Hyderabad'],"External job description\nAmazon is looking for an AI Content Expert II to help with annotations, content generation, and data analysis. As part of the Data Team, you will be responsible for delivering high-quality training data to improve and expand AGI's Large Language Models' (LLMs) capabilities.\nKey job responsibilities\nAs an AI Content Expert, you will be responsible for creating training data that are complex in nature and will require you to make informed and high judgement decisions in each case. You will be working closely with scientists and engineers to review and update guidelines, identify tooling improvement opportunities, and engage in conversations regarding the quality of data.",,,,"['Content Creation', 'Content Writing', 'SEO Writing', 'Proof Reading', 'Business Writing', 'Blog Writing', 'Script Writing', 'Content Strategy', 'Creative Writing', 'Content Management', 'Content Editing', 'Content Development', 'Web Content Writing', 'Copy Writing', 'Article Writing', 'Content Research']",2025-06-12 14:21:12
Artificial Intelligence Architect,Emerson,10 - 20 years,Not Disclosed,['Pune'],"Role & responsibilities\nDesign robust and scalable AI/ML architectures that support the development and deployment of machine learning models and AI solutions.\nDevelop and guide the implementation of end-to-end AI/ML solutions, including model development, data processing, and system integration.\nEvaluate and recommend the latest AI/ML technologies, frameworks, and tools to enhance system capabilities and performance.\nCollaborate with software engineers and other development teams to integrate AI/ML solutions into existing systems and applications. Ensure seamless operation and performance.\nWork with cross-functional teams, including developers, data scientists, machine learning engineers, and business stakeholders, to understand requirements and design solutions that align with business objectives.\n\nPreferred candidate profile\nBachelors degree in computer science, Data Science, Statistics, or a related field or a master's degree or higher is preferred.\nMore than 3 years of experience in designing and implementing AI/ML architectures, with a proven track record of successful projects.\nExtensive experience with machine learning frameworks (e.g., Go, TensorFlow, PyTorch), programming languages C#, .Net, NodeJS and data processing tools.\nStrong understanding of system architecture principles, including distributed systems, microservices, and cloud computing.\nExperience with Microsoft Azure cloud services and their AI/ML offerings\nExperience with event-handling systems such as Kafka\nExperience with big data technologies and data engineering practices.\nExcellent verbal and written communication skills, with the ability to convey complex technical concepts to non-technical stakeholders.",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Aiml', 'Ml', 'Python', 'Tensorflow', 'Pytorch', 'Architecture', 'Artificial Intelligence', '.Net', 'Machine Learning', 'Scikit-Learn']",2025-06-12 14:21:14
Data Analyst,FedEx,2 - 4 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nCollect, analyze, and interpret complex data sets using Python and SQL to support business objectives.\nCollaborate with stakeholders to understand business needs, formulate analytic solutions, and provide actionable insights.\nDevelop and maintain data models and reports to track key performance indicators (KPIs) and business metrics.\nCreate meaningful data visualizations to communicate findings, trends, and actionable insights to non-technical stakeholders.\nConduct exploratory data analysis and identify patterns, trends, and opportunities for business improvement.\nSupport data quality initiatives, ensuring accuracy and consistency across data sources.\nUtilize statistical and quantitative techniques to support problem-solving and business optimization efforts.\n\n\n\n\nPreferred candidate profile\n\nPython: Proficiency in data manipulation, data analysis libraries (Pandas, NumPy),and data visualization libraries (Matplotlib, Seaborn).\nSQL: Strong command of SQL for data extraction, transformation, and complex queries.\nBusiness Acumen: Ability to understand business context and objectives, aligning analytics with organizational goals.\nQuantitative Aptitude: Strong analytical and problem-solving skills, with a keen attention to detail.\nData Visualization: Basic skills in data visualization to effectively communicate insights.\nStatistical Analysis: Foundational understanding of statistical methods (e.g., regression, hypothesis testing).\nCommunication Skills: Ability to distill complex data insights into clear,actionable recommendations for stakeholders.",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'SQL', 'Python', 'Power Bi', 'Business Insights', 'Tableau', 'Data Analytics']",2025-06-13 05:25:35
Data Analyst III,Sadup Soft,5 - 8 years,Not Disclosed,['Bengaluru'],"- Minimum of 5 years of experience in data analysis with a strong SQL background.\n\n- Solid experience in creating and extracting metrics, and writing complex SQL scripts.\n\n- Hands-on experience with Tableau, Looker, or any equivalent data visualization tools.\n\n- Strong skills in SQL and Excel, with the ability to quickly learn other analytic tools.\n\n- Knowledge of Python and ML algorithms is a plus.\n\nResponsibilities :\n\n- Perform detailed data analysis and validation to ensure data integrity and accuracy.\n\n- Extract and create meaningful metrics to support business decisions\n\n- Design, develop, and maintain interactive dashboards using Tableau, Looker, or equivalent tools.\n\n- Translate complex data into visually appealing and actionable insights.\n\n- Document queries, reports, and analytical processes clearly and accurately.\n\n- Create detailed reports and presentations to communicate findings to stakeholders.\n\n- Work closely with cross-functional teams to understand data requirements and provide analytical support.\n\n- Communicate findings effectively and provide actionable recommendations.\n\n- Utilize SQL and Excel extensively for data analysis and reporting.\n\n- Apply Python and ML algorithms as needed for advanced analytics (preferred but not mandatory)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Data Integrity', 'Data Analyst', 'Data Visualization Tools', 'Tableau', 'Data Analytics', 'Looker']",2025-06-13 05:25:37
Data Analyst,Primary Healthtech,1 - 5 years,2.5-4.5 Lacs P.A.,['Noida'],"Roles and Responsibilities\nCollect data from various sources, clean it, and analyze it using statistical tools.\nCreate reports based on analysis findings to present insights to stakeholders.\nDevelop dashboards and visualizations to effectively communicate results.\nManage databases by designing schema, writing queries, and optimizing performance.\nEnsure accuracy of data through quality control measures.\nDesired Candidate Profile\n1-5 years of experience in Data Analysis or related field (Data Analytics).\nB.Tech/B.E. degree in Any Specialization.\nProficiency in SQL programming language with knowledge of database management systems like MySQL or PostgreSQL.\nStrong understanding of statistics, data interpretation, and data visualization techniques.",Industry Type: Medical Devices & Equipment,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Interpretation', 'Data Analysis', 'Data Analytics', 'Data Management', 'Data Visualization', 'Data Reporting']",2025-06-13 05:25:39
"Data Eng, Mgmt & Governance Analyst",Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Data Management - Structured Query Language (SQL)\n\n\n\n\nDesignation: Data Eng, Mgmt & Governance Analyst\n\n\n\n\nQualifications:BE/BTech\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDomain-specific language used in programming and designed for querying and modifying data and managing databases.\n\n\n\n\nWhat are we looking for\nSQL Data Visualization Adaptable and flexible Commitment to quality Ability to work well in a team Strong analytical skills Agility for quick learning\n\n\n\nRoles and Responsibilities: Draft, review and negotiate the supplier/buyside agreements and similar/related documentation with Accenture suppliers, to procure various goods and services including but not limited to Contactors, Human Resources Support, IT & Telecom, Marketing & Communications, Workplace Support (Facilities & Services), Software as a Service etc. in accordance with Accentures suppliers contracting standards, applicable laws, and business requirements. Customize the existing templates in exceptional cases to suit the business requirements thereby ensuring compliance to applicable local laws and Accentures suppliers contracting standards. Review the supplier templates and ensure that the deviations to the Accentures suppliers contracting standards are timely identified and highlighted to the business whenever they pose as risks to Accenture operations. Participate in negotiations by representing company s interests and interface directly with client/ vendor negotiating teams with suppliers, third parties, subcontractors etc., to agree to contractual terms in accordance with Accentures suppliers contracting standards, applicable laws, and stakeholder requirements. Liaise and effectively collaborate with internal stakeholders such as deal teams, Solution Architects, Procurement, HR, Workplace, Finance, Marketing & Communications etc., as well as with external parties such as suppliers, external counsel etc. to ensure contractual risks are clearly identified and addressed in compliance with Accenture s policies and standards. Work closely with the stakeholders to help them understand the contractual clauses in terms of interpretation and its applicability in the contract basis the business opportunity. Advise the Business from legal perspective to address the potential contractual risks that may pose as risks to Accenture business operations. Conduct gap analysis and create legal risk assessment by identifying and flagging potential risks to Accenture and/or clauses which are non-negotiable. Provide recommendations to Business and other related stakeholders to sensitize them on the extent of risk Accenture exposes itself in context of the services and to minimize or mitigate such risks effectively. Structure the legal transactions to be most advantageous from a contracting and business perspective and escalate accordingly to the SME/leadership on the deal etc.\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data management', 'data analysis', 'gap analysis', 'sql', 'data visualization', 'project management', 'python', 'data analytics', 'documentation', 'business analysis', 'power bi', 'business intelligence', 'database management', 'tableau', 'saas', 'advanced excel', 'agile', 'business operations']",2025-06-13 05:25:41
Data Analyst - L3,Wipro,3 - 5 years,Not Disclosed,['Hyderabad'],"Role Purpose\nThe purpose of this role is to interpret data and turn into information (reports, dashboards, interactive visualizations etc) which can offer ways to improve a business, thus affecting business decisions.\nDo\n1. Managing the technical scope of the project in line with the requirements at all stages\na. Gather information from various sources (data warehouses, database, data integration and modelling) and interpret patterns and trends\n\n\n\n\nMandatory Skills: Business Analyst/ Data Analyst(Media). Experience: 3-5 Years.",,,,"['Data analysis', 'data validation', 'data mining', 'business analysis', 'data warehousing', 'business analytics', 'dbms', 'dashboards', 'sales', 'analytics reporting', 'reporting tools', 'data integration', 'digital transformation']",2025-06-13 05:25:43
Data Analyst,Avnet,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Summary:\nDesigns and prepares reports, dashboards, and summaries for statistical analysis and planning purposes. Analyzes business issues using data from internal and external sources to provide insight to decision-makers. Identifies and interprets trends and patterns.\n\nPrincipal Responsibilities:",,,,"['Training', 'Statistical analysis', 'Business analysis', 'Finance', 'Business process mapping', 'Data Analyst', 'Management', 'Business intelligence', 'Principal', 'Remedy']",2025-06-13 05:25:45
Data Analyst,Avnet Emea,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Summary:\nDesigns and prepares reports, dashboards, and summaries for statistical analysis and planning purposes. Analyzes business issues using data from internal and external sources to provide insight to decision-makers. Identifies and interprets trends and patterns.\n\nPrincipal Responsibilities:\nCollects, compiles and analyzes data from various databases and performs statistical analysis for internal customer groups.\nDevelops reports and/or creates dashboards providing financial related information needed to make informed business decisions.\nDesigns, creates and implements templates to collect, display and analyze data for assigned projects\nCommunicates complex data in comprehensible ways. Evaluates information from multiple sources and clearly indicates quality of final analysis.\nDevelops reports and other tools to deliver internal company information enabling business users to make informed decisions.\nGathers, aggregates models, and analyzes information from multiple external sources regarding company financial performance, customer insights, competitor profiling, competitive threats, potential product or technical expansion, industry trends and other such business intelligence aspects.\nEstablishes standards and procedures for a variety of processes, conducting business analysis resulting in detailed creation and maintenance of business process mapping, requirements and training materials documentation.\nMay participate in or lead project teams.\nIdentifies, investigates and participates in opportunities to improve processes and procedures, to include various key performance metrics.\nOther duties as assigned.\n\nJob Level Specifications:\nFoundational knowledge of specialized disciplines, industry practices and standards, acquired via academic instruction and/or relevant work experience of substantially the same level.\nDevelops solutions to defined tasks, typical assignments and projects. May be solved by the application of specialized foundational knowledge, using existing approaches and solutions.\nWork is usually performed independently and requires the exercise of judgment and discretion. Receives initial direction although work may be reviewed for accuracy and quality.\nCollaborates with immediate management and team members within the department or function.\nActions typically affect own work assignments and department. Erroneous decisions or failure to accomplish work may require some assistance or resources to remedy.\n\nWork Experience:\nTypically less than 2 years with bachelors or equivalent.\n\nEducation and Certification(s):\nBachelors degree or equivalent experience from which comparable knowledge and job skills can be obtained.\n\nDistinguishing Characteristics:\nPosition may require the ability to travel.\nThe above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills.",Industry Type: Electronics Manufacturing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Training', 'Statistical analysis', 'Business analysis', 'Finance', 'Business process mapping', 'Data Analyst', 'Management', 'Business intelligence', 'Principal', 'Remedy']",2025-06-13 05:25:46
Data Analyst -Python,Sopra Steria,4 - 8 years,Not Disclosed,['Chennai'],"Experience working in large Software Development Teams\nKnowledge and experience in Agile Delivery mechanisms\nWork with business stakeholders, SCRUM masters, Designers and testers in SCRUM team.\nProficient in English language with ability to lead stakeholder conversations.\nExperience in generating insights through data and articulating stories addressing business problems.\nTotal Experience Expected: 6-8 years\nMandatory",,,,"['Data analysis', 'tableau', 'Agile', 'Scrum', 'Data Analyst', 'Windows', 'data visualization', 'SQL', 'Python']",2025-06-13 05:25:48
Data Analyst - Gurugram,Infosys,5 - 10 years,Not Disclosed,"['Chennai', 'Bengaluru', 'PAN INDIA']","Responsibilities:\nUnderstand architecture requirements and ensure effective design, development, validation, and support activities.\nAnalyze user requirements, envisioning system features and functionality.\nIdentify bottlenecks and bugs, and recommend system solutions by comparing advantages and disadvantages of custom development.\nContribute to team meetings, troubleshooting development and production problems across multiple environments and operating platforms.\nEnsure effective design, development, validation, and support activities for Big Data solutions.\nTechnical and Professional Requirements:\nSkills:\nProficiency in Scala, Spark, Hive, and Kafka.\nIn-depth knowledge of design issues and best practices.\nSolid understanding of object-oriented programming.\nFamiliarity with various design, architectural patterns, and software development processes.\nExperience with both external and embedded databases.\nCreating database schemas that represent and support business processes.\nImplementing automated testing platforms and unit tests.\nPreferred Skills:\nTechnology -> Big Data -> Scala, Spark, Hive, Kafka\nAdditional Responsibilities:\nCompetencies:\nGood verbal and written communication skills.\nAbility to communicate with remote teams effectively.\nHigh flexibility to travel.\nEducational Requirements:Master of Computer Applications, Master of Technology, Master of Engineering, MSc, Bachelor of Technology, Bachelor of Computer Applications, Bachelor of Computer Science, Bachelor of Engineering",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Spark', 'Hive', 'Hadoop', 'Big Data', 'Kafka']",2025-06-13 05:25:50
Data Analyst,Pripton Innovations,0 - 5 years,Not Disclosed,[],We are looking for a Data Analyst with expertise in ERP systems (NetSuite and Workday Financials) and data warehousing (Snowflake) to support our ongoing ERP migration and data-driven decision-making.,Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'ERP System', 'Netsuite', 'Snowflake']",2025-06-13 05:25:51
Data Analyst,Sara Business Solution,0 - 2 years,1.44-1.8 Lacs P.A.,['Karur'],"Responsibilities:\n* Analyze data using advanced tools and techniques.\n* Support agri-data projects with insights from the field.\nPassion for agriculture, rural development, or farming\nBasic computer skills (Excel, Google Sheets, etc.)",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent",['any degree with Agriculture background'],2025-06-13 05:25:53
Data Analyst,Fraoula,3 - 5 years,Not Disclosed,"['Mumbai', 'Bengaluru', 'Delhi / NCR']","We are seeking a highly motivated and detail-oriented Data Analyst to join our growing team. The ideal candidate will be passionate about transforming raw data into actionable insights, helping us make informed strategic decisions. You will play a crucial role in collecting, processing, and performing statistical analyses on large datasets, translating complex findings into clear, concise reports and visualizations for various stakeholders.\n\nKey Responsibilities:\n-Data Collection & Cleaning: Source, collect, and clean data from various internal and external databases, ensuring data accuracy, completeness, and consistency.\n-Data Analysis & Modeling: Perform in-depth statistical analysis, identify trends, patterns, and anomalies in data. Develop and implement data models to predict outcomes and optimize performance.\n-Reporting & Visualization: Create compelling and intuitive dashboards, reports, and presentations using data visualization tools (e.g., Power BI, Tableau) to communicate insights to technical and non-technical audiences.\n\nLocation-Delhi NCR,Bangalore,Chennai,Pune,Kolkata,Ahmedabad,Mumbai,Hyderabad,Remote",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL', 'Python', 'Power BI', 'Data Analysis', 'Data Visualization', 'Tableau', 'Looker', 'Data Cleaning', 'Statistical Analysis']",2025-06-13 05:25:55
Data Analyst - Python/Hadoop,Sadup Soft,3 - 6 years,Not Disclosed,['Bengaluru'],"- Minimum of 3 years of hands-on experience.\n\n- Python/ML, Hadoop, Spark : Minimum of 2 years of experience.\n\n- At least 3 years of prior experience as a Data Analyst.\n\n- Detail-oriented with a structured thinking and analytical mindset.\n\n- Proven analytic skills, including data analysis, data validation, and technical writing.\n\n- Strong proficiency in SQL and Excel.\n\n- Experience with Big Query is mandatory.\n\n- Knowledge of Python and machine learning algorithms is a plus.\n\n- Excellent communication skills with the ability to be precise and clear.\n\n- Learning Ability : Ability to quickly learn and adapt to new analytic tools and technologies.\n\nKey Responsibilities :\n\nData Analysis :\n\n- Perform comprehensive data analysis using SQL, Excel, and Big Query.\n\n- Validate data integrity and ensure accuracy across datasets.\n\n- Develop detailed reports and dashboards that provide actionable insights.\n\n- Create and deliver presentations to stakeholders with clear and concise findings.\n\n- Document queries, reports, and analytical processes clearly and accurately.\n\n- Leverage Python/ML for advanced data analysis and model development.\n\n- Utilize Hadoop and Spark for handling and processing large datasets.\n\n- Work closely with cross-functional teams to understand data requirements and provide analytical support.\n\n- Communicate findings effectively and offer recommendations based on data analysis.\n\nEducation : Bachelor's degree in Computer Science, Data Science, Statistics, or a related field.\n\nExperience : Minimum of 3 years of experience as a Data Analyst with a strong focus on SQL, Excel, and Big Query.\n\nTechnical Skills : Proficiency in SQL, Excel, and Big Query; experience with Python, ML, Hadoop, and Spark is preferred.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Data Validation', 'Big Query', 'Data Integrity', 'Hadoop', 'Spark', 'Python', 'SQL']",2025-06-13 05:25:56
Procurement Data Analyst,Response Informatics,1 - 5 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","Key Responsibilities:\nClean, validate, and standardize extracted datasets in accordance with best practices and any specifications provided by the Client.\nDesign and develop dashboards, visualizations, and reporting tools using Microsoft Excel, Power BI, or other equivalent analytics platforms as may be approved by the Client.\nConduct in-depth analysis of procurement data to identify tail spend, category-level insights, and potential cost-saving opportunities.\nSegment and categorize procurement data by business unit, supplier, spend category, and geographic region to enable targeted sourcing strategies.\nProduce periodic reports and executive summaries for review by the Client s Procurement leadership team.\nTranslate data-driven trends and findings into clear, actionable sourcing recommendations.\nCollaborate closely with the Client s internal buying teams to ensure alignment of data outputs with sourcing priorities and project selection criteria.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Procurement', 'Excel', 'Senior Executive', 'power bi', 'Data Analyst', 'Saving', 'Cost', 'Analytics', 'Reporting tools']",2025-06-13 05:25:58
Data Analyst,LTIMindtree,7 - 12 years,Not Disclosed,"['Chennai', 'Bengaluru', 'Delhi / NCR']","Role & responsibilities\nPrimary Skill SQL, Business Intelligence Tools, Banking products exp, DBMS( Redshift OR Oracle),Cloud Exp (AWS Preferred).\nSecondary Skill Data Management, Agile exp.\nTotal Exp 7+\nNotice Period : 30 Days\nJob Location : Pan India\n\nShare your CV on\npallavi.bhalerao@alphacom.in",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Intelligence Tools', 'DBMS', 'SQL', 'Banking Products']",2025-06-13 05:26:00
Data Analyst,Growing Soonicorn in Auto Components Spa...,3 - 5 years,Not Disclosed,['Bengaluru'],"Dear Candidates,\n\nGreetings!!\n\nWe are hiring for one of the Globalized Product Based & Motor Vehicle Manufacturing MNC.\n\nJob Type: FTE\nJob Role:- Data Analyst\nExperience: 3 to 5 Years\nLocation: Bangalore\nWork Mode: Work from office\nNotice Period: Immediate to 30 days\nBudget: As Per Market Standards\nMandatory Skills:- Azure Data bricks, Power BI, Tableau, SQL, Python\n\n\n\nInterested candidates can share their updated resume on Gurpreet@selectiveglobalsearch.com",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Power Bi', 'Azure Databricks', 'Tableau', 'SQL', 'Python', 'Data Visualization']",2025-06-13 05:26:01
Data Analyst,BP INCORPORATE INTERNATIONAL.,1 - 3 years,Not Disclosed,['Pune'],"Grade IResponsible for supporting the delivery of business analysis and consulting processes and procedures for the defined specialism using basic technical capabilities, developing working relationships to provide support with queries, issues and ad-hoc requests and assisting with quality assurance services. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.\nEntity:\nTechnology\n\nITS Group\n\nYou will work with\nBeing part of a digital delivery data group supporting bp Solutions, you will apply your domain knowledge and familiarity with domain data processes to support the organisation. Part of bp s Production Operations business, bp Solutions has hubs in London, Pune, and Houston. The data team provides daily operational data management, data engineering and analytics support to this organisation across a broad range of activity from facilities and subsea engineering to logistics.\nLet me tell you about the role\nA data analyst collects, processes, and performs analyses on a variety of datasets. Their key responsibilities include interpreting sophisticated data sets to identify trends and patterns, using analytical tools and methods to generate actionable insights, and crafting visualizations and reports to communicate those insights and recommendations to support decision-making. Data analysts collaborate closely with business domain collaborators to understand their data analysis needs, ensure data accuracy, write and recommend data-driven solutions and tackle value impacting business problems.\nYou might be a good fit for this role if you:\nHave strong domain knowledge in at least one of; facilities or subsea engineering, maintenance and reliability, operations, logistics.\nStrong analytical skills and proven capability in applying analytical techniques and Python scripting to solve practical problems.\nAre curious, and keen to apply new technologies, trends methods to improve existing standards and the capabilities of the Subsurface community.\nAre well organized and self-motivated, you balance proactive and reactive approaches and across multiple priorities to complete tasks on time.\nApply judgment and common sense - you use insight and good judgment to inform actions and respond to situations as they arise.\nWhat you will deliver\nBe a link between asset teams and Technology, combining in-depth understanding of one or more relevant domains with data analytics skills\nProvide actionable, data-driven insights by combining deep statistical skills, data manipulation capabilities and business insight.\nProactively identify impactful opportunities and autonomously complete data analysis.\nYou apply existing data analytics strategies relevant to your immediate scope.\nClean, pre-process and analyse both structured and unstructured data\nDevelop data visualisations to analyse and interrogate broad datasets (e.g. with tools such as Microsoft PowerBI, Spotfire or similar).\nPresent results to peers and senior management, influencing decision making\nWhat you will need to be successful (experience and qualifications)\nEssential\nMSc or equivalent experience in a quantitative field, preferably statistics.\nhave strong domain knowledge in at least one of; facilities or subsea engineering, maintenance and reliability, operations, logistics.\nHands-on experience carrying out data analytics, data mining and product analytics in complex, fast-paced environments.\nApplied knowledge of data analytics and data pipelining tools and approaches across all data lifecycle stages.\nDeep understanding of a few and a high-level understanding of several commonly available statistics approaches.\nAdvanced SQL knowledge.\nAdvanced scripting experience in R or python.\nAbility to write and maintain moderately sophisticated data pipelines.\nCustomer-centric and pragmatic approach. Focus on value delivery and swift execution, while maintaining attention to detail.\nGood communication and social skills, with the ability to effectively communicate ideas, expectations, and feedback to team members, partners, and customers. Foster collaboration and teamwork\nDesired\nAdvanced analytics degree.\nExperience applying analytics to support engineering turnarounds\nExperience with big data technologies (e.g. Hadoop, Hive, and Spark) is a plus.\nAbout bp\nOur purpose is to deliver energy to the world, today and tomorrow. For over 100 years, bp has focused on discovering, developing, and producing oil and gas in the nations where we operate. We are one of the few companies globally that can provide governments and customers with an integrated energy offering. Delivering our strategy sustainably is fundamental to achieving our ambition to be a net zero company by 2050 or sooner!\n\nTravel Requirement\nUp to 10% travel should be expected with this role\n\nRelocation Assistance:\nThis role is eligible for relocation within country\n\nRemote Type:\nThis position is a hybrid of office/remote working\n\nSkills:",Industry Type: Oil & Gas,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Data management', 'Business analysis', 'Consulting', 'microsoft', 'Data mining', 'Analytics', 'SQL', 'Logistics']",2025-06-13 05:26:03
Data Analyst,Cushman Wakefield,1 - 2 years,Not Disclosed,['Gurugram'],"Job Title\nData Analyst\nJob Description Summary\nThis role focuses on developing advanced analytics systems, uncovering growth opportunities through data analysis, and creating insightful reports and visualizations. It will involve close collaboration with managers to understand business needs, define KPIs, and deliver actionable insights that enhance performance and efficiency.\nKey responsibilities include data mining, predictive modeling, system evaluation, and maintaining robust data infrastructure to support strategic decision-making.\n\n\n\n\n\n\nINCO: Cushman Wakefield",,,,"['data cleansing', 'advanced analytics', 'Data analysis', 'Scalability', 'Revenue enhancement', 'Infrastructure', 'Manager Technology', 'Predictive modeling', 'Data Analyst', 'Data mining']",2025-06-13 05:26:05
Data Analyst,Innovature Software Labs,2 - 4 years,Not Disclosed,"['Kochi', 'Chennai']",">\nJob Category: Software\nJob Type: Full Time\nJob Location: Infopark - Kochi\nExperience: 2 - 4 Years\nDesignation: Data Analyst\nKey Responsibilities\nAnalyze large volumes of analytical data (sales, customer, product) to identify patterns, trends, and insights.\nDevelop and maintain data reports and dashboards using business intelligence tools (e.g., Tableau, Power BI, etc.)\nCollaborate with business teams to understand key business objectives and data needs.\nAnalyze customer behavior, product usage, and historical purchase data to identify cross-selling opportunities.\nEnsure data models and structures are well-designed to facilitate analysis and reporting.\nAct as a bridge between data engineers and business stakeholders , ensuring data is aligned with business needs.\nSkill set\nProficient in data engineering tools and languages such as Python, SQL, and Java.\nStrong knowledge of business intelligence (BI) tools such as Tableau, Power BI or similar for creating reports and dashboards.\nAbility to work with databases(SQL NoSQL) and perform complex data queries.\nFamiliarity with data wrangling, ETL processes and data cleaning techniques.\nClear understanding of data warehousing cloud based analytics .\nAbility to apply data insights to influence marketing strategies, sales tactics, and product offerings.\nExperience\n2-4 years of experience in a data analyst role with experience in analyzing customer data, sales data, and product data.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Usage', 'Sales', 'Analytical', 'power bi', 'Data Analyst', 'Business intelligence', 'Data warehousing', 'Analytics', 'SQL', 'Python']",2025-06-13 05:26:06
Data Analyst,C&W Services,1 - 4 years,Not Disclosed,['Gurugram'],"Job Title\nData Analyst\nJob Description Summary\nThis role focuses on developing advanced analytics systems, uncovering growth opportunities through data analysis, and creating insightful reports and visualizations. It will involve close collaboration with managers to understand business needs, define KPIs, and deliver actionable insights that enhance performance and efficiency.\nKey responsibilities include data mining, predictive modeling, system evaluation, and maintaining robust data infrastructure to support strategic decision-making.\nWork closely with the Program manager (s) and department heads to understand and maintain focus on their analytics needs, including critical metrics and KPIs, and deliver actionable insights to relevant decision-makers\nProactively analyze data to answer key questions for stakeholders or yourself, with an eye on what drives business performance, and investigate and communicate which areas need improvement in efficiency and productivity\nCreate and maintain rich insights to facilitate cross sell and upsell decisions through deep data mining\nDefine and implement data acquisition and integration logic, selecting an appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution\nDevelop and maintain databases by acquiring data from primary and secondary sources\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nBuild predictive analysis and churn analysis to impact revenue enhancement and retention\n\n\n\n\n\n\nINCO: Cushman & Wakefield",Industry Type: Real Estate,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data cleansing', 'advanced analytics', 'Data analysis', 'Scalability', 'Revenue enhancement', 'Infrastructure', 'Manager Technology', 'Predictive modeling', 'Data Analyst', 'Data mining']",2025-06-13 05:26:08
Data Analyst,Corelogic,5 - 10 years,Not Disclosed,['Noida'],"At Cotality, we are driven by a single mission to make the property industry faster, smarter, and more people-centric. Cotality is the trusted source for property intelligence, with unmatched precision, depth, breadth, and insights across the entire ecosystem. Our talented team of 5,000 employees globally uses our network, scale, connectivity and technology to drive the largest asset class in the world. Join us as we work toward our vision of fueling a thriving global property ecosystem and a more resilient society.\nCotality is committed to cultivating a diverse and inclusive work culture that inspires innovation and bold thinking; its a place where you can collaborate, feel valued, develop skills and directly impact the real estate economy. We know our people are our greatest asset. At Cotality, you can be yourself, lift people up and make an impact. By putting clients first and continuously innovating, were working together to set the pace for unlocking new possibilities that better serve the property industry.\nJob Description:\nIn India, we operate as Next Gear India Private Limited, a fully-owned subsidiary of Cotality with offices in Kolkata, West Bengal, and Noida, Uttar Pradesh. Next Gear India Private Limited plays a vital role in Cotalitys Product Development capabilities, focusing on creating and delivering innovative solutions for the Property & Casualty (P&C) Insurance and Property Restoration industries.\nWhile Next Gear India Private Limited operates under its own registered name in India, we are seamlessly integrated into the Cotality family, sharing the same commitment to innovation, quality, and client success.\nWhen you join Next Gear India Private Limited, you become part of the global Cotality team. Together, we shape the future of property insights and analytics, contributing to a smarter and more resilient property ecosystem through cutting-edge technology and insights.\nCompany Description\nAt Cotality, we are driven by a single mission to make the property industry faster, smarter, and more people-centric. CoreLogic is the trusted source for property intelligence, with unmatched precision, depth, breadth, and insights across the entire ecosystem. Our talented team of 5,000 employees globally uses our network, scale, connectivity, and technology to drive the largest asset class in the world. Join us as we work toward our vision of fueling a thriving global property ecosystem and a more resilient society.\n\nCotality is committed to cultivating a diverse and inclusive work culture that inspires innovation and bold thinking; its a place where you can collaborate, feel valued, develop skills, and directly impact the insurance marketplace. We know our people are our greatest asset. At Cotality, you can be yourself, lift people up and make an impact. By putting clients first and continuously innovating, were working together to set the pace for unlocking new possibilities that better serve the property insurance and restoration industry.\nRegular working hours will be from 12noon to 9pm IST\nIt will be Hybrid work where the team will need to be in the office for the first half of the day for 3 days a week and they can leave in the afternoon around 3pm or 4pm and log back at home for the remaining hours (same as other local teams).\nTraining will be provided about the product.\nDescription\nWe are seeking a highly skilled Data Analyst to join our Analytics Support team to serve customers across the property insurance and restoration industries. As a data analyst you will play a crucial role in developing methods and models to inform data-driven decision processes resulting in improved business performance for both internal and external stakeholder groups. You will be responsible for interpreting complex data sets and providing valuable insights to enhance the value of data assets. The successful candidate will have a strong understanding of data mining techniques, methods of statistical analysis, and data visualization tools. This position offers an exciting opportunity to work in a dynamic environment, collaborating with cross-functional teams to support decision processes that will guide the respective industries into the future.\nResponsibilities\nCollaborate with cross-functional teams to understand and document requirements for analytics products.\nServe as the primary point of contact for new data/analytics requests and support for customers.\nAct as the domain expert and voice of the customer to internal stakeholders during the analytics development process.\nDevelop and maintain an inventory of data, reporting, and analytic product deliverables for assigned customers.\nWork with customer success teams to establish and maintain appropriate customer expectations for analytics deliverables.\nCreate and manage change order tickets on behalf of customers within internal frameworks.\nEnsure timely delivery of assets to customers and aid in the development of internal processes for the delivery of analytics deliverables.\nWork with IT/Infrastructure teams to provide customer access to assets and support internal audit processes to ensure data security.\nCreate and optimize complex SQL queries for data extraction, transformation, and aggregation.\nDevelop and maintain data models, dashboards, and reports to visualize data and track key performance metrics.\nConduct validation checks and implement error handling mechanisms to ensure data reliability.\nCollaborate closely with stakeholders to align project goals with business needs and perform ad-hoc analysis to provide actionable recommendations.\nAnalyze large and complex datasets to identify trends, patterns, and insights, and present findings and recommendations to stakeholders in a clear and concise manner.\nJob Qualifications:\n5+ years experience of building PowerBI dashboards, data modeling and analysis\nBachelor s degree in computer science, data science, statistics, or a related field is preferred.\nAdvanced knowledge of data analysis tools such as Power Query, Excel, and Power BI.\nDemonstrated expertise in Power BI creating reports and dashboards, including the ability to connect to various data sources, prepare and model data, and create visualizations.\nExcellent visual and storytelling skills with data. Experience with Power Query for importing, transforming, and shaping data.\nExpert knowledge of DAX for creating calculated columns and measures to meet report-specific requirements.\nProficiency in SQL with the ability to write complex queries and optimize performance.\nExperience with ETL processes, data pipeline and automation a plus.\nStrong analytical and problem-solving skills\nExcellent attention to detail and the ability to work with large datasets.\nEffective communication skills, both written and verbal.\nAbility to work independently and collaborate in a team environment.\nKnowledge of property insurance industry will be a plus.\nCotalitys Diversity Commitment:\nCotality is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone s unique contributions, experiences and values. We offer an empowered work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. We are better together when we support and recognize our differences.\nEqual Opportunity Employer Statement:\nCotality is an Equal Opportunity employer committed to attracting and retaining the best-qualified people available, without regard to race, ancestry, place of origin, colour, ethnic origin, citizenship, creed, sex, sexual orientation, record of offences, age, marital status, family status or disability. Cotality maintains a Drug-Free Workplace.\nPlease apply on our website for consideration.\nPrivacy Policy\nGlobal Applicant Privacy Policy\nBy providing your telephone number, you agree to receive automated (SMS) text messages at that number from Cotality regarding all matters related to your application and, if you are hired, your employment and company business. Message & data rates may apply. You can opt out at any time by responding STOP or UNSUBSCRIBING and will automatically be opted out company-wide.\nConnect with us on social media! Click on the quicklinks below to find out more about our company and associates",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Manager Internal Audit', 'Automation', 'Data modeling', 'Analytical', 'Social media', 'SMS', 'Data mining', 'SQL', 'Data extraction']",2025-06-13 05:26:10
Data Analyst,Bhavani Shipping services,1 - 3 years,1-2.75 Lacs P.A.,"['Thane', 'Navi Mumbai', 'Mumbai (All Areas)']","Principal Duties and Responsibilities\nInterpreting data, analyzing results using statistical techniques.\nDeveloping and implementing data analyses, data collection systems and other strategies that optimize statistical efficiency and quality.\nAcquiring data from primary or secondary data sources and maintaining databases.\n\nKey Responsibilities:\n\nData Collection and Processing:\nGather data from various sources, ensuring accuracy and completeness.\nCleanse and preprocess data to remove errors and inconsistencies.\nStatistical Analysis and Interpretation:\nUtilize statistical methods to analyze data and identify trends, patterns, and correlations.\nPresent findings through reports, visualizations, and presentations to stakeholders.\nData Visualization and Reporting:\nCreate visualizations and dashboards to effectively communicate insights.\nPrepare regular reports and ad-hoc analyses to support strategic decision-making.\nProblem-Solving and Recommendations:\nCollaborate with cross-functional teams to address business challenges using data-driven insights.",Industry Type: Courier / Logistics,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Reporting', 'Data Analysis', 'Excel Powerpoint', 'Data Extraction', 'Charts', 'Data Collection', 'Advanced Excel', 'Power Point Presentation', 'Powerpoint', 'Excel Report Preparation', 'Presentation Skills', 'Report Generation', 'MS Office Tools', 'Dashboards', 'MS Office Word']",2025-06-13 05:26:12
Data Catalogue - Analyst,AstraZeneca India Pvt. Ltd,1 - 8 years,Not Disclosed,['Chennai'],"Job Title: Data Catalogue Analyst\nCareer Leve : C3\nIntroduction to role:\nAre you ready to make a significant impact in the world of data management? As a Data Catalogue Analyst, youll play a crucial role in ensuring that data is findable, accessible, and fit for use across various business units. Youll be responsible for capturing metadata and developing our data catalogue, supporting the Commercial and Enabling Units business areas. This is your chance to contribute to meaningful work that drives excellence and breakthroughs.\nAccountabilities:\nSupport the Data Catalogue Principal to define Information Asset Registers across business areas to help profile information risk/value\nParticipate in projects to mitigate and control identified priority risk areas\nTake responsibility for nominated markets/business areas, develop domain knowledge and leverage internal customer relationships to respond to localised use cases\nAct as point of contact for nominated business areas or markets\nSupport initiatives to enhance the reusability and transparency of our data by making it available in our global data catalogue\nSupport the capture of user requirements for functionality and usability, and document technical requirements\nWork with IT partners to capture metadata for relevant data sets and lineage, and populate the catalogue\nWork with data stewards and business users to enrich catalogue entries with business data dictionary, business rules, glossaries\nComplete monitoring controls to assure metadata quality remains at a high level\nSupport catalogue principles and data governance leads for tool evaluation and UAT\nEssential Skills/Experience:\nDemonstrable experience of working in a data management, data governance or data engineering domain\nStrong business and system analysis skills\nDemonstrable experience with Data Catalogue, Search and Automation software (Collibra, Informatica, Talend etc)\nAbility to interpret and communicate technical information into business language and in alignment with AZ business\nSolid grasp of metadata harvesting methodologies and ability to create business and technical metadata sets.\nStrong engagement, communication and collaborator management skills, including excellent organizational, presentation and influencing skills\nHigh level of proficiency with common business applications (Excel, Visio, Word, PowerPoint & SAP business user)\nDesirable Skills/Experience:\nDemonstrable experience of working with Commercial or Finance data and systems (Veeva, Reltio, SAP) and consumption\nDomain knowledge of life sciences/pharmaceuticals; manufacturing; corporate finance; or sales & marketing\nExperience with data quality and profiling software\nExperience of working in a complex, diverse global organization\nAstraZeneca offers an environment where you can apply your skills to genuinely impact patients lives. With a focus on innovation and growth, youll be part of a team that challenges norms and embraces intelligent risks. Our collaborative community thrives on sharing knowledge and celebrating successes together. Here, youll find opportunities to learn from diverse perspectives, drive change, and contribute to our digital transformation journey.\nReady to take the next step in your career? Apply now and become a key player in shaping the future at AstraZeneca!\n11-Jun-2025\n11-Jun-2025",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Automation', 'SAP', 'Data management', 'Senior Analyst', 'Life sciences', 'Corporate finance', 'Data quality', 'Visio', 'Monitoring', 'Recruitment']",2025-06-13 05:26:13
"4 To 8 years of exp. as a Data Analyst @ Banglore, Hyderabad , Chennai",A Client of Career Focus Consultancy,4 - 8 years,5-10 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Strong proficiency in Advanced SQL with experience in writing optimized queries for large datasets.\nMandatory skill : Data Analyst, Python ,SQL, Power BI\n\n\nExposure in, including predictive modeling and machine learning techniques.\n\nRequired Candidate profile\nHands-on experience with Python, R, or similar analytical tools is a plus.\nFamiliarity with cloud platforms such as AWS, Azure, or GCP for data processing and analytics.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['R', 'Power BI', 'Data Analyst', 'Python', 'SQL', 'Azure', 'GCP', 'AWS']",2025-06-13 05:26:15
Data Analyst-Having Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Analyst\n\nLocation: Bangalore\nExperience: 8 - 15 Yrs\nType: Full-time\n\nRole Overview\n\nWe are seeking a skilled Data Analyst to support our platform powering operational intelligence across airports and similar sectors. The ideal candidate will have experience working with time-series datasets and operational information to uncover trends, anomalies, and actionable insights. This role will work closely with data engineers, ML teams, and domain experts to turn raw data into meaningful intelligence for business and operations stakeholders.\n\nKey Responsibilities\n\nAnalyze time-series and sensor data from various sources\nDevelop and maintain dashboards, reports, and visualizations to communicate key metrics and trends.\nCorrelate data from multiple systems (vision, weather, flight schedules, etc) to provide holistic insights.\nCollaborate with AI/ML teams to support model validation and interpret AI-driven alerts (e.g., anomalies, intrusion detection).\nPrepare and clean datasets for analysis and modeling; ensure data quality and consistency.\nWork with stakeholders to understand reporting needs and deliver business-oriented outputs.\n\n\nQualifications & Required Skills\n\nBachelors or Masters degree in Data Science, Statistics, Computer Science, Engineering, or a related field.\n5+ years of experience in a data analyst role, ideally in a technical/industrial domain.\nStrong SQL skills and proficiency with BI/reporting tools (e.g., Power BI, Tableau, Grafana).\nHands-on experience analyzing structured and semi-structured data (JSON, CSV, time-series).\nProficiency in Python or R for data manipulation and exploratory analysis.\nUnderstanding of time-series databases or streaming data (e.g., InfluxDB, Kafka, Kinesis).\nSolid grasp of statistical analysis and anomaly detection methods.\nExperience working with data from industrial systems or large-scale physical infrastructure.\n\n\nGood-to-Have Skills\n\nDomain experience in airports, smart infrastructure, transportation, or logistics.\nFamiliarity with data platforms (Snowflake, BigQuery, Custom-built using open-source).\nExposure to tools like Airflow, Jupyter Notebooks and data quality frameworks.\nBasic understanding of AI/ML workflows and data preparation requirements.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Kafka', 'SQL', 'airports', 'InfluxDB', 'Airflow', 'structured Data', 'time-series', 'JSON', 'Tableau', 'Grafana', 'R', 'AI/ML', 'Kinesis', 'Snowflake', 'time-series databases', 'Data Preparation', 'Python', 'smart infrastructure', 'BigQuery', 'streaming data', 'Power BI', 'CSV', 'transportation', 'logistic', 'reporting tools']",2025-06-13 05:26:17
Data Analyst,B.M. House India limited,2 - 4 years,3.5-4.5 Lacs P.A.,['Bengaluru( HSR Layout )'],"Microsoft Excel (including PivotTables, VLOOKUP/XLOOKUP, Power Query, Macros, and Charts) to analyze and present data. CANVA and Photoshop experience and digital marketing ensure data accuracy and integrity at all times.",Industry Type: Import & Export,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Canva', 'Advanced Excel', 'Power Bi', 'VLOOKUP', 'Data Management', 'Data Analysis', 'Pivot', 'Digital Marketing', 'Data Reporting']",2025-06-13 05:26:18
Data Analyst (1yr+ exp) - Mumbai,Aeke Consultancy,1 - 2 years,1.5-2.25 Lacs P.A.,['Mumbai (All Areas)'],"Hiring: Data Analyst (Bcom candidates only)\nSeeking candidates with 1+ year experience in Power BI, Excel, and Macros.\nBudget: 18,000/month\nLocation: Mumbai\nKindly share your CV via WhatsApp at 9076492644. Calls will not be entertained.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Analysis', 'Excel Macros']",2025-06-13 05:26:20
Data Analyst,Skywings Advisors,4 - 9 years,10-17 Lacs P.A.,['Mumbai'],"Actively work with latest technologies&leading practices specific to analytics,data visualization,AI/ML&RPA to drive strategic benefits in the area of audit quality,efficiency&value creation leading audit related data extractions,enablement,analytics\n\nRequired Candidate profile\nMin 4 yrs relevant data analytics experience,EDW concepts,good understanding of data mining and programming languages such as python, oracle sql\nworking exp with visualization tools power BI,SAP BO",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Data Anlalytics', 'Power Bi', 'Oracle SQL', 'Data Visualization', 'Data Extraction', 'SQL']",2025-06-13 05:26:22
Data Analyst,Flywings Hr Services,10 - 17 years,20-22.5 Lacs P.A.,['Pune'],"we are looking Data analyst who has experienced in Data transformation, Etl, Data modeling at least 5 years experienced & No Sql & Complex database at least 5 Years Experienced",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Transformation', 'NoSQL', 'Data Modeling', 'ETL']",2025-06-13 05:26:23
Data loss prevention Analyst,Forvis Mazars,2 - 5 years,Not Disclosed,['Mumbai (All Areas)'],"Role Overview:\nWe are looking for dedicated professionals to join our DLP Operations Desk in Mumbai. The candidate should have practical experience in managing Data Loss Prevention (DLP) technologies and operational workflows.\nProduct Expertise:\nZscalar\nKey Responsibilities:\nMonitor and analyze DLP alerts and incidents as per established processes.\nInvestigate security incidents, coordinate with stakeholders, and drive closure.\nPrepare and share executive reports of DLP incidents/alerts on a defined schedule.\nContinuously fine-tune and optimize DLP policies based on operational insights, emerging threats, and best practices.\nStay updated with the latest trends in DLP and recommend enhancements to current policies.\n\nRequirements:\n2-5 years experience in security operations with a focus on DLP.\nPrior exposure to DLP tools and incident management processes.\nAnalytical mindset with strong documentation and reporting skills.\nAbility to research and apply best practices to policy management.\nExcellent communication and collaboration skills.",Industry Type: Miscellaneous,Department: Other,"Employment Type: Full Time, Permanent","['Dlp', 'Data Loss Prevention', 'Zscaler', 'Forcepoint']",2025-06-13 05:26:25
Product Data Management / Data Analyst,eClerx,0 - 1 years,Not Disclosed,['Coimbatore'],"Greetings and Wishes from eClerx,\n\nCoimbatore | Full time\n\neClerx is hiring a Product Data Management Analyst who will work within our Product Data Management team to help our customers enhance online product data quality for Electrical, Mechanical & Electronics products. It will also involve creating technical specifications and product descriptions for online presentation. The candidate will also be working on consultancy projects on redesigning e-commerce customers website taxonomy and navigation.",,,,"['Communication Skills', 'Engineering', 'Technical Skills']",2025-06-13 05:26:26
Freelance Online Data Analyst - Hindi Speaker,TELUS Digital,0 - 5 years,Not Disclosed,[],Job description\nAre you a detail-oriented individual with a passion for research and a good understanding of national and local geography? This freelance opportunity allows you to work at your own pace and from the comfort of your own home.\n\n\nA Day in the Life of an Online Data Analyst:,,,,"['Artificial Intelligence', 'Data Analytics', 'Ai Solutions', 'Data Analysis', 'Information Technology']",2025-06-13 05:26:28
Data Analyst Intern,Transasia Bio Medicals,6 months duration,"12,000/month",['Mumbai( Chandivali )'],"Tenure: 6 Months followed by confirmation\nLocation : Chandivali, Powai\n\nKey Responsibilities :\nCollect, clean, and organize data from various sources\nPerform data analysis using Excel, SQL, or Python\nGenerate meaningful insights to support business decisions\nCreate dashboards and visualizations using tools like Power BI/Tableau\nAssist in preparing regular MIS reports and presentations\nWork with cross-functional teams to understand data needs\n\nInterested candidates mail their CVs at m.sneha@transasia.co.in",Industry Type: Pharmaceutical & Life Sciences,Department: Product Management,"Employment Type: Full Time, Permanent","['Product Management', 'Data Analytics']",2025-06-13 05:26:29
Data Analyst - Kannada Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Kannada.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you.\nAnti-virus solution that is kept up to date, with regular scans performed.\nOnly one member per household may apply.\nNB: All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['English', 'Kannada', 'Data Interpretation', 'Data Analysis', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:32
Senior Data Research Analyst,Morningstar,0 - 7 years,Not Disclosed,['Mumbai'],"As a Senior Data Research Analyst , you will be responsible for acquiring and validating portfolio holdings data from various vendor sources. Your core responsibilities will involve standardizing this data into agreed formats using internal collection tools and resolving exceptions through thorough validation processes.\nWorking within the Portfolio Data Team, your role will focus on ensuring the accuracy and completeness of portfolio information, which is critical for downstream analytics and reporting. You will collaborate closely with leadership and cross-functional teams to support strategic goals, enhance operational performance, and contribute to the achievement of key KPIs.\nShift: UK/AU /US\nRoles Responsibilities:\nActively collect managed investment data using Morningstar collection systems, and ensure data timelines, completeness and accuracy to meet business goals.\nManage relationships between Morningstar and Asset Management companies, insurance companies and other data vendors.\nPartner with quality assurance, products, and technical departments to resolve clients data issues timely and effectively.\nP articipat e in the initiative s focused on consolidating global data collection platforms and supporting database integration projects.\nEstablish and achieve the set O bjectives K ey R esults (OKRs) with the direction of team lead.\nMonitor, analyze and execute summary reports including an investigation of potential data error to c ontinuously improve data collection and quality assurance process using L ean S ix S igma tools.\nActively discover and raise issues in work (including system, process, and collection methodology ) and propose enhancement suggestions to further improve system functionality, process efficiency and data quality.\nParticipate in data and process related projects such as industry/market research, market expansion, process certification, new product development support, etc.\nFacilitate cross-team projects to implement approved solutions based on priority and impact .\nDemonstrate a high sense of ownership of the process , u nderstand roles responsibilities by act ing as a process trainer and mentor\nRequirements:\n> 3 years experience in finance domain , w ith emphasis on collection systems and methodologies, senior data research analyst role or above .\nFund Portfolio experience would be preferred\nG ood command i n MS Office (Excel, PowerPoint etc.); advanced users preferred. SQL, Macro or Python and machine learning will be a plus.\nShould be critical thinker and should possess good communication skill .\nShould be equipped with understanding of data competencies like data content expertise , data analysis etc.\nStrong analytical, problem-solving capabilities, and excellent communication written as well as verbal reporting skills.\nShould be a good team player with good learning ability and equipped with self-motivation in an independent, fast-paced work environment.\nAbility to exercise control over the planned activities like training / mentoring new hires, doing quality checks etc .\nAble to work under tight deadlines and handle pressure during peak seasons.\nGood project management skills with proven track record of working on and delivering projects independently.\nRemote team working experience is a plus .\nFlexibility to work in shifts.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Analytical', 'Data collection', 'Market research', 'Data quality', 'Asset management', 'Operations', 'Analytics', 'SQL']",2025-06-13 05:26:33
"Data Analytics Fresher , Data Analyst Fresher",Ablycon Global Angalore,0 - 1 years,4.25-6.5 Lacs P.A.,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","NOTE- Please do not call. Apply through Naukri or email your resume at ankit@ablyconglobal.com. or whatsapp on 9821833955 - Don't CALL Please .\n\n\nJob Title: Data Analytics Fresher\nEmployment Type: Full-Time\nExperience: 0 - 1 Year\nQualification- ANY UG , ANY PG\n\n\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented individual to join our Data Analytics team as a Data Analyst Fresher. This position offers a launchpad into the world of data analytics. Youll work on structured and unstructured datasets, assist in building dashboards and models, and get practical exposure to tools like SQL, Python, and BI platforms. Ideal for someone with a strong analytical foundation and a hunger to grow into a full-stack data professional.\n\nKey Responsibilities:\n\nCollect, organize, and analyze large datasets from various internal and external sources.\nAssist in preparing dashboards, reports, and visualizations to present insights and findings.\nSupport the team in identifying trends, anomalies, and patterns that impact business performance.\nWork with different departments (marketing, sales, operations, etc.) to understand data requirements.\nPerform exploratory data analysis (EDA) to help refine business strategies.\nMaintain and ensure data integrity and consistency across databases and reporting tools.\nSupport the automation of repetitive reporting processes using scripting or BI tools.\n\nRequired Skills & Qualifications:\n\nStrong analytical and problem-solving skills.\nProficiency in Excel and a basic understanding of SQL.\nFamiliarity with data visualization tools (e.g., Tableau, Power BI) is a plus.\nKnowledge of programming languages such as Python or R is an advantage.\nStrong communication skills to explain technical results to non-technical audiences.\nAttention to detail and a strong sense of responsibility.\nEagerness to learn new tools, technologies, and business domains.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Data Analytics', 'Business Analytics', 'Power Bi', 'Artificial Intelligence', 'Data Interpretation', 'Data Management', 'Data Extraction', 'Tableau', 'Machine Learning', 'Statistics', 'data analyst', 'SQL', 'Data Science', 'Excel', 'MySQL', 'Data Analysis', 'Data Visualization', 'Data Processing', 'Python']",2025-06-13 05:26:35
"Senior Data Scientist (AI/ML, Data Analysis, Cloud (AWS), and Model",Synechron,8 - 13 years,Not Disclosed,['Pune'],"job requisition idJR1027352\n\nJob Summary\nSynechron is seeking an analytical and innovative Senior Data Scientist to support and advance our data-driven initiatives. The ideal candidate will have a solid understanding of data science principles, hands-on experience with AI/ML tools and techniques, and the ability to interpret complex data sets to deliver actionable insights. This role contributes to the organizations strategic decision-making and technology innovation by applying advanced analytics and machine learning models in a collaborative environment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCandidates with extensive research or academic experience in AI/ML can be considered, provided they demonstrate practical application of skills.",,,,"['java', 'data science', 'python', 'deploying models', 'aws', 'continuous integration', 'kubernetes', 'scikit-learn', 'ci/cd', 'artificial intelligence', 'sql', 'docker', 'tensorflow', 'spark', 'pytorch', 'keras', 'hadoop', 'big data', 'mongodb', 'microsoft azure', 'nosql', 'pandas', 'amazon ec2', 'r', 'cassandra', 'agile']",2025-06-13 05:26:37
Data Analyst - Kannada Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Kannada.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Kannada', 'Data Analysis', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:39
Data Analyst - Marathi Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Marathi.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['English', 'Data Analysis', 'Marathi', 'Research Analysis', 'Data Management', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:40
Data Analyst - Malayalam Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Malayalam.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Malayalam', 'Data Analysis', 'Data Extraction', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:42
Data Analyst - Gujarati Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Gujarati.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply.\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Freelance/Homebased","['English', 'Gujarati', 'Data Interpretation', 'Data Analysis', 'Research Analysis', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:44
Data Analyst - Marathi Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"O)For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Marathi.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Data Interpretation', 'Data Analysis', 'Marathi', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:45
Data Analyst - Urdu Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Urdu.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Urdu', 'Data Analysis', 'Research Analysis', 'Data Interpretation', 'Analytical', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:47
Data Analyst - Bangla Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\nIdeal Candidate\nFluent in English and Bangla.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Bangla', 'Data Analysis', 'Data Research', 'Research Analysis', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:48
Data Analyst - Odia Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\n\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\n\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\n\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Odia.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['Data Analysis', 'English', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-13 05:26:50
Senior Data Analyst,AstraZeneca India Pvt. Ltd,4 - 7 years,Not Disclosed,"['Chennai', 'Bengaluru']","Job Title: Senior Data Analyst\nCareer Level: D1\nIntroduction to role\nAre you ready to lead the charge in data management excellence? As a Senior Data Analyst, youll be instrumental in driving operational and technical proficiency for the US BBU. Your role is crucial in ensuring data accuracy and efficiency, supporting key business functions to achieve strategic goals. Youll bridge the gap between business collaborators and IT, translating sophisticated needs into actionable data solutions that enhance decision-making. Your analytical prowess will guide the development of innovative data products, influencing business strategy and fostering collaboration across teams. With a focus on leadership, youll mentor a team of data professionals, encouraging continuous improvement and innovation. Are you prepared to deliver clear, actionable insights and drive business transformation?\nAccountabilities\nProvide operational and technical support for US BBU data management activities - data quality management, business process workflows, and data management needs for downstream applications and tools.\nFix and triage operational issues related to data processing, business user queries, data investigation, and ad-hoc analytics.\nPerform data validation, reconciliation, and basic ad-hoc analyses to support business teams.\nAct as a liaison between Commercial/Medical collaborators and IT for customer concerns and issue resolution.\nAssist in handling access, user roles, and updates across platforms like Sharp.\nEssential Skills/Experience\nQuantitative bachelor s degree from an accredited college or university is required in one of the following or related fields: Engineering, Operations Research, Management Science, Economics, Statistics, Applied Math, Computer Science or Data Science. An advanced degree is preferred (Masters, MBA or PhD).\nProficient in PBI, PowerApps [development & fix], SQL, Python, Databricks, and AWS S3 operations.\nStrong understanding of data governance, privacy standards, and operational best practices.\nExcellent communication and influencing skills with consistent record to develop and efficiently.\nExperience working in a business support or operational data management environment.\nOrganization and time management skills.\nDefine and document detailed user stories, acceptance criteria, and non-functional requirements for the data products.\nEngage with cross-functional collaborators to understand their requirements, difficulties, and expectations.\nAdvocate for a user-centric design approach, ensuring that the data products are intuitive, accessible, and meet the needs of the target users.\nCollaborate with the development team to plan and implement agile sprints, ensuring timely delivery of high-quality features.\nSupervise the data product ecosystem s Business architecture, design, and development.\nSupervise industry trends and standard processes in data product development and management.\nCollaborate closely with business collaborators to understand their requirements and translate them into technical solutions.\nSupervise the end-to-end development lifecycle of the data products, from conceptualisation to deployment.\nStrong leadership and communication skills with demonstrated ability to work collaboratively with a significant number of business leaders and cross-functional business partners.\nPresent succinct, compelling reviews of independently developed analyses infused with insight and business implications/actions to be considered.\nStrategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team.\nStrong organizational skills and time management; ability to handle diverse range of simultaneous projects.\nDesirable Skills/Experience\nKnowledge of AZ brand and Science.\nExperience of working with multiple 3rd party providers, including information technology partners.\nStrategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team.\nUnderstanding of US BBU commercial and medical business functions.\nExperience with Sharp [Internal AZ platform] administration, Power Apps development or troubleshooting.\nWhen we put unexpected teams in the same room, we ignite ambitious thinking with the power to encourage life-changing medicines. In-person working gives us the platform we need to connect, work at pace and challenge perceptions. Thats why we work, on average, a minimum of three days per week from the office. But that doesnt mean were not flexible. We balance the expectation of being in the office while respecting individual flexibility. Join us in our outstanding and ambitious world.\nAt AstraZeneca, youll be part of a versatile distributed team that powers our enterprise to better serve patients every day. We demonstrate exciting new technology and digital innovations to accelerate our evolution. With an ambitious spirit that keeps us ahead of the rest, we apply creativity to every task we do. Our fast-paced environment grows with collaboration among bright minds who support each other while pushing forward. Here youll find countless opportunities to build an outstanding reputation while being rewarded for your successes.\nReady to make an impact? Apply now to join our dynamic team!\n11-Jun-2025\n19-Jun-2025",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Business transformation', 'Data management', 'Reconciliation', 'Data processing', 'Troubleshooting', 'Technical support', 'Analytics', 'Recruitment', 'SQL']",2025-06-13 05:26:52
"Senior Data Analyst - Power BI, Data Modeling, Data Visualization",IT Services & Consulting,7 - 10 years,Not Disclosed,"['Mumbai', 'Delhi / NCR', 'Bengaluru']","Job Overview:\nYoull design and implement scalable solutions for award-winning platforms like LMX and MAX, automating media transactions and bridging media buyers and sellers. Work in an Agile, POD-based model to revolutionize the role of data and technology in OOH advertising.\n\nWhat Youll Do:\nArchitect scalable solutions aligned with business goals and market needs.\nLead Agile POD teams to deliver iterative, high-impact solutions.\nEnhance products with advanced features like dynamic rate cards and inventory mapping.\nEnsure best practices in security, scalability, and performance.\n\nWhat You Bring:\nStrong expertise in cloud-based architectures, API integrations, and data analytics.\nProven experience in Agile environments and POD-based execution.\nTechnical proficiency in Java, Angular, Python, and AWS.\n\nRequired Skills:\n8+ years of experience as a Solution Architect.\nBachelors/Masters in Computer Science or related field.\nProficiency in Java, Angular, Python, MongoDB, SQL, NoSQL, and AWS.\nStrong understanding of Agile methodologies and POD-based execution.\n\nTech Stack:\nLanguages: Java, Python\nFrontend: Angular\nDatabases: MongoDB, SQL, NoSQL\nCloud: AWS\nLocation-Remote,Delhi NCR, Bangalore, Chennai, Pune, Kolkata, Ahmedabad, Mumbai, Hyderabad",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Visualization', 'Java', 'NoSQL', 'Power BI', 'Data Analysis', 'MongoDB', 'AWS', 'SQL', 'Python']",2025-06-13 05:26:53
Senior Analyst-Data Analysis,Tesco Plc,3 - 8 years,Not Disclosed,['Bengaluru'],"Senior Analyst-Data Analysis\nBack to job search results\nTesco India Bengaluru, Karnataka, India Hybrid Full-Time Permanent Apply by 30-Jun-2025\nAbout the role\nAnalyse complex datasets and make it consumable using visual storytelling and visualization tools such as reports and dashboards built using approved tools (Tableau, PyDash)\nWhat is in it for you\nAt Tesco, we are committed to providing the best for you.\nAs a result, our colleagues enjoy a unique, differentiated, market- competitive reward package, based on the current industry practices, for all the work they put into serving our customers, communities and planet a little better every day.\nOur Tesco Rewards framework consists of pillars - Fixed Pay, Incentives, and Benefits.\nTotal Rewards offered at Tesco is determined by four principles - simple, fair, competitive, and sustainable.\nSalary - Your fixed pay is the guaranteed pay as per your contract of employment.\nPerformance Bonus - Opportunity to earn additional compensation bonus based on performance, paid annually\nLeave & Time-off - Colleagues are entitled to 30 days of leave (18 days of Earned Leave, 12 days of Casual/Sick Leave) and 10 national and festival holidays, as per the company s policy.\nMaking Retirement Tension-FreeSalary - In addition to Statutory retirement beneets, Tesco enables colleagues to participate in voluntary programmes like NPS and VPF.\nHealth is Wealth - Tesco promotes programmes that support a culture of health and wellness including insurance for colleagues and their family. Our medical insurance provides coverage for dependents including parents or in-laws.\nMental Wellbeing - We offer mental health support through self-help tools, community groups, ally networks, face-to-face counselling, and more for both colleagues and dependents.\nFinancial Wellbeing - Through our financial literacy partner, we offer one-to-one financial coaching at discounted rates, as well as salary advances on earned wages upon request.\nSave As You Earn (SAYE) - Our SAYE programme allows colleagues to transition from being employees to Tesco shareholders through a structured 3-year savings plan.\nPhysical Wellbeing - Our green campus promotes physical wellbeing with facilities that include a cricket pitch, football field, badminton and volleyball courts, along with indoor games, encouraging a healthier lifestyle.\nYou will be responsible for\nUnderstands business needs and in depth understanding of Tesco processes\n- Builds on Tesco processes and knowledge by applying CI tools and techniques.\n- Responsible for completing tasks and transactions within agreed KPIs\n- Solves problems by analyzing solution alternatives\n-Engage with market leaders to understand problems to be solved, translate the business problems to analytical problems, taking ownership of specified analysis and translate the answers back to decision makers in business\n- Manipulating, analyzing and synthesizing large complex data sets using different sources and ensuring data quality and integrity\n- Think beyond the ask and develop analysis and reports that will contribute beyond basic asks\n- Accountable for high quality and timely completion of specified work deliverables and ad-hocs business asks\n- Write codes that are well detailed, structured, and compute efficient\n- Drive value delivery through efficiency gain by automating repeatable tasks, report creation or dashboard refresh\n- Collaborate with colleagues to craft, implement and measure consumption of analysis, reports and dashboards\n- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki\n- Understands business needs and in depth understanding of Tesco processes\n- Responsible for completing tasks and transactions within agreed metrics\n- Experience in handling high volume, time pressured business asks and ad-hocs requests\nYou will need\n2-4 years experience preferred in analysis oriented delivery in any one of domains like retail, cpg, telecom or hospitality and for one of the following functional areas - marketing, supply chain, customer, space range and merchandising, operations, finance or digital will be preferred\nStrong understanding of Business Decisions, Skills to develop visualizations, self-service dashboards and reports using Tableau & Basic Statistical Concepts (Correlation Analysis and Hyp. Testing), Good Skills to analyze data using Adv Excel, Adv SQL, Hive, Phython, Data Warehousing concepts (Hadoop, Teradata), Automation using alteryx, python\n\nAbout us\nTesco in Bengaluru is a multi-disciplinary team serving our customers, communities, and planet a little better every day across markets. Our goal is to create a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility through technological solutions, and empowering our colleagues to do even more for our customers. With cross-functional expertise, a wide network of teams, and strong governance, we reduce complexity, thereby offering high-quality services for our customers.\nTesco in Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 3,30,000 colleagues.\nTesco Business Solutions:\nEstablished in 2017, Tesco Business Solutions (TBS) has evolved from a single entity traditional shared services in Bengaluru, India (from 2004) to a global, purpose-driven solutions-focused organisation. TBS is committed to driving scale at speed and delivering value to the Tesco Group through the power of decision science. With over 4,400 highly skilled colleagues globally, TBS supports markets and business units across four locations in the UK, India, Hungary, and the Republic of Ireland. The organisation underpins everything that the Tesco Group does, bringing innovation, a solutions mindset, and agility to its operations and support functions, building winning partnerships across the business. TBSs focus is on adding value and creating impactful outcomes that shape the future of the business. TBS creates a sustainable competitive advantage for the Tesco Group by becoming the partner of choice for talent, transformation, and value creation\nApply",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Telecom', 'Automation', 'Data analysis', 'Analytical', 'Data quality', 'Teradata', 'Business solutions', 'SQL', 'Python']",2025-06-13 05:26:55
MDM Data Analyst / Steward Lead,Gallagher Service Center (GSC),3 - 7 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\n\nThe MDM Analyst / Data Steward works closely with business stakeholders to understand and gather data requirements, develop data models and database designs, and define and implement data standards, policies, and procedures. This role also implements any rules inside of the MDM tool to improve the data, performs deduplication projects to develop golden records, and overall works towards improving the quality of data in the domain assigned.\n\nRequired skills :\nTechnical Skills: Proficiency in MDM tools and technologies such as Informatica MDM, CluedIn, or similar platforms is essential. Familiarity with data modeling, data integration, and data quality control techniques is also important. Experience with data governance platforms like Collibra and Alation can be beneficial1.\nAnalytical Skills: Strong analytical and problem-solving skills are crucial for interpreting and working with large volumes of data. The ability to translate complex business requirements into practical MDM solutions is also necessary.\nData Management: Experience in designing, implementing, and maintaining master data management systems and solutions. This includes conducting data cleansing, data auditing, and data validation activities.\nCommunication and Collaboration: Excellent communication and interpersonal skills to effectively collaborate with business stakeholders, IT teams, and other departments.\nData Governance: In-depth knowledge of data governance, data quality, and data integration principles. The ability to develop and implement data management processes and policies is essential.\nEducational Background: A Bachelor's or Master's degree in Computer Science, Information Systems, Data Science, or a related field is typically required1.\nCertifications: Certification in the MDM domain (e.g., Certified MDM Professional) can be a plus\n\nKey Skills:\nBecome the expert at the assigned domain of data\nUnderstand all source systems feeding into the MDM\nWrite documentation of stewardship for the domain\nDevelop rules and standards for the domain of data\nGenerate measures of improvement to demonstrate to the business the quality of the data\n\nWe are seeking candidates who can join immediately or within a maximum of 30 days' notice.\nMinimum of 3+ years of relevant experience is required.\nCandidates who are willing to relocate to Bangalore or are already based in Bangalore.\nCandidates should be flexible with working UK/US shifts.",Industry Type: Analytics / KPO / Research,Department: Other,"Employment Type: Full Time, Permanent","['Informatica Mdm', 'Data Modeling', 'Data Integration']",2025-06-13 05:26:57
Business Data Analyst,CGI,5 - 8 years,Not Disclosed,['Hyderabad'],"Business Data Analyst - HealthCare\n\nJob Summary\nWe are seeking an experienced and results-driven Business Data Analyst with 5+ years of hands-on experience in data analytics, visualization, and business insight generation. This role is ideal for someone who thrives at the intersection of business and datatranslating complex data sets into compelling insights, dashboards, and strategies that support decision-making across the organization.\nYou will collaborate closely with stakeholders across departments to identify business needs, design and build analytical solutions, and tell compelling data stories using advanced visualization tools.\nKey Responsibilities\nData Analytics & Insights Analyze large and complex data sets to identify trends, anomalies, and opportunities that help drive business strategy and operational efficiency.\n• Dashboard Development & Data Visualization Design, develop, and maintain interactive dashboards and visual reports using tools like Power BI, Tableau, or Looker to enable data-driven decisions.\n• Business Stakeholder Engagement Collaborate with cross-functional teams to understand business goals, define metrics, and convert ambiguous requirements into concrete analytical deliverables.\n• KPI Definition & Performance Monitoring Define, track, and report key performance indicators (KPIs), ensuring alignment with business objectives and consistent measurement across teams.\n• Data Modeling & Reporting Automation Work with data engineering and BI teams to create scalable, reusable data models and automate recurring reports and analysis processes.\n• Storytelling with Data Communicate findings through clear narratives supported by data visualizations and actionable recommendations to both technical and non-technical audiences.\n• Data Quality & Governance Ensure accuracy, consistency, and integrity of data through validation, testing, and documentation practices.\nRequired Qualifications\nBachelor’s or Master’s degree in Business, Economics, Statistics, Computer Science, Information Systems, or a related field.\n• 5+ years of professional experience in a data analyst or business analyst role with a focus on data visualization and analytics.\n• Proficiency in data visualization tools: Power BI, Tableau, Looker (at least one).\n• Strong experience in SQL and working with relational databases to extract, manipulate, and analyze data.\n• Deep understanding of business processes, KPIs, and analytical methods.\n• Excellent problem-solving skills with attention to detail and accuracy.\n• Strong communication and stakeholder management skills with the ability to explain technical concepts in a clear and business-friendly manner.\n• Experience working in Agile or fast-paced environments.\nPreferred Qualifications\nExperience working with cloud data platforms (e.g., Snowflake, BigQuery, Redshift).\n• Exposure to Python or R for data manipulation and statistical analysis.\n• Knowledge of data warehousing, dimensional modeling, or ELT/ETL processes.\n• Domain experience in Healthcare is a plus.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Bigquery', 'Snowflake', 'Data Warehousing', 'Redshift', 'Python', 'ETL']",2025-06-13 05:26:58
Analyst - Data Analytics,AMERICAN EXPRESS,0 - 4 years,Not Disclosed,['Gurugram'],The American Express Enterprise Digital Experimentation & Analytics (EDEA) leads the Enterprise Product Analytics and Experimentation charter for Brand & Performance Marketing and Digital Acquisition & Membership experiences as we'll as Enterprise Platforms. The focus of this collaborative team is to drive growth by enabling efficiencies in paid performance channels & evolve our digital experiences with actionable insights & analytics. The team specializes in using data around digital product usage to drive improvements in the acquisition customer experience to deliver higher satisfaction and business value.\n,,,,"['Mining', 'Career development', 'Finance', 'Analytical', 'Data processing', 'Analytics', 'SQL']",2025-06-13 05:27:00
Senior Data Analyst-Azure Data Factory,Lumen Technologies,8 - 12 years,Not Disclosed,['Bengaluru'],"Were looking for a Senior Data Analyst with a strong foundation in Azure-based data engineering and Machine Learning to design, develop, and optimize robust data pipelines, applications, and analytics infrastructure. This role demands deep technical expertise, cross-functional collaboration, and the ability to align data solutions with dynamic business needs.\nKey Responsibilities:\nData Pipeline Development:\nDesign and implement efficient data pipelines using Azure Databricks with PySpark to transform and process large datasets.\nOptimize data workflows for scalability, reliability, and performance.\nApplication Integration:\nCollaborate with cross-functional teams to develop APIs using the .NET Framework for Azure Web Application integration.\nEnsure smooth data exchange between applications and downstream systems.\nData Warehousing and Analytics:\nBuild and manage data warehousing solutions using Synapse Analytics and Azure Data Factory (ADF).\nDevelop and maintain reusable and scalable data models to support business intelligence needs.\nAutomation and Orchestration:\nUtilize Azure Logic Apps, Function Apps, and Azure DevOps to automate workflows and streamline deployments.\nImplement CI/CD pipelines for efficient code deployment and testing.\nInfrastructure Management:\nOversee Azure infrastructure management and maintenance, ensuring a secure and optimized environment.\nProvide support for performance tuning and capacity planning.\nBusiness Alignment:\nGain a deep understanding of AMO data sources and their business implications.\nWork closely with stakeholders to provide customized solutions aligning with business needs.\nBAU Support:\nMonitor and support data engineering workflows and application functionality in BAU mode.\nTroubleshoot and resolve production issues promptly to ensure business continuity.\nTechnical Expertise:\nProficiency in Microsoft SQL for complex data queries and database management.\nAdvanced knowledge of Azure Databricks and PySpark for data engineering and ETL processes.\nExperience with Azure Data Factory (ADF) for orchestrating data workflows.\nExpertise in Azure Synapse Analytics for data integration and analytics.\nProficiency in .NET Framework for API development and integration.\nCloud and DevOps Skills:\nStrong experience in Azure Infrastructure Management and optimization.\nHands-on knowledge of Azure Logic Apps, Function Apps, and Azure DevOps for CI/CD automation.\n""We are an equal opportunity employer committed to fair and ethical hiring practices. We do not charge any fees or accept any form of payment from candidates at any stage of the recruitment process. If anyone claims to offer employment opportunities in our company in exchange for money or any other benefit, please treat it as fraudulent and report it immediately.""\n#LI-BS1",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'Automation', 'orchestration', 'Infrastructure management', 'Machine learning', 'Business intelligence', 'Business continuity', 'Analytics', 'Downstream', 'Capacity planning']",2025-06-13 05:27:02
"Senior Python Developer (Machine Learning,Data Analysis,Visualization)",Synechron,3 - 5 years,Not Disclosed,"['Pune', 'Hinjewadi']","Software Requirements\nRequired Skills:\nProficiency in Python (version 3.6+) with experience in data analysis, manipulation, and scripting\nKnowledge of SQL for data extraction, transformation, and database querying\nExperience with data visualization tools such as PowerBI, Tableau, or QlikView\nFamiliarity with AI and Machine Learning frameworks such as TensorFlow, Keras, PyTorch, or equivalent",,,,"['Python', 'PostgreSQL', 'MySQL', 'Data Analysis', 'Data Visualization', 'Oracle', 'ETL', 'Machine Learning']",2025-06-13 05:27:04
Business Data Analyst,NetApp,8 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary\nWe are seeking a highly skilled and experienced Senior Business Data Analyst to join our Entitlement and Install Base Master team. You will play a crucial role in driving the Install Base (IB) data strategy and vision. Your deep understanding of Install Base and Renewals business processes will be instrumental in ensuring accurate and efficient management of our Install Base Data.\nJob Requirements\nDrive the Install Base data strategy and vision, collaborating with cross-functional teams to define and implement data management processes and standards.\nDevelop a comprehensive understanding of the Install Base and Renewals business, including key metrics, processes, and customer lifecycles.\nDrive Enterprise projects ensuring alignment with organizational goals and objectives.\nCollaborate with stakeholders to gather requirements and translate business needs into technical solutions for Install Base data management.\nCollaborate with cross-functional teams to define and implement data governance policies and procedures.\nPerform in-depth data analysis and validation to identify trends, patterns, and insights that drive business decision-making.\nCollaborate with IT teams to enhance data systems and tools supporting Install Base data management, ensuring data quality and accessibility.\nProvide guidance and support to cross-functional teams on Install Base data-related matters, acting as a subject matter expert.\nIdentify opportunities for process improvements and automation to streamline Install Base data management and enhance operational efficiency.\nStay up-to-date with industry trends and best practices in Install Base and Renewals business processes and data management.\nCoach and mentor team members to foster their professional growth and ensure smooth operations, promoting a collaborative and high-performing environment.\n",,,,"['data analysis', 'data management', 'analytical', 'workflow', 'business requirements', 'install base', 'sql querying', 'renewals', 'relational databases', 'sql', 'data cleansing', 'data quality', 'business process', 'management', 'collaboration', 'business data analysis', 'data governance', 'communication skills']",2025-06-13 05:27:06
Business Partner Master Data Analyst Associate,Westlake Epoxy,2 - 7 years,Not Disclosed,['Bengaluru'],"Westlake offers you the potential to enrich your work life and career experience in an entrepreneurial environment. We work together to enhance peoples lives through our products and presence in the communities in which we operate.\nBusiness Partner Master Data Analyst Associate\nBusiness Partner Master Data Analyst is part of a global team who establishes and follows procedures that maintain the integrity of data for Customer and Vendor master data in SAP. These procedures allow business objectives to be met and to be compliant to (regional) Government regulations and Westlake Epoxy regulations. The Customer and Vendor Master Analyst role is the key for setting up a good foundation for further execution of the business processes.\nEssential Functions\nTasks:\nCreate, change, or delete Customer/Supplier records following approval workflows and document verification.\nManage partner functions and ensure compliance with SOPs and Westlake Safety & Integrity policies.\nSystem Skills:\nProficiently use systems like ECC, S4 HANA, and Fiori.\nData Quality:\nMaintain high-quality master data according to KPIs.\nRegularly check and verify system parameters against process updates.\nPerform mass changes to master data under supervision.\nKey Relationships / Collaboration:\nWork closely with Customer Service, Master Data, IT, Procurement Operations, Procurement, and Finance.\nSupport:\nCommunicate with internal customers based on business needs.\nValidate active accounts according to business rules.\nBlock inactive accounts in SAP during Annual block/deletion program.\nBusiness Support:\nProactively address system errors or process gaps by escalating to relevant key users for resolution.\nQualification:\nAny degree with minimum 2 years experience in a functional area.\nFluent language skills in English, both verbal and written.\nProficient in Microsoft Office and Outlook.\nSAP functional knowledge required i.e. Master Data.\nIntermediate skills in Microsoft Excel.\nPositive attitude and strong customer focus.\nGood organizational and communication skills.\nProactive and solution focused.\nAttentive to details, able to work accurately.\nAbility to work under pressure, time sensitive environment showing high level of flexibility.\nTeam player.\nWestlake is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to any characteristics protected by applicable legislation.\nIf you are an active Westlake employee (or an employee of any Westlake affiliates), please do not apply here. You will apply via the Jobs Hub application in Workday.",Industry Type: Chemicals,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Master Analyst', 'SAP', 'Excel', 'IT procurement', 'business rules', 'document verification', 'Data quality', 'Data Analyst', 'Customer service', 'MS Office']",2025-06-13 05:27:08
Business Partner Master Data Analyst Associate,Westlake Chemical,2 - 7 years,Not Disclosed,['Bengaluru'],"Westlake offers you the potential to enrich your work life and career experience in an entrepreneurial environment. We work together to enhance peoples lives through our products and presence in the communities in which we operate.\nBusiness Partner Master Data Analyst Associate\nBusiness Partner Master Data Analyst is part of a global team who establishes and follows procedures that maintain the integrity of data for Customer and Vendor master data in SAP. These procedures allow business objectives to be met and to be compliant to (regional) Government regulations and Westlake Epoxy regulations. The Customer and Vendor Master Analyst role is the key for setting up a good foundation for further execution of the business processes.\nEssential Functions\nTasks:\nCreate, change, or delete Customer/Supplier records following approval workflows and document verification.\nManage partner functions and ensure compliance with SOPs and Westlake Safety & Integrity policies.\nSystem Skills:\nProficiently use systems like ECC, S4 HANA, and Fiori.\nData Quality:\nMaintain high-quality master data according to KPIs.\nRegularly check and verify system parameters against process updates.\nPerform mass changes to master data under supervision.\nKey Relationships / Collaboration:\nWork closely with Customer Service, Master Data, IT, Procurement Operations, Procurement, and Finance.\nSupport:\nCommunicate with internal customers based on business needs.\nValidate active accounts according to business rules.\nBlock inactive accounts in SAP during Annual block/deletion program.\nBusiness Support:\nProactively address system errors or process gaps by escalating to relevant key users for resolution.\nQualification:\nAny degree with minimum 2 years experience in a functional area.\nFluent language skills in English, both verbal and written.\nProficient in Microsoft Office and Outlook.\nSAP functional knowledge required i.e. Master Data.\nIntermediate skills in Microsoft Excel.\nPositive attitude and strong customer focus.\nGood organizational and communication skills.\nProactive and solution focused.\nAttentive to details, able to work accurately.\nAbility to work under pressure, time sensitive environment showing high level of flexibility.\nTeam player.\nWestlake is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to any characteristics protected by applicable legislation.\nIf you are an active Westlake employee (or an employee of any Westlake affiliates), please do not apply here. You will apply via the Jobs Hub application in Workday.",Industry Type: Chemicals,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Master Analyst', 'SAP', 'Excel', 'IT procurement', 'business rules', 'document verification', 'Data quality', 'Data Analyst', 'Customer service', 'MS Office']",2025-06-13 05:27:09
Cloud Security Compliance and Data Analyst,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"Generate compliance reports from an existing dashboard or build requirements to create a new reporting dashboard\n\nProactively Monitor, track, and report on security compliance status across systems and processes.\n\nAnalyze large datasets to identify trends, anomalies, and compliance risks.\n\nSupport security audits, assessments, and certification efforts through data collection and analysis.\n\nPossess strong communication skill, collaborate with cross-functional matrix teams to drive root cause analysis, corrective actions and improvements based on data insights.\n\nMaintain and enhance compliance reporting dashboards and metrics for leadership visibility and decision making.\n\n\nRequired education\nBachelor's Degree\n\nRequired technical and professional expertise\n\nExperience working with security architects and technical security teams to define and implement security processes and procedures based on industry-standard best practices and compliance requirements. Defining the requirements and validating the procedures and audit testing methodology\n\nWorking with the Development teams to ensure automation of evidence collection and evidence management is always in line with compliance expectations, otherwise, identifies specific actions and owners to meet the expectations.\n\nAssisting team members in addressing highly complex security issues applicable to enterprise environment\n\nAbility to utilize project management principles to properly scope compliance work efforts by service lines, identify common areas of work, and create a measurable milestone plans across service lines to enable completion of compliance work items on time.\n\nAbility to manage multiple priority projects simultaneously under a short timeline\n\nExperience/familiar with enterprise risk management (ERM) framework, service delivery operations, software development lifecycle and be able to understand when to request and integrate risk items into compliance reporting.\n\nExperience with compliance programs such as FedRAMP/ FISMA, HIPAA, GDPR, SOC 2, PCI, NIST, ISO, ITAR, etc.\n\nConducting regular reviews on compliance progression of systems and hosting internal audit/assessment as required to maintain compliance certifications.\n\nAbility to translate and interpret regulatory compliance requirements into technical controls\n\nAbility to understand cloud enterprise business computing operations/requirements, and effectively communicate to service lines what is expected in order to consider a work item complete. Also, will possess good understanding of networking security including security systems such as firewalls, intrusion detection, vulnerability scanning, OS patching, health-checking\n\nDiagnosing the root cause of problems and propose solutionsExamples would be failed patches, tooling issues, false positives on system tests, authentication problems. Drive and track audit, security and compliance finding remediation to closure.\n\nExperience with enterprise configuration Management  database (CMDB) or  IT Asset inventory Management. Understand CMDB's structure, data quality, relationships between CIs (Configuration Items), and updates. Use the CMDB for risk, audit, and compliance analysis and reporting\n\nProficiency in SQL, Excel (advanced levelpivot tables, macros), and ServiceNow— data analytics and visualization functionalities\n\nAbility to process large datasets, identify and handle missing data, data transformation, normalization, and data quality checks.\n\nAbility to perform data analysis to discover patterns and trends to mitigate security risks and drive business results\n\nWork with stakeholders to define key metrics and KPIs; develop dashboards and reports for business users.\n\nCollaborate with database engineers, data owners, security focal, product managers, and broader metrics teams to understand data needs.\n\nResults oriented with intense focus on achieving both short and long term goals. He/she should be able to drive and execute an agenda in a fast paced, dynamic environment.\n\nStrong project management skills with ability to design visual and appealing presentations\n\nStrong collaboration, problem-solving and critical-thinking abilities.\n\nExcellent communication skills — ability to explain technical findings to non-technical audiences.\n\nGood time management, organizational skills, and ability to prioritize tasks.\n\nCuriosity and a continuous learning mindset.\n\nA highly organized with strong attention to detail, analytical and project management skills\n\nWork independently within a team focused organization.\n\n\n\n\nPreferred technical and professional experience\n\nExperience or familiar with cloud service models; IaaS preferred.\n\nProject management and consulting experience is a plus\n\nExperience with process automation is a plus\n\nExperience with Linux Shell, Perl or Python is a plus",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'python', 'hipaa', 'sql', 'nist', 'soc', 'cmdb', 'cis', 'it asset', 'gdpr', 'configuration management', 'software development life cycle', 'data quality', 'firewall', 'pci', 'enterprise risk management', 'perl', 'iaas', 'fedramp', 'linux shell', 'inventory management']",2025-06-13 05:27:11
Reference Data Analyst,JPMorgan Chase Bank,2 - 7 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","You are a strategic thinker passionate about driving solutions. You have found the right team.\nAs a Reference Data Analyst within our team, you will ensure all client queries and actioned and responded with utmost care and diligence. You will facilitate high quality and timely completion of all client requests. You must display great client service standards to define, analyse, to resolve inquiries and escalations. You should be able to closely manage day to day operations of the team/department, be able to proactively and strategically improve processes to ensure team members are high performing and meeting the firm wide quality standard.\nJob Responsibilities\nUnderstanding and implementation of custody initiations world overing custody and sub custody account opening and maintenance related activities.\nUnderstand the firm s requirements and various smart forms and articulate the same to end clients and guide them through completion.\nPartner with Clients, Sales, Solutions, Implementations, Client Service Managers and downstream teams for seamless completion of the assigned task.\nExhibit the highest standards of customer service to our internal and external customers (inclusive of confidentiality)\nCreate an effective and efficient team through continuous communication, timely feedback, and appropriate supervisory practices\nShowcase Process improvements and implement process changes as necessary\nRequired Qualifications, Capabilities, and skills\nYou must hold a Bachelor s Degree or above\nAt least 2 years experience in the Financial Services industry with a demonstrated track-record of delivery and/or relevant experience in custody domain.\nTechnical skills Microsoft Office including Excel, Word, and PowerPoint\nOutstanding client management, partnership building, leadership, and direct experience of dealing with stakeholders using effective communication, organization, prioritization and interpersonal skills\nAbility to identify risks, issues and successfully navigate through to completion\nSelf-reliance and willingness to ""own"" complications and creatively find solutions\nFoster and champion High Performance Culture where people are empowered to make decisions that affect their work/environment",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Interpersonal skills', 'Excel', 'Client servicing', 'Data Analyst', 'Customer service', 'MS Office', 'Powerpoint', 'Financial services', 'Client management', 'Downstream']",2025-06-13 05:27:13
"Data Analyst, Staff",Qualcomm,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Miscellaneous Group, Miscellaneous Group > Data Analyst\n \n\nQualcomm Overview: \nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.\n\nGeneral Summary:\n\nAbout the Team\n\nQualcomm's People Analytics team plays a crucial role in transforming data into strategic workforce insights that drive HR and business decisions. As part of this lean but high-impact team, you will have the opportunity to analyze workforce trends, ensure data accuracy, and collaborate with key stakeholders to enhance our data ecosystem. This role is ideal for a generalist who thrives in a fast-paced, evolving environment""”someone who can independently conduct data analyses, communicate insights effectively, and work cross-functionally to enhance our People Analytics infrastructure.\n\nWhy Join Us\n\n\nEnd-to-End ImpactWork on the full analytics cycle""”from data extraction to insight generation""”driving meaningful HR and business decisions.\n\n\nCollaboration at ScalePartner with HR leaders, IT, and other analysts to ensure seamless data integration and analytics excellence.\n\n\nData-Driven CultureBe a key player in refining our data lake, ensuring data integrity, and influencing data governance efforts.\n\n\nProfessional GrowthGain exposure to multiple areas of people analytics, including analytics, storytelling, and stakeholder engagement.\n\n\nKey Responsibilities\n\n\nPeople Analytics & Insights\nAnalyze HR and workforce data to identify trends, generate insights, and provide recommendations to business and HR leaders.\nDevelop thoughtful insights to support ongoing HR and business decision-making.\nPresent findings in a clear and compelling way to stakeholders at various levels, including senior leadership.\n\n\nData Quality & Governance\nEnsure accuracy, consistency, and completeness of data when pulling from the data lake and other sources.\nIdentify and troubleshoot data inconsistencies, collaborating with IT and other teams to resolve issues.\nDocument and maintain data definitions, sources, and reporting standards to drive consistency across analytics initiatives.\n\n\nCollaboration & Stakeholder Management\nWork closely with other analysts on the team to align methodologies, share best practices, and enhance analytical capabilities.\nAct as a bridge between People Analytics, HR, and IT teams to define and communicate data requirements.\nPartner with IT and data engineering teams to improve data infrastructure and expand available datasets.\n\n\nQualifications\n\nRequired4-7 years experience in a People Analytics focused role\n\n\nAnalytical & Technical Skills\nStrong ability to analyze, interpret, and visualize HR and workforce data to drive insights.\nExperience working with large datasets and ensuring data integrity.\nProficiency in Excel and at least one data visualization tool (e.g., Tableau, Power BI).\n\n\nCommunication & Stakeholder Management\nAbility to communicate data insights effectively to both technical and non-technical audiences.\nStrong documentation skills to define and communicate data requirements clearly.\nExperience collaborating with cross-functional teams, including HR, IT, and business stakeholders.\n\n\nPreferred:\n\n\nTechnical Proficiency\nExperience with SQL, Python, or R for data manipulation and analysis.\nFamiliarity with HR systems (e.g., Workday) and cloud-based data platforms.\n\n\nPeople Analytics Expertise\nPrior experience in HR analytics, workforce planning, or related fields.\nUnderstanding of key HR metrics and workforce trends (e.g., turnover, engagement, diversity analytics).\n\n\nAdditional Information\nThis is an office-based position (4 days a week onsite) with possible locations that may include India and Mexico",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'people analytics', 'documentation', 'tableau', 'data integration tools', 'hiring', 'data warehousing', 'data architecture', 'sourcing', 'jquery', 'staffing', 'plsql', 'oracle 10g', 'java', 'etl tool', 'html', 'etl', 'mongodb', 'python', 'oracle', 'power bi', 'hrsd', 'r', 'node.js', 'hr analytics', 'angularjs']",2025-06-13 05:27:15
Sr. Data Analyst -ETL,HTC Global Services,5 - 10 years,Not Disclosed,['Chennai'],"Seeking a highly skilled Sr. Data Analyst - ETL with 5 years of experience to join our dynamic team.\nRequirements:\nAt least 5 years of experience in Data Analyst is mandatory.\nExposure in ETL preferably DataStage.\nExtensive experience with Data Cleansing, Data validation, Data Mapping Solutioning, ETL QA.\nProficient in SQL (Snowflake, SQL server, Oracle SQL/ PL SQL).\nMust have experience in Autosys, Snowflake and AWS.",,,,"['data cleansing', 'Data validation', 'Regulatory reporting', 'Datastage', 'Senior Data Analyst', 'PLSQL', 'Data Analyst', 'Investment banking', 'Asset management', 'data mapping']",2025-06-13 05:27:16
Data Research Analyst (BPO Non-Voice) - Immediate Joiners,Trupp Global Technologies,0 - 4 years,2.5-4.5 Lacs P.A.,[],"Role & responsibilities\nWe're hiring a Data Research Analyst to join our Research & Data Services team. This role involves gathering and analyzing information about companies from the web including crafting short descriptions about companies, tracking investments and funding rounds, mergers & acquisitions, and other key corporate events.\nIf you have a knack for internet research, a love for data accuracy, and an interest in the world of startups, finance, and business, this could be a great fit.\n\nWhat You'll Do\nConduct internet research to collect accurate information about companies across sectors.\nTrack and record business events such as Venture funding(Seed, Series A, B, etc), Mergers and acquisitions, IPOs and executive changes.\nWrite clear and concise company descriptions based on publicly available data. Research online and create relevant content as per style, tone, and requirements.\nOrganize data in spreadsheets or internal databases with precision.\nVerify and validate data from multiple sources for consistency and reliability.\nCollaborate with the quality assurance team to ensure data integrity.\n\n\nPreferred candidate profile\n0 - 4 years of experience in a data research, web research, or business intelligence role.\nExcellent written English and ability to summarize complex information quickly.\nFamiliarity with business and financial terms.\nProficient in tools like Google Search, LinkedIn, Pitchbook, Company Websites, business information sites and Excel/Google Sheets.\nStrong attention to detail and ability to meet deadlines.\n\nNice to Have\nBackground in business, finance, Journalism and content writing\nExperience using tools like PitchBook, Owler, or similar research platforms.\nPrior experience in a BPO/KPO or analytics environment.",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Internet Research', 'Research Analysis', 'Data Mining', 'Content Writing', 'Written Communication', 'Bpo Non Voice']",2025-06-13 05:27:18
"Data Analyst, Lead",Lam Research,5 - 10 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\nIn the Global Products Group, we are dedicated to excellence in the design and engineering of Lams etch and deposition products. We drive innovation to ensure our cutting-edge solutions are helping to solve the biggest challenges in the semiconductor industry.\nThe Impact You ll Make\nJoin Lam as an Operations Business Analyst, where youll spearhead process improvement initiatives. With your data expertise, you collect and analyze data through a range of Business Intelligence (BI) tools and apps, develop metrics, and identify root causes with data-driven indicators for future improvements. Organizing cross-functional project teams, you communicate team progress and survey best practices, showcasing your commitment to operational excellence at Lam.\nWhat You ll Do\nWho We re Looking For\nMinimum of 5 years of related experience with a Bachelor s degree; or 3 years and a Master s degree; or a PhD without experience; or equivalent work experience.\nPreferred Qualifications\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent","['Semiconductor', 'Operational excellence', 'Business Analyst', 'Process improvement', 'Flex', 'Data Analyst', 'Research', 'Business intelligence']",2025-06-13 05:27:20
"Data Analyst, Program Lead",Lam Research,9 - 12 years,Not Disclosed,['Bengaluru'],"About LIDAS:\nLIDAS (Lam India Data Analytics and Sciences) team is responsible to provide best-in-class analytics solutions that help improve business decisions in Global Operations and other business sub-functions across Lam. This Organization, a Center of Excellence (CoE), consists of a high-performing team of experts who collaborate cross-functionally and provide analytics solutions to various business functions to suit their business needs. This team strives to improve the productivity & efficiency of business processes through business analytics, data science & automation projects. The resulting projects help accelerate businesses/stakeholders in decision-making by providing data insights. The team continuously develops the required technical skills and business acumen to help solve complex business problems & Use Cases in the semiconductor, manufacturing, and supply chain domains for the company.\nEligibility Criteria:\nYears of Experience : Minimum 9-12 years\nJob Experience: Experience with Power Platform (Power Apps, Power Automate & Power BI)\nExpert in Database and Data warehouse tech (Azure Synapse/ SQL Server/SAP HANA)\nData Analysis/Data Profiling/Data Visualization\nEducational : Bachelor s Degree: Math/Statistics/Operations Research/Computer Science\nMaster s Degree : Business Analytics (with a background in Computer Science)\nPrimary Responsibilities:\nAbility to interact closely with Business Stakeholder on understanding their business requirements and converting them into opportunity.\nLeading POCs to create break through technical solutions, performing exploratory and targeted data analyses.\nAbility to Manage and support existing applications and implementing the best practices on timely Manner.\nDesigns, Develops, and Tests Data Models to import data from source systems to meet Project requirements\nEffectively analyzes the heterogeneous source data and writes SQL scripts to integrate data from multiple data sources\nAnalyzes the results to generate actionable insights and presents the findings to the business users for informed decision making\nUnderstands business requirements and develops dashboards to meet business needs\nAdapts to the changing business requirements and supports the development and implementation of best-known methods with respect to data analytics\nPerforms Data mining which provides actionable data in response to changing business requirements\nMigrates data into standardized platforms (Power BI) and builds critical data models to improve process performance and product quality\nOwns technical implementation and documentation associated with datasets\nProvides updates on project progress, performs root cause analysis on completed projects and works on identified improvement areas (like process, product quality, performance, etc.)\nProvides post-implementation support and ensures the target project benefits are successfully delivered in a robust and sustainable fashion.\nBuilds relationships and partners effectively with cross-functional teams to ensure available data is accurate, consistent and timely\nIndependently manages expectations from stakeholders, optimally utilizes time for larger initiatives with minimal guidance on prioritization or dependencies\nProvides mentorship and guidance to peers and junior team members\nMandatory Skills required to perform the job:\nKnowledge on the software development lifecycle expert in translating business requirements into technical solutions; and fanatical about quality, usability, security and scalability\nStrong Knowledge on Python and PySpark.\nSpecialist in Power Platform (Power Apps & Power Automate)\nExpert in Reports & Dashboard development (Power BI) and ETL tools (SAP DS, SSIS)\nData Analysis skills, experience in extracting information from databases, Office 365\nKnowledge of SAP systems (SAP ECC T-Codes & Navigation)\nExpert in Data Base Development, Troubleshooting & Problem-solving skills (SQL Server, SAP HANA, Azure Synapse)\nExperience in project requirements gathering and converting business requirements into analytical & technical specs.\nGood understanding of business processes and experience in Manufacturing/Inventory Management domains\nKnowledge in performing Root cause analysis and Corrective actions\nExcellent verbal and written communication & presentation skills, able to communicate cross-functionally\nDesirable Skills:\nAgile/SCRUM development using any tools.\nUnderstanding of enterprise server architecture, cloud platforms\nExperience in advanced analytics techniques using Statistical analysis\nAbility to deliver training and presentations in the area of expertise\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Data analysis', 'Database', 'Flex', 'SSIS', 'Troubleshooting', 'Data mining', 'Data warehousing', 'SQL', 'Python']",2025-06-13 05:27:22
"Sr. Data Analyst – Tableau, SQL, Snowflake",Int9 Solutions,5 - 7 years,Not Disclosed,['Bengaluru'],"We are looking for a skilled Data Analyst with excellent communication skills and deep expertise in SQL, Tableau, and modern data warehousing technologies. This role involves designing data models, building insightful dashboards, ensuring data quality, and extracting meaningful insights from large datasets to support strategic business decisions.\n\nKey Responsibilities:\nWrite advanced SQL queries to retrieve and manipulate data from cloud data warehouses such as Snowflake, Redshift, or BigQuery.\nDesign and develop data models that support analytics and reporting needs.\nBuild dynamic, interactive dashboards and reports using tools like Tableau, Looker, or Domo.\nPerform advanced analytics techniques including cohort analysis, time series analysis, scenario analysis, and predictive analytics.\nValidate data accuracy and perform thorough data QA to ensure high-quality output.\nInvestigate and troubleshoot data issues; perform root cause analysis in collaboration with BI or data engineering teams.\nCommunicate analytical insights clearly and effectively to stakeholders.\n\nRequired Skills & Qualifications:\nExcellent communication skills are mandatory for this role.\n5+ years of experience in data analytics, BI analytics, or BI engineering roles.\nExpert-level skills in SQL, with experience writing complex queries and building views.\nProven experience using data visualization tools like Tableau, Looker, or Domo.\nStrong understanding of data modeling principles and best practices.\nHands-on experience working with cloud data warehouses such as Snowflake, Redshift, BigQuery, SQL Server, or Oracle.\nIntermediate-level proficiency with spreadsheet tools like Excel, Google Sheets, or Power BI, including functions, pivots, and lookups.\nBachelor's or advanced degree in a relevant field such as Data Science, Computer Science, Statistics, Mathematics, or Information Systems.\nAbility to collaborate with cross-functional teams, including BI engineers, to optimize reporting solutions.\nExperience in handling large-scale enterprise data environments.\nFamiliarity with data governance, data cataloging, and metadata management tools (a plus but not required).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Tableau', 'Data Warehousing', 'Data Analytics', 'SQL', 'Scenario Analysis', 'Cohort Analysis', 'Data Modeling', 'Predictive Analysis', 'Redshift']",2025-06-13 05:27:23
"Sr. Data Analyst – Tableau, SQL, Snowflake",Int9 Solutions,5 - 10 years,Not Disclosed,"['Mumbai', 'Delhi / NCR', 'Bengaluru']","We are looking for a skilled Data Analyst with excellent communication skills and deep expertise in SQL, Tableau, and modern data warehousing technologies. This role involves designing data models, building insightful dashboards, ensuring data quality, and extracting meaningful insights from large datasets to support strategic business decisions.\n\nKey Responsibilities:\nWrite advanced SQL queries to retrieve and manipulate data from cloud data warehouses such as Snowflake, Redshift, or BigQuery.\nDesign and develop data models that support analytics and reporting needs.\nBuild dynamic, interactive dashboards and reports using tools like Tableau, Looker, or Domo.\nPerform advanced analytics techniques including cohort analysis, time series analysis, scenario analysis, and predictive analytics.\nValidate data accuracy and perform thorough data QA to ensure high-quality output.\nInvestigate and troubleshoot data issues; perform root cause analysis in collaboration with BI or data engineering teams.\nCommunicate analytical insights clearly and effectively to stakeholders.\n\nRequired Skills & Qualifications:\nExcellent communication skills are mandatory for this role.\n5+ years of experience in data analytics, BI analytics, or BI engineering roles.\nExpert-level skills in SQL, with experience writing complex queries and building views.\nProven experience using data visualization tools like Tableau, Looker, or Domo.\nStrong understanding of data modeling principles and best practices.\nHands-on experience working with cloud data warehouses such as Snowflake, Redshift, BigQuery, SQL Server, or Oracle.\nIntermediate-level proficiency with spreadsheet tools like Excel, Google Sheets, or Power BI, including functions, pivots, and lookups.\nBachelor's or advanced degree in a relevant field such as Data Science, Computer Science, Statistics, Mathematics, or Information Systems.\nAbility to collaborate with cross-functional teams, including BI engineers, to optimize reporting solutions.\nExperience in handling large-scale enterprise data environments.\nFamiliarity with data governance, data cataloging, and metadata management tools (a plus but not required).\nLocation : - Mumbai, Delhi / NCR, Bengaluru , Kolkata, Chennai, Hyderabad, Ahmedabad, Pune, Remote",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Tableau', 'SQL', 'BI Tools', 'Scenario Analysis', 'Cohort Analysis', 'Data Warehousing', 'SQL Server', 'Data Modeling', 'Data Analytics', 'Predictive Analysis', 'Redshift']",2025-06-13 05:27:25
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Gurugram'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nChennai\nData Engineer with Neo4j\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nGurugram, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-13 05:27:26
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Chennai'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nGurugram\nData Engineer with Neo4j\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nChennai, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Chennai\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-13 05:27:28
Senior Data Analyst Bangalore,GSPANN,5 - 10 years,13-22.5 Lacs P.A.,['Bengaluru'],"Job Opportunity: Senior Data Analyst Bangalore\n\n\nLocation: Bangalore, India\n\n\nCompany: GSPANN Technologies\nApply: Send your resume to heena.ruchwani@gspann.com\n\n\nGSPANN is hiring a Senior Data Analyst with 57 years of experience to join our dynamic team in Bangalore!\n\n\nWhat Were Looking For:\n\nEducation:\nBachelor’s degree in Computer Science, MIS, or a related field\n\nExperience:\n5–7 years in data analysis, with a strong ability to translate business strategy into actionable insight\nAdvanced SQL expertise\nProficiency in Tableau, Power BI, or Domo\nExperience with AWS, Hive, Snowflake, Presto\nAbility to define and track KPIs across domains like Sales, Consumer Behavior, and Supply Chain\nStrong problem-solving skills and attention to detail\nExcellent communication and collaboration abilities\nExperience working in Agile environments\nRetail or eCommerce domain experience is a plus\n\nIf this sounds like the right fit for you, don’t wait—send your updated resume to heena.ruchwani@gspann.com today!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'SQL', 'Hive', 'Presto', 'Snowflake', 'Statistical Modeling', 'Data Visualization', 'Tableau', 'Data Analytics', 'AWS', 'Python']",2025-06-13 05:27:30
Data Analyst - Senior,FedEx,4 - 7 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nAct as a technical expert on complex and specialist subject(s).\nSupport management with the analysis, interpretation and application of complex information, contributing to the achievement of divisional and corporate goals. Supports or leads projects by applying area of expertise.\nLead and implement advanced analytical processes through data/text mining, model development, and prediction to enable informed business decisions.\nApply sound analytical expertise to examine structured and unstructured data from multiple disparate sources to provide insights and recommend high-quality solutions to leadership across levels.\nPlan initiatives from concept to execution with minimal supervision and communicate results to a broad range of audiences. Develops a superior understanding of pricing and revenue management through internal and external sources to creatively solve business problems and lead the team from concept to execution of projects.\nTypically uses data, statistical and quantitative analysis, modeling, and fact-based management to drive decision-making. Provides regular expert consultative advice to senior leadership.\nEffectively shares best practices and fosters knowledge sharing across teams. Provides crossteam and cross-org consultation and supports communities of practice excellence.\n\n\n\nPreferred candidate profile\n\nRelevant experience in analytics/consulting/informatics and statistics\nKey Skills - Data and Business Analytics, Advanced Statistics and Predictive Modelling,\nStakeholder Management, Project Management\nExperience in pricing and revenue management yield management, customer segmentation analytics, revenue impact analytics, etc. is a plus\nExposure to predictive analytics, ML/ AI techniques is an added advantage\nTools - Oracle, SQL Server, Teradata, SAS, Python, Tableau/PowerBI/Spotfire\nGood to have cloud computing, big data, Azure",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Business Insights', 'Python', 'SQL', 'Power Bi', 'Business Acumen', 'Tableau']",2025-06-13 05:27:32
"Senior Manager- Middle and Back Office Data Analyst- ISS,",Fidelity International,10 - 15 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Title: Middle and Back Office Data Analyst - ISS Data (Senior Manager)\nDepartment: Technology\nLocation: Bangalore & Gurgaon (hybrid / flexible working permitted)\nReports To: Middle and Back Office Data Product Owner\nLevel: Senior Manager\nWe re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our [insert name of team/ business area] team and feel like you re part of something bigger.\nAbout your team\nThe Technology function provides IT services that are integral to running an efficient run-the business operating model and providing change-driven solutions to meet outcomes that deliver on our business strategy. These include the development and support of business applications that underpin our revenue, operational, compliance, finance, legal, marketing and customer service functions. The broader organisation incorporates Infrastructure services that the firm relies on to operate on a day-to-day basis including data centre, networks, proximity services, security, voice, incident management and remediation.\nThe ISS Technology group is responsible for providing Technology solutions to the Investment Solutions & Services (ISS) business (which covers Investment Management, Asset Management Operations & Distribution business units globally)\n\nThe ISS Technology team supports and enhances existing applications as well as designs, builds and procures new solutions to meet requirements and enable the evolving business strategy.\nAs part of this group, a dedicated ISS Data Programme team has been mobilised as a key foundational programme to support the execution of the overarching ISS strategy.\nAbout your role\nThe Middle and Back Office Data Analyst role is instrumental in the creation and execution of a future state design for Fund Servicing & Oversight data across Fidelity s key business areas. The successful candidate will have an in- depth knowledge of data domains that represent Middle and Back-office operations and technology.\nThe role will sit within the ISS Delivery Data Analysis chapter and fully aligned to deliver Fidelity s cross functional ISS Data Programme in Technology, and the candidate will leverage their extensive industry knowledge to build a future state platform in collaboration with Business Architecture, Data Architecture, and business stakeholders.\nThe role is to maintain strong relationships with the various business contacts to ensure a superior service to our clients.\nData Product - Requirements Definition and Delivery of Data Outcomes\nAnalysis of data product requirements to enable business outcomes, contributing to the data product roadmap\nCapture both functional and non-functional data requirements considering the data product and consumers perspectives.\nConduct workshops with both the business and tech stakeholders for requirements gathering, elicitation and walk throughs.\nResponsible for the definition of data requirements, epics and stories within the product backlog and providing analysis support throughout the SDLC.\nResponsible for supporting the UAT cycles, attaining business sign off on outcomes being delivered\nData Quality and Integrity:\nDefine data quality use cases for all the required data sets and contribute to the technical frameworks of data quality.\nAlign the functional solution with the best practice data architecture & engineering principles.\nCoordination and Communication:\nExcellent communication skills to influence technology and business stakeholders globally, attaining alignment and sign off on the requirements.\nCoordinate with internal and external stakeholders to communicate data product deliveries and the change impact to the operating model.\nAn advocate for the ISS Data Programme.\nCollaborate closely with Data Governance, Business Architecture, and Data owners etc.\nConduct workshops within the scrum teams and across business teams, effectively document the minutes and drive the actions.\nAbout you\nAt least 10 years of proven experience as a business/technical/data analyst within technology and/or business changes within the financial services /asset management industry.\nMinimum 5 years as a senior business/technical/data analyst adhering to agile methodology, delivering data solutions using industry leading data platforms such as Snowflake, State Street Alpha Data, Refinitiv Eikon, SimCorp Dimension, BlackRock Aladdin, FactSet etc.\nProven experience. of delivering data driven business outcomes using industry leading data platforms such as Snowflake.\nExcellent knowledge of data life cycle that drives Middle and Back Office capabilities such as trade execution, matching, confirmation, trade settlement, record keeping, accounting, fund & cash positions, custody, collaterals/margin movements, corporate actions , derivations and calculations such as holiday handling, portfolio turnover rates, funds of funds look through .\nIn Depth expertise in data and calculations across the investment industry covering the below.\nAsset-specific data: This includes data related to financial instruments reference data like asset specifications, maintenance records, usage history, and depreciation schedules.\nMarket data: This includes data like security prices, exchange rates, index constituents and licensing restrictions on them.\nABOR & IBOR data: This includes calculation engines covering input data sets, calculations and treatment of various instruments for ABOR and IBOR data leveraging platforms such as Simcorp, Neoxam, Invest1, Charles River, Aladdin etc. Knowledge of TPAs, how data can be structured in a unified way from heterogenous structures.\nShould possess Problem Solving, Attention to detail, Critical thinking.\nTechnical Skills: Excellent hands-on SQL, Advanced Excel, Python, ML (optional) and proven experience and knowledge of data solutions.\nKnowledge of data management, data governance, and data engineering practices\nHands on experience on data modelling techniques such as dimensional, data vault etc.\nWillingness to own and drive things, collaboration across business and tech stakeholders.\nFeel rewarded",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['IT services', 'Data analysis', 'Data management', 'Incident management', 'Scrum', 'Customer service', 'Asset management', 'SDLC', 'SQL', 'Python']",2025-06-13 05:27:34
Senior Financial Data Analyst,Moodys Investors Service,1 - 2 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: RRS(RRS)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSolid accounting background with a strong focus on financial analysis\nDemonstrates knowledge of MS Excel, Word, and PowerPoint\nStrong organizational skills and attention to detail\nAbility to work effectively in a team environment with matrix reporting\nSolid verbal, written communication, and interpersonal skills\nAbility to adapt to a changing environment and prioritize tasks accordingly\nEducation:\nMinimum Experience: 1-2 years relevant in Credit Rating Analysis, Financial Statement Analysis\nPreferably a Postgraduate degree in Accounting, Finance, Economics, from a premium institution\nGood to have CFA/FRM certification\nJob Responsibilities:\nThe Senior Financial Data Analyst contributes to the success of the Research and Ratings Support team by providing a range of data and analytic services that support the overall credit analysis functions performed by the MIS analytic teams. This internal-facing role involves working directly with rating and research support analysts, preparing data, and performing various analytical tasks such as spreading, data gathering, and analysis for credit ratings, research, analytical market outreach, and presentations\nKey responsibilities include:\nPreparing a variety of discrete credit process inputs, performing preliminary analyses to identify trends in data, and applying reasoning to the completed work product\nPerforming financial statement analysis using accounting and finance principles to read and understand financial statements and other disclosures related to debt issuers performance\nApplying Moody s relevant methodology standards and requirements to financial data and making appropriate adjustments\nCreating a variety of standard initial work package items that serve as starting points for the ratings and research process, including data, spreadsheets, charts, and tables\nUpdating financial spreadsheets, charts, and tables\nIdentifying trends in data and applying reasoning to work being completed\nInitiating/escalating deeper reviews when necessary\nPreparing presentation materials for outreach activities\nProviding support for RRS and R&R in monitoring/surveillance of Moody s rated issuers\nSupporting monitoring of analyst credit portfolios through news and industry source tracking and highlighting key issues requiring further analysis\nUnderstanding the application of accounting concepts on a particular entity\nCreating documentation and providing guidance to support analysts and outsourcers\nReviewing, adjusting, and publishing data to external market participants\nSupporting the credit administration process and performing other routine administrative and ad hoc tasks as directed by RRS & R&R Teams\nAbout the Team:\nOur Research and Ratings Support (RRS) team is responsible for providing a range of data and analytic services that support the overall credit analysis functions performed by the MIS analytic teams\nBy joining our team, you will be part of exciting work in credit ratings, research, analytical market outreach, and presentations",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Administration', 'Financial statements', 'Publishing', 'Financial analysis', 'MIS', 'Analytical', 'Credit analysis', 'Financial statement analysis', 'Credit rating', 'Monitoring']",2025-06-13 05:27:35
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Bengaluru'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nChennai\nData Engineer with Neo4j\nData Science\nIndia\nGurugram\nBusiness Analyst\nData Science\nPoland\nRemote Poland\nBengaluru, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Bengaluru\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-13 05:27:37
Data Analyst with AI OR Machine learning,Teleperformance (TP),3 - 7 years,3-8 Lacs P.A.,['Hyderabad'],"Key Responsibilities:\nAnalyze large volumes of labeled and unlabeled data to identify trends, anomalies, and labeling patterns that can improve model training or operational efficiency.\nDesign and maintain automated dashboards and reporting frameworks to track labeling quality, throughput, and issue trends.\nPartner with Client leadership to understand data requirements and provide actionable insights for model optimization.\nDevelop scalable data pipelines for data validation, aggregation, and visualization.\nApply data mining techniques to evaluate annotation consistency, inter-rater reliability, and data quality.\nContribute to AI data evaluation strategies through analytical experimentation and feedback integration.\nCollaborate with cross-functional teams to enhance data annotation workflows and ensure metrics alignment.\nRequirements:\nBachelors degree in Statistics, Mathematics, Computer Science, Data Science, or a related field.\n3–8 years of hands-on experience in data analysis roles, preferably in AI/ML or data labeling environments.\nProficient in SQL and Python for data manipulation, analysis, and automation.\nUnderstanding of data labeling workflows and familiarity with metrics like accuracy, precision, recall, and inter-rater agreement.\nStrong analytical thinking with the ability to interpret large datasets and provide actionable insights.\nExcellent communication skills with the ability to present findings to both technical and non-technical audiences.\nSelf-starter with a keen eye for detail and a passion for working in AI-driven data environments.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data anayst', 'SQL', 'Artificial Intelligence', 'Google Suite', 'Data Analysis', 'Advanced Excel', 'MI', 'Machine Learning']",2025-06-13 05:27:38
Associate Healthcare Research & Data Analyst-1,Clarivate,1 - 3 years,Not Disclosed,['Bengaluru'],"Job Responsibilities:\nProduces or updates sections of large, complex projects or produces small projects with minimal oversight .\nProduces routine and templated descriptions and summaries of a factual nature with minimal oversight .\nDrafts client responses for simple requests in a timely manner .",,,,"['Training', 'Data modeling', 'Client support', 'Market research', 'Healthcare', 'Life sciences', 'Data analytics', 'Data Analyst', 'Analyst 1', 'Forecasting']",2025-06-13 05:27:40
Data Analyst - Power bi - Bangalore,people staffing solutions,5 - 10 years,10-20 Lacs P.A.,['Bengaluru'],"Required Skills:\nProficient in Power BI Desktop and Power BI Service\nStrong knowledge of DAX and Power Query (M Language)\nHands-on experience in SQL and data warehousing concepts\nAbility to create and optimize data models\nExperience in integrating Power BI with Excel, SharePoint, SQL Server, or APIs\nGood to Have:\nExperience with Power Automate and Power Apps\nKnowledge of Azure Synapse, Data Factory, or other Azure services\nExperience with Row-Level Security (RLS) and report sharing best practices\nUnderstanding of Agile/Scrum methodology",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'SQL', 'Sales Analytics', 'Dax Queries', 'Data Analytics', 'Business Intelligence', 'Dashboarding', 'business recommendation', 'Insight Generation', 'Business Intelligence Reporting', 'Power Bi Dashboards', 'Data Analysis', 'Data Visualization', 'Visualization Tools', 'Business Insights']",2025-06-13 05:27:42
Data Scientist Sr. Analyst,Accenture,5 - 10 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Big Data, Python or R\n\n\n\n\nGood to have skills:Scala, SQL\n\n\n\nJob\n\n\nSummary\n\nA Data Scientist is expected to be hands-on to deliver end to end vis a vis projects undertaken in the Analytics space. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\n\n\nRoles and Responsibilities\nIdentify valuable data sources and collection processes\nSupervise preprocessing of structured and unstructured data\nAnalyze large amounts of information to discover trends and patterns for insurance industry.\nBuild predictive models and machine-learning algorithms\nCombine models through ensemble modeling\nPresent information using data visualization techniques\nCollaborate with engineering and product development teams\nHands-on knowledge of implementing various AI algorithms and best-fit scenarios\nHas worked on Generative AI based implementations\n\n\n\nProfessional and Technical Skills\n3.5-5 years experience in Analytics systems/program delivery; at least 2 Big Data or Advanced Analytics project implementation experience\nExperience using statistical computer languages (R, Python, SQL, Pyspark, etc.) to manipulate data and draw insights from large data sets; familiarity with Scala, Java or C++\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications\nHands on experience in Azure/AWS analytics platform (3+ years)\nExperience using variations of Databricks or similar analytical applications in AWS/Azure\nExperience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)\nStrong mathematical skills (e.g. statistics, algebra)\nExcellent communication and presentation skills\nDeploying data pipelines in production based on Continuous Delivery practices.\n\n\n\n\nAdditional Information\nMulti Industry domain experience\nExpert in Python, Scala, SQL\nKnowledge of Tableau/Power BI or similar self-service visualization tools\nInterpersonal and Team skills should be top notch\nNice to have leadership experience in the past\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'scala', 'sql', 'r', 'big data', 'advanced analytics', 'mathematics', 'data manipulation', 'presentation skills', 'microsoft azure', 'pyspark', 'power bi', 'machine learning', 'javascript', 'aws kinesis', 'tableau', 'decision tree', 'java', 'hadoop', 'data visualization', 'aws', 'statistics']",2025-06-13 05:27:44
"Data Eng, Mgmt & Governance Sr Analyst",Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Data Management - Microsoft Fabric\n\n\n\n\nDesignation: Data Eng, Mgmt & Governance Sr Analyst\n\n\n\n\nQualifications:BE,BTech\n\n\n\n\nYears of Experience:5 - 8 Years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIEnd to end, unified analytics platform that brings together existing offerings like Data Factory, Synapse, and Power BI into a single unified product for all your data and analytics workloads.\n\n\n\n\nWhat are we looking for\nMicrosoft Fabric Microsoft Azure PySpark Strong analytical skills Adaptable and flexible Problem-solving skills Agility for quick learning Ability to meet deadlines\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of moderately complex problems May create new solutions, leveraging and, where needed, adapting existing methods and procedures The person would require understanding of the strategic direction set by senior management as it relates to team goals Primary upward interaction is with direct supervisor May interact with peers and/or management levels at a client and/or within Accenture Guidance would be provided when determining methods and procedures on new assignments Decisions made by you will often impact the team in which they reside Individual would manage small teams and/or work efforts (if in an individual contributor role) at a client or within Accenture\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data management', 'data analysis', 'pyspark', 'microsoft azure', 'power bi', 'python', 'data analytics', 'natural language processing', 'bi', 'data warehousing', 'machine learning', 'business intelligence', 'sql', 'tableau', 'r', 'data science', 'data modeling', 'data visualization', 'etl', 'ssis']",2025-06-13 05:27:46
Sr. Data Engineer (Analyst- BI/Visualization),Visa,5 - 10 years,Not Disclosed,['Bengaluru'],"We are looking for a seasoned individual contributor who is comfortable engaging with business owners, data enthusiasts, and technology teams. Successful candidates have strong experience in developing complex data solutions for business intelligence applications. This role will be hands-on and focused on building data pipelines, business intelligence solutions at scale and with a focus on sustained operational excellence.\nHelp improve Visa s decision-making by making data more accessible and relevant to key partners\nDevelop deep partnerships with engineering, finance, and product teams to deliver on major cross-functional solution development\nWork with a team of talented data and analytics engineers with the ability to not only keep up with, but also pioneer, in this space.\nCreate extract, transform, load (ETL) processes for easy ingestion and use\nDevelop visualizations to make your sophisticated analyses accessible to a broad audience\nFind opportunities to create, automate and scale repeatable financial and statistical analysis\nProvide technical leadership in a team that generates business insights based on big data, identify impactful recommendations, and communicate the findings to clients\nBrainstorm innovative ways to use our unique data to answer business problems\nCollaborate with and influence leadership so that your teams work directly impacts company strategy and direction.\nCommunicate effectively to all levels of the organization, including executives.\n\n\nBasic Qualifications\n5 or more years of work experience with a Bachelors Degree or an Advanced Degree (e.g. Masters, MBA, JD, MD, or PhD)\nPreferred Qualifications\n5 or more years of work experience with a Bachelor s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD)\n4+ years experience in data-based decision-making or quantitative analysis\nMaster s degree in Statistics, Operations Research, Applied Mathematics, Economics, Data Science, Business Analytics, Computer Science, or a related technical field\nExposure to Financial Services/ Payments data analytics and ETL development.\nExperience and expertise with data visualization using Tableau, Power BI or similar tools\nExperience in implementing ETL pipelines in Spark, Python, HIVE or SAS that process transaction and account level data and standardization of data pipelines.\nAdvanced experience in writing and optimizing efficient SQL queries with Python, Spark, Hive, Scala handling Large Data Sets in Big-Data Environments.\nExperience with Unix/Shell and exposure to Scheduling tools like Oozie and Airflow.\nStrong written, verbal, and interpersonal skills needed to effectively communicate technical insights and recommendations with business customers and leadership team.\nGood business acumen to orient data analysis to business needs of clients.\nAbility to translate data and technical concepts into requirements documents, business cases and user stories.\nAbility to learn new tools and paradigms as data science continues to evolve at Visa and elsewhere.\nDemonstrated intellectual and analytical rigor, team oriented, energetic, collaborative, diplomatic, and flexible style.\nPrevious experience with product valuations, financial engineering, customer lifetime values or net present value methodologies",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Unix', 'Computer science', 'Data analysis', 'SAS', 'Business analytics', 'Analytical', 'Scheduling', 'Business intelligence', 'Financial services', 'Python']",2025-06-13 05:27:48
Senior Data Management Analyst,Wells Fargo,4 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst in Corporate and Investment Banking ('CIB') to join the Applications Controls Execution & Services team, a subunit of the CIB Data Management organization.\nThe Application Controls Execution & Services team partners and supports CIB's wide network of Application Business Owners (ABO's) with identification, interpretation and/or implementation of governance processes or controls used to mitigate various compliance, operational, or data related risks.",,,,"['Data Management', 'Project Management', 'financial services management', 'operational risk', 'Analytics', 'business support', 'Business Analysis']",2025-06-13 05:27:49
Senior Analyst- Supplier Data Management,Oracle,5 - 8 years,Not Disclosed,['Bengaluru'],"Maintain general accounting systems, policies, and procedures to ensure that proper information is reported in accordance with Generally Accepted Accounting Principles.\nCareer Level - IC1\nAssists in accounting functions which may include general ledger, accounts payable, fixed assets, and inter-company transactions.\nMaintain the general ledger to include the preparation of journal entries, analysis, reconciliation and reporting.\nMaintain and implement general accounting systems.\nConduct account reconciliation periodically, ledger close activities, and provide accurate financial data to support management in decision making.\nDevelop and prepare financial reports including profit and loss, income and balance sheet statements.\nReview and analyze inter-company transactions.\nEnsure all journal entries comply with internal and external audit specifications.\nParticipate in the ongoing development and maintenance of internal procedures and processes.\nMay participate in special projects.",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Journal entries', 'Data management', 'Financial reporting', 'General accounting', 'Fixed assets', 'External audit', 'Senior Analyst', 'Reconciliation', 'Management', 'Balance Sheet']",2025-06-13 05:27:51
Senior Data Engineering Analyst,Optum,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Description\n\nExperience 4 to 7 years.\nExperience in any ETL tools [e.g. DataStage] with implementation experience in large Data Warehouse\nProficiency in programming languages such as Python etc.\nExperience with data warehousing solutions (e.g., Snowflake, Redshift) and big data technologies (e.g., Hadoop, Spark).\nStrong knowledge of SQL and database management systems.\nFamiliarity with cloud platforms (e.g., AWS, Azure, GCP) and data pipeline orchestration tools (e.g. Airflow).\nProven ability to lead and develop high-performing teams, with excellent communication and interpersonal skills.\nStrong analytical and problem-solving abilities, with a focus on delivering actionable insights.\nResponsibilities\nDesign, develop, and maintain advanced data pipelines and ETL processes using niche technologies.\nCollaborate with cross-functional teams to understand complex data requirements and deliver tailored solutions.\nEnsure data quality and integrity by implementing robust data validation and monitoring processes.\nOptimize data systems for performance, scalability, and reliability.\nDevelop comprehensive documentation for data engineering processes and systems.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ETL', 'SQL', 'Python', 'Azure', 'Datastage', 'Snowflake', 'Ab Initio', 'Informatica', 'Teradata', 'AWS']",2025-06-13 05:27:53
Sr. Data Analyst,Icims,4 - 9 years,Not Disclosed,['Hyderabad'],"Overview\nThe Senior Data Analyst is responsible for serving as a subject matter expert who can lead efforts to analyze data with the goal of delivering insights that will influence our products and customers. This position will report into the Data Analytics Manager, and will work closely with members of our product and marketing teams, data engineers, and members of our Customer Success organization supporting client outreach efforts. The chief functions of this role will be finding and sharing data-driven insights to deliver value to less technical audiences, and instilling best practices for analytics in the rest of the team.",,,,"['server', 'data', 'vlookup', 'market data', 'data mapping', 'dashboards', 'research', 'sql', 'analytics', 'tables', 'prep', 'pivot', 'data visualization', 'communication skills', 'python', 'data analytics', 'data analysis', 'insights', 'pivot table', 'data engineering', 'graph', 'excel', 'data quality', 'tableau', 'data governance', 'root cause']",2025-06-13 05:27:55
Senior Data Analyst,OnlineSales.ai,2 - 7 years,Not Disclosed,['Pune'],"About OnlineSales.ai\nBuilt by ex-Amazon ad-tech experts, OnlineSales.ai offers a future-proof Retail Media Operating System - boosting Retailer s profitability by 7% of Sales! We are an Enterprise B2B SaaS startup, based out of Pune India. With OnlineSales.ais platform, retailers activate and delight 10x more Brands by offering an omni-channel media buying experience, advanced targeting, analytics & 2x better ROAS. Tier 1 Retailers and Marketplaces globally are accelerating their Monetization strategy with OnlineSales.ai and are innovating ahead of the market by at least 2 years.\n\nAbout the Role\nWe are seeking a talented and motivated individual to join our team as a Senior Data Analyst who will be responsible for extracting insights from complex datasets to drive informed decision-making and enhance business performance. You will collaborate closely with cross-functional teams to identify key metrics, develop data-driven strategies, and provide actionable recommendations. Additional responsibilities may include managing daily regulatory reporting tasks and remediation activities, as well as process improvement.\n\nWhat will you do @OnlineSales?\nData Analysis: Utilize advanced analytical techniques to explore large datasets, identify trends, patterns, and anomalies, and extract actionable insights.\nData Visualization: Create visually compelling dashboards and reports to communicate findings effectively to stakeholders, enabling them to make informed decisions.\nData Extraction: regular extraction of relevant data from internal databases using SQL queries. Design and optimize SQL queries to retrieve specific datasets required for performance analysis and reporting\nIssue Identification: Proactively identify performance-related issues by monitoring key performance indicators (KPIs), analyzing trends, and investigating anomalies reported by internal stakeholders or external clients.\nAddressing Client Exceptions and Issues: Responsively address performance-related exceptions and issues raised by clients, ensuring timely resolution and effective communication throughout the process. Collaborate with client-facing teams to understand client requirements, prioritize tasks, and deliver solutions that meet or exceed client expectations.\nRoot Cause Analysis: Dive deep into data to understand the root causes of performance issues, considering factors such as system architecture, infrastructure, code efficiency, and user behavior.\nHypothesis Testing: Apply hypothesis testing techniques to validate assumptions and identify statistically significant factors impacting performance.\nDocumentation and SOP Creation: Create clear and detailed Standard Operating Procedures (SOPs) outlining the process for diagnosing, troubleshooting, and resolving performance issues. Ensure that documentation is organized, easily accessible, and regularly updated to reflect changes in systems, processes, or configurations.\nCross-Functional Collaboration: Collaborate with teams across the organization, including business development, marketing, product development and operations, to understand their data needs and provide analytical support\n\nYou will be a great fit, if you have :\n2-4 years of relevant experience.\nBachelors or Masters degree in Computer Science, Engineering, or a related technical field.\nProficiency in SQL for data extraction and manipulation from relational databases.\nFamiliarity with programming languages such as Python for Data Analysis and Data modeling is a plus.\nStrong analytical skills with the ability to interpret complex datasets and draw meaningful insights.\nStrong problem-solving abilities with a proactive approach to troubleshooting and issue resolution.\nAdvanced proficiency in Excel and adept data manipulation skills for efficient analysis and visualization of large datasets.\nEffective communication and interpersonal skills for collaboration with cross-functional teams and stakeholders.\nUnderstanding of E-Commerce as a domain.\nExcellent documentation skills with the ability to create clear and comprehensive reports and SOPs.\nAttention to detail and commitment to data accuracy and quality. Willingness to work for a startup.\n\nWhy Online Sales.ai?\nStartup-y . We believe Startup is a mindset. It s about being scrappy, being nimble, solving tough problems with constrained resources, and more. It s about working hard and playing hard\nEnterprise SaaS . Opportunity to work with an Enterprise Product SaaS firm with aspirations of growing 10x across the globe\nAI-led Retail Tech . We are working to digitize & democratize one of the most exciting and growing verticals - Retail Tech leveraging data, machine learning, and automation (culmination of ad-tech, mar-tech, and analytics for Retail vertical)\nMeaningful work . This is not just a job. You can find a job anywhere. This is a place for the bold to get paid who make a real impact on business\nNo red tape . Say goodbye to pointless meetings or political hoops to jump through. We re scrappy, believe in autonomy, and empower our teams to do whatever it takes to do the unthinkable\nProblem Solving . We ignite the best in you. We exist not only to deliver meaningful innovation but to ignite and inspire the creative problem-solver in you\nQuirky & fun . Enjoy new skills and hobbies like being a quiz master, playing board games, trying your hands on percussion, playing Djembe, and spreading love within the org!",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Data modeling', 'Process improvement', 'Online sales', 'Troubleshooting', 'Analytics', 'Monitoring', 'SQL', 'Data extraction']",2025-06-13 05:27:57
Senior Financial Data Analyst,Simcorp,4 - 5 years,Not Disclosed,['Noida'],"Financial Analyst WHAT MAKES US, US Join some of the most innovative thinkers in FinTech as we lead the evolution of financial technology. If you are an innovative, curious, collaborative person who embraces challenges and wants to grow, learn and pursue outcomes with our prestigious financial clients, say Hello to SimCorp! At its foundation, SimCorp is guided by our values caring, customer success-driven, collaborative, curious, and courageous. Our people-centered organization focuses on skills development, relationship building, and client success. We take pride in cultivating an environment where all team members can grow, feel heard, valued, and empowered. If you like what we re saying, keep reading!\nWHY THIS ROLE IS IMPORTANT TO US\nThe Financial Data Operator is responsible to perform the collection, composition, control and distribution of market and master data for financial instruments (Equities, Funds, Fixed Income, ABTS/MBS, OTS Derivatives, etc.) for various SimCorp clients and in accordance of the effective SLA agreements.\nFurthermore, this role is responsible for answering client questions and conduct all necessary data analyses of financial instruments data to resolve service delivery incidents to continue service delivery. The role is also responsible to adhere to all relevant operational risk as well as data governance and quality frameworks.\nEventually, this role also requires demonstrating very client-focused mindset, substantial know- how of financial instruments (such as Equities, Fixed Income, ABS/MBS, etc.) and provide coaching to other members.\nWHAT YOU WILL BE RESPONSIBLE FOR\nPerforms all daily service deliverables in terms of collecting, composing, controlling, and distributing financial instrument data according to effective client SLAs\nExecution of all quality checks part of the service scope and strict adherence to existing runbook(s) as well as data quality and governance frameworks and conduct first data analysis in case of unexpected data behavior\nResolve all data questions, service requests and requested audit support raised by clients in a timely and professional manner to ensure customer satisfaction and SLA compliance\nPerform all necessary tasks to comply existing operational risk frameworks (e.g., Sarbanes- Oxley Act (SOX), Risk and Control Engine (RACE) etc.)\nEfficiently support and contribute to continuous improvement of operational processes (with predominant focus on manual processes, high-risk areas), data quality checks and system functionality\nWork with local/regional clients to identify specific requirements, special data treatment or any other client demands which need to be delivered as part of the service scope\nExperience working cross-organizationally with both Business and Technology groups.\nPerform continuous know-how exchange between the different Data Operations teams in terms of processes, incidents, documentation, or other open topics to avoid know-how silos/gaps and assure service level consistency\nMonitor and report any kind of issues along the data supply chain including but not limited to interface issues, missing data files or interrupted business processes and trigger the necessary resolution processes to ensure service delivery continuation\nMaintain documentation in terms of business processes, functional descriptions, operational runbooks, or other manuals to ensure information transparency and enable know-how transfers\nWHAT WE VALUE\nFor the Financial Analyst position, we value\nMUST HAVE:\nExperience with data vendor feeds (Bloomberg, IDC, Reuters, etc.) and display products, 4- 5 years\nDeep knowledge of traditional and non-traditional financial instruments and markets including structured securities, Swaps, especially complex instruments like ABS/MBS, index linked bonds, and syndicated loans.\nBachelor s degree or equivalent in finance or engineering\nSolving master and reference data issues based on exception handling, 4-5 years\nExperience of data integration on any EDM platform, 4-5 years\nApplying operational data management and data governance, 2-3 years\nProcess design and engineering experience, 2-3 years\nExperience with service request systems or any other similar ticketing tool, like HPALM, Service Now Salesforce, etc., 4-5 years\nGOOD TO HAVE:\nAbility to troubleshoot technical glitches in existing data process and coordinate with Technology team to resolve.\nExperience in developing process automation, improvements, and streamlining using tools like KNIME, Alteryx, Excel VBA with scripting on programming language such as Python, PowerShell including intermediate knowledge of SQL",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Loans', 'Data analysis', 'Ticketing', 'Data management', 'Operational risk', 'Bloomberg', 'Fixed income', 'SQL', 'Auditing']",2025-06-13 05:27:59
Data Scientist-Artificial Intelligence,IBM,5 - 7 years,Not Disclosed,['Bengaluru'],"Work with broader team to build, analyze and improve the AI solutions.\nYou will also work with our software developers in consuming different enterprise applications\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nResource should have 5-7 years of experience. Sound knowledge of Python and should know how to use the ML related services.\nProficient in Python with focus on Data Analytics Packages.\nStrategy Analyse large, complex data sets and provide actionable insights to inform business decisions.\nStrategy Design and implementing data models that help in identifying patterns and trends. Collaboration Work with data engineers to optimize and maintain data pipelines.\nPerform quantitative analyses that translate data into actionable insights and provide analytical, data-driven decision-making. Identify and recommend process improvements to enhance the efficiency of the data platform. Develop and maintain data models, algorithms, and statistical models\n\n\nPreferred technical and professional experience\nExperience with conversation analytics. Experience with cloud technologies\nExperience with data exploration tools such as Tableu",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['algorithms', 'python', 'data analytics', 'tableau', 'ml', 'hive', 'data analysis', 'natural language processing', 'pyspark', 'data warehousing', 'machine learning', 'artificial intelligence', 'sql', 'pandas', 'deep learning', 'java', 'data science', 'spark', 'kafka', 'hadoop', 'big data', 'aws', 'etl']",2025-06-13 05:28:00
Data Analyst /Science executive,Hav2 Apparels,2 - 5 years,1.75-2.5 Lacs P.A.,"['Bengaluru( Kundalahalli, AECS Layout, Munnekollal, Whitefield )']","Build and run scripts to scrape emails, phone numbers, and business data, clean and organize it, analyze insights using Python/Excel, automate workflows, and support lead generation for import-export operations.",Industry Type: Import & Export,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['basic data analysis', 'Attention to Detail', 'Excel proficiency', 'regex knowledge', 'experience extracting emails/phones', 'Email Marketing', 'Numpy', 'and ability to automate and document tasks.', 'Beautiful Soup', 'CRM Management', 'Pandas', 'Data Scraping', 'Selenium', 'Python']",2025-06-13 05:28:02
Optimal Data Analyst : Supply Chain : 12 LPA : Apply Now,Leading ITES Company,3 - 8 years,10-12 Lacs P.A.,"['Bangalore Rural', 'Bengaluru', 'Mumbai (All Areas)']","Hi,\n\nWe are hiring for the ITES Company for the Optimal Data Analyst Role.\nOverview\nThe Optimal Data Analyst is responsible for leveraging data to generate actionable insights that support strategic decision-making, particularly in supplier negotiations and cost forecasting. The role involves working with large data sets, using statistical methods, programming tools (e.g., SQL, R, Python), and business intelligence platforms like Tableau to identify patterns, trends, and financial opportunities. This position requires strong analytical thinking, problem-solving abilities, and collaboration across technical, operational, and supply chain teams. The analyst plays a key role in translating complex data into meaningful business insights, aligning analytical efforts with high-level business objectives, and driving value through data-informed negotiation support.\n\nKey Skills:\n\na) Bachelor's degree in discipline such as Supply Chain, Economic, Manufacturing, Technology, or Data Analytics\nb) Minimum 3 years of experience in data analysis with understanding of statistical methods and strong analytical skills\n\nTo Apply, WhatsApp 'Hi' @ 9151555419\n\nFollow the Steps Below:\n>Click on Start option to Apply and fill the details\n>Select the location as Other (to get multiple location option)\na)To Apply for above Job Role (Bangalore) Type : Job Code # 20\nb)To Apply for above Job Role (Mumbai) Type : Job Code # 21\n\nJob Description\n\nBachelor's degree in discipline such as Supply Chain, Economic, Manufacturing, Technology, or Data Analytics to bring diversity and different perspectives\nMinimum 3 years of experience in data analysis with understanding of statistical methods and strong analytical skills\nExperience with database management, programming, statistical modelling and/or business intelligence (SQL, R, Python, JMP, Tableau, etc.)\nExperienced with and proficient in Microsoft Office Suite\nLateral and logical thinking. The ability to think creatively and outside the box to solve unique and challenging problems\nMotivated self-starter\nStrong problem-solving tendencies\nWilling and able to push boundaries\nGoal-oriented, with a focus on utilizing data for insight\nAble to multi-task, prioritize and project manage independently in an environment with competing priorities\nExperience working in a technical, operational or manufacturing environment with the ability to translate that knowledge into financial opportunities\nDiverse functional experience, with a desire to use data in negotiations\nExcellent communication skills and a proven history of excelling in a collaborative environment as a key team player\nWorking closely with technical teams, and other organizations to understand the product and data\nFinding and interpreting large data sets to help predict costs\nLearning and understanding Boeing's data resources and knowing when, how, and which to use and which not to use.\nIdentifying, analyzing, and solve systematic problems, while maintaining focus on the bigger picture\nWorking together with the team to ensure data analysis and developed algorithms can be appropriately applied for negotiation support\nEnsuring data collected, analyzed and presented result in actionable insights for negotiation support\nEngaging and participating in negotiation support, to bolster the use of data analytics within supplier negotiations\nUnderstanding high-level business objectives and continually align those objectives to meet needs of the business.",Industry Type: BPM / BPO,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Genpact', 'Supply Chain', 'Sutherland', 'Statistical Modeling', 'Data Modeling', 'Wipro', 'Cognizant', 'Business Intelligence', 'Accenture', 'Data Mining', 'Data Extraction', 'Data Collection', 'HCL', 'Optimal Data Analyst', 'Database Management', 'Data Analysis', 'Data Visualization', 'Amazon', 'Hexaware', 'WNS']",2025-06-13 05:28:04
DATA ANALYST - MEDICAL AFFAIRS,Eli Lilly And Company,7 - 9 years,Not Disclosed,['Bengaluru'],"The purpose of this role is to serve as a trusted partner with Business Unit Medical Affairs and Internal Global Medical Affairs Organization (GMAO) teams to lead creation of high-quality data reporting and visualization support that can drive better customer experience and business impact. This role will champion our self-service reporting strategy and would play a key role in helping us automate and create scalable frameworks for our reporting and analytics. We are looking for a hands-on person who can help expand our analytics & reporting capabilities and drive business-critical initiatives.\n  Key Objectives/Deliverables:\nKnow Lilly TA business and our internal business partners.\nBuild and exhibit deep expertise on available data sets and supports data enabled decision making by developing data lakes, insights, reporting & visualization\nExecute and monitor operations tasks to ensure timely availability of data in a reporting / dashboard structure to the business.\nPerform thorough data validations to ensure data quality\nRespond to queries from internal stakeholders\nConsistently meet operations SLAs\nPerform incident resolution and root cause analysis to support data and reporting operations\nConsistent delivery of high quality, timely and insightful reports to enable stakeholders and senior leadership to take key decisions\nDevelop and publish regularly, different execution dashboard as per the business roadmap & requirements\nDescriptive analytics and visualization to provide data-based insights on planning, execution and outcomes\nDemonstrate deep understanding of information and material flows, processes, procedures, systems, and methods\nDemonstrate understanding of internal business partners people, processes, and technology\nPartner and collaborate with other site-level teams to identify synergies and implementation of best practices\nTechnical Skills\nExpertise in writing and debugging efficient SQL queries.\nStrong experience in data visualization tools - Power BI or Tableau (Power BI preferred) - Should be able to independently design and develop dashboards as per business requirement.\nAdvanced MS-office skills (MS-Excel and MS-PowerPoint)\nCoding: SQL mandatory and one of R, Python would be good to have\nAnalytical Skills\nExperience in business analytics\nData cleaning and preparation skill (database querying, descriptive statistics)\nProblem solving skills and lateral thinking ability and an eye for detail\nEducational Requirements:\nbachelors or masters degree in sciences or quantitative discipline ie Finance, Econometrics, Statistics, Engineering or Computer Sciences\nAdditional Preferences:\nAt least 7-9 years of evolving experience in data management, pharma market intelligence, performance reporting/visualization and/or descriptive analytics for leadership, with demonstrated results in understanding, structuring, and making sense of unfamiliar and messy datasets\nExperience with project management software (eg, Wrike, JIRA, Adobe Workfront) and proficiency in a variety of PC applications and multifunctional diagramming tools including Microsoft Project, Visio, Lucid Chart etc\nStrong work ethic and personal motivation\nInterpersonal and communication skills with ability to work across time zones.\nStrong stakeholder management skills\nAbility to operate effectively in an international matrix environment.\nStrong team player who is dynamic and result oriented\nProven planning and organizational skills\nProven ability to manage multiple projects at a time with flexibility to adjust quickly and effectively to frequent change and altered priorities\nProduct Launch experience\nDemonstrated enthusiasm and the ability to work under pressure to meet deadlines",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data management', 'Coding', 'Project management', 'Pharma', 'Business analytics', 'Healthcare', 'MS Office', 'Adobe', 'Analytics', 'SQL']",2025-06-13 05:28:05
Data Management - Data Analyst-IT I.,Systechcorp Inc,1 - 3 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","Job Description: Interprets results using a variety of techniques, ranging from simple data aggregation via statistical analysis to complex data mining. Designs, develops, implements and maintains business solutions. Works directly with clients and project and business leaders to identify analytical requirements. Requires a bachelors degree in area of specialty and 1-3 years of experience in the field or in a related area. Familiar with standard concepts, practices, and procedures within a particular field. Relies on limited experience and judgment to plan and accomplish goals. Performs a variety of tasks. Works under general supervision. A certain degree of creativity and latitude is required. Typically reports to a supervisor or manager",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supervisor', 'IT Analyst', 'Statistical analysis', 'Data management', 'Analytical', 'Data Analyst', 'Data mining', 'Business solutions', 'Supervision']",2025-06-13 05:28:07
Financial Data Analyst,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: ROC(ROC)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies\nStrong understanding of fundamental finance and financial statements\nBasic understanding of capital markets\nCurious problem solvers who enjoy learning new things, working with others, and continuously growing their interpersonal and technical skills.\nCandidates from diverse backgrounds and academic disciplines with a strong focus on Finance/Technology/Support & Management\nFluency in English with good written and verbal communication skills; good interpersonal skills\nCreate visual representations of data findings through charts, graphs, and dashboards to make the data understandable.\nFamiliarity with Alteryx, SQL and other data visualization tools such as Tableau, PowerBI etc.\nPreferred proficiency in Python for data analysis and scripting.\nRelevant experience of up to 2 years in credit/financial data analysis and interpretation is an added advantage\nEducation\nMasters in Finance, Business, Accounting or similar field. Any knowledge in SQL, Python, PowerBI, Alteryx, etc or any experience related to data science, data analytics will be an added advantage.\nResponsibilities\nPerform analysis to support ratings, research, analytical outreach. Examples of work include:\nPerform various data intake tasks, including scrubbing, validating the data for further use in research and ratings\nApply MIS standards to existing data in order to produce valuable inputs into the rating and research process, including Moodys adjusted data, key indicators, ratios, charts and graphs in line with MISs methodologies\nResponsible for reviewing and understanding financial reports, official statements and other documents related to issuers performance\nWork directly with ratings and support analysts to understand data capture requirements, adjustments and other information needed by the rating team for ratings and research\nTake initiative to participate in projects or process improvements\nComplete simple deliverables such as newsletters, database maintenance, more complex or high profile admin or other ad-hoc support with oversight\nBe able to perform data intake exercises such as resolution of data point or mapping issues\nOur Ratings & Operations Control (ROC) team is responsible for 1) analytic data capture and enrichment, inputs and outputs to support ratings & research, 2) ratings transaction setup and release and rating desk services, 3) regulatory processes and operational controls, 4) product management for regulatory website, 5) center of excellence for process improvement and 6) project management support.\nBy joining our team, you will be part of exciting work in supporting ratings accuracy and timely market impact by delivering high-quality, consistent work product, while driving process excellence.\n\n\n\n\nFor more information on the Securities Trading Program, please refer to the STP Quick Reference guide on ComplianceNet\n\nPlease note: STP categories are assigned by the hiring teams and are subject to change over the course of an employee s tenure with Moody s.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Financial statements', 'MIS', 'Project management', 'Process improvement', 'Analytical', 'Credit analysis', 'Operations', 'SQL']",2025-06-13 05:28:09
Financial Data Analyst,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: ROC(ROC)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies:\nBasic knowledge of financial statements and basic understanding of how data fits into methodologies\nAbility to read, understand and interpret financial metrics reported by rated entities\nStrong organizational skills\nAttention to detail\nAbility to work effectively in a collaborative team environment\nIntermediate Microsoft Excel skills\nGood written and verbal communication skills\nGood interpersonal skills, interact with team members, direct managers and limited other stakeholders\nDevelop working knowledge of more than one simple project/deliverable with guidance\nRelevant experience of up to 2 years in credit/financial data analysis and interpretation; experience in structured finance will be an added advantage\n\nEducation\nBachelors/Masters in Finance, Business, Accounting or similar field\n\nResponsibilities\nPerform analysis to support ratings, research, and analytical outreach\nApply Moody s Ratings standards to existing data to produce valuable inputs into the rating and research process, including Moodys adjusted data, key indicators, ratios, charts, and graphs in line with Moody s Ratings methodologies\nPerform various data intake tasks, including scrubbing and validating data for further use in research and ratings\nReview and understand financial reports, official statements, and other documents related to issuers performance\nWork directly with ratings and support analysts to understand data capture requirements, adjustments, and other information needed by the rating team for ratings and research\nPerform simple calculations and apply judgment for other calculations of data\nGather data from various sources (sometimes unstructured), update relevant databases, escalate or resolve issues\nComplete simple deliverables such as newsletters, database maintenance, more complex or high-profile admin or other ad-hoc support with oversight\n\nAbout the team\nOur Data & Analytics team is responsible for performing a range of data, analytical and research services that contribute to the overall credit analysis function carried out by the structured finance rating groups. By joining our team, you will be part of exciting work in financial data analysis.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['remediation', 'Data analysis', 'Financial statements', 'Excel', 'Analytical', 'Finance', 'Structured finance', 'ROC', 'Credit analysis', 'Research']",2025-06-13 05:28:10
Learning & Development - Data Analyst,Paychex It Solutions,5 - 10 years,Not Disclosed,['Bengaluru'],"About Us Imagine Your Future with Us! Since 1971, Paychex has been at the forefront of simplifying HR, payroll, and benefits for American businesses. Our digital HR technology and advisory solutions cater to the changing needs of employers and their employees. With our award-winning training and endless opportunities for growth and development, you can build a lifelong career with us. We pride ourselves on fostering an inclusive and innovative culture. Our leaders are here to support your career journey; they and our dedicated employees embody the values that drive us to support each other, our clients, and our communities. Join us to pursue your passion and unleash your potential. Overview\n\n\nThe Data Analyst is a centralized resource for Learning & Development, driving data strategy, reporting, and insights to enhance employee and learner performance, productivity, and retention. This role bridges data and decision-making, delivering acti",,,,"['Computer science', 'Payroll', 'Data management', 'Data modeling', 'Process improvement', 'Information systems management', 'Data collection', 'Data Analyst', 'Business strategy', 'Continuous improvement']",2025-06-13 05:28:12
urgent requirement For Data Analyst / BI Developer,Quantzig,3 - 6 years,Not Disclosed,[],"Key Responsibilities:\nDevelop, design, and maintain dashboards and reports using Tableau and Power BI to support business decision-making.\nWrite and optimize complex SQL queries to extract, manipulate, and analyze data from multiple sources.\nCollaborate with cross-functional teams to understand business needs and translate them into effective data solutions.\nWork with AWS Redshift and Databricks for data extraction, transformation, and loading (ETL) processes.\nProactively identify and resolve data issues, acting as a solution finder to overcome challenges and drive improvements.\nWork independently, taking ownership of tasks and ensuring high-quality deliverables within deadlines.\nBe a strong team player, contributing to team knowledge sharing and fostering a collaborative environment.\nApply knowledge of US healthcare systems to help build relevant data solutions and insights.\n\nRequired Skills & Qualifications:\nMinimum 3 years of experience in data analysis, business intelligence, or related roles.\nStrong expertise in SQL for data querying and manipulation.\nExtensive experience creating dashboards and reports using Tableau and Power BI.\nHands-on experience working with AWS Redshift and Databricks.\nProven problem-solving skills with a focus on providing actionable data solutions.\nSelf-motivated and able to work independently, while being a proactive team player.\nExperience or strong understanding of US healthcare systems and data-related needs.\nExcellent communication skills with the ability to work across different teams and stakeholders.\nDesired Skills (Nice to Have):\nFamiliarity with other BI tools or cloud platforms.\nExperience in healthcare data analysis or healthcare analytics.",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Power Bi', 'Tableau', 'SQL', 'Redshift Aws', 'databricks']",2025-06-13 05:28:14
Data Engineer Sr. Analyst,Accenture,2 - 3 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python/Scala, Pyspark/Pytorch\n\n\n\n\nGood to have skills:Redshift\n\n\n\nJob\n\n\nSummary\n\nYoull capture user requirements and translate them into business and digitally enabled solutions across a range of industries. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\nCreating data products for analytics team members to improve productivity\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\nPreparing data to create a unified database and build tracking solutions ensuring data quality\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\nProfessional and Technical Skills\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 2-3 years of hands-on experience working on these technologies.\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\nExperience working in cloud Data warehouses like Redshift or Synapse\nCertification in any one of the following or equivalent\nAWS- AWS certified data Analytics- Speciality\nAzure- Microsoft certified Azure Data Scientist Associate\nSnowflake- Snowpro core- Data Engineer\nDatabricks Data Engineering\n\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'microsoft azure', 'glue', 'amazon redshift', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'scipy', 'snowflake', 'data analysis', 'azure data lake', 'power bi', 'data engineering', 'javascript', 'pandas', 'data bricks', 'tableau', 'lambda expressions', 'aws']",2025-06-13 05:28:16
Data Engineer - Senior Analyst,Accenture,2 - 3 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python/Scala, Pyspark/Pytorch\n\n\n\n\nGood to have skills:Redshift\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)\n\n\n\nJob\n\n\nSummary\n\nYoull capture user requirements and translate them into business and digitally enabled solutions across a range of industries. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\nCreating data products for analytics team members to improve productivity\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\nPreparing data to create a unified database and build tracking solutions ensuring data quality\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\nProfessional and Technical Skills\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 2-3 years of hands-on experience working on these technologies.\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\nExperience working in cloud Data warehouses like Redshift or Synapse\nCertification in any one of the following or equivalent\nAWS- AWS certified data Analytics- Speciality\nAzure- Microsoft certified Azure Data Scientist Associate\nSnowflake- Snowpro core- Data Engineer\nDatabricks Data Engineering\n\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'microsoft azure', 'glue', 'amazon redshift', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'scipy', 'snowflake', 'data analysis', 'azure data lake', 'power bi', 'data engineering', 'javascript', 'pandas', 'data bricks', 'tableau', 'lambda expressions', 'aws']",2025-06-13 05:28:17
Senior Data Research Analyst,Morningstar,3 - 8 years,Not Disclosed,['Mumbai'],"As a Senior Data Research Analyst , you will be responsible for acquiring and validating portfolio holdings data from various vendor sources. Your core responsibilities will involve standardizing this data into agreed formats using internal collection tools and resolving exceptions through thorough validation processes.\nWorking within the Portfolio Data Team, your role will focus on ensuring the accuracy and completeness of portfolio information, which is critical for downstream analytics and reporting. You will collaborate closely with leadership and cross-functional teams to support strategic goals, enhance operational performance, and contribute to the achievement of key KPIs.\nShift: UK/AU/US\nRoles Responsibilities:\nActively collect managed investment data using Morningstar collection systems, and ensure data timelines, completeness and accuracy to meet business goals.\nManage relationships between Morningstar and Asset Management companies, insurance companies and other data vendors.\nPartner with quality assurance, products, and technical departments to resolve clients data issues timely and effectively.\nParticipate in the initiatives focused on consolidating global data collection platforms and supporting database integration projects.\nEstablish and achieve the set Objectives Key Results (OKRs) with the direction of team lead.\nMonitor, analyze and execute summary reports including an investigation of potential data error to continuously improve data collection and quality assurance process using Lean Six Sigma tools.\nActively discover and raise issues in work (including system, process, and collection methodology) and propose enhancement suggestions to further improve system functionality, process efficiency and data quality.\nParticipate in data and process related projects such as industry/market research, market expansion, process certification, new product development support, etc.\nFacilitate cross-team projects to implement approved solutions based on priority and impact.\nDemonstrate a high sense of ownership of the process, understand roles responsibilities by acting as a process trainer and mentor\nRequirements:\n> 3 years experience in finance domain, with emphasis on collection systems and methodologies, senior data research analyst role or above.\nFund Portfolio experience would be preferred\nGood command in MS Office (Excel, PowerPoint etc.); advanced users preferred. SQL, Macro or Python and machine learning will be a plus.\nShould be critical thinker and should possess good communication skill.\nShould be equipped with understanding of data competencies like data content expertise, data analysis etc.\nStrong analytical, problem-solving capabilities, and excellent communication written as well as verbal reporting skills.\nShould be a good team player with good learning ability and equipped with self-motivation in an independent, fast-paced work environment.\nAbility to exercise control over the planned activities like training / mentoring new hires, doing quality checks etc.\nAble to work under tight deadlines and handle pressure during peak seasons.\nGood project management skills with proven track record of working on and delivering projects independently.\nRemote team working experience is a plus.\nFlexibility to work in shifts.\nMorningstar is an equal opportunity employer",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Analytical', 'Data Research Analyst', 'Data collection', 'Market research', 'Asset management', 'Operations', 'Analytics', 'SQL']",2025-06-13 05:28:19
Data Engineer Sr. Analyst,Accenture,5 - 7 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Databricks including Spark-based ETL, Delta Lake\n\n\n\n\nGood to have skills:Pyspark\n\n\n\nJob\n\n\nSummary\n\nWe are seeking a highly skilled and experienced Senior Data Engineer to join our growing Data and Analytics team. The ideal candidate will have deep expertise in Databricks and cloud data warehousing, with a proven track record of designing and building scalable data pipelines, optimizing data architectures, and enabling robust analytics capabilities. This role involves working collaboratively with cross-functional teams to ensure the organization leverages data as a strategic asset. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\nDesign, build, and maintain scalable data pipelines and ETL processes using Databricks and other modern tools.\nArchitect, implement, and manage cloud-based data warehousing solutions on Databricks (Lakehouse Architecture)\nDevelop and maintain optimized data lake architectures to support advanced analytics and machine learning use cases.\nCollaborate with stakeholders to gather requirements, design solutions, and ensure high-quality data delivery.\nOptimize data pipelines for performance and cost efficiency.\nImplement and enforce best practices for data governance, access control, security, and compliance in the cloud.\nMonitor and troubleshoot data pipelines to ensure reliability and accuracy.\nLead and mentor junior engineers, fostering a culture of continuous learning and innovation.\nExcellent communication skills\nAbility to work independently and along with client based out of western Europe.\n\n\n\nProfessional and Technical Skills\n3.5-5 years of experience in Data Engineering roles with a focus on cloud platforms.\nProficiency in Databricks, including Spark-based ETL, Delta Lake, and SQL.\nStrong experience with one or more cloud platforms (AWS preferred).\nHandson Experience with Delta lake, Unity Catalog, and Lakehouse architecture concepts.\nStrong programming skills in Python and SQL; experience with Pyspark a plus.\nSolid understanding of data modeling concepts and practices (e.g., star schema, dimensional modeling).\nKnowledge of CI/CD practices and version control systems (e.g., Git).\nFamiliarity with data governance and security practices, including GDPR and CCPA compliance.\n\n\n\n\nAdditional Information\nExperience with Airflow or similar workflow orchestration tools.\nExposure to machine learning workflows and MLOps.\nCertification in Databricks, AWS\nFamiliarity with data visualization tools such as Power BI\n\n(do not remove the hyperlink)Qualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data warehousing', 'sql', 'data modeling', 'python', 'data bricks', 'hive', 'kubernetes', 'catalog', 'pyspark', 'data architecture', 'docker', 'ansible', 'git', 'java', 'spark', 'devops', 'hadoop', 'etl', 'big data', 'data lake', 'airflow', 'power bi', 'cloud platforms', 'machine learning', 'data engineering', 'aws']",2025-06-13 05:28:21
Senior Analyst - Data Governance & Management,AMERICAN EXPRESS,3 - 7 years,Not Disclosed,['Gurugram'],"Here, your voice and ideas matter, your work makes an impact, and together, you will help us define the future of American Express.\nAt American Express, you ll be recognized for your contributions, leadership, and impact every colleague has the opportunity to share in the company s success. Together, we ll win as a team, striving to uphold our company values and powerful backing promise to provide the world s best customer experience every day. And we ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.\nJoin Team Amex and lets lead the way together.",,,,"['Career development', 'metadata', 'Manager Quality Assurance', 'Data management', 'Finance', 'Shell scripting', 'Wellness', 'Data quality', 'Risk management', 'SQL']",2025-06-13 05:28:23
Sr. Data Research Analyst,Morningstar,3 - 7 years,Not Disclosed,"['Thane', 'Navi Mumbai', 'Mumbai (All Areas)']","Senior Data Research Analyst, Credit Operations Mumbai Analytics\nAbout Us: Morningstar DBRS is a leading provider of independent rating services and opinions for corporate and sovereign entities, financial institutions, and structured finance instruments globally. Currently with 700 employees in eight offices globally. Formed through the July 2019 acquisition of DBRS by Morningstar, Inc., the ratings business is the fourth-largest provider of credit ratings in the world. Morningstar DBRS is committed to empowering investor success, serving the market through leading-edge technology and raising the bar for the industry. Morningstar DBRS is a market leader in Canada, the U.S. and Europe in multiple asset classes. Morningstar DBRS rates more than 4,000 issuers and 60,000 securities worldwide and is driven to bringing more clarity, diversity of opinion, and responsiveness to the ratings process. Morningstar DBRS approach and size provide the agility to respond to customers needs, while being large enough to provide the necessary expertise and resources. Visit: htthttps://www.dbrsmorningstar.com/learn/dbrsmorningstar to learn more. About the Role: Morningstar DBRS is seeking a Senior Data Research Analyst to join the Credit Operations Mumbai Analytics.\nThe Senior Data Research Analyst is part of the team responsible for maintaining critical ratings and origination data. In this role, you will be asked to gather and interpret data requirements, perform research and analysis, and mappings from multiple sources. The Senior Data Research Analyst will partner with our technology team to assist in the development and testing of new requirements when necessary\n\nResponsibilities\n• Assisting with collection and organization of security level data from various data sources\n• Mapping of CUSIP and ISIN to corresponding Morningstar DBRS ratings\n• Maintenance and troubleshooting of scheduled and automated reports\n• Completing various data related inquiries and requests from internal and external parties\n• Collaborate with Global Team to ensure accuracy, quality and reliability of the security ratings database\n• Communicating with and maintaining a strong relationship with rating analysts to adhere with compliance and regulatory matters\n\nRequirements\n• Bachelor’s degree in Accounting, Economics, Finance or Management Studies\n• 3-4 years of Relevant Financial Data experience, experience at a rating agency is a plus\n• Proficient in using data collection and analytical tools\n• Experience working with SQL (MS SQL Server)\n• Experience working with large data sets\n• Exposure to database management\n• Excellent verbal and written communication and interpersonal skills\n• Strong attention to detail and accuracy\n• Highly motivated, self-starter who is keen to learn, has a positive attitude and a strong work ethic\n• Ability to manage multiple tasks at the same time and deliver results in a timely manner\n• Ability to participate/ contribute as a team player\nRecommended Skillsets:\n• Experience with Bloomberg and/or Thomson Reuters terminal\n• Knowledge of fixed income or capital markets\n• Experience with Python\n\nMorningstar DBRS is an equal opportunity employer",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Reference Data', 'Financial Data Extraction', 'Bloomberg', 'Data Management', 'Reuters', 'Fixed Income']",2025-06-13 05:28:24
Sr Analyst I Data Engineering,DXC Technology,9 - 12 years,Not Disclosed,['Hyderabad'],"Job Description:\nEssential Job Functions:\nParticipate in data engineering tasks, including data processing and integration activities.\nAssist in the development and maintenance of data pipelines.\nCollaborate with team members to collect, process, and store data.\nContribute to data quality assurance efforts and adherence to data standards.\nUse data engineering tools and techniques to analyze and generate insights from data.\nCollaborate with data engineers and other analysts on data-related projects.\nSeek out opportunities to enhance data engineering skills and domain knowledge.\nStay informed about data engineering trends and best practices.\n\nBasic Qualifications:\nBachelors degree in a relevant field or equivalent combination of education and experience\nTypically, 5+ years of relevant work experience in industry, with a minimum of 2 years in a similar role\nProven experience in data engineering\nProficiencies in data engineering tools and technologies\nA continuous learner that stays abreast with industry knowledge and technology\n\nOther Qualifications:\nAdvanced degree in a relevant field a plus\nRelevant certifications, such as Oracle Certified Professional, MySQL Database Administrator a plus\nRecruitment fraud is a scheme in which fictitious job opportunities are offered to job seekers typically through online services, such as false websites, or through unsolicited emails claiming to be from the company. These emails may request recipients to provide personal information or to make payments as part of their illegitimate recruiting process. DXC does not make offers of employment via social media networks and DXC never asks for any money or payments from applicants at any point in the recruitment process, nor ask a job seeker to purchase IT or other equipment on our behalf. More information on employment scams is available here .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Usage', 'Manager Quality Assurance', 'Senior Analyst', 'Social media', 'Manager Technology', 'Data processing', 'Data quality', 'Oracle', 'mysql database administrator', 'Recruitment']",2025-06-13 05:28:26
Senior Data Management Analyst,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst.\n\nIn this role, you will:\nMust have strong experience (SME) in JIRA, Assets, Structure, Confluence, Groovy/Python scripting, Linux, Script Runner.\nIn-depth knowledge of Jira Software, JSM and Confluence administration, configuration, customizations and Automations.",,,,"['Data Management', 'Script Runner', 'Linux', 'Confluence', 'JSM', 'Python scripting', 'Groovy', 'Jira', 'REST APIs']",2025-06-13 05:28:28
Senior Data Management Analyst,Wells Fargo,4 - 8 years,Not Disclosed,['Hyderabad'],"In this role, you will:\nLead or participate in moderately complex programs and initiatives for data quality, governance, and metadata activities\nDesign and conduct moderately complex analysis to identify and remediate data quality, data integrity, process, and control gaps\nAnalyze, assess, and test data controls and data systems to ensure quality and risk compliance standards are met and adhere to data governance standards and procedures",,,,"['Data Management Analysis', 'Project Management', 'Data Management', 'data governance', 'Business Analysis']",2025-06-13 05:28:29
Analyst - Direct Display,Merkle B2b,0 - 2 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:Focuses on day-to-day executionProactively reviews and manages client data to ensure optimal performance on all campaignsTracks and reports on campaign results, gathers data analysis and participates in weekly callsGenerates campaign reports and is responsible for pacing, QA and traffickingDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Other,"Employment Type: Full Time, Permanent","['digital marketing', 'data analysis', 'quality control', 'branding', 'business development', 'advertising', 'sales', 'brand management', 'assurance', 'quality analysis', 'marketing', 'promotions', 'qc', 'campaigns', 'quality assurance', 'marketing communication', 'social media marketing', 'reporting']",2025-06-13 05:28:31
Financial Reporting Data Analyst,Vichara Technologies,7 - 12 years,20-30 Lacs P.A.,"['Pune', 'Bengaluru', 'Delhi / NCR']",Responsibilities:\nOwn data reporting:\nMonitoring for Financial Ratio Completeness: troubleshooting and investigation into why these ratios are blank or not tying out.\nTroubleshooting Power BI Issues\nTriaging Issues with the Data Vendors:\n\nRequired Candidate profile\nAdvanced (5+ years) Financial Data Analysis Experience\nIntermediate (3+ years) with Financial Concepts\nSome (1+ year) SQL Experience,Industry Type: Analytics / KPO / Research,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Financial Statements', 'Financial Reporting', 'Power Bi', 'SQL', 'Reconciliation', 'Cfa Level 1', 'Financial Analysis', 'Financial Reconciliation', 'Financial Data', 'Advanced Excel', 'JIRA', 'Power Query', 'Data Reconciliation', 'Excel', 'Financial Analytics', 'VBA', 'Data Analysis', 'Data Reporting']",2025-06-13 05:28:33
S&C GN - Data&AI - Retail - Analyst,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],TBDQualification\nTBD,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['retail sales', 'retail', 'sales', 'marketing', 'store management', 'visual merchandising', 'retail operations', 'channel sales', 'customer service', 'store operations', 'business development', 'apparel', 'distribution', 'merchandising', 'retail store operations', 'selling', 'customer handling']",2025-06-13 05:28:34
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst. We believe in the power of working together because great ideas can come from anyone. Through collaboration, any employee can have an impact and make a difference for the entire company. Explore opportunities with us for a career in a supportive environment where you can learn and grow. This role requires a blend of technical expertise, analytical thinking, and strategic decision making to drive impactful insights.\nAt Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do. We are seeking candidates who embrace diversity, equity and inclusion in a workplace where everyone feels valued and inspired. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.",,,,"['Data Management', 'Hive', 'Power BI', 'DB2', 'SQL Server', 'Tableau', 'Oracle', 'Teradata', 'Analytics', 'Python', 'Business Analysis']",2025-06-13 05:28:36
S&C Global Network - AI - CDI - Data Science Analyst,Accenture,1 - 6 years,Not Disclosed,['Bengaluru'],"Job Title Ind & Func AI Decision Science Analyst - S&C GN\n\n\n\nManagement Level :11 - Analyst\n\n\n\nLocation:Gurgaon\n\n\n\nMust have skills:Generative AI, Machine Learning, Large Language Models (LLMs), Python, SQL\n\n\n\n\nGood to have skills:Spark, Cloud Platforms (AWS, Azure, GCP), NLP, Computer Vision\n\n\n\nJob\n\n\nSummary: As an AI Decision Science Analyst, you will play a key role in designing, building, and deploying advanced AI models and solutions to address business challenges across various industries. You will leverage Generative AI, Machine Learning, and Large Language Models (LLMs) to drive innovation and deliver impactful insights for clients. Your work will involve collaborating with cross-functional teams, and contributing to the development of advanced analytics capabilities.\n\n\n\n\nRoles & Responsibilities:\nLeverage Advanced Data Science Techniques\nDevelop solutions using Generative AI, Machine Learning, and Large Language Models (LLMs).\nDefine data requirements, clean, aggregate, analyze, and interpret data while conducting data quality assessments.\nDevelop and Implement AI Models\nBuild and deploy AI models and Generative AI applications.\nTrain and fine-tune LLMs using large-scale datasets to optimize performance and accuracy.\nEvaluate model performance and implement iterative improvements.\nSolution Integration and Deployment\nCollaborate to integrate AI solutions into end-to-end workflows, ensuring scalability.\nUtilize cloud platforms like AWS, Azure, or GCP for model development and deployment.\nInnovation and Knowledge Sharing\nStay updated on advancements in AI and Data Science, exploring innovative techniques and frameworks.\nDocument methodologies and findings for effective knowledge sharing.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Generative AI, Machine Learning, LLMs, Python, SQL.\nSpark, Cloud platforms (AWS, Azure, GCP), NLP, Computer Vision.\nExperience in developing and AI/ML models.\n\n\n\n\nAdditional Information: - The ideal candidate will possess a strong educational background in computer science or a related field, along with a proven track record of delivering impactful solutions using data science and analytics.\nThis position is based at our Gurugram office.\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:Minimum 1+ years of experience in Data Science, preferably within a consulting environment\n\n\n\n\nEducational Qualification:Bachelors or Masters degree (BE/BTech/MBA) in Statistics, Computer Science, Mathematics, or related disciplines with an excellent academic record",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'sql', 'data science', 'advanced analytics', 'mathematics', 'microsoft azure', 'artificial intelligence', 'data quality', 'computer science', 'gcp', 'spark', 'computer vision', 'model development', 'aws', 'ml', 'statistics']",2025-06-13 05:28:38
S&C GN - Data&AI - Life Sciences - Analyst,Accenture,2 - 7 years,Not Disclosed,['Bengaluru'],"Management Level:Ind & Func AI Decision Science Analyst\n\n\n\n\nJob Location:Bangalore / Gurgaon\n\n\n\nMust-have\n\n\n\n\nSkills:\nLife Sciences/Pharma/Healthcare projects and delivering successful outcomes, commercial, clinical, Statistical Models/Machine Learning including Segmentation & predictive modeling, hypothesis testing, multivariate statistical analysis, time series techniques, and optimization.\n\n\n\nGood-to-have\n\n\n\n\nSkills:\nProficiency in Programming languages such as R, Python, SQL, Spark, AWS, Azure, or Google Cloud for deploying and scaling language models, Data Visualization tools like Tableau, Power BI\n\n\n\nJob\n\n\nSummary\n\nWe are seeking an experienced and visionary - Accenture S&C Global Network - Data & AI practice help our clients grow their business in entirely new ways. Analytics enables our clients to achieve high performance through insights from data - insights that inform better decisions and strengthen customer relationships. From strategy to execution, Accenture works with organizations to develop analytic capabilities - from accessing and reporting on data to predictive modelling - to outperform the competition.\n\n\n\nKey Responsibilities\nSupport delivery of small to medium-sized teams to deliver consulting projects for global clients.\nAn opportunity to work on high-visibility projects with top Pharma clients around the globe.\nPersonalized training modules to develop your strategy & consulting acumen to grow your skills, industry knowledge, and capabilities.\nResponsibilities may include strategy, implementation, process design, and change management for specific modules.\nWork with the team or as an Individual contributor on the project assigned which includes a variety of skills to be utilized from Data Engineering to Data Science\nDevelop assets and methodologies, point-of-view, research, or white papers for use by the team and the larger community.\nWork on variety of projects in Data Modeling, Data Engineering, Data Visualization, Data Science etc.,\nAcquire new skills that have utility across industry groups.\n\n\n\n\n\nAdditional Information\nAbility to solve complex business problems and deliver client delight.\nStrong writing skills to build points of view on current industry trends.\nGood communication, interpersonal, and presentation skills\n\n\nAbout Our Company | Accenture (do not remove the hyperlink)\n\n\nQualification\n\n\n\nExperience:Proven experience (2+ years) in working on Life Sciences/Pharma/Healthcare projects and delivering successful outcomes.\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Statistics, Data Science, Applied Mathematics, Business Analytics, Computer Science, Information Systems, or other Quantitative field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['pharmaceutical', 'python', 'sql', 'life sciences', 'aws', 'presentation skills', 'microsoft azure', 'power bi', 'time series', 'machine learning', 'artificial intelligence', 'tableau', 'r', 'data science', 'gcp', 'spark', 'predictive modeling', 'statistical modeling', 'data visualization', 'statistics']",2025-06-13 05:28:40
Quality Analyst I - Data Access Management,JPMorgan Chase Bank,3 - 6 years,Not Disclosed,['Bengaluru'],"Join our team to enhance your career in data management and governance.\nAs a member of the Data Use and Access Team within the Data Management and Governance organization, you will manage data access protocols across our Data and Analytics Platforms. You will ensure compliance with legal and contractual restrictions, partnering with product, engineering, and end users to maintain a seamless user experience while upholding a best-in-class risk posture.\nJob Responsibilities\nManage data access protocols ensuring compliance with legal, contractual, and regulatory standards.\nDevelop and implement strategic initiatives for consistent, holistic, and cloud-agnostic data access management.\nCollaborate with cross-functional teams to monitor access restrictions and permissions.\nRemediate and strengthen gaps in data access controls through role design, management, and oversight.\nImplement access administration and recertification programs across various data environments and platforms.\nProvide subject matter expertise on access-related matters to the larger CCB organization.\nUtilize project management tools like JIRA and leverage the AGILE framework to deliver value to the business.\nRequired Qualifications, Capabilities, and Skills\n5+ years of experience in data analytics and technology-related positions with Python scripting as a core competency.\nHands-on experience with Python, Alteryx, and Tableau related projects.\nWorking knowledge of JIRA, SharePoint, InfoPath, Confluence, SQL, Snowflake, Git (Bitbucket), and SSRS.\nAdvanced MS Office suite skills (Excel, Word, PowerPoint, Visio, Project).\nExcellent written and oral communication skills with the ability to present information in differing degrees of detail and form depending on the audience.\nPreferred Qualifications, Capabilities, and Skills\nKnowledge of access management ticketing systems.\nExperience with Cyber Security Tools and Identity Access Management tools.\nFamiliarity with data environments and platforms such as Teradata, Oracle, Snowflake, and cloud technologies.",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Ticketing', 'Data management', 'Access management', 'Project management', 'SSRS', 'Agile', 'Visio', 'Oracle', 'Teradata', 'SQL']",2025-06-13 05:28:42
Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures\nIdentify data quality metrics and execute data quality audits to benchmark the state of data quality",,,,"['Data Management', 'Project Management', 'Data Analytics', 'Data Governance', 'Business Analysis']",2025-06-13 05:28:44
AVP Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Agile Methodology', 'Funds Transfer Pricing', 'Financial Data Mapping', 'Big Data Query Techniques', 'Lineage Tracing', 'Data warehousing', 'Data Governance', 'Jira', 'Market Risks', 'SQL']",2025-06-13 05:28:46
Business Analyst/ Data Scientist - SAS & SQL,Khushboo,3 - 8 years,10-20 Lacs P.A.,['Hyderabad'],"hands on SQL/ SAS programming experience & handling complex/large data\nMust have experience inTableau/Power BI\nExperience in campaign performance measurement, customer targeting framework\nProven ability to design and lead strategic projects\n\nRequired Candidate profile\nMust - SAS , SQL, Python\nGood in Statistical model , Predictive model, Logistic regression, Linear regression\nBFSI Mandatory - Credit risk, Credit Card, Retail Banking",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Decision Tree', 'sas', 'sql', 'Advanced Analytics', 'Strategy Building', 'Predictive Modeling', 'python', 'Logistic Regression', 'Segmentation', 'Random Forest', 'Linear Regression', 'Classification', 'Statistical Modeling', 'Credit Risk']",2025-06-13 05:28:47
Business Analyst - Data Warehouse,Vichara Technologies,6 - 11 years,30-35 Lacs P.A.,"['Coimbatore', 'Bengaluru', 'Delhi / NCR']","Collaborate with business stakeholders to gather and validate requirements\nCreate and manage Jira tickets\nSupport sprint planning, backlog grooming\nCreate clear, structured requirements documentation and user stories\n\nRequired Candidate profile\nExperience in analytics, business intelligence, or data warehouse projects (Snowflake, Power BI, Streamlit\nWorking knowledge of Jira\nknowledge in Alternative Asset Management or Investment Banking.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Investment Banking', 'Power Bi', 'User Stories', 'Business Analysis', 'Snowflake', 'python', 'streamlit', 'JIRA', 'SQL', 'Capital Market', 'Hedge Funds', 'Private Equity', 'Credit', 'Private Debt', 'MDM', 'Asset Management', 'Data Warehousing']",2025-06-13 05:28:49
Data Science Analyst (Senior),Infogain,6 - 8 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python.\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n- Strong storytelling and communication skills to convey complex analytical findings to both technical and non-technical audiences.\n- Demonstrates ownership and leadership, driving projects from idea to impact with minimal supervision.\nSKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-13 05:28:51
Lead Data Analyst - Power BI,Bot Consulting,5 - 8 years,Not Disclosed,['Jaipur'],"We are seeking an experienced and proactive Lead Data Analyst \\u2013 Power BI to lead the development of scalable analytics solutions and guide our growing data team in Jaipur. The ideal candidate will bring strong expertise in Power BI, SQL, Python, and experience with cloud data platforms such as Snowflake. You will be responsible for designing data models, leading dashboard/reporting initiatives, mentoring junior analysts, and enabling business stakeholders to make data-driven decisions.\nRoles & Responsibilities:\nLead the development and enhancement of interactive Power BI dashboards, reports, and data visualizations tailored to business requirements.\nArchitect and optimize data models in Power BI for performance and scalability (including DAX and Power Query transformations).\nBuild and manage robust end-to-end data pipelines, including data extraction, transformation, and loading (ETL/ELT).\nCollaborate with cross-functional stakeholders to translate business needs into technical solutions and actionable insights.\nPerform advanced data analysis using SQL and Python to uncover trends, patterns, and opportunities.\nEnsure data governance, quality, and consistency across all reporting assets and data platforms.\nMentor junior analysts and contribute to best practices in reporting, documentation, and code review.\nAct as a bridge between business and engineering teams, ensuring alignment and impact from analytics projects.\nWork with cloud data warehouses such as Snowflake or similar platforms for scalable analytics.\nSkills & Qualifications\n6+ years of experience in Data Analytics, Business Intelligence, or Data Engineering roles.\nProven expertise in Power BI, including dashboard development, DAX, data modeling, and Power Query.\nAdvanced proficiency in SQL and ability to work with large, complex datasets.\nProgramming experience in Python for data manipulation, automation, or machine learning (preferred).\nStrong understanding of ETL/ELT concepts, data warehousing, and modern cloud data platforms (Snowflake preferred).\nBachelors or Masters degree in Computer Science, Data Science, Engineering, or a related field.\nExcellent analytical thinking, problem-solving, and attention to detail.\nStrong communication skills and the ability to present data insights to non-technical stakeholders.\nPreferred Qualifications\nHands-on experience with Snowflake, Redshift, or BigQuery.\nFamiliarity with Airflow, DBT, or other orchestration tools.\nPower BI Certification (eg, PL-300: Microsoft Power BI Data Analyst).\nExperience with Agile methodologies and managing sprint-based BI deliverables.\nExposure to version control (Git) and CI/CD practices in data analytics projects.\nSigns You May Be a Great Fit\nImpact: Play a pivotal role in shaping a rapidly growing venture studio.\nCulture: Thrive in a collaborative, innovative environment that values creativity and ownership.\nGrowth: Access professional development opportunities and mentorship.\nBenefits: Competitive salary, health/we'llness packages, and flexible work options",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['IT services', 'Data analysis', 'Automation', 'Data modeling', 'Analytical', 'microsoft', 'Business intelligence', 'Analytics', 'SQL', 'Data extraction']",2025-06-13 05:28:53
Power BI - Data Analyst,Hakkda,3 - 6 years,Not Disclosed,['Jaipur'],"ABOUT HAKKODA\n\nHakkoda, an IBM Company, is a modern data consultancy that empowers data driven organizations to realize the full value of the Snowflake Data Cloud. We provide consulting and managed services in data architecture, data engineering, analytics and data science. We are renowned for bringing our clients deep expertise, being easy to work with, and being an amazing place to work! We are looking for curious and creative individuals who want to be part of a fast-paced, dynamic environment, where everyone s input and efforts are valued. We hire outstanding individuals and give them the opportunity to thrive in a collaborative atmosphere that values learning, growth, and hard work. Our team is distributed across North America, Latin America, India and Europe. If you have the desire to be a part of an exciting, challenging, and rapidly-growing Snowflake consulting services company, and if you are passionate about making a difference in this world, we would love to talk to you!.\n\nWe are looking for a skilled and motivated Data Analyst / Data Engineer to join our growing data team in Jaipur. The ideal candidate should have hands-on experience with SQL, Python, Power BI , and familiarity with Snowflake is a strong advantage. You will play a key role in building data pipelines, delivering analytical insights, and enabling data-driven decision-making across the organization.\nRole Description:\nDevelop and manage robust data pipelines and workflows for data integration, transformation, and loading.\nDesign, build, and maintain interactive Power BI dashboards and reports based on business needs.\nOptimize existing Power BI reports for performance, usability, and scalability .\nWrite and optimize complex SQL queries for data analysis and reporting.\nUse Python for data manipulation, automation, and advanced analytics where applicable.\nCollaborate with business stakeholders to understand requirements and deliver actionable insights .\nEnsure high data quality, integrity, and governance across all reporting and analytics layers.\nWork closely with data engineers, analysts, and business teams to deliver scalable data solutions .\nLeverage cloud data platforms like Snowflake for data warehousing and analytics (good to have).\nQualifications\n3-6 years of professional experience in data analysis or data engineering.\nBachelor s degree in computer science , Engineering, Data Science, Information Technology , or a related field.\nStrong proficiency in SQL with the ability to write complex queries and perform data modeling.\nHands-on experience with Power BI for data visualization and business intelligence reporting.\nProgramming knowledge in Python for data processing and analysis.\nGood understanding of ETL/ELT , data warehousing concepts, and cloud-based data ecosystems.\nExcellent problem-solving skills , attention to detail, and analytical thinking.\nStrong communication and interpersonal skills to work effectively with cross-functional teams .\nPreferred / Good to Have\nExperience working with large datasets and cloud platforms like Snowflake, Redshift, or BigQuery.\nFamiliarity with workflow orchestration tools (e.g., Airflow) and version control systems (e.g., Git).\nPower BI Certification (e.g., PL-300: Microsoft Power BI Data Analyst).\nExposure to Agile methodologies and end-to-end BI project life cycles.\nBenefits:\n\n- Health Insurance\n- Paid leave\n- Technical training and certifications\n- Robust learning and development opportunities\n- Incentive\n- Toastmasters\n- Food Program\n- Fitness Program\n- Referral Bonus Program\n\nHakkoda is committed to fostering diversity, equity, and inclusion within our teams. A diverse workforce enhances our ability to serve clients and enriches our culture. We encourage candidates of all races, genders, sexual orientations, abilities, and experiences to apply, creating a workplace where everyone can succeed and thrive.\n\nReady to take your career to the next level? Apply today and join a team that s shaping the future!!\n\nHakkoda is an IBM subsidiary which has been acquired by IBM and will be integrated in the IBM organization. Hakkoda will be the hiring entity. By Proceeding with this application, you understand that Hakkoda will share your personal information with other IBM subsidiaries involved in your recruitment process, wherever these are located. More information on how IBM protects your personal information, including the safeguards in case of cross-border data transfer, are available here.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Automation', 'Data modeling', 'Consulting', 'Agile', 'Workflow', 'microsoft', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-13 05:28:54
Data Analysis and Insight Lead,Tatvic Analytics,3 - 4 years,Not Disclosed,['Ahmedabad'],"Data Analysis and Insight Lead\nResponsibilities\nRole Overview\nIn this role:\nDevelop a digital analytics strategy, specific to your industry and organization KPIs. Tailor reporting system and dashboards to your business.\nSupport client team with ongoing business needs and analytics system maintenance.\nSetting up the required reporting system, timeframes, performance metrics, and dimensions. Providing Google Analytics consulting and Marketing Technology strategy.\nDevelop analysis and dashboards and have to communicate data-driven recommendations to improve customers business\nMandatory Qualifications:\nExcellent Time Management & Proactive approach for taking initiative and getting them executed by the team.\nAt least 3-4 years of experience working with major business verticals [BFSI, E-commerce, OTT, Publisher, Automobile] in servicing Indian, North American and APAC markets\nExceptional consulting and Advanced & Statistical analysis (\nsegregation analysis,\npre-post analysis,\nfeature attribution analysis,\nMedia Campaign Opportunity analysis(using DDA & Markov Chain)\nSeasonality Analysis\nMarket Basket Analysis to identify products/channels that drive value\nTV data analysis\nClustering, Linear & Logical Regression, Time Series expertise.\nSkills: Google Analytics, Adobe Analytics, Google Cloud Platform Exposure, Hands-on experience on Big Query [SQL expertise]. GAIQ,\nA tool-agnostic analytics consultant.\nGood to have: Pre-sales Business flavor",Industry Type: Film / Music / Entertainment,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'digital analytics', 'Google Analytics', 'adobe analytics', 'Statistical analysis', 'Bfsi', 'Consulting', 'Manager Technology', 'Analytics', 'SQL']",2025-06-13 05:28:56
Human Resource - Data Analyst,Suzlon Group,3 - 6 years,Not Disclosed,['Pune( Hadapsar )'],"Role & responsibilities\nKey Responsibilities:\nImplement strategies, including compensation, benefits, and recognition programs.\nConduct manpower budgeting and forecasting to ensure optimal workforce planning.\nUtilize advanced Excel skills to analyze HR data and generate insightful reports.\nCreate HR dashboards in Excel\nPrepare the presentations for Management",,,,"['HR Analytics', 'Communication Skills', 'Project Management', 'Data Management', 'Hr Practices']",2025-06-13 05:28:58
Associate Data Analyst- Contractual,Windows Consultants Pvt Ltd,4 - 8 years,Not Disclosed,['Gurugram'],"Job Title: Data Analytics Associate Finance Team\nContractual Role- 1 year\nWe are seeking a Data Analytics Associate to join our Finance team. This role is ideal\nfor an analytical thinker with a passion for data-driven insights and business\nperformance analysis.\nKey Responsibilities:\n• Collect, clean, and maintain datasets from multiple sources (sales, operations,\ncustomer data).\n• Ensure data accuracy and integrity across various platforms.\n• Assist in developing dashboards and reports to support business decision-\nmaking.\n• Analyze sales trends, inventory levels, and operational performance to\nprovide actionable insights.\n• Support in monitoring the effectiveness of marketing campaigns,\npromotions, and pricing strategies.\n• Utilize tools like Excel, SQL, Tableau, and Power BI to interpret data.\n• Collaborate with cross-functional teams (Marketing, Operations, Finance) to\nalign analytics initiatives with business objectives.\n• Identify operational inefficiencies and suggest improvements based on data\nanalysis.\n• Assist in automating and optimizing reporting processes to improve efficiency.\nWhat Were Looking For:\n• 1+ year of experience in data analytics, business intelligence, or financial\nanalytics.\n• Proficiency in Excel, SQL, Power BI (knowledge of Python/R is a plus).\n• Strong analytical skills with the ability to interpret complex datasets and\ngenerate insights.\n• A proactive and detail-oriented mindset with a problem-solving approach.\n• Strong communication skills to present findings in a clear and concise manner.\n• Ability to work collaboratively across teams and contribute to data-driven\ndecision-making.",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'R', 'Power Bi', 'Tableau', 'Dashboards', 'Python']",2025-06-13 05:28:59
Data Analyst (Analytics) - Intermediate,Equifax Credit Information Services Private Limited,2 - 5 years,Not Disclosed,['Pune'],"What you ll do\nWorks independently within Data and Analytics with limited design help from manager or senior associates\nLeverage coding best practices and advanced techniques to ensure efficient execution of code against large datasets, ensuring code is repeatable and scalable\nRun, create and optimize standard processes to ensure metrics, reports and insights are delivered consistently to stakeholders with minimal manual intervention",,,,"['Diagnostics', 'Coding', 'GCP', 'Analytical', 'data governance', 'Healthcare', 'Data structures', 'Analytics', 'SQL', 'Python']",2025-06-13 05:29:01
"Medical Data Analyst (Pharmacovigilance, Medical Summarization)",Ardem Data Services,1 - 5 years,Not Disclosed,[],"Shift Timings: 10:00 PM to 7:00 AM\nNight Shift experience mandatory\n\nWe are seeking a Medical Data Entry professional with a minimum of 1 year of experience in medical data annotation and document review. The ideal candidate will have a background in medical or pharmaceutical sciences and possess key skills related to medical data management, regulatory guidelines (FDA, EMA, ICH, GCP), and patient report handling. This role requires mandatory night shift experience and is a permanent work-from-home position.\nKey Responsibilities:\nReview and annotate medical documents and patient records accurately.\nApply knowledge of FDA, EMA, ICH, and GCP guidelines to data management tasks.\nPerform clinical data management activities.\nHandle and process patient reports efficiently.\nEnsure data quality and integrity during the entry and annotation process.\nRequirements:\nQualification: B.Sc, M.Sc, B.Pharma, or M.Pharma.\nMinimum 1 year of experience in medical data annotation and medical document review.\nMandatory experience working night shifts (US shift: 10:00 pm to 7:00 am).\nExperience with FDA, EMA, ICH, and GCP guidelines.\nProficiency in Clinical Data Management and handling Patient Reports.\nOnly candidates with a medical background and medical data annotation experience will be considered.\nImmediate joiner preferred.\nTechnical Requirements:\nLaptop or Desktop: Windows (i5 or higher, 8GB RAM minimum)\nScreen: 14 inches, Full HD (19201080)\nInternet Speed: 100 Mbps or higher\nAbout ARDEM\nARDEM is a leading Business Process Outsourcing and Business Process Automation service provider. For over twenty years, ARDEM has successfully delivered business process outsourcing and business process automation services to our clients in the USA and Canada. We are growing rapidly. We are constantly innovating to become a better service provider for our customers. We continuously strive for excellence to become the Best Business Process Outsourcing and Business Process Automation company.\nNOTE!\nARDEM will never ask for any personal information or banking information during the hiring process for any data entry/processing type of work. If you are contacted by any party claiming to represent ARDEM Incorporated offering work from home jobs this is fraud. Please disregard and refer to ARDEMs Careers page for all open job positions. We apologize for any inconvenience caused by such acts.",Industry Type: Miscellaneous,Department: Research & Development,"Employment Type: Full Time, Permanent","['US Healthcare', 'Pharmacovigilance', 'Medical Terminology', 'Summarizing', 'Patient reports', 'Electronic Medical Record', 'CPT', 'Medical Records', 'Medical Scribe', 'Medical Data Analyst', 'ICD', 'Medical Summarization', 'Medical Transcription', 'Medical', 'Clinical Data Management', 'Data Annotation']",2025-06-13 05:29:03
Client Reference Data Analyst,Quantum Leap Consulting,2 - 3 years,3.5-4.5 Lacs P.A.,['Mumbai'],"Job Title: Client Reference Data Analyst\nWork Location: Mumbai\nEmployment Type: 1-Year Contract\nShift Timing: 12:30 PM 9:30 PM IST\nExperience Required: 2+ years\nNotice Period: Immediate\nLaptop Provided: Yes, if needed\nCompensation: Up to 5 LPA\nAbout the Role:\nWe are hiring a Client Reference Data Analyst to join the operations team of a leading global financial services firm. This role involves managing client data, setting up new accounts, and ensuring documentation and reporting accuracy. The role is ideal for professionals who are organized, detail-oriented, and familiar with financial data operations or client onboarding processes.\nKey Responsibilities:\nOpen and link client accounts on financial platforms such as Prime Brokerage or Portfolio Accounting systems.\nSet up account-level reporting and entitlements for clients and third-party users.\nReview and validate documentation submitted for account and reporting setup.\nPerform quality checks for newly created or modified client accounts.\nRequest and manage secure login credentials (e.g., Secure IDs) for client systems access.\nTrack and resolve issues related to account setup, data integrity, and documentation.\nCoordinate with internal teams for issue escalation and workflow alignment.\nMonitor key metrics and Service Level Agreements (SLAs) to ensure timely and accurate delivery.\nIdentify areas for process improvement and assist in implementing solutions.\nSupport team leads with rollout of new tools, processes, or reporting templates.\nMust-Have Skills:\nMinimum 2 years of experience in client onboarding, client data management, or financial operations.\nStrong knowledge of account creation and entitlements setup in financial or investment platforms.\nExcellent skills in Microsoft Excel including Pivot Tables, VLOOKUP, and data reporting.\nExposure to client documentation handling, preferably in the capital markets or banking domain.\nStrong problem-solving skills and ability to escalate with context and ownership.\nExperience in managing high volumes with precision under tight timelines.\nGood verbal and written communication skills to liaise with internal stakeholders.\nGood-to-Have:\nExposure to prime brokerage, reference data, or investment banking operations.\nFamiliarity with global markets, client reporting, or capital market products.\nPrior experience in a client-facing or middle office support role in BFSI.\nSoft Skills Required:\nHigh attention to detail and accuracy\nAdaptability and willingness to learn\nAbility to prioritize tasks effectively\nCollaborative team player\nClient service orientation and ownership\nProfessional and proactive communication",Industry Type: IT Services & Consulting,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Client onboarding', 'Data Management', 'Stakeholder management', 'reference data', 'Account opening']",2025-06-13 05:29:05
Financial Data Analyst,IPS group,1 - 6 years,3.5-4.5 Lacs P.A.,['Kolkata'],"Qualification: B Com / M.Com /MBA Finance\n\nExperience: Minimum 1 year of experience as a Financial Data Analyst\n\nJob Requirement:\n* Domain / Accounting knowledge and skills\n* Basic understanding of accounting principles and Finance\n* Good verbal and written communication skills\n* Willingness to work in rotational and night shifts\n\nJob Description:-\n* Research, Review, Analyze and Interpret financial statements/Broker reports of large corporates from global markets.\n* Ensure compliance with global policies including US GAAP & IFRS.\n* Capture data points of interest from financial reports and tag the same from Income Statement, Balance Sheet & Cash flow through an application.\n* Transaction based activities, rule-based decision making, verifying for accuracy and completeness, formatting data, posting and preparing output (various types of reconciliations, system to system  reconciliations, balancing, open item management, reports etc)\n* Constant quality check on the finalization of statement.\n* Capture specific figures from Revenue, Net Income, EPS, Weighted Average Shares, Income before tax,\nIncome Tax & One-time charges & provide timely, relevant and accurate information for Earnings.\n* Capture the future estimated data as given in press release, earnings call & company presentation report for Guidance.\n* Number crunching on specific items of the Income Statement, Balance sheet & Cash Flow.\n* Understanding of financial processes and applications",Industry Type: BPM / BPO,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Finance Data Analyst', 'Financial Statements', 'Ifrs Reporting', 'Financial Reporting', 'US GAAP', 'Financial Accounting', 'IFRS']",2025-06-13 05:29:06
Data Analyst Rights Management Claims,Straive,1 - 3 years,Not Disclosed,[],"Overview\n\nAs a Conflicts Coordinator, you will oversee the resolution of rights conflicts for the client audio and video catalog on various platforms while adhering to strict project deadlines. You will also aid in the development of new projects and processes to proactively free up revenue for our clients and will be responsible for frequently communicating with stakeholders internally and externally, including label management, 3rd party rightsholders, and platform contacts.",,,,"['Google Sheets', 'Excel', 'Complex Data Management', 'Advanced Excel', 'SQL', 'Spreadsheets', 'Data Management']",2025-06-13 05:29:08
Marketing Data Analyst,Ajni Consulting,5 - 10 years,10-14 Lacs P.A.,['Hyderabad'],"5+ years of experience in data management, marketing operations, sales operations,\n• Familiarity with CRM systems (e.g., Salesforce) and data management tools like\nInterested candidates share on purnima.prometheus@gmail.com or whtsapp 9220927729",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Salesforce', 'tag management', 'Sales Operations', 'Marketing Operations', 'Marketing Analytics', 'Customer Support Operations', 'Adobe Analytics']",2025-06-13 05:29:10
Master Data Analyst- Reporting,Client of RK Hr Management,3 - 8 years,20-30 Lacs P.A.,['Ahmedabad'],"Compare and match data between systems; investigate and fix mismatches.\n\nHelp build dashboards, support audits, and maintain clear documentation.\n\nManage new data entries, ensure accuracy, and oversee smooth data processes.\n\nRequired Candidate profile\n3 to 5 years experience\nExperience of Data Governance and systems related DG\nConfidence in using applications, some systems experience - SAP, HFM, Oracle, Snowflake,\nAutonomy to review and research",Industry Type: FMCG,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Mdg', 'Power BI', 'Master Data Management', 'Data Governance', 'Data Reporting', 'SAP', 'Snowflake', 'Data Cleansing', 'Master data reporting', 'Master Data', 'Oracle', 'HFM']",2025-06-13 05:29:12
Master Data Analyst Reporting,RK Hr Management,3 - 7 years,8-14 Lacs P.A.,['Ahmedabad'],"3–5 yrs exp in data reconciliations (Catalyst/Keystone to GFIN, GFIN vs HFM), dashboard support (Power BI), audit support, and data governance (MDG). Proactive, Excel-savvy, system-fluent (SAP, HFM, Oracle), with strong analytical and comms skills.",Industry Type: FMCG,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Reconciliation', 'SAP', 'oracle', 'Power BI', 'Data Governance', 'Data Quality', 'Data Management', 'Data Visualization', 'Etl Process', 'Tableau', 'Communication']",2025-06-13 05:29:13
"Senior Analyst, Data and Product Solution",NOVARTIS,1 - 3 years,Not Disclosed,['Hyderabad'],"Summary\nNovartis specialists within Data and Product Solutions are on a data and digital transformation journey, leveraging analytics to generate actionable insights for Novartis medicines impacting more than 799 million patients worldwide. The team is poised to enable easier, faster, and reliable decisions for Novartis divisions across the globe.\nAbout the Role\nLocation - Hyderabad #Hybrid\nAbout the role:",,,,"['Analytical', 'Pharma', 'Diversity and Inclusion', 'Market research', 'Project planning', 'healthcare analytics', 'Stakeholder management', 'digital transformation', 'SQL', 'Python']",2025-06-13 05:29:15
"Data Analyst-CRM tool (Must Be expert with ZOHO, Sales Force) Delhi",Indo Edge Human Resources Delhi,2 - 7 years,3-5.5 Lacs P.A.,"['New Delhi', 'Delhi / NCR']","hands on experience in CRM Tools especially ZOHO, Sales Force etc\n\nRequired Candidate profile\nMust have hands on experience in CRM Tools especially ZOHO, Sales Force etc",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Sales Force', 'ZOHO', 'Lead Squared', 'CRM tool', 'Data Analyst', 'Crm Software']",2025-06-13 05:29:16
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst\n\nIn this role, you will:\nOrganize and lead complex companywide initiatives to ensure that data quality is maintained so that data can effectively support business processes\nOversee analysis and reporting in support of regulatory requirements",,,,"['Data Management', 'metadata', 'Project Management', 'Teradata', 'Analytics', 'Business Analysis', 'SQL']",2025-06-13 05:29:18
Data Management Analyst,Wells Fargo,2 - 6 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Project Management', 'data Analysis', 'Data governance', 'Business Analysis']",2025-06-13 05:29:20
S&C GN - Data&AI - Life Sciences - Analyst,Accenture,2 - 7 years,Not Disclosed,['Gurugram'],"Management Level:Ind & Func AI Decision Science Analyst\n\n\n\n\nJob Location:Bangalore / Gurgaon\n\n\n\nMust-have\n\n\n\n\nSkills:\nLife Sciences/Pharma/Healthcare projects and delivering successful outcomes, commercial, clinical, Statistical Models/Machine Learning including Segmentation & predictive modeling, hypothesis testing, multivariate statistical analysis, time series techniques, and optimization.\n\n\n\nGood-to-have\n\n\n\n\nSkills:\nProficiency in Programming languages such as R, Python, SQL, Spark, AWS, Azure, or Google Cloud for deploying and scaling language models, Data Visualization tools like Tableau, Power BI\n\n\n\nExperience:Proven experience (2+ years) in working on Life Sciences/Pharma/Healthcare projects and delivering successful outcomes.\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Statistics, Data Science, Applied Mathematics, Business Analytics, Computer Science, Information Systems, or other Quantitative field.\n\n\n\nJob\n\n\nSummary\n\nWe are seeking an experienced and visionary - Accenture S&C Global Network - Data & AI practice help our clients grow their business in entirely new ways. Analytics enables our clients to achieve high performance through insights from data - insights that inform better decisions and strengthen customer relationships. From strategy to execution, Accenture works with organizations to develop analytic capabilities - from accessing and reporting on data to predictive modelling - to outperform the competition.\n\n\n\nKey Responsibilities\nSupport delivery of small to medium-sized teams to deliver consulting projects for global clients.\nAn opportunity to work on high-visibility projects with top Pharma clients around the globe.\nPersonalized training modules to develop your strategy & consulting acumen to grow your skills, industry knowledge, and capabilities.\nResponsibilities may include strategy, implementation, process design, and change management for specific modules.\nWork with the team or as an Individual contributor on the project assigned which includes a variety of skills to be utilized from Data Engineering to Data Science\nDevelop assets and methodologies, point-of-view, research, or white papers for use by the team and the larger community.\nWork on variety of projects in Data Modeling, Data Engineering, Data Visualization, Data Science etc.,\nAcquire new skills that have utility across industry groups.\n\n\n\n\n\nAdditional Information\nAbility to solve complex business problems and deliver client delight.\nStrong writing skills to build points of view on current industry trends.\nGood communication, interpersonal, and presentation skills\n\n\nAbout Our Company | Accenture (do not remove the hyperlink)\n\n\nQualification\n\n\n\nExperience:Proven experience (2+ years) in working on Life Sciences/Pharma/Healthcare projects and delivering successful outcomes.\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Statistics, Data Science, Applied Mathematics, Business Analytics, Computer Science, Information Systems, or other Quantitative field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['pharmaceutical', 'python', 'sql', 'life sciences', 'aws', 'presentation skills', 'microsoft azure', 'power bi', 'time series', 'machine learning', 'artificial intelligence', 'tableau', 'r', 'data science', 'gcp', 'spark', 'predictive modeling', 'statistical modeling', 'data visualization', 'statistics']",2025-06-13 05:29:22
Analyst - Master Data Management,Danfoss,1 - 3 years,Not Disclosed,"['Oragadam', 'Chennai']","Job Description\nWe are seeking a motivated and detail-oriented Analyst to join our team. The successful candidate will be responsible for material creation/extension in Glasswing, executing mass changes in SAP, improving data quality in collaboration with data stewards, and implementing automation rules to streamline processes.\nJob Responsibilities\n    Material Creation/Extension in Glasswing: Create and extend material records in the Glasswing system, ensuring accuracy and compliance with company standards.\n•    Mass Changes in SAP: Perform mass updates and changes in the SAP system, maintaining data integrity and consistency.\n•    Data Quality Improvement: Collaborate with data stewards to identify and rectify data quality issues, ensuring high standards of data accuracy and reliability.\n•    Automation Rules Implementation: Develop and implement automation rules to enhance efficiency and reduce manual intervention in data management processes.",,,,"['SAP MM', 'MDM', 'Master Data Management', 'SAP MDM']",2025-06-13 05:29:24
Data Scientist,Tesco,1 - 3 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Summary:\n\nEnable data driven decision making across the Tesco business globally by developing analytics solutions using a combination of math, tech and business knowledge\n\nRoles and Responsibilities:\n- Identifying operational improvements and finding solutions by applying CI tools and techniques\n- Responsible for completing tasks and transactions within agreed KPI's",,,,"['Data Science', 'Advanced Excel', 'Data Analytics', 'Python', 'SQL', 'Applied Mathematics', 'Machine Learning', 'Statistics']",2025-06-13 05:29:26
Data Science Analyst (Lead),Infogain,8 - 11 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python.\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n- Strong storytelling and communication skills to convey complex analytical findings to both technical and non-technical audiences.\n- Demonstrates ownership and leadership, driving projects from idea to impact with minimal supervision.\n  SKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-13 05:29:27
Senior Data Scientist | Snowflakes | Tableau | AI/ML,Cisco,0 - 2 years,Not Disclosed,['Bengaluru'],"Job posting may be removed earlier if the position is filled or if a sufficient number of applications are received.\n\nMeet the Team\n\nWe are a dynamic and innovative team of Data Engineers, Data Architects, and Data Scientists based in Bangalore, India. Our mission is to harness the power of data to provide actionable insights that empower executives to make informed, data-driven decisions. By analyzing and interpreting complex datasets, we enable the organization to understand the health of the business and identify opportunities for growth and improvement.\n\nYour Impact\n\nWe are seeking a highly experienced and skilled Senior Data Scientist to join our dynamic team. The ideal candidate will possess deep expertise in machine learning models, artificial intelligence (AI), generative AI, and data visualization. Proficiency in Tableau and other visualization tools is essential. This role requires hands-on experience with databases such as Snowflake and Teradata, as well as advanced knowledge in various data science and AI techniques. The successful candidate will play a pivotal role in driving data-driven decision-making and innovation within our organization.\n\nKey Responsibilities\nDesign, develop, and implement advanced machine learning models to solve complex business problems.\nApply AI techniques and generative AI models to enhance data analysis and predictive capabilities.\nUtilize Tableau and other visualization tools to create insightful and actionable dashboards for stakeholders.\nManage and optimize large datasets using Snowflake and Teradata databases.\nCollaborate with cross-functional teams to understand business needs and translate them into analytical solutions.\nStay updated with the latest advancements in data science, machine learning, and AI technologies.\nMentor and guide junior data scientists, fostering a culture of continuous learning and development.\nCommunicate complex analytical concepts and results to non-technical stakeholders effectively.\nKey Technologies &\n\nSkills:\nMachine Learning ModelsSupervised learning, unsupervised learning, reinforcement learning, deep learning, neural networks, decision trees, random forests, support vector machines (SVM), clustering algorithms, etc.\nAI TechniquesNatural language processing (NLP), computer vision, generative adversarial networks (GANs), transfer learning, etc.\nVisualization ToolsTableau, Power BI, Matplotlib, Seaborn, Plotly, etc.\nDatabasesSnowflake, Teradata, SQL, NoSQL databases.\nProgramming LanguagesPython (essential), R, SQL.\nPython LibrariesTensorFlow, PyTorch, scikit-learn, pandas, NumPy, Keras, SciPy, etc.\nData ProcessingETL processes, data warehousing, data lakes.\nCloud PlatformsAWS, Azure, Google Cloud Platform.\nMinimum Qualifications\nBachelor's or Master's degree in Computer Science, Statistics, Mathematics, Data Science, or a related field.\nMinimum of [X] years of experience as a Data Scientist or in a similar role.\nProven track record in developing and deploying machine learning models and AI solutions.\nStrong expertise in data visualization tools, particularly Tableau.\nExtensive experience with Snowflake and Teradata databases.\nExcellent problem-solving skills and the ability to work independently and collaboratively.\nExceptional communication skills with the ability to convey complex information clearly.\nPreferred Qualifications (Provide up to five (5) bullet points these can include soft skills)\nExcellent communication and collaboration skills to work effectively in cross-functional teams.\nAbility to translate business requirements into technical solutions.\nStrong problem-solving skills and the ability to work with complex datasets.\nExperience in statistical analysis and machine learning techniques.\nUnderstanding of business domains such as sales, financials, marketing, and telemetry.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['machine learning', 'artificial intelligence', 'sql', 'tableau', 'data visualization', 'snowflake', 'scipy', 'python', 'scikit-learn', 'data warehousing', 'numpy', 'pandas', 'tensorflow', 'data integration tools', 'matplotlib', 'pytorch', 'keras', 'machine learning algorithms', 'etl', 'nosql databases']",2025-06-13 05:29:29
Data Governance & Data Quality Sr Associate Analyst,Amgen Inc,2 - 5 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgen's data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leveragesstate-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. This role involves working closely with business stakeholder and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with Data Product Owners, Data Stewards and technology teams to increase the trust and reuse of data across Amgen.",,,,"['Data Governance', 'data quality', 'Collibra', 'data stewardship', 'metadata management', 'Agile software development methodologies', 'Alation', 'data protection', 'master data management', 'SQL', 'Python']",2025-06-13 05:29:31
Senior Data Test Analyst,Exavalu,6 - 8 years,Not Disclosed,[],"We are seeking a detail-oriented and experienced Senior Data Test Analyst to join our team. The ideal candidate will have a strong background in testing large-scale data migration projects, along with hands-on experience in ETL testing, data quality validation, and test automation. The role requires designing and executing robust testing strategies to ensure data integrity, accuracy, and compliance.\nKey Responsibilities:\nExperience Range - 6 to 8 Years\nDevelop and execute test strategies for large-scale data migration using statistical sampling and verification techniques.\nDesign and implement test plans covering Data Migration, Obfuscation, Reconciliation, Data Quality, and Data Governance.\nConduct thorough testing of ETL processes using tools such as Ab Initio and Informatica.\nPerform report testing for both operational and regulatory reporting requirements.\nEnsure comprehensive test coverage through data profiling and validation techniques.\nCollaborate with data architects, business analysts, and developers to understand data requirements and transformation logic.\nDevelop and maintain automated test scripts for data validation and regression testing.\nPrepare detailed test plans, test cases, and defect reports for data migration and integration efforts.\nRequirements\nProven experience in data migration testing, including validation strategies and statistical sampling.\nStrong hands-on experience with ETL testing tools such as Ab Initio and/or Informatica.\nExpertise in data obfuscation, reconciliation, data quality, and governance testing.\nSolid understanding of regulatory and operational reporting testing.\nExperience in automation testing frameworks related to data validation.\nAbility to design and document test plans specifically tailored to data migration projects.\nFamiliarity with SQL for data querying and validation.\nExcellent analytical and problem-solving skills",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data migration', 'Test scripts', 'Testing tools', 'Analytical', 'Reconciliation', 'Regression testing', 'Data quality', 'Informatica', 'Test cases', 'SQL']",2025-06-13 05:29:33
Data Modeler,Synechron,0 - 2 years,Not Disclosed,['Bengaluru'],"Synechron is seeking a knowledgeable and proactive Data Modeler to guide the design and development of data structures that support our clients' business objectives. In this role, you will collaborate with cross-functional teams to translate business requirements into scalable and efficient data models, ensuring data accuracy, consistency, and integrity. You will contribute to creating sustainable and compliant data architectures that leverage emerging technologies such as cloud, IoT, mobile, and blockchain. Your work will be instrumental in enabling data-driven decision-making and operational excellence across projects.Software Required\n\nSkills:\nStrong understanding of data modeling concepts, methodologies, and tools Experience with data modeling for diverse technology platforms including cloud, mobile, IoT, and blockchain Familiarity with database management systems (e.g., relational, NoSQL) Knowledge of SDLC and Agile development practices Proficiency in modeling tools such as ERwin, PowerDesigner, or similar Preferred Skills:\nExperience with data integration tools and ETL processes Knowledge of data governance and compliance standards Familiarity with cloud platforms (AWS, Azure, GCP) and how they impact data architectureOverall Responsibilities Collaborate with business analysts, data engineers, and stakeholders to understand data requirements and translate them into robust data models Design logical and physical data models optimized for performance, scalability, and maintainability Develop and maintain documentation for data structures, including data dictionaries and metadata Conduct reviews of data models and code to ensure adherence to quality standards and best practices Assist in designing data security and privacy measures in alignment with organizational policies Stay informed about emerging data modeling trends and incorporate best practices into project delivery Support data migration, integration, and transformation activities as needed Provide technical guidance and mentorship related to data modeling standardsTechnical Skills (By Category) Data Modeling & Data Management: EssentialLogical/physical data modeling, ER diagrams, data dictionaries PreferredDimensional modeling, data warehousing, master data management Programming Languages: PreferredSQL (expertise in writing complex queries) OptionalPython, R for data analysis and scripting Databases & Data Storage Technologies: EssentialRelational databases (e.g., Oracle, SQL Server, MySQL) PreferredNoSQL (e.g., MongoDB, Cassandra), cloud-native data stores Cloud Technologies: PreferredBasic understanding of cloud data solutions (AWS, Azure, GCP) Frameworks & Libraries: Not typically required, but familiarity with data integration frameworks is advantageous Development Tools & Methodologies: EssentialData modeling tools (ERwin, PowerDesigner), version control (Git), Agile/Scrum workflows Security & Compliance: Knowledge of data security best practices, regulatory standards like GDPR, HIPAAExperience Minimum of 8+ years of direct experience in data modeling, data architecture, or related roles Proven experience designing data models for complex systems across multiple platforms (cloud, mobile, IoT, blockchain) Experience working in Agile environments using tools like JIRA, Confluence, Git Preference for candidates with experience supporting data governance and data quality initiativesNoteEquivalent demonstrated experience in relevant projects or certifications can qualify candidates.Day-to-Day Activities Participate in daily stand-ups and project planning sessions Collaborate with cross-functional teams to understand and analyze business requirements Create, review, and refine data models and associated documentation Develop data schemas, dictionaries, and standards to ensure consistency Support data migration, integration, and performance tuning activities Conduct peer reviews and provide feedback on data models and solutions Keep current with the latest industry developments in data architecture and modeling Troubleshoot and resolve data-related technical issuesQualifications Bachelors or Masters degree in Computer Science, Data Science, Information Technology, or related fields Demonstrated experience with data modeling tools and techniques in diverse technological environments Certifications related to data modeling, data management, or cloud platforms (preferred)Professional Competencies Strong analytical and critical thinking skills to develop optimal data solutions Effective communication skills for translating technical concepts to non-technical stakeholders Ability to work independently and in collaborative team environments Skilled problem solver able to handle complex data challenges Adaptability to rapidly evolving technologies and project requirements Excellent time management and prioritization skills to deliver quality outputs consistently",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data modeling', 'modeling tools', 'relational databases', 'scrum', 'agile', 'confluence', 'hipaa', 'data warehousing', 'data architecture', 'erwin', 'sql', 'git', 'gcp', 'mysql', 'etl', 'mongodb', 'jira', 'python', 'oracle', 'microsoft azure', 'sql server', 'nosql', 'gdpr', 'cassandra', 'aws', 'data integration', 'sdlc']",2025-06-13 05:29:35
Data Engineer,Accenture,5 - 10 years,Not Disclosed,['Bengaluru'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL processes to migrate and deploy data across systems. Your day will involve working on data solutions and ensuring data integrity and quality.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Develop and maintain data pipelines for efficient data processing.- Implement ETL processes to migrate and deploy data across systems.- Ensure data quality and integrity throughout the data solutions.- Collaborate with cross-functional teams to optimize data processes.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of data engineering principles.- Experience with cloud-based data solutions like AWS or Azure.- Knowledge of SQL and NoSQL databases.- Hands-on experience with data modeling and schema design.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Bengaluru office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data engineering', 'sql', 'etl', 'aws', 'hive', 'python', 'data processing', 'microsoft azure', 'pyspark', 'data warehousing', 'data integrity', 'knowledge of sql', 'nosql', 'database design', 'data quality', 'data modeling', 'spark', 'hadoop', 'big data', 'etl process', 'nosql databases']",2025-06-13 05:29:37
Intern - Business Analyst,Purplle.com,0 - 1 years,Not Disclosed,['Mumbai'],"As a Business Analyst within our Operations team, you will play a pivotal role in leveraging data-driven insights to optimize processes, enhance operational efficiency, and drive strategic decision-making. Your responsibilities will involve utilizing a mix of technical skills and business acumen to interpret complex data sets, generate actionable insights, and support operational improvements.\n\nKey Responsibilities:\nCollaborate closely with cross-functional teams to understand operational requirements, identify opportunities for improvement, and define key performance indicators (KPIs) to measure success.\n\nAnalyze large datasets using SQL, Python, and advanced Excel techniques to extract, transform, and visualize data for operational reporting and decision making purposes.\n\nDevelop and maintain automated reports and dashboards using Power BI, Power Query, Tableau, Data Studios, Looker, and other visualization tools to communicate insights effectively.\n\nConduct in-depth analysis and interpretation of operational data to identify trends, patterns, and anomalies, providing actionable recommendations to drive operational excellence.\n\nUtilize strong aptitude and logical thinking to solve complex operational challenges and contribute to strategic initiatives that optimize workflows and enhance overall business performance.\n\nFoster strong stakeholder relationships through effective communication, presenting insights, and collaborating on operational strategies and solutions.\n\nRequired Skills and Qualifications:\nBachelor's degree in Business Administration, Data Science, Computer Science, or a related field.\n\nProficiency in SQL, Python, and advanced Excel for data analysis and manipulation.\n\nHands-on experience with Power BI, Power Query, Tableau, Data Studios, Looker, or similar visualization tools.\n\nStrong analytical and problem-solving abilities with a sharp aptitude for logical thinking.\n\nExcellent communication skills and the ability to effectively engage with stakeholders at all levels.\n\nProven track record of successfully managing and prioritizing multiple projects simultaneously in a fast-paced environment.\n\nStrong collaborative skills and the ability to work effectively in a team-oriented culture.\n\nPreferred Qualifications:\nExperience in the e-commerce industry or within a high-growth, dynamic environment.\n\nKnowledge of additional programming languages, statistical tools, or data modeling techniques.\n\nCertifications in business analysis, data visualization, or related fields",Industry Type: Beauty & Personal Care,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analysis', 'power bi', 'business analysis', 'data warehousing', 'analysis', 'business intelligence', 'sql server', 'sql', 'data studio', 'excel', 'power query', 'tableau', 'data modeling', 'advanced excel', 'google analytics', 'data visualization', 'reporting', 'communication skills']",2025-06-13 05:29:39
Scientific Business Analyst (Associate) - ELN,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nThis role involves working closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements scientific software platforms such as Laboratory Information Management Systems (LIMS) that enable the capture of lab workflows & experimental data and Electronic Lab Notebooks (ELN) that act as Amgens System of Record ensuring data integrity and business continuity. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\n\n\n\n\nWe are all different, yet we all use our unique contributions to serve patients.",,,,"['Business Analysis', 'LIMS platforms', 'ELN platforms']",2025-06-13 05:29:40
Data Science Analyst,Cigna Medical Group,2 - 4 years,Not Disclosed,['Bengaluru'],"Key responsibilities\nDeliver quality analytics, from data preparation, data analysis, data exploration, data quality assessment, data manipulation, method selection, design & application, insights generation and visualisation\nDevelop and implement basic machine learning models and algorithms under the guidance of senior data scientists to extract insights and solve business problems\nProactive learning and acquisition of key analytical, technical and commercial skills and business knowledge to become a proficient Analyst working under the supervision of the senior/lead data science analysts.\nKPIs: Timeliness, accuracy, manager and client feedback (Internal and external as required)\nCollaborate with internal stakeholders and demonstrate the ability to transform client questions and problems into analytical solutions\nActive team member in providing the required support to help business understand and optimise use of analytical products and / or solutions\nBuild industry knowledge on the advancements in the field of analytics, data science and GenAI\nComply with the IM Cigna and CHSI Policies, procedures and processes, and continuously demonstrate Cigna Data and Analytics culture.\nKey activities\nWorking in a team to support end-to-end analytical projects\nLiaising with stakeholders to determine objectives / scope of upcoming projects\nData exploration, cleansing and manipulation\nDetermining appropriate type of analysis and undertaking analysis/modelling\nExtracting insights\nClear presentation of insights via spreadsheets, PowerPoint presentations, self-service analytical visualisation tools\nParticipate in client meetings\nOngoing stakeholder interaction (internal and external as required) on project progress\nContribute to the Feedback process (between stakeholders and the team) to ensure continuous improvement with team\nParticipate and contribute in learning forums such as Analytics Community and sharing knowledge with wider team\nExperience and education required\n2-4+ years experience in a technical analytics environment, carrying out data analytics and data science/AI projects and initiatives\nTertiary qualifications in engineering, mathematics, actuarial studies, statistics, physics, or a related discipline\nKnowledge of technical analytics discipline, including data preparation and foundational analytics concepts\nExperience with successfully managing both internal and external stakeholders, delivering against projects, tasks and activities in a dynamic deadline driven environment\nCommercial acumen to understand business needs and be able to suggest the commercial impacts of different analytics solutions or approaches\nCoding and modelling experience in SQL / R / Python and / or Cloud data platforms e.g. AWS\nExperience in visualization and data management tools is an added advantage\nExperience in GenAI/ LLMs is an added advantage\nExperience working with complex datasets\nAttention to detail and self driven continuous learning\nParticipation in external data hackathons and competitions will be an added advantage",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Data management', 'Coding', 'Analytical', 'Healthcare', 'Actuarial', 'Data quality', 'Continuous improvement', 'SQL', 'Python']",2025-06-13 05:29:42
Data Quality Analyst,Yallas Technology Solutions Opc,5 - 10 years,Not Disclosed,[],"Title: Data Quality Analyst/Developer\nDuration: 6 months to 1 year contract\nLocation:  Remote\nNotice period - Immediate to 7 days\nUAN /EPFO Report Required\n\nWork Experience:\n5 + years of this experience - Experience doing Data Emendation\nDesign/Develop Rules, monitoring mechanisms, notification\nDesign/Develop UI, Workflows, security\nDesign/Develop analytics (overall DQ reporting, usage statistics, etc).\nDesign/Develop migration activities to migrate existing DQ assets between our existing DQ platform and new DQ platform.\nDesign integration with MDM & Catalog (as needed)\nMonitor system performance and suggest optimization strategies (as needed).\nWork with DT to maintain system - patches, backups, etc.\nWork with LYB's Data Stewards to support their governance activities.\nTesting\n\nThe DQ Analyst/Developer should have experience with IMDC (for the sake of our example) cloud DQ and observability, JSON (depending on tool) Deep SQL skills, Integration tools/methodologies - API as well as ETL, Data Analysis, Snowflake or Databricks knowledge (for lineage), Power BI (nice to have), SAP ECC knowledge (nice to have), experience with cloud platforms (Azure, AWS, Google).\nIf you are interested please share required details along with resume\nFull Name:\nCurrent or Previous organization:\nCurrent Location:\nTotal Experience:\nRelevant experience as Python Developer:\nhow many years of experience In Azure, AWS, Google\nHow many years of experience in UI, Workflows, security\nWorking as full time or contract:\nReason for job change:\nAny other offers inhand:\nCurrent CTC:\nexpected CTC:\nNotice Period:\nemail id:\ncontact Number :\nDomain name:\nare you ok to work Cotractual role?:\nshare your aadhar or pan card for the verification",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Data quality analyst', 'cloud data quality', 'Azure', 'data quality developer', 'JSON', 'google', 'Informatica', 'AWS']",2025-06-13 05:29:44
"Data Science Specialist - R/Python, Statistical Analysis, AI/Ml",Cisco,4 - 8 years,Not Disclosed,['Bengaluru'],"Responsibilities:\nAnalysis of cross-customer and customer specific data.\nAnalysis for diagnosis of product and customers specific problems and also to demonstrate value of our data to customers.\nSupport sales and product adoption for data related use-cases (occupancy, captive portal, behavioral metrics, BMS integrations etc)\nHelp design monitoring tools to detect product and customer relative issues around product\nCustomer demonstrations of more sophisticated data products like Firehose. Engineering/Product linkages",,,,"['Data Science', 'rest', 'python', 'data analysis', 'natural language processing', 'machine learning', 'relational databases', 'artificial intelligence', 'javascript', 'sql', 'spring', 'r', 'tableau', 'java', 'computer science', 'html', 'mysql', 'data structures', 'data visualization', 'ml', 'statistics']",2025-06-13 05:29:45
HIH - Data Science Lead Analyst - Evernorth,ManipalCigna Health Insurance,5 - 8 years,Not Disclosed,['Hyderabad'],"Internal Title: Data Science Lead Analyst\nExternal Title: Data Science Lead Analyst\nRole Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\nThe role will support the development and maintenance of proprietary advanced neural network ( AI ) foundation models in support of Cigna s business operations.\nKey Responsibilities:\nWrite code using PyTorch and/or Tensorflow to implement, test, and operationalize deep learning models\nCollaborate with data scientists and engineers to improve deep learning models and implement business-facing solutions built on top of those models\nTake responsibility for improving code performance and quality\nFollow developments in deep learning technology to identify opportunities to improve models\nQualifications:\nBachelors or Masters(preferred) in computer science or statistics or any other equivalent discipline with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR), with emphasis on Tensorflow and Pytorch\nKnows and follows best coding and software engineering practices\nSuccessfully completes technical project components with limited guidance\nFamiliarity with deploying machine learning and predictive models to production and cloud environments\nLeadership in Data Science\nUnderstands how assigned work is related to purpose of the overall project\nIndependently identifies project roadblocks, and solutions\nSeeks to understand the health insurance domain\nScope and Impact\nDocuments the business considerations, methodology, process, code, and results associated with their work\nCollaborates to deliver clear and well developed presentations for both technical and business audiences\nConsistently communicates decisions, considerations, and needs for support\nReceives and responds to feedback in a professional and appropriate manner\nLevel of Influence\nPresent technical topics and results to non-technical stakeholders\nCommunicate and gather domain knowledge from non-technical stakeholders\nAbout Evernorth Health Services",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Version control', 'GIT', 'Claims', 'Coding', 'Machine learning', 'Lead Analyst', 'SQL', 'Python', 'Business operations']",2025-06-13 05:29:47
"Data & Analytics Analyst, VP",NatWest Markets,15 - 20 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Join us as a Data & Analytics Analyst\nTake on a new challenge in Data & Analytics and help us shape the future of our business\nYou ll take accountability for the analysis of complex data to identify business issues and opportunities, and supporting the delivery of high quality business solutions\nWere committed to mapping a career path that works for you, with a focus on helping you build new skills and engage with the latest ideas and technologies in data analytics\nWere offering this role at vice president level\nWhat youll do\nAs a Data & Analytics Analyst, you ll be driving the production of high quality analytical input to support the development and implementation of innovative processes and problem resolution. You ll be capturing, validating and documenting business and data requirements, making sure they are in line with key strategic principles.\nWe ll look to you to interrogate, interpret and visualise large volumes of data to identify, support and challenge business opportunities and identify solutions.\nYou ll also be:\nPerforming data extraction, storage, manipulation, processing and analysis\nConducting and supporting options analysis, identifying the most appropriate solution\nAccountable for the full traceability and linkage of business requirements of analytics outputs\nSeeking opportunities to challenge and improve current business processes, ensuring the best result for the customer\nCreating and executing quality assurance at various stages of the project in order to validate the analysis and to ensure data quality, identify data inconsistencies, and resolve as needed\nStrong sense of ownership with a focus on delivering high-quality outcomes\nExceptional attention to detail\nEmphasis on measurable outcomes and impact of work\nExpertise in data analytics and reporting\nThe skills youll need\nYou ll need a background in business analysis tools and techniques, along with the ability to influence through communications tailored to a specific audience. Additionally, you ll need the ability to use core technical skills.\nYou ll also demonstrate:\nClear and effective communication\nProficiency in SQL, and tools such as Excel and Power BI\nExperience in Informatica, Snowflake or others\nResponsible for performance metrics and data solutions across the entire data architecture team\nSkilled in data visualization, report generation and presentation to both technical and business audiences\nOver 15 years of professional experience\nHours\n45\nJob Posting Closing Date:\n23/06/2025",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Manager Quality Assurance', 'Business analysis', 'Analytical', 'Data quality', 'Data analytics', 'Informatica', 'Business solutions', 'SQL', 'Data extraction', 'Data architecture']",2025-06-13 05:29:49
Data Governance Process Analyst,K-logix Partnering Solutions,5 - 9 years,Not Disclosed,[],"Key Responsibilities:\n\nAnalyze end-to-end business processes using Celonis Process Mining to identify inefficiencies, root causes, and data quality issues.\nCollaborate with Data Stewards, IT, and business units to ensure data governance policies are aligned with process insights.\nDevelop and maintain dashboards and reports in Celonis to track key performance indicators (KPIs), data lineage, and governance metrics.\nWork with cross-functional teams to define and implement data governance controls and remediation strategies based on process analytics.\nSupport the development of data dictionaries, metadata management, and data cataloging in alignment with enterprise data standards.\nAssist in the rollout of enterprise-wide data governance programs and compliance initiatives (e.g., GDPR, CCPA).\nContinuously monitor and assess data quality metrics and suggest corrective actions to improve data accuracy and reliability.\nProvide training and documentation on Celonis best practices and data governance processes to business stakeholders.\n\nRequired Qualifications:\n\nBachelors degree in Information Systems, Data Analytics, Business Administration, or a related field.\n5+ years of experience in data governance, business process analysis, or data analytics roles.\n2+ years of hands-on experience with Celonis EMS (Execution Management System) or comparable process mining tools.\nStrong understanding of data governance frameworks, data quality principles, and data lifecycle management.\nProficient in SQL and working knowledge of data visualization tools (e.g., Power BI, Tableau).\nExcellent analytical and problem-solving skills, with a keen attention to detail.\nStrong communication and stakeholder engagement skills across technical and non-technical teams.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Celonis', 'Business Process Analysis', 'Data Governance']",2025-06-13 05:29:51
Trade Support Analyst,JPMorgan Chase Bank,0 - 5 years,Not Disclosed,['Mumbai'],"Join our team as a Trading Services Analyst to drive operational excellence, support trading strategies, and ensure regulatory compliance. Collaborate with US traders, resolve trade discrepancies, and enhance process efficiency\nJob Summary\nAs a Trading Services Analyst in our dynamic team, you will play a crucial role in enhancing operational excellence and supporting strategic trading initiatives. You will execute and monitor operational tasks with precision, ensuring accuracy and timeliness. You will reconcile and resolve trade discrepancies, maintaining compliance with regulatory standards. You will collaborate with US traders and internal teams to support trading activities and strategies. You will contribute to process improvements to boost operational efficiency and provide expert support for trade-related inquiries from both internal and external stakeholders.\nJob Responsibilities\nPerform daily reconciliation of trades, positions, and cash balances to ensure accuracy\nInvestigate and resolve breaks or discrepancies promptly\nEnsure accurate and timely execution and settlement of trades\nMonitor trade flows and address discrepancies during settlement\nIdentify and implement process improvements to enhance efficiency\nCollaborate with technology teams to enhance trade systems\nMonitor and manage operational risks in trade processing\nImplement controls to mitigate risks and adhere to policies\nCommunicate effectively with internal teams and counterparties\nSupport traders and compliance teams in operational tasks\nAdapt to changing market conditions and operational demands\nRequired Qualifications, Capabilities, and Skills\nHold a Bachelor s degree in Finance, Business, or a related field\nDemonstrate experience in trade operations or financial services\nExhibit proficiency in trade management and settlement systems\nPossess strong computer skills, including Microsoft Office Suite\nCommunicate effectively both verbally and in writing\nCollaborate with traders, compliance, and technology teams\nAdapt to changing market conditions and operational demands\nPreferred Qualifications, Capabilities, and Skills\nHold a Master s degree in Finance, Business Administration, or a related field\nDemonstrate extensive experience in trade operations, especially within specific asset classes like equities or ETFs\nUtilize data analysis tools and programming languages such as SQL or Python for automation and data management\nPossess an in-depth understanding of financial markets and trading strategies\nApply strong critical thinking skills to develop innovative solutions to operational challenges\nExhibit strong interpersonal skills for effective negotiation and communication with stakeholders\nWork effectively in a global environment, adapting communication styles to cultural differences",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Operational excellence', 'Data management', 'Reconciliation', 'trade operations', 'Operations', 'Financial services', 'SQL', 'Python']",2025-06-13 05:29:52
Data Management Analyst Mutual Fund & Investment Operations,International IT Companies,3 - 8 years,4.25-6 Lacs P.A.,['Bengaluru'],"Manage process reference data, pricing data, dividends, benchmarks, and fund classification for mutual funds and equity instruments.\nReview key fund-related documents\nFactsheets to extract, validate, and update critical data points.\n\nRequired Candidate profile\nInteract with multiple stakeholders including internal teams and external clients for data quality and operational updates.\nEnsure data accuracy and integrity in all deliverables\n\nPerks and benefits\nPerks and Benefits",Industry Type: BPM / BPO,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Financial Services', 'Mutual Funds', 'Data Management', 'ETFs', 'Investment Operations', 'Fund Documentation', 'Pricing Data', 'Reference Data', 'Investment Management Analyst.', 'Corporate Actions', 'Equity Operations', 'Annual Reports', 'KIIDs', 'Factsheet Review', 'Benchmark Data']",2025-06-13 05:29:54
MIS Analyst,Data Marshall,1 - 4 years,Not Disclosed,['Hyderabad'],"Job Description\nThe MIS Analyst plays a crucial role in managing and optimizing the organizations information management system. This position involves pulling up pre-identified reports, validating the content, interpreting and formatting the data into details that provide insight, and sharing it in a timely manner or agreed upon TAT.\nWhat You Will Do: MIS Analyst\nData Management: Pulling, interpreting, processing, reporting, and storing specified data.\nRequirements Translation: Convert business requirements into specifications for reports and dashboards, integrating multiple data sources.\nCollaboration: Work with specialists, leads, and managers to understand reporting needs and develop solutions accordingly.\nStatistical Reporting: Compile, prepare, and present statistical information for both internal and external stakeholders.\nWhat You Will Need:\n\nAdded Advantage\nReporting Tools: Experience with Power BI for reporting and analysis will be an added advantage.\nAutomation: Knowledge of VBA for developing automation scripts using Excel Macros.\nDatabase Development: Familiarity with MS Access for database and application development.\nClient Communication: Ability to communicate effectively with client business lines, leadership teams, and other stakeholders.\nFamiliarity with Python, Power Automate, and Power Apps is a plus. Role & responsibilities\n\n\nPreferred candidate profile\n\nEducation: Bachelors degree\nHealthcare Experience; Minimum 1 year of RCM experience or US Medical Coding Experience.\nMIS Experience: Minimum One year of experience in MIS execution\nTechnical Skills: Proficiency in MS Office applications (Excel, Word, PowerPoint), Proficiency in SQL will be an advantage.\nCommunication: Excellent verbal and written communication skills to facilitate collaboration with internal, external, and customer teams.\nAnalytical Skills: Strong analytical, conceptual, and problem-solving abilities.\nPrioritization: Ability to manage multiple priorities and adapt quickly to changing demands.\nFor more Details Kindly reach out\n\nName: Pagidoju Dhana Laxmi\nContact No: 7995682418\nEmai: dhanalaxmi.pagidoju@datamarshall.com",Industry Type: Analytics / KPO / Research,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent","['Word', 'Excel', 'Excel Powerpoint', 'Power Bi', 'SQL', 'Excel Macros']",2025-06-13 05:29:56
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Navi Mumbai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:29:58
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Chennai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:00
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Pune'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to effectively migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and contribute to the overall data strategy of the organization, ensuring that data solutions are efficient, scalable, and aligned with business objectives.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with stakeholders to gather and analyze data requirements.- Design and implement robust data pipelines to support data processing and analytics.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of data modeling and database design principles.- Experience with ETL tools and data integration techniques.- Familiarity with cloud platforms and services related to data storage and processing.- Knowledge of programming languages such as Python or Scala for data manipulation.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data analytics', 'database design', 'data modeling', 'design principles', 'hive', 'scala', 'data manipulation', 'data processing', 'pyspark', 'data warehousing', 'data engineering', 'sql', 'data quality', 'tableau', 'etl tool', 'spark', 'hadoop', 'etl', 'big data', 'data integration', 'etl process']",2025-06-13 05:30:02
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Indore'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:04
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Bhubaneswar'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:06
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Bhubaneswar'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:08
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Pune'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:10
Data Engineer,Accenture,5 - 10 years,Not Disclosed,['Chennai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL processes to migrate and deploy data across systems. Your day will involve working on data architecture and engineering tasks to support business operations and decision-making.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Develop and maintain data pipelines for efficient data processing.- Implement ETL processes to ensure seamless data migration and deployment.- Collaborate with cross-functional teams to design and optimize data solutions.- Conduct data quality assessments and implement improvements for data integrity.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of data architecture principles.- Experience in designing and implementing data solutions.- Proficient in SQL and other data querying languages.- Knowledge of cloud platforms such as AWS or Azure.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Chennai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'sql', 'data architecture principles', 'etl', 'aws', 'hive', 'python', 'data processing', 'airflow', 'microsoft azure', 'pyspark', 'data warehousing', 'data integrity', 'data migration', 'data engineering', 'data quality', 'spark', 'hadoop', 'business operations', 'big data', 'etl process']",2025-06-13 05:30:12
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Chennai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:14
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Hyderabad'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:16
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Navi Mumbai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-13 05:30:18
FP&A Analyst / Sr. Analyst / Manager - Chennai,2coms,3 - 8 years,Not Disclosed,['Chennai'],"SUMMARY\nFP&A Analyst / Sr. Analyst / Manager\n\nExperience: 6+ Years\n\nLocation: Chennai\n\nWork Arrangement: On-site\n\nRESPONSIBILITIES:\n\nThis position offers a unique opportunity to support our Corporate FP&A team. You will be instrumental in maintaining data integrity, conducting financial reporting and analysis, and ensuring efficient process execution. Your role will be pivotal in upholding the accuracy of essential data resources that contribute to all FP&A reports and processes.\n\nThe ideal candidate for this role will:\n\nTake charge of administrative operational cadences and have the potential to enhance existing processes, which includes organizing static meetings, managing communications related to scenario updates, and conducting daily validation checks of data.\nCreate standard template views utilized by the Global FP&A teams to deliver key results and performance insights, such as ensuring all Anaplan GSheet saved views are up to date and refreshing, and sending the monthly Close review excel template to Int’l at the beginning of each month.\nPreserve and generate source of truth materials to maintain data integrity and alignment of results across the broader FP&A team, achieved by maintaining monthly validation files and collaborating with the US based Corporate FP&A analyst to create the quarterly E-Binder TOC for the earnings team to reference in SmartSheets.\nConduct preliminary forecast/trend analysis and schedule creation for processes driven by the Corporate FP&A team, including rolling forward and refreshing all Earnings P0/P1 schedules and driving the quarterly EBITDA, SBC, Gains/Losses forecasts through partnership with Accounting.\nServe as the initial point of contact for all Earnings, BOD, and annual Operating Plan deck summaries, including staging the first pass proposals for all decks and managing all processes associated with final touches.\n\nRequirements\nRequirements:\n\nBachelor’s degree in Finance, Accounting, Business, or related field\nDemonstrated experience in financial planning and analysis\nProficiency in data analysis and financial modeling\nStrong communication and presentation skills\nAdvanced proficiency in Microsoft Excel and other financial software\nAbility to thrive in a fast-paced, dynamic environment\nStrong attention to detail and accuracy\nRelevant certifications (e.g., CFA, CPA) preferred",Industry Type: Banking,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['data analysis', 'software', 'forecasting', 'presentation skills', 'accounting', 'analysis', 'budgeting', 'excel', 'planning', 'annual operating plan', 'fpa', 'financial reporting', 'financial modelling', 'financial planning', 'financial planning and analysis', 'reporting', 'finance', 'communication skills']",2025-06-13 05:30:19
"Analyst, Provider Data Management",Evolent Health,2 - 4 years,Not Disclosed,['Pune'],"Are we growing? Absolutely and Globally. In 2021 we grew our teams by almost 50% and continue to grow even more in 2022. Are we recognized as a company you are supported by for your career and growth, and a great place to work? Definitely. Evolent Health International (Pune, India) has been certified as Great Places to Work in 2021. In 2020 and 2021 Evolent in the U.S. was both named Best Company for Women to Advance list by Parity.org and earned a perfect score on the Human Rights Campaign (HRC) Foundation s Corporate Equality Index (CEI). This index is the nations foremost benchmarking survey and report measuring corporate policies and practices related to LGBTQ+ workplace equality.\nWhat You ll Be Doing:\nJob Description\nEvolent Health is looking for a Provider Data Specialist to be a key member of the PDM Operations team. Reporting to the Supervisor of Provider Data Management, this individual will play a critical role in executing Evolent Health s mission by working directly with our partners, focused on coordinating, monitoring, trending and supporting report requirements of business operational and clinical programs within Provider Network Management. This Provider Data Analyst will work with both internal and external business partners to implement ongoing operational monitoring, resolve service barriers, develop solutions to improve effectiveness and identify continuous improvement initiatives to increase service levels.\n\nEssential functions\n\nServe as a liaison between the internal team members and partner organization providing support for provider data enrollment activities; acts as liaison with technology team and business product team members.\n\nDefines analysis methodology and provides analytic support.\n\nAnalyzes existing systems to recommend enhancements and creates new systems to reduce manual processes and maximize the business efficiencies.\n\nAnalyzes data from conceptualization through presentation and requires proficiency with analytical tools, knowledge of data analysis methodology, use of presentation software, and strong communication skills.\n\nIdentifies, evaluates, and implements new data-driven strategies and processes for the department\n\nDevelops tools and reports that lend valuable insights that capitalize on a combination of internal and external data.\n\nRecommends enhancements to existing systems in accordance to business needs by creating ad hoc and standard reports as well as information delivery technologies.\n\nPrepare reports in an accurate, concise and timely fashion.\n\nPerforms data collection, analysis, reporting.\n\nProvide guidance and support to all claims and operations personnel towards resolution of provider data and claims problems with an emphasis on root cause analysis and resolution of problems\n\nCompile, review and analyze management reports and take appropriate action\n\nIdentify and advise Claims, Provider Network Management, Medicare Operations and other operational areas of trends, problems, and issues as well as recommended course of action; ensure timely communication; participate in the development and implementation of solutions\n\nMonitor adherence to the efficiency and service level goals including volume, processing, timeliness, accuracy and other metrics.\n\nCompose, submit and track claim system questions and configuration requests to correct identified systemic issues\n\nPrioritize issues identified by TPA/BPO, internal team members and/or partner representatives and monitors progress in the resolution of the issues\n\nDevelop deep understanding of processing capabilities and limitations of claims and benefits with TPA/BPO systems, tools and resources; provide recommendations to meet plan requirements\n\nConfirm that all provider data elements have been set up within the claims payment system and are aligned with the requirements as specified by the plan materials.\n\nCreate and report operational tracking metrics and dashboards for monitoring claims, provider disputes and benefits performance.\n\nCoordinate corrective action plans with partner/client and TPA/BPO operations services administrator to resolve issues.\n\nSupport internal plan team members with the resolution of daily issues.\n\nWork with other departments to identify and resolve problems leading to incorrect provider data and issues regarding payment of claims.\n\nServe on various committees and attends required meetings.\n\nPerform other duties and projects as assigned\n\nKey competencies/skill/success factors:\n\nExperience working within a health plan, managed care organization, provider operated healthcare environment or third party administrator\nGood Knowledge on Python, SQL Server- SSMS, SSRS.\n\nExtensive knowledge of PCs and related software applications, such as Word, PowerPoint, Excel, Project\n\nDemonstrated exceptional active listening and communications skills\n\nExperience in systems and languages related to database lifecycle management such as MS Access, Visual Basic, etc\n\nQualification and Experience:\n\nRequired\n\nAssociates Degree or equivalent\n\n2-4 years of experience in collecting, analyzing, and presenting data and recommendations to management\n\nBig plus\n\nBachelor s degree in Computer Science, Statistics, Mathematics or related field\n\n1-3 years data analysis and business intelligence experience working with BI suites such as Power BI, SSRS or other enterprise class tools\nMandatory Requirements:\nEmployees must have a high-speed broadband internet connection with a minimum speed of 50 Mbps and the ability to set up a wired connection to their home network to ensure effective remote work. These requirements may be updated as needed by the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['BPO', 'Data analysis', 'Claims', 'Visual Basic', 'Data management', 'MS Access', 'Analytical', 'Data collection', 'Business intelligence', 'SQL']",2025-06-13 05:30:21
"Analyst II, Global Finacial Data Operations",Kroll,1 - 4 years,Not Disclosed,['Mumbai'],"We are looking for an analyst for our Client Services Operations team which performs, Data extraction, Data analysis on financial models and financial valuation reports along with report updates and various support services. The team undertakes research and collects financial and business data based on the request from the internal Kroll business units. The relevant financial and business data is collected through various publicly available sources and Kroll proprietary files. Pursuant to the collection, the data is summarized in the format prescribed by the Kroll business units. The team also undertakes subsequent analysis with respect to the completeness of the data and verification of accuracy of the information. This enables the business units to have easy access of information / data as available at various sources.",,,,"['Analytical skills', 'Data analysis', 'Due diligence', 'Consulting', 'Anti money laundering', 'Workflow', 'Support services', 'Corporate finance', 'Research', 'Data extraction']",2025-06-13 05:30:23
HIH - Data Science Lead Analyst - Evernorth,Cigna Medical Group,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\nThe role will support the development and maintenance of proprietary advanced neural network (AI) foundation models in support of Cigna business operations.\nKey Responsibilities:\nWrite code using PyTorch and/or Tensorflow to implement, test, and operationalize deep learning models\nCollaborate with data scientists and engineers to improve deep learning models and implement business-facing solutions built on top of those models\nTake responsibility for improving code performance and quality\nFollow developments in deep learning technology to identify opportunities to improve models\nQualifications:\nBachelors or Masters(preferred) in computer science or statistics or any other equivalent discipline with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR), with emphasis on Tensorflow and Pytorch\nKnows and follows best coding and software engineering practices\nSuccessfully completes technical project components with limited guidance\nFamiliarity with deploying machine learning and predictive models to production and cloud environments\nLeadership in Data Science\nUnderstands how assigned work is related to purpose of the overall project\nIndependently identifies project roadblocks, and solutions\nSeeks to understand the health insurance domain\nScope and Impact\nDocuments the business considerations, methodology, process, code, and results associated with their work\nCollaborates to deliver clear and well developed presentations for both technical and business audiences\nConsistently communicates decisions, considerations, and needs for support\nReceives and responds to feedback in a professional and appropriate manner\nLevel of Influence\nPresent technical topics and results to non-technical stakeholders\nCommunicate and gather domain knowledge from non-technical stakeholders",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Health insurance', 'Version control', 'GIT', 'Claims', 'Coding', 'Machine learning', 'SQL', 'Python', 'Business operations']",2025-06-13 05:30:25
"Market Data Operations, Analyst",Primetrace Technologies,3 - 5 years,Not Disclosed,['Gurugram'],"About this role\nAbout the role:\nThe user entitlement function is solely responsible for managing terminal access and data exchange within BlackRock, updating user permissions in the MDM system. This MDM information helps validate invoices and create declaration reports.\nOur team primarily handles requests received from the business or HR departments to change employee market data access due to events like additions, departures, or transfers. Apart from this, there are other job responsibilities as well, which include preparing weekly vendor reconciliations, working on Data Notifications and collaborate with vendors to update user access in accordance with requests.\nResponsibilities:\nResponsibility includes setting up new deals/contracts, user per missioning, inventory updating, customer invoicing, monthly accounting close, vendor reconciliations, and supporting/leading ad hoc projects.\nTimely entry of data and making corrections as required.\nReview and update contracts and users against the internal inventory of index and market data services.\nResearch and resolve discrepancies to ensure accurate and timely inventory updates.\nActively follow up with vendors and internal colleagues to ensure timely issue resolution.\nRespond to inquiries related to inventory, contracts management, and reporting.\nPrepare user reconciliations to explain differences between the inventory of services and invoices.\nAssist in maintaining the accuracy of internal inventory of services in use and corresponding fees.\nDevelop an understanding of factors that impact invoicing and utilize that knowledge to improve and streamline processes.\nPrepare index and market data usage reports for providers.\nPrepare financial reports and analytics for internal stakeholders.\nSkills:\n3-5 years of experience in inventory/contract management or user/vendor reconciliation is preferred.\nDemonstrated ability to optimize new operational processes and establish quality controls.\nBasic understanding of financial markets.\nAdvanced proficiency in Excel and knowledge of Microsoft Access is preferred.\nStrong problem-solving and analytical skills.\nExcellent time-management abilities.\nEffective communicator (both orally and in writing) with a self-starter attitude capable of overcoming challenges.\nHighly organized and adaptable, displaying a sense of urgency, able to manage multiple priorities, meet deadlines, and maintain composure and integrity.\nEnjoys working in and contributing to an inclusive and diverse environment.\nTeam player who enhances overall team performance and objectives.\nEducation: Degree in Business, Commerce or related field\n#EarlyCareers\nOur benefits\n\n.\nOur hybrid work model\n.\nAbout BlackRock\n.\nThis mission would not be possible without our smartest investment - the one we make in our employees. It s why we re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.\nFor additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com / company / blackrock\nBlackRock is proud to be an Equal Opportunity Employer. We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Analytical skills', 'Contract management', 'Time management', 'Finance', 'Healthcare', 'Issue resolution', 'market data', 'Operations', 'Analytics', 'Inventory']",2025-06-13 05:30:26
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,8 - 9 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n8 to 9+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-13 05:30:28
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,7 - 9 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n7 to 9+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-13 05:30:30
Agile Business Analyst/Senior Business Analyst,Hsbc,10 - 13 years,Not Disclosed,['Pune'],"Some careers shine brighter than others.\nIf you re looking for a career that will help you stand out, join HSBC and fulfil your potential. Whether you want a career that could take you to the top, or simply take you in an exciting new direction, HSBC offers opportunities, support and rewards that will take you further.\nHSBC is one of the largest banking and financial services organisations in the world, with operations in 64 countries and territories. We aim to be where the growth is, enabling businesses to thrive and economies to prosper, and, ultimately, helping people to fulfil their hopes and realise their ambitions.\nWe are currently seeking an experienced professional to join our team in the role of Senior Business Analyst.\nIn this role, you will:\nWe are currently seeking an experienced, skilled information technology candidate to join our growing organization in the role of Senior Business Analyst with minimum 10 years of experience. In this position, you will be responsible for ensuring the effective delivery of technology services through support and maintenance of the technology estate and delivery of new services as well as management of existing services as per defined product roadmap.\nThis role demands responsibility for prioritizing the work with the Product Owner, clarifying requirements, Project Planning and tracking, responsible performing gap analysis, coordinate with different teams & stakeholders, assist in testing and actively get involved in production issues.\nParticipate and contribute to the relevant workshops (business and IT) which aims to clarify requirements and scope definition.\nDocumentation of current state of systems or processes linked to this project.\nCarrying out the analysis required to iron-out or enhance the business requirements. This will require effective working relationship with associated system SME s.\nAppropriate walkthrough be carried out and ensure signoffs are secured to finalise the document.\nParticipate in the applicable test phases ensuring that systems are tested thoroughly according to the business requirements and functional specification document.\nCreation of applicable documentations (e.g. System documents) as and when applicable\nMaintain full and up-to-date understanding of the business strategy.\nGood understanding of Agile practices (Writing detailed Jira stories)\nExperience in performing analysis using various tools, like excel, Word, PPT, Visios and present the same to relevant stakeholders.\nUnderstanding of Agile, Scrum and associate software s like Jira, Confluence.\nNeed to be a good Team Leader with People Management & Problem-Solving skills.\nGood time-management skills\nGreat interpersonal and communication skills i.e. both verbal & written.\nAbility to manage conflicting business requirements and project scope.\nAbility to escalate risks, issues and dependencies to Project & Program Management.\nA delivery-orientated approach to both individually assigned tasks and projects at all times.\nRequirements\nTo be successful in this role, you should meet the following requirements:\nProven experience working as an Agile Business Analyst across multi-disciplinary and multi-culturally diverse work environments (locations, pods, etc) supporting banking programs.\nPrevious experience of using the BDD methodology and associated tooling (e.g., Cucumber, etc)\nPrevious experience documenting processes and knowledge of associated business process tooling (e.g., CaseWise, Signavio, Visio, etc)\nPrevious experience on data analysis and conceptual data modelling, and knowledge of associated data modelling tooling (e.g., Erwin, etc)\nCan-do attitude and problem-solving mindset.\nAdaptability\nPractical experience of Agile & DevOps tooling, for example Jira or equivalent, Confluence or equivalent, GitHub, etc.\nStrong communication skills to help for negotiating, collaborating, presenting, facilitating, influencing, or stakeholder management.\nUnderstanding of web platforms and associated technologies Self-starter\nGood knowledge of Marketing & CRM domains; Marketing related experience would be preferred but is not a pre-requisite if the applicant has good financial products or portfolio management experience.\nHands on Woking experience of in an Agile project\nFull life cycle Business Analysis experience from requirements definition through to implementation within a business facing IT environment.\nComplete formal knowledge of the document life cycle, terms of reference, technical and functional specs, business requirements and business cases\nExperience working with offshore development, analysis & test teams.\nProblem solving and analysing an issue\\opportunity highly desirable.\nTools\nExperience with SQL\nExperience of producing Use Cases and Process Flow Diagrams.\nFeasibility assessment and business case development or keen to move from theoretical to practical experience.\nDesign thinking experience or keen to move from theoretical to practical experience.\nUnderstanding of constraints associated to cloud-based platform.\nKnowledge of the collaboration tools like Monday.com and Mural\nYou ll achieve more when you join HSBC.\n\n.\n\n\n",Industry Type: Consumer Electronics & Appliances,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Business analysis', 'Agile', 'Project planning', 'Visio', 'JIRA', 'Information technology', 'Financial services', 'SQL', 'CRM']",2025-06-13 05:30:32
"Sr Business Analyst (Process Modeling, and Stakeholder Collaboration)",Synechron,7 - 12 years,Not Disclosed,"['Pune', 'Hinjewadi']","Job Summary\nSynechron is seeking a highly experienced and detail-oriented Senior Business Analyst to join our dynamic team. In this role, you will serve as a key contributor to our business analysis function, translating complex business needs into effective solutions that support organizational goals. Your expertise will enable our teams to deliver value-driven projects efficiently and effectively, ensuring alignment with strategic objectives and stakeholder expectations.\nSoftware Requirements\nRequired Skills:",,,,"['Python', 'Azure', 'Kanban', 'NoSQL', 'Scrum', 'SQL Server', 'Oracle', 'AWS']",2025-06-13 05:30:34
"Global Payplus, GPP SP, Business Analyst/Sr. BA",Hsbc,5 - 8 years,Not Disclosed,['Pune'],"Some careers shine brighter than others.\nIf you re looking for a career that will help you stand out, join HSBC and fulfil your potential. Whether you want a career that could take you to the top, or simply take you in an exciting new direction, HSBC offers opportunities, support and rewards that will take you further.\nHSBC is one of the largest banking and financial services organisations in the world, with operations in 64 countries and territories. We aim to be where the growth is, enabling businesses to thrive and economies to prosper, and, ultimately, helping people to fulfil their hopes and realise their ambitions.\nWe are currently seeking an experienced professional to join our team in the role of Consultant Specialist.\nIn payment domain with 5+ years of experience. The role of the SME is to create test strategy, supporting test engineer in testing activities, identifying the automation opportunities and able to do hands on GPP SP platform. Associate should have hands on knowledge of Global Payment plus (GPP SP). experience on bug tracking system like Jira, good knowledge of SQL queries, understanding of defect life cycle and good communication are essential for this role. Knowledge of any automation tool is preferable. It is expected that SME should be able to work on automation tool. This role will also require interaction with various teams, timely and quality deliveries of assigned task\nIn this role, you will:\nProcess and System Analysis\nRequirements Gathering and Documentation\nData Analysis and Reporting\nSolution Design and Implementation\nStakeholder Communication\nContinuous Improvement\n\n\n\n\n\n\n\n\n\n\nRequirements\n\n\n\nTo be successful in this role, you should meet the following requirements:\nHands on experience GPP product is MUST\nAnalytical Skills\nCommunication Skills\nProblem-Solving Skills\nTechnical Skills\nBusiness Acumen\nProject Management Skills\nGood communication skill\nHands on experience on Jira and Confluence.",Industry Type: Consumer Electronics & Appliances,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analytical skills', 'Automation', 'Data analysis', 'Test strategy', 'Project management', 'Defect life cycle', 'JIRA', 'Continuous improvement', 'System analysis', 'Financial services']",2025-06-13 05:30:36
Sr. Business Analyst,Merkle B2b,8 - 13 years,Not Disclosed,['Mumbai'],"As a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms\nJob Description:\nSr. Business Analyst\nJob Description:\nAs a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms.\nKey Responsibilities\nUnderstand and identify the business issues / requirements and create a detailed Functional Requirement Document\nDevelop a prototype / framework that meets requirements and addresses the business issue.\nBrief the technical team on the requirements. Address and resolve all doubts/queries of the developer / tester. As and when required, check with stakeholders and seek clarity.\nEnsure smooth deployment of the solution and conduct training for end users as and when required.\nPost project completion; seek for feedback from project stakeholders.\nConduct a thorough impact analysis on system for change requests.\nAssist with solution testing and user acceptance testing plans and execution.\nUpdate and maintain solution documentation including requirements documents, data flows, schema/layout documentation, etc.\nMaintain the solution in production, working with end users, and facilitating change requests with the broader team using a defined change management process.\nQualifications + Skills\nBachelor s Degree or equivalent\n8+ years of experience in gathering and documenting solution requirements for the purposes of scope management, design, development and testing enablement.\nGood problem solving and business acumen\nExperience writing and maintaining solution documentation (requirements documents, data flows, User stories, etc.).\nExperience working within common delivery methodologies (e.g. agile and/or waterfall).\nExperience with business intelligence reporting (e.g. Power BI, Tableau, and/or similar platforms).\nExperience with system and user acceptance testing.\nExperience writing SQL to perform data analysis.\nStrong customer service orientation and collaboration skills.\nEffective communication skills, ability to simplify and structure complex concepts to streamline interactions and highlight key points.\nLocation:\nMumbai\nBrand:\nDentsu\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'Change management', 'Manager Quality Assurance', 'Prototype', 'Schema', 'Agile', 'Scope management', 'User acceptance testing', 'SQL']",2025-06-13 05:30:38
Sr. Business Analyst,Merkle Science,10 - 15 years,Not Disclosed,['Mumbai'],"As a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms\nJob Description:\nSr. Business Analyst\nJob Description:\nAs a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms.\nKey Responsibilities\nUnderstand and identify the business issues / requirements and create a detailed Functional Requirement Document\nDevelop a prototype / framework that meets requirements and addresses the business issue.\nBrief the technical team on the requirements. Address and resolve all doubts/queries of the developer / tester. As and when required, check with stakeholders and seek clarity.\nEnsure smooth deployment of the solution and conduct training for end users as and when required.\nPost project completion; seek for feedback from project stakeholders.\nConduct a thorough impact analysis on system for change requests.\nAssist with solution testing and user acceptance testing plans and execution.\nUpdate and maintain solution documentation including requirements documents, data flows, schema/layout documentation, etc.\nMaintain the solution in production, working with end users, and facilitating change requests with the broader team using a defined change management process.\nQualifications + Skills\nBachelor s Degree or equivalent\n8+ years of experience in gathering and documenting solution requirements for the purposes of scope management, design, development and testing enablement.\nGood problem solving and business acumen\nExperience writing and maintaining solution documentation (requirements documents, data flows, User stories, etc.).\nExperience working within common delivery methodologies (e.g. agile and/or waterfall).\nExperience with business intelligence reporting (e.g. Power BI, Tableau, and/or similar platforms).\nExperience with system and user acceptance testing.\nExperience writing SQL to perform data analysis.\nStrong customer service orientation and collaboration skills.\nEffective communication skills, ability to simplify and structure complex concepts to streamline interactions and highlight key points.\nLocation:\nMumbai\nBrand:\nDentsu\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'Change management', 'Manager Quality Assurance', 'Prototype', 'Schema', 'Agile', 'Scope management', 'User acceptance testing', 'SQL']",2025-06-13 05:30:40
Analyst,HARMAN,2 - 7 years,Not Disclosed,['Bengaluru'],"JOB IDENTIFICATION\nBusiness Title: Analyst\nBusiness Unit: Symphony Health Solutions\nLocation: Bangalore\nJOB SUMMARY\nWe are looking for a candidate with relevant analytics experience including working with larger datasets with healthcare background as a preference, Basic SQL and Advance Excel skills.\nAnalyst performs complex data analysis independently, preparing comprehensive reports and presentations of data analysis findings for the client or data vendor per established service level agreements. Job functions include inputs to processes, executing programs, assessing data accuracy, drawing research conclusions, and formatting and presenting output. This position is an expert in researching, resolving and documenting client/vendor inquiries. Work in a fast paced dynamic environment.",,,,"['Data analysis', 'Service level', 'Senior Analyst', 'Process improvement', 'Agile', 'Healthcare', 'Manager Quality Control', 'Downstream', 'Auditing', 'SQL']",2025-06-13 05:30:42
Data Entry (Fresher),Rapid Care,0 years,1-1.5 Lacs P.A.,['Chennai'],"Greetings from rapid care!!!!!!\n\nHiring Freshers and Experienced !!!!!!!!!\n\nwalkin interview\n\n\nJob Title: Data Analyst (Data Entry)\n\nLocation: Chennai\n\nShift: General and Rotational Shift\n\nGraduation: ( 10th, 12th, OR Any Diploma Qualification)\n\nInterview mode : walkin\n\n\nOffice Address : VLV Complex, 2nd floor, 41, SH 48, Little Mount, Saidapet, Chennai, Tamil Nadu 600015\n\nshare your resume : tag@rapidcare.ai\ncall , whatsapp : 9500170691, 9500170663.",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Typing Speed', 'Data Entry', 'Typing', 'Data Entry Operation']",2025-06-13 05:30:44
Data Scientist,Paypal,2 - 4 years,Not Disclosed,['Bengaluru'],"You will be the Data Scientist in the Fraud Risk team , where you will work on leading new projects to build and improve the Risk strategies to prevent fraud using the Risk tooled and custom data & AL/ML models. In this position, you will be partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.\nYour day to day\nIn your day to day role you will -\nIn this role you will have full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates.\nCollaborate with different teams to develop strategies for fraud prevention, loss savings, and optimize transaction declines or improve customer friction.\nYou will work together with cross-functional teams to deliver solutions and providing Risk analytics on frustration trend/ KPIs monitoring or alerting for fraud events.\nThese solutions will adapt PayPal s advanced proprietary fraud prevention tools enabling business growth.\nWhat do you need to bring-\n2-4 years of relevant experience working with large-scale complex dataset.\nStrong analytical mindset, ability to decompose business requirements into an analytical plan, and execute the plan to answer those business questions\nExcellent communication skills, equally adept at working with engineers as we'll as business leaders\nWant to build new solutions and invent new approaches to big, ambiguous, critical problems\nStrong working knowledge of Excel, SQL and Python/R\nTechnical Proficiency: Exploratory Data Analysis and expertise in preparing a clean and structured data for model development. Experience in applying AI/ML techniques for business decisioning including supervised and unsupervised learning (eg, regression, classification, clustering, decision trees, anomaly detection, etc). Knowledge of model evaluation techniques such as Precision, Recall, ROC-AUC Curve, etc along with basic statistical concepts.",Industry Type: FinTech / Payments,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Risk analytics', 'Analytical', 'Diversity and Inclusion', 'ROC', 'Risk management', 'Forecasting', 'Monitoring', 'SQL']",2025-06-13 05:30:46
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Bengaluru'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Microsoft Dynamics 365 ERP Technical\n\n\n\n\nGood to have skills :Microsoft Dynamics AX TechnicalMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Develop and implement strategies for process improvement.- Conduct business process modeling and simulation.- Facilitate workshops and meetings to gather requirements.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Microsoft Dynamics 365 ERP Technical.- Good To Have\n\n\n\n\nSkills:\nExperience with Microsoft Dynamics AX Technical.- Strong understanding of ERP systems and business processes.- Knowledge of data analysis and interpretation.- Experience in system integration and customization.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Microsoft Dynamics 365 ERP Technical.- This position is based at our Hyderabad office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['erp', 'data analysis', 'microsoft dynamics', 'erp systems', 'microsoft dynamics ax', 'business process modeling', 'project management', 'business analysis', 'process improvement', 'user stories', 'sql', 'system integration', 'brd', 'frd', 'scrum', 'agile', 'requirement analysis']",2025-06-13 05:30:48
Technical Business Analysis Specialist,Telstra,4 - 9 years,Not Disclosed,['Bengaluru'],"Employment Type Permanent\nClosing Date 29 June 2025 11:59pm\nJob Title Technical Business Analysis Specialist\nJob Summary\nAs a Technical Business Analysis Specialist, you thrive on collaborating with your team and providing valuable input to support stakeholders and team members to deliver technical analysis and research that enables successful business initiative/mission design and delivery, and ongoing technical capability operational performance. Job Description",,,,"['Data analysis', 'Business analysis', 'Agile', 'Data structures', 'Workflow', 'Gap analysis', 'Continuous improvement', 'JIRA', 'Operations', 'Business Technical Analyst']",2025-06-13 05:30:50
Technical Business Analysis Specialist,Telstra,4 - 9 years,Not Disclosed,"['Pune', 'Bengaluru']","Employment Type Permanent\nClosing Date 29 June 2025 11:59pm\nJob Title Technical Business Analysis Specialist\nJob Summary\nAs a Technical Business Analysis Specialist, you thrive on collaborating with your team and providing valuable input to support stakeholders and team members to deliver technical analysis and research that enables successful business initiative/mission design and delivery, and ongoing technical capability operational performance. Job Description Key Responsibilities",,,,"['Data analysis', 'Business analysis', 'Agile', 'Workflow', 'Data structures', 'business rules', 'Gap analysis', 'Continuous improvement', 'Operations', 'performance measurement']",2025-06-13 05:30:51
Business Analyst,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work-related problems.- Develop detailed business requirements and user stories.- Conduct stakeholder interviews to gather business requirements.- Create process flow diagrams and business process models.- Collaborate with cross-functional teams to ensure project success.- Assist in the implementation and testing of business solutions.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis.- Strong understanding of business process modeling.- Experience with Agile methodologies.- Knowledge of data analysis and interpretation.- Hands-on experience with requirement gathering tools.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Business Analysis.- This position is based at our Bengaluru office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business process modeling', 'data analysis', 'business analysis', 'user stories', 'agile methodology', 'process flow diagram', 'project management', 'gap analysis', 'business solutions', 'wireframing', 'sql', 'product management', 'brd', 'fsd', 'flow diagrams', 'frd', 'agile', 'requirement analysis']",2025-06-13 05:30:53
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Navi Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Property and Casualty Insurance\n\n\n\n\nGood to have skills :Business AnalysisMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Additionally, you will research, gather, and synthesize information to contribute to the success of the organization.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Conduct thorough analysis of business processes and systems.- Identify areas for improvement and propose solutions.- Collaborate with stakeholders to gather and document business requirements.- Create and maintain project documentation.- Assist in the development and execution of test plans.- Conduct user acceptance testing and provide feedback.- Support the implementation of new processes and systems.- Provide training and support to end-users.- Stay up-to-date with industry trends and best practices.- Assist in the development and implementation of change management strategies.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Property and Casualty Insurance, Business Analysis.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.- Strong understanding of business process modeling and analysis.- Experience in conducting stakeholder interviews and workshops.- Ability to translate business requirements into functional specifications.- Familiarity with data analysis and visualization tools.- Ability to work effectively in a cross-functional team environment.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Property and Casualty Insurance and Business Analysis.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business process modeling', 'property and casualty insurance', 'business analysis', 'machine learning algorithms', 'statistics', 'data analysis', 'bi', 'power bi', 'machine learning', 'data cleansing', 'business requirement analysis', 'tableau', 'data visualization', 'data munging']",2025-06-13 05:30:55
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Navi Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Property and Casualty Insurance\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Additionally, you will research, gather, and synthesize information to contribute to the success of the organization.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Conduct thorough analysis of business processes and systems.- Identify areas for improvement and propose solutions.- Collaborate with stakeholders to gather and document business requirements.- Create and maintain project documentation.- Assist in the development and execution of test plans.- Conduct user acceptance testing and provide feedback.- Support the implementation of new processes and systems.- Provide training and support to end-users.- Stay up-to-date with industry trends and best practices.- Assist in the development and implementation of change management strategies.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Property and Casualty Insurance.- Strong understanding of business analysis methodologies and techniques.- Experience in conducting business process analysis and improvement.- Knowledge of requirements gathering and documentation.- Familiarity with project management principles and practices.- Good To Have\n\n\n\n\nSkills:\nExperience with Agile methodologies.- Experience with data analysis and visualization tools.- Knowledge of insurance industry regulations and compliance.- Excellent communication and interpersonal skills.- Ability to work independently and in a team environment.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Property and Casualty Insurance.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'business analysis', 'business process analysis', 'user acceptance testing', 'agile methodology', 'data analysis', 'project documentation', 'documentation', 'change management', 'sql', 'providing training', 'business requirement analysis', 'brd', 'frd', 'agile']",2025-06-13 05:30:57
Technical Business Analyst - Consutant,KPMG India,5 - 8 years,Not Disclosed,['Bengaluru'],"KPMG India is looking for Technical Business Analyst - Consutant to join our dynamic team and embark on a rewarding career journey Analyze the business requirements of the organization and develop solutions to improve business processes and systemsConduct market research and data analysis to support decision-makingCollaborate with cross-functional teams, including development, product management, and project management, to ensure the delivery of high-quality solutionsCommunicate findings and recommendations to stakeholders, including management and technical teamsDevelop business requirements documents, use cases, process flows, and other deliverables as neededDevelop and maintain a deep understanding of the organization's products, services, and business operationsParticipate in the implementation and testing of solutions to ensure that they meet business requirementsContinuously evaluate and improve business processes and systemsStrong analytical and problem-solving skillsExcellent written and verbal communication skills",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Networking', 'Focus', 'Manager Technology', 'professional services', 'Business Technical Analyst', 'international clients']",2025-06-13 05:30:59
Hiring Business Analyst with MSTR or Dataiku - Bangalore/ Chennai !!!!,Tech Mahindra,8 - 13 years,Not Disclosed,"['Chennai', 'Bengaluru']","A Business Analyst in the Financial Crime Surveillance Operations (FCSO) Data & Reporting PO Team understands the core concepts, principles, processes or procedures of Data & MI.\nExperienced in using MSTR reports & Dataiku. The FCSO Business Analyst gathers requirements from various stakeholders and creates user stories for the squad to understand and take it for delivery. They must have strong analytical skills, understand the strategic framework & make sense of data.\n\n1.Core Business Analysis Skills\nRequirement Gathering\nDocumentation\nGap analysis\n\n2. Data & MI Expertise\nData Analysis\nData mapping & Metrics understanding\nFCSO Process knowledge (Good to have)\n\n3. Technical Skills\nQuery Databases\nFamiliarity with BI Tools like Dataiku, MSTR\n\n4. Agile & Delivery management\n\nUnderstanding of Scrum for collaborating with Squads\nUser Story Creation\nBacklog Management\nStakeholder Management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Microstrategy', 'Business Analytics', 'Dataiku', 'Business Analysis']",2025-06-13 05:31:00
Business Operations Analyst,Qualcomm,3 - 6 years,Not Disclosed,['Bengaluru'],"Job Area: Operations Group, Operations Group > Business Operations\n\nGeneral Summary:\n\nHiring TitleBusiness Operations Analyst, (Compute GTM)\n\nAbout the GBFS TeamThe Global Business and Finance Support (GBFS) team provide support to HQ and the global regional team on Finance & Business Operation activities. This job role is for business operations related activities- Partner Onboarding, Global Channel Incentive and Marketing Development fund claims, fund requests, fund allocation, invoicing support and ad-hoc reporting.\n\nGeneral Job SummaryThis role serves as a key point of contact for both external customers and internal teams, providing essential support to HQ and Sales Teams. Responsibilities include overseeing account onboarding, managing product SKUs, administering partner offerings, and process MDF/GCI claims. Additionally, the role plays a vital part in ensuring precise reporting, smooth payment integration and communication to internal stakeholders/partners. The ideal candidate will be driven by a passion for fostering outstanding internal collaboration across the organization. Responsibilities include, but are not limited to, the following activities:\n\nJob Overview:\nOversee Partner account onboarding, manage product SKUs, and administer partner offerings\nprocessing of Market Development Funds and Global Channel Incentive claims, ensuring compliance with program guidelines and financial accuracy\nHandle marketing budgets, fund allocations, fund requests with accuracy\nEnsure seamless financial tracking, reporting, and billing processes.\nServe as a key contact for external customers and internal HQ and Sales Teams.\nProvide world-class assistance for Qualcomms products and services while fostering strong internal partnerships.\nPerform additional ad hoc business operations activities from time to time.\n\n\n:\n3 to 6 years relevant industry experience in Sales operations activities\nPrior experience in semiconductor industry, OEMs and partner management is desired.\nExcellent Advanced Excel Skills, Salesforce, data analysis and reporting.\nStrong analytical, problem solving and conceptual skills.\nPositive attitude and willingness to learn skills/tools\nFlexible for evening calls (8PM- 11PM IST) for HQ reviews and transition calls on regular basis and/or working in shift (2.30pm to 11.30pm) as needed\nStrong written and verbal communication skills.\n\n\nEducation :\nBachelors in Science / B.Tech / Commerce / Economics and/or,\nDiploma or Masters in business Analytics\nBusiness Administration from a reputed B-school.\n\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Engineering, Finance, Marketing, or related field and 2+ years of business operations or related experience.\nOR\nHigh School Diploma or equivalent and 4+ years of business operations or related experience.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'salesforce', 'sales operations', 'advanced excel', 'business operations', 'channel sales', 'business analytics', 'business development', 'partner management', 'distribution', 'sales', 'oems', 'business administration', 'marketing', 'sales management', 'dealer network']",2025-06-13 05:31:02
"Business Research Analyst - II, RBS ACCX Program",Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Amazon.com strives to be Earths most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want low prices, vast selection, and convenience Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazons evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the companys DNA. The worlds brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.\n\nOverview of the role\nThe Business Research Analyst will be responsible for Data and Machine learning part of continuous improvement projects across the Discoverability space. This will require collaboration with local and global teams. The Research Analyst should be a self-starter who is passionate about discovering and solving complicated problems, learning complex systems, working with numbers, and organizing and communicating data and reports. The Research Analyst will perform Big data analysis to identify patterns, train model to generate product to product relationship and product to brand & model relationship. The Research Analyst is also expected to continuously improve the ML/LLM solutions in terms of precision & recall, efficiency and scalability. The Research Analyst should be able to write clear and detailed functional specifications based on business requirements.\n\n\nScoping, driving and delivering complex projects across multiple teams.\nPerforms root cause analysis by understanding the data need, get data / pull the data and analyze it to form the hypothesis and validate it using data.\nBuild programs to create a culture of continuous improvement within the business unit, and foster a customer-centric focus on the quality, productivity, and scalability of our services.\nFind the scalable solution for business problem by executing pilots and build Deterministic and ML/LLM models.\nManages meetings, business and technical discussions regarding their part of the projects.\nMakes recommendations and decisions that impact development schedules and the success for a product or project.\nDrives team(s)/partners to meet program and/or product goals.\nCoordinates design effort between internal team and External team to develop optimal solutions.\nPerforms supporting research, conduct analysis of the bigger part of the projects and effectively interpret reports to identify opportunities, optimize processes, and implement changes.\nAbility to convince and interact with stakeholders at all level either to gather data and information or to execute and implement according to the plan.\nAbility to deal with ambiguity and problem solver\nCommunicate ideas effectively and with influence (both verbally and in writing), within and outside the team.\n\nKey Performance Areas:\nSolve large and complex business problems by aligning multiple teams together.\nData analytics and Data Sciences\nMachine learning\nProject/Program Management\nAutomation initiative conceptualization and implementation\nBig Data analytics\nProduct development Scoping and Testing\nDefect Elimination\nAgile Continuous Improvement\n\nAbout the team\nThe RBS group in Chennai/Bangalore is an integral part of Amazon online product lifecycle and buying operations. The team is designed to ensure Amazon remains competitive in the online retail space with the best price, wide selection and good product information. The team s primary role is to create and enhance retail selection on the worldwide Amazon online catalog. The tasks handled by this group have a direct impact on customer buying decisions and online user experience. 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience\nExperience with data visualization using Tableau, Quicksight, or similar tools\nExperience with data modeling, warehousing and building ETL pipelines\nExperience writing complex SQL queries\nExperience in Statistical Analysis packages such as R, SAS and Matlab\nExperience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift\nExperience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets",,,,"['Automation', 'Data analysis', 'SAS', 'Data modeling', 'Machine learning', 'Agile', 'Oracle', 'Data mining', 'MATLAB', 'Python']",2025-06-13 05:31:04
"Business Analyst I, AOP - Perfectmile",Amazon,1 - 6 years,Not Disclosed,['Bengaluru'],"AOP FC Analytics team manages a suite of MIS reporting published at a various regular frequency, productivity tools to bridge the current software challenges and serve all analytical needs of leadership team with data & analysis.\n\nThe ideal candidate relishes working with large volumes of data, enjoys the challenge of highly complex business contexts, and, above all else, is passionate about data and analytics. The candidate is an expert with business intelligence tools and passionately partners with the business to identify strategic opportunities where data-backed insights drive value creation. An effective communicator, the candidate crisply translates analysis result into executive-facing business terms. The candidate works aptly with internal and external teams to push the projects across the finishing line. The candidate is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced and global team.\n\n\nInterfacing with business customers, gathering requirements and delivering complete BI solutions to drive insights and inform product, operations, and marketing decisions.\nInterfacing with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL (Redshift, Oracle) and ability to use a programming and/or scripting language to process data for modeling\nEvolve organization wide Self-Service platforms\nBuilding metrics to analyze key inputs to forecasting systems\nRecognizing and adopting best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation\n\nA day in the life\n1) Solve analyses with well-defined inputs and outputs; drive to the heart of the problem and identify root causes\n2) Have the capability to handle large data sets in analysis\n3) Derive recommendations from analysis\n4) Understand the basics of test and control comparison; may provide insights through basic statistical measures such as hypothesis testing\n5) Communicate analytical insights effectively\n\nAbout the team\nAOP (Analytics Operations and Programs) team is missioned to standardize BI and analytics capabilities, and reduce repeat analytics/reporting/BI workload for operations across IN, AU, BR, MX, SG, AE, EG, SA marketplace.\n\nAOP is responsible to provide visibility on operations performance and implement programs to improve network efficiency and defect reduction. The team has a diverse mix of strong engineers, Analysts and Scientists who champion customer obsession.\n\nWe enable operations to make data-driven decisions through developing near real-time dashboards, self-serve dive-deep capabilities and building advanced analytics capabilities.\n\nWe identify and implement data-driven metric improvement programs in collaboration (co-owning) with Operations teams. 1+ years of tax, finance or a related analytical field experience\n2+ years of complex Excel VBA macros writing experience\nBachelors degree or equivalent\nExperience defining requirements and using data and metrics to draw business insights\nExperience with SQL or ETL Experience working with Tableau\nExperience using very large datasets",,,,"['Data analysis', 'Analytical', 'Test design', 'Hypothesis Testing', 'data integrity', 'Oracle', 'Business intelligence', 'Forecasting', 'Macros', 'SQL']",2025-06-13 05:31:06
Business Analyst,Global Banking Organization,3 - 8 years,Not Disclosed,['Bengaluru'],"Key Skills: Marketing Analytics, Analytics, SQL, Python, Business Analysis, Predictive Analysis, Statistical Analysis.\nRoles and Responsibilities:\nGathers operational data from various cross-functional stakeholders to examine past business performance.\nIdentifies data patterns and trends, and provides insights to enhance business decision-making capability in business planning, process improvement, solution assessment, etc.\nRecommends actions for future developments and strategic business opportunities, as well as enhancements to operational policies.\nMay be involved in exploratory data analysis, confirmatory data analysis, and/or qualitative analysis.\nTranslates data into consumer or customer behavioral insights to drive targeting and segmentation strategies, and communicates clearly and effectively to business partners and senior leaders all findings.\nContinuously improves processes and strategies by exploring and evaluating new data sources, tools, and capabilities.\nWorks closely with internal and external business partners in building, implementing, tracking, and improving decision strategies.\nAppropriately assesses risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing, and reporting control issues with transparency.\nExperience Requirement:\n3-8 years of relevant experience in business analytics, data analysis, or business intelligence roles.\nProven experience in using analytical tools such as SQL, Excel, Python, or R to extract and analyze data.\nHands-on experience with data visualization tools such as Tableau, Power BI, or similar platforms.\nExperience working in cross-functional teams and supporting decision-making through data-driven insights.\nStrong track record of identifying business trends and providing actionable recommendations based on data analysis.\nDemonstrated ability to handle multiple projects simultaneously with a strong attention to detail.\nEducation: B.Tech M.Tech (Dual), MCA, B.Tech.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Marketing Analytics', 'Analytics', 'SQL', 'Python', 'Business Analysis', 'Statistical Analysis.', 'Predictive Analysis']",2025-06-13 05:31:08
Data Researcher & Email Marketing Executive,BTB Venture,0 - 1 years,Not Disclosed,['Pune'],"Role & res\nJob Title: Research Analyst (Fresher)\nCompany: BTB Venture Group\nLocation: Treza Business Hub, 105, Bengaluru - Mumbai Hwy, near Bitwise Tower, Baner, Pune, Maharashtra 411045\nWork Type: Work from Home\nWork Schedule: Monday to Friday (Saturday & Sunday fixed off)\nTimings: 09:30 AM 06:30 PM\nCompany Description:\nBTB Venture Group is a leading Forbes-listed demand generation and lead generation company operating globally. We specialize in delivering high-quality, targeted leads and boosting sales for businesses across various industries. Using advanced analytics, market expansion strategies, and real-time insights, we provide scalable, ROI-driven solutions to help our clients succeed. Join us to be part of a dynamic team that's shaping the future of global marketing.\nwww.btbventure.com\nEducation Qualification:\nBCA / BBA / MCA\nDiploma / BE / BTech in Computer Science or Information Technology\nRequired Skills:\nBasic understanding of Google Sheets\nFamiliarity with Email and Calendar tools\nExposure to tracking systems (e.g., Pivot tables, Filters)\nAbility to conduct effective online research\nKey Responsibilities:\nConduct market research and perform data analysis to identify trends and insights\nPrepare detailed research reports to support business strategies\nCollaborate with cross-functional teams to generate strategic insights\nWork on live projects to enhance practical analytical skills\nMaintain and regularly update the Campaign Spreadsheet to track performance metrics and research outcomes\nponsibilities\n\n\nPreferred candidate profile",Industry Type: Advertising & Marketing (Public Relations),Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Email Campaign', 'Database Marketing', 'Mass Mailing', 'Marketing Campaigns', 'Zoominfo', 'Email Marketing', 'Online Lead Generation', 'Online Research', 'Research', 'Demand Generation']",2025-06-13 05:31:10
Data Scientist,"Sourced Group, an Amdocs Company",4 - 9 years,Not Disclosed,['Gurugram'],"0px> Who are we?\nIn one sentence\nThis is a hands-on position for a motivated and talented innovator. The Data Scientist performs data mining and develops algorithms that provide insight from data.\nWhat will your job look like?\nYou will be responsible for and perform end-top-end data-based research.\nYou will craft data mining solutions to be implemented and executed with alignment to the planned scope and design coverage and needs/uses, demonstrating knowledge and a broad understanding of E2E business processes and requirements.\nYou will define the data analytics research plan, scope and resources required to meet the objectives of his/her area of ownership.\nYou will identify and analyze new data analytic directions and their potential business impact to determine the accurate prioritization of data analytics activities based on business needs and analytics value.\nYou will identify data sources, supervises the data collection process and crafts the data structure in collaboration with data experts (BI or big-data) and subject matter and business experts. Ensures that data used in the data analysis activities are of the highest quality.\nYou will construct data models (algorithms and formulas) for required business needs and predictions.\nYou will present results, including the preparation of patents and white papers and facilitating presentations during conferences.\nAll you need is...\nPh.D. in Computer Science, Mathematics or Statistics\n4 years experience in tasks related to data analytics\nKnowledge of telecommunications and of the subject area being investigated - advantage\nKnowledge in the product (ACC or other) application knowledge and configuration knowledge\nKnowledge in BSS, billing, Telco and the business processes\nFamiliarity in the Telco Networking - mobile, landline, cable TV, Internet\nknowledge in Oracle SQL\nWhy you will love this job:\nYou will ensure timely resolution or critical issue within the agreed SLA. This includes creating a positive customer support experience and build strong relationships through problem understanding, presenting promptly on progress, and handling customers with a professional demeanour.\nYou will be able to demonstrates an understanding of key business drivers and ensures strategic directions are followed and the organization succeeds\nWe are a dynamic, multi-cultural organization that constantly innovates and empowers our employees to grow. Our people our passionate, daring, and phenomenal teammates that stand by each other with a dedication to creating a diverse, inclusive workplace!\nWe offer a wide range of stellar benefits including health, dental, vision, and life insurance as well as paid time off, sick time, and parental leave!\n",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Bss', 'Networking', 'Billing', 'Data collection', 'Customer handling', 'Customer support', 'Data mining', 'Amdocs']",2025-06-13 05:31:12
Financial Planning And Analysis Intern,Kinara Capital,6 months duration,"15,000/month",['Bengaluru( Indira Nagar )'],"Job Title: Financial Planning & Analysis Intern\nDepartment : Finance & Accounting\nPurpose of Job: Vendor Management\n\nJob Responsibilities:\n\nSection 1: Vendor Management\n• Formulation & maintenance of Procure to Pay process\n• To check the pricing as per market rate, to negotiate with the\nvendor, save cost and & to select the potential vendor\n• To assess the risk level of the vendors\n• Liaise with various stakeholders to sign off on the contract terms\n• Ensure smooth on boarding of the vendor\n• Liaise with the various stakeholders to ascertain the\nperformance of the vendor\n• To renew the contracts within the due date\n• Support sourcing strategy, negotiations, and performance\nmanagement\n• Researching vendors\n• Improve vendor relationships\n• Establishing vendor management tools & technologies\n• Troubleshooting vendor issues\n• Stakeholder Management\n• Budget Check and analysis\n• Provide Executive Level briefings to Lead & Finance Controller at\nregular intervals to help keep them current with changes and\nperformance against existing agreements with vendors\nSection 2: Data Management\n• Maintaining a central repository of reports\n• Preparation of a monthly data pack that contains all the\noperational & financial parameters\n• Ensuring control checks on the operational reports being\npublished on a monthly basis\n\nQualifications:\n\nEducation: Degree/CA/MBA\nWork Experience:  Fresher\nOther Requirements: • Excellent communication skills\n• An Excel test needs to be undertaken\n• A PowerPoint presentation to be prepared\n\n• Negotiation\n• Problem-solving\n• Knowledge of procurement processes\n• Metrics and data analysis\n• Engage in continuous learning\n• Risk Identification & mitigation\n\nSkills & Competencies\n\nSkills\nTechnical Skills\n• Microsoft Excel Advanced\n• Financial Modeling & Forecasting\n• Budgeting & Variance Analysis\n• Accounting Knowledge\nSoft Skills\n• Communication Skills\n• Analytical Thinking\n• Collaboration & Teamwork\n• Adaptability\nCompetencies\n• Presentation skills\n• Data-Driven Decision Making\n• Business Partnering\n\nPlace of work: Head office, Bangalore.\nJob Type: Full Time",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent",['Vendor Management'],2025-06-13 05:31:13
Assistant Data Scientist,Rocket Software,0 - 1 years,Not Disclosed,['Pune'],"Face to Face interview in Pune . Please apply only if you are available for a Face to Face interview .\n\nJob highlights\n\nRequired Qualifications . 0 -2 years of relevant industry experience or fresh graduates are welcome to apply.\nBasic experience or understanding in applying Data Science methodologies to extract, process, and transform data from multiple sources.\nPreferred Qualifications . Bachelors degree in Data Science , AI, Statistics ,Computer Science, Economics, or a directly related field.\n\nEssential Duties and Responsibilities\n\nAssist in developing, fine-tuning, and deploying machine learning models.\nAid in consulting with key internal and external stakeholders to understand and frame model requirements and potential applications.\nParticipate in the development of sound analytic plans based on available data sources, business partner needs, and required timelines.\nWork with software engineers in integrating trained models into end-user applications.\nHelp manage deliverables across multiple projects in a deadline-driven environment.\nPresent results, insights, and recommendations to both technical and non-technical stakeholders.\n\nRequired Qualifications\n\n0 -2 years of relevant industry experience or fresh graduates are welcome to apply.\nGood knowledge of Python and Linux, familiarity with ML frameworks, and a willingness to learn.\nDemonstrated problem-solving abilities and creative thinking.\nBasic experience or understanding in applying Data Science methodologies to extract, process, and transform data from multiple sources.\nExcellent communication and interpersonal skills.\nMust be comfortable working in a team-oriented environment.\n\nPreferred Qualifications\n\nBachelor's degree in Statistics, Computer Science, Economics, or a directly related field.\nMasters degree or current enrollment in a Masters program in Statistics, Computer Science, Mathematics, Economics, or directly related fields is a plus.\nDemonstrated passion for continued learning and innovation.\nAs a Data Science Assistant, we expect not just skills and qualifications, but also an enthusiasm for learning and growing within our team. We value those who are adaptable, innovative, and ready to take on challenges in a fast-paced work environment.\n\nDiversity, Inclusion & Equity\n\nAt Rocket we are committed to an inclusive workplace environment, where every Rocketeer can thrive by bringing their full selves to work. Being a Rocketeer means you are part of our movement to continually drive inclusivity, diversity and equity in our workforce.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'NLP', 'Natural Language Processing', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-13 05:31:15
Senior Data Scientist,Ericsson,3 - 8 years,Not Disclosed,['Bengaluru'],"About this Opportunity\nThe complexity of running and optimizing the next generation of wireless networks, such as 5G with distributed edge compute, will require Machine Learning (ML) and Artificial Intelligence (AI) technologies. Ericsson is setting up an AI Accelerator Hub in India to fast-track our strategy execution, using Machine Intelligence (MI) to drive thought leadership, automate, and transform Ericsson s offerings and operations. We collaborate with academia and industry to develop state-of-the-art solutions that simplify and automate processes, creating new value through data insights.\n\nAs a Senior Data Scientist, you will apply your knowledge of data science and ML tools backed with strong programming skills to solve real-world problems.\nResponsibilities:\n1. Lead AI/ML features/capabilities in product/business areas\n2. Define business metrics of success for AI/ML projects and translate them into model metrics\n3. Lead end-to-end development and deployment of Generative AI solutions for enterprise use cases\n4. Design and implement architectures for vector search, embedding models, and RAG systems\n5. Fine-tune and evaluate large language models (LLMs) for domain-specific tasks\n6. Collaborate with stakeholders to translate vague problems into concrete Generative AI use cases\n7. Develop and deploy generative AI solutions using AWS services such as SageMaker, Bedrock, and other AWS AI tools. Provide technical expertise and guidance on implementing GenAI models and best practices within the AWS ecosystem.\n8. Develop secure, scalable, and production-grade AI pipelines\n9. Ensure ethical and responsible AI practices\n10. Mentor junior team members in GenAI frameworks and best practices\n11. Stay current with research and industry trends in Generative AI and apply cutting-edge techniques\n12. Contribute to internal AI governance, tooling frameworks, and reusable components\n13. Work with large datasets including petabytes of 4G/5G networks and IoT data\n14. Propose/select/test predictive models and other ML systems\n15. Define visualization and dashboarding requirements with business stakeholders\n16. Build proof-of-concepts for business opportunities using AI/ML\n17. Lead functional and technical analysis to define AI/ML-driven business opportunities\n18. Work with multiple data sources and apply the right feature engineering to AI models\n19. Lead studies and creative usage of new/existing data sources",,,,"['Wireless', 'Computer science', 'Data analysis', 'cassandra', 'Neural networks', 'Artificial Intelligence', 'Machine learning', 'Telecommunication', 'data visualization', 'Python']",2025-06-13 05:31:16
"SENIOR, DATA SCIENTIST",Walmart,3 - 8 years,Not Disclosed,['Bengaluru'],"Position Summary...\nWhat youll do...\nAbout Team\nThe Catalog Data Science Team at Walmart Global Tech is focused on using the latest research in generative AI (GenAI), artificial intelligence (AI), machine learning (ML), statistics, deep learning, computer vision and optimization to implement solutions that ensure Walmart s product catalog is accurate, complete, and optimized for customer experience. Our team tackles complex data science and ML engineering challenges related to product classification, attribute extraction, trust & safety, and catalog optimization, empowering next-generation retail use cases.\nThe Data Science and ML Engineering community at Walmart Global Tech is active in most of the Hack events, utilizing the petabytes of data at our disposal, to build some of the coolest ideas. All the work we do at Walmart Global Tech will eventually benefit our operations & our associates, helping Customers Save Money to Live Better.\nWhat youll do:\nAs a Senior Data Scientist - ML Engineer, you ll have the opportunity to:\nDrive research initiatives and proof-of-concepts that push the state of the art in generative AI and large-scale machine learning.\nDesign and implement high-throughput, low-latency AI/ML pipelines and microservices that operate at global scale.\nOversee data ingestion, model training, evaluation, deployment and monitoring-ensuring performance, quality and reliability.\nCustomize and optimize LLMs for specific business use cases, balancing accuracy, latency and cost.\nPrototype novel generative AI solutions, integrate advancements into production, and collaborate with research partners.\nChampion best practices in data quality, lineage, governance and cost optimization across ML pipelines.\nMentor a team of ML engineers, establish coding standards, conduct design reviews, and foster a culture of continuous improvement.\nPresent your team s work at top-tier AI/ML conferences, publish scientific papers, and cultivate partnerships with universities and research labs.\nWhat youll bring\nPhD in Computer Science, Statistics, Applied Mathematics or related field with 3+ years experience in ML engineering-or Master s with 6+ years or Bachelor s with 8+ years.\nProven track record of leading and scaling AI/ML products in production environments.\nDeep expertise in generative AI, large-scale model deployment, and fine-tuning of transformer-based architectures.\nStrong programming skills in Python, or equivalent, and experience with big data frameworks (Spark, Hadoop) and ML platforms (TensorFlow, PyTorch).\nDemonstrated history of scientific publications or patents in AI/ML.\nExcellent communication skills, a growth mindset, and the ability to drive cross-functional collaboration.\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nMinimum Qualifications:Option 1- Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years experience in an analytics related field. Option 2- Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years experience in an analytics related field. Option 3 - 5 years experience in an analytics or related field.\nPreferred Qualifications...\nPrimary Location...\n\n\n",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Prototype', 'Networking', 'Coding', 'Machine learning', 'Continuous improvement', 'Information technology', 'Monitoring', 'Analytics', 'Python']",2025-06-13 05:31:18
Senior Data Scientist - Multi-Agent AI Systems,Capgemini,9 - 14 years,Not Disclosed,"['Pune', 'Bengaluru']","Role & responsibilities\nWe are seeking an exceptional Data Scientist with specialized expertise in developing multi-agent AI systems. In this role, you will design, implement, and optimize complex AI ecosystems where multiple intelligent agents collaborate to solve sophisticated problems. You will leverage your deep understanding of generative AI, retrieval-augmented generation (RAG), and prompt engineering to create cutting-edge solutions that push the boundaries of artificial intelligence.\nKey Responsibilities\nDesign and develop generative AI-based multi-agent systems that can collaborate, communicate, and coordinate to achieve complex objectives\nArchitect and implement RAG-based chatbot solutions that effectively leverage knowledge bases and external data sources\nCreate sophisticated prompt engineering strategies to optimize AI agent behavior and inter-agent communication\nBuild, train, and fine-tune generative AI models for various applications within multi-agent systems\nDevelop robust evaluation frameworks to measure and improve multi-agent system performance\nImplement efficient knowledge sharing mechanisms between AI agents\nWrite clean, efficient, and well-documented Python code for production-ready AI systems\nCollaborate with cross-functional teams to integrate multi-agent systems into broader product ecosystems\nStay at the forefront of AI research and incorporate state-of-the-art techniques into our solutions\n\nPreferred candidate profile\nMaster's or PhD in Computer Science, Machine Learning, Artificial Intelligence, or related field\n4+ years of professional experience in data science or machine learning engineering\nExtensive experience with Python programming and related data science/ML libraries\nDemonstrated expertise in developing and deploying generative AI models (e.g., LLMs, diffusion models)\nProven experience building RAG-based systems and implementing vector databases\nStrong background in prompt engineering for large language models\nExperience designing and implementing generative AI-based multi-agent architectures\nExcellent problem-solving skills and ability to optimize complex AI systems\n\nPreferred Qualifications\nExperience with LangChain, AutoGPT, CrewAI, or similar frameworks for building agent-based systems\nFamiliarity with orchestration tools for managing complex AI workflows\nKnowledge of agent communication protocols and collaborative problem-solving frameworks\nExperience with distributed systems and cloud computing platforms (AWS, GCP, Azure)\nContributions to open-source AI projects or research publications in relevant fields\nExperience with knowledge graphs and semantic reasoning systems\nFamiliarity with MLOps practices and deployment of AI systems at scale",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Crewai', 'Langchain', 'AutoGPT']",2025-06-13 05:31:20
Data Scientist,Leading Automobile Manufacturing Company...,5 - 10 years,Not Disclosed,['Chennai'],"Kindly share your resume on sv17@svmanagement.com\nResponsibility:\nWork with different user groups/ departments\nIdentify processes where Analytics driven decision making can create powerful impact\nDesign original analysis that helps generate relevant insights\nEstablishes credibility by thought partnering with business and service teams on analytics topics; takes positions and draws conclusions on a range of external and internal issues\nCommunicates analytical insights through sophisticated synthesis and packaging of results (including PPT slides, dashboards, mailers and alerts)\nCollect, synthesize, analyze team learning & inputs into new best practices and methodologies\nWork with IT teams for implementation of solutions in a production environment\nWork on development of internal capability on the subject\nKeep abreast of most recent developments in the Analytics space and identify new tools and capabilities relevant to company needs.\nAptitude to constantly learn and explore new analytical advancements\nContributes to development of new topic- and sector-related analytics products (development in scope for separate proprietary data & tools team)\nDevelops topic and content related to analytics work for trainings\nProfile:\nExperience in designing analytical solutions using machine learning algorithms\nKnowledge of advanced Excel for preliminary data analysis and good presentation skills\nProficient Coding Knowledge in Python is essential. Developing visualizations in Tableau is desirable\nAdditional coding knowledge in R & Visual Basic will be an advantage\nProficient in web analytics and predictive analytics\nGraduate/certificate in Business Analytics from premier Institute would be an advantage",Industry Type: Automobile,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'R', 'Visual Basic', 'Machine Learning', 'Python', 'Web Analytics', 'Tableau', 'Data Analytics', 'Predictive Analytics']",2025-06-13 05:31:21
Business Operations Analyst 3,Lam Research,5 - 10 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\nAs an Operations Analyst at Lam Research, you will play a pivotal role in enhancing the operational effectiveness and efficiency of the Global Operations team. By employing analytical methodologies, you will guide decision-makers towards achieving operational excellence. Your contributions will be critical in driving improvements and optimizing processes within the organization.\nThe Impact You ll Make\nAs an Operations Analyst at Lam Research, you will play a pivotal role in enhancing the operational effectiveness and efficiency of the Global Operations team. By employing analytical methodologies, you will guide decision-makers towards achieving operational excellence. Your contributions will be critical in driving improvements and optimizing processes within the organization.\nWhat You ll Do\nDevelop, automate, and maintain comprehensive reports and dashboards in both Excel & Power BI.\nAnalyze datasets to provide insights and create visualizations that tell a compelling data story.\nEnsure compliance with analytical standards and data governance policies to maintain data integrity and accuracy.\nChallenge stakeholders to prioritize long-term, data-driven decisions over quick fixes.\nIdentify and communicate process gaps, providing data-driven recommendations to leadership.\nFacilitate change management for data and process changes, ensuring smooth implementation and seamless rollout.\nMeasure and publish operational performance against established metrics and targets\nWho We re Looking For\nRequired Education:\nBachelor s degree in business administration, operations management, supply chain, project management, finance, engineering, or a related field.\nMinimum Qualifications:\nMinimum 5+ years of experience in operations, focused on extracting and analyzing operational data to generate meaningful insights.\nAdvanced capability in data analysis tools and software, particularly Excel (including advanced functions such as Pivot Tables and Power Query) and/or Power BI.\nDemonstrated ability to be a self-learner, continuously seeking out new knowledge and skills to overcome obstacles and enhance performance.\nExcellent written and verbal communication skills.\nProven ability to manage multiple tasks and prioritize effectively.\nDemonstrated ability to develop innovative, out-of-the-box solutions to complex business problems.\nBasic understanding of business operations and processes.\nRequired Skills:\nOperations, Excel (Advanced), Power BI, Data Analysis, Excellent Written and Verbal Communication Skills\nPreferred Qualifications\nExperience with Alteryx for data preparation, modelling, and advanced analytics.\nExceptional ability to analyze and optimize complex operational processes, driving significant improvements in efficiency and effectiveness.\nExtensive experience in process mapping and workflow analysis, with a proven track record of identifying and implementing process enhancements.\nStrong expertise in root cause analysis and corrective action planning, demonstrating the ability to resolve complex issues and prevent recurrence.\nPreferred Skills:\nData Modelling, Workflow Analysis, Corrective Action, Change Management, Root Cause Analysis, Data Governance, Metrics/KPIs, Project Management\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Supply chain', 'Root cause analysis', 'Data analysis', 'Change management', 'Operational excellence', 'Project management', 'Analytical', 'power bi', 'Operations', 'Business operations']",2025-06-13 05:31:23
Business Systems Analyst,Lam Research,6 - 10 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\n[GOPS] [LIGO] [Spares Planning][Planning Systems]\nThe Impact You ll Make\nAs a Business Systems Analyst at Lam, you will be l eading strategic Programs that identify business problems and provide systems solutions/ systems improvement analysis in the Spares Planning function. In your role, you will be closely working on financial reporting of E&O for the spares planning organization and accounting for the worldwide spares inventory\nWhat You ll Do\nMonitoring and analyzing inventory levels, identifying trends, and forecasting demand to prevent excess buildup\nDetermining which parts are excess or obsolete, considering factors like shelf life, market demand, and potential for future use.\nCreating and implementing strategies to manage excess and obsolete inventory, including sell-off programs, returns, or disposal.\nDeveloping and implementing processes to optimize E&O management, including data analysis, reporting, and automation.\nShould be experienced in SAP. Have a good understanding of interfacing excel, SAP, external forecasting tool (SPM provided by PTC).\nProvides/defines input to Planning Systems Roadmap.\nWho We re Looking For\nEngineering degree in the field of Industrial Production/Mechanical (APICS CSCP/CPIM preferred). An MBA with experience in Financial reporting of E&O and exposure to inventory management is mandatory with 6-10 years of experience.\nProficiency in relevant software (e.g., SAP ERP, inventory management systems).\nHands-On technical skills (like Advanced Excel, SQL Programming, Power BI, Power Apps)\nStrong understanding of inventory management principles.\nExperience with E&O (Excess & obsolescence) processes and strategies.\nAbility to analyze data and identify trends.\nExcellent communication and collaboration skills.\nPreferred Qualifications\nHigh energy, strong work ethic, adaptive, able to meet tight deadlines\nProven ability and skill set to analyze, document and improve business processes with sustained results\nHigh level of customer interfacing skills, effective listener, professional and courteous\nExcellent verbal and written communication skills, able to communicate cross-functionally\nStrong interpersonal skills, with a desire to work as part of a team\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Product Management,"Employment Type: Full Time, Permanent","['Automation', 'Data analysis', 'SAP ERP', 'Financial reporting', 'Flex', 'Inventory management', 'Forecasting', 'Monitoring', 'Spares planning', 'SQL']",2025-06-13 05:31:25
Data Engineer - Databricks,KPI Partners,3 - 6 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","About KPI Partners.\nKPI Partners is a leading provider of data analytics solutions, dedicated to helping organizations transform data into actionable insights. Our innovative approach combines advanced technology with expert consulting, allowing businesses to leverage their data for improved performance and decision-making.\n\nJob Description.\nWe are seeking a skilled and motivated Data Engineer with experience in Databricks to join our dynamic team. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and data processing solutions that support our analytics initiatives. You will collaborate closely with data scientists, analysts, and other engineers to ensure the consistent flow of high-quality data across our platforms.",,,,"['python', 'data analytics', 'analytical', 'scala', 'pyspark', 'microsoft azure', 'data warehousing', 'data pipeline', 'data architecture', 'data engineering', 'sql', 'data bricks', 'cloud', 'analytics', 'data quality', 'data modeling', 'gcp', 'teamwork', 'integration', 'aws', 'etl', 'programming', 'communication skills', 'etl scripts']",2025-06-13 05:31:27
Data Engineer,Luxoft,5 - 8 years,Not Disclosed,['Pune'],"Help Group Enterprise Architecture team to develop our suite of EA tools and workbenches\nWork in the development team to support the development of portfolio health insights\nBuild data applications from cloud infrastructure to visualization layer\nProduce clear and commented code\nProduce clear and comprehensive documentation\nPlay an active role with technology support teams and ensure deliverables are completed or escalated on time\nProvide support on any related presentations, communications, and trainings\nBe a team player, working across the organization with skills to indirectly manage and influence\nBe a self-starter willing to inform and educate others\nSkills\nMust have\nB.Sc./M.Sc. degree in computing or similar\n5-8+ years experience as a Data Engineer, ideally in a large corporate environment\nIn-depth knowledge of SQL and data modelling/data processing\nStrong experience working with Microsoft Azure\nExperience with visualisation tools like PowerBI (or Tableau, QlikView or similar)\nExperience working with Git, JIRA, GitLab\nStrong flair for data analytics\nStrong flair for IT architecture and IT architecture metrics\nExcellent stakeholder interaction and communication skills\nUnderstanding of performance implications when making design decisions to deliver performant and maintainable software.\nExcellent end-to-end SDLC process understanding.\nProven track record of delivering complex data apps on tight timelines\nFluent in English both written and spoken.\nPassionate about development with focus on data and cloud\nAnalytical and logical, with strong problem solving skills\nA team player, comfortable with taking the lead on complex tasks\nAn excellent communicator who is adept in, handling ambiguity and communicating with both technical and non-technical audiences\nComfortable with working in cross-functional global teams to effect change\nPassionate about learning and developing your hard and soft professional skills\nNice to have\nExperience working in the financial industry\nExperience in complex metrics design and reporting\nExperience in using artificial intelligence for data analytics\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Power BI Developer\nBI Engineering\nIndia\nBengaluru\nSenior Power BI Developer\nBI Engineering\nIndia\nChennai\nSenior Power BI Developer\nBI Engineering\nIndia\nGurugram\nPune, India\nReq. VR-114797\nBI Engineering\nBCM Industry\n02/06/2025\nReq. VR-114797\nApply for Data Engineer in Pune\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['GIT', 'Enterprise architecture', 'Analytical', 'Artificial Intelligence', 'Data processing', 'Data analytics', 'QlikView', 'JIRA', 'SDLC', 'SQL']",2025-06-13 05:31:28
Data Entry Operator / Mis Executive,Talentlink Solutions,0 - 4 years,1-4 Lacs P.A.,[],"We Are looking For Computer Operator, Who can Perform defined tasks per documented instructions/process\n\nMale And Female Both Can apply\n\nFresher And Experience Both Can Apply\n\nBasic computer knowledge must\n\nHardworking\n\nWork from Home",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Back Office Processing', 'Non Voice Process', 'Data Entry', 'Back Office', 'Back Office Operations', 'Typing Speed', 'Computer Operating', 'Backend Operations', 'Chat Support', 'Non Voice', 'MS Office', 'Email Process', 'Chat Process', 'Data Processing', 'Data Entry Operation']",2025-06-13 05:31:30
Copywriting Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Content Creation\n\n\n\n\nDesignation: Copywriting Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires:Light Creative (Content Writer)Graduate, Post Graduate or Graduate in Fine ArtsThe role will include research, industry-related topics (combining online sources, interviews and studies), writing clear marketing copies to promote products/services, preparing well-structured drafts using CMS/tools, proofreading & editing content before publication, coordinating with marketing and design teams to illustrate articles, conducting simple keyword research, using SEO guidelines to increase web traffic and identifying customers needs and gaps in the content and updating on website.\n\n\n\n\nWhat are we looking for\nContent managementSearch Engine Optimization (SEO)Google AdsGood to have:Basic knowledge of SEO principles, including keyword research and optimization.Knowledge of digital ad platforms like Google Ads, Meta Ads, or LinkedIn Ads.Familiarity with social media analytics tools to gauge campaign performance.\n\n\n\nRoles and Responsibilities:\nRoles & Responsibilities:1.Content Creation:oDevelop high-quality, engaging, and SEO-optimized content for various channels, including websites, blogs, whitepapers, social media, email campaigns, and more.oCreate thought leadership articles, case studies, and product-centric content that aligns with brand goals.oCreate brochures and point of sales materials.2.Editing and Proofreading:oEdit and proofread content to ensure grammatical accuracy, clarity, and consistency with brand tone and style.oReview and refine user-facing content to meet high-quality standards and eliminate errors.3.Research and Analysis:oPerform thorough research on industry trends, topics, and competitors to deliver credible and relevant content.oAnalyze content performance metrics to iterate and improve strategies for better engagement.4.Collaboration:oWork closely with marketing, design, and product teams to ensure alignment between content and overall campaign goals.oPartner with designers to create visually appealing and content-rich assets, such as infographics and presentations.5.Content Optimization:oOptimize web content for search engines (SEO) using targeted keywords, metadata, and link-building strategies.oAdapt and repurpose content for different formats and platforms to maximize reach and impact.6.Project Management:oManage multiple content projects simultaneously, ensuring timely delivery while maintaining quality.oStay flexible and efficient in a fast-paced, deadline-driven environment.7.Compliance and Documentation:oEnsure all content complies with legal and brand standards, including accessibility and regulatory requirements.oMaintain organized project files, style guides, and documentation for easy handoff and collaboration.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'service operations', 'sales', 'seo', 'content optimization', 'ab initio', 'digital marketing', 'metadata', 'data analysis', 'data management', 'oracle', 'data warehousing', 'sql', 'data quality', 'campaigns', 'data governance', 'google analytics', 'etl', 'informatica', 'unix']",2025-06-13 05:31:31
Analyst - Direct Display,Merkle Science,1 - 2 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:Focuses on day-to-day executionProactively reviews and manages client data to ensure optimal performance on all campaignsTracks and reports on campaign results, gathers data analysis and participates in weekly callsGenerates campaign reports and is responsible for pacing, QA and traffickingDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-13 05:31:33
Senior Business Analyst Healthcare (FHIR),Happiest Minds Technologies,10 - 15 years,Not Disclosed,['Bengaluru'],"Job Title: Senior Business Analyst Healthcare (FHIR)\nLocation: Bangalore, India\nExperience: 1015 years\nEmployment Type: Full-time\n\nAbout the Role:\nWe are seeking a skilled and experienced Senior Business Analyst Healthcare (FHIR) to drive the design and implementation of FHIR-based solutions that enable seamless interoperability across healthcare systems. This role requires close collaboration with stakeholders, technical teams, and healthcare domain experts to ensure robust, compliant, and scalable data exchange mechanisms.",,,,"['HL7', 'Business Analyst', 'FHIR']",2025-06-13 05:31:34
Senior Business Analyst - Trade Finance,Luxoft,7 - 12 years,Not Disclosed,['Bengaluru'],"Project description\nTrade Team requires a strong Business Analyst having good knowledge on Trade finance and IMEX product.\n\nResponsibilities\n\nWork with stakeholders (business users, product owners, compliance teams) to gather and document business requirements.\n\nTranslate business needs into functional and technical specifications.\n\nAnalyze existing systems and data flows (e.g., core banking systems, trade finance platforms).\n\nCreate technical specifications for IT teams, including APIs, data mapping, and interface definitions.\n\nUnderstand and document system dependencies and integration touchpoints (e.g., with SWIFT, compliance , Accounting ).\n\nAnalyze current trade finance processes (e.g., letters of credit, guarantees, collections) and recommend improvements.\n\nUnderstand end-to-end trade finance products (e.g., LC, SBLC, BG, Forfaiting, Factoring).\n\nEnsure that solutions meet regulatory and operational requirements specific to trade finance.\n\nCollaborate with operations, product management, compliance, technology, and relationship management teams.\n\nWork with technology teams to design systems or process solutions.\n\nCreate functional specification documents (FSDs), user stories, or process flows.\n\nSupport User Acceptance Testing (UAT) by preparing test cases, validating results, and logging issues.\n\nParticipate in trade finance project planning, tracking milestones, and reporting status.\n\nSupport delivery and deployment activities for new systems or upgrades.\n\nEnsure proposed solutions adhere to compliance, risk management, and operational control standards.\n\nAssist with internal audits, risk assessments, and remediation activities.\n\nPrepare business cases, reports, and dashboards for management.\n\nMaintain documentation including process maps, SOPs, and training guides.\n\nAssist in managing change within the business due to system or process updates.\n\nProvide training or support materials to end-users on new systems or workflows.\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nSkills\nMust have\n\n7+ years of experience in Indian and International trade finance domain\n\nExperience in IMEX\n\nKnowledge in LC, BG, Bills, Loans, EDPMS, IDPMS , TRRACS, Core banking\n\nExperience on SWIFT messages like MT103 and MT202, MT 700, MT 400 and Nostro\n\nStrong knowledge of trade finance instruments and regulatory landscape.\n\nAnalyze business workflows and work with QA and dev teams to identify repetitive and high-impact test cases suitable for automation.\n\nProficiency in SQL, Data Analysis, and Database Management.\n\nProficient API testing (Postman, SoapUI, Swagger) knowledge\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nStrong communication, documentation, and stakeholder engagement skills.\n\nFamiliarity with Agile and/or Waterfall project methodologies.\n\nNice to have\n\nStrong Agile Knowledge.\n\nOther\n\nLanguages\n\nEnglishC2 Proficient\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'documentation', 'sql', 'database management', 'agile', 'trade finance', 'regulatory', 'international trade finance', 'soap ui', 'user stories', 'dashboards', 'swagger', 'instruments', 'postman', 'waterfall', 'stakeholder engagement', 'user acceptance testing', 'api testing', 'swift']",2025-06-13 05:31:36
Technical Business Analysis Specialist,Telstra,4 - 9 years,Not Disclosed,['Pune'],"Employment Type Permanent\nClosing Date 29 June 2025 11:59pm\nJob Title Technical Business Analysis Specialist\nJob Summary\nAs a Technical Business Analysis Specialist, you thrive on collaborating with your team and providing valuable input to support stakeholders and team members to deliver technical analysis and research that enables successful business initiative/mission design and delivery, and ongoing technical capability operational performance. Job Description",,,,"['Data analysis', 'Business analysis', 'Agile', 'Data structures', 'Workflow', 'Gap analysis', 'Continuous improvement', 'JIRA', 'Operations', 'Business Technical Analyst']",2025-06-13 05:31:38
Business Analyst,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis, Cucumber (Software)\n\n\n\n\nGood to have skills : Hands-on Exp. on SQL , . Jira (XRAY) and ConfluenceMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirement gathering sessions with stakeholders.- Create detailed business requirements documentation.- Conduct gap analysis to identify areas for process improvement.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis, Data Analysis & Interpretation, Scrum.- Strong understanding of project management methodologies.- Experience in process mapping and modeling.- Excellent communication and interpersonal skills.- Ability to prioritize and manage multiple tasks simultaneously.- Hands-on experience in SQL- Strong experience using Jira and Confluence.- Strong analytic skills.- Knowledge of all phases of IT software development and implementation life cycle.- Capable to effectively interact with technical team.- Team spirit - Like to explain and share knowledge.- Proactive with continuous improvement mindset.- Hands-on experience in API testing.- At least one experience using Jira XRAY for test cases.- Experience writing feature files in Cucumber format.- Comfortable using process diagram design tools such as Draw.IO or Visio.- Financial/banking industry knowledge is a strong plus.\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Business Analysis.- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['confluence', 'data analysis', 'business analysis', 'scrum', 'jira', 'project management', 'cucumber', 'gap analysis', 'documentation', 'test cases', 'process improvement', 'project management process', 'user stories', 'sql', 'process mapping', 'drawio', 'brd', 'visio', 'fsd', 'frd', 'agile', 'api testing']",2025-06-13 05:31:40
Business Analyst,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis, Data Analysis & Interpretation, Scrum\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirement gathering sessions with stakeholders.- Create detailed business requirements documentation.- Conduct gap analysis to identify areas for process improvement.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis, Data Analysis & Interpretation, Scrum.- Strong understanding of project management methodologies.- Experience in process mapping and modeling.- Excellent communication and interpersonal skills.- Ability to prioritize and manage multiple tasks simultaneously.- Hands-on experience in SQL- Strong experience using Jira and Confluence.- Strong analytic skills.- Knowledge of all phases of IT software development and implementation life cycle.- Capable to effectively interact with technical team.- Team spirit - Like to explain and share knowledge.- Proactive with continuous improvement mindset.- Hands-on experience in API testing.- At least one experience using Jira XRAY for test cases.- Experience writing feature files in Cucumber format.- Comfortable using process diagram design tools such as Draw.IO or Visio.- Financial/banking industry knowledge is a strong plus.\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Business Analysis.- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['confluence', 'data analysis', 'business analysis', 'scrum', 'jira', 'project management', 'gap analysis', 'documentation', 'test cases', 'process improvement', 'project management process', 'user stories', 'sql', 'process mapping', 'drawio', 'ms visio', 'brd', 'visio', 'fsd', 'frd', 'agile', 'api testing']",2025-06-13 05:31:41
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Finastra Fusion Loan IQ\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Strong Exposure to Credit Risk, Counterparty Risk, Financial product, Regulatory reporting, Accounting, Back-office processes within Lending Systems.- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirements gathering sessions with stakeholders.- Conduct data analysis to identify trends and insights.- Develop business process models and documentation.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nExperience with ACBS v8.0 Servicing application is a MUST- Other Lending systems experience such as Loan IQ would be plus.- Experience on additional ACBS components such as Datamart, Notifications, APIs, ATS is appreciated- Technical experience to be comfortable with data models, hands-on with SQL\nAdditional Information:- The candidate should have a minimum of 5 years of experienceas a Business Analyst in Financial Industry- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['credit risk', 'iq', 'regulatory reporting', 'accounting', 'financial products', 'project management', 'data analysis', 'lending', 'documentation', 'business analysis', 'loaniq', 'sql', 'fusion', 'loan operations', 'agile', 'loan syndication', 'acbs', 'finance', 'jira', 'agile methodology']",2025-06-13 05:31:43
Business Analyst,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis, Data Analysis & Interpretation, Scrum\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirement gathering sessions with stakeholders.- Create detailed business requirements documentation.- Conduct gap analysis to identify areas for process improvement.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis, Data Analysis & Interpretation, Scrum.- Strong understanding of project management methodologies.- Experience in process mapping and modeling.- Excellent communication and interpersonal skills.- Ability to prioritize and manage multiple tasks simultaneously.\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Business Analysis.- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'business analysis', 'project management process', 'scrum', 'gap analysis', 'documentation', 'program management', 'process improvement', 'process mapping', 'pmp', 'prince2', 'stakeholder management', 'delivery management', 'pmp trained', 'agile']",2025-06-13 05:31:45
Business Analyst,Accenture,7 - 12 years,Not Disclosed,['Hyderabad'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :SAP CO Management Accounting\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead process improvement initiatives to enhance efficiency.- Conduct data analysis to identify trends and insights.- Develop and maintain project documentation.- Facilitate communication between stakeholders.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in SAP CO Management Accounting.- Strong understanding of financial analysis and reporting.- Experience in process optimization and business process reengineering.- Knowledge of SAP ERP systems.- Hands-on experience in data analysis and interpretation.\nAdditional Information:- The candidate should have a minimum of 7.5 years of experience in SAP CO Management Accounting.- This position is based at our Hyderabad office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['financial analysis', 'data analysis', 'sap erp', 'management accounting', 'sap co management', 'erp', 'hr generalist activities', 'project documentation', 'documentation', 'business analysis', 'process optimization', 'business process re-engineering', 'employee engagement', 'recruitment']",2025-06-13 05:31:46
Business Interlock Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Talent Development - Instructor-Led Training (ILT)\n\n\n\n\nDesignation: Business Interlock Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nImprove workforce performance and productivity, boosts business agility, increases revenue and reduces costsTalent Development processThe practice of training and learning material between an instructor and learners, either individuals or groups. Instructors can also be referred to as a facilitator, who may be knowledgeable and experienced in the learning material, but can also be used more for their facilitation skills and ability to deliver material to learners.\n\n\n\n\nWhat are we looking for\nTalent ManagementIncentive CompensationPayment Processing OperationsPayroll, Benefits, Performance Mgmt & Career DevelopmentAbility to meet deadlinesCollaboration and interpersonal skillsWritten and verbal communicationWFA, TA, CompensationAbility to perform under pressurePerformance Measurement Analysis and ImprovementHR Policy Development & Maintenance\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'business analysis', 'business analytics', 'capital market', 'performance measurement', 'financial analysis', 'data analysis', 'data analytics', 'team management', 'bloomberg', 'investment banking', 'training', 'business consulting', 'agile', 'performance management']",2025-06-13 05:31:48
Business Analyst,Highradius,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Summary:\nBusiness Analyst is responsible for delivering the HighRadius Cloud product implementations of Fortune 1000 clients. He/She will be owning solutioning for client engagements throughout the project life cycle. This is a highly visible and complex role since the candidate will be the main point of contact for project design and work with Client SMEs and stakeholders and Client users across client organization. The candidate must have strong solutioning skills, well organized, detail-oriented, quality-minded and possess excellent written and verbal communication skills. He/She will be responsible for guiding the team members, Associate Consultant and Data Analyst to implement the design and achieve project objectives.",,,,"['Software Implementation', 'Product Implementation', 'Integration', 'Treasury Management', 'Software Delivery', 'Software Solutions', 'SDLC', 'Business Analysis', 'Delivery Management', 'Software Development', 'ERP Implementation', 'Technical Delivery', 'Solutioning', 'IT Management', 'IT Projects']",2025-06-13 05:31:50
MIS & Trading Data Coordinator,Abans Finance,0 - 3 years,Not Disclosed,['Ahmedabad'],"Position Summary:\nWe are looking for a meticulous and proactive Data coordinator to manage trading book entries in our in-house software system. This role is critical for ensuring the accurate generation of Management Information System (MIS) outputs and supporting data analysis. The ideal candidate will have a strong eye for detail, an aptitude for software systems, and a basic understanding of trading and financial operations.\n\n\nRole & responsibilities\nAccurately input trading book data into the companys in-house software system.\nEnsure completeness and consistency in all entries, adhering to organizational standards.\nUnderstand the intricacies of the in-house software system and its functionality.\nMonitor system workflows to identify and resolve issues or anomalies.\nStay updated on software enhancements and implement changes as required.\nPerform validation checks to ensure data integrity and accuracy.\nIdentify discrepancies in trading records and rectify them in coordination with relevant teams.\nGenerate MIS reports and ensure timely and accurate delivery to stakeholders.\nMaintain proper documentation of processes, changes, and findings.\nSupport audits by providing accurate and timely records as needed.\n\nPreferred candidate profile\nDegree in finance, commerce, business administration or a related field with 0-3 years of work experience in trading ops domain.\nBasic understanding of trading operations and financial concepts.\nFamiliarity with financial software systems and MIS reporting.\nProficiency in Microsoft Excel and database management tools.\nAbility to quickly learn and navigate proprietary software systems.\n\nWork Location- Gift City, Ahmedabad\n\nFreshers with trading knowledge can also apply at astha.satam@abans.co.in",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Management Information System', 'MIS Reporting', 'Trade Finance Operations', 'Trade Operations', 'MIS', 'MIS Operations', 'Database Management', 'Trading', 'Trade Finance', 'Trade Finance Management', 'Financial Operations']",2025-06-13 05:31:51
Research Analyst,CapeStart,0 - 5 years,Not Disclosed,['Nagercoil'],"We are looking for smart, dynamic, self-motivated, and collaborative individuals with strong analytic and communication skills to join our growing and fast-paced team of Research Analysts. Daily responsibilities include:\nAssist with a wide variety of qualitative and quantitative research activities, including collecting and analyzing data\nConduct searches; compile and manage databases\nTranslate data into summaries and analyses with conclusions that deliver on objectives and support proactive insights and recommendations",,,,"['Analytical skills', 'Data analysis', 'Excel', 'Quantitative research', 'Networking', 'Data Analyst', 'Research', 'Management', 'Research Analyst', 'Monitoring']",2025-06-13 05:31:53
Data Input & Management Executive,D&B Italiano,0 - 2 years,1.5-1.75 Lacs P.A.,['Ahmedabad'],"Position Overview:\nWe are seeking a diligent and organized professional to join our operations team. The ideal candidate will be responsible for accurate data entry, system management, and reporting processes that support our project and business workflows.\n\nKey Responsibilities:\nInput and manage project-related and administrative data with precision and consistency\nMaintain internal data systems and ensure regular updates across relevant platforms\nGenerate basic analytical reports to assist in operational decision-making\nCollaborate with design and procurement teams to ensure data accuracy across departments\nAssist in documentation of vendor, inventory.\n\nQualifications & Skills:\nBachelors degree in Business Administration, Information Systems, Statistics, or a related field\nStrong proficiency in Microsoft Excel, Google Sheets, and basic data visualization tools\nExcellent attention to detail, organizational, and time management skills\nAbility to work independently and in a cross-functional team environment\nPrior experience in data handling or operations support is advantageous but not mandatory",Industry Type: Architecture / Interior Design,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data Management', 'Data Analysis', 'Data Maintenance', 'Data Collection', 'Advanced Excel', 'Google Sheets', 'Records Management', 'Excel Sheet', 'Data Reporting', 'Excel Report Preparation']",2025-06-13 05:31:55
Associate Analyst,Overture Rede,0 - 1 years,Not Disclosed,['Hyderabad'],"Job Title: Associate Analyst DataLocation: HyderabadExperience:03 YearsQualification: B\nComOpen Position(s):18Job Role:Maintain and update CRM, billing, and project data while supporting content creation and ensuring SLA-based client account management\nMust-Have Skills:-Understanding of advertising sales processes- CRM data entry and account updates-\nContent creation for internal and client-facing use- Invoice processing and account closure- Attention to detail and SLA adherence- Basic financial record management and reporting"",""Work_Experience0-1 year",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Client account management', 'Basic', 'Associate Analyst', 'Sales', 'Invoice processing', 'Finance', 'Billing', 'Advertising', 'Data entry', 'CRM']",2025-06-13 05:31:57
S&C Global Network - AI - Healthcare Analytics - Senior Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title -\n\n\n\nS&C Global Network - AI - Healthcare Analytics - Senior Analyst\n\n\n\nManagement Level:\n\n\n\n10-Senior Analyst\n\n\n\nLocation:\n\n\n\nGurgaon/Bangalore/Mumbai\n\n\n\nMust-have skills:Phython, Spark,SQL, Tableau, Power BI\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\nWHATS IN IT FOR YOU\nConduct data wrangling and analysis on healthcare claims, provider datasets, and publicly available health data.\nDevelop predictive models using data science and AI techniques to address client needs.\nUtilize natural language processing (NLP) capabilities to extract insights from unstructured data sources.\nCollaborate with cross-functional teams to implement analytics solutions effectively.\nTranslate complex data findings into clear, concise, and actionable strategies.\n\n\n\nWhat you would do in this role\nWork with Managers to get Client's business requirements and deliver Analytics driven solution.\nDuties and Responsibilities\nSr. Data Scientist responsible for generating actionable recommendations well-supported by quantitative analysis to help our clients address their ongoing problems.\nPresent analytic findings & opportunities for improvement to senior management and summarize key findings, and aid in the dissemination of metrics throughout the organization.\nBuild knowledge base and disseminate information on applications of variety of analytical techniques.\nDevelop statistical models and delivery of analytic offerings and solutions in health domain areas.\n\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\nExperience in resolving complex data issues in creative and effective ways.\nStrong people management skills both at client site and an offshore environment\nExcellent communication skills and ability to interact with all levels of end users, stakeholders, and technical resources.\nAdept with using Statistical (like forecasting/modeling, optimization models), Machine Learning (GBM, Decision Trees etc.), AI techniques (Deep Learning)\nGood exposure to consulting experience/basic understanding of business problems and suggesting solutions.\n\n\nTechnical\n\n\n\n\nSkills:\nProficient in data handling suites PYTHON, Spark, SQL, or similar packages\nExcellent written and oral communication skills with ability to clearly communicate ideas and results to non-technical businesspeople.\nStrong aptitude, ability, motivation, and interest in placing quantitative analysis in the context of health care business for providers / payers/Public health systems\nExperience working with cloud providers (e.g. AWS, Azure, GCP)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5 Years in Healthcare Analytics\n\n\n\n\nEducational Qualification:\n\n\n\nBachelor's / masters degree in computer science, statistics, applied mathematics, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'power bi', 'sql', 'tableau', 'spark', 'switching', 'advanced analytics', 'network engineering', 'data analytics', 'data analysis', 'microsoft azure', 'networking', 'machine learning', 'data science', 'gcp', 'healthcare analytics', 'network analysis', 'data handling', 'aws', 'ccna']",2025-06-13 05:31:59
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\nAbility to work well in a teamAgility for quick learningAbility to perform under pressureAdaptable and flexibleCommitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'macros', 'service operations', 'data analysis', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-13 05:32:01
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Delivery - Sales Reporting\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDesign, develop and provide reports of exports and representations of pipeline data, sales results and other relevant data points. Assess pipeline status, and sales performance, identify trends and analyze root causes.\n\n\n\n\nWhat are we looking for\nSales Reporting & Channel Analytics Sales Incentive Analytics and Reporting Power BI Adaptable and flexible Commitment to quality Ability to work well in a team Written and verbal communication Agility for quick learning Adhering to timelines\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day-to-day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['service operations', 'bi', 'power bi', 'root cause analysis', 'sales', 'python', 'project management', 'data analysis', 'data analytics', 'data warehousing', 'business analysis', 'business intelligence', 'sql server', 'sql', 'tableau', 'data modeling', 'data visualization', 'etl', 'ssis']",2025-06-13 05:32:03
S&C Global Network - AI - Responsible AI - Sr Analyst,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Entity:- Accenture Strategy & Consulting\n\n\n\nTeam:- Strategy & Consulting Global Network\n\n\n\nPractice:- Responsible AI COE\n\n\n\nTitle:- Responsible AI Specialist/ Sr. Analyst\n\n\n\nJob location:- Bangalore/Gurgaon/Pune/ Hyderabad/Chennai/Mumbai\n\nThe rapid development of AI is creating new opportunities to improve the lives of people around the world, from business to healthcare to education. As a result, it is also raising new questions about the best way to build fairness, interpretability, privacy and security into these systems.\n\nThe Data and AI revolution is changing everything. Its everywhere transforming how we work and play. Join Accenture and help transform leading companies and communities around the world.\n\nAccenture is driving these exciting changes and bringing them to life across 40 industries in more than 120 countries. The sheer scale of our capabilities and client engagements and the way we collaborate with the ecosystem, operate, and deliver value provides an unparalleled opportunity to grow and advance.\n\nAccentures S&C Global Network Data & AI team covers the range of skills, from Strategy, Data Science, Data Architecture, AI Engineering and Visual Insights. When combined with our broader Strategy and Consulting practice, we bring a unique ability to drive end to end business change through the application of Data and AI.\n\nAt the forefront of the industry, youll help make our Responsible AI vision a reality for clients looking to better serve their customers and operate always-on enterprises. Were not just focused on increasing revenues our technologies and innovations are making millions of lives easier and more comfortable. But above all, were doing this responsibly and inclusively to make sure AI technology is used equitably and in a way that is both ethically and technically sound.\n\nJoin us and become an integral part of our global Responsible AI team with the credibility, expertise and insight clients depend on. There will never be a typical day at Accenture, but thats why people love it here. You will be working with famous brands and household names no worrying about how to explain what you do to your family again!\n\nWe are looking for experienced and motivated individuals who will be a part of the\n\n\n\nResponsible AI\n\n\n\nCentre of Excellence (COE) within Accenture to join our multi-disciplinary Responsible AI team. We are committed to help people build AI products/solutions/services in a responsible and trustworthy manner.\n\n\n\nThe ideal candidate should have a strong client-facing consulting background in data science/analytics with an ability to pick up new technologies very quickly. He/she will be passionate about understanding the impact of AI systems on people and society and will have a track record in using tools to undertake assessments such as\n\n\n\nFairness/Bias, Explainability, Model Validation and Robustness, to assess model behaviour through a Responsibility lens.\n\nBeing a part of Accenture will help you grow both professionally and personally as you help shape our thinking and approaches to Responsible AI, working alongside world-class academics, industry leaders and practitioners. Responsible AI is a key strategic priority for Accenture and were looking for the very best in the field to help us meet our ambitious goals in this space.\n\n\n\nResponsibilities:\n\nAs a client-facing in Responsible AI, you will consult with Accentures clients on how todesign & develop reliable, effective user-centered AI systems in adherence to general best practices for software systems, together with practices that address responsibility considerations unique to AI & machine learning. You will also be expected to contribute to research on how AI systems can be designed holistically with fairness, interpretability, privacy, security, safety, and robustness built in by design.\n\nAs part of our team, you will:\nBe a subject matter expert on technical aspects of Responsible AI & Data\nCollaborate with colleagues to develop best practices, frameworks, tools for scalable implementation of Responsible AI in enterprises\nConduct research on Responsible AI policies, principles, issues, risk identification, risk remediation, regulatory requirements, latest trends etc.\nBring a strong conceptual understanding of Responsible AI, principles & tools with experience of using these tools in close collaboration with internal and external stakeholders/clients\nEvaluate and implement technical best practices and tools for fairness, explainability, transparency, accountability, and other relevant aspects of Responsible AI\nDevelop a clear understanding of clients business issues to adopt the best approach to implement the Responsible AI Framework\nEstablish a consistent and collaborative presence by partnering with clients to understand the wider business goals, objectives & competitive constraints\nProvide thought leadership by publishing in public forums/conferences/blogs on Responsible AI products, research or developments\nLeading diverse and well-qualified RAI team.\n\n\nQualification\n\n\n\nSkillset :\n\n\n\n\nEducation:- PhD / Masters / Bachelors degree in Statistics / Economics / Mathematics /Computer Science / Physics or related disciplines from Premier Colleges in India or Abroad. Specialization in Data Science.\n\n\n\nMust Have\n3 10 years of Hands-on Data science experience in solving real life complex business problems\nMinimum 1 years experience in enhancing AI systems to meet Responsible AI principles - Explainability, Fairness, Accountability, etc.\nPassionate about understanding the impact of AI systems on people and society\nHands-on experience of using techniques such as data bias testing (e.g. for under-represented groups, proxy variables, recall bias, skew etc), Explainability (e.g. SHAP values, LIME), sensitivity testing, repeatability and similar to understand model limitations.\nDemonstrated experience in writing reports that summarize analysis / assessments into simple and concise actionable points\nStrong conceptual knowledge and practical experience in the Development, Validation, and Deployment of ML/AL models such as:\nSupervised Learning - regression, classification techniques\nUnsupervised Learning clustering techniques\nRecommender Systems\nReinforcement Learning\nDeep Learning Sequence models (RNN, GRU, LSTM etc.), CNN, GAN etc\nEconometric models\nExploratory Data analysis, Hypothesis testing etc.\nComfortable in ingestion of technical whitepapers, legal policies, government regulations etc. in relation into Responsible AI and work with Academic partners to convert them into practice\nAbility to learn and develop new methods, strategies and frameworks to proactively identify potential loopholes.\nComfortable with ambiguity, believe in first principles and have the skill to transform broad ideas into action plans\nExcellent written and verbal communication skills with ability to clearly communicate ideas and results to both technical and non-technical business audience, such as senior leaders\nGood time management skills to manage day-to-day work progress and ensure timely and high-quality deliverables\nSelf-motivated with ability to work independently across multiple projects and set priorities and Strong analytical bent of mind.\n\n\n\n\nGood to have\nCloud Certifications (Azure / AWS / GCP)\nKnowledge of AWS SageMaker Clarify / Azure Responsible ML and Fairlearn SDK / GCP AI Explanations\nExperience in Chatbot Analytics, Web Crawling\nExperience in MLOps tools like MLflow or Kubeflow\nKnowledge of cybersecurity, vulnerability assessment, risk remediation etc.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'chatbot', 'network analysis', 'aws', 'web crawling', 'switching', 'eigrp', 'network engineering', 'load balancing', 'networking', 'bgp', 'network data', 'ccnp', 'f5', 'routing', 'vlan', 'mpls', 'cisco', 'network security', 'network administration', 'ospf', 'sdwan', 'firewall', 'cisco routers', 'ccna']",2025-06-13 05:32:05
Capital Projects Management Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: IX Intelligent Capital Project Operations - Low Carbon Grid Capital Projects\n\n\n\n\nDesignation: Capital Projects Management Sr Analyst\n\n\n\n\nQualifications:BTech\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Power System Engineer Analyst is responsible for performing detailed analysis of electrical power systems, including transmission, distribution, and generation. The role involves modeling, simulation, and assessment of power systems to ensure their functionality, reliability, and efficiency. The individual will work closely with engineers and stakeholders to identify potential improvements and help design cost-effective solutions. This position requires an in-depth understanding of electrical systems, excellent analytical abilities, and an ability to work in a collaborative environment to ensure that power systems are efficient and reliable.Investment project management and control capabilities related to grid assets to enable the energy transition (e.g. transmission interconnections).\n\n\n\n\nWhat are we looking for\nEducation:Proficient Electrical Engineer with experience around power system modelling and study. A Masters degree in ""Power System Engineering"" is a plus. Technical Skills :Proficiency in power system analysis and simulation software (e.g., PSS/E, ETAP, DIgSILENT PowerFactory, MATLAB/Simulink).Solid understanding of power system components and their operations, including generators, transformers, circuit breakers, relays, and protection devices.Experience with load flow analysis, fault analysis, voltage stability, and other power system studies.Additional Skills :Knowledge of renewable energy integration and energy storage systems. Familiarity with SCADA systems and real-time monitoring of power systems.Experience with advanced automation or grid optimization techniques.Data Analysis and Reporting:Analyze large sets of electrical system data to identify trends, inefficiencies, and areas for improvement.Prepare detailed reports on power system performance, including recommendations for upgrades or modifications.Present findings to senior engineers, managers, and clients.Compliance and Standards:Ensure compliance with industry standards, regulations, and best practices for power system operations.Stay updated on emerging technologies, standards, and regulations related to power systems.\n\n\n\nRoles and Responsibilities: Power System Modeling and Simulation:Use software tools (e.g., MATLAB, PSCAD, PSS/E, ETAP, Digsilent Powerfactory) to model and simulate electrical power systems.Analyze the dynamic behavior of power systems under different operating conditions. Perform load flow analysis, short circuit analysis, stability analysis, and contingency studies.Power Grid Analysis:Assess grid reliability and performance through modeling of transmission and distribution systems. Identify potential risks, faults, and vulnerabilities in power systems. Evaluate and recommend solutions for system optimization, power factor correction, and fault tolerance.System Design and Optimization:Collaborate with electrical engineers to design power systems, including control systems, protection systems, and energy storage solutions. Provide technical support for power system design, including capacity planning, voltage regulation, and fault detection. Recommend improvements to power system components (transformers, circuit breakers, switches, etc.) to ensure efficiency.\n\nQualification\n\nBTech",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['pscad', 'power system', 'system analysis', 'electrical equipment', 'simulation software', 'matlab', 'simulink', 'project operations', 'project management', 'stability analysis', 'system design', 'circuit analysis', 'scada', 'fault analysis', 'power grid analysis', 'short circuit', 'load flow']",2025-06-13 05:32:07
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Delivery - Sprinklr\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIA social media management tool for enterprises. It provides social media marketing, social advertising, content management, collaboration, advocacy and social media monitoring for large enterprises.\n\n\n\n\nWhat are we looking for\nSprinklr Social Media Monitoring & Analytics Adaptable and flexible Written and verbal communication Ability to work well in a team Agility for quick learning Commitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day-to-day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['digital marketing', 'service operations', 'content management', 'sprinklr', 'seo', 'adobe analytics', 'data analysis', 'google adwords', 'power bi', 'social listening', 'radian6', 'sql', 'twitter', 'tableau', 'web analytics', 'social media marketing', 'google analytics', 'sem', 'brandwatch']",2025-06-13 05:32:08
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:Chartered Accountant\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Implementation of gen. ledger processes including yearend closing, journalizing. Creating and maintaining ledgers, ledger currencies, budgets, and journal entries, design to deliver a financial management solution including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry and reporting as well as dynamic allocations and the management of commitments and expenditures also run Interface reports and perform close books of accounts.\n\n\n\n\nWhat are we looking for\nAbility to perform under pressureAbility to establish strong client relationshipStrong analytical skillsProblem-solving skillsFinancial Consolidation, Reporting and month end close activities\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nChartered Accountant",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'budgeting', 'record to report', 'macros', 'service operations', 'data analysis', 'data analytics', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-13 05:32:10
Measurement & Report Senior Analyst,Accenture,6 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Insurance Services - Property and Casualty Insurance\n\n\n\n\nDesignation: Measurement & Report Senior Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:6 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe help insurers redefine their customer experience while accelerating their innovation agenda to drive sustainable growth by transforming to an intelligent operating model. Intelligent Insurance Operations combines our advisory, technology, and operations expertise, global scale, and robust ecosystem with our insurance transformation capabilities. It is structured to address the scope and complexity of the ever-changing insurance environment and offers a flexible operating model that can meet the unique needs of each market segment.Insurance is a legal agreement between two parties the insurer and the insured, also known as insurance coverage or insurance policy. The insurer provides financial coverage for the losses of the insured that s/he may bear under certain circumstancesIn this role, you will be managing workflow process and inventory handle policy maintenance inclusive of, contract amendments, customer & policy maintenance, broker of record changes. You will be managing terminations as needed in internal systems issuance of policy certificates to agents within desired timelines for Property, Auto, Workers Comp, Inland Marine, Travel and Marine Insurance (Commercial & Personal lines in the English Language)\n\n\n\n\nWhat are we looking for\nAnalysis and ReportingDashboard ReportingMonth End ReportingReporting AnalyticsManagement ReportingAbility to work well in a teamPrioritization of workloadHands-on experience with trouble-shootingCommitment to qualityStrong analytical skillsAnalysis and ReportingDashboard ReportingMonth End ReportingReporting AnalyticsManagement ReportingAbility to work well in a teamPrioritization of workloadHands-on experience with trouble-shootingCommitment to qualityStrong analytical skills\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['macros', 'pivot table', 'vlookup', 'reporting analysis', 'advanced excel', 'data analysis', 'mis reporting', 'quality control', 'software testing', 'forecasting', 'power bi', 'business analysis', 'sql', 'tableau', 'vba', 'mis', 'quality assurance', 'data visualization']",2025-06-13 05:32:12
"Senior Analyst, Manufacturing Quality Applications",Schneider Electric India Pvt. Ltd.,3 - 5 years,Not Disclosed,['Bengaluru'],"Title : Senior Analyst, Manufacturing Quality Applications\nLocation: Bengaluru, KA\nWe are seeking a skilled Manufacturing Quality Application analyst with 3 - 5 years of experience Digital Project and/or Support organization, along with a strong understanding of discrete manufacturing processes. Candidate should have experienced applications among those categories : Statistical Process Control application, Incoming Goods Inspections application, Tools Calibration Management application, Product Inspections Management application, Manufacturing or Engineering Change Notice application, Quality Surveillance Plan application, Quality modules of Manufacturing Execution Systems. Knowledge experience on Manufacturing Execution System (MES), Agile Project execution Outsystems lowcode platform is a plus.\nResponsibilities :\nLead the continuous improvement, configuration, and maintenance of CSQ applications (Customer Satisfaction Quality) applied to Manufacturing domain to optimize manufacturing processes and data management.\nCollaborate with cross-functional teams to analyze, design, and improve Quality processes within applications and integrations to other systems\nProvide functional and technical guidance in Board of Change and provide functional specifications based on business requirements\nAnalyze Level 2 tickets, trouble shoot the issues and coordinate with Level 3 Application Developers (internal or 3rd parties) and other Digital Teams to ensure minimal disruptions to production.\nWork with Application developers Digital / Business teams on building functional specifications coordinate agile project releases.\nConduct training programs to educate end-users on system functionalities and best practices.\nStay updated on industry trends and best practices in manufacturing systems to recommend and implement continuous improvements.\nRequirements :\nBachelor s degree in engineering, Mechanical/Production, or related field.\nProven experience (3 -5 years) in implementing and supporting quality applications.\nKnowledge of discrete manufacturing processes and industry standards.\nProficiency in system integration, data analysis, and troubleshooting.\nExcellent communication skills and ability to collaborate with diverse teams.\nExposure to Agile Project execution (optional)\nExposure to Outsystems lowcode platform (optional)\n\n\nBachelor s degree in engineering, Mechanical/Production, or related field.\nProven experience (3 -5 years) in implementing and supporting manufacturing quality applications.\nExposure to",Industry Type: Industrial Equipment / Machinery,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'discrete manufacturing', 'Data management', 'Senior Analyst', 'Manufacturing quality', 'Manufacturing execution system', 'System integration', 'Agile', 'Continuous improvement', 'Project execution']",2025-06-13 05:32:14
"Program Analyst, Senior",Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Operations Group, Operations Group > Program Analyst\n\nGeneral Summary:\n\nAssists with program development and implementation through managing processes, procedures, and tools that improve efficiencies. A Program Analyst coordinates across teams and monitors timelines, budgets, risks, and priorities to achieve program progress. Typically, a program needing a Program Analyst will be of significant size and will require expertise related to the development of project management mechanisms.\n\nMinimum Qualifications:\n\nBachelors degree in engineering, Computer Science, or related field.\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Management, Computer Science, Engineering, Computer Science, or related field.\nOR\nHigh School Diploma or equivalent and 2+ years of relevant work experience.\n\nPreferred Qualifications:\n\nBachelors degree in electrical, Electronics engineering, Computer Science, or related field.\n\n3+ years of experience creating, scheduling, and maintaining program plans or related experience.\n2+ years of experience with program management tools.\n\nPrincipal Duties and Responsibilities:\nRegularly coordinates with third parties and/or internal customers for large, complex programs to identify and meet needs, track and communicate program status updates, and ensure compliance with processes and guidelines.\nPrepares and discusses agenda for review board meetings under guidance of the Program Manager and documents key discussion points, project plan changes, and stakeholder needs.\nContributes to and updates project plans to support Program Managers or Leads on large programs that include priorities, timelines, critical tasks, stakeholder identification for each task, and forecasted resource allocation.\nCollects, compiles, monitors, and maintains budget data, identifies potential issues, and communicates to the Program Manager.\nTracks the progress and execution of complex deliverables to ensure deadlines are met, and identifies and escalates issues that may impact deadlines.\nCoordinates schedules and task assignments for complex projects by following proper project management practices with some guidance from the Program Manager.\nManages and communicates changes in program timelines, priorities, and deliverables to stakeholders.\nIdentifies risks and issues in limited capacity that occur throughout the program lifecycle, communicates issues to the Program Manager, and identifies team members needed to determine a solution.\nGathers, analyzes, and interprets data and program metrics using advanced tools (e.g., macros, pivot tables, charts, graphs) and resolves inconsistencies.\nMaintains and updates databases using advanced aspects of data management tools (e.g., Excel, agile).\nSynthesizes moderately complex data and metrics into a summary of key trends, risks, and changes, and presents results into a report that can be easily understood by key stakeholders.\nGathers feedback and implements improvements to assigned planning processes, tools, and methods.\n\nLevel of Responsibility:\nWorking under some supervision.\nProviding some supervision/guidance to others.\nMaking decisions that are moderate in impact; errors may have relatively minor financial impact or affect on projects, operations, or customer relationships; errors may require involvement beyond immediate work group to correct.\nUsing verbal and written communication skills to convey information that may be somewhat complex to others who may have limited knowledge of the subject in question. May require basic negotiation and influence, cooperation, tact, and diplomacy, etc.\nCompleting most tasks with multiple steps which can be performed in various orders; some planning and prioritization must occur to complete the tasks effectively; mistakes may result in some rework.\nExercising creativity to draft original documents, imagery, or work products within established guidelines.\nUsing deductive problem solving to solve moderately complex problems; most problems have defined processes of diagnosis/detection; some limited data analysis may be required.\n\nThe responsibilities of this role do not include\nBudgetary accountability.\nInfluence over key organizational decisions.\nRole in strategic planning.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['project management', 'macros', 'program management', 'computer science', 'agile', '3d modeling', 'rest', 'data management', 'production', 'assembly design', 'design engineering', 'autocad', 'catia', 'part modeling', 'sheet metal design', 'solid works', 'drafting', 'creo', 'manufacturing', 'part design']",2025-06-13 05:32:16
CPU Performance & Power Analyst/Sr Staff Engineer - 3 Open positions,Qualcomm,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 5+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 12 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'uart', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-13 05:32:18
CPU Performance and Power Analyst/Sr Staff Engineer,Qualcomm,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 5+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 12 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-13 05:32:20
CPU Performance & Power Analyst/Sr Lead Engineer - 5 Open positions,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 5 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-13 05:32:22
CPU Performance and Power Analyst/Sr Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 4+ years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-13 05:32:25
Data Engineer,Accenture,2 - 3 years,Not Disclosed,['Kochi'],"Job Title - Data Engineer Sr.Analyst ACS SONG\n\n\n\nManagement Level:Level 10 Sr. Analyst\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python/Scala, Pyspark/Pytorch\n\n\n\n\nGood to have skills:Redshift\n\n\n\n\n\n\n\nJob\n\n\nSummary\n\nYoull capture user requirements and translate them into business and digitally enabled solutions across a range of industries. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\n\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\n\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\n\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\n\nCreating data products for analytics team members to improve productivity\n\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\n\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\n\nPreparing data to create a unified database and build tracking solutions ensuring data quality\n\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\n\n\nProfessional and Technical Skills\n\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\n\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 2-3 years of hands-on experience working on these technologies.\n\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\n\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\n\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\n\nExperience working in cloud Data warehouses like Redshift or Synapse\n\nCertification in any one of the following or equivalent\n\nAWS- AWS certified data Analytics- Speciality\n\nAzure- Microsoft certified Azure Data Scientist Associate\n\nSnowflake- Snowpro core- Data Engineer\n\nDatabricks Data Engineering\n\n\nAbout Our Company | Accenture (do not remove the hyperlink)\n\n\n\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'microsoft azure', 'glue', 'amazon redshift', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'snowflake', 'scipy', 'data analysis', 'azure data lake', 'power bi', 'data engineering', 'javascript', 'data bricks', 'pandas', 'tableau', 'lambda expressions', 'aws']",2025-06-13 05:32:27
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Coimbatore'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Talend ETL\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL processes to migrate and deploy data across systems. Be involved in the end-to-end data management process.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work-related problems.- Develop and maintain data pipelines for efficient data processing.- Ensure data quality and integrity throughout the data lifecycle.- Implement ETL processes to extract, transform, and load data.- Collaborate with cross-functional teams to optimize data solutions.- Conduct data analysis to identify trends and insights.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Talend ETL.- Strong understanding of data integration and ETL processes.- Experience with data modeling and database design.- Knowledge of SQL and database querying languages.- Hands-on experience with data warehousing concepts.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Talend ETL.- This position is based at our Hyderabad office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'talend etl', 'etl', 'data integration', 'etl process', 'hive', 'python', 'data analysis', 'data management', 'talend', 'data processing', 'data warehousing', 'knowledge of sql', 'data engineering', 'database design', 'data quality', 'data modeling', 'spark', 'data warehousing concepts', 'hadoop']",2025-06-13 05:32:29
Senior Data Scientist,Capgemini,5 - 9 years,Not Disclosed,['Gurugram'],"At Capgemini Invent, we believe difference drives change. As inventive transformation consultants, we blend our strategic, creative and scientific capabilities,collaborating closely with clients to deliver cutting-edge solutions. Join us to drive transformation tailored to our client's challenges of today and tomorrow.Informed and validated by science and data. Superpowered by creativity and design. All underpinned by technology created with purpose.\n\n \n\nYour role \n\nAs a Senior Data Scientist, you are expected to develop and implement Artificial Intelligence based solutions across various disciplines for the Intelligent Industry vertical of Capgemini Invent. You are expected to work as an individual contributor or along with a team to help design and develop ML/NLP models as per the requirement. You will work closely with the Product Owner, Systems Architect and other key stakeholders right from conceptualization till the implementation of the project. You should take ownership while understanding the client requirement, the data to be used, security & privacy needs and the infrastructure to be used for the development and implementation.\n\nThe candidate will be responsible for executing data science projects independently to deliver business outcomes and is expected to demonstrate domain expertise, develop, and execute program plans and proactively solicit feedback from stakeholders to identify improvement actions. This role requires a strong technical background, excellent problem-solving skills, and the ability to work collaboratively with stakeholders from different functional and business teams.\nThe role also requires the candidate to collaborate on ML asset creation and eager to learn and impart trainings to fellow data science professionals. We expect thought leadership from the candidate, especially on proposing to build a ML/NLP asset based on expected industry requirements. Experience in building Industry specific (e.g. Manufacturing, R&D, Supply Chain, Life Sciences etc), production ready AI Models using microservices and web-services is a plus.\n\nProgramming Languages Python NumPy, SciPy, Pandas, MatPlotLib, Seaborne\nDatabases RDBMS (MySQL, Oracle etc.), NoSQL Stores (HBase, Cassandra etc.)\nML/DL Frameworks SciKitLearn, TensorFlow (Keras), PyTorch,\nBig data ML Frameworks - Spark (Spark-ML, Graph-X), H2O\nCloud Azure/AWS/GCP\n\n \n\nYour Profile \n\nPredictive and Prescriptive modelling using Statistical and Machine Learning algorithms including but not limited to Time Series, Regression, Trees, Ensembles, Neural-Nets (Deep & Shallow CNN, LSTM, Transformers etc.). Experience with open-source OCR engines like Tesseract, Speech recognition, Computer Vision, face recognition, emotion detection etc. is a plus.\nUnsupervised learning Market Basket Analysis, Collaborative Filtering, Dimensionality Reduction, good understanding of common matrix decomposition approaches like SVD. Various Clustering approaches Hierarchical, Centroid-based, Density-based, Distribution-based, Graph-based clustering like Spectral.\nNLP Information Extraction, Similarity Matching, Sentiment Analysis, Text Clustering, Semantic Analysis, Document Summarization, Context Mapping/Understanding, Intent Classification, Word Embeddings, Vector Space Models, experience with libraries like NLTK, Spacy, Stanford Core-NLP is a plus. Usage of Transformers for NLP and experience with LLMs like (ChatGPT, Llama) and usage of RAGs (vector stores like LangChain & LangGraps), building Agentic AI applications.\nModel Deployment ML pipeline formation, data security and scrutiny check and ML-Ops for productionizing a built model on-premises and on cloud.\n\nRequired Qualifications\nMasters degree in a quantitative field such as Mathematics, Statistics, Machine Learning, Computer Science or Engineering or a bachelors degree with relevant experience.\nGood experience in programming with languages such as Python/Java/Scala, SQL and experience with data visualization tools like Tableau or Power BI.\n\nPreferred Experience\nExperienced in Agile way of working, manage team effort and track through JIRA\nExperience in Proposal, RFP, RFQ and pitch creations and delivery to the big forum.\nExperience in POC, MVP, PoV and assets creations with innovative use cases\nExperience working in a consulting environment is highly desirable.\nPresupposition\n\nHigh Impact client communication\nThe job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face.\n\n \n\nWhat you will love about working here \nWe recognize the significance of flexible work arrangements to provide support. Be it remote work, or flexible work hours, you will get an environment to maintain healthy work life balance.\nAt the heart of our mission is your career growth. Our array of career growth programs and diverse professions are crafted to support you in exploring a world of opportunities.\nEquip yourself with valuable certifications in the latest technologies such as Generative AI.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['numpy', 'sql', 'java', 'python', 'pandas', 'scala', 'poc', 'nltk', 'dl', 'artificial intelligence', 'tensorflow', 'spacy', 'spark', 'gcp', 'pytorch', 'keras', 'mysql', 'hbase', 'ml', 'jira', 'scipy', 'rdbms', 'oracle', 'mvp', 'microsoft azure', 'power bi', 'nosql', 'tableau', 'cassandra', 'matplotlib', 'agile', 'aws']",2025-06-13 05:32:31
Data Engineer-Business Intelligence,IBM,5 - 10 years,Not Disclosed,['Hyderabad'],"Provide expertise in analysis, requirements gathering, design, coordination, customization, testing and support of reports, in client’s environment\nDevelop and maintain a strong working relationship with business and technical members of the team\nRelentless focus on quality and continuous improvement\nPerform root cause analysis of reports issues\nDevelopment / evolutionary maintenance of the environment, performance, capability and availability.\nAssisting in defining technical requirements and developing solutions\nEffective content and source-code management, troubleshooting and debugging\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n5+ years of experience with BI tools, with expertise and/or certification in at least one major BI platform – Tableau preferred.\nAdvanced knowledge of SQL, including the ability to write complex stored procedures, views, and functions.\nProven capability in data storytelling and visualization, delivering actionable insights through compelling presentations.\nExcellent communication skills, with the ability to convey complex analytical findings to non-technical stakeholders in a clear, concise, and meaningful way.\n5.Identifying and analyzing industry trends, geographic variations, competitor strategies, and emerging customer behavior\n\n\nPreferred technical and professional experience\nTroubleshooting capabilities to debug Data controls Capable of converting business requirements into workable model.\nGood communication skills, willingness to learn new technologies, Team Player, Self-Motivated, Positive Attitude.\nMust have thorough understanding of SQL & advance SQL (Joining & Relationships)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['advance sql', 'sql', 'bi tools', 'debugging', 'troubleshooting', 'python', 'data analysis', 'data analytics', 'bi', 'data warehousing', 'power bi', 'business analysis', 'machine learning', 'business intelligence', 'sql server', 'qlikview', 'tableau', 'r', 'data visualization', 'etl', 'ssis']",2025-06-13 05:32:34
Training & Internship - Data Analytics,SSS Grameen Services,3 months duration,Unpaid,[],"This is a remote position.\n\nThere are internships and Projects for\n- Final Year University students (BBA/MBA)\n- Freshers & housewives\nPassionate students willing to learn and hone their skills are welcome to apply.\n\nRequirements\nWhat Next:\n- Apply with Resume, bonafide certificate, UID Aadhaar, Tentative area of project ( Analytics / AI / Sustainability / Cybersecurity etc.,))\nAppear for\nTechnical Screening #1 (Python or R Coding)\nTechnical Screening #2 (Coding test on ML algorithms like SVM and its implementation or similar)\nAptitude #3 (for Industry Usecases)\n\n- Technical assessment result\nPass - direct Project internship 2-3 months\n- Closure: Letter of internship, Project Report, Completion certificate (apply for respective UGC credits from your University)\n\n\nBenefits\nStipend: nil\nBenefits: Certificate of internship and Project\nMode: LIVE Virtual Remote\n",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Training', 'Technical training', 'LMS', 'Coding', 'Soft skills training', 'Data analytics', 'Internship', 'Python', 'Testing', 'Recruitment']",2025-06-13 05:32:35
MDM Associate Data Steward,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\n\nRole Description\n\nWe are seeking an MDM Associate Data Steward who will be responsible for ensuring the accuracy, completeness, and reliability of master data across critical business domains such as Customer, Product, Affiliations, and Payer. This role involves actively managing and curating master data through robust data stewardship processes, comprehensive data cataloging, and data governance frameworks utilizing Informatica or Reltio MDM platforms. Additionally, the incumbent will perform advanced data analysis, data validation, and data transformation tasks through SQL queries and Python scripts to enable informed, data-driven business decisions. The role emphasizes cross-functional collaboration with various teams, including Data Engineering, Commercial, Medical, Compliance, and IT, to align data management activities with organizational goals and compliance standards.\n\nRoles & Responsibilities\nBasic Qualifications and Experience\nFunctional\n\n\n\nProfessional Certifications\nSoft",,,,"['Data management', 'python', 'project management', 'data analysis', 'data stewardship', 'agile database', 'data processing', 'sql', 'data profiling']",2025-06-13 05:32:37
Associate Data Engineer,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role We are seeking a Associate Data Engineer to design, build, and maintain scalable data solutions that drive business insights. You will work with large datasets, cloud platforms (AWS preferred), and big data technologies to develop ETL pipelines, ensure data quality, and support data governance initiatives.\nDevelop and maintain data pipelines, ETL/ELT processes, and data integration solutions.\nDesign and implement data models, data dictionaries, and documentation for accuracy and consistency.",,,,"['Data Engineering', 'data analysis', 'data modeling', 'data warehousing', 'data visualization', 'Databricks', 'ETL', 'AWS', 'SQL', 'Apache Spark', 'Python']",2025-06-13 05:32:39
Financial Data Operator,International Communication Services India Private Limited,0 - 2 years,Not Disclosed,['Pune'],"*Job Description:\n-We are looking for a detail-oriented Financial Data Operator to join our team.\n-Your primary responsibility will be to update, maintain, and record financial information in both Japanese and English using computerized databases.\n-The accuracy of these records will directly support our clients' operations.\n*Responsibilities:\n-Accurately collect and enter data into financial databases.\n-Maintain precise records in Japanese and English.\n-Perform routine data checks to ensure accuracy and consistency.\n-Utilize spreadsheets and online tools efficiently.\n-Collaborate with the team to troubleshoot and solve challenges effectively.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer Proficiency', 'Team Coordination', 'Jlpt N4', 'Data Analysis', 'Typing Skills', 'Teamwork']",2025-06-13 05:32:41
Data Scientist,NatWest Markets,5 - 10 years,Not Disclosed,['Bengaluru'],"Join us as a Data Scientist\nYou ll design and implement data science tools and methods which harness our data in order to drive market leading purposeful customer solutions\nWe ll look to you to actively participate in the data community to identify and deliver opportunities to support the bank s strategic direction through better use of data\nThis is an opportunity to promote data literacy education with business stakeholders supporting them to foster a data driven culture and to make a real impact with your work\nWere offering this role at associate level\nWhat youll do\nAs a Data Scientist, you ll bring together statistical, mathematical, machine-learning and software engineering skills to consider multiple solutions, techniques and algorithms to develop and implement ethically sound models end-to-end. We ll look to you to understand the needs of business stakeholders, form hypotheses and identify suitable data and analytics solutions to meet those needs in order to support the achievement of our business strategy.\nYou ll also be:\nUsing data translation skills to work closely with business stakeholders to define detailed business questions, problems or opportunities which can be supported through analytics\nApplying a software engineering and product development lens to business problems, creating, scaling and deploying software driven products and services\nWorking in an Agile way within multi-disciplinary data and analytics teams to achieve agreed project and scrum outcomes\nSelecting, building, training and testing machine learning models considering model valuation, model risk, governance and ethics, making sure that models are ready to implement and scale\nIteratively building and prototyping data analysis pipelines to provide insights that will ultimately lead to production deployment\nThe skills youll need\nYou ll need a strong academic background in a STEM discipline such as Mathematics, Physics, Engineering or Computer Science. You ll have an experience of atleast five years with statistical modelling and machine learning techniques.\nWe ll also look for financial services knowledge, and an ability to identify wider business impact, risk or opportunities and make connections across key outputs and processes\nYou ll also demonstrate:\nThe ability to use data to solve business problems from hypotheses through to resolution\nExperience using Python, Tableau, SQL and software engineering fundamentals\nExperience of of analytics in fraud prevention and detection\nExperience of monitoring and maintaining model performance through developing new dashboards and reports, improve existing dashboards and in-house Python packages\nExperience of exploratory data analysis\nGood communication skills with the ability to proactively engage with a wide range of stakeholders",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Machine learning', 'Agile', 'Scrum', 'Analytics', 'Monitoring', 'Financial services', 'SQL', 'Python']",2025-06-13 05:32:43
Data Scientist,Xoom,2 - 4 years,Not Disclosed,['Bengaluru'],"Job Summary\nWhat you need to know about the role\n\nEach Data Scientist on this team has full ownership of a portfolio of a product and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.\n\nMeet our team\n\nPayPals Global Fraud Protection team is responsible for partnering with global business units to manage a variety of risk of various types, including identity fraud, account takeover, stolen financial fraud, and credit issues. This is an exciting department that plays an important role in contributing PayPals bottom line financial savings, ensuring safe and secure global business growth, and delivering the best customer experience.\n\nThis open opportunity is within the Large Merchant and Markets Fraud Risk team. This portfolio is comprised of PayPal s newest leading-edge payments solutions, such as Risk-as-Service, Fastlane, PayPal Complete Payments, etc. as well as customized experiences developed for the company s highest-priority strategic Markets and Partnerships.\nJob Description\nYour way to impact\nYou will be the Data Scientist in the Fraud Risk team , where you will work on leading new projects to build and improve the Risk strategies to prevent fraud using the Risk tooled and custom data & AL/ML models. In this position, you will be partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.\nYour day to day\nIn your day to day role you will -\nIn this role you will have full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates.\nCollaborate with different teams to develop strategies for fraud prevention, loss savings, and optimize transaction declines or improve customer friction.\nYou will work together with cross-functional teams to deliver solutions and providing Risk analytics on frustration trend/ KPIs monitoring or alerting for fraud events.\nThese solutions will adapt PayPal s advanced proprietary fraud prevention tools enabling business growth.\nWhat do you need to bring-\n2-4 years of relevant experience working with large-scale complex dataset.\nStrong analytical mindset, ability to decompose business requirements into an analytical plan, and execute the plan to answer those business questions\nExcellent communication skills, equally adept at working with engineers as well as business leaders\nWant to build new solutions and invent new approaches to big, ambiguous, critical problems\nStrong working knowledge of Excel, SQL and Python/R\nTechnical Proficiency Exploratory Data Analysis and expertise in preparing a clean and structured data for model development. Experience in applying AI/ML techniques for business decisioning including supervised and unsupervised learning (e.g., regression, classification, clustering, decision trees, anomaly detection, etc.). Knowledge of model evaluation techniques such as Precision, Recall, ROC-AUC Curve, etc. along with basic statistical concepts.\nPreferred Qualification\nSubsidiary\nPayPal\nTravel Percent\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https//www.paypalbenefits.com .\nWho We Are\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. .\nBelonging at PayPal\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: Internet,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Risk analytics', 'Analytical', 'Diversity and Inclusion', 'ROC', 'Wellness', 'Risk management', 'Forecasting', 'Monitoring', 'SQL']",2025-06-13 05:32:45
Data Scientist,New Relic One,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an experienced and dynamic Senior Data Scientist to join our team. You will be primarily responsible for driving data-oriented projects and transforming ambiguous business problems into clear, actionable insights as well as productionalizing insights. The ideal candidate is adept at understanding the business needs that are often quantitatively ambiguous and using large complex data sets to find opportunities for product and process optimization.\nWhat youll do\nAnalyzing complex datasets, applying advanced statistical methods as necessary (e.g., time series forecasting, classification, linear/logistic regression).\nDesigning and deploying data-science and technology-based algorithmic solutions to address business needs.\nTranslating data findings into actionable business insights and plans.\nCollaborating effectively with internal stakeholders, understanding their needs and being able to communicate data-driven recommendations.\nPresenting information using data visualization techniques and clearly communicating complex findings and ideas to non-technical stakeholders.\nThis role requires\n2+ years of experience\nProven experience as a Data Scientist, or in a similar role.\nPhD or Masters degree in Statistics, Mathematics, Computer Science, or related quantitative field.\nStrong understanding and application of advanced statistical techniques and concepts, including but not limited to machine learning algorithms, classification, regression, and time series analysis.\nProficiency with data analysis tools and languages such as Python, SQL, etc.\nFamiliarity with data visualization tools (e.g., Looker, Tableau, PowerBI, etc.).\nStrong problem-solving abilities, business acumen, and excellent communication skills.\nAbility to work independently and with minimal supervision.Proven ability in managing and delivering on multiple, competing priorities.\nPrior experience with stakeholder management and ability to present complex data in a clear manner to non-technical audience.\nBonus points if you have\nExperience in Observability is a plus.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAN', 'Logistic regression', 'Data analysis', 'Process optimization', 'Machine learning', 'Stakeholder management', 'Forecasting', 'SQL', 'Python']",2025-06-13 05:32:47
Data Scientist,Neoware Technology Solutions,3 - 7 years,Not Disclosed,"['Chennai', 'Bengaluru']","Data Scientist - Neoware Technology Solutions Private Limited\nRequirements\nDevelop predictive and prescriptive models to optimize business outcomes and drive growth.\nDesign and build Generative AI solutions to enhance business capabilities.\nWork with leading cloud platforms such as AWS, Azure, or GCP.\nProcess and analyze unstructured data using NLP and Computer Vision techniques.\nLead data-driven initiatives and collaborating with stakeholders to understand business needs and develop strategic solutions.\nConduct exploratory data analysis (EDA) to identify patterns, trends and insights in large, complex datasets.\nMentor and coach junior team members, providing technical guidance and fostering a culture of continuous learning and innovation.\nResponsibilities\nB.E. / Masters in Computer Science, Statistics, Applied Mathematics, Economics or a related quantitative field.\n3-7years of experience in data science, with a proven track record of delivering impactful business solutions.\nStrong proficiency in Python/R and SQL; experience with cloud platforms (AWS, Azure or GCP) is a plus.\nSolid understanding of machine learning techniques (classification, regression, clustering) and statistical methods.\nExcellent communication skills, with the ability to convey complex concepts to diverse audiences.\nStrong problem-solving abilities and capability to work both independently and in a team environment\nChennai / Bangalore / Mumbai\nPrincipal Architect (Data and Cloud) Development",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'Data analysis', 'GCP', 'Machine learning', 'Cloud', 'Business solutions', 'AWS', 'SQL', 'Python']",2025-06-13 05:32:48
Business Analyst,CGI,6 - 11 years,Not Disclosed,['Hyderabad'],"Business Data Analyst - HealthCare\nPosition Description\nJob Summary\nWe are seeking an experienced and results-driven Business Data Analyst with 5+ years of hands-on experience in data analytics, visualization, and business insight generation. This role is ideal for someone who thrives at the intersection of business and datatranslating complex data sets into compelling insights, dashboards, and strategies that support decision-making across the organization.\nYou will collaborate closely with stakeholders across departments to identify business needs, design and build analytical solutions, and tell compelling data stories using advanced visualization tools.\nKey Responsibilities\nData Analytics & Insights Analyze large and complex data sets to identify trends, anomalies, and opportunities that help drive business strategy and operational efficiency.\n• Dashboard Development & Data Visualization Design, develop, and maintain interactive dashboards and visual reports using tools like Power BI, Tableau, or Looker to enable data-driven decisions.\n• Business Stakeholder Engagement Collaborate with cross-functional teams to understand business goals, define metrics, and convert ambiguous requirements into concrete analytical deliverables.\n• KPI Definition & Performance Monitoring Define, track, and report key performance indicators (KPIs), ensuring alignment with business objectives and consistent measurement across teams.\n• Data Modeling & Reporting Automation Work with data engineering and BI teams to create scalable, reusable data models and automate recurring reports and analysis processes.\n• Storytelling with Data Communicate findings through clear narratives supported by data visualizations and actionable recommendations to both technical and non-technical audiences.\n• Data Quality & Governance Ensure accuracy, consistency, and integrity of data through validation, testing, and documentation practices.\nRequired Qualifications\nBachelor’s or Master’s degree in Business, Economics, Statistics, Computer Science, Information Systems, or a related field.\n• 5+ years of professional experience in a data analyst or business analyst role with a focus on data visualization and analytics.\n• Proficiency in data visualization tools: Power BI, Tableau, Looker (at least one).\n• Strong experience in SQL and working with relational databases to extract, manipulate, and analyze data.\n• Deep understanding of business processes, KPIs, and analytical methods.\n• Excellent problem-solving skills with attention to detail and accuracy.\n• Strong communication and stakeholder management skills with the ability to explain technical concepts in a clear and business-friendly manner.\n• Experience working in Agile or fast-paced environments.\nPreferred Qualifications\nExperience working with cloud data platforms (e.g., Snowflake, BigQuery, Redshift).\n• Exposure to Python or R for data manipulation and statistical analysis.\n• Knowledge of data warehousing, dimensional modeling, or ELT/ETL processes.\n• Domain experience in Healthcare is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Healthcare Domain', 'Bigquery', 'Redshift Aws', 'Snowflake', 'Data Analytics', 'Data Visualization', 'Python']",2025-06-13 05:32:50
Manager-Business Analyst,Jubilant FoodWorks (JFL),8 - 12 years,Not Disclosed,['Noida'],"The IT Business Analyst is responsible for bridging business needs and IT capabilities, ensuring that technology solutions align with strategic objectives. This role involves analysing business processes including SAP, gathering requirements, and collaborating with IT teams to develop effective solutions. The ideal candidate has strong analytical skills, deep understanding of both business processes preferably Finance background along with IT systems including SAP, and experience in project management.\n\nKey Responsibilities:\n\nBusiness Requirements Gathering\nWork with business stakeholders to identify needs, pain points, and opportunities for process improvement.\nDocument business requirements in clear, detailed formats for technical teams.\n\nSolution Design and Analysis\nAnalyze and evaluate technology solutions that best align with business requirements.\nCreate functional specifications, use cases, and workflow diagrams to communicate solutions effectively.\n\nProject Support and Coordination\nCollaborate with project managers to ensure that projects meet business goals and timelines.\nTrack progress and provide updates on requirements, ensuring adherence to project scope and budget.\n\nTesting and Quality Assurance\nDevelop test cases and participate in system testing to validate that requirements are met.\nAssist in User Acceptance Testing (UAT) and ensure successful project delivery.\n\nContinuous Improvement and Documentation\nRecommend improvements to business processes based on data analysis.\nMaintain and update documentation for requirements, processes, and system changes.\n\nPreferred qualification & skills\n\nBachelors degree preferably in Finance Business, IT, or a related field.\n8+ years of experience in business analysis or a similar role. Experience of Finance & HR domain is preferred under QSR Industry.\nStrong analytical and problem-solving skills, with experience in requirements gathering and process improvement.\nExcellent communication skills, with the ability to work cross-functionally.\nFamiliarity with project management methodologies (Agile, Waterfall).\nKnowledge of data analysis and ERP preferably SAP, CRM, or other business applications.",Industry Type: Hotels & Restaurants,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['User Acceptance Testing', 'SAP', 'Digital Transformation', 'Business Transformation', 'Digitization', 'Process Improvement']",2025-06-13 05:32:52
"Senior Data Engineer ( T-SQL & SSIS,Data Warehousing & ETL Specialist)",Synechron,5 - 10 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Job Summary\nSynechron is seeking a highly skilled Senior Data Engineer specializing in T-SQL and SSIS to lead and advance our data integration and warehousing initiatives. In this role, you will design, develop, and optimize complex ETL processes and database solutions to support enterprise data needs. Your expertise will enable efficient data flow, ensure data integrity, and facilitate actionable insights, contributing to our organizations commitment to data-driven decision-making and operational excellence.\nSoftware Requirements\nOverall Responsibilities\nTechnical Skills (By Category)\nExperience Requirements\nDay-to-Day Activities\nQualifications\nProfessional Competencies",,,,"['Data Engineering', 'T-SQL', 'Azure Data Factory', 'query optimization', 'performance tuning', 'database security', 'AWS Glue', 'Data Warehousing', 'SSIS', 'ETL']",2025-06-13 05:32:54
Data Engineer,Grid Dynamics,4 - 9 years,Not Disclosed,['Bengaluru'],"Required Qualifications:\n4+ years of professional experience in data engineering and data analysis roles.\nStrong proficiency in SQL and experience with database management systems such as MySQL, PostgreSQL, Oracle, and MongoDB.\nHands-on experience with big data tools like Hadoop and Apache Spark.\nProficient in Python programming.\nExperience with data visualization tools such as Tableau, Power BI, and Jupyter Notebooks.\nProven ability to design, build, and maintain scalable ETL pipelines using tools like Apache Airflow, DBT, Composer (GCP), Control-M, Cron, and Luigi.\nFamiliarity with data engineering tools including Hive, Kafka, Informatica, Talend, SSIS, and Dataflow.\nExperience working with cloud data warehouses and services (Snowflake, Redshift, BigQuery, AWS Glue, GCP Dataflow, Azure Data Factory).\nUnderstanding of data modeling concepts and data lake/data warehouse architectures.\nExperience supporting CI/CD practices with Git, Docker, Terraform, and DevOps workflows.\nKnowledge of both relational and NoSQL databases, including PostgreSQL, BigQuery, MongoDB, and DynamoDB.\nExposure to Agile and DevOps methodologies.\nExperience with at least one cloud platform:\nGoogle Cloud Platform (BigQuery, Dataflow, Composer, Cloud Storage, Pub/Sub)\nAmazon Web Services (S3, Glue, Redshift, Lambda, Athena)\nMicrosoft Azure (Data Factory, Synapse Analytics, Blob Storage)\nEssential functions\nKey Responsibilities:\nDesign, develop, and maintain robust, scalable ETL pipelines using Apache Airflow, DBT, Composer (GCP), Control-M, Cron, Luigi, and similar tools.\nBuild and optimize data architectures including data lakes and data warehouses.\nIntegrate data from multiple sources ensuring data quality and consistency.\nCollaborate with data scientists, analysts, and stakeholders to translate business requirements into technical solutions.\nAnalyze complex datasets to identify trends, generate actionable insights, and support decision-making.\nDevelop and maintain dashboards and reports using Tableau, Power BI, and Jupyter Notebooks for visualization and pipeline validation.\nManage and optimize relational and NoSQL databases such as MySQL, PostgreSQL, Oracle, MongoDB, and DynamoDB.\nWork with big data tools and frameworks including Hadoop, Spark, Hive, Kafka, Informatica, Talend, SSIS, and Dataflow.\nUtilize cloud data services and warehouses like AWS Glue, GCP Dataflow, Azure Data Factory, Snowflake, Redshift, and BigQuery.\nSupport CI/CD pipelines and DevOps workflows using Git, Docker, Terraform, and related tools.\nEnsure data governance, security, and compliance standards are met.\nParticipate in Agile and DevOps processes to enhance data engineering workflows.\nQualifications\nData Engineer with experience in MySQL or SQL or PL/SQL and any cloud experience like GCP or AWS or Azure\nWould be a plus\nPreferred Skills:\nStrong problem-solving and communication skills.\nAbility to work independently and collaboratively in a team environment.\nExperience with service development, REST APIs, and automation testing is a plus.\nFamiliarity with version control systems and workflow automation.\nWe offer\nOpportunity to work on bleeding-edge projects\nWork with a highly motivated and dedicated team\nCompetitive salary\nFlexible schedule\nBenefits package - medical insurance, sports\nCorporate social events\nProfessional development opportunities\nWell-equipped office",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Data modeling', 'MySQL', 'Workflow', 'Informatica', 'Oracle', 'Apache', 'SSIS', 'Analytics']",2025-06-13 05:32:56
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Indore'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-13 05:32:58
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Pune'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-13 05:32:59
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,"['Mumbai', 'Any Location']","We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-13 05:33:01
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Nagpur'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-13 05:33:03
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Ahmedabad'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-13 05:33:04
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Delhi / NCR'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-13 05:33:06
Data Engineer,Luxoft,5 - 8 years,Not Disclosed,['Pune'],"Project description\nAre you passionate about leveraging the latest technologies for strategic changeDo you enjoy problem solving in clever waysAre you organized enough to drive change across complex data systemsIf so, you could be the right person for this role.\nAs an experienced data engineer, you will join a global data analytics team in our Group Chief Technology Officer / Enterprise Architecture organization supporting our strategic initiatives which ranges from portfolio health to integration.\n\nResponsibilities\n\nHelp Group Enterprise Architecture team to develop our suite of EA tools and workbenches\n\nWork in the development team to support the development of portfolio health insights\n\nBuild data applications from cloud infrastructure to visualization layer\n\nProduce clear and commented code\n\nProduce clear and comprehensive documentation\n\nPlay an active role with technology support teams and ensure deliverables are completed or escalated on time\n\nProvide support on any related presentations, communications, and trainings\n\nBe a team player, working across the organization with skills to indirectly manage and influence\n\nBe a self-starter willing to inform and educate others\n\nSkills\nMust have\n\nB.Sc./M.Sc. degree in computing or similar\n\n5-8+ years' experience as a Data Engineer, ideally in a large corporate environment\n\nIn-depth knowledge of SQL and data modelling/data processing\n\nStrong experience working with Microsoft Azure\n\nExperience with visualisation tools like PowerBI (or Tableau, QlikView or similar)\n\nExperience working with Git, JIRA, GitLab\n\nStrong flair for data analytics\n\nStrong flair for IT architecture and IT architecture metrics\n\nExcellent stakeholder interaction and communication skills\n\nUnderstanding of performance implications when making design decisions to deliver performant and maintainable software.\n\nExcellent end-to-end SDLC process understanding.\n\nProven track record of delivering complex data apps on tight timelines\n\nFluent in English both written and spoken.\n\nPassionate about development with focus on data and cloud\n\nAnalytical and logical, with strong problem solving skills\n\nA team player, comfortable with taking the lead on complex tasks\n\nAn excellent communicator who is adept in, handling ambiguity and communicating with both technical and non-technical audiences\n\nComfortable with working in cross-functional global teams to effect change\n\nPassionate about learning and developing your hard and soft professional skills\n\nNice to have\n\nExperience working in the financial industry\n\nExperience in complex metrics design and reporting\n\nExperience in using artificial intelligence for data analytics\n\nOther\n\nLanguages\n\nEnglishC1 Advanced\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data processing', 'microsoft azure', 'sql', 'data modeling', 'screening', 'it architecture', 'hiring', 'power bi', 'hrsd', 'knowledge of sql', 'data engineering', 'artificial intelligence', 'sourcing', 'qlikview', 'talent acquisition', 'tableau', 'git', 'recruitment', 'gitlab', 'sdlc', 'jira']",2025-06-13 05:33:07
Data Annotation // Upto 3 LPA,Skill Seekers Consultants,0 - 5 years,2.25-3 Lacs P.A.,"['Noida', 'New Delhi', 'Gurugram', 'Greater Noida', 'Delhi / NCR']","- Job Profile : Data Annotation\n- Location : Gurugram Sector 18\n- Rotational Shifts and Offs\n- Both side Cabs as per International Process\n- Excellent English speaking candidates\n- Freshers and Experienced candidates\n- Data Annotation Assessment\n\nRequired Candidate profile\nYouTube Channel - Sonu Chaurasiya\n\nInterview Location Video --- https://youtu.be/1AmXOLMEPEw\nGaurav Tower near Bank of Baroda pvr, , Vikaspuri, New Delhi, Delhi, 110018\n4th Floor- Waiting area",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Fluent English', 'Back Office', 'Interpretation', 'Data Annotation', 'BPO', 'Communication Skills', 'Transcription', 'Data Analysis', 'Data Collection', 'English Typing', 'Annotation', 'Strong Communication Skills']",2025-06-13 05:33:09
Data Annotation hiring For Fresher || Excellent communication skills,Multinational Company,0 - 4 years,1-3 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Lead data annotation and collection projects.\nDevelop and implement data annotation guidelines and processes.\nTrain and manage data annotation teams.\nCollaborate with data scientists and engineers to understand data requirements.\n\nHR - 63980 09438\n\nRequired Candidate profile\nQualification - Graduate\nSalary :-\nCTC\n25,000 / experience\n20,000 / fresher\nExperience - Data Annotation only\nTransport:- Both Side\n\n5 Day working / Rotation shift / 2 day Rotation week off",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Object Detection', 'Data Annotation', 'Business Intelligence', 'Digital Image Processing', 'Data Management', 'Image Recognition', 'Image Analysis', 'Annotation', 'Deep Learning', 'Pattern Recognition', 'Image Processing', 'Imaging', 'Content Moderation', 'Data Warehousing', 'Data Analytics']",2025-06-13 05:33:11
"STAFF, DATA SCIENTIST",Walmart,4 - 9 years,Not Disclosed,['Bengaluru'],"Position Summary... Drives the execution of multiple business plans and projects by identifying customer and operational needs; developing and communicating business plans and priorities; removing barriers and obstacles that impact performance; providing resources; identifying performance standards; measuring progress and adjusting performance accordingly; developing contingency plans; and demonstrating adaptability and supporting continuous learning. Provides supervision and development opportunities for associates by selecting and training; mentoring; assigning duties; building a team-based work environment; establishing performance expectations and conducting regular performance evaluations; providing recognition and rewards; coaching for success and improvement; and ensuring Belonging awareness. Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application; ensuring compliance with them; and utilizing and supporting the Open Door Policy. Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives; consulting with business partners, managers, co-workers, or other key stakeholders; soliciting, evaluating, and applying suggestions for improving efficiency and cost-effectiveness; and participating in and supporting community outreach events.\nWhat youll do...\nAbout the Team :\nCentroid team at Walmart serves as the backbone of Walmarts end-to-end supply chain strategy. They are entrusted with the task of designing and implementing a long-term supply chain strategy that uses advanced data analytics and data science. Their primary objective is to ensure that Walmart provides top-tier customer service while supporting the increasing demand over time and simultaneously operating at low and efficient costs.\nThe team utilizes sophisticated data analysis methods to understand patterns, identify potential bottlenecks, and predict future trends. This enables them to optimize processes, make informed business decisions, and enhance overall operational efficiency.\nOne of Centroids key responsibilities also includes the creation of a Digital Twin Simulation platform for Walmarts supply chain. This innovative tool allows the team to test and validate all future strategies and tactical decisions before they are launched operationally. It also enables a deep assessment of long-term strategic sensitivity.\nIn essence, the Centroid teams work is integral to ensuring Walmarts supply chain is robust, flexible, and capable of adapting to ever-changing market demands. Their work helps to keep Walmart at the forefront of retail supply chain management, delivering exceptional service to customers while maintaining efficient operational costs.\nWhat Youll do :\nDevelop and manage advanced data analytics models to optimize supply chain strategies, balancing customer satisfaction with operational cost and asset efficiency.\nLeverage data analytics to identify opportunities for improvement and drive impactful results through collaboration with cross-functional teams.\nEstablish relationships across Walmart functional areas to identify best practices, solicit data/input, coordinate interdisciplinary initiatives, and rally support for data-driven recommendations.\nSecure alignment and support from relevant business partners and management for data-centric projects, leading discussions to drive necessary change.\nUtilize all available data resources effectively to ensure successful project outcomes.\nCommunicate data insights clearly and persuasively through emails, verbal discussions, and presentations, tailoring communication methods to the audience for maximum impact.\nCollaborate with multiple supply chain business teams to proactively identify, assess, and leverage cost-saving and service improvement opportunities through advanced data analytics.\nUtilize advanced analytics models to derive insights that will inform policy design across various supply chain areas, laying out multiple scenarios and performing sensitivity analysis.\nCollaborate with Data Scientists and Engineers to productionize and scale advanced analytics models as needed.\nDevelop and present compelling data-driven narratives/documents/visuals to influence key stakeholders in their decision-making.\nProvide coaching and training support to other team members in the supply chain area, leveraging your expertise in advanced data analytics.\nWhat Youll bring :\nStrong analytical acumen with technical expertise in Advanced Data Analytics and modelling\nExpert in SQL, - BigQuery like cloud data platforms.\nExpert in programming in Python, (or R)\nExperience in using data visualization tools like Tableau and Looker and be able to drive powerful insights.\nExperience working with large data sets and distributed computing tools (Map/Reduce, Hadoop, Hive, and/or Spark)\nExperience in operating from a cloud environment such as Google Could Platform or Microsoft Azure.\nAbility to work in a fast-paced, iterative development environment.\nStrong communication skills, both written and verbal, plus ability to work with cross functional teams of technical and non-technical members.\nStrong ability to understand the business and have good stakeholder management capabilities.\nExperience of working in cross-functional environment and leading or mentoring teams.\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nMinimum Qualifications:Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years experience in an analytics related field. Option 3: 6 years experience in an analytics or related field.\nPreferred Qualifications...\nPrimary Location... G, 1, 3, 4, 5 Floor, Building 11, Sez, Cessna Business Park, Kadubeesanahalli Village, Varthur Hobli , India",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Data analysis', 'Supply chain management', 'Networking', 'Analytical', 'Consulting', 'Programming', 'Analytics', 'Python', 'SQL']",2025-06-13 05:33:13
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an exceptional Data Scientist to join a team of experts in the field of machine learning, and work together to tackle challenging problems across diverse compliance domains. We leverage multi-modal and large-language-models (LLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for multi-modal classification, intent detection, information retrieval, anomaly and fraud detection, and generative AI.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of image, text and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nExplore and evaluate state-of-the-art algorithms and approaches in multi-modal classification, large language models (LLMs), intent detection, information retrieval, anomaly and fraud detection, and generative AI\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nContributing to team retrospectives for continuous improvements\nParticipating in science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists building AI/ML solutions to make Amazon Earth s most trusted shopping destination for safe and compliant products. 2+ years of data scientist experience\n2+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience\n2+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\nExperience applying theoretical models in an applied environment\nKnowledge of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Experience in Python, Perl, or another scripting language\nExperience in a ML or data scientist role with a large technology company",,,,"['Data analysis', 'Statistical modeling', 'SAS', 'Machine learning', 'Information retrieval', 'Perl', 'MATLAB', 'Fraud detection', 'Auditing', 'Python']",2025-06-13 05:33:14
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an exceptional Data Scientist to join a team of experts in the field of machine learning, and work together to tackle challenging problems across diverse compliance domains. We leverage risk models (including boosted trees and graph neural networks) as well as vision and large-language-models (LLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for multi-modal classification, intent detection, information retrieval, anomaly and fraud detection, and generative AI.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of image, text and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nExplore and evaluate state-of-the-art algorithms and approaches in risk modeling and vision/language models\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\nEvaluate model performance in production and refresh/implement necessary updates to maintain optimal system performance.\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nContributing to team retrospectives for continuous improvements\nParticipating in science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists building AI/ML solutions to make Amazon Earth s most trusted shopping destination for safe and compliant products. 2+ years of data scientist experience\n3+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience\n3+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\nExperience applying theoretical models in an applied environment\nKnowledge of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Experience in Python, Perl, or another scripting language\nExperience in a ML or data scientist role with a large technology company",,,,"['Data analysis', 'SAS', 'Neural networks', 'risk modeling', 'Machine learning', 'Information retrieval', 'Perl', 'MATLAB', 'Auditing', 'Python']",2025-06-13 05:33:16
Senior Business Analyst,Skillsoft Software Services,2 - 7 years,Not Disclosed,['Hyderabad'],"India-based candidates only. We’re primarily a NYC-based team, but have a growing international team. \n \nROLE OVERVIEW:  \nAs a Senior Data Analyst, you will be pivotal in driving strategic decision-making for the Codecademy consumer and enterprise business lines. Reporting to the senior manager, Strategy and business Operations, this role will work cross-functionally to tackle the business’ highest priorities. You will utilize your technical expertise in data analytics, financial modeling, and executive communication to create actionable business strategies that drive growth.",,,,"['snowflake', 'python', 'data analytics', 'data analysis', 'modeling', 'analytical', 'verbal communication', 'business analysis', 'sql', 'analytics', 'marketing analytics', 'data integration tools', 'looker', 'writing', 'financial modelling', 'data visualization', 'business operations', 'reporting', 'communication skills']",2025-06-13 05:33:18
Senior Business Analyst - Trade Finance,Luxoft,7 - 12 years,Not Disclosed,['Chennai'],"Project description\nTrade Team requires a strong Business Analyst having good knowledge on Trade finance and IMEX product.\n\nResponsibilities\n\nWork with stakeholders (business users, product owners, compliance teams) to gather and document business requirements.\n\nTranslate business needs into functional and technical specifications.\n\nAnalyze existing systems and data flows (e.g., core banking systems, trade finance platforms).\n\nCreate technical specifications for IT teams, including APIs, data mapping, and interface definitions.\n\nUnderstand and document system dependencies and integration touchpoints (e.g., with SWIFT, compliance , Accounting ).\n\nAnalyze current trade finance processes (e.g., letters of credit, guarantees, collections) and recommend improvements.\n\nUnderstand end-to-end trade finance products (e.g., LC, SBLC, BG, Forfaiting, Factoring).\n\nEnsure that solutions meet regulatory and operational requirements specific to trade finance.\n\nCollaborate with operations, product management, compliance, technology, and relationship management teams.\n\nWork with technology teams to design systems or process solutions.\n\nCreate functional specification documents (FSDs), user stories, or process flows.\n\nSupport User Acceptance Testing (UAT) by preparing test cases, validating results, and logging issues.\n\nParticipate in trade finance project planning, tracking milestones, and reporting status.\n\nSupport delivery and deployment activities for new systems or upgrades.\n\nEnsure proposed solutions adhere to compliance, risk management, and operational control standards.\n\nAssist with internal audits, risk assessments, and remediation activities.\n\nPrepare business cases, reports, and dashboards for management.\n\nMaintain documentation including process maps, SOPs, and training guides.\n\nAssist in managing change within the business due to system or process updates.\n\nProvide training or support materials to end-users on new systems or workflows.\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nSkills\nMust have\n\n7+ years of experience in Indian and International trade finance domain\n\nExperience in IMEX\n\nKnowledge in LC, BG, Bills, Loans, EDPMS, IDPMS , TRRACS, Core banking\n\nExperience on SWIFT messages like MT103 and MT202, MT 700, MT 400 and Nostro\n\nStrong knowledge of trade finance instruments and regulatory landscape.\n\nAnalyze business workflows and work with QA and dev teams to identify repetitive and high-impact test cases suitable for automation.\n\nProficiency in SQL, Data Analysis, and Database Management.\n\nProficient API testing (Postman, SoapUI, Swagger) knowledge\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nStrong communication, documentation, and stakeholder engagement skills.\n\nFamiliarity with Agile and/or Waterfall project methodologies.\n\nNice to have\n\nStrong Agile Knowledge.\n\nOther\n\nLanguages\n\nEnglishC2 Proficient\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'documentation', 'sql', 'database management', 'agile', 'trade finance', 'regulatory', 'international trade finance', 'soap ui', 'user stories', 'dashboards', 'swagger', 'instruments', 'postman', 'waterfall', 'stakeholder engagement', 'user acceptance testing', 'api testing', 'swift']",2025-06-13 05:33:20
Senior Functional Business Analyst,Luxoft,5 - 10 years,Not Disclosed,['Gurugram'],"Project description\nThis is a high-visibility opportunity for experienced Functional Business Analysts to work on transformation programs in the Corporate & Institutional Banking (C&IB) domain. The project is centered around enhancing client onboarding processes, strengthening credit and risk evaluation systems, and improving compliance with regulatory requirements, including AML and KYC. The initiative operates in a dynamic Agile environment and involves cross-functional collaboration between business, risk, operations, and technology teams.\n\nResponsibilities\n\nWork closely with business stakeholders to understand, document, and prioritize requirements.\n\nConduct detailed analysis of current-state processes for client onboarding, credit scoring, lending workflows, and compliance.\n\nDefine and document user stories, functional specifications, process flows, and data mappings.\n\nSupport the product owner with backlog refinement, sprint planning, and prioritization.\n\nFacilitate workshops and walkthroughs with subject matter experts.\n\nEnsure alignment between business requirements and technical deliverables.\n\nAssist with UAT planning, test case development, and defect triaging.\n\nMaintain strong communication with project managers, developers, testers, and stakeholders throughout the SDLC.\n\nSkills\nMust have\n\n5+ years of experience as a Functional Business Analyst in the banking or financial services domain.\n\nProven domain expertise in the following:\n\nC&IB Client Onboarding\n\nCredit and Risk Scoring\n\nLending Processes\n\nAML (Anti-Money Laundering)\n\nKYC\n\nStrong verbal and written communication skills in English.\n\nAbility to create structured and well-documented artefacts (resumes will be reviewed for documentation quality).\n\nExperience working in Agile delivery models (Scrum, SAFe).\n\nFamiliarity with tools like JIRA, Confluence, and MS Office Suite.\n\nNice to have\n\nExposure to regulatory change or transformation programs.\n\nKnowledge of GRC platforms or tools (e.g., Archer, ServiceNow GRC).\n\nPrior experience in data analysis or data mapping activities.\n\nFamiliarity with integration patterns between front-office and back-office systems.\n\nAwareness of global banking regulations and compliance frameworks.\n\nOther\n\nLanguages\n\nEnglishB2 Upper Intermediate\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Consulting,"Employment Type: Full Time, Permanent","['aml', 'client onboarding', 'ib', 'lending', 'kyc', 'confluence', 'user stories', 'data mapping', 'financial services', 'brd', 'grc', 'frd', 'jira', 'c', 'data analysis', 'software testing', 'documentation', 'dns', 'business analysis', 'process flow', 'servicenow', 'ms office suite', 'archer', 'scrum', 'agile', 'sdlc']",2025-06-13 05:33:22
Data Scientist-Artificial Intelligence,IBM,10 - 15 years,Not Disclosed,['Bengaluru'],"We're seeking a results-driven and collaborative Software Development Manager to lead the design and development of IBM Consulting Advantage Platform. As a management leader, you'll collaborate with peers and stakeholders to ensure business continuity. You'll also be responsible for building and leading an impactful team of Developers & QA engineers, focusing on software developments, productivity improvements and fostering a culture of continuous learning and improvement.\nIn this role, you will be responsible for:\nLead a team of engineers to meet release dates along with committed deliverables on-time and with quality\nBalance priorities and work assignments across team members following agile processes to meet delivery schedules\nInterface with product management and offering managers to understand customer requirements and business prioritization\nDrive development activities, monitor progress, collaborate to align dependencies, remove blockers for team members and manage risks\nDevelop and implement effective strategies for software development, testing, and deployment\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n10+ years of professional experience; 5+ years as team lead/manager\nExcellent organizational skills including attention to details, time management, and multi-tasking skills\nHands-on experience Experienced building Microservices & REST APIs using Java, and other related technologies\nExperience with Front End Development programming languages and design Frameworks\nStrong project management, organizational, problem-solving, communication, and collaboration skills\n\n\nPreferred technical and professional experience\nHands-on experience with SpringBoot, ReactJS, NodeJS etc\nExperience in working on a production SaaS application with SOC2 certification\nKnowledge of Containerisation technologies such as Kubernetes & Docker, and CI/CD pipelines such as Tekton, ArgoCD etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'ci/cd', 'microservices', 'java', 'project management', 'kubernetes', 'docker', 'ansible', 'sql', 'react.js', 'git', 'devops', 'linux', 'jenkins', 'html', 'shell scripting', 'rest', 'python', 'github', 'maven', 'microsoft azure', 'javascript', 'spring boot', 'node.js', 'saas', 'terraform', 'aws']",2025-06-13 05:33:24
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"As an Associate Data Scientist at IBM, you will work to solve business problems using leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites. You will prepare, analyze, and understand data to deliver insight, predict emerging trends, and provide recommendations to stakeholders.\n\nIn your role, you may be responsible for\nImplementing and validating predictive and prescriptive models and creating and maintaining statistical models with a focus on big data & incorporating machine learning. techniques in your projects\nWriting programs to cleanse and integrate data in an efficient and reusable manner\nWorking in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors\nCommunicating with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.\nEvaluating modelling results and communicating the results to technical and non-technical audiences\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\nCollaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\nDocument solution architectures, design decisions, implementation details, and lessons learned.\nCreate technical documentation, white papers, and best practice guides\n\n\nPreferred technical and professional experience\nStrong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face.\nUnderstanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms\nExperience and working knowledge in COBOL & JAVA would be preferred",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'scikit-learn', 'tensorflow', 'pytorch', 'keras', 'natural language processing', 'neural networks', 'predictive', 'huggingface', 'machine learning', 'prototype', 'artificial intelligence', 'sql', 'pandas', 'deep learning', 'r', 'java', 'cobol', 'data science', 'matplotlib', 'big data', 'statistics']",2025-06-13 05:33:26
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"An AI Data Scientist at IBM is not just a job title - it’s a mindset. You’ll leverage the watsonx,AWS Sagemaker,Azure Open AI platform to co-create AI value with clients, focusing on technology patterns to enhance repeatability and delight clients.\n\nWe are seeking an experienced and innovative AI Data Scientist to be specialized in foundation models and large language models. In this role, you will be responsible for architecting and delivering AI solutions using cutting-edge technologies, with a strong focus on foundation models and large language models. You will work closely with customers, product managers, and development teams to understand business requirements and design custom AI solutions that address complex challenges. Experience with tools like Github Copilot, Amazon Code Whisperer etc. is desirable.\n\nSuccess is our passion, and your accomplishments will reflect this, driving your career forward, propelling your team to success, and helping our clients to thrive.\n\nDay-to-Day Duties:\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions. Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\nDocumentation and Knowledge SharingDocument solution architectures, design decisions, implementation details, and lessons learned. Create technical documentation, white papers, and best practice guides. Contribute to internal knowledge sharing initiatives and mentor new team members.\nIndustry Trends and InnovationStay up to date with the latest trends and advancements in AI, foundation models, and large language models. Evaluate emerging technologies, tools, and frameworks to assess their potential impact on solution design and implementation\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nStrong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face. Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms (e.g. Kubernetes, AWS, Azure, GCP) and related services is a plus.\nExperience and working knowledge in COBOL & JAVA would be preferred\nHaving experience in Code generation, code matching & code translation leveraging LLM capabilities would be a Big plus (e.g. Amazon Code Whisperer, Github Copilot etc.) * Soft\n\nSkills:\nExcellent interpersonal and communication skills. Engage with stakeholders for analysis and implementation. Commitment to continuous learning and staying updated with advancements in the field of AI.\nGrowth mindsetDemonstrate a growth mindset to understand clients' business processes and challenges.\nExperience in python and pyspark will be added advantage\n\n\nPreferred technical and professional experience\nExperienceProven experience in designing and delivering AI solutions, with a focus on foundation models, large language models, exposure to open source, or similar technologies. Experience in natural language processing (NLP) and text analytics is highly desirable. Understanding of machine learning and deep learning algorithms.\nStrong track record in scientific publications or open-source communities\nExperience in full AI project lifecycle, from research and prototyping to deployment in production environments",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'keras', 'kubernetes', 'github', 'natural language processing', 'scikit-learn', 'pyspark', 'microsoft azure', 'artificial intelligence', 'text analytics', 'pandas', 'deep learning', 'java', 'code generation', 'cobol', 'gcp', 'matplotlib', 'aws']",2025-06-13 05:33:28
Senior Business Analyst,BP INCORPORATE INTERNATIONAL.,1 - 4 years,Not Disclosed,['Pune'],"Grade HResponsible for supporting the delivery of business analysis and consulting processes and procedures for the defined specialism using sound technical capabilities, building and maintaining effective working relationships, ensuring relevant standards are defined and maintained, and supporting delivery of process and system improvements. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.\nEntity:\nTechnology\n\nITS Group\n\nYou will work with\nThe AppSim team is responsible for driving application simplification across the organization, focusing on reducing operational complexity and technical debt. They work closely with the wider digital delivery and digital core teams to identify and pursue simplification opportunities. The team collaborates with business partners to align simplification efforts with broader transformation goals and drive measurable improvements in operational efficiency.\nLet me tell you about the role\nA Business Analyst at bp provides enduring deep domain expertise to bridge the gap between business goals and technology solutions. Using techniques such as data analysis, customer and partner interviews and workshops, they gather, refine, and define business requirements and then collaborate with technology colleagues to deliver solutions that meet both user and business needs, ensuring successful roll-out and adoption of solutions.\nWhat you will deliver\nUser research: Engage with users, observe and analyze their workflows, and extract meaningful insights about how they perform a process and interact with a product or system. This involves uncovering pain points, process mapping, pattern recognition, and connecting learnings to potential solutions.\nRequirements definition: Take responsibility for eliciting requirements through various techniques such as interviews, workshops, and document analysis. They lead workshops to assemble and refine requirements, consider tradeoffs, and ensure a clear understanding of system constraints. Additionally, they collaborate with design teams to develop solutions that meet both business and user needs.\nRelationship management: Build strong relationships with commercial and technology partners at all levels within a distributed team, ensuring effective communication, alignment and collaboration.\nBusiness process change: Lead business process workshops to analyze and map business processes, find opportunities for process improvements, and implements changes to enhance efficiency and effectiveness.\nData analysis: Analyze and model data requirements, understand data models and database design to support sophisticated datasets, and provide insights and recommendations based on data analysis to support decision-making.\nService delivery: Diagnose issues and work closely with other support teams across functions to understand defects, drive minor improvements, and document change requests clearly and concisely in order to bring quick resolution.\nWhat you will need to be successful (experience and qualifications)\nStrong analytical and problem-solving skills.\nSuperb oral and written communication skills.\nAbility to build positive relationships with a variety of domain experts.\nTechnical proficiency in areas such as data analysis and modeling, service design, and application design.\nAt this level, a business analyst is encouraged to have strong expertise in core business analysis principles, with extensive knowledge in areas such as requirements definition, stakeholder management, service delivery, testing, business process change, and data analysis. They independently tackle sophisticated problems, lead initiatives, and drive them to completion, demonstrating high skill and expertise in their domain!\nPreferred experience:\nBachelors degree in Business Administration, Information Technology, or a related field, or equivalent experience.\nDemonstrable experience as a Business Analyst or in a similar role.\nFamiliarity with business analysis tools (e.g., ADO, Power BI).\nAbout bp\nOur purpose is to deliver energy to the world, today and tomorrow. For over 100 years, bp has focused on discovering, developing, and producing oil and gas in the nations where we operate. We are one of the few companies globally that can provide governments and customers with an integrated energy offering. Delivering our strategy sustainably is fundamental to achieving our ambition to be a net zero company by 2050 or sooner!\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nTravel Requirement\nUp to 10% travel should be expected with this role\n\nRelocation Assistance:\nThis role is eligible for relocation within country\n\nRemote Type:\nThis position is a hybrid of office/remote working\n\nSkills:\nBusiness Analysis, Business Analysis Tools, Business Analytics, Business Requirements Documentation (BRD), Business Strategy Analysis, Functional Requirements Document (FRD), IT Business Analysis, Software Requirements Analysis, Software Requirements Specifications",Industry Type: Oil & Gas,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Relationship management', 'Data analysis', 'Data management', 'Business analysis', 'Business analytics', 'Analytical', 'Consulting', 'Business strategy', 'Information technology']",2025-06-13 05:33:29
"PRINCIPAL, DATA SCIENTIST",Walmart,10 - 15 years,Not Disclosed,['Bengaluru'],"Position Summary...\nWhat youll do...\nAbout Team\nWalmart s Enterprise Business Services (EBS) is a powerhouse of several exceptional teams delivering world-class technology solutions and services making a profound impact at every level of Walmart.\nAs a key part of Walmart Global Tech, our teams set the bar for operational excellence and leverage emerging technology to support millions of customers, associates, and stakeholders worldwide. Each time an associate turns on their laptop, a customer makes a purchase, a new supplier is onboarded, the company closes the books, physical and legal risk is avoided, and when we pay our associates consistently and accurately, that is EBS. Joining EBS means embarking on a journey of limitless growth, relentless innovation, and the chance to set new industry standards that shape the future of Walmart.\nWhat you will do\nYou will work with the multiple teams and guide them on technical aspects, set quality standards and participate in design discussion and drive technical decisions\nLead the end-to-end lifecycle of AI/ML projects, from ideation to deployment, ensuring alignment with Walmarts strategic goals.\nDesign and implement scalable cloud-based machine learning and data science solutions, leveraging, GCP, or other cloud platforms.\nDevelop novel algorithms and leverage state-of-the-art AI frameworks (e.g., TensorFlow, PyTorch, HuggingFace) to solve complex problems in indirect procurement optimization, customer personalization, and operational efficiency.\nBuild highly parallelized compute environments for processing large-scale datasets, optimizing performance across CPU and GPU architectures.\nCollaborate with diverse teams across engineering, business, and operations to understand requirements and integrate data science solutions seamlessly.\nAdvocate for best practices in software development, including CI/CD, unit testing, and documentation, to ensure robust and reliable systems.\nMentor junior data scientists and contribute to building a culture of innovation and learning within the data science community at Walmart.\nCode Reviews across teams\nEngage with Product Management and Business to drive the agenda, set your priorities and deliver awesome products.\nDrive design, development, implementation and documentation\nBuild, test and deploy cutting edge solutions at scale, impacting associates of Walmart worldwide.\nInteract with Walmart engineering teams across geographies to leverage expertise and contribute to the tech community.\nDrive the success of the implementation by applying technical skills, to design and build enhanced processes and technical solutions in support of strategic initiatives.\nYou will use your engineering experience and technical skill to develop highly scalable and robust solutions. You will work with Engineering Lead/architect.\nWork closely with the Architects and cross functional teams and follow established practices for the delivery of solutions meeting QCD (Quality, Cost & Delivery). Within the established architectural guidelines.\nWork with senior leadership to chart out the future roadmap of the products\nParticipate in hiring and build teams enabling them to be high performing agile teams.\nYou will help and participate with the teams that leverage and contribute to open source technologies to Make impact on a global scale\nInteract closely for requirements with Business owners and technical teams both within India and across the globe.\nWhat you will bring\nB.Tech. / B.E. / M.Tech. / M.S. in Computer Science or relevant discipline\n10+ years of experience in design and development of highly -scalable applications and platform development\nWork in a highly collaborative environment with a multidisciplinary team.\nWork with senior data scientists to design, architect, and build AI/ML model and model systems.\nWork with machine learning engineers to deploy, operate, and optimize scalable solutions\nWork with product managers to design user journeys, feedback loop and analyze user telemetry.\nCreate opportunities to develop yourself with an end-to-end AI/ML product experience.\nWork with a set of robust work standards to ensure we build trustworthy AI/ML solutions\nHosted & Participated Architecture Review & Design/Code Review events.\nHands on System Designing experience.\nStrong computer science fundamentals: data structures, algorithms, design patterns.\nExtensive hands-on experience building services using these technologies (Scala, Java, Springboot, Microservices ,NodeJs)\nHands-on experience in web technologies like React JS/Angular Js, Java script, Type script, CSS\nGood Knowledge in messaging systems: Kafka/RabbitMQ\nWorking knowledge of SQL and NoSQL database technologies.\nKnowledge on Linux platform\nKnowledge on unit testing frameworks (Junit, Jest , Spock etc) and code quality control platforms like Sonar\nKnowledge on cloud platforms any cloud platforms like IAAS/PAAS\nCI/CD development environments/tools: Git, Maven, Gradle, Docker, Kubernetes, Jenkins, Azure DevOps\nExperience in implementing Distributed Cache(Redis/Hazlecast)\nWell-Versed with Logging and Metrics tools and technologies (ELK/Splunk/Grafana)\nKnowledge in search engines like Lucene/Solr\nDemonstrated end-to-end ownership for development and design of least one cloud based project.\nStrong hands on development skills to prototype technical solutions.\nStrong desire to drive change, and ability to adapt to change quickly. Willing to learn new and emerging technologies.\nExceptional communication and interpersonal skills - including negotiation, facilitation, and consensus building skills; ability to influence and persuade, without direct control.\nPractitioner of Agile (Scrum) methodology\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nMinimum Qualifications:Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years experience in an analytics related field. Option 3: 7 years experience in an analytics or related field.\nPreferred Qualifications...",Industry Type: Retail,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Maven', 'Linux', 'Networking', 'Data structures', 'Unit testing', 'Open source', 'Information technology', 'Analytics', 'SQL']",2025-06-13 05:33:31
"STAFF, DATA SCIENTIST",Walmart,5 - 10 years,Not Disclosed,['Bengaluru'],"Position Summary...\nWhat youll do...\nAbout Team\nThe Catalog Data Science Team at Walmart Global Tech is focused on using the latest research in generative AI (GenAI), artificial intelligence (AI), machine learning (ML), statistics, deep learning, computer vision and optimization to implement solutions that ensure Walmart s product catalog is accurate, complete, and optimized for customer experience. Our team tackles complex data science and ML engineering challenges related to product classification, attribute extraction, trust & safety, and catalog optimization, empowering next-generation retail use cases.\nThe Data Science and ML Engineering community at Walmart Global Tech is active in most of the Hack events, utilizing the petabytes of data at our disposal, to build some of the coolest ideas. All the work we do at Walmart Global Tech will eventually benefit our operations & our associates, helping Customers Save Money to Live Better.\nWhat youll do:\nWe are looking for a Staff Machine Learning Engineer who can help build large scale AI/ML/Optimization products. Expected qualities include ability to build, deploy, maintain and troubleshoot large scale systems.\nAs a Staff ML Engineer, you ll have the opportunity to\nDrive research initiatives and proof-of-concepts that push the state of the art in generative AI and large-scale machine learning.\nDesign and implement high-throughput, low-latency AI/ML pipelines and microservices that operate at global scale.\nOversee data ingestion, model training, evaluation, deployment and monitoring-ensuring performance, quality and reliability.\nCustomize and optimize LLMs for specific business use cases, balancing accuracy, latency and cost.\nPrototype novel generative AI solutions, integrate advancements into production, and collaborate with research partners.\nChampion best practices in data quality, lineage, governance and cost optimization across ML pipelines.\nMentor a team of ML engineers, establish coding standards, conduct design reviews, and foster a culture of continuous improvement.\nPresent your team s work at top-tier AI/ML conferences, publish scientific papers, and cultivate partnerships with universities and research labs.\nWhat youll bring:\nPhD in Computer Science, Statistics, Applied Mathematics or related field with 5+ years experience in ML engineering-or Master s with 8+ years or Bachelor s with 10+ years.\nProven track record of leading and scaling AI/ML products in production environments.\nDeep expertise in generative AI, large-scale model deployment, and fine-tuning of transformer-based architectures.\nStrong programming skills in Python, or equivalent, and experience with big data frameworks (Spark, Hadoop) and ML platforms (TensorFlow, PyTorch).\nDemonstrated history of scientific publications or patents in AI/ML.\nExcellent communication skills, a growth mindset, and the ability to drive cross-functional collaboration.\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and\nMinimum Qualifications...\nMinimum Qualifications:Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years experience in an analytics related field. Option 3: 6 years experience in an analytics or related field.\nPreferred Qualifications...\nPrimary Location...",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Prototype', 'Networking', 'Coding', 'Machine learning', 'Continuous improvement', 'Information technology', 'Monitoring', 'Analytics', 'Python']",2025-06-13 05:33:33
Data Scientist (Data & AI Engineer),Visa,2 - 7 years,Not Disclosed,['Bengaluru'],"The Client Services BI & Analytics team strives to create an open, trusting data culture where the cost of curiosity - the number of steps, amount of time, and complexity of effort needed to use operational data to derive insights - is as low as possible. We govern Client Services operational data and metrics, create easily usable dashboards and data sources, and analyze data to share insights.\nWe are a part of the Client Services Global Business Operations function and work with all levels of stakeholders, from executive leaders sharing insights with the C-Suite to customer-facing colleagues who rely on our assets to incorporate data into their daily responsibilities.\nThis specialist role makes data available from new sources, builds robust data models, creates and optimizes data enrichment pipelines, and provides engineering support to specific projects. You will partner with our Data Visualizers and Solution Designers to ensure that data needed by the business is available and accurate and to develop certified data sets. This technical lead and architect role is a force multiplier to our Visualizers, Analysts, and other data users across Client Services.\nResponsibilities\nDesign, develop, and maintain scalable data pipelines and systems.\nMonitor and troubleshoot data pipeline issues to ensure seamless data flow.\nEstablish data processes and automation based on business and technology requirements, leveraging Visa s supported data platforms and tools\nDeliver small to large data engineering and Machine learning projects either individually or as part of a project team\nSetup ML Ops pipelines to Productionalize ML models and setting up Gen AI pipelines\nCollaborate with cross-functional teams to understand data requirements and ensure data quality, with a focus on implementing data validation and data quality checks at various stages of the pipeline\nProvide expertise in data warehousing, ETL, and data modeling to support data-driven decision making, with a strong understanding of best practices in data pipeline design and performance optimization\nExtract and manipulate large datasets using standard tools such as Hadoop (Hive), Spark, Python (pandas, NumPy), Presto, and SQL\nDevelop data solutions using Agile principles\nProvide ongoing production support\nCommunicate complex concepts in a clear and effective manner\nStay up to date with the latest data engineering trends and technologies to ensure the companys data infrastructure is always state-of-the-art, with an understanding of best practices in cloud-based data engineering\nThis is a remote position. A remote position does not require job duties be performed within proximity of a Visa office location. Remote positions may be required to be present at a Visa office with scheduled notice.\n\n\nBasic Qualifications\n-2 or more years of work experience with a Bachelor s Degree or an Advanced Degree (e.g. Masters, MBA, JD, MD, or PhD)\n\nPreferred Qualifications\n-3 or more years of work experience with a Bachelor s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD)\n-3+ years of work experience with a bachelor s degree in the STEM field.\n-Strong experience with SQL, Python, Hadoop, Spark, Hive, Airflow and MPP data bases\n-5+ years of analytics experience with a focus on data Engineering and AI\n-Experience with both traditional data warehousing tools and techniques (such as SSIS, ODI, and on-prem SQL Server, Oracle) as well as modern technologies (such as Hadoop, Denodo, Spark, Airflow, and Python), and a solid understanding of best practices in data engineering\n-Advanced knowledge of SQL (e.g., understands subqueries, self-joining tables, stored procedures, can read an execution plan, SQL tuning, etc.)\n-Solid understanding of best practices in data warehousing, ETL, data modeling, and data architecture.\n-Experience with NoSQL databases (e.g., MongoDB, Cassandra)\n-Experience with cloud-based data warehousing and data pipeline management (AWS, GCP, Azure)\n-Experience in Python, Spark, and exposure to scheduling tools like Tuber/Airflow is preferred.\n-Able to create data dictionaries, setup and monitor data validation alerts, and execute periodic jobs to maintain data pipelines for completed projects\n-Experience with visualization software (e.g., Tableau, QlikView, PowerBI) is a plus.\n-A team player and collaborator, able to work well with a diverse group of individuals in a matrixed environment",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Automation', 'Production support', 'Data modeling', 'Agile', 'Stored procedures', 'QlikView', 'Oracle', 'SSIS', 'Analytics', 'Python']",2025-06-13 05:33:35
Sr. Business Analyst,Aegis Media,8 - 13 years,Not Disclosed,['Mumbai'],"As a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms\nJob Description:\nSr. Business Analyst\nJob Description:\nAs a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms.\nKey Responsibilities\nUnderstand and identify the business issues / requirements and create a detailed Functional Requirement Document\nDevelop a prototype / framework that meets requirements and addresses the business issue.\nBrief the technical team on the requirements. Address and resolve all doubts/queries of the developer / tester. As and when required, check with stakeholders and seek clarity.\nEnsure smooth deployment of the solution and conduct training for end users as and when required.\nPost project completion; seek for feedback from project stakeholders.\nConduct a thorough impact analysis on system for change requests.\nAssist with solution testing and user acceptance testing plans and execution.\nUpdate and maintain solution documentation including requirements documents, data flows, schema/layout documentation, etc.\nMaintain the solution in production, working with end users, and facilitating change requests with the broader team using a defined change management process.\nQualifications + Skills\nBachelor s Degree or equivalent\n8+ years of experience in gathering and documenting solution requirements for the purposes of scope management, design, development and testing enablement.\nGood problem solving and business acumen\nExperience writing and maintaining solution documentation (requirements documents, data flows, User stories, etc.).\nExperience working within common delivery methodologies (e.g. agile and/or waterfall).\nExperience with business intelligence reporting (e.g. Power BI, Tableau, and/or similar platforms).\nExperience with system and user acceptance testing.\nExperience writing SQL to perform data analysis.\nStrong customer service orientation and collaboration skills.\nEffective communication skills, ability to simplify and structure complex concepts to streamline interactions and highlight key points.\nLocation:\nMumbai\nBrand:\nDentsu\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'Change management', 'Manager Quality Assurance', 'Prototype', 'Schema', 'Agile', 'Scope management', 'User acceptance testing', 'SQL']",2025-06-13 05:33:36
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"About Amazon Regulatory Intelligence, Safety, and Compliance (RISC).\n\nAmazon RISC s vision is to make Amazon the Earth s most trusted shopping destination for safe and compliant products. Towards this mission, we take a science-first approach to building technology, products and services, that protect customers from unsafe, illegal, controversial, or policy-violating products while offering the optimal selling partner experience.\n\nJob Summary\n\nWe are seeking an exceptional Data Scientist to join a team of experts in the field of AI/ML, and work together to tackle challenging business problems across diverse compliance domains. We leverage and train state-of-the-art multi-modal, large-language-models (LLMs), and vision language models (VLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for generative AI, agentic system, multi-modal classification, intent detection, information retrieval, anomaly and fraud detection.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of images, texts, documents, and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nDesign and evaluate state-of-the-art algorithms and approaches in generative AI, agentic system, multi-modal classification, intent detection, information retrieval, anomaly and fraud detection.\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\nKey author in writing high quality scientific papers in internal and external peer-reviewed conferences.\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nWriting science papers for submission to peer-review venues, and reviewing science papers from other scientists in the team.\nContributing to team retrospectives for continuous improvements\nDriving science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists and engineers building AI/ML solutions to make Amazon the Earth s most trusted shopping destination for safe and compliant products. PhD, or Masters degree with 2+ years of machine learning experience, or bachelor degree with 3+ years of machine learning experience\nExperience programming in Python, Java, C++, or related language\nExperience with neural deep learning methods, LLM, and natural language processing\nExperience with conducting research in a corporate setting Experience with large scale machine learning systems such as profiling and debugging and understanding of system performance and scalability",,,,"['deep learning', 'C++', 'Debugging', 'Machine learning', 'Information retrieval', 'Natural language processing', 'Scientist II', 'Fraud detection', 'Auditing', 'Python']",2025-06-13 05:33:38
Senior Business Analyst,TechVantage,8 - 10 years,Not Disclosed,['Thiruvananthapuram'],"Role Overview:\nWe are seeking a highly experienced and results-driven Senior Business Analyst with 8+ years of experience in gathering and defining business requirements for complex digital products and platforms. The ideal candidate will have a deep understanding of business processes, exceptional analytical skills, and experience in working with cross-functional teams on technology solutions especially in AI-driven or data-centric environments .\nExperience in the BFSI (Banking, Financial Services, and Insurance) domain is a strong plus , especially for candidates who have worked on digital transformation, risk & compliance, or intelligent automation in financial services.\nWhat we are looking from an ideal candidate?\nEngage with internal and external stakeholders to capture business needs and translate them into clear technical and functional requirements.\nDefine and document user stories , process flows , use cases , and BRDs/FRDs .\nAct as the liaison between business users, developers, QA teams, and product managers to ensure alignment.\nAnalyze current workflows and suggest optimizations to support scalable AI/ML-enabled platforms.\nWork closely with engineering teams to support solution design and development.\nSupport user acceptance testing, training, and change management efforts.\nContribute to product strategy by providing insights based on business analysis and domain trends.\nPreferred Skills: What skills do you need?\nRequirements:\n8+ years of experience as a Business Analyst , preferably in technology product or enterprise solution environments.\nStrong understanding of Agile methodologies , tools like JIRA , Confluence , and modern product delivery practices.\nProven experience with business process mapping , requirements elicitation , and solution validation .\nExcellent communication, stakeholder engagement, and presentation skills.\nFamiliarity with data-driven and AI-integrated products is a strong advantage.\nAbility to work cross-functionally in fast-paced, iterative environments.\nPreferred Qualifications:\nExperience in the BFSI domain (e.g., banking operations, lending, digital payments, fraud detection, insurance workflows).\nExposure to AI/ML-based applications or data platforms.\nCertifications such as CBAP , PMI-PBA , CSPO , or CSM are desirable.\nBasic understanding of data analysis tools, dashboards, and BI reports.\nWhat We Offer:\nOpportunity to work at the intersection of AI innovation and business transformation\nA collaborative, intellectually stimulating work environment\nCareer growth pathways and access to cutting-edge tools and technologies\nAttractive compensation no constraints for the right candidate",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Automation', 'Data analysis', 'Change management', 'Product engineering', 'Business transformation', 'Business analysis', 'Agile', 'JIRA', 'User acceptance testing', 'Financial services']",2025-06-13 05:33:40
Senior Functional Business Analyst,Luxoft,5 - 10 years,Not Disclosed,['Gurugram'],"Work closely with business stakeholders to understand, document, and prioritize requirements.\nConduct detailed analysis of current-state processes for client onboarding, credit scoring, lending workflows, and compliance.\nDefine and document user stories, functional specifications, process flows, and data mappings.\nSupport the product owner with backlog refinement, sprint planning, and prioritization.\nFacilitate workshops and walkthroughs with subject matter experts.\nEnsure alignment between business requirements and technical deliverables.\nAssist with UAT planning, test case development, and defect triaging.\nMaintain strong communication with project managers, developers, testers, and stakeholders throughout the SDLC.\nSkills\nMust have\n5+ years of experience as a Functional Business Analyst in the banking or financial services domain.\nProven domain expertise in at least three of the following:\nC&IB Client Onboarding\nCredit and Risk Scoring\nLending Processes\nAML (Anti-Money Laundering)\nKYC\nStrong verbal and written communication skills in English.\nAbility to create structured and well-documented artefacts (resumes will be reviewed for documentation quality).\nExperience working in Agile delivery models (Scrum, SAFe).\nFamiliarity with tools like JIRA, Confluence, and MS Office Suite.\nNice to have\nExposure to regulatory change or transformation programs.\nKnowledge of GRC platforms or tools (e.g., Archer, ServiceNow GRC).\nPrior experience in data analysis or data mapping activities.\nFamiliarity with integration patterns between front-office and back-office systems.\nAwareness of global banking regulations and compliance frameworks.\nOther\nLanguages\nEnglish: B2 Upper Intermediate\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nJunior Implementation Consultant\nOther Vendor specific (Quantum, Coremont etc.)\nSingapore\nSingapore\nFunctional BA (Orchestrade/Murex/Calypso)\nOther Vendor specific (Quantum, Coremont etc.)\nHong Kong\nHong Kong\nJunior Implementation Consultant\nOther Vendor specific (Quantum, Coremont etc.)\nSingapore\nSingapore\nGurugram, India\nReq. VR-114629\nOther Vendor specific (Quantum, Coremont etc.)\nBCM Industry\n27/05/2025\nReq. VR-114629\nApply for Senior Functional Business Analyst in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Front office', 'Agile', 'calypso', 'Back office', 'Scrum', 'JIRA', 'SDLC', 'Murex', 'Financial services']",2025-06-13 05:33:42
Measurement & Report Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Jaipur'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Senior Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nEffective communication and organization skills with Polished, professional presence Experience in reporting of contractual metrics and operational KPIs Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Candidate who is good in excel and MIS reports are looked at for these skillsPrepare management reports and analysis, both recurring and ad-hoc. It focuses on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nProficient in MS Office with advance knowledge in excel formulas. Ability to create Nice & User friendly excel dashboards. Ability to create meaningful presentation through PowerPoint. Working Knowledge in Power Automate, Power Apps, PowerBi Basic Automation abilities using VBA Macros Good Understanding of processes like (e.g., F&A, Marketing Operations, HR, Procurement and Supply Chain) Proficient in MS Office with advance knowledge in excel formulas. Ability to create Nice & User friendly excel dashboards. Ability to create meaningful presentation through PowerPoint. Working Knowledge in Power Automate, Power Apps, PowerBi Basic Automation abilities using VBA Macros Good Understanding of processes like (e.g., F&A, Marketing Operations, HR, Procurement and Supply Chain)\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Create and Design New Dashboard / Reports as required. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts. Connect with Stakeholders and drive governance around performance metrics. Play Individual Contributor or Manage a team dedicated for the assignment and drive performance.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business reporting', 'vlookup', 'reporting and analytics', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'business analysis', 'power bi', 'business analytics', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'powerapps', 'tableau', 'data visualization']",2025-06-13 05:33:44
Risk and Compliance Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Gurugram'],"Skill required: Risk & Compliance - Sarbanes-Oxley Act (SOX)\n\n\n\n\nDesignation: Risk and Compliance Senior Analyst\n\n\n\n\nQualifications:BE/BTech\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Risk and Compliance vertical and help us perform compliance reviews, publish reports with actions and provide closure guidance as needed. We design & recommend effective controls to mitigate risks and help service delivery team prepare for upcoming client / external audits.You will be working as a part of the Risk & compliance team which is responsible for helping clients and organizations identify risks and create mitigation plans.United States federal law that set new or expanded requirements for all U.S. public company boards, management and public accounting firms. Assist in implementation of client-designed Sarbanes-Oxley controls into client s financial processes, enterprise resource planning system or supporting technology.\n\n\n\n\nWhat are we looking for\nIn this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shiftsIn this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['risk compliance', 'aml', 'auditing', 'compliance analysis', 'sox', 'risk management', 'risk assessment', 'due diligence', 'data analysis', 'anti money laundering', 'investment banking', 'information security', 'business analysis', 'internal audit', 'it audit', 'kyc', 'it governance']",2025-06-13 05:33:46
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Navi Mumbai'],"Skill required: Delivery - Warranty Management\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDefine warranty offerings; run outsourced after-sales warranty support and entitlement programs; evaluate customer feedback and planned versus actual costs of warranty coverage; use warranty data analytics to reduce cost and improve product quality; increase recoveries from suppliers and design and deploy warranty solutions.\n\n\n\n\nWhat are we looking for\nAutomotive Warranty / Warranty Analytics Data Analysis Business Intelligence Business logic Scripting Reporting Commitment to quality Adaptable and flexible Agility for quick learning Ability to work well in a team Written and verbal communication Python (Programming Language)/ SQL/ ML\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['warranty management', 'python', 'data analytics', 'data analysis', 'sql', 'service operations', 'field service', 'customer service', 'business development', 'business intelligence', 'customer support', 'service engineering', 'after sales service', 'after market service']",2025-06-13 05:33:48
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Navi Mumbai'],"Skill required: Delivery - Warranty Management\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDefine warranty offerings; run outsourced after-sales warranty support and entitlement programs; evaluate customer feedback and planned versus actual costs of warranty coverage; use warranty data analytics to reduce cost and improve product quality; increase recoveries from suppliers and design and deploy warranty solutions.\n\n\n\n\nWhat are we looking for\nWarranty Analytics Automotive Warranty Scripting Data Analysis & Interpretation Business Intelligence Commitment to quality Adaptable and flexible Agility for quick learning Ability to work well in a team Written and verbal communication Data Engineering/SQL Databricks ML\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day-to-day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['warranty management', 'data analytics', 'data analysis', 'business intelligence', 'sql', 'hive', 'python', 'service operations', 'pyspark', 'data warehousing', 'microsoft azure', 'machine learning', 'data engineering', 'tableau', 'data science', 'data modeling', 'spark', 'hadoop', 'big data', 'aws', 'etl']",2025-06-13 05:33:49
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Gurugram'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nLanguage - Ability:English(International) - Proficient\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Implementation of gen. ledger processes including yearend closing, journalizing. Creating and maintaining ledgers, ledger currencies, budgets, and journal entries, design to deliver a financial management solution including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry and reporting as well as dynamic allocations and the management of commitments and expenditures also run Interface reports and perform close books of accounts.\n\n\n\n\nWhat are we looking for\nProblem-solving skillsAbility to perform under pressureStrong analytical skillsAbility to manage multiple stakeholdersThought leadership\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'business administration', 'record to report', 'macros', 'service operations', 'data analysis', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'budgeting', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:33:52
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Hyderabad'],"Skill required: Record To Report - Balance Sheet Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.\n\n\n\n\nWhat are we looking for\nInvolves balancing all balance sheet accounts against sub-ledger or other non-general ledger based source data to verify whether the balance sheet accounts are in balance with the source system feeding the general ledger. Differences which arise are addressed as reconciling items.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['balance sheet', 'journal entries', 'general ledger', 'business administration', 'record to report', 'macros', 'service operations', 'data analysis', 'forecasting', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:33:53
Campaign Management Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Campaign Management\n\n\n\n\nDesignation: Campaign Management Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe B2B Sales and Event Support Specialist will play a critical role in enhancing business-to-business interactions and promoting products within the oil and gas industry.Role requires - B2B Sales and event Support (project Manager)Understanding client requirements for multichannel Campaign/content and cascading tasks to content authors/art workers etc.\nManaging and triaging tickets to relevant teams as per agreed timelinesEnsuring Standards and Data Privacy Compliance for every CampaignMaintain high quality standards for the campaign delivery and ensure timelines are met with Quality Execute Projects in line with project management principles of Communication, Stakeholder management, Risk & Issue Management etc.Campaign Management focuses on planning, executing, tracking and analysis of direct marketing campaigns. The team is responsible for the entire lifecycle of a marketing campaign, from inception to launch to evaluation of result. The team is accountable for analyzing the effectiveness of marketing campaigns using ROI calculations. The role may require for you to have a good understanding of digital marketing, email marketing and technologies like Salesforce Marketing Cloud, Salesforce CRM, Salesforce Automation studio, Google DV360 and Responsys.\n\n\n\n\nWhat are we looking for\nB2B Sales TransformationEnsure Process, Metrics & Reporting compliance for every Campaign throughout the various stages of campaign journey & delivery.\nMultitasking with wide range of responsibilities, including the creation of sales collateral, coordinating training programs, managing product demonstrations, and providing event support. Possess strong organizational skills, creativity, and the ability to communicate effectively with various stakeholders to ensure the successful execution of sales and event initiatives.\nStrong written and verbal communication skills.\nExcellent organizational and project management abilities.\nProficiency in Microsoft office especially PowerPoint and any other presentation tools.\nBasic knowledge of content creation and design software (e.g., Adobe Creative Suite, Microsoft Office).\nExperience in coordinating events and training programs.\nAbility to work collaboratively with sales and marketing teams.\nStrong attention to detail and problem-solving skills.\nWorked on Project management tools like Workfront, Jira Service Now etcBasic knowledge of graphic design principles and tools.\nProficiency in virtual communication platforms (e.g., Zoom, Microsoft Teams).\nFamiliarity with customer relationship management (CRM) systems.\nExperience with data analysis and reporting tools (e.g., Microsoft Excel, Google Analytics) will be good to have skills.\nBachelors degree in Business, Marketing, Communications, or a related field preferred.\nPrevious experience in sales support, event management, or a similar role within the oil and gas industry is an asset.\n\n\n\nRoles and Responsibilities: Sales Support ServicesWork with the team to create engaging sales materials, including brochures, presentations, and case studies, aligned with branding guidelines.\nSchedule and manage logistics for training sessions; develop customized training materials based on feedback from sales teams.\nCollaborate with client organize and conduct product demonstrations, ensuring alignment with client needs and effective communication of product value.\nManage client communications with multiple stakeholders.\nEvents Support ServicesCollaborate with event agencies to ensure smooth execution of events, managing timelines, logistics, and stakeholder communications.\nWork with team to develop promotional materials and event-specific content, ensuring alignment with branding and event objectives as per client briefings.\nManage invitations, Pre-event communication with target audience, registrations, and follow-up communications, including feedback collection and reporting.\nUnderstanding of compliance and safety standards relevant to event management.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'project management', 'salesforce', 'salesforce crm', 'design principles', 'email marketing', 'adobe creative suite', 'google', 'campaign management', 'salesforce marketing cloud', 'marketing campaigns', 'campaigns', 'google analytics', 'automation studio', 'jira']",2025-06-13 05:33:55
Content Mgmt Advisory Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Hyderabad'],"Skill required: Marketing Operations - Content management\n\n\n\n\nDesignation: Content Mgmt Advisory Senior Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designOrganize, categorize and publish content and information using specific tools and channels, for use by different groups and individuals within the organization.\n\n\n\n\nWhat are we looking for\nCommitment to qualityProcess-orientationDetail orientationWritten and verbal communication - Strong writing and editing background, preferably with a portfolio of past work Experience in corporate communications and project management Experience with remote, cross-functional teams and communicating with shareholders Ability to analyze data that drives business decisions Excellent organization and communication skills, good at managing projects Proficiency with the Google suite a plus Ability to work in a fast-paced, deadline-driven environmentHigh school diploma required, Associates preferred. Will accept equivalent workexperience (2-3 years) in lieu of degree.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts Replicate/copy provided content, ensuring accurate transcription and duplication Create, edit and publish content for various topics, including strategy, organizationalmanagement, education and help center support Work closely with POCs and SMEs to formulate content relevant for the task/scope of theassignment Seeks opportunities to improve knowledge, skills, and performance by reviewingknowledge base content, practicing skills and being receptive to coaching andconstructive feedback Produce documents that convey strategy, status, reorganization, scope, timelines, taskplanning, action items, risks, issues, project dependencies, test planning, or rollout planning Monitor project performance and timelines, setting and meeting deadlines as necessary Maintain confidentiality of our partners content Able to function well with a team in a highly collaborative cross-functional environment, but still able to work as an individual contributor to track down answers to properlyformulate content Ability to think on your feet and adapt to changing circumstances and situations\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Content, Editorial & Journalism","Employment Type: Full Time, Permanent","['digital marketing', 'content management', 'editing', 'google suite', 'content analysis', 'data analysis', 'data analytics', 'mis reporting', 'dns', 'content editing', 'sql', 'creative writing', 'content development', 'tableau', 'active directory', 'advanced excel', 'content writing', 'dhcp']",2025-06-13 05:33:57
Project Analyst Senior,Qualcomm,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Area: Operations Group, Operations Group > Project Analyst\n\nGeneral Summary:\n\nJob OverviewQualcomm Customer Engineering team is seeking a highly organized, self-motivated problem solver with exceptional communication skills and expertise as a Salesforce Service Cloud Specialist. The ideal candidate will have\n\nSalesforce administrative experience with\n\na strong knowledge of standard (out-of-the-box) Salesforce administrative functions and features, including but not limited to\n\nreports/dashboards, case assignments, validations, and profiles/permissions sets. This individual will work closely with Operations, Administrators, Customer Engineering, and IT Development teams to\n\nsupport, organize, prioritize, manage and deliver\n\na large variety of support requests and issues by leveraging established processes, solutions, or features and escalating/driving improvements when necessary. This role requires the\n\nability to\n\nextract business needs,\n\nidentify and promote existing solutions/workarounds,\n\nconnect stakeholders, discover answers or data, assess impact,\n\ncollect requirements, write and define user stories, perform user acceptance testing, write/update user trainings,\n\nand promote user adoption of new solutions. Salesforce Admin, Business Analys, and/or Advanced Admin certification is preferred.\n\nResponsibilities include:\nUtilize\n\nbroad knowledge of Salesforce Service Cloud to support internal and external customers as well as the company's programs\n\nthough standard and available custom features.\nCollaborate with Data and Business Analysts, System Administrators, Development teams, and Customer Engineers to\n\ncollect, interpret, analyze, and document use, functional, and technical requirements for new projects and enhancements.\nMust\n\ntriage and share solutions/workarounds/status updates for known system issues, compile and prioritize new issues, and test/QA delivered solutions.\nEnsures\n\neffective\n\nprocessing of internal stakeholder support tickets submitted through JIRA by internal users for support on case team management, customer role/profile changes, attachment visibility, tools licensing, general tech support and use of the system(s), system downtime and case assignment corrections/redirections.\n\n\nBackup of administrative business operations around case support entitlement for contractually licensed customers, case assignment rule and queue, reports and dashboards, and other administratively controlled operational functions.\nEnabling users and supporting business needs through profile changes,\n\nreports type creation, validation analysis, sharing rules evaluation, and\n\nrecord/values configurations.\nExperience with Data Load, Import Wizard, and/or Workbench\n\nfor database management tasks, including defining, preparing, and executing data corrections and alignment tasks.\nCreate and execute user guides and process documentation for end users.\nWork with internal stakeholders (CE team, Finance, Engineering, Sales, etc.) to gather requirements, support, and\n\ndevelop functional work statements as needed.\nExcellent\n\norganizational, prioritization, and time management skills.\nDemonstrate a strong work ethic and ready to execute best practices for supporting the business.\nCustomer support experience maintaining, triaging, and troubleshooting existing programmatic integrations with internal and external systems.\n\nRequired if we take up Case API, otherwise not necessary\nStrong communication abilities and soft skills like organization are essential- Must be capable of addressing a diverse range of audiences.\n\n\nMinimum Qualifications:\n2+ years relevant work experience on Salesforce Lightning administration\nBachelor in one of the following or equivalent experience Business Administration, Business Operations, Data Analysis, Communication or Information Systems, or related field\nExpert level knowledge in MS Excel (current versions) and MS PowerPoint\n\n\nPreferred Qualifications:\nMaster's in Business Administration, Business Operations, Computer Science, Information Systems, or related field\nSalesforce\n\nCertified Administrator, Advanced Administrator, or Business Analyst\nExperience using, interacting and supporting established API or programmatic integrations\n\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Management, Computer Science, Engineering, Computer Science, or related field.\nOR\nHigh School Diploma or equivalent and 2+ years of relevant work experience.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['salesforce lightning', 'prioritization', 'salesforce', 'data loader', 'salesforce service cloud', 'visualforce', 'data analysis', 'import wizard', 'sfdc', 'business analysis', 'triggers', 'javascript', 'apex', 'sales force development', 'salesforce crm', 'project analysis']",2025-06-13 05:33:59
"Systems Analyst, Senior",Qualcomm,3 - 8 years,Not Disclosed,['Hyderabad'],"Job Area: Information Technology Group, Information Technology Group > Systems Analysis\n\nGeneral Summary:\n\nWe are seeking a Systems Analyst,Senior to join our growing organization with specialized skills in IBM Planning Analytics/TM1 and functional understanding of Finance budgeting and forecasting. This role involves advanced development, troubleshooting, and implementation of TM1 solutions to meet complex business requirements.The person will be part of Finance Planning and reporting team and will primarily work closely with his/her manager and will be helping in delivering TM1 planning and budgeting roadmap for the global stakeholders.Key Responsibilities:\nAble to design and develop IBM Planning Analytics(TM1) solutions as per standards. Able to write logical, complex, concise, efficient, and well-documented code for both TM1 rules and Turbo Integrator processes. Good to have knowledge of Python and TM1py libraries.\nAble to write business requirement specifications, define level of efforts for Projects/Enhancements and should design and coordinate system tests to ensure solutions meet business requirements\nSQL skills to be able to work with source data and understand source data structures. Good understanding of the SQL and ability to write complex queries.\nUnderstanding cloud technologies especially AWS and Databricks will be an added advantage.\nExperience in client reporting and dashboard tools like Tableau, PA Web,PAFE.\nUnderstanding of ETL processes and data manipulation\nWorking independently with little supervision\nTaking responsibility for own work and making decisions that are moderate in impact; errors may have financial impact or effect on projects, operations, or customer relationships; errors may require involvement beyond immediate work group to correct.\nShould provide ongoing system support, including troubleshooting and resolving issues to ensure optimal system performance and reliability\nUsing verbal and written communication skills to convey information that may be complex to others who may have limited knowledge of the subject in question\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or incomplete; intermediate data analysis/interpretation skills may be required.\nExercising substantial creativity to innovate new processes, procedures, or work products within guidelines or to achieve established objectives.\n\nMinimum Qualifications:\n3+ years of IT-relevant work experience with a Bachelor's degree.\nOR\n5+ years of IT-relevant work experience without a Bachelors degree.\nQualifications:The ideal candidate will have 8-10 years of experience in designing, modeling, and developing enterprise performance management (EPM) applications using IBM Planning Analytics (TM1).Able to design and develop IBM Planning Analytics(TM1) solutions as per standards. Able to write logical, complex, concise, efficient, and well-documented code for both TM1 rules and Turbo Integrator processes.Lead the design, modeling, and development of TM1 applications, including TI scripting, MDX, rules, feeders, and performance tuning.Should able to provide technical expertise in identifying, evaluating, and developing systems and procedures that are efficient, cost effective and meet user requirements.Plans and executes unit, integration and acceptance testingMust be a good team player who can work seamlessly with Global teams and Data teamsExcellent communication and collaboration skills to work with business stakeholdersHaving functional understanding of Finance budgeting and forecasting\n\nUnderstanding cloud technologies especially AWS and Databricks will be an added advantageExperience in Agile methodologies and JIRA user storiesAble to design and develop solutions using python as per standards\n\nwe are seeking a Systems Analyst,Senior to join our growing organization with specialized skills in IBM Planning Analytics/TM1 and functional understanding of Finance budgeting and forecasting.The person will be part of Finance Planning and reporting te\n\nRequired bachelors or masters degree in information science, computer science, business, or equivalent work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'sql', 'tableau', 'enterprise performance management', 'etl', 'rest', 'data analysis', 'performance tuning', 'cloud technologies', 'data bricks', 'system analysis', 'planning analytics', 'computer science', 'tm', 'troubleshooting', 'data structures', 'agile', 'aws', 'jira', 'agile methodology']",2025-06-13 05:34:01
Senior Analyst - Direct Display,Merkle B2b,2 - 8 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-13 05:34:02
"Sr. Functional App Analyst, FOAA",Amazon,10 - 15 years,Not Disclosed,['Pune'],"Amazons Finance Operations, Accounting & Analysis (FOAA) team is a fast-paced, team-focused, dynamic environment and delivering great experiences for our customers is top priority. FOAA is seeking a Functional App Analyst to support our Accounting Onboarding team.\n\nThe Functional App Analyst will partner with the Accounting Onboarding team (based in the US) to support various Amazon businesses to launch their products and services by automating their accounting use cases. This is an exciting opportunity to join fast-paced businesses at Amazon. The successful candidate will be strategic, analytical, and have a demonstrated ability to support financial systems and architecture. The successful candidate will be comfortable working in cross-functional teams, and demonstrate strong leadership skills.\n\nThe Functional App Analyst manager will independently manage a team of Functional Analysts, establish structures that enable their team to deliver on projects. Partner with customers, team members, and other teams on what projects move forward and in what priority order. A successful candidate will track team level activities in terms of customer engagement, adherence to SLAs, and execution of projects and programs, customer roadmaps and successfully deliver projects that executes that vision of the org.\n\nThe ideal candidate must have superior attention to detail and the ability to manage multiple competing priorities. The position represents an exciting opportunity to be a part of an extremely dynamic and high -paced environment, support a global organization and work with accounting and business teams. The role offers significant opportunities for rapid growth and is a great place to learn about various businesses at Amazon.\n\n\n-Build relationships with stakeholders, earn trust through transparency and alignment.\n-Dive deep into our customers business to understand pain points and future needs.\n-Lead an existing team of Functional App Analyst and System Analysts.\n-Partner with stakeholders to define strategy and roadmaps for the strategic areas your team owns.\n-Represent verbally and in writing complex decisions, tough trade-offs, and potential solutions clearly to leaders up to 2 levels above.\n-Understand system capabilities in order to deliver IT solutions to business users across Amazon.\n-Advise the customers on the financial integration architecture.\n-Acquire deep understanding of one or more lines of businesses and system integration and data flows.\n-Must have a strong knowledge of an application s functionality. They know what functionality is available in their system and how to configure it to work for business processes\n-Help customers author and release accounting configurations using home grown business configuration management solutions.\n-Troubleshoot integration issues by partnering with internal technical teams across the orgs.\n-Work very closely with the technical teams across Amazons lines of businesses to come up with innovative solutions that will accelerate the adoption of technology used for Financial Reporting and reconciliation.\n-Work independently to manage projects and support Amazons global businesses and development teams in the design and implementation of accounting systems.\n-Provide project management update within and across business units to transition new processes and/or permanent solutions to support the Amazon accounting team.\n-Coordinate with the global accounting teams to establish and maintain strong communication channels.\n-Identify, implement, and adhere to best practices across all new project launches -Offering and receiving coaching, support, and guidance to the team.\n-Supporting in User Acceptance Testing (UATs) in close co-ordination with business and accounting teams.\n-Provide inputs for monthly and quarterly business reviews in a timely manner.\n-Facilitate the business reviews with data analysis and follow through with business leaders on actionable items for improving business metrics over a period of time.\n-Measuring and monitoring of metrics for new business initiatives.\n-Present recommendations to senior management on strategic decisions, and planned future initiatives.\n-Demonstrate appropriate understanding / working knowledge of accounting principles and internal controls, and apply them.\n-Ensure appropriate financial policies, procedures, and internal controls are in place, documented, and operating as intended.\n-Drive process improvements required to enhance controls.\n-Actively participate in strategic initiatives and special projects when assigned or required.\n\nA day in the life\nPrioritization, Resource Planning and Stakeholder Management.\n\nGathering requirements from various Amazon businesses integrating with financial automation tools.\n\nCollaborate with engineering teams to come up with optimal solutions for accounting automation.\n\nWork on code review and config review process by following the guidelines.\n\nParticipate in UAT and guide internal customers with troubleshooting.\n\nWork on deployments to production after acquiring UAT sign-off from stakeholders.\n\nAbout the team\nAmazons Finance Operations, Accounting & Analysis (FOAA) team is a fast-paced, team-focused, dynamic environment and delivering great experiences for our customers is top priority. FOAA is seeking a Finance Analyst to support our Accounting Onboarding team. 10+ years of relevant experience in identifying, leading, and executing opportunities to improve, automate, standardize or simplify finance or business tools and processes experience\n5+ years of experience of working in Financial Services implementing solutions.\nHands on experience in ERP implementation along with understanding of modules like GL, AP, AR, CM, FA, Expenses, PPM etc.\nAct as liaison between customers and engineering teams.\nAbility to understand complex business flows and break them into use cases\nExperience using data to influence business decisions\nExcellent verbal and written communication. Good interpersonal skills\nStrong Project Management skills\n-Experience working with large-scale data reporting tools (examples: SQL, MS Access, Essbase, Cognos) and other financial systems (examples: Oracle, PeopleSoft, SAP, Lawson, JD Edwards)\nExperience in a technical consulting or techno-functional consulting role in a customer centric, fast-moving environment.\nProven ability to develop new ideas and creative solutions\nProven ability to work successfully in an ambiguous environment\nProven ability to meet tight deadlines and prioritize workload\nAbility to work in cross-functional teams\nCustomer focus and professional demeanor",,,,"['Data analysis', 'SAP', 'MS Access', 'Cognos', 'Configuration management', 'Consulting', 'PeopleSoft', 'JD Edwards', 'Oracle', 'SQL']",2025-06-13 05:34:04
Senior Analyst - Direct Display,Merkle Science,1 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-13 05:34:06
Lead Business analyst,Glance,3 - 5 years,Not Disclosed,['Bengaluru'],"What will you be doing?\nWe are seeking a motivated and detail-oriented Junior Business Analyst to join our dynamic team. In this entry-level role, you will work closely with senior analysts, project managers, and various departments to support the analysis of business processes, gather requirements, and assist in data-driven decision-making. This position is ideal for someone eager to grow their career in business analysis and contribute to the development of solutions that drive business improvement.\nKey Responsibilities:\nRequirements Gathering: Assist in the collection and documentation of business requirements from stakeholders across various departments.\nData Analysis: Analyse business data, generate reports, and identify trends or insights to support business decisions.\nProcess Mapping: Collaborate with senior analysts to create process flow diagrams, identifying opportunities for process improvement.\nStakeholder Communication: Support communication between business teams, technical teams, and other stakeholders to ensure alignment and understanding of project goals.\nDocumentation: Help produce clear and concise documentation for business requirements, user stories, and process workflows.\nTesting Support: Assist in the preparation and execution of user acceptance testing (UAT) to ensure that solutions meet business needs and requirements.\nContinuous Improvement: Assist in the evaluation and improvement of current business processes, providing recommendations for optimization.\nSupport Project Deliverables: Contribute to project deliverables, ensuring timely and accurate completion of assigned tasks.\nWhat are we looking for?\nEducation: Bachelor s degree in business administration, Information Technology, or a related field (or equivalent work experience).\nExperience: 3-5 years of experience in business analysis, data analysis, or a related field\nTechnical Skills:\nProficient in Microsoft Office Suite (Excel, Word, PowerPoint).\nProficient with data analysis tools (Excel, SQL, etc.) and business intelligence software is a plus.\nIntermediate understanding of process modelling or flowcharting tools.\nKey Competencies:\nStrong analytical and problem-solving skills.\nExcellent communication skills (both written and verbal).\nAbility to work collaboratively within a team and with cross-functional stakeholders.\nDetail-oriented with strong organizational skills.\nQuick learner with a passion for business analysis and technology.\nAbility to prioritize and manage multiple tasks in a fast-paced environment.\n""",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business improvement', 'Data analysis', 'Business analysis', 'Process improvement', 'Analytical', 'Business intelligence', 'Continuous improvement', 'Gaming', 'Information technology', 'SQL']",2025-06-13 05:34:07
Business Analyst,Kuku Fm,1 - 3 years,Not Disclosed,['Bengaluru'],"About the Role\nWe are looking for a data-driven Business Analyst to join our high-impact team. As a key enabler of data-backed decisions, you will work closely with cross-functional stakeholders product, marketing, operations, and leadership to drive insights and strategic initiatives in a fast-paced tech environment. This role demands strong analytical capabilities, an ownership mindset, and the ability to translate complex data into actionable business recommendations.\nResponsibilities:\nClosely work with business leaders and founders office to discover insights and solve high-impact problems across business verticals using data.\nLead day-to-day analysis requirements and present insights in a structured form.\nBe on top of data to help develop actionable insights from weekly / monthly business performance reviews.\nCollaborate across different teams to reach the root of a problem/insight.\nLeverage multiple sources of information (primary data analysis, qualitative research, etc.) to generate deeper insights.\nDesign, run and measure experiments to test the business hypotheses in collaboration with Product and Engineering teams.\nMonitor and forecast key business metrics regularly.\nRequirements:\nYou have 1-3 years of experience in high-growth tech startups, management consulting, PE/VC funds.\nYou have hands-on experience of using SQL on a daily basis to extract data and are comfortable with excel.\nYou have hands-on experience in building dashboards on visualization platforms like Tableau, Power BI, periscope data, cluvio etc.\nBreathe data and have exceptional problem-solving and presentation skills.\nPreferably have some basic knowledge of python / R (not a deal-breaker).\n\nWhy Join Us?\nOpportunity to work in a fast-growing audio and content platform.\nExposure to multi-language marketing and global user base strategies.\nA collaborative work environment with a data-driven and innovative approach.\nCompetitive salary and growth opportunities in marketing and growth strategy.\nAbout KUKU\nFounded in 2018, KUKU is India s leading storytelling platform, offering a vast digital library of audio stories, short courses, and microdramas. KUKU aims to be India s largest cultural exporter of stories, culture and history to the world with a firm belief in Create In India, Create For The World .\nWe deliver immersive entertainment and education through our OTT platforms: Kuku FM, Guru, Kuku TV, and more. With a mission to provide high-quality, personalized stories across genres from entertainment across multiple formats and languages, KUKU continues to push boundaries and redefine India s entertainment industry.\nWebsite: www.kukufm.com\nAndroid App: Google Play\niOS App: App Store\nLinkedIn: KUKU\nReady to make an impact? Apply now!",Industry Type: Film / Music / Entertainment,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Qualitative research', 'Data analysis', 'Analytical', 'Management consulting', 'IOS app', 'Marketing operations', 'Product marketing', 'SQL', 'Android', 'Python']",2025-06-13 05:34:09
Technical Business Analyst,Holiday Inn Club Vacations,4 - 9 years,Not Disclosed,['Bengaluru'],"At Holiday Inn Club Vacations, we believe in strengthening families. And we look for people who exhibit the courage, caring and creativity to help us become the most loved brand in family travel. Were committed to growing our people, memberships, resorts, and guest love. Thats why we need individuals who are passionate in life and bring those qualities to work every day. Do you instill confidence, trust, and respect in those around you? Do you encourage success and build relationships? If so, were looking for you.\n\nPOSITION DESCRIPTION:\nWe are seeking a results-driven Technical Business Analyst with deep domain expertise in timeshare products, a strong technical foundation in SQL Server, experience with Salesforce CRM, and a solid understanding of API integrations. The ideal candidate will serve as the bridge between business stakeholders and development teams, enabling scalable and efficient solutions across systems in the vacation ownership lifecycle.\nOther responsibilities include assisting with complex operational and support concerns, ensuring alignment with development best practices and Agile/Scrum methodologies. The position requires a hands-on approach to resolving critical system issues, helping the team enhance their understanding of processes and software system challenges, and setting or adjusting team norms and SLAs.\n\nESSENTIAL DUTIES AND TASKS:\nAnalyze, document, and communicate business and functional requirements for enhancements and integrations related to timeshare products, including property management systems (PMS), reservations, owner portals, and inventory management.\nCollaborate with cross-functional teams to design and implement seamless Salesforce CRM integrations with internal systems and third-party platforms.\nUse SQL Server to perform data analysis, create queries and validate data integrity across systems.\nDesign and document API requirements, including payload structures, authentication, data mapping, and error handling.\nPartner with development and QA teams to ensure technical solutions align with business goals and maintain system reliability.\nSupport system integration efforts including testing, troubleshooting, & deployment of features & APIs.\nCreate user stories, process flows, data models, and integration diagrams to support technical specifications.\nParticipate in Agile ceremonies and help prioritize features based on business impact and technical complexity.\nContribute to architectural decisions and participate in code and design reviews.\nTroubleshoot, debug, and resolve issues in both development and production environments.\nContribute to improving team efficiency, development processes, and overall software quality.\nPROFESSIONAL SKILLSET QUALIFICATIONS\nBachelors degree in Information Technology, Business Analysis, Computer Science, or related field.\n5+ years of experience as a Technical Business Analyst, with at least 2 years in the timeshare or vacation ownership industry.\nStrong understanding of SQL Server and data analysis best practices.\nHands-on experience with Salesforce CRM, including objects, workflows, and custom integrations.\nWorking knowledge of RESTful APIs, including reading/writing API specs, JSON payloads, and integration testing tools (e.g., Postman).\nExperience in system integration projects, including third-party tools (e.g., booking engines, payment gateways, or marketing platforms).\nStrong documentation skills: user stories, BRDs, FRDs, use cases, sequence diagrams.\nFamiliarity with Agile/Scrum methodologies and tools like ServiceNow and Azure DevOps.\n\nSOFT SKILLS\nStrong analytical and problem-solving mindset.\nExcellent verbal and written communication skills.\nAbility to prioritize tasks and manage multiple projects in a fast-paced environment.\nTeam player with a proactive attitude and a high attention to detail.",Industry Type: Travel & Tourism,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Api Integration', 'Third Party Integration', 'Salesforce CRM', 'Scrum Agile Development Methodology', 'Documentation', 'SQL Server', 'Salesforce']",2025-06-13 05:34:11
Business Analyst - Configuration Management,Moodys Investors Service,3 - 8 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: Technology Services Group(TSG)\nJob Category:\nEngineering & Technology\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nPosition Overview\nWe are looking for a skilled Configuration Management Data Analyst with expertise in ServiceNow to manage, analyze, and optimize configuration data across our organization. The ideal candidate will play a critical role in maintaining the accuracy and integrity of our Configuration Management within ServiceNow, ensuring alignment with ITIL best practices and supporting business decision-making. This role requires a strong background in ServiceNow, analytical capabilities, and a collaborative approach to working with cross-functional teams.\nKey Responsibilities\n1. Configuration Management Administration and Maintenance\no Maintain and enhance the ServiceNow CMDB to ensure data accuracy, completeness, and compliance with organizational standards.\no Regularly audit configuration data to identify inconsistencies, address gaps, and enforce data governance policies.\no Design and implement automated workflows within ServiceNow to streamline data updates and ensure real-time accuracy.\n2. Data Analysis and Reporting\no Analyze configuration data stored in ServiceNow to identify trends, risks, and opportunities for optimization.\no Create and maintain dashboards, reports, and KPIs within ServiceNow to provide actionable insights to stakeholders.\no Provide data-driven recommendations to improve IT infrastructure and configuration management processes.\n3. Collaboration and Process Improvement\no Work closely with IT, operations, and engineering teams to ensure the proper integration of configuration management processes with business objectives.\no Act as a subject matter expert for CMDB best practices and ServiceNow capabilities, providing training and support to teams as needed.\n4. ServiceNow Development and Optimization\no Collaborate with ServiceNow developers to customize CMDB modules, workflows, and scripts based on organizational needs.\no Stay up-to-date with ServiceNow platform updates, features, and releases to identify opportunities for improved functionality.\no Troubleshoot and resolve technical issues related to ServiceNow CMDB operations.\nExperience and Qualification\n* 3+ years of experience in configuration management, data analysis, or CMDB administration, preferably in financial services.\n* Hands-on experience with ServiceNow, including CMDB module administration and customization.\n* Strong understanding of ITIL principles, particularly Configuration Management.\n* Proficiency in creating dashboards, reports, and workflows within ServiceNow.\n* Bachelor s degree in Information Technology, Computer Science, or a related field.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Configuration management', 'Analytical', 'Process improvement', 'data governance', 'IT operations', 'Information technology', 'Financial services', 'Auditing']",2025-06-13 05:34:13
Business Analyst Capital Markets / Fund Accounting,Pro Integrate,10 - 12 years,Not Disclosed,['Bengaluru'],"Job Title: Business Analyst Capital Markets / Fund Accounting\n\nLocation: Bangalore (Hybrid Model)\n\nShift Timing: UK Shift Hours\n\nExperience: 10 12 Years\n\nNotice Period: Immediate to 15 Days Only\n\nIndustry: BFSI / Investment Banking / Capital Markets\n\nEducation: MBA (Finance) Premier Institutes Only\n\nJob Description\n\nWe are looking for a Business Analyst with a strong foundation in software development and deep domain expertise in Capital Markets, Fund Accounting, and Investment Banking. The ideal candidate will be a former developer who has transitioned into a Business Analyst role and brings a unique combination of technical and functional expertise.\n\nKey Responsibilities\n\nAct as a bridge between business and technology teams\nTranslate business requirements into functional specifications\nAnalyze data using SQL and prepare insights for financial reporting\nCollaborate with global stakeholders in Agile delivery environments\nEnsure high-quality documentation and deliverables\nManage multiple priorities with a strong focus on accuracy and detail\nMust-Have Skills\n\nCareer Path: Started as a software developer (Java, .NET, SQL, PL/SQL) and transitioned to Business Analyst\nDomain Expertise:\nCapital Markets (Mandatory)\nFund Accounting & Reporting (Mandatory)\nOTC Derivatives / Investment Banking (Preferred)\nPrivate Equity / Private Credit (Nice to have)\nTechnical Skills:\nSQL for data analysis\nAgile ALM tools: JIRA, Rally, Azure Boards\nExperience working in Agile, distributed teams\nSoft Skills:\nExcellent communication (verbal & written)\nStrong stakeholder management and client interaction\nDetail-oriented with a focus on financial reporting accuracy\nOther Details\n\nJob Type: Full-Time / Permanent\nWork Model: Hybrid (Bangalore-based)\nShift: UK Hours\nNotice Period: Immediate to 15 days only\nApply Now if you meet the above criteria and are ready to make an immediate impact!",Industry Type: Analytics / KPO / Research,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Capital Markets', 'Business Analysis', 'Java', 'Financial Reporting', 'Investment Banking', 'Business Analyst', 'Fund Accounting', 'JIRA', 'SDLC', 'SQL', 'Private Equity', 'Client Communication', 'Azure Boards', 'Otc Derivatives', 'Agile', 'Data Analysis', 'PLSQL', '.Net', 'Private Credit', 'Rally', 'STLC', 'Stakeholder Management']",2025-06-13 05:34:15
Full Stack Performance Analyst,IBM,5 - 10 years,Not Disclosed,['Bengaluru'],"As a Full Stack Performance Analyst your responsibilities would be\n\n1. Study workloads characteristics on IBM Power and x86\n\n2. Executing & measuring performance of various PowerVM (Hypervisor) functions & features\n\n3. Using various performance tools to analyze performance & identify bottlenecks / opportunities for improving PowerVM (Hypervisor) stack/functions performance\n\n4. Provide tuning & performance optimizations suggestion to improve performance\n\n5. Working on client performance issues\n\n\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\n5-15 years of overall IT experience.\n3+ years of experience as a System Performance Analyst\n5+ Experience with OS internals, hands on debugging\nExperience doing Performance Analysis, Performance Tuning & Performance Optimization\nGood Knowledge & Experience in using Performance Monitoring Tools like vmstat, netstat, iostat, nmon, topas etc\nGood Knowledge & Experience in C/C++ programming\nGood understanding of Hypervisor & Virtualization concepts\nGood understanding of Virtual IO concepts\nGood understanding of System Architecutre\nGood understanding of Operating System concepts\nGood communication & presentation skills.\n\n\n\n\nPreferred technical and professional experience\n\n\n\n\nDemonstrated application of machine-learning or AI technologies to data analysis\nAgile/ Scrum methodology experience",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analysis', 'os internals', 'ai techniques', 'scrum', 'agile', 'load runner', 'c++', 'c', 'performance tuning', 'performance testing', 'hp performance center', 'presentation skills', 'dynatrace', 'neoload', 'nmon', 'jmeter', 'hypervisor', 'performance center', 'debugging', 'performance analysis']",2025-06-13 05:34:17
S&C Global Network - AI - Auto & Industrial - Analyst,Accenture,1 - 3 years,Not Disclosed,['Bengaluru'],"Management Level:Ind & Func AI Decision Science Analyst\n\n\n\nLocation:Bengaluru (Bangalore), Gurugram (Gurgaon), Hyderabad, Chennai.\n\n\n\nMust-have skills:Programming languages -Python/R, Generative AI, Large Language Models (LLMs), ML libraries such as Scikit-learn, TensorFlow, Torch, Lang Chain, or OpenAI API, RAG Applications.\n\n\n\n\nGood to have skills:Big data technologies such as Spark or Hadoop,AI model explainability(XAI),bias detection and AI ethics. Familiarity with Edge AI and deploying models on embedded devices for industrial automation. Experience with Reinforcement Learning (RL) and AI-driven optimization techniques.\n\n\n\nJob\n\n\nSummary\n\nWe are looking for a Data Scientist / AI Specialist with 1-3 years of experience to join our team and work on client projects in the Automotive & Industrial sectors. This role will involve leveraging traditional Machine Learning (ML), Generative AI (GenAI), Agentic AI, and Autonomous AI Systems to drive innovation, optimize processes, and enhance decision-making in complex industrial environments.\n\nPrior experience in the Auto/Industrial industry is a plus, but we welcome candidates from any domain with a strong analytical mindset and a passion for applying AI to real-world business challenges.\n\n\n\n\nRoles & Responsibilities:\nDevelop, deploy and monitor AI/ML models in production environments & enterprise systems, including predictive analytics, anomaly detection, and process optimization for clients.\nWork with Generative AI models (e.g., GPT, Stable Diffusion, DALLE) for applications such as content generation, automated documentation, code synthesis, and intelligent assistants.\nImplement Agentic AI systems, including AI-powered automation, self-learning agents, and decision-support systems for industrial applications.\nDesign and build Autonomous AI solutions for tasks like predictive maintenance, supply chain optimization, and robotic process automation (RPA).\nWork with structured and unstructured data from various sources, including IoT sensors, manufacturing logs, and customer interactions.\nOptimize and fine-tune LLMs (Large Language Models) for specific business applications, ensuring ethical and explainable AI use.\nUtilize MOps and AI orchestration tools to streamline model deployment, monitoring, and retraining cycles.\nCollaborate with cross-functional teams, including engineers, business analysts, and domain experts, to align AI solutions with business objectives.\nStay updated with cutting-edge AI research in Generative AI, Autonomous AI, and Multi-Agent Systems.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n1-3 years of experience in Data Science, Machine Learning, or AI-related roles.\nProficiency in Python (preferred) or R, and experience with ML libraries such as Scikit-learn, TensorFlow, Torch, Lang Chain, or OpenAI API.\nStrong understanding of Generative AI, Large Language Models (LLMs), and their practical applications.\nHands-on experience in fine-tuning and deploying foundation models (e.g., OpenAI, Llama, Claude, Gemini, etc.).\nExperience with Vector Databases (e.g., FAISS, Chroma, Weaviate, Pinecone) for retrieval-augmented generation (RAG) applications.\nKnowledge of Autonomous AI Agents (e.g., AutoGPT, BabyAGI) and multi-agent orchestration frameworks.\nExperience working with SQL and NoSQL databases.\nFamiliarity with cloud platforms (AWS, Azure, or GCP) for AI/ML model deployment.\nStrong problem-solving and analytical thinking abilities.\nAbility to communicate complex AI concepts to technical and non-technical stakeholders.\nBonus:Experience in Automotive, Industrial, or Manufacturing AI applications (e.g., predictive maintenance, quality inspection, digital twins).\n\n\n\n\nAdditional Information:\nBachelor/Masters degree in Statistics/Economics/ Mathematics/ Computer Science or related disciplines with an excellent academic record /MBA from top-tier universities.\nExcellent Communication and Interpersonal Skills.\n\n\n\n\n\nAbout Our Company | Accenture\n\n\n\n\n\nQualification\n\n\n\nExperience:Minimum 1-3 years of relevant Data Science, Machine Learning or AI-related roles., Exposure to Industrial & Automotive Firms or Professional Services.\n\n\n\n\nEducational Qualification: Bachelor/Masters degree in Statistics/Economics/ Mathematics/ Computer Science or related disciplines with an excellent academic record or MBA from top-tier universities.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'sql', 'tensorflow', 'data science', 'image processing', 'c++', 'scikit-learn', 'microsoft azure', 'artificial intelligence', 'nosql', 'deep learning', 'r', 'spark', 'gcp', 'computer vision', 'network analysis', 'hadoop', 'api', 'big data', 'aws', 'opencv']",2025-06-13 05:34:19
I&F Decision Sci Practitioner Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Delivery - Sprinklr\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIA social media management tool for enterprises. It provides social media marketing, social advertising, content management, collaboration, advocacy and social media monitoring for large enterprises.\n\n\n\n\nWhat are we looking for\nSprinklr Social Media Monitoring & Analytics Adaptable and flexible Written and verbal communication Ability to work well in a team Agility for quick learning Commitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day-to-day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['digital marketing', 'service operations', 'content management', 'sprinklr', 'seo', 'python', 'adobe analytics', 'data analysis', 'google adwords', 'power bi', 'social listening', 'radian6', 'sql', 'twitter', 'tableau', 'web analytics', 'social media marketing', 'google analytics', 'brandwatch']",2025-06-13 05:34:21
GN - SONG - Service - CX - Value Architect - Analyst,Accenture,2 - 5 years,Not Disclosed,['Bengaluru'],"Template\n\nJob Title - GN - SONG - Service - CX - Value Architect - Analyst\n\nManagement Level :11 - Analyst\n\nLocation:Delhi, Gurgaon, Mumbai, Bangalore, Chennai, Pune, Hyderabad\n\nMust have skills:Value Realization\n\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute\n\nJob\n\n\nSummaryAs part of the team, you will provide transformation services driven by key offerings like Living Marketing, Connected Commerce and Advanced Customer Engagement. These services help our clients become living businesses by optimizing their marketing, sales and customer service strategy, thereby driving cost reduction, revenue enhancement, customer satisfaction and impacting front end business metrics in a positive manner.\nRoles & ResponsibilitiesTranslate strategic objectives into high-impact use cases in the specific area of expertise.\nUnderstand clients business priorities and focus areas to identify the right business scenarios and impacted value levers (KPIs) to include in the business case.\nIdeate and execute on compelling value creation workshops.\nConduct detailed qualitative and quantitative research to lay the foundation of a strong business case.\nOwn every stage of the value creation process, from research and identification to value drafting and dashboarding.\nDefine value architecting requirements and work with Accenture teams to deliver solutions.\nAdvise clients on industry best practices (when appropriate).\nAccurately estimate time to complete work.\nContinually experiment with new tools, technologies and sharpen analytical skills.\nAbility to research and provide strategic, goal-driven solutions for clients.\nCollaborate with other value architects, both offshore & onshore, including client-side managers, business heads, and other stakeholders across the organization.\nProvide useful contributions to team meetings and conversations, actively participating in client meetings and workshops- Ability to create hypothesis based on understanding of clients issues.\nProfessional & Technical\n\n\n\n\nSkills:\nApply best of breed Excel practices- Deep-dive with solid knowledge of formulas & macros to bring in speed & efficiency.\nMaximize experience in developing interactive models:Use relevant dashboard creation platforms (Power BI, Tableau, etc.) to design and apply interactive dashboards.\nInnovate with Creativity:Demonstrate an ability to work in a fast-paced environment with the ability to abstract value into compelling business story.\nParticipate in pre-sales activities including response to RFPs, creating proofs of concept, creating effective presentations, demonstrating solutions during client orals, effort and cost estimation process, etc.\nParticipate in practice-specific initiatives including creating points of view, creating reusable assets on contact center space, performing analysis on industry research and market trends and bringing in innovative solutions, etc.\nAdditional InformationGood understanding of sales, service & marketing as a function\nSolid experience in developing quantitative models.\nConducting qualitative & quantitative research\nAnchoring client/senior stakeholder conversations\nCreating engaging storyboards using the best data visualization tools such as Power BI, Tableau, etc.\n\nAbout Our Company | AccentureQualification\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ssas', 'bi', 'power bi', 'sql', 'tableau', 'python', 'data analysis', 'oracle', 'data warehousing', 'pivot table', 'microsoft azure', 'business analysis', 'vlookup', 't-sql', 'business intelligence', 'sql server', 'plsql', 'data modeling', 'advanced excel', 'ssrs', 'data visualization', 'ssis', 'etl', 'msbi']",2025-06-13 05:34:23
GN - SONG - Design and Digital Products - UI/UX - Analyst,Accenture,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Title:GN - SONG - Design and Digital Products - UI/UX - Analyst\n\n\n\nManagement Level:11 Analyst\n\n\n\nLocation:Bangalore, Gurgaon, Hyderabad\n\n\n\nMust have skills:UX/UI Design, Figma, Sketch\n\n\n\n\nGood to have skills:Video editing tools, Motion design\n\n\n\nExperience:Minimum 4 years of experience is required .\n\n\n\n\nRoles & Responsibilities:\nCollaborate with product managers and stakeholders to gather and refine user requirements.\nConduct user studies, benchmark best practices, and create personas through research and data analysis.\nCreate wireframes, user flows, flow diagrams, and storyboards to communicate interaction and design concepts effectively.\nDevelop high-fidelity mockups and interactive prototypes using design tools like Figma.\nDesign and conduct UX testing sessions to evaluate usability, accessibility, and desirability of prototypes.\nDesign UI elements such as navigation components, search boxes, page ribbons, tabs, widgets, CTAs, carousels, in-app banners, etc.\nWork closely with developers to ensure designs are implemented accurately and according to design specifications.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\nMust have skills:Proficiency in UX/UI Design, Figma, Sketch.\nStrong understanding of UX/UI design concepts and principles.\nExperience in developing and maintaining UX/UI designs.\nExperience in debugging and troubleshooting UX/UI designs.\nExperience in working with digital products and services.\n\n\n\n\nAdditional Information:\nThe ideal candidate will possess a strong educational background in design or a related field, along with a proven track record of delivering impactful UX/UI solutions.\nThis position is based at our Bangalore, Gurgaon, or Hyderabad office.\n\n\n\n\nAbout Accenture: Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the worlds largest delivery network Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 624,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us atAbout Our Company | Accenture\n\n\n\nAbout Accenture Strategy & Consulting:\n\nAccenture Strategy shapes our clients future, combining deep business insight with the understanding of how technology will impact industry and business models. Our focus on issues such as digital disruption, redefining competitiveness, operating and business models as well as the workforce of the future helps our clients find future value and growth in a digital world. Today, digital is changing the way organizations engage with their employees, business partners, customers, and communities. This is our unique differentiator. To bring this global perspective to our clients, Accenture Strategy's services include those provided by our Global Network a distributed management consulting organization that provides management consulting and strategy expertise across the client lifecycle. Our Global Network teams complement our in-country teams to deliver cutting-edge expertise and measurable value to clients all around the world.For more information visit https://www.accenture.com/us-en/Careers/capability-network\n\nAccenture Global Network | Accenture in One Word\n\ncome and be a part of our team.\n\nQualification\n\n\n\n\nEducational Qualification:Bachelor's degree or Master's in Design\n\n\n\nJob\n\n\nSummary:As a UX/UI Designer, you will be responsible for designing, building, and implementing user experiences that enhance business performance and drive customer satisfaction. Your typical day will involve collaborating with product managers and stakeholders, conducting UX research, creating wireframes and prototypes, and working closely with developers to ensure accurate implementation of designs",Industry Type: IT Services & Consulting,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent","['ux', 'user interface designing', 'sketching', 'figma', 'ui/ux', 'persona', 'motion designing', 'user flows', 'video editing', 'gui testing', 'photoshop', 'prototype', 'banners', 'ux research', 'visual design', 'ui', 'wireframe', 'graphic designing', 'mockups', 'debugging', 'troubleshooting', 'html', 'illustrator']",2025-06-13 05:34:25
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,2 - 3 years,Not Disclosed,['Bengaluru'],"Entity:- Accenture Strategy & Consulting\n\n\n\nTeam:- Strategy & Consulting Global Network\n\n\n\nPractice:- Supply Chian Analytics\n\n\n\nTitle:- Ind & Func AI Decision Science Analyst\n\n\n\nJob location:- Bangalore/Gurgaon/Hyderabad/ Mumbai\n\n\n\nExplore an Exciting Career at Accenture\n\nDo you believe in creating an impactAre you a problem solver who enjoys working on transformative strategies for global clientsAre you passionate about being part of an inclusive, diverse, and collaborative culture\n\n\n\nThen, this is the right place for you! Welcome to a host of exciting global opportunities in Accenture Strategy and Consulting\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\nExperience and Education:\n2-3 years of experience in Machine Learning, Time series forecasting or Optimization Techniques.\nMasters degree in technology or engineering or quantitative field (e.g. MSc in Statistics and Operations Research, M.Tech. in Industrial Engineering, Applied Math/Statistics, Computer Science, MBA in Operations).\nCertifications in any one or two of the areas will be an added advantage:Python, AI/ML, Optimization, Simulation, any of the cloud platforms (Azure/ GCP/ AWS).\n\nQualification\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\nAbout Accenture:\nwww.accenture.com\n\nAbout Accenture Strategy & Consulting:\n\nAccenture Strategy shapes our clients future, combining deep business insight with the understanding of how technology will impact industry and business models. Our focus on issues such as digital disruption, redefining competitiveness, operating and business models as well as the workforce of the future helps our clients find future value and growth in a digital world. Today, digital is changing the way organizations engage with their employees, business partners, customers and communities. This is our unique differentiator. To bring this global perspective to our clients, Accenture Strategy's services include those provided by our Capability Network a distributed management consulting organization that provides management consulting and strategy expertise across the client lifecycle. Our Capability Network teams complement our in-country teams to deliver cutting-edge expertise and measurable value to clients all around the world.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'time series analysis', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'data preparation', 'artificial intelligence', 'tableau', 'descriptive analysis', 'data modeling', 'cloud applications', 'data visualization', 'ml']",2025-06-13 05:34:27
S&C Global Network - AI - CDP - Analyst,Accenture,8 - 10 years,Not Disclosed,['Gurugram'],"Job Title -\n\n\n\nS&C Global Network - AI - RTCDP - Consultant\n\n\n\nManagement Level:\n\n\n\n9-Team Lead/Consultant\n\n\n\nLocation:\n\n\n\nBengaluru\n\n\n\nMust-have skills:Web Analytics Tools\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nTechnical\n\n\n\n\nSkills:\n\nAny CDP platforms experience e.g., Lytics CDP platform developer, or/and\nSegment CDP platform developer, or/and\nAdobe Experience Platform (Real time CDP) developer, or/and\nCustom CDP developer on any cloud\nGA4/GA360, or/and Adobe Analytics\nGoogle Tag Manager, and/or Adobe Launch, and/or any Tag Manager Tool\nGoogle Ads, DV360, Campaign Manager, Facebook Ads Manager, The Trading desk etc.\nDeep Cloud experiecne (GCP, AWS, Azure)\nAdvance level Python, SQL, Shell Scripting experience\nData Migration, DevOps, MLOps, Terraform Script programmer\n\n\n\nSoft\n\n\n\n\nSkills:\n\nStrong problem solving skills\nGood team player\nAttention to details\nGood communication skills\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\nWHATS IN IT FOR YOU\n\nAs part of our Analytics practice, you will join a worldwide network of over 20k+ smart and driven colleagues experienced in leading AI/ML/Statistical tools, methods and applications. From data to analytics and insights to actions, our forward-thinking consultants provide analytically-informed, issue-based insights at scale to help our clients improve outcomes and achieve high performance.\n\n\n\nWhat you would do in this role\n\nA Consultant/Manager for Customer Data Platforms serves as the day-to-day marketing technology point of contact and helps our clients get value out of their investment into a Customer Data Platform (CDP) by developing a strategic roadmap focused on personalized activation. You will be working with a multidisciplinary team of Solution Architects, Data Engineers, Data Scientists, and Digital Marketers.\n\n\n\nKey Duties and Responsibilities:\nBe a platform expert in one or more leading CDP solutions. Developer level expertise on Lytics, Segment, Adobe Experience Platform, Amperity, Tealium, Treasure Data etc. Including custom build CDPs\nDeep developer level expertise for real time even tracking for web analytics e.g., Google Tag Manager, Adobe Launch etc.\nProvide deep domain expertise in our clients business and broad knowledge of digital marketing together with a Marketing Strategist industry\nDeep expert level knowledge of GA360/GA4, Adobe Analytics, Google Ads, DV360, Campaign Manager, Facebook Ads Manager, The Trading desk etc.\nAssess and audit the current state of a clients marketing technology stack (MarTech) including data infrastructure, ad platforms and data security policies together with a solutions architect.\nConduct stakeholder interviews and gather business requirements\nTranslate business requirements into BRDs, CDP customer analytics use cases, structure technical solution\nPrioritize CDP use cases together with the client.\nCreate a strategic CDP roadmap focused on data driven marketing activation.\nWork with the Solution Architect to strategize, architect, and document a scalable CDP implementation, tailored to the clients needs.\nProvide hands-on support and platform training for our clients.\nData processing, data engineer and data schema/models expertise for CDPs to work on data models, unification logic etc.\nWork with Business Analysts, Data Architects, Technical Architects, DBAs to achieve project objectives - delivery dates, quality objectives etc.\nBusiness intelligence expertise for insights, actionable recommendations.\nProject management expertise for sprint planning\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n8 to 10 Years\n\n\n\n\nEducational Qualification:\n\n\n\nB.Com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['digital marketing', 'display video', 'google ads', 'campaign management', 'facebook ads manager', 'trading', 'python', 'adobe analytics', 'adobe', 'microsoft azure', 'sql', 'gcp', 'web analytics', 'devops', 'segmentation', 'web analytics tools', 'shell scripting', 'network analysis', 'aws', 'seo']",2025-06-13 05:34:28
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title -\n\n\n\nS&C Global Network - AI - Supply Chain Analytics - Analyst\n\n\n\nManagement Level:\n\n\n\n11-Analyst\n\n\n\nLocation:\n\n\n\nHyderabad, HDC2A\n\n\n\nMust-have skills:Data Analytics\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'anaplan', 'data analytics', 'sap', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'supply', 'data preparation', 'tableau', 'descriptive analysis', 'data modeling', 'sap ibp', 'cloud applications', 'ibp', 'data visualization']",2025-06-13 05:34:30
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\n..\n\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:34:33
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\n..\n\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:34:35
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:Chartered Accountant\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Implementation of gen. ledger processes including yearend closing, journalizing. Creating and maintaining ledgers, ledger currencies, budgets, and journal entries, design to deliver a financial management solution including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry and reporting as well as dynamic allocations and the management of commitments and expenditures also run Interface reports and perform close books of accounts.\n\n\n\n\nWhat are we looking for\nAbility to perform under pressureAbility to establish strong client relationshipStrong analytical skillsProblem-solving skillsFinancial Consolidation, Reporting and month end close activities\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nChartered Accountant",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'budgeting', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:34:37
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Balance Sheet Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe are looking to hire an Accountant on the Payroll Accounting Team that will play a critical role in the month-end close process. You will get the opportunity to work on a multitude of projects and streamline processes and will become a subject matter expert in processing accruals across multiple financial statement line items. This person will act as a cross-functional business partner to implement automation and create improvements to optimize the month-end close. You will work in a dynamic environment and be able to recommend and implement process improvements, work independently and handle multiple tasks simultaneously.\n\n\n\n\nWhat are we looking for\nThe Candidate should be well verse with accounting background and ground experience.The resource should understand of the core activities that we perform- Payroll journals and BS recons or the tools we use extensively.We need somebody who can easily grasp the subject matter with minimum instructions.Adaptable and flexibleProblem-solving skillsAbility to establish strong client relationshipAgility for quick learningAbility to work well in a team\n\n\n\nRoles and Responsibilities: Prepare and review journal entries and account reconciliations for various GL accounts.Analyze monthly variances across GL accounts and investigate discrepancies.Collaborate with Global Business Service (third party service provider) team to automate and streamline processes and review work product.Partner closely with financials statement line-item owners and business partners from various departmentsLead process improvement and automation initiativesEnhance existing processes and internal controls, perform and maintain assigned internal controls.Support external audit activities and ongoing internal auditsExecute special projects and complete other ad hoc assignments as required\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounting', 'journal', 'record to report', 'recon', 'payroll', 'accounts receivable', 'balance sheet', 'accounts payable', 'service operations', 'data analysis', 'mis reporting', 'journal entries', 'pivot table', 'vlookup', 'reporting analysis', 'advanced excel', 'mis', 'external audit', 'finance']",2025-06-13 05:34:38
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\nAbility to perform under pressureAbility to work well in a teamAbility to establish strong client relationshipNA\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:34:40
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Business Reporting & Governance - Microsoft SQL Server\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Customer Support vertical and help us in managing/ resolving customers query, handling escalations and complaints of the dissatisfied customers & giving best resolutions. You will also be responsible for closing the fault and complaints within SLA s.Candidate who is good in excel and MIS reports are looked at for these skillsA relational database management system which runs as a server and provides multiuser access to a number of databases. Provide database functionality through this relational database management system from Microsoft.\n\n\n\n\nWhat are we looking for\nStrong system skills including advanced proficiency with Microsoft Excel (Power Query) as well as a working knowledge of SQL, Data Analytics, and Relational Databases. Strong written and verbal communication skills including process documentation and system flowcharts along with the ability to work well in cross-functional teams. Excellent critical thinking, analytical and problem-solving skills including the ability to think outside of the box, deal with ambiguity and challenge informationKnowledge of POS Systems (Bulloch),JDE, PDI, ServiceNow, and Market Basket is considered an asset / MS Excel (Macros/VBA)\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'business reporting', 'relational databases', 'sql server', 'sql', 'macros', 'python', 'data analysis', 'power bi', 'javascript', 'power query', 'reporting analysis', 'spring', 'tableau', 'java', 'vba', 'mis', 'html', 'mysql', 'data structures', 'data visualization', 'aws']",2025-06-13 05:34:42
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English(Domestic) - Expert\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.The Financial Consolidation & Close Operations team is responsible for general ledger processes including year-end closing, journalizing, etc. They help create & maintain ledgers, currencies, budgets, & journal entries, deliver solutions including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry & reporting, dynamic allocations & the management of commitments & expenditures, run interface reports & perform close books of accounts. The team reviews P&L accounts errors, omissions, or inconsistencies and managing the preparation of all reports. They also work on posting journal entries, preparing balance sheet reconciliations, investigating and reporting open items, reviewing entries and reconciliations, supporting month-end closing, preparing various reports as required, and supporting audits. The team also oversees improvement projects, including automation, simplifications, and enhanced controls.\n\n\n\n\nWhat are we looking for\nAbility to establish strong client relationship\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['balance sheet', 'journal entries', 'accounting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'forecasting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'budgeting', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:34:44
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Business Reporting and Governance vertical helps to deploy and deliver robust tracking mechanism for SLA/KPI or any other operations on a day-to-day basis. The Governance team will be responsible for contractual compliance of various aspects of contract like Governance, Reporting, Incident Management, Change Management and Survey Management along with driving automation and analytics. Assessing, managing, using, improving, monitoring, maintaining, and protecting organizational information through a system of decision rights and accountabilities for information related processes, executed according to agreed-upon models which describe who can take what actions, with what information, when, under what circumstances and using what methods. Candidate who is good in excel and MIS reports are looked at for these skillsIn Reporting and Analytics, you will have to prepare management reports and analysis, both recurring and ad-hoc. This includes focusing on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nEffective communication and organization skills with Polished, professional presence Experience in working on automation projects Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Proficient in MS Office with advance knowledge in excel formulas. Ability to simplify and automate manual intensive processes using basic VBA, MS Access Expertise in creating reports, and exposure to using PowerBI\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ms access', 'business reporting', 'vlookup', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'power bi', 'business analysis', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'reporting and analytics', 'tableau', 'advanced excel', 'data visualization']",2025-06-13 05:34:46
Risk and Compliance Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Risk & Compliance - Operational Audit & Compliance\n\n\n\n\nDesignation: Risk and Compliance Analyst\n\n\n\n\nQualifications:Chartered Accountant/Master of Business Administration/CA Inter\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Risk and Compliance vertical and help us perform compliance reviews, publish reports with actions and provide closure guidance as needed. We design & recommend effective controls to mitigate risks and help service delivery team prepare for upcoming client / external audits.You will be working as a part of the Risk & compliance team which is responsible for helping clients and organizations identify risks and create mitigation plans.Audit and manage effective implementation and delivery of functional processes within operations to mitigate risk. e.g. Policies; Anticorruption, BCM, InfoSec, P104, Records Management and Contractor controls. Establish processes to audit/validate current control effectiveness and drive improvements wherever required.\n\n\n\n\nWhat are we looking for\nAudit and manage effective implementation and delivery of functional processes within operations to mitigate risk. e.g. Policies; Anticorruption, BCM, InfoSec, P104, Records Management and Contractor controls. Establish processes to audit/validate current control effectiveness and drive improvements wherever required. Audit and manage effective implementation and delivery of functional processes within operations to mitigate risk. e.g. Policies; Anticorruption, BCM, InfoSec, P104, Records Management and Contractor controls. Establish processes to audit/validate current control effectiveness and drive improvements wherever required.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nChartered Accountant,Master of Business Administration,CA Inter",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['risk compliance', 'aml', 'auditing', 'compliance analysis', 'kyc', 'financial analysis', 'risk management', 'risk assessment', 'due diligence', 'data analysis', 'anti money laundering', 'sox compliance', 'internal control', 'internal audit', 'advanced excel', 'due diligence review']",2025-06-13 05:34:48
Transitions Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Talent Acquisition -Enabling Functions - Data Analysis Reporting\n\n\n\n\nDesignation: Transitions Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nRole Overview:This role is part of the Recruitment Process Transformation Team for all of India. You will be responsible for supporting the WD stabilization and driving improvements in recruitment operations through effective project management, stakeholder engagement, and process optimization.Key Responsibilities:1.Agile Goal Setting:Create and manage short-term goals aligned with long-term objectives, ensuring an agile mindset for the team.2.Program Stewardship & Organization:Organize programs and activities aligned with business goals, supporting recruitment initiatives in India to enhance ways of working.3.Stakeholder Management:Handle complex stakeholder relationships, set expectations, and manage diverse asks from teams (including leadership). Work with extended stakeholders such as Legal, ER & Policies, Marcom, Audit, Compliance, Payroll, etc.4.Communication & Collaboration:Facilitate transparent communication with stakeholders through meetings, addressing project issues, and setting the program s operating structure for seamless collaboration and alignment across teams.5.Documentation & Updates:Regularly document meeting discussions, assign action owners, and track next steps to ensure stakeholders stay informed on project progress.6.Process Design:Design clear and effective process flows (as-is and to-be) to communicate ideas and decisions to stakeholders.7.Governance & Prioritization:Establish and manage governance models, define principles, and prioritize tasks to ensure smooth project execution.8.Change Management:Implement and manage changes to ensure projects meet their goals, managing interventions as necessary.9.Status Reporting:Ensure timely and accurate reporting on program status throughout the lifecycle, including ownership of executive conversations, decision boards, and steering committees.10.Risk Management:Proactively analyze risks and issues, facilitate change control discussions, and lead decision review boards.11.Milestone Tracking & Planning:Work closely with the business to define key priorities, milestones, and plans for delivery, change, and stabilization.12.Expectation Management:Track milestones, deliverables, and ensure consistent management of expectations with stakeholders.Preferred Skill - Automation & Data Analytics, Recruitment & WD Related knowledge, Process Design, Drawing As-Is & To-Be, Power BI knowledge, Storyboarding, Stakeholder management skills, MS Power Apps, Leveraging AI for regular work\n\n\n\n\nWhat are we looking for\nData AnalyticsData AutomationAdaptable and flexibleAgility for quick learningAbility to establish strong client relationshipWritten and verbal communication\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['data analysis', 'data analytics', 'power bi', 'talent acquisition', 'recruitment', 'c#', 'project management', 'css', 'process design', 'auditing', 'sharepoint', 'javascript', 'jquery', 'ms power apps', 'infopath', 'stakeholder management', 'asp.net', 'drawing', 'html', 'agile', 'angularjs']",2025-06-13 05:34:49
Fund and Information Management - Analyst,Goldman Sachs,2 - 4 years,Not Disclosed,['Bengaluru'],"Asset Wealth Management (AWM):\nAWM invests in corporate equity and debt, real estate equity and debt, and infrastructure-related assets and companies around the world. AWM operates on a global platform and our team works in a fast-paced, exciting environment. We look for individuals with versatile skills and a passion for investing.\nWithin AWM, the Funds Information Management Group supports the division in a variety of functions, including standard and custom client reporting, data analysis and process management/oversight. The Funds Information Management Group also partners with Engineering and Product Management to assist in building automation and reporting solutions.\nThe Analyst/Associate will perform a variety of recurring tasks, project-based work and ad hoc analyses. The successful applicant will have an ability to understand financial information, draw relationships and raise issues or concerns.\nSpecific Responsibilities May Include:\nTracking/reporting/analyzing investor/investment/portfolio metrics\nGathering data and assisting with internal/external information requests\nSupporting AWM s quarterly portfolio company monitoring process using iLevel software\nDesigning/enhancing processes and supporting/furthering technology initiatives related to the above responsibilities\nAdditional responsibilities will be based on the needs of the division and the candidate s specific skills\nQualifications:\nBachelor s Degree in Accounting, Finance or other business discipline\nMinimum 2-4 years related work experience (May 2020 - December 2022 graduation dates)\nStrong analytical skills and detail orientation\nStrong interpersonal and communication skills, oral as well as written\nStrong coordination and organizational skills\nAbility to multi-task and meet tight deadlines\nAbility to work independently in a small team, exhibit initiative and be proactive\nAbility to organize and analyze large volumes of information\nFacility with and interest in working on technology initiatives\nTeam player, willing to help in areas not explicitly related to job duties\nComfortable working in a fast-paced, high-energy environment\nStrong Excel, Word, PowerPoint skills\nAbout Goldman Sachs",Industry Type: Banking,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Automation', 'Wealth management', 'Wellness', 'HTML', 'Investment banking', 'Information management', 'Monitoring', 'Process management']",2025-06-13 05:34:51
Analyst-Qlik Sense Developer,AstraZeneca India Pvt. Ltd,5 - 6 years,Not Disclosed,['Bengaluru'],"Job Title: Analyst-Qlik Sense Developer\nGlobal Career Level: C3\nIntroduction to role:\nAre you ready to transform raw data into actionable insights? As a Qlik Sense Data Reporting and Analytics Developer, youll be at the forefront of driving informed decision-making and strategic initiatives across Alexion. Your expertise in designing, developing, and maintaining data reporting solutions will empower our organization to make data-driven decisions. If you have a strong background in data analysis, proficiency in visualization tools, and excellent communication skills, this is the role for you!\nAccountabilities:\nSupport the Alexion team with field force reporting by designing, developing, validating, and maintaining Qlik Sense dashboards and supporting model tiers for various business units and indications.\nUnderstand business objectives, data sources, and key performance indicators (KPIs) to design effective solutions.\nDesign and implement data models in QlikSense, including ETL processes.\nWrite and optimize Qlik scripting language using SQL to transform raw data into actionable insights by creating QVDs; transforming source data into dimensions/factors for dashboards.\nIntegrate data from multiple sources, ensuring accuracy, consistency, and optimal performance.\nDevelop interactive dashboards, reports, and visualizations using Qlik Sense.\nIdentify and address performance bottlenecks in Qlik applications; optimize data models, load scripts, and front-end visualizations for fast user experiences.\nConduct thorough testing of Qlik applications to validate data accuracy, functionality, and usability.\nCollaborate with QA testers and business users to resolve issues promptly.\nDesign intuitive user interfaces that facilitate data exploration, analysis, and insight generation.\nWork closely with cross-functional teams to align Qlik development efforts with organizational goals.\nCommunicate project status, challenges, and recommendations to stakeholders clearly.\nInstill a culture of continuous improvement, testing, and deployment of new capabilities for the business.\nEssential Skills/Experience:\nAdvanced understanding/experience with SQL, Snowflake, and Veeva CRM.\nAbility to create new rules and adjust existing rules.\nExpertise in Qlik scripting language + data modelling concepts, including related skills in:\n- Data warehouse\n- Data architecture\n- Data visualization (inclusive of Vizlib extensions)\n- Section access (security)\n- N-printing for sending reports.\nRecent project experience with Qlik + experience with other BI tools\nDesirable Skills/Experience:\nBackground in computer science, information systems, or related field.\n5-6 years of experience in developing reporting and visualization applications.\nExperience in web-development (JavaScript and CSS)\nExcellent analytical and problem-solving skills, with keen attention to detail.\nAbility to work independently and collaboratively in a dynamic environment.\nStrong communication and interpersonal skills.\nAt AstraZenecas Alexion division, youll find an environment where work isnt ordinary. Our closeness to patients brings us closer to our work and each other. With a rapidly expanding portfolio, youll enjoy the entrepreneurial spirit of a leading biotech combined with the security of a global pharma. Here, your career is not just a path but a journey to making a difference where it truly counts. Youll be empowered with tailored development programs designed for skill enhancement and fostering a deep understanding of our patients journeys. Join us to innovate and grow in a culture that celebrates diversity, innovation, and connection.\nReady to make an impact? Apply now and be part of our journey!\n11-Jun-2025\n14-Jun-2025\nAlexion is proud to be an Equal Employment Opportunity and Affirmative Action employer. We are committed to fostering a culture of belonging where every single person can belong because of their uniqueness. The Company will not make decisions about employment, training, compensation, promotion, and other terms and conditions of employment based on race, color, religion, creed or lack thereof, sex, sexual orientation, age, ancestry, national origin, ethnicity, citizenship status, marital status, pregnancy, (including childbirth, breastfeeding, or related medical conditions), parental status (including adoption or surrogacy), military status, protected veteran status, disability, medical condition, gender identity or expression, genetic information, mental illness or other characteristics protected by law. Alexion provides reasonable accommodations to meet the needs of candidates and employees. To begin an interactive dialogue with Alexion regarding an accommodation, please contact accommodations@Alexion.com . Alexion participates in E-Verify.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Printing', 'Data analysis', 'Front end', 'Pharma', 'Web development', 'Javascript', 'Analytics', 'SQL', 'CRM']",2025-06-13 05:34:53
CPU Performance & Power Analyst/Staff Engineer - 4 Open positions,Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 8 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'uart', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-13 05:34:55
CPU Performance and Power Analyst/Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 5 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-13 05:34:57
Treasury Analyst,Wells Fargo,2 - 4 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Treasury Analyst\n\nIn this role, you will:\nPlan and set policies and guidelines for managing global treasury activities including funding, liquidity risk management, asset and liability management, capital management, financial performance management, and related activities",,,,"['Treasury', 'capital management', 'liability management', 'Power BI', 'liquidity risk management', 'Alteryx', 'Data Analysis', 'Forecasting', 'Python']",2025-06-13 05:34:58
Market Intelligence Associate Analyst,Salesforce,3 - 4 years,Not Disclosed,['Bengaluru'],"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.\nJob Category\nData\nJob Details\nAbout Salesforce\nCustomer & Market Intel Overview:\nWe re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good - you ve come to the right place.\nDo you enjoy a blend of strategy and research? The Customer & Market Intel team partners directly with the Sales team as a trusted advisor, focused on providing strategic insights around our customers, prospects, industries, CXOs, and Competitors. You will collaborate with many cross-functional teams such as Strategy, Marketing Operations, Programs, Enablement, Sales Dev, and others. This is a high-velocity and high-impact role, with constantly evolving priorities and demands.\nImpact:\nAs a Market Intelligence Associate Analyst at Salesforce, you will play a critical role in gathering, analyzing, and synthesizing information to provide strategic insights and support to our business. Your primary responsibility will be to ensure that our company remains informed about key market trends, what s happening in our client s organizations as well as key competitor activities. You will work closely with various departments, including Strategy, Marketing Operations, Programs, Enablement, Sales Dev, to help shape our strategies and initiatives.\nKey Responsibilities:\nCustomer & Persona Insights:\nResearch about the company- Overview, numbers, trends, key leadership & stakeholders, value chain, recent initiatives, strategic & tech priorities, Current Tech landscape, Digital Audit, etc.\nLeveraging the above research to create detailed PoV on how Salesforce can help that customer succeed\nCreate detailed customer profiles for sales understanding - What s top of mind of a persona and how can we support that persona\nIndustry PoVs & Bashos:\nResearch about the industry - numbers, trends, key players, value chain, recent initiatives, strategic & tech priorities\nLeveraging the above research to create emails/Bashos as well as detailed PoV on how Salesforce can help customers of that industry\nCompetitor Insights:\nEvaluating a competitor s focus areas - products, verticals, geographies, etc.\nComparison of Competitor s strengths vs ours\nCreating Win Wires:\nOne-stop solution for sales reps on won deals\nHighlights customer challenges and use cases sold\nWin-loss analysis: Identify and call out the reason for winning a deal and how can we scale it\nRequirements:\nBachelors degree or equivalent experience in Business, Strategy, Marketing or related field. MBA preferred\nCompetence in market research and competitive analysis\nExcellent communication and presentation skills\nKnowledge of industry trends and market dynamics\nDemonstrated business acumen and understanding of sales and research processes.\nStrong analytical skills and proficiency in data analysis\nRelated experience 3-4 years+ in sales research or saas sales.\nAccommodations\nIf you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .\nPosting Statement",Industry Type: Internet,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Data analysis', 'Sales', 'Competitive analysis', 'Market intelligence', 'Market research', 'Marketing operations', 'Business strategy', 'Research', 'Salesforce', 'Auditing']",2025-06-13 05:35:00
"Finance Analyst, IN Amazon Now Finance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"Amazon seeks a Finance Analyst to be a key member of its Now (Quick Commerce) Finance team. The person would play a pivotal role in driving the business agenda and would work as a copilot in delivering business results while driving the P&L for the Now business. This includes responsibility for financial metrics, reporting, forecasting, and providing decision support through data analysis & business insights.\n\nThe Finance Analyst position is based in Bangalore.\n\n\nThe successful candidate will be strategic, analytical, and will need to demonstrate ability to effectively manage finances of a high-growth business including:Drive financial reporting and analysis for Now business, including daily/weekly business reviews, variance analysis, and real-time operational metrics tracking\nPartner with business teams to analyze and optimize key metrics like order density, delivery speed, catalog availability, and dark store economics\nDevelop and maintain P&L forecasting models, incorporating key business levers across dark stores and delivery network\nProvide controllership support and build scalable processes that enhance transparency and strengthen controls across high-velocity operations\nSupport business reviews with leadership team, focusing on unit economics and network efficiency\nPartner with operations teams to analyze and optimize dark store costs, delivery economics, and inventory holding costs\nWork closely with category teams to analyze and improve product margins and inventory turns\nDrive monthly, quarterly, and annual financial close process in partnership with accounting teams\nPerform ad-hoc analysis and financial modeling to support network expansion and strategic initiatives\nPresent data-driven recommendations to senior management on growth and profitability initiatives ideal candidate should possess good analytical skills, attention to detail, and the ability to work effectively in a dynamic, fast-paced environment while managing multiple stakeholders in real-time operations. 2+ years of finance experience\n2+ years of applying key financial performance indicators (KPIs) to analyses experience\nKnowledge of standard software including Excel, Access, Oracle, Essbase, SQL and VBA skills\nExperience using data to influence business decisions\nExperience in corporate finance including budgeting/planning, forecasting and reporting\nChartered Accountant or MBA (Finance) 2+ years of participating in continuous improvement projects in your team to scale and improve controllership with measurable results experience\nExperience of working in ecommerce/Quick commerce domain",,,,"['Data analysis', 'Financial reporting', 'Corporate finance', 'Budgeting', 'Oracle', 'Continuous improvement', 'Forecasting', 'Variance analysis', 'Operations', 'SQL']",2025-06-13 05:35:02
Analyst - Tax & Transfer Pricing,HARMAN,3 - 8 years,Not Disclosed,['Bengaluru'],"Introduction: Corporate\nWe re a global, multi-disciplinary team that s putting the innovative power of technology to work and transforming tomorrow. At HARMAN Corporate, you are integral to our company s award-winning success.\nEnrich your managerial and organizational talents - from finance, quality, and supply chain to human resources, IT, sales, and strategy",,,,"['Supply chain', 'Data analysis', 'Change management', 'SAP', 'Analytical', 'Transfer pricing', 'International taxation', 'Wellness', 'Corporate taxation', 'Automotive']",2025-06-13 05:35:04
AVP - Finance Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Finance Analyst\n\nIn this role, you will:\nParticipate in functions related to financial research and reporting\nForecast analysis of key metrics, as well as other financial consulting related to business performance, operating and strategic reviews",,,,"['financial research', 'Data analysis', 'Project management', 'documentation', 'Gap analysis', 'financial consulting', 'SQL']",2025-06-13 05:35:06
Senior Executive,Flipkart,0 - 1 years,Not Disclosed,['Kolkata'],Skills Required :\nBSc agri holder with Good communication and basic excel skills,Industry Type: Courier / Logistics,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['excel', 'Agricultural Science', 'Data Analysis', 'Agricultural Data Management', 'Agricultural Research']",2025-06-13 05:35:08
Data Scientist For DMAI,Prodapt Solutions,2 - 5 years,Not Disclosed,['Chennai'],"Overview\n\nThe Senior Data Science Engineer will leverage advanced data science techniques to solve complex business problems, guide decision-making processes, and mentor junior team members. This role requires a combination of technical expertise in data analysis, machine learning, and project management skills.\n\nResponsibilities\n\n Data Analysis and Modeling Analyze large-scale telecom datasets to extract actionable insights and build predictive models for network optimization and customer retention.\n Conduct statistical analyses  to validate models and ensure their effectiveness.\n Machine Learning Development Design and implement machine learning algorithms for fraud detection, churn prediction, and network failure analysis.\n Telecom-Specific Analytics Apply domain knowledge to improve customer experience by analyzing usage patterns, optimizing services, and predicting customer lifetime value.\n ETL Processes Develop robust pipelines for extracting, transforming, and loading telecom data from diverse sources.\n Collaboration Work closely with data scientists, software engineers, and telecom experts to deploy solutions that enhance operational efficiency.\n Data Governance :  Ensure data integrity, privacy, security and compliance with industry standards\n\n\nAdvanced degree in Data Science, Statistics, Computer Science, or a related field.\nExtensive experience in data science roles with a strong focus on machine learning and statistical modeling.\nProficiency in programming languages such as Python or R and strong SQL skills.\nFamiliarity with big data technologies (e.g., Hadoop, Spark) is advantageous.\nExpertise in cloud platforms such as AWS or Azure.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'machine learning', 'sql', 'statistical modeling', 'algorithms', 'python', 'big data technologies', 'microsoft azure', 'cloud platforms', 'r', 'data science', 'spark', 'data governance', 'hadoop', 'aws', 'etl', 'machine learning algorithms', 'statistics']",2025-06-13 05:35:10
Data Scientist,Equifax Credit Information Services Private Limited,5 - 7 years,Not Disclosed,['Pune'],"This position allows the successful incumbent to develop deep technical and broad commercial skills by being exposed to, and working on a wide variety of internal projects.\nWorking as part of a large, sophisticated analytics team, this role will be required to:\nManipulate and analyse data for the development and validation of predictive models in the areas of credit risk, demographics, marketing, fraud and ratings, in distributed computing environment\nMonitor Equifax s cutting edge scorecards and risk tools\nCreate business case and analytic insight materials that show the value of predictive modelling and visualise the insights\nConduct ad hoc queries such as bureau insights, testing solutions\nLead small projects and quality check own and others outputs guide junior data scientists\nMaintain documentation that supports Analytics platform of databases, data products and analytical solutions.\n\nWhat you'll Do:\n\nProject Leadership / Mentoring\nMentor Analysts through development process\nDriving a focus on learning so that the team benefits from your coaching and other learning events that contribute to improved performance.\nDevelop and maintain a network of influence.\nDemonstrate leadership by example.\nData Analysis\nLeading statistical and data analysis, sometimes as project team leader.\nDemonstrate analytic leadership in the approaches used and proactively provide technical guidance and support to analysts.\nDemonstrate a high level of skill in programming required to perform analysis such as demonstrated experience with SQL, R, Python and Tableau on Cloud environments such as GCP or equivalent. Process and analyse large volumes of data in the development of insights.\nPrepare documentation for all work, to ensure that an audit trail is sufficient for a colleague to be able to quality review and/or repeat your analysis.\nQuality check your own and other analyst work output to ensure error-free delivery of information and analysis.\nDevelop extensive repertoire of analytical methodologies and techniques for investigating data relationships and insights\nAdhere to Equifax project management standards and effective use of project management resources (methodology, templates, time recording systems and project office).\nProduct and Service\nContributing to analytic roadmap, product development and innovation\nDevelop a detailed understanding of the full product and service offering available through Equifax as we'll as the market dynamics and requirements within the data driven marketing space.\nProactively use this understanding to work with the team and stakeholders to enhance and expand Equifax s data and insights assets.\nWhat experience you need\nBS degree in a STEM major or equivalent discipline\n5-7 years of experience in a related analytical role\nProven track record of designing and developing predictive models in real-world applications\nExperience with model performance evaluation and predictive model optimization for accuracy and efficiency\nCloud certification strongly preferred\nAdditional role-based certifications may be required depending upon region/BU requirements\nProcess Improvement and Efficiencie\nDrive transition to more advanced modelling environments, utilising distributed computing and methodologies such as machine learning\nDemonstrate an understanding of business needs, making recommendations relating to new or improved data and insights assets.\nSupporting the other teams within the Analytics function by working with them to improve processes as needed.\nSystems and Processes\nDevelop a detailed understanding of Equifax databases, data structures and core data analysis procedures, as we'll as maximising output through a Hadoop based file system.\nDevelop understanding of best practice model management framework to ensure Equifax s models remain optimal in terms of performance and stability\nDevelop familiarity with Equifax s documented project management methodology and resources (templates, time recording system, work scheduling etc).\nWhat could set you apart\nPassion for data science, data mining, machine learning and experience with big data architectures and methods\nA Masters degree in a quantitative field (Statistics, Mathematics, Economics)\nCloud certification such as GCP strongly preferred\nSelf Starter\nExcellent communicator / Client Facing\nAbility to work in fast paced environment\nFlexibility work across A/NZ time zones based on project needs",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Project management', 'Process improvement', 'Analytical', 'Healthcare', 'Data structures', 'Scheduling', 'Data mining', 'SQL', 'Auditing']",2025-06-13 05:35:12
Data Scientist,Swits Digital,5 - 12 years,Not Disclosed,['Chennai'],"Job Title: Data Scientist\nLocation: Chennai\nExperience: 5-12 Years\nJob Summary:\nWe are seeking a highly analytical and results-driven Data Scientist with a strong background in statistics , machine learning , and data science , combined with domain knowledge in mechanical engineering and cost analysis . The ideal candidate will have experience working with Google Cloud Platform (GCP) and will play a key role in transforming engineering and operational data into actionable insights to drive business decisions.\nRequired Skills & Experience:\nStrong knowledge of statistics , machine learning , and data science principles\nHands-on experience with Google Cloud Platform (GCP) , especially BigQuery , Vertex AI , and Cloud Functions\nProficiency in Python or R for data analysis and modeling\nSolid understanding of mechanical engineering concepts and their application in data analysis\nExperience with cost modeling , cost-benefit analysis , or operational performance analytics\nExcellent problem-solving , analytical thinking , and communication skills\nAbility to work with large datasets and create clear, actionable insights",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'data science', 'GCP', 'Analytical', 'Machine learning', 'Cost benefit analysis', 'Operations', 'Mechanical engineering', 'Analytics', 'Python']",2025-06-13 05:35:14
Data Scientist,H3 Technologies,3 - 8 years,Not Disclosed,['Thiruvananthapuram'],"Position: Data Scientist\nLocation: Trivandrum\nJob Description :\nWe are urgently looking for a motivated Data Scientist with a focus on Computer Vision and Machine Learning. The candidate will have a passion for solving complex problems using deep learning, image processing, and AI-driven techniques. He shall work closely with a team of data scientists, engineers, etc and to build, optimize, and deploy machine learning models for real-world applications\nKey Responsibilities :\nDevelop, train, and optimize deep learning models for image classification, object detection, segmentation, and other computer vision tasks.\nImplement and fine-tune machine learning algorithms for structured and unstructured data analysis.\nPreprocess and augment image/video datasets to improve model accuracy and robustness.\nWork with frameworks such as YOLO, TensorFlow, PyTorch, and OpenCV to build scalable models.\nAssist in deploying models to production environments, including cloud and edge computing platforms.\nCollaborate with cross-functional teams to integrate AI solutions into existing workflows and products.\nStay up-to-date with the latest research and trends in AI, computer vision, and machine learning.\nQualifications :\nBachelors or masters degree in computer science, Data Science, AI/ML, or a related field.\nMinimum of 3 year of professional experience in Python programming and AI/ML integrations\nSolid understanding of machine learning concepts, neural networks, and deep learning architectures.\nHands-on experience in training and optimizing computer vision models.\nFamiliarity with data preprocessing techniques, image annotation tools, and model evaluation metrics.\nStrong problem-solving skills and the ability to work in a fast-paced environment.\nJoining: Immediate to less than 30 days\nBudget: 13 - 14 LPA\n"",",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'deep learning', 'Data analysis', 'Image processing', 'data science', 'Neural networks', 'Machine learning', 'Budgeting', 'Python']",2025-06-13 05:35:16
Data Scientist - Python / Machine Learning,Blueberry Unicorn Services,6 - 11 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Working Hours : 2PM to 11PM IST\n\nMid-Level ML Engineers / Data Scientist Role : (4-5 years of experience )\n\n- Experience processing, filtering, and presenting large quantities (100K to Millions of rows) of data using Pandas and PySpark\n\n- Experience with statistical analysis, data modeling, machine learning, optimizations, regression modeling and forecasting, time series analysis, data mining, and demand modeling.\n\n- Experience applying various machine learning techniques and understanding the key parameters that affect their performance.\n\n- Experience with Predictive analytics (e.g., forecasting, time-series, neural networks) and Prescriptive analytics (e.g., stochastic optimization, bandits, reinforcement learning).\n\n- Experience with Python and Python packages like NumPy, Pandas and deep learning frameworks like TensorFlow, Pytorch and Keras\n\n- Experience in Big Data ecosystem with frameworks like Spark, PySpark , Unstructured DBs like Elasticsearch and MongoDB\n\n- Proficiency with TABLEAU or other web-based interfaces to create graphic-rich customizable plots, charts data maps etc.\n\n- Able to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL).\n\n- Previous experience in ML, data scientist or optimization engineer role with a large technology company.\n\n- Experience in an operational environment developing, fast-prototyping, piloting, and launching analytic products.\n\n- Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations.\n\n- Experience in creating data driven visualizations to describe an end-to-end system.\n\n- Excellent written and verbal communication skills. The role requires effective communication with colleagues from computer science, operations research, and business backgrounds.\n\n- Bachelors or Masters in Artificial Intelligence, Computer Science, Statistics, Applied Math, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'Data Scientist', 'Artificial Intelligence', 'Data Management', 'Big Data', 'Data Modeling', 'Spark', 'Numpy', 'Python', 'Predictive Analytics']",2025-06-13 05:35:18
Data Scientist,Paypal,2 - 5 years,Not Disclosed,['Bengaluru'],"The Company\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\nOur beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do - and they push us to ensure we take care of ourselves, each other, and our communities.\nJob Summary:\nMeet your team:\n\nThis role sits within Credit card fraud risk strategy team of Global Fraud Prevention Org., focused on safeguarding our customers and business from evolving fraud threats. The team is responsible for developing and executing data-driven strategies to mitigate fraud in UK PPC portfolio.\n\nWhat do you need to know about the role:\n\nGlobal Fraud Prevention resides in the Global Risk Management (GRM) organization that supports various business lines in optimizing risk and rewards to enable profitable business growth.\n\nYou will be working closely with global fraud risk professionals focusing on managing and mitigating fraud risk in the UK PayPal Credit Portfolio,\n\nBe a part of this fraud revolution and enjoy the journey being with PayPal s growing team. Why You ll Love It here:\n\nImpact: Your work directly influences the success and growth of PayPal s credit offerings.\nLearning: Expect to level up your analytical and problem-solving skills every day with more challenges to solve\nGrowth: The credit card industry is constantly evolving, and you ll be right there on the cutting edge, sharpening your skills and new learnings along the way.\nCulture: We re a team of passionate professionals who love challenges and are always ready to celebrate a job well done.\nJob Description:\nYour way to impact:\nOwn the areas of Transaction Fraud risk policy: Work on Broad area of projects from Card risk strategies, acquisition and payment risk strategies, all depending on the business need.\nWork closely with Stakeholders: this includes Credit Risk, Product, finance teams to optimize fraud strategies and portfolio performance.\nProactively identify emerging fraud trends and propose mitigation strategies .\nMaintain and develop Monitoring and Alerting capabilities: to clearly monitor the PPC Card program health and simplify insights for key stakeholders.\nPresent regular updates to senior leaders: on Portfolio Health, highlights, lowlights, and actionable insights.\nYour day to day:\nIn this role you will have full ownership of portfolio and is responsible for end-to-end management of Fraud loss and decline rates.\nWorks independently and proficiently. Accountable for own results.\nCollaborate with different teams to develop strategies for fraud prevention, loss savings, and optimize transaction declines .\nAnalyze and assess risks to provide informed recommendations for mitigation strategies\nPrepare periodic KPI reports summarizing the business units risk and control environment for senior management\nWhat do you need to bring:\n2-5 years of domain expertise\nExcellent Problem-Solving Skills : Strong judgment and the ability to think strategically, creatively, and practically to address complex challenges.\nAdvanced Analytics expertise : Proficiency in SQL, Python, Advanced Excel, Tableau, and other analytics tools, with a proven track record of using them to solve real-world problems.\nExceptional communication skills : Outstanding written, verbal communication abilities, capable of translating complex technical concepts into clear, actionable insights for diverse audiences\nCollaboration Influence : Strong ability to collaborate across teams, build relationships, and drive results through influence and teamwork\nExperience in Payments / Transaction risk management / Credit / Fraud Risk is a strong plus.\n** We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please dont hesitate to apply.\nPreferred Qualification:\nSubsidiary:\nPayPal\nTravel Percent:\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits:\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com .\nWho We Are:\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talentaccommodations@paypal.com .\nBelonging at PayPal:\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: FinTech / Payments,Department: Other,"Employment Type: Full Time, Permanent","['advanced analytics', 'PPC', 'Analytical', 'Diversity and Inclusion', 'Wellness', 'Advanced Excel', 'Risk management', 'Analytics', 'Monitoring', 'SQL']",2025-06-13 05:35:20
Senior PySpark Data Engineer,Synechron,7 - 12 years,Not Disclosed,"['Pune', 'Hinjewadi']","Job Summary\nSynechron is seeking an experienced and technically proficient Senior PySpark Data Engineer to join our data engineering team. In this role, you will be responsible for developing, optimizing, and maintaining large-scale data processing solutions using PySpark. Your expertise will support our organizations efforts to leverage big data for actionable insights, enabling data-driven decision-making and strategic initiatives.\nSoftware Requirements\nRequired Skills:\nProficiency in PySpark\nFamiliarity with Hadoop ecosystem components (e.g., HDFS, Hive, Spark SQL)\nExperience with Linux/Unix operating systems\nData processing tools like Apache Kafka or similar streaming platforms\nPreferred Skills:\nExperience with cloud-based big data platforms (e.g., AWS EMR, Azure HDInsight)\nKnowledge of Python (beyond PySpark), Java or Scala relevant to big data applications\nFamiliarity with data orchestration tools (e.g., Apache Airflow, Luigi)\nOverall Responsibilities\nDesign, develop, and optimize scalable data processing pipelines using PySpark.\nCollaborate with data engineers, data scientists, and business analysts to understand data requirements and deliver solutions.\nImplement data transformations, aggregations, and extraction processes to support analytics and reporting.\nManage large datasets in distributed storage systems, ensuring data integrity, security, and performance.\nTroubleshoot and resolve performance issues within big data workflows.\nDocument data processes, architectures, and best practices to promote consistency and knowledge sharing.\nSupport data migration and integration efforts across varied platforms.\nStrategic Objectives:\nEnable efficient and reliable data processing to meet organizational analytics and reporting needs.\nMaintain high standards of data security, compliance, and operational durability.\nDrive continuous improvement in data workflows and infrastructure.\nPerformance Outcomes & Expectations:\nEfficient processing of large-scale data workloads with minimum downtime.\nClear, maintainable, and well-documented code.\nActive participation in team reviews, knowledge transfer, and innovation initiatives.\nTechnical Skills (By Category)\nProgramming Languages:\nRequired: PySpark (essential); Python (needed for scripting and automation)\nPreferred: Java, Scala\nDatabases/Data Management:\nRequired: Experience with distributed data storage (HDFS, S3, or similar) and data warehousing solutions (Hive, Snowflake)\nPreferred: Experience with NoSQL databases (Cassandra, HBase)\nCloud Technologies:\nRequired: Familiarity with deploying and managing big data solutions on cloud platforms such as AWS (EMR), Azure, or GCP\nPreferred: Cloud certifications\nFrameworks and Libraries:\nRequired: Spark SQL, Spark MLlib (basic familiarity)\nPreferred: Integration with streaming platforms (e.g., Kafka), data validation tools\nDevelopment Tools and Methodologies:\nRequired: Version control systems (e.g., Git), Agile/Scrum methodologies\nPreferred: CI/CD pipelines, containerization (Docker, Kubernetes)\nSecurity Protocols:\nOptional: Basic understanding of data security practices and compliance standards relevant to big data management\nExperience Requirements\nMinimum of 7+ years of experience in big data environments with hands-on PySpark development.\nProven ability to design and implement large-scale data pipelines.\nExperience working with cloud and on-premises big data architectures.\nPreference for candidates with domain-specific experience in finance, banking, or related sectors.\nCandidates with substantial related experience and strong technical skills in big data, even from different domains, are encouraged to apply.\nDay-to-Day Activities\nDevelop, test, and deploy PySpark data processing jobs to meet project specifications.\nCollaborate in multi-disciplinary teams during sprint planning, stand-ups, and code reviews.\nOptimize existing data pipelines for performance and scalability.\nMonitor data workflows, troubleshoot issues, and implement fixes.\nEngage with stakeholders to gather new data requirements, ensuring solutions are aligned with business needs.\nContribute to documentation, standards, and best practices for data engineering processes.\nSupport the onboarding of new data sources, including integration and validation.\nDecision-Making Authority & Responsibilities:\nIdentify performance bottlenecks and propose effective solutions.\nDecide on appropriate data processing approaches based on project requirements.\nEscalate issues that impact project timelines or data integrity.\nQualifications\nBachelors degree in Computer Science, Information Technology, or related field. Equivalent experience considered.\nRelevant certifications are preferred: Cloudera, Databricks, AWS Certified Data Analytics, or similar.\nCommitment to ongoing professional development in data engineering and big data technologies.\nDemonstrated ability to adapt to evolving data tools and frameworks.\nProfessional Competencies\nStrong analytical and problem-solving skills, with the ability to model complex data workflows.\nExcellent communication skills to articulate technical solutions to non-technical stakeholders.\nEffective teamwork and collaboration in a multidisciplinary environment.\nAdaptability to new technologies and emerging trends in big data.\nAbility to prioritize tasks effectively and manage time in fast-paced projects.\nInnovation mindset, actively seeking ways to improve data infrastructure and processes.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['PySpark', 'S3', 'Unix operating systems', 'Spark SQL', 'Luigi', 'HDFS', 'AWS EMR', 'Apache Airflow', 'Hive', 'Linux', 'Azure HDInsight', 'Apache Kafka', 'AWS']",2025-06-13 05:35:21
Data Techology Senior Associate,MSCI Services,4 - 8 years,Not Disclosed,['Pune'],"As data engineers, we build scalable systems to process data in various formats and volumes, ranging from megabytes to terabytes. Our systems perform quality checks, match data across various sources, and release it in multiple formats. We leverage the latest technologies, sources, and tools to process the data. Some of the exciting technologies we work with include Snowflake, Databricks, and Apache Spark.\nYour skills and experience that will help you excel\nCore Java, Spring Boot, Apache Spark, Spring Batch, Python. Exposure to sql databases like Oracle, Mysql, Microsoft Sql is a must. Any experience / knowledge / certification on Cloud technology preferrably Microsoft Azure or Google cloud platform is good to have. Exposures to non sql databases like Neo4j or Document database is again good to have.\n  What we offer you\nTransparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall we'llbeing.\nFlexible working arrangements, advanced technology, and collaborative workspaces.\nA culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\nA global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\nGlobal Orientation program to kickstart your journey, followe'd by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\nMulti-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\nWe actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women s Leadership Forum.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['CVS', 'Core Java', 'Bloomberg', 'spring batch', 'MySQL', 'Oracle', 'Analytics', 'Downstream', 'Python', 'Recruitment']",2025-06-13 05:35:23
Senior - AWS Data Engineering,KPMG India,4 - 8 years,Not Disclosed,['Gurugram'],"KPMG India is looking for Senior - AWS Data Engineering to join our dynamic team and embark on a rewarding career journey Designs and builds scalable data pipelines using AWS servicesOptimizes data ingestion, storage, and processingCollaborates with data scientists and analystsEnsures performance, security, and compliance",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Networking', 'Focus', 'Manager Technology', 'professional services', 'AWS', 'international clients']",2025-06-13 05:35:25
Senior Data Engineer - Azure,Blend360 India,6 - 11 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Senior Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n5+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fie",Industry Type: Advertising & Marketing,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-13 05:35:27
Senior Data Engineer - Azure,Blend360 India,6 - 11 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Senior Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Access control', 'Data analysis', 'Team leading', 'Architecture', 'Analytical', 'Agile', 'data governance', 'Data processing', 'Mentor', 'Data quality']",2025-06-13 05:35:28
Senior Data Engineer - Azure,Blend360 India,3 - 6 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n3+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-13 05:35:30
Senior Data Engineer - AWS,Blend360 India,5 - 10 years,Not Disclosed,['Hyderabad'],"Job Description\nWe are looking for an experienced Senior Data Engineer with a strong foundation in Python, SQL, and Spark , and hands-on expertise in AWS, Databricks . In this role, you will build and maintain scalable data pipelines and architecture to support analytics, data science, and business intelligence initiatives. You ll work closely with cross-functional teams to drive data reliability, quality, and performance.\nResponsibilities:\nDesign, develop, and optimize scalable data pipelines using Databricks in AWS such as Glue, S3, Lambda, EMR, Databricks notebooks, workflows and jobs.\nBuilding data lake in WS Databricks.\nBuild and maintain robust ETL/ELT workflows using Python and SQL to handle structured and semi-structured data.\nDevelop distributed data processing solutions using Apache Spark or PySpark .\nPartner with data scientists and analysts to provide high-quality, accessible, and well-structured data.\nEnsure data quality, governance, security, and compliance across pipelines and data stores.\nMonitor, troubleshoot, and improve the performance of data systems and pipelines.\nParticipate in code reviews and help establish engineering best practices.\nMentor junior data engineers and support their technical development.\n\n\nQualifications\nRequirements\nBachelors or masters degree in computer science, Engineering, or a related field.\n5+ years of hands-on experience in data",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Version control', 'GIT', 'Workflow', 'Data quality', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-13 05:35:32
Sales Operations & Data Analytics- Sr. Associate,GEP,2 - 6 years,Not Disclosed,['Navi Mumbai'],"Overview\nGEP is a diverse, creative team of people passionate about procurement. We invest ourselves entirely in our client’s success, creating strong collaborative relationships that deliver extraordinary value year after year. Our clients include market global leaders with far-flung international operations, Fortune 500 and Global 2000 enterprises, leading government and public institutions. \n We deliver practical, effective services and software that enable procurement leaders to maximise their impact on business operations, strategy and financial performance. That’s just some of the things that we do in our quest to build a beautiful company, enjoy the journey and make a difference. GEP is a place where individuality is prized, and talent respected. We’re focused on what is real and effective. GEP is where good ideas and great people are recognized, results matter, and ability and hard work drive achievements. We’re a learning organization, actively looking for people to help shape, grow and continually improve us.",,,,"['crm systems', 'project management', 'data analytics', 'oracle', 'data analysis', 'bi', 'power bi', 'business analysis', 'dashboards', 'sql', 'plsql', 'power query', 'sales operations', 'salesforce', 'analytics', 'excel', 'advanced excel', 'collaboration', 'data governance', 'hubspot', 'powerpoint', 'communication skills', 'crm']",2025-06-13 05:35:34
Data Techology Senior Associate,MSCI Services,4 - 7 years,Not Disclosed,['Pune'],"Overview\nThe Data Technology team at MSCI is responsible for meeting the data requirements across various business areas, including Index, Analytics, and Sustainability. Our team collates data from multiple sources such as vendors (e.g., Bloomberg, Reuters), website acquisitions, and web scraping (e.g., financial news sites, company websites, exchange websites, filings). This data can be in structured or semi-structured formats. We normalize the data, perform quality checks, assign internal identifiers, and release it to downstream applications.\nResponsibilities\nAs data engineers, we build scalable systems to process data in various formats and volumes, ranging from megabytes to terabytes. Our systems perform quality checks, match data across various sources, and release it in multiple formats. We leverage the latest technologies, sources, and tools to process the data. Some of the exciting technologies we work with include Snowflake, Databricks, and Apache Spark.\nQualifications\nCore Java, Spring Boot, Apache Spark, Spring Batch, Python. Exposure to sql databases like Oracle, Mysql, Microsoft Sql is a must. Any experience/knowledge/certification on Cloud technology preferrably Microsoft Azure or Google cloud platform is good to have. Exposures to non sql databases like Neo4j or Document database is again good to have.\n What we offer you\nTransparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\nFlexible working arrangements, advanced technology, and collaborative workspaces.\nA culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\nA global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\nGlobal Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\nMulti-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\nWe actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women’s Leadership Forum.\nAt MSCI we are passionate about what we do, and we are inspired by our purpose – to power better investment decisions. You’ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n To all recruitment agencies\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n Note on recruitment scams\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['hive', 'access', 'scala', 'pyspark', 'data warehousing', 'hibernate', 'research', 'sql', 'analytics', 'spring', 'java', 'spring batch', 'spark', 'gcp', 'mysql', 'html', 'hadoop', 'big data', 'etl', 'snowflake', 'python', 'oracle', 'data analysis', 'microsoft azure', 'power bi', 'sql server', 'javascript', 'data bricks', 'spring boot', 'tableau', 'neo4j', 'aws', 'sql database']",2025-06-13 05:35:35
Data Engineer KL-BL,Puresoftware,5 - 12 years,Not Disclosed,['Bengaluru'],"Core Competences Required and Desired Attributes:\nBachelors degree in computer science, Information Technology, or a related field.\nProficiency in Azure Data Factory, Azure Databricks and Unity Catalog, Azure SQL Database, and other Azure data services.\nStrong programming skills in SQL, Python and PySpark languages.\nExperience in the Asset Management domain would be preferable.\nStrong proficiency in data analysis and data modelling, with the ability to extract insights from complex data sets.\nHands-on experience in Power BI, including creating custom visuals, DAX expressions, and data modelling.\nFamiliarity with Azure Analysis Services, data modelling techniques, and optimization.\nExperience with data quality and data governance frameworks with an ability to debug, fine tune and optimise large scale data processing jobs.\nStrong analytical and problem-solving skills, with a keen eye for detail.\nExcellent communication and interpersonal skills, with the ability to work collaboratively in a team environment.\nProactive and self-motivated, with the ability to manage multiple tasks and deliver high-quality results within deadlines.",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Interpersonal skills', 'Data modeling', 'Analytical', 'data governance', 'Data quality', 'Asset management', 'Information technology', 'SQL', 'Python']",2025-06-13 05:35:37
Senior BI Analyst - Tableau Expert,BMC Software,7 - 12 years,Not Disclosed,['Pune'],"BU Description:\nOur Analytics and Automation team is at the forefront of leveraging data-driven insights to enhance business performance across sales, marketing, product development, and VSE. We specialize in harnessing advanced analytics and automation techniques to provide actionable intelligence, drive efficiency, and foster innovation. Our commitment to excellence ensures that we deliver impactful solutions that propel our organization's strategic goals forward.\n\nAbout You:\n\nYou like to develop, design, and deliver data visualization solutions that deliver sustained business value from our and associated solutions\nYou enjoy working cross-functionally across Sales, Marketing, Operations, and IT organizations for supporting the customer success organization\nYou re a team player and believe in building synergies across BMC to create/continually evolve one integrated customer journey.\nYou like to innovate, and have a passion for solving business problems, to continuously improve our quality of service\nYou have a passion for development, and challenge yourself to learn new things\nYou know how to have fun and connect with people.\n\nKey Responsibility/Role Expectations:\n\nThe Senior BI Analyst supports senior leadership by providing data-driven insights and analytics, enabling informed decision-making, and driving strategic initiatives to enhance customer success and align with business objectives. You should be responsible to\n\nDesign, develop, and maintain advanced and interactive Tableau dashboards to provide actionable insights into customer success metrics.\nAnalyze customer behavior, trends, and performance metrics to identify actionable opportunities for improvement.\nMonitor key customer success indicators (e.g., retention, churn, satisfaction) and provide insights to drive enhanced customer engagement and satisfaction.\nCreate visually compelling and interactive reports tailored for senior leadership to support data-driven strategic decision-making.\nCollaborate with cross-functional teams, including Customer Success, Product, and Support, to gather requirements and deliver tailored BI solutions.\nIntegrate data from multiple sources (e.g., CRM systems like Salesforce, support tools, and internal databases) to create a unified view of performance.\nProvide data-driven recommendations to senior leadership to align customer success efforts with organizational objectives.\nIdentify and report on key trends and anomalies in customer success data, proactively addressing potential challenges.\nDevelop and implement automated workflows for reporting and analytics to enhance efficiency and reduce manual effort.\nStay updated on Tableau and broader BI trends, implementing best practices in data visualization and analysis.\n\nProfessional Experience:\n\nMinimum of 7+ years of experience in Business Intelligence and data analysis.\nExpert proficiency in Tableau, with demonstrated ability to build advanced visualizations.\nStrong understanding of relational databases with expertise in advanced SQL writing.\nProven ability to extract and analyze data from sources such as Snowflake, Excel, CSV, and text files.\nProficient knowledge of Salesforce.com, with experience in CRM data analysis and integration.\nAdvanced skills in Excel, PowerPoint, and Word for creating reports and presentations.\nStrong analytical skills to critically evaluate data, reconcile discrepancies, and ensure accuracy.\nAbility to translate user requirements into technical solutions and design effective BI implementations.\nExcellent organizational skills, with the ability to manage multiple complex projects in a fast-paced, dynamic environment.\nSelf-motivated, detail-oriented, and able to deliver quality outcomes under tight deadlines.\nStrong communication and presentation skills to effectively collaborate with stakeholders, including senior leaders such as Sr. Directors and VPs.\nDemonstrated ability to influence and build long-term relationships with cross-functional teams and business partners.\nExperience mentoring and training team members on technical skills and BI best practices.\nQuick learner, adaptable to changing tools, environments, and priorities.\nCustomer-oriented mindset, with a proven ability to partner with stakeholders to achieve shared business goals.\nFamiliarity with programming languages like Python or R, cloud-based platforms like AWS are a plus.\nBasic understanding of machine learning concepts and predictive analytics is a bonus.\n\nEducation\n\nBachelor s or master s degree in computer science, Information Systems, or a related field (Advanced degree preferred).",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Tableau', 'salesforce', 'python', 'data analysis', 'predictive analytics', 'presentation skills', 'relational databases', 'machine learning', 'business intelligence', 'sql']",2025-06-13 05:35:39
Senior Data Scientist,Cradlepoint,3 - 8 years,Not Disclosed,['Bengaluru'],"Join our Team\nAbout this Opportunity\nThe complexity of running and optimizing the next generation of wireless networks, such as 5G with distributed edge compute, will require Machine Learning (ML) and Artificial Intelligence (AI) technologies. Ericsson is setting up an AI Accelerator Hub in India to fast-track our strategy execution, using Machine Intelligence (MI) to drive thought leadership, automate, and transform Ericsson s offerings and operations. We collaborate with academia and industry to develop state-of-the-art solutions that simplify and automate processes, creating new value through data insights.\nWhat you will do\nAs a Senior Data Scientist, you will apply your knowledge of data science and ML tools backed with strong programming skills to solve real-world problems.\nResponsibilities:\n1. Lead AI/ML features/capabilities in product/business areas\n2. Define business metrics of success for AI/ML projects and translate them into model metrics\n3. Lead end-to-end development and deployment of Generative AI solutions for enterprise use cases\n4. Design and implement architectures for vector search, embedding models, and RAG systems\n5. Fine-tune and evaluate large language models (LLMs) for domain-specific tasks\n6. Collaborate with stakeholders to translate vague problems into concrete Generative AI use cases\n7. Develop and deploy generative AI solutions using AWS services such as SageMaker, Bedrock, and other AWS AI tools. Provide technical expertise and guidance on implementing GenAI models and best practices within the AWS ecosystem.\n8. Develop secure, scalable, and production-grade AI pipelines\n9. Ensure ethical and responsible AI practices\n10. Mentor junior team members in GenAI frameworks and best practices\n11. Stay current with research and industry trends in Generative AI and apply cutting-edge techniques\n12. Contribute to internal AI governance, tooling frameworks, and reusable components\n13. Work with large datasets including petabytes of 4G/5G networks and IoT data\n14. Propose/select/test predictive models and other ML systems\n15. Define visualization and dashboarding requirements with business stakeholders\n16. Build proof-of-concepts for business opportunities using AI/ML\n17. Lead functional and technical analysis to define AI/ML-driven business opportunities\n18. Work with multiple data sources and apply the right feature engineering to AI models\n19. Lead studies and creative usage of new/existing data sources\nWhat you will bring\n1. Bachelors/Masters/Ph.D. in Computer Science, Data Science, AI, ML, Electrical Engineering, or related disciplines from reputed institutes\n2. 3+ years of applied ML/AI production-level experience\n3. Strong programming skills (R/Python)\n4. Proven ability to lead AI/ML projects end-to-end\n5. Strong grounding in mathematics, probability, and statistics\n6. Hands-on experience with data analysis, visualization techniques, and ML frameworks (Python, R, H2O, Keras, TensorFlow, Spark ML)\n7. Experience with semi-structured/unstructured data for AI/ML models\n8. Strong understanding of building AI models using Deep Neural Networks\n9. Experience with Big Data technologies (Hadoop, Cassandra)\n10. Ability to source and combine data from multiple sources for ML models\nPreferred Qualifications:\n1. Good communication skills in English\n2. Certifying MI MOOCs, a plus\n3. Domain knowledge in Telecommunication/IoT, a plus\n4. Experience with data visualization and dashboard creation, a plus\n5. Knowledge of Cognitive models, a plus\n6. Experience in partnering and collaborative co-creation in a global matrix organization.\nWhy join Ericsson\n\n\nWhat happens once you apply\nPrimary country and city: India (IN) || Bangalore\nReq ID: 766481",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Wireless', 'Computer science', 'Data analysis', 'cassandra', 'Neural networks', 'Artificial Intelligence', 'Machine learning', 'Telecommunication', 'data visualization', 'Python']",2025-06-13 05:35:41
Mis Executive,Connected Value Health Solutions,1 - 3 years,Not Disclosed,['Coimbatore'],"Job Title: MIS Executive\n\nJob Location: Coimbatore\n\nJob Summary:\n\nThe MIS Executive will be responsible for the efficient handling, analysis, and presentation of data using advanced Excel and PowerPoint skills. The role requires a detail-oriented individual capable of generating insightful reports, dashboards, and presentations that support decision-making processes within the organization.\n\nResponsibilities:\n\nData Management:\nCollect, organize, and maintain large datasets from various sources.\nClean and validate data to ensure accuracy, consistency, and completeness.\nCreate and manage databases or spreadsheets for storing data securely.\n\nReporting & Analysis:\nDevelop and maintain daily, weekly, and monthly reports that provide actionable insights.\nAnalyse data trends and create statistical models to support business decisions.\nAutomate repetitive reporting tasks using Excel functions, macros, and VBA (Visual Basic for Applications).\n\nDashboard Creation:\nDesign and develop interactive dashboards in Excel to visualise key performance indicators (KPIs).\nImplement formulas, pivot tables, and conditional formatting to enhance data readability.\n\nPresentation Development:\nCreate professional and visually appealing PowerPoint presentations that summarize key findings.\nCollaborate with various departments to gather information and data for presentations.\nEnsure presentations align with the organizations branding and communication guidelines.\n\nProcess Improvement:\nIdentify opportunities to streamline data collection and reporting processes.\nImplement best practices for data management and reporting to improve efficiency and accuracy.\n\nSupport & Training:\nProvide support and training to team members on Excel and PowerPoint usage.\nTroubleshoot issues related to data, reports, and presentations.\n\nQualifications:\nBachelor’s degree in computer science, Information Technology, Business Administration, or a related field.\n\nExperience:\n2-4 years of experience in a similar role, with a strong emphasis on data analysis, Excel, and PowerPoint.\nExperience with VBA (Visual Basic for Applications) is a plus.\n\nPreferred Qualifications:\nAdvanced proficiency in Microsoft Excel (formulas, pivot tables, macros).\nProficient in Microsoft PowerPoint, with a focus on creating executive-level presentations.\nStrong analytical and problem-solving skills.\nAttention to detail and a high level of accuracy.\nExcellent communication and interpersonal skills.\nAbility to work independently and as part of a team.\n\nWorking Conditions:\nNight Shift or afternoon shifts (as per business requirements).\nAbility to commute/relocate to Coimbatore.\nThis position involves working from the office only. It may require occasional extension of work or weekend work to accommodate the client requests.",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Management Information System', 'Pivot Table', 'Visual Basic Application', 'Excel Dashboards', 'VLOOKUP', 'Data Analysis', 'Data Analytics', 'HLOOKUP', 'Information System']",2025-06-13 05:35:43
Senior Data Scientist - AI/ML,Inumellas Consultancy Services,9 - 14 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Role - Senior Data Scientist / Senior Gen AI Engineer\nExp Range - 8 to 18 yrs\nPosition - Permanent Fulltime\nCompany - Data Analytics & AIML MNC\nLocation - Hyderabad, Pune, Bangalore (Relocation accepted)\nAbout the Role:\n\nWe are seeking a Software Engineer with expertise in Generative AI and Microsoft technologies to design, develop, and deploy AI-powered solutions using the Microsoft ecosystem. You will work with cross-functional teams to build scalable applications leveraging generative AI models and Azure services.\n\nSkills Required:\n\nExperience with Large Language Models (LLMs) like GPT, LLaMA, Claude, etc.\nProficiency in Python for building and fine-tuning AI/ML models\nFamiliarity with LangChain, LLMOps, or RAG (Retrieval-Augmented Generation) pipelines\nExperience with Vector Databases (e.g. FAISS, Pinecone, Weaviate)\nKnowledge of Prompt Engineering and model evaluation techniques\nExposure to cloud platforms (Azure, AWS or GCP) for deploying GenAI solutions\n\nPreferred Skills:\n\nExperience with Azure OpenAI, Databricks or Microsoft Fabric\nHands-on with Hugging Face Transformers, OpenAI APIs or custom model training",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Deep Learning', 'Prompt Engineering', 'Large Language Model', 'Vector Database', 'Retrieval Augmented Generation', 'GenAI', 'Langchain', 'Artificial Intelligence', 'LLMOps', 'LLaMa', 'GPT', 'Azure OpenAI', 'Machine Learning', 'ML Models', 'Model Evaluation', 'Huggingface', 'Aiml', 'OpenAI', 'Azure Machine Learning', 'Python']",2025-06-13 05:35:45
Senior Data Scientist,eka.care,3 - 5 years,Not Disclosed,['Bengaluru'],"EkaCare (Orbi Health) is a well-funded startup working on a suite of technologies in the healthcare domain ranging from AI-powered EMR for doctors to one of the most comprehensive personal health record (PHR) applications for consumers. EkaCare seeks enthusiastic senior candidates to develop Large Language Models around medical/clinical data.\n\nWe look forward to a candidate with\nPassion for problem-solving and taking end-to-end ownership of projects\nExtensive knowledge and prior work experience in machine learning (specifically in developing LLMs)\nDesire for a high-paced start-up ride\n\nKey Responsibilities :\nFormulate and implement data-driven solutions in the HealthTech domain:\nBuilding LLMs around healthcare data, wherein the work would involve creating datasets, continual pre-training, supervised fine-tuning, and preference alignment of models.\nDeveloping product-led AI solutions for various healthcare entities.\n\nQualifications / Requirements\nMaster / PhD degree in a relevant academic discipline (Preferred)\n3-5 years of industry experience in building ML production-level pipelines.\nExtensive experience with LLMs (production-level deployment and fine-tuning)\nStrong track record of project delivery\n\nExperience Required: 3-5 years\n\nFull Time Employee Benefits:\nInsurance Benefits - Medical Insurance, Accidental Insurance\nParental Support - Maternity Benefit, Paternity Benefit Program\nMobility Benefits - Relocation benefits, Transfer Support Policy, Travel Policy\nRetirement Benefits - Employee PF Contribution, Flexible PF Contribution, Gratuity, NPS, Leave Encashment\nOther Benefits - Car Lease, Salary Advance Policy",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Training', 'Machine learning', 'Leasing', 'Healthcare', 'Deployment', 'Medical insurance', 'Project delivery', 'Supervision', 'clinical data']",2025-06-13 05:35:47
Senior Data Scientist,Hindustan Unilever (HUL),2 - 5 years,Not Disclosed,['Bengaluru'],"Job Title: Senior Data Scientist\nLocation: Bangalore\nJob Title: Assistant Manager - Security Engineering\nLocation: UniOps Bangalore\nABOUT UNILEVER:\nEvery individual here can bring their purpose to life through their work. Join us and you ll be surrounded by inspiring leaders and supportive peers. Among them, you ll channel your purpose, bring fresh ideas to the table, and simply be you. As you work to make a real impact on the business and the world, we ll work to help you become a better you.\nABOUT UNIOPS:\nUnilever Operations (UniOps) is the global technology and operations engine of Unilever offering business services, technology, and enterprise solutions. UniOps serves over 190 locations and through a network of specialized service lines and partners delivers insights and innovations, user experiences and end-to-end seamless delivery making Unilever Purpose Led and Future Fit\nBackground\nFor Unilever to remain competitive in the future, the business needs to continue on the path to become data intelligent. The Data Analytics team will persevere to make Unilever Data Intelligent, powering key decisions with data, insights, advanced analytics and AI. Our ambition is to enable democratization of data, information and insights as a completely agile organization that builds fantastic careers for our people and is accountable for delivering great work that maximizes impact and delivers growth.\nThis Data Analytics function endeavours to create clear accountability for all aspects of Data Strategy, Data Management, Information Management, Analytics, and Insights. We are accountable for impact of solutions, maintaining market relevance and minimising unnecessary overlaps in analytics products, ensuring simplicity and that our solutions better meet the needs of our users. We partner with the Digital and Data Legal Counsel to ensure that our Data Defence (Privacy, Governance, Quality, etc) is well structured and sufficiently robust to use data and AI correctly throughout the enterprise. We democratize information across the business, while supporting the culture shift required for data driven decision making.\nOur vision is to make Unilever data intelligent, partnering with the business to power key decisions with data, advanced analytics and AI to accelerate growth. Our 5 strategies to achieve this are:\nAccelerate simplify access to relevant data, information and insights Build in-house, leading-edge data, information, insights analytics capability Lead the data insights culture and careers to empower employees across Unilever Rapidly embed analytics products, solutions and services to drive growth Advance Information Automation at Scale\nThe Senior Data Scientist is an exciting role in the Data Foundation. This team builds state of the art machine learning algorithms, maximising the impact of analytic solutions in driving enterprise performance. Typical initiatives include optimizing trade promotion investments, accurately forecasting customer demand, using NLP to glean insight on consumer trends from search data, and making individual assortment recommendations for each of the millions of stores that sell Unilever products.\nMain Purpose of the Job:\nThe Senior Data Scientist improves business performance in the functional area of Unilever they serve, through the application of world class data science capability. They own delivery of data science on moderate projects or specific modules of a major global initiative.\nKey accountabilities:\nInteract with relevant teams to identify business challenges where data science can help\nApply comprehensive data science knowledge to propose optimal techniques for key business challenges\nCreate detailed data science proposals and project plans, flagging any limitations of proposed solution\nDesign and prototype experimental solutions, particularly machine learning models\nDesign scaled solutions and ensure high quality and timely delivery\nFacilitate industrialization and ongoing operation of solutions through well organised code, clear documentation and collaboration with ML Ops resources\nGovern the work of 3rd party vendors where needed to support delivery, while maximising creation of Unilever IP\nRepresent Data Science in cross-functional governance of projects, engaging with stakeholders up to Director level\nHighlight recent developments in data science capability which could solve additional challenges\nLead a team of up 1-2 data scientists / interns, providing career mentorship and line management\nProvide technical guidance to data scientists across DA, particularly on the projects you lead\nSupport the growth of DA s data science capability by contributing to activities such as tool and vendor selection, best practice definition, recruitment, and creation of training materials\nBuild the reputation of DA s data science capability within Unilever and externally, through activities such as community engagement (e. g. Yammer), publications or blogs\nProvide ad-hoc immediate support to the business when needed (for example Covid-19 crisis support)\nDepending on the specific project, the Senior Data Scientist can expect 60-90% of their work to be hands-on prototyping solutions, with the remainder spent planning and designing, overseeing and reviewing work of project staff, interfacing with stakeholders and managing team members.\nExperience and qualifications required:\nStandards of Leadership Required in This Role\nPersonal Mastery (Data-science and advanced analytics)\nAgility\nBusiness acumen\nPassion for High Performance\nKey Skills Required\nProfessional Skills\nMachine learning - Expert\nStatistical modelling - Expert\nForecasting - Expert\nOptimisation techniques and tools - Fully Operational\nPython coding - Fully Operational\nData science platform tools e. g. MS Azure, Databricks - Fully Operational\nDeep learning (and applications to NLP Computer Vision) - Fully Operational\nCollaborative development using Git repos - Fully Operational\nAutomated Machine Learning platforms - Foundational knowledge\nWhile a broad data science technical background is required, the role will benefit from deeper skills (for example graduate studies or prior work experience) in one of the following areas, optimization, simulation, forecasting, natural language processing, computer vision or geospatial analysis.\nGeneral Skills\nProject Management - Expert\nCommunication / presentation skills - Expert\n3rd party resource management - Expert\nCPG Industry analytics - Expert\nStrong communication and stakeholder engagement skills are essential, including the ability to influence peers and senior business stakeholders across Unilever.\nRelevant Experience:\nMinimum of B. E. in a relevant technical field (e. g. Computer Science, Engineering, Statistics, Operations Research); preferably a postgraduate (Masters or Doctorate) degree\nAt least 4 years building data science solutions to solve business problems, preferably in the CPG industry (less experience may be acceptable if balanced by strong post-grad qualifications)\nExperience with open source languages (eg. Python) and preferably with distributed computing (PySpark)\nExperience deploying solutions in a modern cloud-based architecture\nExperience managing the work of team members and 3rd party resource vendors\nExperience presenting insights and influencing decisions of senior non-technical stakeholders\nKey interfaces\nInternal\nUnilever operational, marketing, customer development, supply chain, product finance teams\nInternal DA teams (Engagement teams; Data CoE; Solution Factory; BDL Factory; Information Factory; Tech Transformation)\nWider Unilever analytics and data science professionals\nExternal\n3rd party Data Science vendors\nUniversities\nIndustry bodies",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Operations research', 'Automation', 'data science', 'Data management', 'Project management', 'Information management', 'Resource management', 'Forecasting', 'Recruitment']",2025-06-13 05:35:49
Senior Data Scientist with GCP,TVS Next,5 - 7 years,Not Disclosed,['Bengaluru'],"What you’ll do:\nUtilize advanced mathematical, statistical, and analytical expertise to research, collect, analyze, and interpret large datasets from internal and external sources to provide insight and develop data driven solutions across the company\nBuild and test predictive models including but not limited to credit risk, fraud, response, and offer acceptance propensity\nResponsible for the development, testing, validation, tracking, and performance enhancement of statistical models and other BI reporting tools leading to new innovative origination strategies within marketing, sales, finance, and underwriting",,,,"['analytical', 'scikit-learn', 'searching', 'bi', 'pyspark', 'numpy', 'sql', 'analytics', 'apache', 'automation', 'data science', 'spark', 'gcp', 'bigquery', 'data visualization', 'xgboost', 'programming', 'reporting', 'ml', 'advanced analytics', 'python', 'data processing', 'predictive', 'jupyter notebook', 'bert', 'pandas', 'matplotlib', 'statistics']",2025-06-13 05:35:51
Sr Data Scientist,Gartner for HR,7 - 10 years,Not Disclosed,['Gurugram'],"The Senior Data Scientist in the Interaction Insights team will help in generating actionable insights for driving the creation of fact-based research from client interactions and other Gartner internal and external data assets. At the core we are looking for a person who is passionate about learning new technologies, text analytics, digging into rows of unstructured data, drawing recommendations & actionable insights, and using creative ways to visualize & interpret it for research. This person will have a flair of innovation along with a strong experience in Python, Data Science, NLP, Machine Learning, Deep Learning, LLMs and the analysis of unstructured data. They would be working closely with various stakeholders to explore opportunities to optimize data mining techniques and improve the accuracy of insights generated using NLP or various types of Machine Learning/Deep Learning/LLM models.\n  What you will do:\nExecute large-scale, high-impact data science projects, translating research objectives into actionable data and insights from both internal and external data assets\nProvide ad hoc modeling and analytical insights to inform strategic and operational initiatives\nAnalyze unstructured text data to discover insights and patterns using advanced data science techniques, including machine learning (ML) and natural language processing (NLP)\nInterpret data-driven patterns and insights in alignment with original business objectives\nAddress critical business challenges by leveraging data science, ML, and NLP methodologies\nInteract with internal and external stakeholders to refine and enhance findings\nCollaborate as part of a team in a fast-paced environment, meeting strict SLAs and turnaround times\nDevelop a deep understanding of the technology industry and maintain expertise in the data science domain\nEnsure delivery of high-quality data science solutions with a focus on accuracy and coverage\nBe accountable for the scalability, stability, and business adoption of data science solutions\nMaintain proper documentation and adhere to code reusability and best practices\nTake ownership of algorithms, including their ongoing enhancement and optimization to meet evolving business requirements\nStay current with advancements in AI/ML models and technologies, and apply disruptive data science solutions as appropriate.\nCollaborate with engineering and product teams to launch MVPs and iterate quickly based on feedback\nIndependently plan, drive and execute data science projects that deliver clear and measurable business value\nWhat you will need:\nEducation - masters in engineering, Computer Science, Computer Applications, Statistics, Mathematics, Applied Mathematics, Computer Science with focus on AI or Data Science; BE/BTech or Bachelors (Comp. Sc./AI) with relevant experience\nTotal experience - 7 to 10 years of which 5+ yrs as hands-on Data Science, AI/ML experience on real-world industry problems, with focus on Text Mining and Natural Language Processing/text analytics\nAdvanced proficiency in Python and SQL, with experience using key data science libraries and tools (eg, Pandas, Numpy, scikit-learn, TensorFlow, PyTorch, Spacy, NLTK, Scipy)\nHands-on experience with machine learning, deep learning, NLP (including LLMs/GenAI), and applying these models to real-world business problems\nStrong background in data preparation, including cleaning, normalization, and handling unstructured text data for modeling\nExperience with cloud computing platforms such as AWS or Azure for model training, testing, and deployment\nFamiliarity with both relational (eg, Oracle) and NoSQL databases (eg, MongoDB, graph databases), as we'll as distributed computing frameworks like Spark\nProficiency in best coding practices and code/repo management using GitHub or Bitbucket\nBasic skills in Power BI, Excel, and PowerPoint\nStrong analytical, critical thinking, and problem-solving skills, with the ability to extract insights from complex and unstructured datasets\nDemonstrated ability to collaborate across product, engineering, and data science teams, and to influence stakeholders at all levels\nExcellent communication skills in both technical and business contexts\nSelf-motivated, eager to learn, adaptable to feedback, and comfortable working in a fast-paced, milestone-driven environment\nWhat you will get:\nCompetitive salary, generous paid time off policy, charity match program, Group Medical Insurance, Parental Leave, Employee Assistance Program (EAP) and more!\nCollaborative, team-oriented culture that embraces diversity\nProfessional development and unlimited growth opportunities",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Excel', 'Coding', 'Analytical', 'power bi', 'Powerpoint', 'Oracle', 'Data mining', 'SQL', 'Recruitment']",2025-06-13 05:35:53
Senior Data Scientist,Toast,6 - 11 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist - S&A\nNow, more than ever, the Toast team is committed to our customers. We re taking steps to help restaurants navigate these unprecedented times with technology, resources, and community. We focus on building the restaurant platform that helps restaurants adapt, take control, and get back to what they do best: building the businesses they love. And because our technology is purpose-built for restaurants, by restaurant people, restaurants can trust that we ll deliver on their needs for today while investing in experiences that will power their restaurant of the future.\nBready*\nto make a change?\n\nAs the Senior Data Scientist in our Bangalore Data Science team, you will contribute to building machine learning algorithms using our huge reservoir of point of sale transaction data. You will work with architects, engineers and product managers to solve business and customer problems and turn machine learning models into business impact across product lines, including financial processing and fraud.\nAbout this\nRoll*\n:\nDesign, build, train and evaluate machine learning models to drive business value for Toast and our restaurant customers\nCollaborate closely with internal and external product stakeholders, both technical and non-technical and help translate deep machine learning knowledge to product applications\nBreak down larger ML initiatives into smaller problems that enables data science to deliver incremental business value and lead the team to execute on them\nWork closely with Production Engineering and Data Platform teams to deploy models to production and regularly monitor for efficiency, key KPIs and enhance them as needed\nWork with incident response and problem resolution teams to check and resolve any problems/challenges as and when identified in the model deployed in the production\nEffectively document all steps and manage code repositories for easy scalability and knowledge sharing with the the team\nIncorporate up-to-date ML technology and DS approach as best practice for the team\nHelp in continuing to build out and expand the Data Science and ML Engineering teams\nWork effectively in a dynamic, changing environment while focusing on key goals and objectives\nDo you have the right\ningredients*\n?\nAdvanced degree in Data Science, Statistics, Applied Math, Computer Science, Engineering or other equivalent quantitative disciplines\n6 + years of industry experience in the field of Data Science and Machine Learning\nExperience in time series modelling. Familiarity with ARIMA, SARIMA, ETS, VAR models. Familiarity with forecasting tools like Facebook Prophet, GluonTS, or NeuralProphet.\nStrong proficiency in Python and SQL; experience with some of the following languages, tools, and frameworks: R, Spark, Scala, scikit-learn, Tensorflow, PyTorch, etc.\nFamiliarity with standard software engineering practices and tools including object-oriented programming, test-driven development, CI/CD, git, shell scripting, task orchestration (Airflow, Luigi, etc.) and preferably AWS tooling (Sagemaker, DynamoDB, ECS, etc.)\nStrong knowledge of underlying mathematical foundations of statistics and machine learning\nPrior success deploying machine learning solutions in large-scale production environments\nExperience collaborating with cross-functional teams and stakeholders to evaluate new Machine Learning opportunities\nProblem solver who loves to dig into different kinds of data and can communicate their findings to cross-functional stakeholders\nBonus\ningredients*\n:\nPassion for research and curiosity that calls you to go beyond good enough to create something innovative and exciting\nDiversity, Equity, and Inclusion is Baked into our Recipe for Success\nAt Toast, our employees are our secret ingredient when they thrive, we thrive. The restaurant industry is one of the most diverse, and we embrace that diversity with authenticity, inclusivity, respect, and humility. By embedding these principles into our culture and design, we create equitable opportunities for all and raise the bar in delivering exceptional experiences.\nWe Thrive Together\nWe embrace a hybrid work model that fosters in-person collaboration while valuing individual needs. Our goal is to build a strong culture of connection as we work together to empower the restaurant community. To learn more about how we work globally and regionally, check out: https: / / careers.toasttab.com / locations-toast .\nApply today!\nToast is committed to creating an accessible and inclusive hiring process. As part of this commitment, we strive to provide reasonable accommodations for persons with disabilities to enable them to access the hiring process. If you need an accommodation to access the job application or interview process, please contact .\n------\nFor roles in the United States, It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'orchestration', 'data science', 'Production engineering', 'Machine learning', 'Shell scripting', 'test driven development', 'Forecasting', 'SQL', 'Python']",2025-06-13 05:35:54
Senior Data Scientist,Epsilon,6 - 9 years,Not Disclosed,['Bengaluru'],"Responsibilities: -\nContribute and build an internal product library that is focused on solving business problems related to prediction & recommendation.\nResearch unfamiliar methodologies, techniques to fine tune existing models in the product suite and, recommend better solutions and/or technologies.\nImprove features of the product to include newer machine learning algorithms in the likes of product recommendation, real time predictions, fraud detection, offer personalization etc\nCollaborate with client teams to on-board data, build models and score predictions.\nParticipate in building automations and standalone applications around machine learning algorithms to enable a One Click solution to getting predictions and recommendations.\nAnalyze large datasets, perform data wrangling operations, apply statistical treatments to filter and fine tune input data, engineer new features and eventually aid the process of building machine learning models.\nRun test cases to tune existing models for performance, check criteria and define thresholds for success by scaling the input data to multifold.\nDemonstrate a basic understanding of different machine learning concepts such as Regression, Classification, Matrix Factorization, K-fold Validations and different algorithms such as Decision Trees, Random Forrest, K-means clustering.\nDemonstrate working knowledge and contribute to building models using deep learning techniques, ensuring robust, scalable and high-performance solutions\nMinimum Qualifications:\nEducation: Master's or PhD in a quantitative discipline (Statistics, Economics, Mathematics, Computer Science) is highly preferred.\nDeep Learning Mastery: Extensive experience with deep learning frameworks (TensorFlow, PyTorch, or Keras) and advanced deep learning projects across various domains, with a focus on multimodal data applications.\nGenerative AI Expertise: Proven experience with generative AI models and techniques, such as RAG, VAEs, Transformers, and applications at scale in content creation or data augmentation.\nProgramming and Big Data: Expert-level proficiency in Python and big data/cloud technologies (Databricks and Spark) with a minimum of 4-5 years of experience.\nRecommender Systems and Real-time Predictions: Expertise in developing sophisticated recommender systems, including the application of real-time prediction frameworks.\nMachine Learning Algorithms: In-depth experience with complex algorithms such as logistic regression, random forest, XGBoost, advanced neural networks, and ensemble methods.\nExperienced with machine learning algorithms such as logistic regression, random forest, XG boost, KNN, SVM, neural network, linear regression, lasso regression and k-means.\nDesirable Qualifications:\nGenerative AI Tools Knowledge: Proficiency with tools and platforms for generative AI (such as OpenAI, Hugging Face Transformers).\nDatabricks and Unity Catalog: Experience leveraging Databricks and Unity Catalog for robust data management, model deployment, and tracking.\nWorking experience in CI/CD tools such as GIT & BitBucket",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Engineering', 'Pyspark', 'Azure Aws', 'Generative AI', 'Big Data', 'AWS', 'Data Bricks', 'Deep Learning', 'Python', 'SQL']",2025-06-13 05:35:56
Sr. Data Scientist-Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist\n\nLocation: Onsite Bangalore\nExperience: 8+ years\n\nRole Overview\n\nWe are seeking a Senior Data Scientist with a strong foundation in machine learning, deep learning, and statistical modeling, with the ability to translate complex operational problems into scalable AI/ML solutions. In addition to core data science responsibilities, the role involves building production-ready backends in Python and contributing to end-to-end model lifecycle management. Exposure to computer vision is a plus, especially for industrial use cases like identification, intrusion detection, and anomaly detection.\n\nKey Responsibilities\n\nDevelop, validate, and deploy machine learning and deep learning models for forecasting, classification, anomaly detection, and operational optimization\nBuild backend APIs using Python (FastAPI, Flask) to serve ML/DL models in production environments\nApply advanced computer vision models (e.g., YOLO, Faster R-CNN) to object detection, intrusion detection, and visual monitoring tasks\nTranslate business problems into analytical frameworks and data science solutions\nWork with data engineering and DevOps teams to operationalize and monitor models at scale\nCollaborate with product, domain experts, and engineering teams to iterate on solution design\nContribute to technical documentation, model explainability, and reproducibility practices\n\n\nRequired Skills\n\nStrong proficiency in Python for data science and backend development\nExperience with ML/DL libraries such as scikit-learn, TensorFlow, or PyTorch\nSolid knowledge of time-series modeling, forecasting techniques, and anomaly detection\nExperience building and deploying APIs for model serving (FastAPI, Flask)\nFamiliarity with real-time data pipelines using Kafka, Spark, or similar tools\nStrong understanding of model validation, feature engineering, and performance tuning\nAbility to work with SQL and NoSQL databases, and large-scale datasets\nGood communication skills and stakeholder engagement experience\n\n\nGood to Have\n\nExperience with ML model deployment tools (MLflow, Docker, Airflow)\nUnderstanding of MLOps and continuous model delivery practices\nBackground in aviation, logistics, manufacturing, or other industrial domains\nFamiliarity with edge deployment and optimization of vision models\n\n\nQualifications\n\nMasters or PhD in Data Science, Computer Science, Applied Mathematics, or related field\n7+ years of experience in machine learning and data science, including end-to-end deployment of models in production",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scikit-learn', 'time-series modeling', 'ML/DL libraries', 'data science', 'Python', 'Airflow', 'Kafka', 'MLflow', 'logistics', 'anomaly detection', 'aviation', 'SQL', 'PyTorch', 'NoSQL', 'MLOps', 'forecasting techniques', 'Docker', 'manufacturing', 'FastAPI', 'Spark', 'TensorFlow', 'Flask']",2025-06-13 05:35:58
Data Scientist-Advanced Analytics,IBM,3 - 7 years,Not Disclosed,['Kochi'],"We are seeking a highly skilled Advanced Analytics Specialist to join our dynamic team. The successful candidate will be responsible for leveraging advanced analytics techniques to derive actionable insights, inform business decisions, and drive strategic initiatives. This role requires a deep understanding of data analysis, statistical modeling, machine learning, and data visualization.\nIn this role, you will be responsible for architecting and delivering AI solutions using cutting-edge technologies, with a strong focus on foundation models and large language models. You will work closely with customers, product managers, and development teams to understand business requirements and design custom AI solutions that address complex challenges. Experience with tools like Github Copilot, Amazon Code Whisperer etc. is desirable.\nSuccess is our passion, and your accomplishments will reflect this, driving your career forward, propelling your team to success, and helping our clients to thrive.\nDay-to-Day Duties:\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions. Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\nDocumentation and Knowledge SharingDocument solution architectures, design decisions, implementation details, and lessons learned. Create technical documentation, white papers, and best practice guides. Contribute to internal knowledge sharing initiatives and mentor new team members.\nIndustry Trends and InnovationStay up to date with the latest trends and advancements in AI, foundation models, and large language models. Evaluate emerging technologies, tools, and frameworks to assess their potential impact on solution design and implementation\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nDevelop and implement advanced analytical models and algorithms to solve complex business problems, analyze large datasets to uncover trends, patterns, and insights that drive business performance.\nCollaborate with cross-functional teams to identify key business challenges and opportunities, Create and maintain data pipelines and workflows to ensure the accuracy and integrity of data, Design and deliver insightful reports and dashboards to communicate findings to stakeholders.\nStay up to date with the latest advancements in analytics, machine learning, and data science. Provide technical expertise and mentorship to junior team members.\nQualificationsBachelor’s or master’s degree in data science, Statistics, Mathematics, Computer Science, or a related field. Proven experience in advanced analytics, data science, or a similar role. Proficiency in programming languages such as Python, R, or SQL. Experience with data visualization tools like Tableau, Power BI, or similar.\nStrong understanding of statistical modelling and machine learning algorithms. Excellent analytical, problem-solving, and critical thinking skills. Ability to communicate complex analytical concepts to non-technical stakeholders. Experience with big data technologies (e.g., Hadoop, Spark) is a plus\n\n\nPreferred technical and professional experience\nFamiliarity with cloud-based analytics platforms (e.g., AWS, Azure).\nKnowledge of natural language processing (NLP) and deep learning techniques.\nExperience with project management and agile methodologies",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'machine learning', 'statistical modeling', 'data visualization', 'machine learning algorithms', 'advanced analytics', 'python', 'github', 'natural language processing', 'power bi', 'microsoft azure', 'sql', 'r', 'tableau', 'java', 'data science', 'spark', 'hadoop', 'aws']",2025-06-13 05:36:00
Senior Engineer - Data Science,Sasken Technologies,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Summary\nPerson at this position has gained significant work experience to be able to apply their knowledge effectively and deliver results. Person at this position is also able to demonstrate the ability to analyse and interpret complex problems and improve change or adapt existing methods to solve the problem.\nPerson at this position regularly interacts with interfacing groups / customer on technical issue clarification and resolves the issues. Also participates actively in important project/ work related activities and contributes towards identifying important issues and risks. Reaches out for guidance and advice to ensure high quality of deliverables.\nPerson at this position consistently seek opportunities to enhance their existing skills, acquire more complex skills and work towards enhancing their proficiency level in their field of specialisation.\nWorks under limited supervision of Team Lead/ Project Manager.\n\n\nRoles & Responsibilities\nResponsible for design, coding, testing, bug fixing, documentation and technical support in the assigned area. Responsible for on time delivery while adhering to quality and productivity goals. Responsible for adhering to guidelines and checklists for all deliverable reviews, sending status report to team lead and following relevant organizational processes. Responsible for customer collaboration and interactions and support to customer queries. Expected to enhance technical capabilities by attending trainings, self-study and periodic technical assessments. Expected to participate in technical initiatives related to project and organization and deliver training as per plan and quality.\n\n\nEducation and Experience Required\nEngineering graduate, MCA, etc Experience: 2-5 years\n\nCompetencies Description\nData Science TCB is applicable to one who\n1) Analyses data to arrive at patterns/Insights/models\n2) Come up with models based on the data to provide recommendations, predictive analytics etc\n3) Provides implementation of the models in R, Matlab etc\n4) Can understand and apply machine learning/AI techniques\nPlatforms-\nUnix\nTechnology Standard-\nNA\nTools-\nR, Matlab, Spark Machine Learning, Python-ML, SPSS, SAS\nLanguages-\nR, Perl, Python, Scala\nSpecialization-\nCOGNITIVE ANALYTICS INCLUDING COMPUTER VISION, AI and ML, STATISTICS.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'R', 'SAS', 'Scala', 'Perl', 'SPSS', 'Spark', 'machine learning', 'Python']",2025-06-13 05:36:01
S&C GN - Data&AI - Retail - Consultant,Accenture,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Title - Retail Specialized Data Scientist Level 9 SnC GN Data & AI\n\n\n\nManagement Level:09 - Consultant\n\n\n\nLocation:Bangalore / Gurgaon / Mumbai / Chennai / Pune / Hyderabad / Kolkata\n\n\n\nMust have skills:\nA solid understanding of retail industry dynamics, including key performance indicators (KPIs) such as sales trends, customer segmentation, inventory turnover, and promotions.\nStrong ability to communicate complex data insights to non-technical stakeholders, including senior management, marketing, and operational teams.\nMeticulous in ensuring data quality, accuracy, and consistency when handling large, complex datasets.\nGather and clean data from various retail sources, such as sales transactions, customer interactions, inventory management, website traffic, and marketing campaigns.\nStrong proficiency in Python for data manipulation, statistical analysis, and machine learning (libraries like Pandas, NumPy, Scikit-learn).\nExpertise in supervised and unsupervised learning algorithms\nUse advanced analytics to optimize pricing strategies based on market demand, competitor pricing, and customer price sensitivity.\n\n\n\n\nGood to have skills:\nFamiliarity with big data processing platforms like Apache Spark, Hadoop, or cloud-based platforms such as AWS or Google Cloud for large-scale data processing.\nExperience with ETL (Extract, Transform, Load) processes and tools like Apache Airflow to automate data workflows.\nFamiliarity with designing scalable and efficient data pipelines and architecture.\nExperience with tools like Tableau, Power BI, Matplotlib, and Seaborn to create meaningful visualizations that present data insights clearly.\n\n\nJob\n\n\nSummary: The Retail Specialized Data Scientist will play a pivotal role in utilizing advanced analytics, machine learning, and statistical modeling techniques to help our retail business make data-driven decisions. This individual will work closely with teams across marketing, product management, supply chain, and customer insights to drive business strategies and innovations. The ideal candidate should have experience in retail analytics and the ability to translate data into actionable insights.\n\n\n\n\nRoles & Responsibilities:\nLeverage Retail Knowledge:Utilize your deep understanding of the retail industry (merchandising, customer behavior, product lifecycle) to design AI solutions that address critical retail business needs.\nGather and clean data from various retail sources, such as sales transactions, customer interactions, inventory management, website traffic, and marketing campaigns.\nApply machine learning algorithms, such as classification, clustering, regression, and deep learning, to enhance predictive models.\nUse AI-driven techniques for personalization, demand forecasting, and fraud detection.\nUse advanced statistical methods help optimize existing use cases and build new products to serve new challenges and use cases.\nStay updated on the latest trends in data science and retail technology.\nCollaborate with executives, product managers, and marketing teams to translate insights into business actions.\n\n\n\n\nProfessional & Technical Skills:\nStrong analytical and statistical skills.\nExpertise in machine learning and AI.\nExperience with retail-specific datasets and KPIs.\nProficiency in data visualization and reporting tools.\nAbility to work with large datasets and complex data structures.\nStrong communication skills to interact with both technical and non-technical stakeholders.\nA solid understanding of the retail business and consumer behavior.\nProgramming Languages:Python, R, SQL, Scala\nData Analysis Tools:Pandas, NumPy, Scikit-learn, TensorFlow, Keras\nVisualization Tools:Tableau, Power BI, Matplotlib, Seaborn\nBig Data Technologies:Hadoop, Spark, AWS, Google Cloud\nDatabases:SQL, NoSQL (MongoDB, Cassandra)\n\n\n\n\nAdditional Information: -\n\nQualification\n\n\n\nExperience:Minimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification:Bachelors or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'artificial intelligence', 'data visualization', 'statistics', 'algorithms', 'data manipulation', 'scikit-learn', 'scala', 'numpy', 'unsupervised learning', 'sql', 'pandas', 'tensorflow', 'spark', 'consumer behavior', 'keras', 'hadoop', 'aws', 'reporting tools', 'retail business']",2025-06-13 05:36:03
S&C Global Network - AI - CG&S - Data Engineer Consultant,Accenture,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Title:Industry & Function AI Data Engineer + S&C GN\n\n\n\nManagement Level:09 - Consultant\n\n\n\nLocation:Primary - Bengaluru, Secondary - Gurugram\n\n\n\nMust-Have Skills:Data Engineering expertise, Cloud platforms:AWS, Azure, GCP, Proficiency in Python, SQL, PySpark and ETL frameworks\n\n\n\nGood-to-Have Skills:LLM Architecture, Containerization tools:Docker, Kubernetes, Real-time data processing tools:Kafka, Flink, Certifications like AWS Certified Data Analytics Specialty, Google Professional Data Engineer,Snowflake,DBT,etc.\n\n\n\nJob\n\n\nSummary:\n\nAs a Data Engineer, you will play a critical role in designing, implementing, and optimizing data infrastructure to power analytics, machine learning, and enterprise decision-making. Your work will ensure high-quality, reliable data is accessible for actionable insights. This involves leveraging technical expertise, collaborating with stakeholders, and staying updated with the latest tools and technologies to deliver scalable and efficient data solutions.\n\n\n\n\nRoles & Responsibilities:\nBuild and Maintain Data Infrastructure:Design, implement, and optimize scalable data pipelines and systems for seamless ingestion, transformation, and storage of data.\nCollaborate with Stakeholders:Work closely with business teams, data analysts, and data scientists to understand data requirements and deliver actionable solutions.\nLeverage Tools and Technologies:Utilize Python, SQL, PySpark, and ETL frameworks to manage large datasets efficiently.\nCloud Integration:Develop secure, scalable, and cost-efficient solutions using cloud platforms such as Azure, AWS, and GCP.\nEnsure Data Quality:Focus on data reliability, consistency, and quality using automation and monitoring techniques.\nDocument and Share Best Practices:Create detailed documentation, share best practices, and mentor team members to promote a strong data culture.\nContinuous Learning:Stay updated with the latest tools and technologies in data engineering through professional development opportunities.\n\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\nStrong proficiency in programming languages such as Python, SQL, and PySpark\nExperience with cloud platforms (AWS, Azure, GCP) and their data services\nFamiliarity with ETL frameworks and data pipeline design\nStrong knowledge of traditional statistical methods, basic machine learning techniques.\nKnowledge of containerization tools (Docker, Kubernetes)\nKnowing LLM, RAG & Agentic AI architecture\nCertification in Data Science or related fields (e.g., AWS Certified Data Analytics Specialty, Google Professional Data Engineer)\n\n\n\n\n\nAdditional Information:\n\nThe ideal candidate has a robust educational background in data engineering or a related field and a proven track record of building scalable, high-quality data solutions in the Consumer Goods sector.\n\nThis position offers opportunities to design and implement cutting-edge data systems that drive business transformation, collaborate with global teams to solve complex data challenges and deliver measurable business outcomes and enhance your expertise by working on innovative projects utilizing the latest technologies in cloud, data engineering, and AI.\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:Minimum 3-7 years in data engineering or related fields, with a focus on the Consumer Goods Industry\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Computer Science, Information Systems, Engineering, or a related field",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'data engineering', 'sql', 'machine learning algorithms', 'kubernetes', 'snowflake', 'data analytics', 'microsoft azure', 'cloud platforms', 'machine learning', 'apache flink', 'artificial intelligence', 'docker', 'pipeline', 'data science', 'gcp', 'kafka', 'aws', 'etl', 'etl scripts']",2025-06-13 05:36:05
S&C GN - Data&AI - CMT Eng - Consultant,Accenture,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Title - S&C Global Network - AI - CMT DE- Consultant\n\n\n\nManagement Level:9- Consultant\n\n\n\nLocation:Open\n\n\n\nMust-have skills:Data Engineering\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nWe are looking for a passionate and results-driven\n\n\n\nData Engineerto join our growing data team. You will be responsible for designing, building, and maintaining scalable data pipelines and infrastructure that support data-driven decision-making across the organization.\n\n\n\n\nRoles & Responsibilities:\n\nDesign, build, and maintain robust, scalable, and efficient data pipelines (ETL/ELT).\nWork with structured and unstructured data across a wide variety of data sources.\nCollaborate with data analysts, data scientists, and business stakeholders to understand data requirements.\nOptimize data systems and architecture for performance, scalability, and reliability.\nMonitor data quality and support initiatives to ensure clean, accurate, and consistent data.\nDevelop and maintain data models and metadata.\nImplement and maintain best practices in data governance, security, and compliance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n2+ years in data engineering or related fields\nProficiency in SQL and experience with relational databases (e.g., PostgreSQL, MySQL).\nStrong programming skills in Python, Scala, or Java.\nExperience with big data technologies such as Spark, Hadoop, or Hive.\nFamiliarity with cloud platforms like AWS, Azure, or GCP, especially services like S3, Redshift, BigQuery, or Azure Data Lake.\nExperience with orchestration tools like Airflow, Luigi, or similar.\nSolid understanding of data warehousing concepts and data modeling techniques.\nGood problem-solving skills and attention to detail.\nExperience with modern data stack tools like dbt, Snowflake, or Databricks.\nKnowledge of CI/CD pipelines and version control (e.g., Git).\nExposure to containerization (Docker, Kubernetes) and infrastructure as code (Terraform, CloudFormation).\n\n\n\n\nAdditional Information: - The ideal candidate will possess a strong educational background in quantitative discipline and experience in working with Hi-Tech clients\n\n- This position is based at our Bengaluru (preferred) and other AI Accenture locations.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:4+ years\n\n\n\n\nEducational Qualification:Btech/ BE",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'scala', 'data engineering', 'sql', 'java', 'hive', 'continuous integration', 'kubernetes', 'snowflake', 'amazon redshift', 'airflow', 'microsoft azure', 'ci/cd', 'aws cloudformation', 'docker', 'data bricks', 'data modeling', 'spark', 'gcp', 'data warehousing concepts', 'terraform', 'hadoop', 'aws']",2025-06-13 05:36:07
Junior Business Analyst,Innovature Software Labs,1 - 2 years,Not Disclosed,"['Kochi', 'Chennai']",">\nJob Category: Software\nJob Type: Full Time\nJob Location: Infopark - Kochi\nExperience: 1 - 2 Years\nDesignation: Junior Business Analyst\nKey Responsibilities\nCollaborate with stakeholders to gather, document, and analyze business requirements.\nConduct market research, competitive analysis, and feasibility studies for new projects.\nWork closely with development teams to translate business requirements into technical specifications.\nCreate business process models, workflows, and use case diagrams to illustrate system functionalities.\nDefine and maintain project documentation, including BRDs (Business Requirements Documents) and FRDs (Functional Requirements Documents).\nFacilitate meetings, presentations, and workshops with stakeholders, product managers, and developers.\nEnsure alignment between business objectives and technology solutions.\nAssist in UAT (User Acceptance Testing) and validate that the final product meets business needs.\nProvide ongoing support, training, and guidance to stakeholders on system enhancements.\nSkill set\nExperience as a Business Analyst in IT or related industries.\nGood understanding of the full software development lifecycle.\nStrong communication, stakeholder management, and presentation skills.\nProficiency in requirements gathering, process mapping, and data analysis.\nStrong understanding of Agile, Scrum, and Waterfall methodologies.\nAbility to analyze complex data sets and translate findings into actionable insights.\nUnderstanding of UI/UX principles and experience working with designers.\nExperience with tools like JIRA, Confluence, Backlog, and SQL.\nKnowledge of database queries, reporting tools, and BI (Business Intelligence) platforms is an advantage.\nExperience\n1-2 years of experience",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Business Analyst', 'Competitive analysis', 'Software development life cycle', 'Market research', 'Business intelligence', 'Stakeholder management', 'User acceptance testing', 'SQL']",2025-06-13 05:36:08
Consultant- Real-World Data (RWD),IQVIA,2 - 7 years,Not Disclosed,"['Pune', 'Gurugram', 'Bengaluru']","Project Role: Consultant- Real-World Data (RWD)\nWork Experience: 2 to 8 Years\nWork location: Bengaluru/Pune/Gurugram\nWork Mode: Hybrid\nMust Have Skills: Real-World Data (RWD), Healthcare, Data analytics, SQL/Python\nJob Overview:\nWe are seeking a highly motivated Associate Consultant to join our Real-World Data (RWD) team. The selected candidate will support data analysis activities using IQVIA Connected Intelligence RWD and clinical data assets across multiple R&D projects. This role involves close collaboration with Therapeutic Analytic Leads to ensure standardized, data-driven decision-making at the indication, program, and study levels.\n\nKey Responsibilities:\nLeverage IQVIA Connected Intelligence datasets to inform and enhance clinical trial strategies (pre- and post-award).\nCollaborate with internal stakeholders to align on data analytics requirements, capabilities, and deliverables.\nLead the development and implementation of analytics methodologies, including:\nCountry evaluation and ranking\nCompetitive landscape assessments\nHistorical recruitment analysis\nPatient density analytics\nGenerate patient insights using RWD to support site targeting strategies.\nCoordinate the collection and analysis of site outreach data to inform country/site strategy development.\n\nQualifications:\nBachelors degree in Life Sciences, Information Technology, Computer Science, Statistics, or a related field.\n2-7 years of experience in data analytics, clinical research, or consulting within the pharmaceutical or healthcare industry.\nExperience working with large-scale electronic data (e.g., medical claims, EMRs/EHRs, prescriptions, sales data).\nFamiliarity with the pharmaceutical and healthcare market and drug development lifecycle.\nPreferred experience working with global, cross-functional teams.\nProficiency in business intelligence tools (e.g., Power BI, Tableau) is a plus.\nHands-on experience with programming/scripting languages (Python, R, Spark, PySpark) and relational databases (SQL Server, Oracle, PostgreSQL) is advantageous.\n\nSkills & Competencies:\nStrong attention to detail and analytical thinking.\nEffective verbal and written communication skills.\nProficiency in MS Excel and PowerPoint.\nLogical problem-solving and task prioritization abilities.\nAdaptability and eagerness to learn new tools and systems.\nStrong presentation and stakeholder engagement skills.",Industry Type: Analytics / KPO / Research,Department: Consulting,"Employment Type: Full Time, Permanent","['Real World Evidence', 'Healthcare', 'Data Analytics', 'Healthcare Analytics', 'Pharma', 'Feasibility Analysis', 'Clinical']",2025-06-13 05:36:10
Data Bricks,PwC India,7 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary:\n\nWe are seeking a talented Data Engineer with strong expertise in Databricks, specifically in Unity Catalog, PySpark, and SQL, to join our data team. Youll play a key role in building secure, scalable data pipelines and implementing robust data governance strategies using Unity Catalog.\n\nKey Responsibilities:",,,,"['DataBricks', 'Data Bricks', 'Pyspark', 'Delta Lake', 'Databricks Engineer', 'Unity Catalog', 'SQL']",2025-06-13 05:36:12
Data Engineer _Technology Lead,Broadridge,6 - 10 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nAnalyzes and solve problems using technical experience, judgment and precedents\nProvides informal guidance to new team members\nExplains complex information to others in straightforward situations\n1. Data Engineering and Modelling:\nDesign & Develop Scalable Data Pipelines: Leverage AWS technologies to design, develop, and manage end-to-end data pipelines with services like .",,,,"['Star Schema', 'Snowflake', 'AWS', 'Apache Airflow']",2025-06-13 05:36:13
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Bengaluru'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\n\nYour primary responsibilities include:\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\nStrive for continuous improvements by testing the build solution and working under an agile framework.\nDiscover and implement the latest technologies trends to maximize and build creative solutions\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nExperience with Apache Spark (PySpark)In-depth knowledge of Spark’s architecture, core APIs, and PySpark for distributed data processing.\nBig Data TechnologiesFamiliarity with Hadoop, HDFS, Kafka, and other big data tools. Data Engineering\n\nSkills:\nStrong understanding of ETL pipelines, data modeling, and data warehousing concepts.\nStrong proficiency in PythonExpertise in Python programming with a focus on data processing and manipulation. Data Processing FrameworksKnowledge of data processing libraries such as Pandas, NumPy.\nSQL ProficiencyExperience writing optimized SQL queries for large-scale data analysis and transformation.\nCloud PlatformsExperience working with cloud platforms like AWS, Azure, or GCP, including using cloud storage systems\n\n\nPreferred technical and professional experience\nDefine, drive, and implement an architecture strategy and standards for end-to-end monitoring.\nPartner with the rest of the technology teams including application development, enterprise architecture, testing services, network engineering,\nGood to have detection and prevention tools for Company products and Platform and customer-facing",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-13 05:36:15
S&C GN - Data&AI - Hi Tech - Data Science - Consultant,Accenture,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Title - S&C Global Network - AI - Hi Tech - Data Science Consultant\n\n\n\nManagement Level:9-Team Lead/Consultant\n\n\n\nLocation:Hyderabad, HDC2A\n\n\n\nMust-have skills:Data Science\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\nWHATS IN IT FOR YOU\nWe are seeking a skilled and experienced Data Scientist to join our Hi-Tech practice.\nThe ideal candidate should have hands-on experience in data science within industries such as semiconductors, enterprise technology, consumer technology, medical technology.\nAs a Data Scientist, you will be responsible for developing AI models/applying GenAI techniques in areas such as marketing & consumer analytics, predictive asset maintenance, production optimization, supply chain, sales & channel partner program analytics, and connected products.\n\n\n\nWhat you would do in this role\nDevelop and implement AI models and GenAI applications to address business challenges in semiconductors, enterprise technology, consumer technology, medical technology and related industries.\nCollaborate with cross-functional teams to gather requirements, design solutions, and deploy models into production environments.\nDevelop and implement GenAI based solutions through contextual prompt engineering and prompt tuning and supporting solution architects on the design of GenAI-powered solutions/assets.\nUtilize your expertise in PLM/ERP/CRM/Contact Center systems to integrate data sources and ensure seamless operation of AI solutions.\nDesign and develop machine learning models using Python, with proficiency in NLP and Computer Vision techniques.\nArchitect functional solutions and provide technical guidance to enhance the performance and scalability of AI systems.\nLeverage cloud platforms, with preference for Azure/GCP, and experience with AWS is also valued.\nStay updated on emerging technologies and industry trends, contributing to continuous improvement initiatives within the organization.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\nProven track record of developing AI models in areas such as channel analytics, marketing & customer experience, supply chain analytics, predictive maintenance, production optimization, and connected products.\nStrong proficiency in Python programming, with experience in NLP and Computer Vision.\nExposure to PLM/ERP/CRM systems and understanding of their integration with AI solutions.\nExperience with cloud platforms, preferably Azure/GCP, and familiarity with AWS.\nKnowledge of LLM exposure and experience with tools such as ChatGPT, Llama 2, Claude 2, Hugging Face, etc. for prompt engineering, prompt tuning, etc will be an advantage.\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'erp', 'natural language processing', 'data science', 'computer vision', 'appium', 'ai solutions', 'cucumber', 'microsoft azure', 'machine learning', 'artificial intelligence', 'eclipse', 'plm', 'deep learning', 'tensorflow', 'java', 'gcp', 'ai techniques', 'aws', 'testng', 'bdd framework', 'crm']",2025-06-13 05:36:17
Sales Excellence - COE - Data Engineering Specialist,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Job Title -\n\n\n\nSales Excellence - COE - Data Engineering Specialist\n\n\n\nManagement Level:\n\n\n\n9-Team Lead/Consultant\n\n\n\nLocation:\n\n\n\nMumbai, MDC2C\n\n\n\nMust-have skills:Sales\n\n\n\n\nGood to have skills:Data Science, SQL, Automation, Machine Learning\n\n\n\nJob\n\n\nSummary:\n\nApply deep statistical tools and techniques to find relationships between variables\n\n\n\n\nRoles & Responsibilities:\n\n- Apply deep statistical tools and techniques to find relationships between variables.\n\n- Develop intellectual property for analytical methodologies and optimization techniques.\n\n- Identify data requirements and develop analytic solutions to solve business issues.\n\nJob Title - Analytics & Modelling Specialist\n\nManagement Level :9-Specialist\n\nLocation:Bangalore/ Gurgaon/Hyderabad/Mumbai\n\nMust have skills:Python, Data Analysis, Data Visualization, SQL\nGood to have skills:Machine Learning\n\nJob\n\n\nSummary:\n\nThe Center of Excellence (COE) makes sure that the sales and pricing methods and offerings of Sales Excellence are effective.\n\n- The COE supports salespeople through its business partners and Analytics and Sales Operations teams.\n\nThe Data Engineer helps manage data sources and environments, utilizing large data sets and maintaining their integrity to create models and apps that deliver insights to the organization.\nRoles & Responsibilities:\n\nBuild and manage data models that bring together data from different sources.\n\nHelp consolidate and cleanse data for use by the modeling and development teams.\n\nStructure data for use in analytics applications.\n\nLead a team of Data Engineers effectively.\nProfessional & Technical\n\n\n\n\nSkills:\nA bachelors degree or equivalent\n\nTotal experience Range:5-8 years in the relevant field\n\nA minimum of 3 years of GCP experience with exposure to machine learning/data science\n\nExperience in configuration the machine learning workflow in GCP.\n\nA minimum of 5 years Advanced SQL knowledge and experience working with relational databases\n\nA minimum of 3 years Familiarity and hands on experience in different SQL objects like stored procedures, functions, views etc.,\n\nA minimum of 3 years Building of data flow components and processing systems to extract, transform, load and integrate data from various sources.\n\nA minimum of 3 years Hands on experience in advanced excel topics such as cube functions, VBA Automation, Power Pivot etc.\n\nA minimum of 3 years Hands on experience in Python\nAdditional Information:\n\nUnderstanding of sales processes and systems.\n\nMasters degree in a technical field.\n\nExperience with quality assurance processes.\n\nExperience in project management.\n\nYou May Also Need:\n\nAbility to work flexible hours according to business needs.\n\nMust have good internet connectivity and a distraction-free environment for working at home, in accordance with local guidelines.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | AccentureQualification\n\n\n\nExperience:8 to 10 Years\n\n\n\n\nEducational Qualification:\n\n\n\nB.Com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analysis', 'sales', 'sql', 'data visualization', 'hive', 'advance sql', 'ssas', 'dbms', 'machine learning', 'data engineering', 'power pivot', 'sql server', 'vba automation', 'data science', 'gcp', 'spark', 'advanced excel', 'hadoop', 'ssis', 'etl', 'big data', 'data flow', 'sql joins']",2025-06-13 05:36:19
"Data Eng, Mgmt & Governance Assoc Mgr",Accenture,10 - 14 years,Not Disclosed,['Bengaluru'],"Skill required: Data Management - Microsoft Fabric\n\n\n\n\nDesignation: Data Eng, Mgmt & Governance Assoc Mgr\n\n\n\n\nQualifications:BE/BTech\n\n\n\n\nYears of Experience:10 to 14 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIEnd to end, unified analytics platform that brings together existing offerings like Data Factory, Synapse, and Power BI into a single unified product for all your data and analytics workloads.\n\n\n\n\nWhat are we looking for\nMicrosoft Fabric Microsoft Azure PySparkStrong analytical skillsAbility to establish strong client relationshipAbility to manage multiple stakeholdersAbility to perform under pressure\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of moderately complex problems Typically creates new solutions, leveraging and, where needed, adapting existing methods and procedures The person requires understanding of the strategic direction set by senior management as it relates to team goals Primary upward interaction is with direct supervisor or team leads Generally, interacts with peers and/or management levels at a client and/or within Accenture The person should require minimal guidance when determining methods and procedures on new assignments Decisions often impact the team in which they reside and occasionally impact other teams Individual would manage medium-small sized teams and/or work efforts (if in an individual contributor role) at a client or within Accenture\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data management', 'data analysis', 'sql', 'data governance', 'etl', 'data analytics', 'data warehousing', 'power bi', 'business analysis', 'business intelligence', 'master data management', 'merchandising', 'data cleansing', 'garments', 'data quality', 'tableau', 'data modeling', 'data profiling']",2025-06-13 05:36:21
S&C GN - Data&AI - CMT Eng - Consultant,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Title - S&C Global Network - AI - CMT AI ML Consultant\n\n\n\nManagement Level:9- Consultant\n\n\n\nLocation:Open\n\n\n\nMust-have skills:Gen AI ML\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\nWHATS IN IT FOR YOU\nAccenture has committed to invest USD 3Billion into GenAI in the next 3 years. We will continually invest in your learning and growth. You'll work with Accentures highly skilled and experienced practitioners, and Accenture will support you in growing your own career path and interests.\nYoull be part of a diverse, vibrant, global Accenture Data and AI community, continually pushing the boundaries of business capabilities.\n\n\n\nWhat you would do in this role\n\n\n\nML Maturity Assessment:\nConduct comprehensive assessments of the organization's ML maturity, identifying strengths, weaknesses, and areas for improvement.\nProvide strategic recommendations to enhance the overall ML capability and align it with business objectives.\n\n\n\nML Ops Roadmap & Processes:\nDevelop ML Ops roadmaps and establish robust processes for the end-to-end machine learning lifecycle, including data preparation, model training, deployment, and monitoring.\nImplement best practices in ML Ops to ensure efficiency, scalability, and reliability of ML systems.\n\n\n\nImplementation of Gen AI Solutions:\nLead the design and implementation of state-of-the-art Generative AI solutions, leveraging deep learning frameworks such as TensorFlow and PyTorch.\nDrive innovation in Gen AI, staying abreast of the latest advancements and incorporating cutting-edge technologies into solutions.\n\n\n\nIncubating and Designing:\nProactively identify opportunities for ML and / or Gen AI applications within the organization.\nWork closely with cross-functional teams to incubate and design bespoke ML solutions tailored to business requirements.\n\n\n\nTechnical Leadership:\nProvide technical leadership and mentorship to data scientists, engineers, and other team members.\nCollaborate with stakeholders to ensure alignment between technical solutions and business objectives.\n\n\n\nCollaboration and Communication:\nCollaborate with business stakeholders to understand their needs and translate them into ML and Gen AI requirements.\nEffectively communicate complex technical concepts to non-technical audiences.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\nProven expertise in conducting ML maturity assessments and developing ML Ops roadmaps.\nHands-on experience in operationalizing the Machine learning system on a cloud and / or an On-Prem platform.\nExperience in implementing Generative AI solutions, including incubation, design, and deployment will be a big plus.\nProficiency in deep learning frameworks such as TensorFlow and PyTorch.\nGood knowledge of ML Ops best practices and processes.\nExcellent problem-solving skills and ability to design scalable and reliable ML architectures.\nStrong leadership and communication skills, with a track record of leading successful ML initiatives.\nExperience in Telecom or Hi Tech or Software and platform industry desirable\nTools & Techniques\nTensorFlow, PyTorch, Scikit-learn, Keras\nNumPy, Pandas\nMatplotlib, Seaborn\nTensorFlow Serving, Docker and Kubernetes\nGood software engineering practices, including code modularization, documentation, and testing.\nExperience with open API , Integration architecture , microservices\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:4+ years\n\n\n\n\nEducational Qualification:Btech/ BE",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['deep learning frameworks', 'machine learning', 'assessment', 'gen', 'ml', 'kubernetes', 'hi', 'python', 'scikit-learn', 'ai solutions', 'numpy', 'integration architecture', 'docker', 'microservices', 'pandas', 'deep learning', 'tensorflow', 'seaborn', 'matplotlib', 'open api', 'pytorch', 'keras', 'telecom']",2025-06-13 05:36:23
Data Platform Engineer,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models. You will play a crucial role in the development and maintenance of the data platform components, contributing to the overall success of the project.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist with the data platform blueprint and design.- Collaborate with Integration Architects and Data Architects to ensure cohesive integration between systems and data models.- Develop and maintain data platform components.- Contribute to the overall success of the project.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Hyderabad office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'tableau', 'machine learning algorithms', 'statistics', 'data munging', 'python', 'data analysis', 'natural language processing', 'power bi', 'machine learning', 'sql', 'data quality', 'r', 'data modeling', 'data science', 'predictive modeling', 'text mining', 'logistic regression']",2025-06-13 05:36:25
Data Platform Engineer,Accenture,12 - 15 years,Not Disclosed,['Bengaluru'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Collibra Data Governance\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, encompassing the relevant data platform components. Your typical day will involve collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models, while also engaging in discussions to refine and enhance the overall data architecture. You will be involved in various stages of the data platform lifecycle, ensuring that all components work harmoniously to support the organization's data needs and objectives.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Expected to provide solutions to problems that apply across multiple teams.- Facilitate knowledge sharing sessions to enhance team capabilities and foster a culture of continuous improvement.- Monitor and evaluate team performance, providing constructive feedback to ensure alignment with project goals.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Collibra Data Governance.- Strong understanding of data governance frameworks and best practices.- Experience with data integration tools and techniques.- Familiarity with data modeling concepts and methodologies.- Ability to analyze and interpret complex data sets to inform decision-making.\nAdditional Information:- The candidate should have minimum 12 years of experience in Collibra Data Governance.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data architecture', 'sql', 'data modeling', 'data governance', 'data analysis', 'oracle', 'data management', 'data warehousing', 'business analysis', 'machine learning', 'business intelligence', 'javascript', 'sql server', 'data quality', 'tableau', 'java', 'html', 'mysql', 'etl', 'informatica']",2025-06-13 05:36:27
Data Governance Practitioner,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Project Role :Data Governance Practitioner\n\n\n\n\n\nProject Role Description :Establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Collaborate with key stakeholders to define data standards, facilitate effective data collection, storage, access, and usage; and drive data stewardship initiatives for comprehensive and effective data governance.\n\n\n\nMust have skills :Snowflake Data Warehouse\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Governance Practitioner, you will establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Your typical day will involve collaborating with key stakeholders to define data standards, facilitating effective data collection, storage, access, and usage, and driving data stewardship initiatives for comprehensive and effective data governance. You will engage in discussions that shape the data governance framework and contribute to the overall data strategy of the organization.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist in the development and implementation of data governance frameworks and policies.- Monitor compliance with data governance policies and report on data quality metrics.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Snowflake Data Warehouse.- Strong understanding of data governance principles and best practices.- Experience with data quality assessment and improvement techniques.- Familiarity with data management tools and technologies.- Ability to communicate complex data concepts to non-technical stakeholders.\nAdditional Information:- The candidate should have minimum 3 years of experience in Snowflake Data Warehouse.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'data management', 'warehouse', 'sql', 'data governance', 'hive', 'python', 'data analysis', 'data analytics', 'data warehousing', 'business analytics', 'machine learning', 'business intelligence', 'tableau', 'data science', 'data modeling', 'hadoop', 'sqoop', 'etl', 'informatica']",2025-06-13 05:36:29
Data Science,Global Banking Organization,5 - 10 years,Not Disclosed,['Bengaluru'],"Key Skills: Machine Learning, Data Science, Azure, Python, Hadoop.\nRoles and Responsibilities:\nStrong understanding of Math, Statistics, and the theoretical foundations of Statistical & Machine Learning, including Parametric and Non-parametric models.\nApply advanced data mining techniques to curate, process, and transform raw data into reliable datasets.\nUse various statistical techniques and ML methods to perform predictive modeling/classification for problems related to clients, distribution, sales, client profiles, and segmentation, and provide actionable insights for business decision-making.\nDemonstrate expertise in the full Machine Learning lifecycle--feature engineering, training, validation, scaling, deployment, scoring, monitoring, and feedback loops.\nProficiency in Python visualization libraries such as matplotlib and seaborn.\nExperience with cloud computing infrastructure like Azure, including Machine Learning Studio, Azure Data Factory, Synapse, Python, and PySpark.\nAbility to develop, test, and deploy models on cloud/web platforms.\nExcellent knowledge of Deep Learning Architectures, including Convolutional Neural Networks and Transformer/LLM Foundation Models.\nStrong expertise in supervised and adversarial learning techniques.\nRobust working knowledge of deep learning frameworks such as TensorFlow, Keras, and PyTorch.\nExcellent Python coding skills.\nExperience with version control tools (Git, GitHub/GitLab) and data version control.\nExperience in end-to-end model deployment and productionization.\nDemonstrated proficiency in deploying, scaling, and optimizing ML models in production environments with low latency, high availability, and cost efficiency.\nSkilled in model interpretability and CI/CD for ML using tools like MLflow and Kubeflow, with the ability to implement automated monitoring, logging, and retraining strategies.\nExperience Requirement:\n5-12 years of experience in designing and deploying deep learning and machine learning solutions.\nProven track record of delivering AI/ML solutions in real-world business applications at scale.\nHands-on experience working in cross-functional teams including data engineers, product managers, and business stakeholders.\nExperience mentoring junior data scientists and providing technical leadership within a data science team.\nExperience working with big data tools and environments such as Hadoop, Spark, or Databricks is a plus.\nPrior experience in managing model lifecycle in enterprise production environments including drift detection and retraining pipelines.\nEducation: B.Tech.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure', 'Hadoop.', 'Machine Learning', 'Python']",2025-06-13 05:36:30
IN_Manager_Azure Data Engineer_Data Analytics_Advisory,PwC Service Delivery Center,5 - 10 years,Not Disclosed,['Bengaluru'],"Not Applicable\nSpecialism\nData, Analytics & AI\n& Summary\nAt PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decisionmaking and driving business growth.\n\nIn data engineering at PwC, you will focus on designing and building data infrastructure and systems to enable efficient data processing and analysis. You will be responsible for developing and implementing data pipelines, data integration, and data transformation solutions.\n& Summary A career within Data and Analytics services will provide you with the opportunity to help organisations uncover enterprise insights and drive business results using smarter data analytics. We focus on a collection of organisational technology capabilities, including business intelligence, data management, and data assurance that help our clients drive innovation, growth, and change within their organisations in order to keep up with the changing nature of customers and technology. We make impactful decisions by mixing mind and machine to leverage data, understand and navigate risk, and help our clients gain a competitive edge.\nResponsibilities\nMust have\nCandidates with minimum 5 years of relevant experience for 1012 years of total experience (Architect / Managerial level).\nDeep expertise with technologies such as Data factory, Data Bricks (Advanced), SQLDB (writing complex Stored Procedures), Synapse, Python scripting (mandatory), Pyspark scripting, Azure Analysis Services.\nMust be certified with DP 203 (Azure Data Engineer Associate), Databricks Certified Data Engineer Professional (Architect / Managerial level)\nStrong troubleshooting and debugging skills. Proven experience in working source control technologies (such as GITHUB, Azure DevOps), build and release pipelines.\nExperience in writing complex PySpark queries to perform data analysis.\nMandatory skill sets\nAzure Databricks, Pyspark, Datafactory\nPreferred skill sets\nAzure Databricks, Pyspark, Datafactory, Python, Azure Devops\nYears of experience required\n712yrs\nEducation qualification\nB.Tech / M.Tech / MBA / MCA\nEducation\nDegrees/Field of Study required Bachelor of Technology, Master of Business Administration\nDegrees/Field of Study preferred\nRequired Skills\nMicrosoft Azure\nAccepting Feedback, Accepting Feedback, Active Listening, Agile Scalability, Amazon Web Services (AWS), Analytical Thinking, Apache Airflow, Apache Hadoop, Azure Data Factory, Coaching and Feedback, Communication, Creativity, Data Anonymization, Data Architecture, Database Administration, Database Management System (DBMS), Database Optimization, Database Security Best Practices, Databricks Unified Data Analytics Platform, Data Engineering, Data Engineering Platforms, Data Infrastructure, Data Integration, Data Lake, Data Modeling {+ 32 more}\nTravel Requirements\nGovernment Clearance Required?",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Data modeling', 'Debugging', 'Database administration', 'Agile', 'Stored procedures', 'Apache', 'Business intelligence', 'Troubleshooting', 'Python']",2025-06-13 05:36:32
Data Engineer III,Expedia Group,5 - 10 years,Not Disclosed,['Bengaluru'],"Why Join Us?\nTo shape the future of travel, people must come first. Guided by our Values and Leadership Agreements, we foster an open culture where everyone belongs, differences are celebrated and know that when one of us wins, we all win.\nWe provide a full benefits package, including exciting travel perks, generous time-off, parental leave, a flexible work model (with some pretty cool offices), and career development resources, all to fuel our employees passion for travel and ensure a rewarding career journey. We re building a more open world. Join us.\nData Engineer III\nIntroduction to the Team\nExpedia Technology teams partner with our Product teams to create innovative products, services, and tools to deliver high-quality experiences for travelers, partners, and our employees. A singular technology platform powered by data and machine learning provides secure, differentiated, and personalized experiences that drive loyalty and traveler satisfaction.\nExpedia Group is seeking a skilled and motivated Data Engineer III to join our Finance Business Intelligence team supporting the Product & Technology Finance organization. In this role, you will help drive data infrastructure and analytics solutions that support strategic financial planning, reporting, and operational decision-making across the Global Finance community. You ll work closely with Finance and Technology partners to ensure data accuracy, accessibility, and usability in support of Expedia s business objectives.\nAs a Data Engineer III, you have strong experience working with a variety of datasets, data environments, tools, and analytical techniques. You enjoy a fun, collaborative and stimulating team environment. Successful candidates should be able to own projects end-to-end, including identifying problems and solutions, building and maintain data pipelines and dashboards, distilling key insights and communicate to stakeholders.\nIn this role, you will:\nDevelop new and improve existing end to end Business Intelligence products (data pipelines, Tableau dashboards, and Machine Learning predictive forecasting models).\nDrive internal efficiencies through streamline code/documentation/Tableau development to maintain high data integrity.\nTroubleshoot and resolve production issues with the team products (automation opportunities, optimizations, back-end data issues, data reconciliations).\nProactively reach out to subject matter experts /stakeholders and collaborate to solve problems.\nRespond to ad hoc data requests and conduct analysis to provide valuable insights to stakeholders.\nCollaborate and coordinate with team members/stakeholders to translate complex data into meaningful insights, that improve the analytical capabilities of the business.\nApply knowledge of database design to support migration of data pipelines from on prem to cloud environment (including data extraction, ingestion, processing of large data sets)\nSupport dashboard development on cloud environment to enable self-service reporting.\nCommunicate clearly on current work status and design considerations\nThink broadly and comprehend the how, why, and what behind data architecture designs\nExperience & Qualifications:\nBachelor s in Computer Science, Mathematics, Statistics, Information Systems, or related field\n5+ years experience in a Data Analyst, Data Engineer or Business Analyst role\nProven expertise in SQL, with practical experience utilizing query engines including SQL Server, Starburst, Trino, Querybook and data science tools such as Python/R, SparkSQL.\nProficient visualization skills (Tableau, Looker, or similar) and excel modeling/report automation.\nExceptional understanding of relational and dimensional datasets, data warehouse and data mining and applies database design principles to solve data requirements\nExperience building robust data extract, load and transform (ELT) processes, that source data from multiple databases.\nDemonstrated record of defining and executing key analysis and solving problems with minimal supervision.\nDynamic individual contributor who consistently enhances operational playbooks to address business problems.\n3+ year working in a hybrid environment that uses both on-premise and cloud technologies is preferred.\nExperience working in an environment that manipulates large datasets on the cloud platform preferred.\nBackground in analytics, finance or a comparable reporting and analytics role preferred.\nAccommodation requests\nIf you need assistance with any part of the application or recruiting process due to a disability, or other physical or mental health conditions, please reach out to our Recruiting Accommodations Team through the Accommodation Request .\nWe are proud to be named as a Best Place to Work on Glassdoor in 2024 and be recognized for award-winning culture by organizations like Forbes, TIME, Disability:IN, and others.\nExpedia Groups family of brands includes: Brand Expedia , Hotels.com , Expedia Partner Solutions, Vrbo , trivago , Orbitz , Travelocity , Hotwire , Wotif , ebookers , CheapTickets , Expedia Group Media Solutions, Expedia Local Expert , CarRentals.com , and Expedia Cruises . 2024 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. . Never provide sensitive, personal information to someone unless you re confident who the recipient is. Expedia Group does not extend job offers via email or any other messaging tools to individuals with whom we have not made prior contact. Our email domain is @expediagroup.com. The official website to find and apply for job openings at Expedia Group is careers.expediagroup.com/jobs .\nExpedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Database design', 'Machine learning', 'Business intelligence', 'Data mining', 'Analytics', 'SQL', 'Python', 'Data architecture']",2025-06-13 05:36:34
Data Engineer II,Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Amazon strives to be the worlds most customer-centric company, where customers can research and purchase anything they might want online\nWe set big goals and are looking for people who can help us reach and exceed them\nThe CPT Data Engineering & Analytics (DEA) team builds and maintains critical data infrastructure that enhances seller experience and protects the privacy of Amazon business partners throughout their lifecycle\nWe are looking for a strong Data Engineer to join our team\n\nThe Data Engineer I will work with well-defined requirements to develop and maintain data pipelines that help internal teams gather required insights for business decisions timely and accurately\nYou will collaborate with a team of Data Scientists, Business Analysts and other Engineers to build solutions that reduce investigation defects and assess the health of our Operations business while ensuring data quality and regulatory compliance\n\nThe ideal candidate must be passionate about building reliable data infrastructure, detail-oriented, and driven to help protect Amazons customers and business partners\nThey will be an individual contributor who works effectively with guidance from senior team members to successfully implement data solutions\nThe candidate must be proficient in SQL and at least one scripting language (e\ng\nPython, Perl, Scala), with strong understanding of data management fundamentals and distributed systems concepts\n\n\nBuild and optimize physical data models and data pipelines for simple datasets\nWrite secure, stable, testable, maintainable code with minimal defects\nTroubleshoot existing datasets and maintain data quality\nParticipate in team design, scoping, and prioritization discussions\nDocument solutions to ensure ease of use and maintainability\nHandle data in accordance with Amazon policies and security requirements Masters degree in computer science, engineering, analytics, mathematics, statistics, IT or equivalent\n3+ years of data engineering experience\nExperience with SQL\nExperience with data modeling, warehousing and building ETL pipelines\nKnowledge of distributed systems concepts from data storage and compute perspective\nAbility to work effectively in a team environment Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions\nFamiliarity with big data technologies (Hadoop, Spark, etc\n)\nKnowledge of data security and privacy best practices\nStrong problem-solving and analytical skills\nExcellent written and verbal communication skills",Industry Type: Internet,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data management', 'Data modeling', 'data security', 'Perl', 'Data quality', 'Distribution system', 'Analytics', 'SQL', 'Python']",2025-06-13 05:36:36
Graph Engineer- Data Science,HARMAN,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Description\nIntroduction: Digital Transformation Solutions (DTS)\n.\nExtensive experience in defining, developing, and implementing security software, ideally with a strong embedded firmware development background\nAbout the Role\nThis position offers an opportunity to work in a globally distributed team where you will get a unique opportunity of personal development in a multi-cultural environment. You will also get a challenging environment to develop expertise in the technologies useful in the industry.",,,,"['Computer science', 'Product quality', 'UML', 'XML', 'Relationship', 'Javascript', 'HTML', 'Oracle', 'Automotive', 'Python']",2025-06-13 05:36:38
"Associate Director, Data Science/Software Engineering",ATT Communication Services,10 - 15 years,Not Disclosed,['Bengaluru'],"Associate Director, Data Science/Software Engineering:\nAT&T is one of the leading service providers in the telecommunication sector and propelling it into the data and AI driven era is powered by CDO (Chief Data Office) . CDO is empowering AT&T, through execution, self-service, and as a data and AI center of excellence, to unlock transformative insights and actions that drive value for the company and its customers.\nEmployees in CDO imagine, innovate, and unlock data & AI driven insights and actions that create value for our customers and the enterprise. Part of the work, we govern data collection and use, mitigate for potential bias in machine learning models, and encourage an enterprise culture of responsible AI.\nAT&T s Chief Data Office (CDO) is harnessing data and making AT&T s data assets and ground-breaking AI functionality accessible to employees across the firm. In addition, our talented employees are a significant component that contributes to AT&T s place as the U.S. company with the sixth most AI-related patents. CDO also maintains academic and tech partnerships to cultivate the next generation of experts in statistics and machine learning, statistical computing, data visualization, text mining, time series modelling, data stream and database management, data quality and anomaly detection, data privacy, and more.\nWe are looking for an accomplished and visionary professional for the role of Associate Director, Data Science/Software Engineering to join our team and lead the development of cutting-edge software solutions. This is a hands-on leadership position that requires the fine balance of supervising and leading people while providing significant technical contributions to the projects you will be responsible for. As a key technical leader, you will leverage your expertise in full-stack development, DevOps best practices, Data analysis, AI/ML and Generative AI to lead your team in creating scalable, reliable, and efficient systems.\nThis role demands a strategic thinker and hands-on contributor who can work across multiple teams, drive innovation, and ensure technical excellence. You will be instrumental in shaping the technical roadmap, mentoring teams, and delivering transformative solutions that align with business objectives.\nKey Responsibilities:\nTechnical Leadership:\nDefine and drive the technical vision and architecture for scalable, resilient, and secure full-stack applications utilizing data powered insights.\nLead end-to-end software development projects from concept to deployment and maintenance.\nCollaborate with cross-functional teams to translate business requirements into technical solutions.\nServe as a mentor and technical advisor to engineering teams, fostering a culture of innovation and excellence.\nFull-Stack Development:\nDesign and implement scalable and high-performance web applications using modern front-end and back-end frameworks (e.g., React, Angular, Node.js, Python, Java).\nDevelop modular and reusable APIs (RESTful or GraphQL) with an emphasis on maintainability and performance.\nEnsure seamless integration of front-end and back-end systems while maintaining best practices for UI/UX design.\nOptimize database structures and queries for both relational (e.g., MySQL, PostgreSQL) and non-relational (e.g., MongoDB, DynamoDB) databases.\nDevOps and Automation:\nArchitect and implement CI/CD pipelines to streamline build, test, and deployment processes.\nEnsure seamless deployment and scalability of applications through containerization tools (e.g., Docker) and orchestration platforms (e.g., Kubernetes).\nLeverage infrastructure-as-code solutions (e.g., Terraform, Ansible) to automate infrastructure provisioning and management.\nMonitor application performance, troubleshoot issues, and ensure high availability through tools like Prometheus, Grafana, or New Relic.\nShell Scripting and Automation:\nDevelop and maintain shell scripts to automate routine tasks, system monitoring, and application deployments.\nDebug and troubleshoot production issues using scripting techniques to ensure minimal downtime.\nEnhance system efficiency by automating log analysis, error detection, and reporting.\nStrategic Contribution:\nCollaborate with stakeholders to align technical priorities with business goals.\nEvaluate emerging technologies and tools to recommend and implement solutions that advance the organization s technical capabilities.\nEstablish and enforce software engineering best practices, ensuring robust security, scalability, and maintainability.\nQualifications:\nEducation:\nBachelor s or Master s degree in Computer Science, Software Engineering, or a related field. A Ph.D. is a plus.\nExperience:\n13+ years of experience in software engineering, including hands-on experience with full-stack development and DevOps practices.\nProven track record of delivering large-scale, high-impact software solutions in a leadership capacity.\nTechnical Expertise:\nAdvanced proficiency in front-end frameworks (React, Angular, or Vue.js) and back-end technologies (Node.js, Python, Java, Go, etc.).\nStrong experience with DevOps tools (Jenkins, GitLab CI/CD, Docker, Kubernetes).\nDeep understanding of cloud platforms (AWS, Azure, GCP), including architecture and deployment strategies.\nSolid grasp of database technologies (SQL and NoSQL) and optimization techniques.\nProficiency in writing, debugging, and maintaining shell scripts for automation and system monitoring.\nStrong knowledge of microservices architecture, API gateways, and distributed systems.\nSoft Skills:\nExceptional problem-solving and critical-thinking abilities.\nStrong leadership and mentoring skills, with the ability to inspire and guide teams.\nExcellent communication skills, both written and verbal, to collaborate effectively with technical and non-technical stakeholders.\nStrategic mindset, capable of balancing technical depth with business impact.\nPreferred Qualifications:\nExperience with serverless computing frameworks (e.g., AWS Lambda).\nCertifications in cloud platforms (e.g., AWS Certified Solutions Architect, Azure DevOps Engineer Expert).\nKnowledge of security best practices in software development and DevOps.\n#DataEngineering\nLocation:\nIND:KA:Bengaluru / Innovator Building, Itpb, Whitefield Rd - Adm: Intl Tech Park, Innovator Bldg\nJob ID R-66889 Date posted 05/14/2025",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Data analysis', 'Front end', 'Postgresql', 'MySQL', 'Shell scripting', 'Telecommunication', 'SQL', 'Python']",2025-06-13 05:36:40
Audit Manager Vice President Data Analytics,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Analytics/Audit Manager, VP to lead audits within a dynamic environment. The person we seek will supervise audits and manage work within our CDO audit team, which is responsible for audit coverage of data management and data risk audit coverage strategy for Internal Audit. This is an individual contributor role.\nIn this role, you will:\nLead execution of the integrated audit process\nParticipate in audits in accordance with Wells Fargo Internal Audit policy",,,,"['Data Analytics', 'data management', 'Project management', 'data governance', 'data quality management', 'Risk management']",2025-06-13 05:36:42
MIS Executive,Pleasant Inc,0 - 3 years,Not Disclosed,['Surat'],"Job Description:\nKey Responsibilities:\nDevelop, maintain, and generate MIS reports, dashboards, and presentations for various business functions.\nDesign and automate reports to enhance operational efficiency.\nEnsure the accuracy, consistency, and timeliness of data across all reporting tools.\nSupport various departments (sales, finance, operations, HR, etc.) by providing customized reports and data-driven insights.\nAnalyze trends, variances, and patterns in data to provide actionable insights to management.\nEnsure that all reports are delivered within agreed timelines and meet business requirements.\nMaintain and update internal databases and ensure proper data integrity and accuracy.\nCreate and maintain databases, spreadsheets, and reports using advanced Excel functions and other reporting tools (e.g., Power BI, Tableau).\nCoordinate with IT teams for data system updates and improvements.\nWork closely with team members to understand their data and reporting needs.\nTroubleshoot data-related issues and ensure effective solutions are in place.\nSupport audits and compliance activities by providing necessary data.\nKey Skills :\nMis Executive\nData Analysis\nCoomunication\nStrategic Planning",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MIS reporting', 'Data analysis', 'Strategic planning', 'Financial operations', 'power bi', 'data integrity', 'Advanced Excel', 'Operations', 'Reporting tools', 'MIS Executive']",2025-06-13 05:36:43
Analyst - Direct Display,Aegis Media,1 - 3 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-13 05:36:45
Logistics Analyst 4,Lam Research,8 - 12 years,Not Disclosed,['Bengaluru'],"Logistics Analyst, Program Lead\nThe Logistics Analyst will be the point of contact for all SAP TMS system implementation, Training internal team and enhancement as part of Digital transformation\nPrimary Job Responsibilities:\nOperations Support\nRouting guide management\nEnsure booking of shipments for respective Logistics Service Providers (LSP)\nTrack & tracing and exception handling : BN4L exception management\nAbility to quickly react to unforeseen events and communicate with stakeholders as needed\nFreight Rate tender & Freight audit\nBN4L exception management\nFollow SOPs (Standard Operations Procedures) with great attention to details\nSAP TMS Administration & Troubleshooting\nUser management (user set up, onboarding and ongoing support)\nWork with core technical team and Training internal teams on new SAP TMS tools\nMaster data maintenance as needed\nTMS troubleshooting and communication between the user base and TMS BSA/service provider regarding system performance and outages\nSupport standardization and documentation of processes (SOP creation) as needed\nAnalytics\nReport generation and analysis turning data into actionable insights (improving transportation provider selection, route optimization, identifying cost reduction opportunities, etc.)\nGain insight over carrier performance to evaluate trends and pursue advantageous alternatives\nThe Group You ll Be A Part Of\nThe Global Operations Group brings information systems, facilities, supply chain, logistics, and high-volume manufacturing together to drive the engine of our global business operations. We help Lam deliver industry-leading solutions with speed and efficiency, while actively supporting the resilient and profitable growth of Lams business.\nThe Impact You ll Make\nAs a Logistics Analyst at Lam, youll orchestrate and streamline material flow, ensuring efficient supply chain operations and maintaining optimal inventory levels. Your role encompasses a broad set of responsibilities, including supply chain services, inventory control, and ensuring critical parts availability through enterprise warehouse and inventory systems. Your skilled analysis will support production planning and volume studies. Your expertise will be pivotal in optimizing Lams logistics plans for seamless operations.\nWhat You ll Do\nWho We re Looking For\nMinimum 8-12 years working experience in any of the following areas: Global Logistics Project/Program mgt, Global Transportation, SAP TMS & Trade operations in global environment\nPreferred Qualifications\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAP', 'Production planning', 'Cost reduction', 'Logistics Analyst', 'Inventory control', 'Analytics', 'Freight', 'Auditing', 'Logistics', 'Business operations']",2025-06-13 05:36:47
Programmer/Analyst 5,Lam Research,10 - 17 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\nLAM HR-Applications team is looking for a passionate, engaging Sr HR Applications Architect to join our growing team. This role will perform Technology evaluation, Identification, Solution Design, Execute the design for entire stack of HR-Applications echo-system and perform Production Support.\nThe Global Information Systems Group is dedicated to the success of Lam through providing best-in-class and innovative information system solutions and services. Together, we support users globally with data, information, and systems to achieve their business objectives.\nThe Impact You ll Make\nDesigns, develops, modifies, debugs and evaluates programs for functional areas, including but not limited to finance, human resources, manufacturing and marketing. Analyzes existing programs or formulates logic for new systems, devises logic procedures, prepares flowcharting, performs coding and tests/debugs programs. Develops conversion and system implementation plans. Prepares and obtains approval of system and programming documentation. Recommends changes in development, maintenance and system standards. Trains users in conversion and implementation of system. May be internal or external, client-focused, working in conjunction with Professional Services and outsourcing functions. May include company-wide, web-enabled solutions.\nWhat You ll Do\nLead design and implementation of the HR systems of the organization across HR technologies\nInterface with business stakeholders, assess feasibility of the requirements and guide the Technology Leads and Implementation teams to align the solution development\nFront-run the transformation and migration initiative in HR Applications COE ensuring a scalable solution to accommodate future enhancements and adoption to all BU s of Lam\nExplore new technologies and practices, be a part of the core team building an HR COE and define the standards and best practices\nAct as a SPOC/L3 for the current product support related activities and the\nHR-Echo System\nCross- training teams on knowledge transfer across business functions\nWho We re Looking For\nExcellent grasp of HR systems (both SAAS & On-Premises) technical and functional\nProven experience leading System Transformation, Integrations, Data Migrations, Implementations, Assessments and Process re-engineering.\n14+ years of experience as an HR Applications Architect\nVery strong communication and collaboration skills\nFlexible to travel and work hours.\nPreferred Qualifications",Industry Type: Electronic Components / Semiconductors,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Architect', 'Production support', 'Coding', 'Flex', 'Manager Technology', 'Process re-engineering', 'HR', 'Outsourcing', 'Product support', 'Team building']",2025-06-13 05:36:48
Hiring For MIS (Senior Analyst)-Chandigarh,Skyway Solution,1 - 4 years,1-4.25 Lacs P.A.,['Chandigarh'],"Hiring For MIS ( Senior Analyst)-Male\nLocation - Chandigarh\n\nGraduate\nExperience - 1year exp in MIS\n\nSalary - Up to 35,000/-\nRotational shift\n5 days working\nCandidate should must have knowledge of Advance Excel\n\nShare cv@9988352892\nHR -Sonali Rana",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Advanced Excel', 'MIS Operations', 'Formulas', 'Charts', 'MIS Reporting', 'Excel Reporting', 'HLOOKUP', 'Macros', 'Pivot Table', 'MIS', 'VLOOKUP', 'Data Analysis', 'Data Reporting']",2025-06-13 05:36:50
Senior Data Scientist,Straive,5 - 10 years,Not Disclosed,"['Hyderabad', 'Gurugram', 'Bengaluru']","Role & responsibilities\nRequires 5-8 years of proven experience in banking/payments/other domains\nStrong experience in developing Machine Learning models, Python & SQL\nExperience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases\nDetailed oriented with a proactive mindset towards problem-solving\nExcellent communication and presentation skills with the ability to convey complex information clearly and concisely",,,,"['Machine Learning', 'Python', 'SQL', 'Xgboost', 'Neural Networks', 'Random Forest']",2025-06-13 05:36:52
Business Analyst - D2C Ecommerce,Glan Management Consultancy,23 - 28 years,Not Disclosed,['Gurugram'],"Job Description:\nJob Title: Business Analyst\nLocation :Gurugram (On-site)\nExperienceRequired: 23 years in D2C/e-commerce sector\nSalary :Negotiable\nIndustry :Fashion/apparel/garment\nRole Overview:\nWere seeking a detail-oriented and data-driven BusinessAnalyst to join our team. Youll work closely with cross-functionalteamsmarketing, supply chain, tech, and operationsto drive insights, optimizeperformance, and support strategic decisions.\nKeyResponsibilities:\nAnalyze business data across channels (Shopify,GA4, Meta, Google Ads, marketplaces, CRM, WhatsApp, Insta, etc.) to identifytrends, gaps, and growth opportunities\nBuild dashboards and automated reports for keymetrics, including CAC, LTV, retention, inventory velocity, and marketing ROI\nCollaborate with marketing and product teams toevaluate the performance of campaigns, cohorts, and product launches\nDrive demand forecasting and supportchannel-wise distribution planning using historical data and market signals\nPrepare detailed reports and presentations forsenior leadership, highlighting key insights and recommendations.\nWork with finance and ops on margin analysis,pricing models, and contribution tracking\nConduct competitor benchmarking and consumerbehavior analysis to inform brand strategy\nConduct cost/benefit analysis, feasibilitystudies, and risk assessments for proposed solutions.\nRequirements;\n23 years of experience in a Business/DataAnalyst role, preferably in a D2C or e-commerce environment\nProficient in SQL, Excel/Google Sheets, and datavisualization tools (Looker Studio, Power BI)\nStrong grasp of e-commerce KPIs, retentionmetrics, and performance marketing analytics\nFamiliarity with tools like Shopify, GA4, MetaAds Manager, Google Ads Manager, Search Console, etc.\nExcellent communication and presentation skills\nKnowledge of CRM and marketing automationplatforms (e.g., WebEngage, MoEngage, Freshmarketer)\nComfortable working in a fast-paced, high-growthstartup environment\nMail updated resume with current salary-\nEmail: etalenthire@gmail.com\nSatish: 88O2749743\nWebsite: www.glansolutions.com\nGoogle search: Glan management Consultancy\nKey Skill:\nBusiness Analyst, Data Analyst, E-commerce Analytics, E-commerce Business Analyst, Digital Commerce Analyst, D2C (Direct-to-Consumer), Data Visualization, E-commerce KPIs, Retention Metrics\nPosted on: 10th Jun, 2025\nApply for Business Analyst - D2C Ecommerce\nSubmit\n\nApply Submit Resume Share with Friends (Mail)\n\n\nSee all Jobs",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business Analyst', 'Business Data Analyst', 'Demand forecasting', 'E-commerce', 'Data Analyst', 'data visualization', 'Analytics', 'CRM', 'SQL']",2025-06-13 05:36:53
Business Analyst,Purplle.com,1 - 4 years,Not Disclosed,['Mumbai'],"As a Business Analyst within our Operations team, you will play a pivotal role in leveraging data-driven insights to optimize processes, enhance operational efficiency, and drive strategic decision-making. Your responsibilities will involve utilizing a mix of technical skills and business acumen to interpret complex data sets, generate actionable insights, and support operational improvements.\n\nKey Responsibilities:\nCollaborate closely with cross-functional teams to understand operational requirements, identify opportunities for improvement, and define key performance indicators (KPIs) to measure success.\n\nAnalyze large datasets using SQL, Python, and advanced Excel techniques to extract, transform, and visualize data for operational reporting and decision making purposes.\n\nDevelop and maintain automated reports and dashboards using Power BI, Power Query, Tableau, Data Studios, Looker, and other visualization tools to communicate insights effectively.\n\nConduct in-depth analysis and interpretation of operational data to identify trends, patterns, and anomalies, providing actionable recommendations to drive operational excellence.\n\nUtilize strong aptitude and logical thinking to solve complex operational challenges and contribute to strategic initiatives that optimize workflows and enhance overall business performance.\n\nFoster strong stakeholder relationships through effective communication, presenting insights, and collaborating on operational strategies and solutions.\n\nRequired Skills and Qualifications:\nBachelor's degree in Business Administration, Data Science, Computer Science, or a related field.\n\nProficiency in SQL, Python, and advanced Excel for data analysis and manipulation.\n\nHands-on experience with Power BI, Power Query, Tableau, Data Studios, Looker, or similar visualization tools.\n\nStrong analytical and problem-solving abilities with a sharp aptitude for logical thinking.\n\nExcellent communication skills and the ability to effectively engage with stakeholders at all levels.\n\nProven track record of successfully managing and prioritizing multiple projects simultaneously in a fast-paced environment.\n\nStrong collaborative skills and the ability to work effectively in a team-oriented culture.\n\nPreferred Qualifications:\nExperience in the e-commerce industry or within a high-growth, dynamic environment.\n\nKnowledge of additional programming languages, statistical tools, or data modeling techniques.\n\nCertifications in business analysis, data visualization, or related fields.",Industry Type: Beauty & Personal Care,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analysis', 'bi', 'strong analytical skills', 'power bi', 'business analysis', 'analysis', 'dashboards', 'sql', 'business administration', 'data studio', 'excel', 'power query', 'tableau', 'data modeling', 'advanced excel', 'data visualization', 'communication skills']",2025-06-13 05:36:55
Business Analyst(BA),Utopian Dreams Private Limited,1 - 3 years,Not Disclosed,['Noida( Sector-2 Noida )'],"Job Profile:\n\nWe are currently seeking for Business Analysts proficient in Business analysis, Data Analysis, Agile Methodology, Project Management. Collaborate with project team and support test planning and working on UAT. To work closely with development team to ensure requirements are accurately mapped as per clients requirements. Also Coordinate with stakeholders to ensure timely and accurate delivery of reports in the required formats. As a Business Analyst at DistrictD, you have to identify trends, deviations, and areas of improvement. Develop and finalize management report templates with the Management team.\n\nDesignation: Business Analyst\n\nTech Stack: Agile Methodology / Project Management / Stakeholder Management\n\nLocation: Noida\n\nRoles and Responsibilities\nCollaborate with stakeholders to understand business requirements and translate them into technical specifications.\nDevelop and maintain documentation of project plans, progress reports, and issue logs.\nUtilize advanced excel skills to analyze data and create insightful reports for decision-making purposes.\nWork closely with cross-functional teams to identify areas for improvement and implement changes using Agile methodologies.\nProvide effective communication management by ensuring timely updates on project status to stakeholders.\nDesired Candidate Profile\n1-3 years of experience in Business Analyst (BA) role or related field.\n\nStrong understanding of Business Analytics, Business Analysis, Communication Management, Documentation, Data Analysis, SDLC Life Cycle & Project Management principles.\n\nProficiency in tools such as Advanced Excel, SQL, Power BI, Tableau; ability to learn new technologies quickly.\n\nYou must be an excellent problem solver with a passion of self-learning.\n\nBe an innovative and creative thinker, somebody who is not afraid to try something new",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analytics', 'Advanced Excel', 'Power Bi', 'Documentation', 'Tableau', 'SDLC Life Cycle', 'SDLC', 'SQL', 'Business Analysis', 'Software Development Life Cycle', 'Agile Methodology', 'Excel', 'Project Management', 'Communication Management', 'Data Analysis', 'Agile', 'Stakeholder Management']",2025-06-13 05:36:57
Senior Associate - Data Science,Axtria,3 - 8 years,Not Disclosed,['Noida'],"Job Summary-\nData Scientist with good hands-on experience of 3+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nJob Responsibilities-\n\n1. Hands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\n2. Proficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\n3. Experience of working in large teams and using collaboration tools like GIT, Jira and Confluence\n4. Good understanding of any of the cloud platform - AWS, Azure or GCP\n5. Understanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\n6. Should have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\n7. Should be able to mentor and guide mid to large sized teams under him/her\n\nJob -\n1. Strong experience on Spark with Scala/Python/Java\n2. Strong proficiency in building/training/evaluating state of the art machine learning models and its deployment\n3. Proficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\n4. Proficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'keras', 'spark mllib', 'jira', 'sentiment analysis', 'lingpipe', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-13 05:36:58
Senior Associate - Data Science,Axtria,2 - 5 years,Not Disclosed,['Noida'],"Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT\nSoftware development experience in python is needed as backend for UI based applications\nBe a part of large delivery teams working on advanced projects when expert assistance is required.\nDeliver advanced Data Science capabilities to businesses in a meaningful manner through successful proof-of-concept solutions, and later smoothly transition the proof-of-concept into production.\nCreate Technical documents, develop, test, and deploy data analytics processes using Python, SQL on Azure/AWS platforms\nCan interact with client on GenAI related capabilities and use cases\n\n\nMust have\n\nSkills:\n\n\nMinimum of 3-5years develop, test, and deploy Python based applications on Azure/AWS platforms\nMust have basic knowledge on concepts of Generative AI / LLMs / GPT\nDeep understanding of architecture and work experience on Web Technologies\nPython, SQL hands-on experience\nExpertise in any popular python web frameworks e.g. flask, Django etc.\nFamiliarity with frontend technologies like HTML, JavaScript, REACT",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'software testing', 'gpm', 'microsoft azure', 'python web framework', 'data analytics', 'neural networks', 'aws stack', 'machine learning', 'javascript', 'artificial intelligence', 'sql', 'react.js', 'deep learning', 'django', 'data science', 'html', 'flask', 'aws']",2025-06-13 05:37:00
Scientific Business Analyst (Specialist) - Biological Studies (LIMS),Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements LIMS platforms that enable the capture, analysis, storage, and report of pre-clinical and clinical studies as well as those that manage biological sample banks. You will collaborate with Product Owners and developers to maintain an efficient and consistent process, ensuring quality work from the team. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\n\n\n\n\nWe are all different, yet we all use our unique contributions to serve patients.\n\n\nMust-Have\n\n\nProfessional Certifications:\nSoft\n\nAs we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, well support your journey every step of the way.",,,,"['Biological Studies', 'computational biology', 'FDA 21 CFR Part 11', 'biopharma', 'GCP', 'bioinformatics', 'system validation', 'GLP', 'computational chemistry', 'GxP data']",2025-06-13 05:37:02
Business Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role we are seeking a Business Systems Analyst with a good background in data and analytics to define and manage product requirements for AI-driven applications.\nPartner with Data Scientists, ML Engineers, and Product Managers to define business processes, product needs, and AI solution requirements.\nCapture and document epics, user stories, acceptance criteria, and data process flows for AI-powered analytics applications.",,,,"['Business analysis', 'continuous integration', 'data science', 'gcp', 'ci/cd', 'microsoft azure', 'information systems', 'aws', 'artificial intelligence']",2025-06-13 05:37:03
Scientific Business Analyst ( Specialist ) - Large Molecule Discovery,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that they technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role demonstrates scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams.",,,,"['Business Analysis', 'Spotfire', 'Power BI', 'Tableau', 'Databricks', 'JIRA', 'LLM', 'AWS', 'SQL']",2025-06-13 05:37:05
Business Analyst,Arting Digital,1 - 4 years,Not Disclosed,['New Delhi'],"- Documenting Requirements:\n-Clearly and concisely documenting the gathered requirements in the from of user.\n-Examining and breaking down complex requirements/epics into manageablefeatures and user stories.\n-Establishing clear and measurable acceptance criteria that will be used todetermine if the delivered solution is acceptable to the stakeholders.\n- Prioritizing Requirements: Working with functional team including functional leadsand product owners to prioritize requirements based on business value and otheragreed identifies.\n- Managing Requirements Traceability: Establishing and maintain traceability betweenfeatures, user stories, design elements, and testing artifacts to ensure that thedelivered solution meets the release goals and objectives.\n- Managing Requirements Changes: Facilitating the process of managing changes torequirements throughout the project lifecycle.\n- Participating in Testing: Involved in reviewing test plans and test cases, to ensure thesolution meets the requirements.\n- Serving as a Liaison: Acting as a communication bridge between businessstakeholders and technical teams. Working closely with Functional lead for the same.\n- Collaborate with stakeholders (business users, product owners, and technical teams) tounderstand business needs and gather detailed requirements for new and ongoingprojects.\n- Analyze and document current business processes, identify opportunities forimprovement, and propose process optimization solutions.\n- Prepare clear and concise functional specifications and user stories for developmentteams, ensuring alignment with business objectives.\n- Work closely with Scrum Masters and Product Owners in Agile ceremonies (e.g., sprintplanning, backlog refinement) to ensure business requirements are captured,prioritized, and clearly understood by development teams.\n- Serve as the primary liaison between business stakeholders and technical teams toensure clear communication and alignment on project objectives, requirements, andprogress.\n- Perform data analysis, create reports, and assist in defining KPIs to track businessperformance and help decision-making.\n- Support & Own the UAT process, lead product demos along working with users tovalidate the delivered solutions against business requirements.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['IT services', 'Functional Lead', 'Data analysis', 'Process optimization', 'Business Analyst', 'Management', 'Test cases', 'Process Lead', 'Testing', 'Salesforce']",2025-06-13 05:37:07
Business Analyst,WP Translation And Testing Services,1 - 4 years,5-7 Lacs P.A.,['Navi Mumbai'],"Role - Business Analyst Software Testing Products\nExperience 1-3 Years\nLocation Ghansoli, Navi Mumbai\nNotice period – Immediate – 30 days\nJob Type – Contract (6-9 Months)\n\nWP is looking for a results-oriented Business Analyst with 1-2 years of experience in software product development, specializing in quality assurance (QA) and testing solutions. The candidate should have expertise in gathering and analyzing business requirements by coordinating with relevant stakeholders, act as an interface between stakeholders and development teams, and contribute to the development of scalable, user-friendly test management and testing automation products.\n\nResponsibilities:\n• Collaborate with development team, UI/UX engineering and QA, assist on continuous basis to shape product features aligned with product testing workflows.\n• Research and document requirements from stakeholders and product owners.\n• Document detailed functional specifications and write user stories. Prioritize tasks using internal task management tool.\n• Worked closely with developers to validate logic and alignment with product requirements & functionalities.\n• Perform UAT, validate test cases, and coordinate with QA for release signoffs.\n\nKey Skills:\n• Business analysis expertise with software testing experience will be an added advantage\n• Agile Software Development Lifecycle (SDLC) understanding\n• Exposure to various tools like TestRail, Jira, Bugzila, etc.\n• Workflow Design & User Story Creation (Agile/Scrum)\n• Background of API & Integration Requirement Analysis\n• SQL & Basic Data Analysi",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Agile', 'JIRA', 'SDLC Life Cycle', 'SQL', 'Testrail', 'Scrum', 'API', 'Bugzilla']",2025-06-13 05:37:09
Business Analyst (Capital Markets),Eagle Technology Resources,5 - 10 years,Not Disclosed,[],"Job Title: Business Analyst Capital Markets\nLocation: Bhuvaneswar/Chennai/Remote Work\nSalary: Based on competency\nRequired Skills (Domain):\nCandidate must possess minimum of 5+ years of experience in Banking and Financial services domain with Investment Management experience.\nGood understanding of the systems, workflows and data related to front, middle, and back-office solutions in Asset Servicing/Asset Management.\nStrong grasp of Investment operational processes with respect to Accounting, Pricing, Nav Calculation, Trade Settlement, Reconciliation, Reference Data Management, Corporate Actions etc\nHands-on experience in Eagle suit of products (Accounting, RDC/SRM, Data Management or Performance) is a must.\nClient interfacing skills, Requirements gathering, Data Analysis skills and Test Execution skills are mandatory\nGood understanding of Market Data and operational workflow related to EQ, Fixed Income, Derivatives (Options, Futures, Swaps, etc) and/or Alternatives are a must\nStrong understanding of data integration, meta data management and ability to run SQL queries to perform data analysis are must to have.\nStrong communication and Documentation skills are mandatory Exposure to Third-party data providers such as Bloomberg, Reuters, MSCI, and other rating agencies is a plus.\nThis is what you will do:\nThis position requires a highly motivated individual with the ability to work independently and as part of a project team.\nYou will :\nBe working with the client team to gather requirements, demonstrate product capabilities, define/streamline Business Processes, train the client team on product modules, triage, debug, and fix quality issues through resolution.\nMust rationalize problems and use judgment and innovation to define clear and concise solutions.\nPerform gap analysis or conduct Proof of concepts where necessary\nPrepare Functional Requirements and to articulate them to Client Stakeholders to pursue approvals.\nHandle client expectations and manage the delivery of related interfaces by internally coordinating with teams across the globe.\nPrepare test bed for UAT executions\nBe writing test cases, test plans and preparing detailed test logs with suitable proof of validation.\nBe writing SQL queries to validate voluminous data across systems and performing reconciliation.\nCollaborate across regions (APAC, EMEA, and NA) to effectively and efficiently identify root cause of code/data issues and come up with a permanent solution.\nTeam Overview:\nThe dedicated team of highly skilled professionals at Eagle Technology Resources Pvt Ltd work on ensuring deployment of innovative solutions for the complex world of finance. Our extensive experience helps clients bring to life their business and technology operations, as well as gain the most value from their ongoing investments in technology.\nThis is what you will get:\nCompetitive compensation package.\nA close and informal relation with the client’s team (We are treated as the extension of the project team of our client).\nChallenging product development work with a team of professionals.\nDynamic environment with very low level of bureaucracy.\nFlexible working hours with the option to work from home under certain circumstances.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Data Management', 'Fixed Income Analysis', 'Capital Market', 'Market Data', 'Requirement Gathering', 'Reconciliation', 'Middle Office Operations', 'Derivatives', 'Consulting And Implementation', 'Trade Settlements', 'Investment Management', 'SQL']",2025-06-13 05:37:11
Technical Business Analyst,Euclid Innovations,10 - 20 years,Not Disclosed,[],"Hi ,\nGreetings from Euclid Innovations !!!\n\nWe have openings for Technical Business Analyst with one of our Banking based Company as Remote work Mode.\n\nPosition : Technical Business Analyst\nExperience : 10+ Years\nLocation : Remote\nNotice Period: Immediate to 20 Days Max\n\nSkills set: FINANCIAL /CAPITAL MARKET and FIXED INCOME, EQUITY, CREDIT, Bond, Investment Banking any\n\nDuties and Responsibilities\nAssist in the Business Analysis phase including the capture and translation of business requirements turning these into functional requirements, and non-functional requirements (i.e. architectural, infrastructure, security, testing, migration, operational, DR). Ensuring appropriate documentation of requirements is captured and recorded (e.g. 'Requirement Story' in JIRA).\nAnalysing end to end business streams to establish data requirements in line with XML/XSD modelling, specifically FpML, of entities across multiple business areas across multiple geographical regions.\nLogical Data Modelling working closely with both business and IT teams.\nIdentification of common data requirements and helping to drive shared data platforms.\nCleaning, mapping, and extending data sets to improve business processes and tools.\nCoordination and delivery management of solutions across Enterprise Delivery teams in support of end to end testing and production delivery.\nAdherence to existing global, local and department project standards for documentation, security, testing and release management.\nQualifications, Skills and Experience\nBachelors Degree or equivalent.\nExcellent technical analysis and investigatory skills.\nAbility to work with both business and IT staff in a pressured environment.\nBusiness analysis within an Agile development project.\nStrong data analysis skills to ensure accurate system data extracts and reconciliations working with large datasets.\nProven track record of writing structured business requirements and functional specifications.\nWorking knowledge of financial instruments: government bonds, SAS bonds, credit bonds, exchange traded bond futures, interest rate swaps, repos, stock lending and equities.\nWell-structured and logical approach to working.\nGood knowledge of Compliance business processes.\nProven track record of supporting Back/Middle Office systems.\nProven experience of developing mutually beneficial relationships with business stake holders, users, software solution providers, and other IT teams.\nProven experience of full involvement in project life cycles within Investment Banking.\nProven experience performing system testing and guiding users with building their functional plans for user testing.\nAbility to handle multiple work streams and assignments simultaneously.\nProven experience of issue resolution through data mining and investigation\n\nif interested share profile to aruna.c@euclidinnovations.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Capital Market', 'Data Modelling', 'Investment Banking', 'Business Analyst', 'Technical Business Analyst', 'XML', 'XSD', 'Fixed Income', 'EQUITY']",2025-06-13 05:37:13
BPEX (Business Process Excellence) - Malad,Motilal Oswal Financial Services (MOFSL),0 - 4 years,Not Disclosed,['Mumbai (All Areas)'],"Role & responsibilities\n1. Work full time on improvement projects\n2. Deliver BPEX trainings\n3. Support MBB/BB in projects\n4. Support Organization wide BPEX initiatives\n\nKey Work Relationships:\n\n1.Internal\n\nInvolving project team members including process owners, influencing people and driving process excellence across the organization\n2.External\n\nLimited\n\nPreferred candidate profile\n1.Experience - 0-2 years overall experience\n2.Other Skills - Good analytical and communication skills",Industry Type: Financial Services (Broking),Department: Quality Assurance,"Employment Type: Full Time, Permanent","['Lean Six Sigma', 'Process Excellence', 'Process Automation', 'Project Documentation', 'Six Sigma Certified', 'Process Documentation', 'Green Belt', 'Business Improvement', 'Yellow Belt', 'Data Analysis', 'Process Optimization', 'Business Excellence', 'BPEX']",2025-06-13 05:37:15
Senior Analyst,Vestas,4 - 7 years,Not Disclosed,['Chennai'],"The main purpose of this position is to support Digital Procurement products and day-to-day handling of the L1/ L2 technical incidents, ensuring smooth operation, optimization, and continuous improvement of procurement systems such as SAP Ariba, ECC or similar platforms, reporting to Procurement System Support Team Manager. The Senior Analyst works with Digital Procurement Product owners, Direct/Indirect procurement buyers, Purchasers Sourcing responsible to support system bugs/errors or route enhancement requests from line of business in the production system such as SAP Ariba, Go Buy and Ariba buyer network. The successful person must be a self-starter and could work on their own with Digital Procurement Product Owners, Line of Business and technical teams. Its key that they could build up relationships with the business and gain credibility and respect to fully engage the business users in the Procurement operations.",,,,"['Automation', 'Data analysis', 'SAP', 'Social media', 'System integration', 'Incident management', 'MS Office', 'Information technology', 'Monitoring', 'Ariba']",2025-06-13 05:37:16
Sr Tax Analyst,Illumina,4 - 7 years,Not Disclosed,['Bengaluru'],"What if the work you did every day could impact the lives of people you know? Or all of humanity?\nJoin us and you can make a difference\nIllumina s mission is to improve human health by unlocking the power of the genome. If that inspires you, let s talk.\nAt Illumina, we push boundaries. We think beyond the conventional. We dream big. With the energy of so many bright and accomplished people, the opportunities are endless. You ll join a culture fueled by innovation, collaboration and openness. We change lives by driving advancements in life sciences, oncology, reproductive health, genetic disease and other emerging markets. We are all deeply passionate about what we do, knowing that our work has the power to improve lives.\nJob Summary\nIllumina is looking for Tax Analyst/Sr Tax Analyst to be part of newly created Tax Center of Excellence in India and reports to Tax Manager in India. This role will be APAC tax compliance focused and primarily responsible in all aspects of data analysis, tax calculation and reconciliation necessary to meet APAC tax filing, tax audit and statutory audit requirements in APAC region. You will support the Tax Manager in fostering seamless collaboration with global/regional Finance and Tax teams, and other business stakeholders to ensure the adherence of tax compliance governance and efficient tax process maintained in the region.\nTasks and Responsibilities:\nJob duties include but not limited to:\nPrepare monthly tax calculation for APAC entities, this includes extracting SAP reports, analyzing and reconciling financial data, and coordinating with finance teams.\nCollation and managing all aspects of information necessary for submission in tax audits, inquiries and notices raised by tax authorities.\nPerform financial data analysis/schedules/reports necessary for internal and external tax reporting for APAC entities\nInvolve in month-end/statutory audit activities, this includes preparing tax provision/deferred tax calculation and reconciliation relating to tax accounts for APAC entities\nIdentify and drive opportunities for process optimization within the tax reporting workflow, which includes collaborating with internal stakeholder to align processes and implementing into the working environment.\nResearch tax regulations to address daily inquiry on TDS/GST/withholding tax/SAC coding\nParticipate in cross-functional projects and tax projects as and when assigned by the Regional Tax Team/Tax Manager\nPreferred Educational Background:\nBachelor s degree or equivalent in Accounting/Finance/Taxation.\nMinimum 4-7 year in accounting with direct and indirect tax from Big 4 or Accounting with taxation experience. APAC region exposure is a plus\nProficiency in Microsoft Office applications especially Microsoft Excel;\nPrior experience in SAP (or equivalent ERP system) is preferred;\nGood organizational skills, highly detailed oriented and ability to work with minimal supervision and independently;\nAbility to work in a dynamic and fast paced environment and a multi-tasker;\nAbility to be flexible and work analytically in a problem-solving environment;\nExcellent communication (written and oral) and interpersonal skills.\n\nWe are a company deeply rooted in belonging, promoting an inclusive environment where employees feel valued and empowered to contribute to our mission. Built on a strong foundation, Illumina has always prioritized openness, collaboration, and seeking alternative perspectives to propel innovation in genomics. We are proud to confirm a zero-net gap in pay, regardless of gender, ethnicity, or race. We also have several Employee Resource Groups (ERG) that deliver career development experiences, increase cultural awareness, and offer opportunities to engage in social responsibility. We are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. Illumina conducts background checks on applicants for whom a conditional offer of employment has been made. Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable local, state, and federal laws. Background check results may potentially result in the withdrawal of a conditional offer of employment. The background check process and any decisions made as a result shall be made in accordance with all applicable local, state, and federal laws. Illumina prohibits the use of generative artificial intelligence (AI) in the application and interview process. . To learn more, visit: https: / / www.dol.gov / ofccp / regs / compliance / posters / pdf / eeopost.pdf. The position will be posted until a final candidate is selected or the requisition has a sufficient number of qualified applicants. This role is not eligible for visa sponsorship.",Industry Type: Biotechnology,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['TDS', 'Data analysis', 'Process optimization', 'SAP', 'Excel', 'Coding', 'Tax reporting', 'Workflow', 'Taxation', 'Auditing']",2025-06-13 05:37:18
Supplier Quality Management Senior Analyst,Vertiv Group Corp,5 - 8 years,Not Disclosed,['Mumbai'],"Vertiv Group Corp is looking for Supplier Quality Management Senior Analyst to join our dynamic team and embark on a rewarding career journey.\nThe Senior Analyst plays a crucial role in driving data-driven decision-making processes within the organization\nThis position involves analyzing complex data sets, generating actionable insights, and providing strategic recommendations to support key business initiatives\nKey Responsibilities:Data Analysis:Conduct in-depth analysis of large and complex datasets to extract meaningful insights",,,,"['inprocess quality', 'sqa', 'data analysis', 'apqp', 'quality control', 'iso', 'control plan', 'spc', '7qc', 'pfmea', 'incoming quality', '8d', 'fmea', 'supplier quality assurance', 'quality assurance', 'qms', 'vendor quality', 'supplier quality', 'msa', 'supplier audit', 'ppap', 'customer quality']",2025-06-13 05:37:20
Analytics and Modeling Senior Analyst,Overture Rede,2 - 5 years,Not Disclosed,['Bengaluru'],"Lead sales reporting, business analysis, and team development to enable data-driven decision-making and support sales enablement strategies.\n\nJob Summary\nWe are seeking an experienced Analytics and Modeling Senior Analyst to drive insights and reporting for sales enablement initiatives. The role involves managing analytics processes, mentoring teams, and supporting strategic decision-making through accurate data reporting and business intelligence.\n\nRequired Skills\n5+ years in sales operations and data analysis\nAdvanced Excel skills; Power Query, Power Pivot, Power BI preferred\nExperience in Software & Platforms and cloud/data infrastructure\nExcellent communication and stakeholder management\nProficiency in MS Office Suite (Excel, Word, PowerPoint, Outlook)\nExpertise in workflow management, process mapping, and training delivery\nStrong in RCA, collaboration, and team coaching",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MS Office suite', 'RCA', 'Data analysis', 'Sales operations', 'Business analysis', 'Senior Analyst', 'sales enablement', 'Business intelligence', 'Stakeholder management', 'Analytics']",2025-06-13 05:37:21
Sr Tax Analyst,Illuminz,4 - 7 years,Not Disclosed,['Bengaluru'],"What if the work you did every day could impact the lives of people you know? Or all of humanity?\nAt Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients.\nWorking at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world changing projects, you will do more and become more than you ever thought possible.\nJoin us and you can make a difference\nIllumina s mission is to improve human health by unlocking the power of the genome. If that inspires you, let s talk.\nAt Illumina, we push boundaries. We think beyond the conventional. We dream big. With the energy of so many bright and accomplished people, the opportunities are endless. You ll join a culture fueled by innovation, collaboration and openness. We change lives by driving advancements in life sciences, oncology, reproductive health, genetic disease and other emerging markets. We are all deeply passionate about what we do, knowing that our work has the power to improve lives.\nJob Summary\nIllumina is looking for Tax Analyst/Sr Tax Analyst to be part of newly created Tax Center of Excellence in India and reports to Tax Manager in India. This role will be APAC tax compliance focused and primarily responsible in all aspects of data analysis, tax calculation and reconciliation necessary to meet APAC tax filing, tax audit and statutory audit requirements in APAC region. You will support the Tax Manager in fostering seamless collaboration with global/regional Finance and Tax teams, and other business stakeholders to ensure the adherence of tax compliance governance and efficient tax process maintained in the region.\nTasks and Responsibilities:\nJob duties include but not limited to:\nPrepare monthly tax calculation for APAC entities, this includes extracting SAP reports, analyzing and reconciling financial data, and coordinating with finance teams.\nCollation and managing all aspects of information necessary for submission in tax audits, inquiries and notices raised by tax authorities.\nPerform financial data analysis/schedules/reports necessary for internal and external tax reporting for APAC entities\nInvolve in month-end/statutory audit activities, this includes preparing tax provision/deferred tax calculation and reconciliation relating to tax accounts for APAC entities\nIdentify and drive opportunities for process optimization within the tax reporting workflow, which includes collaborating with internal stakeholder to align processes and implementing into the working environment.\nResearch tax regulations to address daily inquiry on TDS/GST/withholding tax/SAC coding\nParticipate in cross-functional projects and tax projects as and when assigned by the Regional Tax Team/Tax Manager\nPreferred Educational Background:\nBachelor s degree or equivalent in Accounting/Finance/Taxation.\nMinimum 4-7 year in accounting with direct and indirect tax from Big 4 or Accounting with taxation experience. APAC region exposure is a plus\nProficiency in Microsoft Office applications especially Microsoft Excel;\nPrior experience in SAP (or equivalent ERP system) is preferred;\nGood organizational skills, highly detailed oriented and ability to work with minimal supervision and independently;\nAbility to work in a dynamic and fast paced environment and a multi-tasker;\nAbility to be flexible and work analytically in a problem-solving environment;\nExcellent communication (written and oral) and interpersonal skills.\n\nWe are a company deeply rooted in belonging, promoting an inclusive environment where employees feel valued and empowered to contribute to our mission. Built on a strong foundation, Illumina has always prioritized openness, collaboration, and seeking alternative perspectives to propel innovation in genomics. We are proud to confirm a zero-net gap in pay, regardless of gender, ethnicity, or race. We also have several Employee Resource Groups (ERG) that deliver career development experiences, increase cultural awareness, and offer opportunities to engage in social responsibility. We are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. Illumina conducts background checks on applicants for whom a conditional offer of employment has been made. Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable local, state, and federal laws. Background check results may potentially result in the withdrawal of a conditional offer of employment. The background check process and any decisions made as a result shall be made in accordance with all applicable local, state, and federal laws. Illumina prohibits the use of generative artificial intelligence (AI) in the application and interview process. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https: / / www.dol.gov / ofccp / regs / compliance / posters / pdf / eeopost.pdf. The position will be posted until a final candidate is selected or the requisition has a sufficient number of qualified applicants. This role is not eligible for visa sponsorship.",Industry Type: Pharmaceutical & Life Sciences,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['TDS', 'Data analysis', 'Process optimization', 'SAP', 'Excel', 'Coding', 'Tax reporting', 'Workflow', 'Taxation', 'Auditing']",2025-06-13 05:37:23
Content Mgmt Advisory Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Marketing Operations - Content management\n\n\n\n\nDesignation: Content Mgmt Advisory Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designOrganize, categorize and publish content and information using specific tools and channels, for use by different groups and individuals within the organization.\n\n\n\n\nWhat are we looking for\nCommitment to quality Process-orientation Detail orientation Written and verbal communication Strong writing and editing background, preferably with a portfolio of past work Experience in corporate communications and project management Experience with remote, cross-functional teams and communicating with shareholders Ability to analyze data that drives business decisions Excellent organization and communication skills, good at managing projects Proficiency with the Google suite a plus Ability to work in a fast-paced, deadline-driven environmentHigh school diploma required, Associates preferred. Will accept equivalent workexperience (2-3 years) in lieu of degree.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shiftsReplicate/copy provided content, ensuring accurate transcription and duplicationCreate, edit and publish content for various topics, including strategy, organizationalmanagement, education and help center supportWork closely with POCs and SMEs to formulate content relevant for the task/scope of theassignmentSeeks opportunities to improve knowledge, skills, and performance by reviewingknowledge base content, practicing skills and being receptive to coaching andconstructive feedbackProduce documents that convey strategy, status, reorganization, scope, timelines, taskplanning, action items, risks, issues, project dependencies, test planning, or rolloutplanningMonitor project performance and timelines, setting and meeting deadlines as necessaryMaintain confidentiality of our partners contentAble to function well with a team in a highly-collaborative cross-functional environment,but still able to work as an individual contributor to track down answers to properlyformulate contentAbility to think on your feet and adapt to changing circumstances and situations\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Content, Editorial & Journalism","Employment Type: Full Time, Permanent","['digital marketing', 'content management', 'editing', 'google suite', 'content analysis', 'data analysis', 'dns', 'content editing', 'content development', 'system administration', 'windows system administration', 'active directory', 'content writing', 'windows server', 'dhcp']",2025-06-13 05:37:25
Advertising Sales Rep Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Digital Inside Sales - Inside Sales\n\n\n\n\nDesignation: Advertising Sales Rep Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nTransforming sales to become a future-ready and digital B2B revenue engine.The team helps assess, design, build and implement best practices on process, organization, and technology to create, execute, and run a collaborative sales and support roles.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\n\nWhat are we looking for\nProvide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['business development', 'sales', 'inside sales', 'marketing', 'sales analysis', 'data analysis', 'sales forecasting', 'mis reporting', 'market research', 'sales support', 'sales operations', 'lead generation', 'advanced excel', 'mis', 'sales coordination', 'sales planning']",2025-06-13 05:37:27
GN - SONG - Service - CX - Value Architect - Analyst,Accenture,2 - 5 years,Not Disclosed,['Gurugram'],"Template\n\nJob Title - GN - SONG - Service - CX - Value Architect - Analyst\n\nManagement Level :11 - Analyst\n\nLocation:Delhi, Gurgaon, Mumbai, Bangalore, Chennai, Pune, Hyderabad\n\nMust have skills:Value Realization\n\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute\n\nJob\n\n\nSummaryAs part of the team, you will provide transformation services driven by key offerings like Living Marketing, Connected Commerce and Advanced Customer Engagement. These services help our clients become living businesses by optimizing their marketing, sales and customer service strategy, thereby driving cost reduction, revenue enhancement, customer satisfaction and impacting front end business metrics in a positive manner.\nRoles & ResponsibilitiesTranslate strategic objectives into high-impact use cases in the specific area of expertise.\nUnderstand clients business priorities and focus areas to identify the right business scenarios and impacted value levers (KPIs) to include in the business case.\nIdeate and execute on compelling value creation workshops.\nConduct detailed qualitative and quantitative research to lay the foundation of a strong business case.\nOwn every stage of the value creation process, from research and identification to value drafting and dashboarding.\nDefine value architecting requirements and work with Accenture teams to deliver solutions.\nAdvise clients on industry best practices (when appropriate).\nAccurately estimate time to complete work.\nContinually experiment with new tools, technologies and sharpen analytical skills.\nAbility to research and provide strategic, goal-driven solutions for clients.\nCollaborate with other value architects, both offshore & onshore, including client-side managers, business heads, and other stakeholders across the organization.\nProvide useful contributions to team meetings and conversations, actively participating in client meetings and workshops- Ability to create hypothesis based on understanding of clients issues.\nProfessional & Technical\n\n\n\n\nSkills:\nApply best of breed Excel practices- Deep-dive with solid knowledge of formulas & macros to bring in speed & efficiency.\nMaximize experience in developing interactive models:Use relevant dashboard creation platforms (Power BI, Tableau, etc.) to design and apply interactive dashboards.\nInnovate with Creativity:Demonstrate an ability to work in a fast-paced environment with the ability to abstract value into compelling business story.\nParticipate in pre-sales activities including response to RFPs, creating proofs of concept, creating effective presentations, demonstrating solutions during client orals, effort and cost estimation process, etc.\nParticipate in practice-specific initiatives including creating points of view, creating reusable assets on contact center space, performing analysis on industry research and market trends and bringing in innovative solutions, etc.\nAdditional InformationGood understanding of sales, service & marketing as a function\nSolid experience in developing quantitative models.\nConducting qualitative & quantitative research\nAnchoring client/senior stakeholder conversations\nCreating engaging storyboards using the best data visualization tools such as Power BI, Tableau, etc.\n\nAbout Our Company | AccentureQualification\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ssas', 'bi', 'power bi', 'sql', 'tableau', 'python', 'data analysis', 'oracle', 'data warehousing', 'pivot table', 'microsoft azure', 'business analysis', 'vlookup', 't-sql', 'business intelligence', 'sql server', 'plsql', 'data modeling', 'advanced excel', 'ssrs', 'data visualization', 'ssis', 'etl', 'msbi']",2025-06-13 05:37:29
Digital Content Management Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Salesforce Marketing Cloud\n\n\n\n\nDesignation: Digital Content Management Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires:SFMC Campaign QA""HTML and CSS:Familiarity with HTML and CSS coding for email template customization and troubleshooting rendering issues.Digital Marketing:Understanding of broader digital marketing strategies and tactics to align SFMC campaigns with overall marketing objectives.UX/UI Design:Knowledge of user experience (UX) and user interface (UI) design principles to improve the visual appeal and usability of campaign assets.""You will help design, implement & manage Salesforce Marketing Cloud, a customer relationship management (CRM) platform for marketers that allows them to create and manage marketing relationships and campaigns with customers. You will help incorporate incorporates integrated solutions for customer journey management, email, mobile, social, web personalization, advertising, content creation and management, and data analysis.\n\n\n\n\nWhat are we looking for\nQuality Assurance (QA)Quality AuditingSalesforce Marketing CloudMust Have\n\n\n\n\nSkills:\nSalesforce Marketing Cloud Expertise:In-depth knowledge of SFMC functionalities, including Email Studio, Mobile Studio, Automation Studio, and Journey Builder. Knowledge of AMPscripts, SSJS personalization language along with Proficiency in SQL.Campaign Management:Experience in end-to-end campaign execution, including segmentation, audience targeting, content personalization, and journey automation.Quality Assurance:Strong attention to detail and ability to conduct rigorous testing and validation of campaign setups.Technical Troubleshooting:Proficiency in identifying and resolving technical issues related to SFMC configurations and data integration.Marketing Automation:Understanding of marketing automation principles and best practices for customer engagement and conversion.Data Analysis:Basic data analysis skills to interpret campaign performance metrics and make data-driven recommendations.Collaboration:Excellent communication skills to collaborate effectively with cross-functional teams and convey complex technical concepts to non-technical stakeholders.Requirement:Campaign Review:Conduct thorough reviews of marketing campaign requirements and specifications to understand the campaign objectives, target audience, segmentation rules, and personalization requirements.Quality Assurance Testing:Execute testing of campaign setups across different channels Email, SMS, Push, Direct mail, social, paid campaign etc., data queries, to validate the accuracy and functionality of the campaign components.Data Validation:Verify the integrity of data used in the campaigns, including audience lists, data extensions, and dynamic content personalization, to ensure that the right message is delivered to the right audience.Journey Testing:Validate customer journeys and automation workflows to ensure that subscribers progress through the intended paths and receive the appropriate messages at each stage.Compliance and Best Practices:Ensure email campaigns adhere to email marketing best practices, data privacy regulations, and anti-spam laws.Campaign Optimization:Provide insights and recommendations to optimize campaign performance, increase engagement, and achieve better conversion rates.A/B Testing:Support A/B testing efforts by setting up and validating test campaigns,\n\n\n\nRoles and Responsibilities: Documentation:Maintain comprehensive documentation of campaign testing processes, results, and issue resolutions.Collaboration:Work closely with marketing teams, project managers, data analysts, and developers to address campaign-related challenges and implement improvements.Collaborate with development team to ensure that creative build align with the campaign objectives and data build.Continuous Improvement:Stay updated with the latest SFMC features, best practices, and industry trends to enhance campaign build quality and overall marketing effectiveness.Work Orchestration and Data hygiene:Fully understand ticketing/request management tool and accurately record updates, data points, timestamps etc. to provide seamless experience to both internal and external stakeholders.Adhere to all Desktop Procedures (DTPs) / Standard Operating Procedures (SOP) along with checklist and other important process document to carry out all required tasks.Complete all required reports so that accurate numbers are reported to both client and leadership.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Content, Editorial & Journalism","Employment Type: Full Time, Permanent","['css', 'sql', 'salesforce marketing cloud', 'html', 'sfmc', 'standard operating procedures', 'digital marketing', 'project management', 'data analysis', 'digital content', 'content management', 'content creation', 'salesforce', 'marketing', 'desktop', 'content writing', 'marketing operations']",2025-06-13 05:37:31
S&C - GN - CFO EV - RC - Analyst,Accenture,1 - 3 years,Not Disclosed,['Mumbai'],"Job Title Risk and Compliance- Analyst- S&C GN-CFO&EV\n\n\n\nManagement Level:11 Analyst\n\n\n\nLocation:Gurgaon, Mumbai, Bangalore, Pune, Hyderabad\n\n\n\nMust have skills:Risk modelling\n\n\n\n\nGood to have skills:Credit risk, Market risk, Liquidity risk\n\n\n\nExperience:1-3 years\n\n\n\n\nEducational Qualification:MBA(Finance) or CA or CMA\n\n\n\nJob\n\n\nSummary:\nAdvise financial and non-financial Institutions across risk management areas such as risk strategy, transformation programs, enterprise risk, portfolio management, capability maturity assessments, fraud and financial crime risk compliance.\nPartner with global deal teams in selling, shaping and solution development of client deals by providing subject matter expertise on risk related topics.\nShape thought capital around current and emerging risk management topics and contribute to development of Accenture points-of-view on risk trends and issues.\nSupport practice development through various activities such as staffing, quality management, capability development and knowledge management.\nBuild strong relationships with global Accenture Risk Management teams, and develop existing relationships based on mutual benefit and synergies.\n\n\n\n\nRoles & Responsibilities:\nGood project management skills and demonstrated experience in managing teams across functions and geographies\nStrong business acumen and knowledge of risk management process\nAbility to solve complex business problems and deliver client delight\nStrong writing skills to build point of views on current industry trends\nGood analytical and problem-solving skills with an aptitude to learn quickly\nExcellent communication, interpersonal and presentation skills\nCross-cultural competence with an ability to thrive in a dynamic consulting environment\n\n\nQualification\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\nMBA from Tier-1 B-schools with specialization in risk management\n2-5 years of risk management experience at one or more Financial Services institutions, Rating Agency or Professional Services OR Risk Advisory with an understanding of one or more of the following areas:\n\n\n\n\nCredit risk measurement for the purpose of financial instruments impairment and/or capital requirements calculation (PD, LGD, EAD methodologies), Credit Risk Underwriting Frameworks, Risk Based Pricing, Early Warning Systems, Credit Policy & Limit Management, Collections Frameworks, Counterparty credit risk management and experience on counterparty risk methodologies such as PFE, EPE.\n\n\n\n\nMarket risk measurement and management-related topics including operational processes, technologies, modelling approaches, risk aggregation and reporting, FRTB:Expected Shortfall, Default Risk Charge, NMRF; IBOR or LIBOR Transition experience.\n\n\n\n\nOperational risk management\n\n\n\nframework and methodology.\n\n\n\n\nLiquidity risk measurement, reporting and management, balance sheet framework, contingency funding requirement\n\n\nHands-on experience in VaR/SVaR/IRC/CRM calculations for variety of financial instruments across Currencies, Credit, Commodities and Rates; In-depth understanding of new/evolving regulations in the Market Risk management space including treatment of off-balance sheet exposures, proprietary trading, systemic risk, stress testing, capital calculations, reporting standards etc.\nTreasury experiences in areas such as Asset Liability Management, Fund Transfer Pricing, and Interest Rate Risk in Banking Book with FO touchpoints.\nHands-on experience in developing risk registers, conducting RCSAs, defining KRIs for risk management and control indicators, Risk Scenario Library & Analysis, Cyber and Tech Risk & Controls Assessment, SOX Compliance/ Internal Controls over Financial Reporting (ICOFR).\nRegulatory reporting compliance-European reg. reports:FINREP/COREP/Anacredit. Experience in platforms like Axiom, Wolters Kluwer etc.\nExperience in managing financial crime and compliance with a focus on fraud risk management, compliance/AML analytics, enterprise risk management (financial services and non-financial services), data analysis & aggregation, trade surveillance, robotic process automation. Experience in platforms like Quantexa, Actimize, Featurespace etc.\nUsing Open AI in Modelling\nEnterprise Risk Management experience\nStrong understanding of risk regulatory framework of one more of the major economies across globe\nKnowledge of Risk Platforms such as Sungard, Murex, Sungard , Calypso, OpenPage, Fenergo, PEGA, JIRA, SAP HANA, Bloomberg, Reuters, and so on\nExperience in third-party risk consulting will be preferred. Prior Risk Consulting experience at pre-eminent, global risk management consulting firms desirable\nIndustry certifications such as FRM, PRM, CFA preferred\n\n\n\n\n\nAdditional Information:\nAn opportunity to work on\n\n\n\ntransformative projects with key G2000 clients\nPotential to\n\n\n\nCo-create with leaders in strategy, industry experts, enterprise function practitioners and, business intelligence professionals to shape and recommend innovative solutions that leverage emerging technologies.\nAbility to embed\n\n\n\nresponsible business into everythingfrom how you service your clients to how you operate as a responsible professional.\nPersonalized training modules to develop your\n\n\n\nstrategy & consulting acumen to grow your skills, industry knowledge and capabilities\nOpportunity to thrive in a\n\n\n\nculture that is committed to accelerate equality for all. Engage in boundaryless collaboration across the entire organization.\n\nAbout Our Company | Accenture",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['risk management', 'risk modeling', 'regulatory', 'presentation skills', 'business acumen', 'financial analysis', 'project management', 'credit risk', 'bloomberg', 'risk consulting', 'sungard', 'murex', 'reuters', 'fenergo', 'calypso', 'financial reporting', 'actimize', 'pega', 'sap hana', 'ca', 'jira', 'cfa']",2025-06-13 05:37:32
Advertising Sales Rep Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Digital Inside Sales - Inside Sales\n\n\n\n\nDesignation: Advertising Sales Rep Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nTransforming sales to become a future-ready and digital B2B revenue engine.The team helps assess, design, build and implement best practices on process, organization, and technology to create, execute, and run a collaborative sales and support roles.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\n\nWhat are we looking for\nProvide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['business development', 'sales', 'inside sales', 'marketing', 'sales analysis', 'data analysis', 'sales forecasting', 'mis reporting', 'market research', 'sales support', 'sales operations', 'lead generation', 'advanced excel', 'mis', 'sales coordination', 'sales planning']",2025-06-13 05:37:34
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"JR:\n\n\n\nR00244153\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree\n\n\n\n---------------------------------------------------------------------\n\n\n\nJob Title -\n\n\n\nS&C Global Network - AI - Supply Chain Analytics - Analyst\n\n\n\nManagement Level:\n\n\n\n11-Analyst\n\n\n\nLocation:\n\n\n\nMumbai, MC1 Building, NonSTPI\n\n\n\nMust-have skills:Data Analytics\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'anaplan', 'data analytics', 'sap', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'supply', 'data preparation', 'tableau', 'descriptive analysis', 'data modeling', 'sap ibp', 'cloud applications', 'ibp', 'data visualization']",2025-06-13 05:37:36
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Job Title -\n\n\n\nS&C Global Network - AI - Supply Chain Analytics - Analyst\n\n\n\nManagement Level:\n\n\n\n11-Analyst\n\n\n\nLocation:\n\n\n\nPune, PDC6A\n\n\n\nMust-have skills:Data Analytics\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'anaplan', 'data analytics', 'sap', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'supply', 'data preparation', 'tableau', 'descriptive analysis', 'data modeling', 'sap ibp', 'cloud applications', 'ibp', 'data visualization']",2025-06-13 05:37:38
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Record To Report - Financial Analysis\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Design and implementation of tools and processes which enable the client to perform financial analysis of its statements. Involves the ability to assess materiality and volatility of financial statement line items and key metrics utilizing financial ratios to determine the financial health of the company.\n\n\n\n\nWhat are we looking for\nPosting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['financial analysis', 'journal entries', 'forecasting', 'reporting analysis', 'record to report', 'hlookup', 'tds', 'service operations', 'data analysis', 'mis reporting', 'pivot table', 'vlookup', 'accounting', 'autocad', 'sql', 'kaizen', 'tableau', 'solid works', 'advanced excel', 'mis']",2025-06-13 05:37:40
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Chennai'],"Skill required: Record To Report - Fixed Asset Accounting\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Design and implement process and solutions to record and process all aspects of fixed assets accounting. Includes chart of accounts alignment, back office integration, folio management, payment processing, transfer & retirement of assets, physical inventory and Construction In Process (CIP) project accounting.\n\n\n\n\nWhat are we looking for\nWritten and verbal communicationAbility to handle disputesStrong analytical skillsCommitment to qualityRisk management\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'accounting', 'payment processing', 'record to report', 'fixed asset accounting', 'hlookup', 'macros', 'service operations', 'data analysis', 'forecasting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:37:42
Advertising Sales Rep Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Digital Inside Sales - Inside Sales\n\n\n\n\nDesignation: Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 Years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nTransforming sales to become a future-ready and digital B2B revenue engine. The team helps assess, design, build and implement best practices on process, organization, and technology to create, execute, and run a collaborative sales and support roles. Provide support for lead/opportunity generationconduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\n\nWhat are we looking for\nProvide support for lead/opportunity generationconduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems. Your day to day interaction is with peers within Accenture before updating supervisors. In this role you may have limited exposure with clients and/or Accenture management. You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments. The decisions you make impact your own work and may impact the work of others. You will be an individual contributor as a part of a team, with a focused scope of work. Please note that this role may require you to work in rotational shifts. Your day to day interaction is with peers within Accenture before updating supervisors. In this role you may have limited exposure with clients and/or Accenture management. You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments. The decisions you make impact your own work and may impact the work of others. You will be an individual contributor as a part of a team, with a focused scope of work. Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['business development', 'sales', 'inside sales', 'marketing', 'sales analysis', 'data analysis', 'sales forecasting', 'team management', 'mis reporting', 'market research', 'sales support', 'sales operations', 'lead generation', 'advanced excel', 'mis', 'sales coordination', 'sales planning']",2025-06-13 05:37:44
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Chennai'],"Skill required: Record to Report- Tax - Tax Process Design\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits. Posting direct tax and indirect tax and GST s and returnsDesign and implement processes for direct Tax/income tax. Includes direct tax/income tax planning, income tax accounting, income tax compliance and income tax audit.\n\n\n\n\nWhat are we looking for\nWritten and verbal communicationAbility to handle disputesStrong analytical skillsCommitment to qualityRisk management\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'record to report', 'taxation', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'pivot table', 'vlookup', 'dashboards', 'indirect taxation', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-13 05:37:45
Digital Mktg Advisory Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Marketing Operations - Campaign Analytics & Reporting\n\n\n\n\nDesignation: Digital Mktg Advisory Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English(International) - Proficient\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designEncompasses a set of technologies that enable the process of collecting & analyzing user behavioral activities with different marketing touch points, to reach on a web site or a mobile app with the ultimate aim of enhancing the targeted business goals. It comprises the processes and technologies that enable marketers to evaluate the success of their marketing initiatives, by measuring performance.\n\n\n\n\nWhat are we looking for\nDigital MarketingDigital Marketing CampaignsGoogle AdsMicrosoft ExcelCampaign ManagementStrong analytical skillsResults orientationProblem-solving skillsDetail orientationCommitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'marketing', 'marketing operations', 'seo', 'campaign analytics', 'digital analytics', 'python', 'adobe analytics', 'data analysis', 'sas', 'google adwords', 'power bi', 'sql', 'tableau', 'web analytics', 'social media marketing', 'google analytics', 'data visualization']",2025-06-13 05:37:47
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Chennai'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\nAbility to establish strong client relationshipAbility to handle disputesAbility to manage multiple stakeholdersAbility to meet deadlinesAbility to perform under pressure\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-13 05:37:49
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Business Reporting and Governance vertical helps to deploy and deliver robust tracking mechanism for SLA/KPI or any other operations on a day-to-day basis. The Governance team will be responsible for contractual compliance of various aspects of contract like Governance, Reporting, Incident Management, Change Management and Survey Management along with driving automation and analytics. Assessing, managing, using, improving, monitoring, maintaining, and protecting organizational information through a system of decision rights and accountabilities for information related processes, executed according to agreed-upon models which describe who can take what actions, with what information, when, under what circumstances and using what methods. Candidate who is good in excel and MIS reports are looked at for these skillsIn Reporting and Analytics, you will have to prepare management reports and analysis, both recurring and ad-hoc. This includes focusing on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nEffective communication and organization skills with Polished, professional presence Experience in working on automation projects Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Proficient in MS Office with advance knowledge in excel formulas. Ability to simplify and automate manual intensive processes using basic VBA, MS Access Expertise in creating reports, and exposure to using PowerBI\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ms access', 'business reporting', 'vlookup', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'power bi', 'business analysis', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'reporting and analytics', 'tableau', 'advanced excel', 'data visualization']",2025-06-13 05:37:51
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Marketing Operations - Campaign Analytics & Reporting\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English(International) - Proficient\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designIn this role you will, define, implement and monitor Paid Campaigns. Generate Reports on the performance of campaigns\n\n\n\n\nWhat are we looking for\nAnalysis and ReportingData ReportingBusiness Data AnalysisDetail orientationAbility to manage multiple stakeholdersNumerical abilityWritten and verbal communicationResults orientationAnalytical ThinkingBusiness Intelligence (BI) Reporting Tools\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'reporting analysis', 'data reporting', 'marketing operations', 'campaign analytics', 'digital marketing', 'python', 'data analytics', 'sas', 'business analysis', 'power bi', 'business analytics', 'business intelligence', 'sql', 'tableau', 'vba', 'data visualization']",2025-06-13 05:37:53
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Noida'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 - 5 Years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Business Reporting and Governance vertical helps to deploy and deliver robust tracking mechanism for SLA/KPI or any other operations on a day-to-day basis. The Governance team will be responsible for contractual compliance of various aspects of contract like Governance, Reporting, Incident Management, Change Management and Survey Management along with driving automation and analytics. Assessing, managing, using, improving, monitoring, maintaining, and protecting organizational information through a system of decision rights and accountabilities for information related processes, executed according to agreed-upon models which describe who can take what actions, with what information, when, under what circumstances and using what methods. Candidate who is good in excel and MIS reports are looked at for these skillsIn Reporting and Analytics, you will have to prepare management reports and analysis, both recurring and ad-hoc. This includes focusing on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nEffective communication and organization skills with Polished, professional presence Experience in reporting of contractual metrics and operational KPIs Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Proficient in MS Office with advance knowledge in excel formulas. Ability to create Nice & User friendly excel dashboards. Ability to create meaningful presentation through PowerPoint. Working Knowledge in Power Automate, Power Apps, PowerBi Basic Automation abilities using VBA Macros Good Understanding of processes like (e.g., F&A, Marketing Operations, HR, Procurement and Supply Chain)\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Create and Design New Dashboard / Reports as required. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts. Connect with Stakeholders and drive governance around performance metrics. Play Individual Contributor or Manage a team dedicated for the assignment and drive performance.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business reporting', 'vlookup', 'reporting and analytics', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'business analysis', 'power bi', 'business analytics', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'powerapps', 'tableau', 'data visualization']",2025-06-13 05:37:55
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Reinsurance - Collections Processing\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom/Chartered Accountant/PGDBM\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English - Advanced\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe help insurers redefine their customer experience while accelerating their innovation agenda to drive sustainable growth by transforming to an intelligent operating model. Intelligent Insurance Operations combines our advisory, technology, and operations expertise, global scale, and robust ecosystem with our insurance transformation capabilities. It is structured to address the scope and complexity of the ever-changing insurance environment and offers a flexible operating model that can meet the unique needs of each market segment.Canceling and rewriting insurance policies and endorsementsThe Collections Operations team focuses on managing collections and disputes such as debt collection, reporting on aged debt, bad debt provisioning, trade promotions, and outperform cash reconciliations. The team is responsible for follow up for missing remittances, prepare refund package with accuracy and supply to clients, record all collections activities in a consistent manner as per client process (tool), delivery of process requirements to achieve key performance targets, and ensure compliance to internal controls, standards, and regulations.\n\n\n\n\nWhat are we looking for\nAccounting & Financial Reporting StandardsFinancial AnalysisFinancial Consolidation & Close OperationsBalance Sheet Account ReconciliationsAbility to manage multiple stakeholdersWritten and verbal communicationCommitment to qualityAbility to perform under pressure\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,Chartered Accountant,PGDBM",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounting', 'reinsurance', 'reporting analysis', 'financial reporting', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'tableau', 'trade', 'vba', 'advanced excel', 'mis']",2025-06-13 05:37:57
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Navi Mumbai'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\n""Campus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard doneCampus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard doneCampus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard done""\n\n\n\n\nWhat are we looking for\n""Campus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard doneCampus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard done""\n\n\n\nRoles and Responsibilities: Campus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard done\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'service operations', 'vlookup', 'reporting analysis', 'record to report', 'hlookup', 'macros', 'data analysis', 'data analytics', 'mis reporting', 'ms access', 'pivot table', 'power bi', 'sql', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-13 05:37:58
Campaign Management Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Campaign Management\n\n\n\n\nDesignation: Campaign Management Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe are seeking a highly skilled and detail-oriented Ad Operations Specialist to join our dynamic team. The ideal candidate will be responsible for managing and optimizing the delivery of digital advertising campaigns, ensuring smooth execution, and maintaining the quality and performance of digital ad operations. The role requires a strong understanding of digital advertising platforms, analytics, and the ability to troubleshoot issues effectively1.Campaign Management:oSet up, monitor, and optimize digital ad campaigns across various platforms/products (display, video, social media, etc.).oEnsure proper targeting, scheduling, and creative deployment for optimal campaign delivery.oManage creative assets and ad trafficking, ensuring the correct formats and specifications are used.oWork closely with the client and provide analytical/campaign reports, track KPIs, and optimize campaigns based on performance metrics.oTroubleshoot and resolve campaign issues related to delivery, tracking, and ad quality.2.Technical Setup & Troubleshooting:oPerform ad trafficking tasks, ensuring that all campaigns are set up properly and execute without errors.oTroubleshoot technical issues, such as discrepancies in reporting, creative issues, or campaign performance problems.oCoordinate with vendors or partners to resolve any issues impacting campaign delivery.3.Client Servicing:oCollaborate with account managers/clients, and internal teams to align campaign objectives with ad execution.oCommunicate with Internal & External teams to ensure a smooth campaign delivery takes place.oExcellent written and verbal communication skills for internal and client-facing interactionsoGood at articulating the problems/challenges in simple wordsoProactive in identifying issues/challenges and use the technical knowledge to suggest solutions\n\n\n\n\nWhat are we looking for\n\nQualifications &\n\n\n\n\nSkills:\nEducation:Bachelors degree or Preferred in Marketing, Advertising or related field.Experience:2-3 years of experience in Campaign Management or Ad Operations or Digital marketing.Technical\n\n\n\n\nSkills:\nFamiliarity with ad-serving platforms (DoubleClick, Sizmek, Google Ad Manager, etc.) and analytics tools (Google Analytics, Magnite, Tableau, etc).Attention to Detail:Strong ability to manage and optimize campaigns with a focus on precision and accuracy.Analytical Mindset:Strong data analysis skills and comfort with numbers to make informed decisions.Communication\n\n\n\n\nSkills:\nExcellent written and verbal communication skills for internal and client-facing interactions.Problem-Solving:Ability to troubleshoot and resolve issues in a timely and efficient mannerPreferred\n\n\n\n\nSkills:\nExperience in Video, Audio, Mobile, or Display advertising.Knowledge in Microsoft Excel is must.Excellent written and verbal communication skills for internal and client-facing interactions.Experience with programmatic advertising and RTB (Real-Time Bidding) will be a plus point\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shiftsWork Environment:Working with dynamic team.Work from office or Hybrid depending on project requirementsThe role involves working in night shift catering to US client with 5-day work schedule with weekly 2 days week offs\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'data analysis', 'ad operations', 'digital advertising', 'campaign management', 'rtb', 'programmatic buying', 'bidding', 'google', 'advertising', 'sizmek', 'tableau', 'display advertising', 'vendor', 'google analytics', 'troubleshooting', 'marketing operations', 'doubleclick']",2025-06-13 05:38:00
Process QA Analyst,The Coca-Cola CompanyÂ,4 - 5 years,Not Disclosed,['Pune'],"Location(s):\nIndia\nCity/Cities:\nPune\nTravel Required:\n00% - 25%\nRelocation Provided:\nYes\nJob Posting End Date:\nJune 15, 2025\nShift:\nJob Description Summary:\nA. JOB SUMMARY: Describe the Purpose of this job in 2-3 Sentences.\nBuild a Total Quality Management culture by driving/developing the capabilities of the Associates on Quality aspects on the job and to evaluate process/equipment capabilities through the Validations and Process Monitoring.\nEnsure manufacturing processes/process quality activities are followed in compliance with KORE ISO, GMP and local regulation requirements by developing providing SOP s for plant processes and timely technical support and decision on the quality problem, observation to protect product s integrity and specification and final disposition of customer complains/feedback.\nEstablish and maintain an effective, governed and documented system for all company processes, which is integrated compliant to its entire applicable standard references and capable of meeting company requirements continually.\nEvaluate new packaging material and ensure the packaging fitness for use and handling of all packing material documentation which is part of quality system.\nShould be knowing digitals skills and data analysis skills.\nB. KEY DUTIES/RESPONSIBILITIES:\nBriefly describe the primary duties/responsibilities of this job in 5-8 bullet points. Please list these duties in order of importance and include the percentage of time spent or required for each activity.\nPrioritized Responsibilities\n% of Time\nProcess Quality Activities:\nEnsure plant s operations continue keeping pace with new KORE requirements, regulations, quality management methods and industry best practices.\nRegular conduct the risk assessment for plant key processes to mitigate the risk of failure to deliver Quality product.\nEnsure that quality is built into the process by training Associates on Quality monitoring aspects.\nValidate equipment and processes, routinely monitoring and adherence to Good Manufacturing Practices of the highest standard.\nCreate a technical library/database by compiling in an easy retrieval system all the technical information available in the plant post-commissioning and compiling the validation reports generated as a result of the Validation Master Plan implementation.\nEnsure all manufacturing instructions (SMI) are followed by production effectively.\nOrganize and support plant s associates to use the problem-solving tools for root-cause analysis and action plans to eliminate the recurrence of quality issue\nSupport Corrective/Preventive actions of PDR, TDQ, and analysis of manufacturing problems.\nPerform process validations and process capability studies to ensure the performance of production equipment meet KORE requirements and required actions are implemented if there is any deficiency\nInspect manufacturing equipment for use after maintenance (calibration, maintenance, etc).\nAssess existing processes/operations to seek the possibility to eliminate non-value activities by adopting OE concept and methodology\nTo review the completed analysis report against KO requirements and documents relating to food regulation for auxiliary material / processing aid to authorize the supplier finally\n60 %\nPlant GMP / Security Program\nRoutinely monitoring and adherence to Good Manufacturing Practices of the highest standard and ensure plant s security program are in-placed effective.\nFollow-up on the execution of the GMP programs in both general facilities by outsourced service contractor and manufacturing area by direct GMP housekeepers\nManagement of the pest control and housekeeping program by monitoring evaluating the service performance (contractors), controlling, and monitoring the housekeepers performance inside the manufacturing area to ensure total compliance with GMP standards.\n10 %\nManagement System\nImplement Quality requirements (KORE and ISO) and provide suggestions and recommendations for improvement based on food/pharmaceutical industry s experience.\nLead the team to play a key role in the implementation, assessment and improvement of Quality and Food Safety Management System\nSupport internal auditor team of quality system and actively participate the scheduled internal audit to continuously improve/upgrade plant s quality system and operations.\n15%\nNew Packaging development and routine incoming inspection\nWork with Asia packaging specialist to develop new packaging suppliers to meet the increased volume and introduced new process/equipment.\nContinuously optimize packaging material to improve the plant s performance on TDQ and OTIF and ensure the packaging material meet our spec prior to use.\nCollate packaging information to ensure completeness and accuracy in PICASSO and related databases.\n10%\nCapability\nIdentify training needs of the associates.\nResponsible to lead midyear/annual performance review, provide feedback and documenting the performance of associates.\n5 %\nD. COMMUNICATION COMPLEXITIES:\nAs indicated, the impact is on all manufacturing operations as far as quality is concerned and this applies to warehouse, distribution aspects, Customer Complaints investigation and resolutions.\nE. ANALYSIS:\nParticipate in visits to Customers to resolve alleged quality issues with manufacturing. Co-ordinate joint efforts with other CPS plants on quality initiatives and was identified to participate in cross audits with Corporate Quality. Daily contact with the Leadership Team, Wider Management Team and associates throughout the plant.\nF. JUDGMENT AND DECISION MAKING:\nThe job can recommend to stop production of beverage base if any potential process or product quality issue is noted during the manufacturing.\nG. INNOVATION:\nThe job has the responsibilities to suggest solution to the existing processes, package material to upgrade the quality of our products and processing/quality system\nH. SUPERVISORY RESPONSIBILITIES:\nConduct performance review of processes and equipments. Identify training need and train associate.\nI. QUALIFICATIONS / COMPENTENCIES / SKILLS:\nIs this position a:\nLeader of Others\nMinimum experience is 4-5 years prior experience in production supervision role in a food/beverage or pharmaceutical industry.\nFamiliar with ISO and Food Safety Quality System, understand KORE requirements will be preferred.\nKnowledge of concentrate manufacturing and quality system, project management experience; strong GMP experience, problem solving skills. strategic-thinking, planning, organizing and executing skills. Knowledge of local food laws/regulations.\nSix sigma methodology or certification\nJ. RELATED EXPERIENCE REQUIREMENTS/ QUALIFICATIONS:\nOf prime importance are communication and listening skills.\nTime management is a key considering the level of involvement in many simultaneous projects.\nK. EDUCATIONAL REQUIREMENTS: Indicate the minimum education level required to perform the job.\nEducation Required\nLevel of Certificate\nPostgraduate/Master s degree\nIn life sciences\nL. PREFERRED QUALIFICATIONS:\nBachelor of science or postgraduate degree, major in the subject of chemistry or food science, or biochemistry, Food technology and food engineering\nM. CULTURAL DIVERSITY:\nTargeting employment of local associates as much as practically possible, As part of communication skills with other CPS-Plants or Corporate Quality, both oral and written English language in fluent is required.\nN. WORKING CONDITIONS: Describe the risk of exposure to hazards in performing this job, and the types of hazards faced.\nHazards and risks are normal ones associated with a CPS manufacturing plant.\nO. TRAVEL REQUIREMENTS:\nTravel requirements are in response to problems for the most part and therefore no specifically planned up front. Approximate time is 10%.\nP. ADDITIONAL INFORMATION:\nThis document serves as a common job description for a Process QA role in a CPS Plant. The job scope of this position in the respective plant location is subject to complexity and scale of operating business in the Plant.\nSkills:\nOur Purpose and Growth Culture:\nWe are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors - curious, empowered, inclusive and agile - and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.",Industry Type: Beverage,Department: Quality Assurance,"Employment Type: Full Time, Permanent","['Data analysis', 'ISO', 'Food technology', 'Project management', 'Risk assessment', 'Biochemistry', 'GMP', 'Technical support', 'Monitoring', 'Six sigma']",2025-06-13 05:38:02
Paid Search Analyst,Merkle B2b,3 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Paid Search campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nProvides initial insights on campaign trends to executives and planners\nLocation:\nDGS India - Chennai - Anna Nagar Tyche Towers\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Other,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-13 05:38:04
Financial Planning Analysis - Associate,JPMorgan Chase Bank,5 - 10 years,Not Disclosed,['Mumbai'],"You are a strategic thinker passionate about driving solutions in Finance. You have found the right team. As a Financial Analysis professional in our Corporate Investment Banking, you will spend each day defining, refining and delivering set goals for our firm\nYour team will be Sales PA Infrastructure team , which is responsible for managing core reference data, overseeing various data collection tools and driving standardized reporting initiatives. The team drives strategies to enhance the integration of core data across various platforms and drive our tools to state of the art technologies. The Infrastructure team acts in a broad array of roles that include business analysis, project management, report writing, database development, database management, system administration and end user training. Creative aspects of these responsibilities include creation of innovative solutions to management information, data analysis and reporting. The team is currently working a developing a data analysis platform built around Alteryx and a comprehensive data library which will drive the automation of numerous data intensive, repetitive and mundane tasks. Tools like Tableau, Alteryx, Qlikview Qliksense are also relied on to provide enhanced visualization and self-service reporting. You will act as a business liaison and subject matter expert responsible for the ongoing development and administration of various reporting initiatives and platforms (i. e. XIB Business Objects, WCP Cognos, Alteryx, Tableau) and various business tools (i. e. SCRIBE, Clover, iODS ( Team Workflow, Tagging, etc. ). You will require a strong understanding of the end to end business needs, alignment to tools and corresponding technical capabilities.\nJob Responsibilities\nServe as the subject matter expert for the Alteryx COE Integration Scheduling process.\nOversee the design, development, and delivery of standard reports, automation workflows, and dashboard tools.\nEnsure system management, administration, and testing. Manage reference data, user support, communications, training, and inquiry management.\nCreate innovative solutions to meet management reporting needs. Interact with technical teams to enhance and troubleshoot system issues and inefficiencies.\nCoordinate the collection of system requirements for the consolidated reporting initiative. Assist in QA UA testing.\nDevelop and manage proof of concept tools (Tableau, Alteryx, etc. ) to drive requirements for strategic solutions.\nSupport the heritage toolset and assume responsibilities for user support and data management.\nEnhance the efficiency and consistency of the reporting environment. Improve ad-hoc reporting capabilities for a broad user community.\nBuild commonly used formulas and variables into the reporting universe.\nOrganize, clearly label, and assign meaningful descriptions to reporting elements. Design supporting databases efficiently to maximize performance.\nCollaborate with broader sales support and business management teams to design effective solutions for management reporting needs.\nRequired qualifications, capabilities, and skills\nBachelor s Degree Required with minimum 4 years of experience in reporting, automation and/or dashboard development\nRequired technical skills Tableau and Alteryx, Pitchpro+, SAP Business objects, Cognos\nInnovative, self-motivated and solutions oriented. Extensive working knowledge of system management practices\nAbility to be flexible, follow tight deadlines, organize and prioritize work and multi-task in a fast paced environment.\nHighly motivated, able to thrive, comfortable with frequently changing priorities and think clearly under pressure and tight deadlines.\nAbility to work with all levels of employees and have a strong presence enabling effective influencing, interaction, and communication with senior management. Proven ability to work independently with minimal guidance. Excellent written and oral communication skills; and demonstrated ability to interact with technical, non-technical, and business members of the organization\nPreferred qualifications, capabilities, and skills\nAdditional Technical skills are a plus Superior skills in SQL, Python, or other scripting language Qlik Sense\nSubject matter knowledge of finance and business management functions and/or banking technologies/infrastructure a plus",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Data analysis', 'SAP', 'Data management', 'Financial analysis', 'Business analysis', 'Project management', 'Workflow', 'Scheduling', 'Investment banking', 'SQL']",2025-06-13 05:38:06
Lead Analyst,AMERICAN EXPRESS,5 - 10 years,Not Disclosed,['Gurugram'],"Global Merchant & Network Services (GMNS) brings together American Express merchant-and network-related businesses to enable a sharp focus on using the power of our network to provide unique value to all of our mutual customers. The organization manages the relationships with the millions of merchants around the world that accept American Express and runs the company s payment network and manages bank partnerships globally.\nIn support of GMNS s mission, Global, Strategy, Operations & Processes (GSOP) is focused on delivering a friction free, resilient, and efficient operational core for critical merchant experiences; strengthening monitoring and adherence to network and merchant policies; and leading key operational excellence functions. As part of GSOP, the Merchant Onboarding & Maintenance team prioritizes strengthening governance for merchant account setup, account management, and Know Your Customer (KYC) activities.",,,,"['Career development', 'Operational excellence', 'Data management', 'Account management', 'Information technology', 'Client management', 'Monitoring', 'SQL']",2025-06-13 05:38:08
"Financial Analyst II - AR, FinOps",Amazon,5 - 10 years,Not Disclosed,['Hyderabad'],"Are you an experienced Program Manager interested in an opportunity to help drive Amazon s flywheel and develop your A to Z business understanding? Do you enjoy learning about different Amazon business types and new subsidiaries, and thinking creatively about brand new businesses that Amazon is inventing on behalf of customers? The Global Accounts Receivable (GAR) team is seeking a creative and passionate program manager to help achieve our vision to provide a world-class Order-to-Cash (O2C) onboarding experience to our global business partners in support of Amazon s journey to become earth s most customer-centric company. We love to offer our customers unique world-class experiences, and we invite you to help Amazon make history!\n\nThe Program Manager will have global oversight of the integration of new initiatives onto O2C platforms, driving effective people, processes, and technology to achieve organizational goals and deliver results. This individual will have ownership over new business integration programs while standardizing the global implementation processes and driving efficiency. This role will require engagement and alignment with global business teams, finance teams, operational teams, system developers and product managers. Responsibilities include supporting new business initiatives through designing transactional workflows in line with the business model, defining requirements and testing of the solutions to ensure delivery is as expected and delivering and improving the customer experience. Implementation of mechanisms to monitor and measure performance is essential.\n\nThe ability to thrive in a fast-paced, ambiguous and demanding work environment is critical to success in this role. The ideal candidate will be a self-starter with knowledge of program management, experience with accounts receivable operational processes, demonstrate faster learning and adoptability, demonstrate good relationship and strategic influencing skills, experienced in large scale change management across functions and geographies, and exhibit a relentless pursuit for improvement. This individual must have a proven record of delivering results through good program management skills, problem solving skills, financial process and system knowledge, and a passion for customer experience.\n\nCore Requirements:\n5+ years of Accounts Receivable experience, with at least 2 years in a leadership role( not mandate)\nBachelors degree in Finance, Accounting, Business Administration, or related field\nAdvanced Excel skills and experience with ERP systems\nData Analytics Requirements:\n3+ years experience with data analysis and reporting tools\nProficiency in SQL for data extraction and analysis\nExperience with visualization tools (e.g., Tableau, Power BI)\nDemonstrated ability to translate data insights into actionable recommendations\n\nProgram Management Skills:\n3+ years experience managing complex projects or programs\nTrack record of process improvement initiatives\nExperience leading cross-functional teams\nGood stakeholder management abilities\nTechnical Skills:\nExperience with AR automation tools and systems\nKnowledge of financial control frameworks\nProficiency in Microsoft Office Suite\nExperience with business intelligence platforms\n\nAdditional Desired Qualifications:\nMBA or relevant masters degree\nProfessional certifications (CPA, PMP, or similar)\nExperience with machine learning or predictive analytics\nKnowledge of Python or R for advanced data analysis\n\n\nOwnership and implementation of new businesses and subsidiaries onto AR platforms\nPartner with key counterparts across geographies to launch and support initiatives globally in a scalable manner\nDevelop a solid understanding of Amazon s Finance Operations systems and processes\nDefine and implement global standards for business integration program management\nDefine and describe various business scenarios that can be relevant to New Businesses and convert them into system and operational requirements.\nTranslate complex business requirements into functional designs\nOversee comprehensive testing of systems changes and development of standard operating procedures, process documentation and performance metrics\nManage process transitions/implementations across multiple functions and geographies\nMotivate and influence business, operational and technical teams to ensure that best practices are followed and implemented\nIdentify, assess, track and mitigate risks at multiple levels\nProactively monitor program performance to identify, address and prevent potential issues\nAddress barriers through problem solving, communication and active coordination with stakeholders\nDrive effective teamwork, communication collaboration and commitment across multiple disparate groups with competing priorities\nIdentify gaps and strive constantly for re-engineering of systems and processes\nAmazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability /\nVeteran / Gender Identity / Sexual Orientation\n5+ years of Accounts Receivable (AR) experience 4+ years of participating in continuous improvement projects in your team to scale and improve controllership with measurable results experience\nMBA, or CPA\nKnowledge of Tableau\nExperience working with large-scale data mining and reporting tools (examples: SQL, MS Access, Essbase, Cognos) and other financial systems (examples: Oracle, SAP, Lawson, JD Edwards)",,,,"['Data analysis', 'Change management', 'PMP', 'SAP', 'MS Access', 'Process improvement', 'Oracle', 'Data mining', 'Business intelligence', 'SQL']",2025-06-13 05:38:10
Budgeting Analyst Cloud & Enterprise ( Immediate Joiner),Hiring for Telecom Client,7 - 10 years,14-22.5 Lacs P.A.,['Hyderabad'],"Key Result Areas/Accountabilities\n\nBudgeting Strategy and forecasting\nFiscal budget forecasting for Core based on inputs from various stakeholders viz. Business, Marketing, COG, Radio Planning and Enterprise.\nLong Range Planning (LRP), annual and quarterly capex budgeting strategies for Core domain.\nCapex budget finalisation for the year, present annual budgets to CXOs.\nReview budget requests for approval. Prioritization and allocations based on criticality across sub domains and circles.\nFinalisation of capacity, coverage targets, KPIs, deliverables for Core.\nForecast future budget needs and quarter-wise refresh cycles. Interfacing with the finance team for available budget and further execution.\nBudget control and cost efficiency\nRegular monitoring of budget release v/s spend.\nPost budget approval, execution of budget - involvement in various stages of execution, resolving issues in the process, managing budget shortfalls.\nEstimate QoQ capex savings due to various cost-effective measures in coordination with cross functional teams.\nMonitoring reusability of inventory\nEnsure cost effective network solution\nCore Competencies, Knowledge, Experience\n\nTechnical Skills\nNetwork Understanding: A solid grasp of telecommunications networks, especially mobility network (2G/4G/5G) Core and cloud networks. A thorough understanding of cloud infrastructure and various enterprise solutions like CPaaS, U/CCaaS, IoT, SIP Trunking, SDWAN, Private 5G etc.\nData Analysis: Proficiency in data analysis tools (e.g., Excel, Python) to extract insights from large datasets.\nTechnical Writing: Ability to create clear and concise documentation, reports, and presentations.\nProblem-Solving: Strong analytical and problem-solving skills to identify and resolve technical issues.\nTechnical Tools: Extensive experience in leveraging MS Office Suite (Excel, PowerPoint, Word) and SAP for data analysis and reporting,\nSoft Skills\nCommunication Skills: Effective written and verbal communication skills to convey complex technical information to both technical and non-technical audiences.\nAttention to Detail: Meticulous attention to detail to ensure accuracy in data analysis and report generation.\nSchedule Management: Ability to prioritize tasks and meet deadlines efficiently.\nAdaptability: Flexibility to adapt to changing business requirements and technological advancements.\nMust have technical / professional qualifications\n\nEngineering Graduate.\nAny industry grade certifications in Telecom Network, SAP are good to have.\nYears of Experience\n\nMin 6 Years",Industry Type: Telecom / ISP,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Budget Analysis', 'Ucaas', 'SDWAN', 'SAP', 'QoQ capex', 'Cost Optimization', 'IoT', 'mobility network', 'Private 5G', 'CPaaS', 'Budgeting Strategy and forecasting', 'SIP Trunking', 'cloud infrastructure', 'Cost Planning', 'Revenue Planning']",2025-06-13 05:38:12
Data Scientist,Mastercard,4 - 8 years,Not Disclosed,['Gurugram'],"As consumer preference for digital payments continues to grow, ensuring a seamless and secure consumer experience is top of mind. Optimization Soltions team focuses on tracking of digital performance across all products and regions, understanding the factors influencing performance and the broader industry landscape. This includes delivering data-driven insights and business recommendations, engaging directly with key external stakeholders on implementing optimization solutions (new and existing), and partnering across the organization to drive alignment and ensure action is taken.\n\nThe Role:\n\nWork closely with global optimization solutions team to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data to support data insights and analytical needs across products, markets, and services\nThe candidate for this position will focus on Building solutions using Machine Learning and creating actionable insights to support product optimization and sales enablement.\nPrototype new algorithms, experiment, evaluate and deliver actionable insights.\nDrive the evolution of products with an impact focused on data science and engineering.\nDesigning machine learning systems and self-running artificial intelligence (AI) software to automate predictive models.\nPerform data ingestion, aggregation, and processing on high volume and high dimensionality data to drive and enable data unification and produce relevant insights.\nContinuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nA superior academic record at a leading university in Computer Science, Data Science, Technology, mathematics, statistics, or a related field or equivalent work experience\nExperience in data management, data mining, data analytics, data reporting, data product development and quantitative analysis\nStrong analytical skills with track record of translating data into compelling insights\nPrior experience working in a product development role.\nknowledge of ML frameworks, libraries, data structures, data modeling, and software architecture.\nproficiency in using Python/Spark, Hadoop platforms & tools (Hive, Impala, Airflow, NiFi), and SQL to build Big Data products & platforms\nExperience with Enterprise Business Intelligence Platform/Data platform ie Tableau, PowerBI is a plus.\nDemonstrated success interacting with stakeholders to understand technical needs and ensuring analyses and solutions meet their needs effectively.\nAbility to build a strong narrative on the business value of products and actively participate in sales enablement efforts.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data management', 'Data modeling', 'Information security', 'Machine learning', 'Data structures', 'Data mining', 'Business intelligence', 'SQL', 'Python']",2025-06-13 05:38:13
Data Scientist,Dynamic Yield,5 - 10 years,Not Disclosed,['Gurugram'],"Our Purpose\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\nTitle and Summary\nData Scientist\nWho is Mastercard?\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships, and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOur Team:\nAs consumer preference for digital payments continues to grow, ensuring a seamless and secure consumer experience is top of mind. Optimization Soltions team focuses on tracking of digital performance across all products and regions, understanding the factors influencing performance and the broader industry landscape. This includes delivering data-driven insights and business recommendations, engaging directly with key external stakeholders on implementing optimization solutions (new and existing), and partnering across the organization to drive alignment and ensure action is taken.\nAre you excited about Data Assets and the value they bring to an organization?\nAre you an evangelist for data-driven decision-making?\nAre you motivated to be part of a team that builds large-scale Analytical Capabilities supporting end users across 6 continents?\nDo you want to be the go-to resource for data science & analytics in the company?\n\n\nThe Role:\n\nWork closely with global optimization solutions team to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data to support data insights and analytical needs across products, markets, and services\nThe candidate for this position will focus on Building solutions using Machine Learning and creating actionable insights to support product optimization and sales enablement.\nPrototype new algorithms, experiment, evaluate and deliver actionable insights.\nDrive the evolution of products with an impact focused on data science and engineering.\nDesigning machine learning systems and self-running artificial intelligence (AI) software to automate predictive models.\nPerform data ingestion, aggregation, and processing on high volume and high dimensionality data to drive and enable data unification and produce relevant insights.\nContinuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nA superior academic record at a leading university in Computer Science, Data Science, Technology, mathematics, statistics, or a related field or equivalent work experience\nExperience in data management, data mining, data analytics, data reporting, data product development and quantitative analysis\nStrong analytical skills with track record of translating data into compelling insights\nPrior experience working in a product development role.\nknowledge of ML frameworks, libraries, data structures, data modeling, and software architecture.\nproficiency in using Python/Spark, Hadoop platforms & tools (Hive, Impala, Airflow, NiFi), and SQL to build Big Data products & platforms\nExperience with Enterprise Business Intelligence Platform/Data platform i.e. Tableau, PowerBI is a plus.\nDemonstrated success interacting with stakeholders to understand technical needs and ensuring analyses and solutions meet their needs effectively.\nAbility to build a strong narrative on the business value of products and actively participate in sales enablement efforts.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor.\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\nAbide by Mastercard s security policies and practices;\nEnsure the confidentiality and integrity of the information being accessed;\nReport any suspected information security violation or breach, and\nComplete all periodic mandatory security trainings in accordance with Mastercard s guidelines.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data management', 'Data modeling', 'Information security', 'Machine learning', 'Data structures', 'Data mining', 'Business intelligence', 'SQL', 'Python']",2025-06-13 05:38:15
Join us as a Data Scientist!!,Zensar,6 - 11 years,Not Disclosed,"['Hyderabad', 'Delhi / NCR']","-\nData Scientist\n\n-6+ years of experience in data science, with at least 2 years focused on LLMs or Generative AI.\n\n-Proven implementation experience in Data Science, Machine Learning, Deep Learning, and NLP for multiple domains.\n\n-Strong programming skills in Python, with experience in libraries such as Transformers (Hugging Face), PyTorch, or TensorFlow.\n\n-Hands-on experience with fine-tuning, prompt engineering, RAG (Retrieval-Augmented Generation), and LLM evaluation.\n\n-Familiarity with vector databases and embedding techniques.\n\n-Experience deploying models using APIs, Docker, and cloud platforms\n\n-Strong analytical, problem-solving, and communication skills.\n\n-Experience in ML Ops, Model deployment, Model lifecycle and management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Pytorch', 'NLP', 'Machine Learning', 'Deep Learning', 'Tensorflow', 'Cloud Deployment', 'ML Ops', 'Generative AI', 'Hugging Face', 'LLM', 'Python']",2025-06-13 05:38:17
Data Scientist (Offshore),HTC Global Services,2 - 7 years,Not Disclosed,['Chennai'],"We are seeking a Data Scientist (Offshore) with minimum experience of 3 or more years. The ideal candidate should be familiar with relational or NoSQL databases such as Oracle, Teradata, SQL Server, Hadoop and ELK etc.\nRequirements:\nMinimum 3 or more years working with languages such as R, Python or Java\nAt least 3 or more years working with advanced statistical methods such as regressions, classifiers, recommenders, anomaly detection, optimization algorithms, tree methods and neural nets etc.",,,,"['tableau', 'NoSQL', 'Hadoop', 'Agile', 'Teradata SQL', 'data visualization', 'Oracle', 'Powerpoint', 'SDLC', 'Python']",2025-06-13 05:38:19
Business Analyst,Hidden Brains Infotech,4 - 9 years,Not Disclosed,['Ahmedabad'],Requirements Gathering and Analysis\nProcess Modeling & Improvement\nStakeholder Management\nSolution Evaluation & Validation\nData Analysis and Reporting\nDocumentation\nChange Management,Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Requirement Gathering', 'Business Analysis', 'Client Interaction', 'Post Sales']",2025-06-13 05:38:20
Business Analyst,Abad Fisheries,3 - 5 years,4-7 Lacs P.A.,['Kochi( Thoppumpady )'],"Collaborate with department heads to define data needs and ensure consistent metric capture. Apply statistical tools to analyze data, identify trends & create clear visualizations using Power BI. Identify bottlenecks and improvement opportunities,\n\nRequired Candidate profile\nWe are looking for candidates from FMCG background with advanced Exel Knowledge and other data analysis tools like power BI, tableau etc..\n\nPerks and benefits\nBest in the industry",Industry Type: Food Processing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'VLOOKUP', 'Data Analysis', 'Advanced Excel', 'MIS Reporting', 'Data Visualizations', 'Excel', 'Dashboards']",2025-06-13 05:38:22
Data Engineer,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"Role Description:\nAs part of the cybersecurity organization, In this vital role you will be responsible for designing, building, and maintaining data infrastructure to support data-driven decision-making. This role involves working with large datasets, developing reports, executing data governance initiatives, and ensuring data is accessible, reliable, and efficiently managed. The role sits at the intersection of data infrastructure and business insight delivery, requiring the Data Engineer to design and build robust data pipelines while also translating data into meaningful visualizations for stakeholders across the organization. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture, ETL processes, and cybersecurity data frameworks.",,,,"['data engineering', 'data analysis', 'data modeling', 'analysis tools', 'data warehousing', 'troubleshooting', 'data architecture', 'data integration', 'etl process']",2025-06-13 05:38:24
Data Engineer,Luxoft,5 - 10 years,Not Disclosed,['Pune'],"Project description\nYou'll be working in the GM Business Analytics team located in Pune. The successful candidate will be a member of the global Distribution team, which has team members in London and Pune.\n\nWe work as part of a global team providing analytical solutions for IB distribution/sales people. Solutions deployed should be extensible globally with minimal localization.\n\nResponsibilities\n\nAre you passionate about data and analyticsAre you keen to be part of the journey to modernize a data warehouse/ analytics suite of application(s). Do you take pride in the quality of software delivered for each development iteration\n\nWe're looking for someone like that to join us and\n\nbe a part of a high-performing team on a high-profile project.\n\nsolve challenging problems in an elegant way\n\nmaster state-of-the-art technologies\n\nbuild a highly responsive and fast updating application in an Agile & Lean environment\n\napply best development practices and effectively utilize technologies\n\nwork across the full delivery cycle to ensure high-quality delivery\n\nwrite high-quality code and adhere to coding standards\n\nwork collaboratively with diverse team(s) of technologists\n\nYou are:\n\nCurious and collaborative, comfortable working independently, as well as in a team\n\nFocused on delivery to the business\n\nStrong in analytical skills. For example, the candidate must understand the key dependencies among existing systems in terms of the flow of data among them. It is essential that the candidate learns to understand the 'big picture' of how IB industry/business functions.\n\nAble to quickly absorb new terminology and business requirements\n\nAlready strong in analytical tools, technologies, platforms, etc. The candidate must also demonstrate a strong desire for learning and self-improvement.\n\nOpen to learning home-grown technologies, support current state infrastructure and help drive future state migrations. imaginative and creative with newer technologies\n\nAble to accurately and pragmatically estimate the development effort required for specific objectives\n\nYou will have the opportunity to work under minimal supervision to understand local and global system requirements, design and implement the required functionality/bug fixes/enhancements. You will be responsible for components that are developed across the whole team and deployed globally.\n\nYou will also have the opportunity to provide third-line support to the application's global user community, which will include assisting dedicated support staff and liaising with the members of other development teams directly, some of which will be local and some remote.\n\nSkills\nMust have\n\nA bachelor's or master's degree, preferably in Information Technology or a related field (computer science, mathematics, etc.), focusing on data engineering.\n\n5+ years of relevant experience as a data engineer in Big Data is required.\n\nStrong Knowledge of programming languages (Python / Scala) and Big Data technologies (Spark, Databricks or equivalent) is required.\n\nStrong experience in executing complex data analysis and running complex SQL/Spark queries.\n\nStrong experience in building complex data transformations in SQL/Spark.\n\nStrong knowledge of Database technologies is required.\n\nStrong knowledge of Azure Cloud is advantageous.\n\nGood understanding and experience with Agile methodologies and delivery.\n\nStrong communication skills with the ability to build partnerships with stakeholders.\n\nStrong analytical, data management and problem-solving skills.\n\nNice to have\n\nExperience working on the QlikView tool\n\nUnderstanding of QlikView scripting and data model\n\nOther\n\nLanguages\n\nEnglishC1 Advanced\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'data management', 'big data technologies', 'sql', 'spark', 'python', 'scala', 'mathematics', 'business analytics', 'data engineering', 'azure cloud', 'qlikview', 'data bricks', 'computer science', 'database creation', 'data transformation', 'agile', 'big data', 'agile methodology']",2025-06-13 05:38:26
Data Engineer - Asset Lending,Investec Global Services,2 - 5 years,Not Disclosed,['Mumbai'],"About the role :\nPrimary function of the role is to deliver high quality data engineering solutions to business and end users across Asset Lending (Asset Finance, Working Capital and Asset Based Lending businesses either directly via self-service data products, or by working closely with the Analytics team, providing modelled data warehouses on which they can add reporting and analytics.\nReporting to the Head of ccc Technology, this role will fill a crucial role in bridging the gap between business needs, the requirements from the data analytics team and translating these into engineering delivery.\nKey Responsibilities :\nWork closely with end-users and Data Analysts to understand the business and their data requirements\nCarry out ad hoc data analysis and data wrangling using Synapse Analytics and Databricks\nBuilding dynamic meta-data driven data ingestion patterns using Azure Data Factory and Databricks\nBuild and maintain the Enterprise Data Warehouse (using Data Vault 2.0 methodology)\nBuild and maintain business focused data products and data marts\nBuild and maintain Azure Analysis Services databases and cubes\nShare support and operational duties within the wider engineering and data teams\nWork with Architecture and Engineering teams to deliver on these projects. and ensure that supporting code and infrastructure follows best practices outlined by these teams.\nHelp define test criteria to establish clear conditions for success and ensure alignment with business objectives.\nManage their user stories and acceptance criteria through to production into day-to-day support\nAssist in the testing and validation of new requirements and processes to ensure they meet business need\nWhat are we looking for?\nExcellent data analysis and exploration using T-SQL\nStrong SQL programming (stored procedures, functions)\nExtensive experience with SQL Server and SSIS\nKnowledge and experience of data warehouse modelling methodologies (Kimball, dimensional modelling, Data Vault 2.0)\nExperience in Azure one or more of the following: Data Factory, Databricks, Synapse Analytics, ADLS Gen2\nExperience in building robust and performant ETL processes\nBuild and maintain Analysis Services databases and cubes (both multidimensional and tabular)\nExperience in using source control & ADO\nUnderstanding and experience of deployment pipelines\n",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Agile', 'Stored procedures', 'SSIS', 'Operations', 'Data warehousing', 'Analytics', 'Analysis services', 'SQL', 'google maps']",2025-06-13 05:38:27
R&D Technologist - Clinical Data Management,ZS,5 - 10 years,Not Disclosed,"['Pune', 'Bengaluru']","Our team has deep understanding of EDC tools like Rave, Veeva, InForm, openClinica, clinical data repositories like SAS LSAF, Oracle LSH, eCS elluminate, Metadata Repositories like Nurocor, Sycamore, Formedix, statistical computing environments like Sycamore, Domino, Sas Viya systems, Clinical data review systems, RBQM systems, and more. With experience as solution architects, business analysts, or techno-functional SMEs in GXP compliant validated environments, they guide the creation of solution, data flows and strategies for building clinical development and data management systems. Their offerings encompass technical advisory, consultancy, developing of clinical data platforms and products, system integration, and intelligent automation. Additionally, the team has created innovative tools through advanced technology and data science, aiding numerous clients in expediting the drug development process.",,,,"['Automation', 'SAS', 'Business analysis', 'Pharma', 'Consulting', 'Financial planning', 'Oracle', 'Risk management', 'Analytics', 'Clinical data management']",2025-06-13 05:38:29
Data Science Manager,ZS,10 - 15 years,Not Disclosed,"['Pune', 'Bengaluru']","A key enabler of our services is leveraging data in delivering client solutions. The data available about customers is getting richer and the problems that our customers are trying to answer continue to evolve. In our endeavor to stay ahead in providing solutions to these evolving complex problems, ZS has set up an Advanced Data Science which has three major focus areas:\nResearch the evolving datasets and advanced analytical techniques to develop new offerings/solutions\nDeliver client impact by collaboratively implementing these solutions",,,,"['Team management', 'data science', 'Pharma', 'Analytical', 'Management consulting', 'Financial planning', 'Healthcare', 'Project planning', 'Predictive modeling', 'Financial services']",2025-06-13 05:38:31
Data Engineer,Luxoft,5 - 10 years,Not Disclosed,['Pune'],"Are you passionate about data and analytics? Are you keen to be part of the journey to modernize a data warehouse/ analytics suite of application(s). Do you take pride in the quality of software delivered for each development iteration?\nWere looking for someone like that to join us and\nbe a part of a high-performing team on a high-profile project.\nsolve challenging problems in an elegant way\nmaster state-of-the-art technologies\nbuild a highly responsive and fast updating application in an Agile & Lean environment\napply best development practices and effectively utilize technologies\nwork across the full delivery cycle to ensure high-quality delivery\nwrite high-quality code and adhere to coding standards\nwork collaboratively with diverse team(s) of technologists\nYou are:\nCurious and collaborative, comfortable working independently, as well as in a team\nFocused on delivery to the business\nStrong in analytical skills. For example, the candidate must understand the key dependencies among existing systems in terms of the flow of data among them. It is essential that the candidate learns to understand the big picture of how IB industry/business functions.\nAble to quickly absorb new terminology and business requirements\nAlready strong in analytical tools, technologies, platforms, etc. The candidate must also demonstrate a strong desire for learning and self-improvement.\nOpen to learning home-grown technologies, support current state infrastructure and help drive future state migrations. imaginative and creative with newer technologies\nAble to accurately and pragmatically estimate the development effort required for specific objectives\nYou will have the opportunity to work under minimal supervision to understand local and global system requirements, design and implement the required functionality/bug fixes/enhancements. You will be responsible for components that are developed across the whole team and deployed globally.\nYou will also have the opportunity to provide third-line support to the applications global user community, which will include assisting dedicated support staff and liaising with the members of other development teams directly, some of which will be local and some remote.\nSkills\nMust have\nA bachelors or masters degree, preferably in Information Technology or a related field (computer science, mathematics, etc.), focusing on data engineering.\n5+ years of relevant experience as a data engineer in Big Data is required.\nStrong Knowledge of programming languages (Python / Scala) and Big Data technologies (Spark, Databricks or equivalent) is required.\nStrong experience in executing complex data analysis and running complex SQL/Spark queries.\nStrong experience in building complex data transformations in SQL/Spark.\nStrong knowledge of Database technologies is required.\nStrong knowledge of Azure Cloud is advantageous.\nGood understanding and experience with Agile methodologies and delivery.\nStrong communication skills with the ability to build partnerships with stakeholders.\nStrong analytical, data management and problem-solving skills.\nNice to have\nExperience working on the QlikView tool\nUnderstanding of QlikView scripting and data model\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nBig Data Engineer (Scala/Java/Python)\nBigData Development\nUnited States of America\nStamford, US\nBig Data Engineer (Scala/Java/Python)\nBigData Development\nUnited States of America\nWeehawken\nData Engineer - PostgreSQL\nBigData Development\nPoland\nRemote Poland\nPune, India\nReq. VR-114879\nBigData Development\nBCM Industry\n05/06/2025\nReq. VR-114879\nApply for Data Engineer in Pune\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data management', 'Coding', 'Postgresql', 'Agile', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-13 05:38:33
Analyst - Projects,Microland,4 - 6 years,Not Disclosed,['Bengaluru'],"Microland Limited is looking for Analyst - Projects to join our dynamic team and embark on a rewarding career journey Supports project planning, tracking, and performance monitoring\n\nAssists in data analysis, documentation, and coordination\n\nPrepares reports for stakeholders and leadership\n\nEnsures project timelines and deliverables are met",,,,"['Data analysis', 'Master Analyst', 'Project management', 'Agile', 'Manager Technology', 'Scrum', 'Data analytics']",2025-06-13 05:38:35
Senior Data Scientist,Codetru Software Solutions,8 - 12 years,Not Disclosed,['Hyderabad'],"Senior Data ScientistLocation: Hyderabad, IndiaExperience: 8-10 YearsWe are seeking a highly motivated, driven, and experienced Senior Data Scientist to join our dynamic team. As a go-getter with a passion for uncovering insights from complex data, you will play a pivotal role in shaping our data strategy and driving business decisions. The ideal candidate is a proactive problem-solver who thrives in a fast-paced environment and possesses a deep understanding of the entire data lifecycle, from extraction to model deployment.\n\nNote: This is purely a Technical role not Managerial.\n\nKey Responsibilities\nLead and execute end-to-end data science projects, from conception and data collection to model building and delivering actionable insights.\nDesign, build, and maintain robust and scalable ETL pipelines to process large volumes of structured and unstructured data from our data lake.\nUtilize advanced SQL and Python (Pandas, NumPy) for data extraction, manipulation, and in-depth analysis to identify critical trends, patterns, and opportunities.\nDevelop and implement a variety of machine learning algorithms, such as regression, classification, clustering, and forecasting models, to solve key business challenges.\nCreate compelling and intuitive data visualizations and dashboards using tools like Tableau or Power BI to communicate complex findings to both technical and non-technical stakeholders.\nMentor junior data scientists and contribute to the team's technical growth and best practices.\n\nMust-Have Qualifications & Skills\n\nExperience: A minimum of 8-10 years of hands-on experience in a data science or related role.\nSQL and Visualization: Expert-level proficiency in SQL for complex querying and proven experience with data visualization tools such as Tableau, Power BI, or Looker.\nData Engineering: Strong, hands-on experience building and managing ETL processes and working extensively within a data lake environment.\nPython and Data Analysis: Mastery of Python and its core data science libraries, especially Pandas, for data wrangling, exploration, and identifying hidden patterns.\nMachine Learning: In-depth theoretical knowledge and practical application of various ML algorithms, including supervised and unsupervised learning techniques. A portfolio of successfully deployed models is a strong plus.\nAttitude: A proactive, self-starting go-getter with excellent problem-solving skills and the drive to take ownership of projects from start to finish.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pandas', 'Fast Api', 'Machine Learning', 'Numpy', 'Python', 'Power Bi', 'Tableau', 'SQL', 'Flask']",2025-06-13 05:38:36
Senior Associate Data Scientist,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will identify trends, root causes, and potential improvements in our products and processes, ensuring that patient voices are heard and addressed with utmost precision.\nAs the Sr Associate Data Scientist at Amgen, you will be responsible for developing and deploying basic machine learning, operational research, semantic analysis, and statistical methods to uncover structure in large data sets. This role involves creating analytics solutions to address customer needs and opportunities.",,,,"['Data Science', 'data bricks', 'hypothesis testing', 'predictive analytics', 'data visualization', 'machine learning', 'statistics']",2025-06-13 05:38:38
Senior Data Scientist,Virtana Corp,5 - 10 years,Not Disclosed,"['Pune', 'Chennai']","Position Overview:\nWe are seeking a Senior Data Scientist Engineer with experience bringing highly scalable enterprise SaaS applications to market. This is a uniquely impactful opportunity to help drive our business forward and directly contribute to long-term growth at Virtana.\nIf you thrive in a fast-paced environment, take initiative, embrace proactivity and collaboration, and you re seeking an environment for continuous learning and improvement, we d love to hear from you!\nVirtana is a remote first work environment so you ll be able to work from the comfort of your home while collaborating with teammates on a variety of connectivity tools and technologies.\nRole Responsibilities:\nResearch and test machine learning approaches for analyzing large-scale distributed computing applications.\nDevelop production-ready implementations of proposed solutions across different models AI and ML algorithms, including testing on live customer data to improve accuracy, efficacy, and robustness\nWork closely with other functional teams to integrate implemented systems into the SaaS platform\nSuggest innovative and creative concepts and ideas that would improve the overall platform.\nJob Location - Pune, Chennai or Remote\nQualifications:\nThe ideal candidate must have the following qualifications:\n6 + years experience in practical implementation and deployment of large customer-facing ML based systems.\nMS or M Tech (preferred) in applied mathematics/statistics; CS or Engineering disciplines are acceptable but must have with strong quantitative and applied mathematical skills\nIn-depth working, beyond coursework, familiarity with classical and current ML techniques, both supervised and unsupervised learning techniques and algorithms\nImplementation experiences and deep knowledge of Classification, Time Series Analysis, Pattern Recognition, Reinforcement Learning, Deep Learning, Dynamic Programming and Optimization\nExperience in working on modeling graph structures related to spatiotemporal systems\nProgramming skills in Python is a must\nExperience in understanding and usage of LLM models and Prompt engineering is preferred.\nExperience in developing and deploying on cloud (AWS or Google or Azure)\nGood verbal and written communication skills\nFamiliarity with well-known ML frameworks such as Pandas, Keras, TensorFlow\nAbout Virtana:\nVirtana delivers the industry s only unified software multi-cloud management platform that allows organizations to monitor infrastructure, de-risk cloud migrations, and reduce cloud costs by 25% or more.\nOver 200 Global 2000 enterprise customers, such as AstraZeneca, Dell, Salesforce, Geico, Costco, Nasdaq, and Boeing, have valued Virtana s software solutions for over a decade.\nOur modular platform for hybrid IT digital operations includes Infrastructure Performance Monitoring and Management (IPM), Artificial Intelligence for IT Operations (AIOps), Cloud Cost Management (Fin Ops), and Workload Placement Readiness Solutions. Virtana is simplifying the complexity of hybrid IT environments with a single cloud-agnostic platform across all the categories listed above. The $30B IT Operations Management (ITOM) Software market is ripe for disruption, and Virtana is uniquely positioned for success.\nCompany Profitable Growth and Recognition\nIn FY2023 (Fiscal year ending January 2023), Virtana earned:\nBest CEO, Best CEO for Women, and Best CEO for Diversity by Comparably\nTwo years in a row YoY Profitable Annual Recurring Revenue (ARR) Growth\nTwo consecutive years of +EBITDA, 78% YoY EBITDA growth, or 20% of Revenue\nPositive Cash Flow, 171% YoY cash flow growth\n\nYou can schedule with us through Calendly at https: / / calendly.com / bimla-dhirayan / zoom-meeting-virtana",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Usage', 'Time series analysis', 'Artificial Intelligence', 'IT operations management', 'Machine learning', 'Cloud', 'Cash flow', 'Pattern recognition', 'Performance monitoring', 'Python']",2025-06-13 05:38:40
Senior Data Scientist,Clarice Technologie,4 - 8 years,Not Disclosed,['Pune'],"At Globant, we are working to make the world a better place, one step at a time. We enhance business development and enterprise solutions to prepare them for a digital future. With a diverse and talented team present in more than 30 countries, we are strategic partners to leading global companies in their business process transformation.\nWe seek a Data Scientist Senior-Level (Senior) who shares our passion for innovation and change. This role is critical to helping our business partners evolve and adapt to consumers personalized expectations in this new technological era.\nWhat will help you succeed:",,,,"['Usage', 'Business process transformation', 'Machine learning', 'Manager Technology', 'digital transformation', 'AWS', 'Recruitment', 'Python']",2025-06-13 05:38:41
SR DATA SCIENTIST I GLOBAL,McCormick,5 - 9 years,Not Disclosed,['Gurugram'],"At McCormick, we bring our passion for flavor to work each day. We encourage growth, respect everyones contributions and do whats right for our business, our people, our communities and our planet. Join us on our quest to make every meal and moment better.\nFounded in Baltimore, MD in 1889 in a room and a cellar by 25-year-old Willoughby McCormick with three employees, McCormick is a global leader in flavour. With over 14,000 employees around the world and more than $6 Billion in annual sales, the Company manufactures, markets, and distributes spices, seasoning mixes, condiments and other flavourful products to the entire food industry, retail outlets, food manufactures, food service businesses and consumers.\nWhile our global headquarters are in the Baltimore, Maryland, USA area, McCormick operates and serves customers from nearly 60 locations in 25 countries and 170 markets in Asia-Pacific, China, Europe, Middle East and Africa, and the Americas.\nAt McCormick, we have over a 100-year legacy based on our Power of People principle. This principle fosters an unusually dedicated workforce requiring a culture of respect, recognition, inclusion and collaboration based on the highest ethical values.\nPosition Overview\nProvide the business with analytic tools and insights that drive growth and/or productivity. Provide technical leadership for analytics community via forward thinking attitude, use of cutting-edge tools and approaches and business consulting. Individual should help shape business and analytics strategies for our business units globally.\nKey Responsibilities\nBringing new tools to the business; leading data mining and analytics, interpreting and reporting of large integrated data sets built with structured and unstructured data; developing tools to leverage new proprietary data sources.\nStatistical model building and deployment in the areas of forecasting, marketing mix, machine learning/AI, etc.\nContinuously seeking out industry best practices and skills development to create new capabilities for data analytics at McCormick to drive marketing strategy.\nMay include managing/coaching direct reports to enable responsibilities above.\nRequired Qualifications & Experience\nBachelor s or Master s degree in Mathematics, Statistics, Engineering or Data Analytics/Science, or closely related field. Demonstrated skills and results in analyzing complex datasets, generating insights and building robust statistical models; Demonstrated sound understanding of concepts, principles and practices in Marketing and Sales and a working knowledge of practices in other areas including Finance and Supply Chain. Demonstrated ability to connect the dots between complex data/analytics and business understanding. Expertise in data management, integration & harmonization. Expertise in SQL, coding in one or more languages (R & Python preferred)\nExperience with data visualization software (Tableau preferred) Comfortable working with structured and unstructured data sources, including syndicated data, SAP\nStrong technical curiosity and passion for problem solving and innovation\nInterpersonal Skills\nStrong global cross-functional leadership, influence, communication and teamwork skills. Ability to manage multiple priorities simultaneously and foresee and address issues before they become significant obstacles\nWHY WORK AT MCCORMICK?\nUnited by flavor. Driven by results.\nAs a McCormick employee you ll be empowered to focus on more than your individual responsibilities. You ll have the opportunity to be part of something bigger than yourself to have a say in where the company is going and how it s growing.\nBetween our passion for flavor, our 130-year history of leadership and integrity, the competitive and comprehensive benefits we offer, and our culture, which is built on respect and opportunities for growth, there are many reasons to join us at McCormick.",Industry Type: Consumer Electronics & Appliances,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Interpersonal skills', 'SAP', 'Data management', 'Machine learning', 'Data analytics', 'data visualization', 'Data mining', 'Forecasting', 'Marketing strategy']",2025-06-13 05:38:43
Process Executive - B&L,Cognizant,0 - 2 years,Not Disclosed,['Coimbatore'],Job Summary\nThe Process Executive - B&L role is designed for individuals with 0 to 2 years of experience focusing on tasks related to consumer lending cards and payments. This position requires proficiency in MS Excel and offers a hybrid work model with day shifts. The role does not require travel allowing for a balanced work-life integration.,,,,"['cards', 'data analysis', 'analytical', 'workflow', 'lending', 'documentation', 'policies', 'business analysis', 'monitoring', 'process improvements', 'sql', 'plsql', 'excel', 'flexcube', 'operations', 'customer satisfaction', 'service delivery', 'compliance', 'onboarding', 'core banking', 'consumer lending', 'communication skills']",2025-06-13 05:38:45
Azure Senior Data Engineers,IT Services & Consulting,5 - 9 years,14-24 Lacs P.A.,['Bengaluru'],"Job Title: Senior Data Engineer Azure\nLocation: Bengaluru\nExperience: 6+ years (3+ years on Azure data services preferred)\nDepartment: Data Engineering / IT\nJob Summary:\nWe are seeking a highly skilled Senior Data Engineer with expertise in Microsoft Azure to design, develop, and optimize data pipelines, data lakes, and warehouse solutions. The ideal candidate will play a key role in building scalable and secure data platforms to support business intelligence, analytics, and machine learning use cases.\nKey Responsibilities:\nDesign, build, and maintain scalable data pipelines using Azure Data Factory, Databricks, Synapse Analytics, and related tools.\nDevelop and optimize ETL/ELT processes for structured and unstructured data.\nImplement data lake and data warehouse solutions following best practices and security standards.\nCollaborate with data scientists, analysts, and business stakeholders to understand data requirements.\nEnsure data quality, lineage, and governance using tools like Purview, Azure Monitor, and Data Catalog.\nMonitor and troubleshoot performance issues across data flows and batch processing pipelines.\nSupport real-time data integration and streaming solutions using Azure Event Hubs, Stream Analytics, or Kafka.\nMaintain and enhance CI/CD pipelines for data solutions using Azure DevOps or GitHub Actions.\nLead and mentor junior engineers in best practices for Azure data engineering.\nRequired Skills & Qualifications:\nBachelor’s or Master’s degree in Computer Science, Engineering, or related field.\n6+ years of experience in data engineering roles, with 3+ years working with Azure data services.\nProficiency in SQL, Python or Scala.\nExperience with tools like Azure Data Factory, Azure Synapse Analytics, Azure Databricks, Azure SQL Database, and Azure Blob Storage.\nStrong understanding of data modeling, data warehousing, and data lake architecture.\nFamiliarity with DevOps practices, infrastructure-as-code (IaC) tools (ARM, Bicep, Terraform), and CI/CD pipelines.\nKnowledge of data governance and data security best practices on cloud platforms.\nExcellent communication and documentation skills.\nPreferred Qualifications:\nAzure certification (e.g., Azure Data Engineer Associate, Azure Solutions Architect, etc.)\nExperience with big data frameworks (e.g., Spark, Hadoop).\nKnowledge of machine learning pipelines or MLOps in Azure.\nExperience with Power BI or integration with other visualization tools.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure Senior Data Engineers', 'Azure Data Factory', 'azure']",2025-06-13 05:38:47
Senior Data Engineer,PulseData labs Pvt Ltd,7 - 10 years,Not Disclosed,['Bengaluru'],"Company name: PulseData labs Pvt Ltd (captive Unit for URUS, USA)\n\nAbout URUS\nWe are the URUS family (US), a global leader in products and services for Agritech.\n\nSENIOR DATA ENGINEER\nThis role is responsible for the design, development, and maintenance of data integration and reporting solutions. The ideal candidate will possess expertise in Databricks and strong skills in SQL Server, SSIS and SSRS, and experience with other modern data engineering tools such as Azure Data Factory. This position requires a proactive and results-oriented individual with a passion for data and a strong understanding of data warehousing principles.\n\nResponsibilities\nData Integration\nDesign, develop, and maintain robust and efficient ETL pipelines and processes on Databricks.\nTroubleshoot and resolve Databricks pipeline errors and performance issues.\nMaintain legacy SSIS packages for ETL processes.\nTroubleshoot and resolve SSIS package errors and performance issues.\nOptimize data flow performance and minimize data latency.\nImplement data quality checks and validations within ETL processes.\nDatabricks Development\nDevelop and maintain Databricks pipelines and datasets using Python, Spark and SQL.\nMigrate legacy SSIS packages to Databricks pipelines.\nOptimize Databricks jobs for performance and cost-effectiveness.\nIntegrate Databricks with other data sources and systems.\nParticipate in the design and implementation of data lake architectures.\nData Warehousing\nParticipate in the design and implementation of data warehousing solutions.\nSupport data quality initiatives and implement data cleansing procedures.\nReporting and Analytics\nCollaborate with business users to understand data requirements for department driven reporting needs.\nMaintain existing library of complex SSRS reports, dashboards, and visualizations.\nTroubleshoot and resolve SSRS report issues, including performance bottlenecks and data inconsistencies.\nCollaboration and Communication\nComfortable in entrepreneurial, self-starting, and fast-paced environment, working both independently and with our highly skilled teams.\nCollaborate effectively with business users, data analysts, and other IT teams.\nCommunicate technical information clearly and concisely, both verbally and in writing.\nDocument all development work and procedures thoroughly.\nContinuous Growth\nKeep abreast of the latest advancements in data integration, reporting, and data engineering technologies.\nContinuously improve skills and knowledge through training and self-learning.\nThis job description reflects managements assignment of essential functions; it does not prescribe or restrict the tasks that may be assigned.\n\nRequirements\nBachelor's degree in computer science, Information Systems, or a related field.\n7+ years of experience in data integration and reporting.\nExtensive experience with Databricks, including Python, Spark, and Delta Lake.\nStrong proficiency in SQL Server, including T-SQL, stored procedures, and functions.\nExperience with SSIS (SQL Server Integration Services) development and maintenance.\nExperience with SSRS (SQL Server Reporting Services) report design and development.\nExperience with data warehousing concepts and best practices.\nExperience with Microsoft Azure cloud platform and Microsoft Fabric desirable.\nStrong analytical and problem-solving skills.\nExcellent communication and interpersonal skills.\nAbility to work independently and as part of a team.\nExperience with Agile methodologies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Etl Development', 'Azure Databricks', 'Spark', 'SQL Server', 'Databricks Engineer', 'Data Warehousing', 'Pythonspark']",2025-06-13 05:38:49
Sr. Data Science,Disa Consulting Services,7 - 9 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Title: SR DATA SCIENCE\nExperience: 7 - 9 Years\nNotice Period: Immediate to 15 days\nWork Mode: Remote, Hybrid\nLocation: Hyderabad & Chennai\n\nRequirements:\nExperience designing and developing automated pipelines that utilize some combination of RAG pipelines, automated generation of prompts to LLMs, and/or multi-agent Agentic inference engines.\nAll skills / experience of above listed data scientist roles plus:\nArchitected and designed end to end pipelines that utilize LLMs and Autonomous Agents.\nDesigned and implemented methods for assuring quality and governing the output of Gen AI or Agentic solutions.\nDesigned and developed APIs exposing services of services that consume LLMs.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Restfull Api', 'Azure Cloud', 'LLM', 'Machine Learning', 'SQL', 'Python']",2025-06-13 05:38:50
Senior Data Engineer -Bangalore,Happiest Minds Technologies,6 - 10 years,Not Disclosed,['Bengaluru'],"Job Overview:\nThe primary purpose of this role is to translate business requirements and functional specifications into logical program designs and to deliver dashboards, schema, data pipelines, and software solutions. This includes developing, configuring, or modifying data components within various complex business and/or enterprise application solutions in various computing environments. You will partner closely with multiple Business partners, Product Owners, Data Strategy, Data Platform, Data Science and Machine Learning (MLOps) teams to drive innovative data products for end users. Additionally, you will help shape overall solution & data products, develop scalable solutions through best-in-class engineering practices.",,,,"['NoSQL', 'big data systems', 'Data Pipeline', 'MongoDB', 'SQL', 'Hive', 'GIT', 'Hadoop', 'Kafka', 'Agile', 'MQL', 'Ci/Cd']",2025-06-13 05:38:52
Sr Data Engineer,Lowes Services India Private limited,5 - 10 years,Not Disclosed,['Bengaluru'],"We are seeking a seasoned Senior Data Engineer to join our Marketing Data Platform team. This role is pivotal in designing, building, and optimizing scalable data pipelines and infrastructure that support our marketing analytics and customer engagement strategies. The ideal candidate will have extensive experience with big data technologies, cloud platforms, and a strong understanding of marketing data dynamics.\n\nData Pipeline Development & Optimization\nDesign, develop, and maintain robust ETL/ELT pipelines using Apache PySpark on GCP services like Dataproc and Cloud Composer.\nEnsure data pipelines are scalable, efficient, and reliable to handle large volumes of marketing data.\nData Warehousing & Modeling\nImplement and manage data warehousing solutions using BigQuery, ensuring optimal performance and cost-efficiency.\nDevelop and maintain data models that support marketing analytics and reporting needs.\nCollaboration & Stakeholder Engagement\nWork closely with marketing analysts, data scientists, and cross-functional teams to understand data requirements and deliver solutions that drive business insights.\nTranslate complex business requirements into technical specifications and data architecture.\nData Quality & Governance\nImplement data quality checks and monitoring to ensure the accuracy and integrity of marketing data.\nAdhere to data governance policies and ensure compliance with data privacy regulations.\nContinuous Improvement & Innovation\nStay abreast of emerging technologies and industry trends in data engineering and marketing analytics.\nPropose and implement improvements to existing data processes and infrastructure\n  Years of Experience\n5 Years in Data Engineer space\n  Education Qualification & Certifications\nB.Tech or MCA\n  Experience\nProven experience with Apache PySpark, GCP (including Dataproc, BigQuery, Cloud Composer), and data pipeline orchestration.\nTechnical Skills\nProficiency in SQL and Python.\nExperience with data modeling, ETL/ELT processes, and data warehousing concepts.",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['orchestration', 'Data modeling', 'data governance', 'Data quality', 'Apache', 'Continuous improvement', 'Monitoring', 'SQL', 'Python', 'Data architecture']",2025-06-13 05:38:54
Senior GCP Data Engineer,Swits Digital,6 - 9 years,Not Disclosed,['Bengaluru'],"Job Title: Senior GCP Data Engineer\nLocation: Chennai, Bangalore, Hyderabad\nExperience: 6-9 Years\nJob Summary:\nWe are seeking a GCP Data & Cloud Engineer with strong expertise in Google Cloud Platform services, including BigQuery, Cloud Run, Cloud Storage , and Pub/Sub . The ideal candidate will have deep experience in SQL coding , data pipeline development, and deploying cloud-native solutions.\nKey Responsibilities:\nDesign, implement, and optimize scalable data pipelines and services using GCP\nBuild and manage cloud-native applications deployed via Cloud Run\nDevelop complex and performance-optimized SQL queries for analytics and data transformation\nManage and automate data storage, retrieval, and archival using Cloud Storage\nImplement event-driven architectures using Google Pub/Sub\nWork with large datasets in BigQuery , including ETL/ELT design and query optimization\nEnsure security, monitoring, and compliance of cloud-based systems\nCollaborate with data analysts, engineers, and product teams to deliver end-to-end cloud solutions\nRequired Skills & Experience:\n3+ years of experience working with Google Cloud Platform (GCP)\nStrong proficiency in SQL coding , query tuning, and handling complex data transformations\nHands-on experience with:\nBigQuery\nCloud Run\nCloud Storage\nPub/Sub\nUnderstanding of data pipeline and ETL/ELT workflows in cloud environments\nFamiliarity with containerized services and CI/CD pipelines\nExperience in scripting languages (e.g., Python, Shell) is a plus\nStrong analytical and problem-solving skills",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SUB', 'query optimization', 'GCP', 'Analytical', 'Cloud', 'query', 'cloud storage', 'Security monitoring', 'SQL coding', 'Python']",2025-06-13 05:38:55
Senior Data Engineer,Talentien Global Solutions,4 - 8 years,12-18 Lacs P.A.,"['Hyderabad', 'Chennai', 'Coimbatore']","We are seeking a skilled and motivated Data Engineer to join our dynamic team. The ideal candidate will have experience in designing, developing, and maintaining scalable data pipelines and architectures using Hadoop, PySpark, ETL processes, and Cloud technologies.\n\nResponsibilities:\nDesign, develop, and maintain data pipelines for processing large-scale datasets.\nBuild efficient ETL workflows to transform and integrate data from multiple sources.\nDevelop and optimize Hadoop and PySpark applications for data processing.\nEnsure data quality, governance, and security standards are met across systems.\nImplement and manage Cloud-based data solutions (AWS, Azure, or GCP).\nCollaborate with data scientists and analysts to support business intelligence initiatives.\nTroubleshoot performance issues and optimize query executions in big data environments.\nStay updated with industry trends and advancements in big data and cloud technologies.\nRequired Skills:\nStrong programming skills in Python, Scala, or Java.\nHands-on experience with Hadoop ecosystem (HDFS, Hive, Spark, etc.).\nExpertise in PySpark for distributed data processing.\nProficiency in ETL tools and workflows (SSIS, Apache Nifi, or custom pipelines).\nExperience with Cloud platforms (AWS, Azure, GCP) and their data-related services.\nKnowledge of SQL and NoSQL databases.\nFamiliarity with data warehousing concepts and data modeling techniques.\nStrong analytical and problem-solving skills.\n\nInterested can reach us at +91 7305206696/ saranyadevib@talentien.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Engineering', 'Hadoop', 'Spark', 'ETL', 'Airflow', 'Etl Pipelines', 'Big Data', 'EMR', 'Gcp Cloud', 'Data Bricks', 'Azure Cloud', 'Data Pipeline', 'SCALA', 'Snowflake', 'Data Lake', 'Data Warehousing', 'Data Modeling', 'AWS', 'Python']",2025-06-13 05:38:57
Data Engineer-Data Platforms,IBM,5 - 10 years,Not Disclosed,['Navi Mumbai'],"As a Big Data Engineer, you will develop, maintain, evaluate, and test big data solutions. You will be involved in data engineering activities like creating pipelines/workflows for Source to Target and implementing solutions that tackle the clients needs.\n\nYour primary responsibilities include:\nDesign, build, optimize and support new and existing data models and ETL processes based on our clients business requirements.\nBuild, deploy and manage data infrastructure that can adequately handle the needs of a rapidly growing data driven organization.\nCoordinate data access and security to enable data scientists and analysts to easily access to data whenever they need too\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nMust have 5+ years exp in Big Data -Hadoop Spark -Scala ,Python\nHbase, Hive Good to have Aws -S3,\nathena ,Dynomo DB, Lambda, Jenkins GIT\nDeveloped Python and pyspark programs for data analysis.\nGood working experience with python to develop Custom Framework for generating of rules (just like rules engine).\nDeveloped Python code to gather the data from HBase and designs the solution to implement using Pyspark. Apache Spark DataFrames/RDD's were used to apply business transformations and utilized Hive Context objects to perform read/write operations\n\n\nPreferred technical and professional experience\nUnderstanding of Devops.\nExperience in building scalable end-to-end data ingestion and processing solutions\nExperience with object-oriented and/or functional programming languages, such as Python, Java and Scala",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['scala', 'hadoop spark', 'spark', 'big data', 'python', 'hive', 'cloudera', 'pyspark', 'sql', 'java', 'git', 'postgresql', 'devops', 'jenkins', 'data ingestion', 'mysql', 'hadoop', 'etl', 'hbase', 'data analysis', 'dynamo db', 'oozie', 'microsoft azure', 'impala', 'data engineering', 'lambda expressions', 'kafka', 'sqoop', 'aws']",2025-06-13 05:38:59
Data Engineer Specialist,Accenture,3 - 4 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level :\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python, Pyspark\n\n\n\n\nGood to have skills:Redshift\n\n\n\nJob\n\n\nSummary: We are seeking a highly skilled and experienced Senior Data Engineer to join our growing Data and Analytics team. The ideal candidate will have deep expertise in Databricks and cloud data warehousing, with a proven track record of designing and building scalable data pipelines, optimizing data architectures, and enabling robust analytics capabilities. This role involves working collaboratively with cross-functional teams to ensure the organization leverages data as a strategic asset. Your responsibilities will include:\n\n\n\n\nRoles & Responsibilities\nDesign, build, and maintain scalable data pipelines and ETL processes using Databricks and other modern tools.\nArchitect, implement, and manage cloud-based data warehousing solutions on Databricks (Lakehouse Architecture)\nDevelop and maintain optimized data lake architectures to support advanced analytics and machine learning use cases.\nCollaborate with stakeholders to gather requirements, design solutions, and ensure high-quality data delivery.\nOptimize data pipelines for performance and cost efficiency.\nImplement and enforce best practices for data governance, access control, security, and compliance in the cloud.\nMonitor and troubleshoot data pipelines to ensure reliability and accuracy.\nLead and mentor junior engineers, fostering a culture of continuous learning and innovation.\nExcellent communication skills\nAbility to work independently and along with client based out of western Europe\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\nCreating data products for analytics team members to improve productivity\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\nPreparing data to create a unified database and build tracking solutions ensuring data quality\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\n\nProfessional and Technical Skills\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 3-4 years of hands-on experience working on these technologies.\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\nExperience working in cloud Data warehouses like Redshift or Synapse\nCertification in any one of the following or equivalent\nAWS- AWS certified data Analytics- Speciality\nAzure- Microsoft certified Azure Data Scientist Associate\nSnowflake- Snowpro core- Data Engineer\nDatabricks Data Engineering\n\nQualification\n\n\n\nExperience:5-8 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'data bricks', 'glue', 'amazon redshift', 'data warehousing', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'snowflake', 'scipy', 'data analysis', 'azure data lake', 'microsoft azure', 'power bi', 'javascript', 'pandas', 'tableau', 'lambda expressions', 'aws']",2025-06-13 05:39:01
Enterprise Data Operations Manager,Pepsico,12 - 17 years,Not Disclosed,['Hyderabad'],"Overview\n\nDeputy Director - Data Engineering\n\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCos global business scale to enable business insights, advanced analytics, and new product development. PepsiCos Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.",,,,"['Data Engineering', 'Pyspark', 'Azure', 'Power BI', 'Github', 'Azure Databricks', 'Tableau', 'ADO', 'Scala programming', 'SQL', 'Azure Data Factory', 'Azure Machine learning', 'Data Lakehouse', 'Azure Data Engineering', 'CI/CD', 'Data Warehousing', 'Data Analytics', 'AWS', 'Python']",2025-06-13 05:39:03
Data Engineer,Capgemini,6 - 9 years,Not Disclosed,['Gurugram'],"\nesign, implement, and maintain data pipelines for data ingestion, processing, and transformation in Azure.\nWork together with data scientists and analysts to understand the needs for data and create effective data workflows.\nCreate and maintain data storage solutions including Azure SQL Database, Azure Data Lake, and Azure Blob Storage.\nUtilizing Azure Data Factory or comparable technologies, create and maintain ETL (Extract, Transform, Load) operations.\nImplementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.\nImprove the scalability, efficiency, and cost-effectiveness of data pipelines.\nMonitoring and resolving data pipeline problems will guarantee consistency and availability of the data.\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'azure data factory', 'sql', 'azure blob storage', 'sql azure', 'hive', 'azure databricks', 'python', 'data validation', 'pyspark', 'data warehousing', 'power bi', 'data engineering', 'spark', 'data ingestion', 'software engineering', 'hadoop', 'etl', 'big data', 'aws', 'sql database']",2025-06-13 05:39:05
Data Engineer,Capgemini,6 - 9 years,Not Disclosed,['Hyderabad'],"\nDesign, implement, and maintain data pipelines for data ingestion, processing, and transformation in Azure.\nWork together with data scientists and analysts to understand the needs for data and create effective data workflows.\nCreate and maintain data storage solutions including Azure SQL Database, Azure Data Lake, and Azure Blob Storage.\nUtilizing Azure Data Factory or comparable technologies, create and maintain ETL (Extract, Transform, Load) operations.\nImplementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.\nImprove the scalability, efficiency, and cost-effectiveness of data pipelines.\nMonitoring and resolving data pipeline problems will guarantee consistency and availability of the data.\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'azure data factory', 'sql', 'azure blob storage', 'sql azure', 'hive', 'azure databricks', 'python', 'data validation', 'pyspark', 'data warehousing', 'power bi', 'data engineering', 'spark', 'data ingestion', 'software engineering', 'hadoop', 'etl', 'big data', 'aws', 'sql database']",2025-06-13 05:39:07
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Mumbai'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\nYour primary responsibilities include\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\nStrive for continuous improvements by testing the build solution and working under an agile framework.\nDiscover and implement the latest technologies trends to maximize and build creative solutions\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nExperience with Apache Spark (PySpark)In-depth knowledge of Spark’s architecture, core APIs, and PySpark for distributed data processing.\nBig Data TechnologiesFamiliarity with Hadoop, HDFS, Kafka, and other big data tools. Data Engineering\n\nSkills:\nStrong understanding of ETL pipelines, data modeling, and data warehousing concepts.\nStrong proficiency in PythonExpertise in Python programming with a focus on data processing and manipulation. Data Processing FrameworksKnowledge of data processing libraries such as Pandas, NumPy.\nSQL ProficiencyExperience writing optimized SQL queries for large-scale data analysis and transformation.\nCloud PlatformsExperience working with cloud platforms like AWS, Azure, or GCP, including using cloud storage systems\n\n\nPreferred technical and professional experience\nDefine, drive, and implement an architecture strategy and standards for end-to-end monitoring.\nPartner with the rest of the technology teams including application development, enterprise architecture, testing services, network engineering,\nGood to have detection and prevention tools for Company products and Platform and customer-facing",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-13 05:39:09
Data Quality Management & Configuration,Capgemini,4 - 7 years,Not Disclosed,['Coimbatore'],"\nThis role involves the development and application of engineering practice and knowledge in defining, configuring and deploying industrial digital technologies (including but not limited to PLM and MES) for managing continuity of information across the engineering enterprise, including design, industrialization, manufacturing and supply chain, and for managing the manufacturing data.\n\n - Grade Specific \nFocus on Digital Continuity and Manufacturing. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['project management', 'supply chain', 'data quality management', 'manufacturing', 'industrialization', 'npd', 'data analytics', 'data analysis', 'program management', 'new product development', 'manufacturing engineering', 'process engineering', 'sql', 'industrial engineering']",2025-06-13 05:39:11
Data Engineer-Data Integration,IBM,2 - 5 years,Not Disclosed,['Pune'],"As Data Engineer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You'll contribute to data gathering, storage, and both batch and real-time processing.\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\n\nIn this role, your responsibilities may include:\nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise seach applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results\n\n\n Your primary responsibilities include: \nDevelop & maintain data pipelines for batch & stream processing using informatica power centre or cloud ETL/ELT tools.\nLiaise with business team and technical leads, gather requirements, identify data sources, identify data quality issues, design target data structures, develop pipelines and data processing routines, perform unit testing and support UAT.\nWork with data scientist and business analytics team to assist in data ingestion and data-related technical issues.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nExpertise in Data warehousing/ information Management/ Data Integration/Business Intelligence using ETL tool Informatica PowerCenter\nKnowledge of Cloud, Power BI, Data migration on cloud skills.\nExperience in Unix shell scripting and python\nExperience with relational SQL, Big Data etc\n\n\nPreferred technical and professional experience\nKnowledge of MS-Azure Cloud\nExperience in Informatica PowerCenter\nExperience in Unix shell scripting and python",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['information management', 'data warehousing', 'business intelligence', 'etl', 'data integration', 'python', 'informatica powercenter', 'power bi', 'relational sql', 'data migration', 'azure cloud', 'sql', 'elastic search', 'unix shell scripting', 'splunk', 'agile', 'big data', 'informatica']",2025-06-13 05:39:12
Data Consultant_Strategy & Consulting,Capgemini,8 - 10 years,Not Disclosed,['Pune'],"Capgemini Invent \n\nCapgemini Invent is the digital innovation, consulting and transformation brand of the Capgemini Group, a global business line that combines market leading expertise in strategy, technology, data science and creative design, to help CxOs envision and build whats next for their businesses.\n\n Your Role \n Client Engagement & Advisory: \nPartner with clients to understand their business goals, CX challenges, and data needs.\nProvide strategic recommendations on how to leverage data to enhance customer engagement, satisfaction, and retention.\n Data Strategy Development: \nDesign comprehensive data strategies tailored to client objectives, including customer segmentation, predictive modelling, and personalization.\nDefine KPIs and metrics to measure the success of CX initiatives.\n Data Analysis & Insights: \nAnalyze structured and unstructured data to derive actionable insights.\nLeverage advanced analytics techniques, including machine learning and AI, to identify trends and opportunities.\n Solution Design & Implementation: \nCollaborate with technical teams to design and implement data platforms, dashboards, and analytics solutions.\nDrive the implementation of customer data platforms (CDPs), marketing automation tools, and analytics systems.\n Stakeholder Management: \nAct as a trusted advisor to business stakeholders.\nPresent findings, recommendations, and reports in a clear, compelling manner\n\n\n Your Profile \n8-10 years of experience in data analytics, data strategy, or consulting roles, with a focus on customer experience, marketing, or business transformation.\nMinimum of 5-8 years of experience in omni-channel marketing, data analytics, or marketing automation implementation, with at least 2 years in a consulting role.\n3+ years of experience in marketing orchestration, preferably with hands-on experience using marketing automation platforms (e.g., Salesforce Marketing Cloud, Adobe Campaign, Braze, Marketo, etc.) and leveraging customer data for personalized, cross-channel campaigns.\nBachelors degree in data science, Business Analytics, Computer Science, Marketing, or related fields. Masters degree preferable.\n Technical\n\nSkills:\n Proficiency in analytics tools (e.g., Python, R, SQL).\nFamiliarity with visualization tools (e.g., Tableau, Power BI).\nExperience implementing CDP tools (Salesforce CDP, Adobe CDP, Segment etc)\nKnowledge of cloud platforms (e.g., AWS, Azure, Google Cloud) is a plus.\nData Analytics\nData modelling\nDigital Marketing\nDigital Technology Consulting\nData-Driven Marketing\nProven track record of contributing to client engagements and delivering data-driven solutions.\nStrong communication, problem-solving, and interpersonal skills.\n\n\n What you will love about working here \nWe recognize the significance of flexible work arrangements to provide support. Be it remote work, or flexible work hours, you will get an environment to maintain healthy work life balance.\nAt the heart of our mission is your career growth. Our array of career growth programs and diverse professions are crafted to support you in exploring a world of opportunities.\nEquip yourself with valuable certifications in the latest technologies such as Generative AI.\n\n\n About Capgemini \n\nCapgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of 22.5 billion",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'analytics tool', 'channel marketing', 'marketing automation', 'marketing', 'digital marketing', 'python', 'power bi', 'microsoft azure', 'adobe', 'omni', 'cdp', 'sql', 'salesforce', 'tableau', 'r', 'salesforce marketing cloud', 'data modeling', 'gcp', 'adobe campaign', 'aws']",2025-06-13 05:39:14
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Pune'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\nYour primary responsibilities include:\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\nStrive for continuous improvements by testing the build solution and working under an agile framework.\nDiscover and implement the latest technologies trends to maximize and build creative solutions\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nExperience with Apache Spark (PySpark)In-depth knowledge of Spark’s architecture, core APIs, and PySpark for distributed data processing.\nBig Data TechnologiesFamiliarity with Hadoop, HDFS, Kafka, and other big data tools. Data Engineering\n\nSkills:\nStrong understanding of ETL pipelines, data modeling, and data warehousing concepts.\nStrong proficiency in PythonExpertise in Python programming with a focus on data processing and manipulation. Data Processing FrameworksKnowledge of data processing libraries such as Pandas, NumPy.\nSQL ProficiencyExperience writing optimized SQL queries for large-scale data analysis and transformation.\nCloud PlatformsExperience working with cloud platforms like AWS, Azure, or GCP, including using cloud storage systems\n\n\nPreferred technical and professional experience\nDefine, drive, and implement an architecture strategy and standards for end-to-end monitoring.\nPartner with the rest of the technology teams including application development, enterprise architecture, testing services, network engineering,\nGood to have detection and prevention tools for Company products and Platform and customer-facing",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-13 05:39:16
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Navi Mumbai'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\n\nYour primary responsibilities include:\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\nStrive for continuous improvements by testing the build solution and working under an agile framework.\nDiscover and implement the latest technologies trends to maximize and build creative solutions\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nExperience with Apache Spark (PySpark)In-depth knowledge of Spark’s architecture, core APIs, and PySpark for distributed data processing.\nBig Data TechnologiesFamiliarity with Hadoop, HDFS, Kafka, and other big data tools. Data Engineering\n\nSkills:\nStrong understanding of ETL pipelines, data modeling, and data warehousing concepts.\nStrong proficiency in PythonExpertise in Python programming with a focus on data processing and manipulation. Data Processing FrameworksKnowledge of data processing libraries such as Pandas, NumPy.\nSQL ProficiencyExperience writing optimized SQL queries for large-scale data analysis and transformation.\nCloud PlatformsExperience working with cloud platforms like AWS, Azure, or GCP, including using cloud storage systems\n\n\nPreferred technical and professional experience\nDefine, drive, and implement an architecture strategy and standards for end-to-end monitoring.\nPartner with the rest of the technology teams including application development, enterprise architecture, testing services, network engineering,\nGood to have detection and prevention tools for Company products and Platform and customer-facing",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-13 05:39:18
Data Modeler,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Data Modeler\n\n\n\n\n\nProject Role Description :Work with key business representatives, data owners, end users, application designers and data architects to model current and new data.\n\n\n\nMust have skills :Data Modeling Techniques and Methodologies\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\nProject Role :Data Architect & Modeler\n\nProject Role Description Data Model, Design, build and lead the complex ETL data integration pipelines to meet business process and application requirements. Management Level :9Work Experience :6+ yearsWork Location :AnyMust have skills :Data Architecture Principles\nGood to have skills :Data Modeling, Data Architect, Informatica PowerCenter, Informatica Data Quality, SAP BusinessObjects Data Services, SQL, PL/SQL, SAP HANA DB, MS Azure, Python, ErWin, SAP Power Designer Job :Data Architect, Modeler, and data Integration LeadKey Responsibilities:1) Working on building Data models, Forward and Reverse Engineering.2) Working on Data and design analysis and working with data analysts team on data model design.3) Working on presentations on design, end to end flow and data models.4) Work on new and existing data models using Power designer tools and other designing tools like Visio5) Work with functional SMEs, BAs to review requirements, mapping documents\nTechnical Experience:1) Should have good understanding of ETL design concepts like CDC, SCD, Transpose/ pivot, Updates, Validation2) Should have strong understanding of SQL concepts, Data warehouse concepts and can easily understand data technically and functionally.3) Good understanding of various file formats like xml, delimited, fixed width etc.4) Understand the concepts of data quality, data cleansing, data profiling5) Good to have Python and other new data technologies and cloud exposure.6) Having Insurance background is a plus.\nEducational Qualification :15 years of fulltime education with BE/B Tech or equivalent\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Modeling Techniques and Methodologies.- Strong understanding of relational and non-relational database design principles.- Experience with data integration and ETL processes.- Familiarity with data governance and data quality frameworks.- Ability to translate business requirements into technical specifications.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sql', 'data architecture principles', 'data modeling', 'data warehousing concepts', 'sql joins', 'python', 'ms azure', 'sap', 'informatica powercenter', 'informatica data quality', 'data warehousing', 'erwin', 'data architecture', 'plsql', 'modeler', 'hana db', 'etl', 'sap hana', 'data integration']",2025-06-13 05:39:20
Data Modeler,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Data Modeler\n\n\n\n\n\nProject Role Description :Work with key business representatives, data owners, end users, application designers and data architects to model current and new data.\n\n\n\nMust have skills :Data Building Tool\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Modeler, you will engage with key business representatives, data owners, end users, application designers, and data architects to model both current and new data. Your typical day will involve collaborating with various stakeholders to understand their data needs, analyzing existing data structures, and designing effective data models that support business objectives. You will also be responsible for ensuring that the data models are aligned with best practices and organizational standards, facilitating smooth data integration and accessibility across different systems. This role requires a proactive approach to problem-solving and a commitment to delivering high-quality data solutions that enhance decision-making processes within the organization.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Facilitate training sessions and workshops to enhance team capabilities.- Continuously evaluate and improve data modeling processes to ensure efficiency.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Building Tool.- Strong understanding of data modeling techniques and methodologies.- Experience with data integration and ETL processes.- Familiarity with database management systems and SQL.- Ability to translate business requirements into technical specifications.\nAdditional Information:- The candidate should have minimum 7.5 years of experience in Data Building Tool.- This position is based in Mumbai.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'database management', 'data modeling', 'etl', 'data integration', 'python', 'oracle', 'data analysis', 'data warehousing', 'sme', 'data architecture', 'business intelligence', 'sql server', 'plsql', 'unix shell scripting', 'etl tool', 'modeler', 'informatica', 'unix', 'etl process']",2025-06-13 05:39:21
Data Modeler,Accenture,12 - 15 years,Not Disclosed,['Kolkata'],"Project Role :Data Modeler\n\n\n\n\n\nProject Role Description :Work with key business representatives, data owners, end users, application designers and data architects to model current and new data.\n\n\n\nMust have skills :Data Building Tool\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Modeler, you will engage with key business representatives, data owners, end users, application designers, and data architects to model both current and new data. Your typical day will involve collaborating with various stakeholders to understand their data needs, analyzing existing data structures, and designing effective data models that support business objectives. You will also be responsible for ensuring that the data models are aligned with best practices and organizational standards, facilitating smooth data integration and accessibility across different systems. This role requires a proactive approach to problem-solving and a commitment to delivering high-quality data solutions that enhance decision-making processes within the organization.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Expected to provide solutions to problems that apply across multiple teams.- Facilitate workshops and meetings to gather requirements and feedback from stakeholders.- Develop and maintain comprehensive documentation of data models and architecture.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Building Tool.- Strong understanding of data modeling techniques and methodologies.- Experience with data integration and ETL processes.- Familiarity with database management systems and SQL.- Ability to translate business requirements into technical specifications.\nAdditional Information:- The candidate should have minimum 12 years of experience in Data Building Tool.- This position is based at our Kolkata office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sql', 'database management', 'data modeling', 'etl', 'data integration', 'python', 'oracle', 'data analysis', 'data warehousing', 'sme', 'data architecture', 'business intelligence', 'sql server', 'plsql', 'unix shell scripting', 'etl tool', 'modeler', 'informatica', 'unix', 'etl process']",2025-06-13 05:39:23
Data Insights & Visualization Practition,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Project Role :Data Insights & Visualization Practition\n\n\n\n\n\nProject Role Description :Create interactive interfaces that enable humans to understand, interpret, and communicate complex data and insights. Wrangle, analyze, and prepare data to ensure delivery of relevant, consistent, timely, and actionable insights. Leverage modern business intelligence, storytelling, and web-based visualization tools to create interactive dashboards, reports and emerging VIS/BI artifacts. Use and customize (Gen)AI and AI-powered VIS/BI capabilities to enable a dialog with data.\n\n\n\nMust have skills :Data Analytics\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n2 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education:**Position\n\n\nSummary:**The Data Visualization Specialist will transform complex datasets into clear, actionable visualizations that support decision-making.**Key Responsibilities:**- Design and develop interactive dashboards and reports.- Collaborate with analysts and stakeholders to gather visualization requirements.- Ensure data visualizations are accurate, intuitive, and impactful.- Stay updated on best practices in data visualization.- Create visually compelling dashboards and reports to communicate insights.- Work closely with stakeholders to understand visualization requirements.- Ensure consistency in visual design and adherence to branding guidelines.- Optimize visualizations for performance and scalability.- Train end-users on interpreting and utilizing visual analytics tools.**\nQualifications:**- Bachelor's degree in Data Science, Computer Science, or a related field.- 3-5 years of experience in data visualization.- Proficiency in Power BI, Tableau, or similar tools.- Strong design sense and attention to detail.- Excellent communication and collaboration skills.\nAdditional Information:- The candidate should have minimum 2 years of experience in Data Analytics.- This position is based at our Hyderabad office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'power bi', 'business intelligence', 'tableau', 'data visualization', 'python', 'data analysis', 'bi', 'data warehousing', 'business analysis', 'business analytics', 'machine learning', 'dashboards', 'sql server', 'sql', 'r', 'data science', 'data modeling', 'advanced excel', 'etl', 'ssis']",2025-06-13 05:39:25
Data Governance Practitioner,Accenture,5 - 10 years,Not Disclosed,['Pune'],"Project Role :Data Governance Practitioner\n\n\n\n\n\nProject Role Description :Establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Collaborate with key stakeholders to define data standards, facilitate effective data collection, storage, access, and usage; and drive data stewardship initiatives for comprehensive and effective data governance.\n\n\n\nMust have skills :Collibra Data Governance\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Governance Practitioner, you will establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Collaborate with key stakeholders to define data standards, facilitate effective data collection, storage, access, and usage; and drive data stewardship initiatives for comprehensive and effective data governance.\nRoles & Responsibilities:- Expected to be an SME- Collaborate and manage the team to perform- Responsible for team decisions- Engage with multiple teams and contribute on key decisions- Provide solutions to problems for their immediate team and across multiple teams- Lead data governance initiatives within the organization- Develop and implement data governance policies and procedures- Ensure compliance with data governance standards and regulations\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Collibra Data Governance- Strong understanding of data governance principles- Experience in implementing data governance frameworks- Knowledge of data quality management- Familiarity with data privacy regulations\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Collibra Data Governance.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['data stewardship', 'data quality management', 'regulations', 'data governance', 'data privacy', 'python', 'data analysis', 'data analytics', 'data management', 'data warehousing', 'data collection', 'sql', 'data cleansing', 'data quality', 'tableau', 'data modeling', 'informatica', 'data profiling']",2025-06-13 05:39:27
Data Platform Engineer,Accenture,2 - 7 years,Not Disclosed,['Pune'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models. You will play a crucial role in the development and maintenance of the data platform components, contributing to the overall success of the project.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist with the data platform blueprint and design.- Collaborate with Integration Architects and Data Architects to ensure cohesive integration between systems and data models.- Develop and maintain data platform components.- Contribute to the overall success of the project.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.\nAdditional Information:- The candidate should have a minimum of 2 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'tableau', 'machine learning algorithms', 'statistics', 'data munging', 'python', 'data analysis', 'natural language processing', 'power bi', 'machine learning', 'sql', 'data quality', 'r', 'data modeling', 'data science', 'predictive modeling', 'text mining', 'logistic regression']",2025-06-13 05:39:29
Data Management Practitioner,Accenture,12 - 17 years,Not Disclosed,['Kolkata'],"Project Role :Data Management Practitioner\n\n\n\n\n\nProject Role Description :Maintain the quality and compliance of an organizations data assets. Design and implement data strategies, ensuring data integrity and enforcing governance policies. Establish protocols to handle data, safeguard sensitive information, and optimize data usage within the organization. Design and advise on data quality rules and set up effective data compliance policies.\n\n\n\nMust have skills :Data Architecture Principles\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :any graduate\n\n\nSummary:As a Data Management Practitioner, you will be responsible for maintaining the quality and compliance of an organization's data assets. Your role involves designing and implementing data strategies, ensuring data integrity, enforcing governance policies, and optimizing data usage within the organization.\nRoles & Responsibilities:- Expected to be an SME- Collaborate and manage the team to perform- Responsible for team decisions- Engage with multiple teams and contribute on key decisions- Design and advise on data quality rules- Set up effective data compliance policies- Ensure data integrity and enforce governance policies- Optimize data usage within the organization\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Architecture Principles- Strong understanding of data management best practices- Experience in designing and implementing data strategies- Knowledge of data governance and compliance policies- Ability to optimize data usage for organizational benefit\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Data Architecture Principles- This position is based at our Kolkata office- A degree in any graduate is required\n\nQualification\n\nany graduate",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data management', 'data architecture', 'sql', 'data architecture principles', 'hive', 'data analysis', 'oracle', 'data warehousing', 'machine learning', 'business intelligence', 'sql server', 'plsql', 'tableau', 'data science', 'data modeling', 'hadoop', 'sqoop', 'etl', 'etl development']",2025-06-13 05:39:31
Data Platform Engineer,Accenture,3 - 8 years,Not Disclosed,['Pune'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models. You will play a crucial role in the development and maintenance of the data platform components, contributing to the overall success of the project.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist with the data platform blueprint and design.- Collaborate with Integration Architects and Data Architects to ensure cohesive integration between systems and data models.- Develop and maintain data platform components.- Contribute to the overall success of the project.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'tableau', 'machine learning algorithms', 'statistics', 'data munging', 'python', 'data analysis', 'natural language processing', 'power bi', 'machine learning', 'sql', 'data quality', 'r', 'data modeling', 'data science', 'predictive modeling', 'text mining', 'logistic regression']",2025-06-13 05:39:32
"Level 2 Market Data Support Engineer (Windows, Linux, SQL, IM)",Synechron,3 - 7 years,Not Disclosed,['Pune'],"Job Summary\nSynechron is seeking a technically skilled and proactive Level 2 Market Data Support Engineer specializing in Market Data operations to join our dedicated back-office support team. This role is pivotal in maintaining the stability, security, and efficiency of our market data systems and related infrastructure. The ideal candidate will deliver advanced technical support, troubleshoot complex issues, and contribute to process improvements, ensuring seamless access and data accuracy in a highly regulated financial environment.\nThis position provides an opportunity to work with cross-functional teams, implement best practices, and support critical business functions. It requires a combination of technical expertise, analytical acumen, and effective communication skills to sustain the integrity of our market data platform and ensure high service standards.\nSoftware Requirements\nRequired Skills:\nProficiency with Windows Server management and troubleshooting (user accounts, system configuration)\nExperience managing and troubleshooting Unix/Linux environments\nStrong SQL skills for data retrieval, analysis, and troubleshooting (writing complex queries)\nHands-on experience with ITSM tools such as ServiceNow and JIRA for incident tracking\nFamiliarity with version control tools like Git for release and deployment management\nKnowledge of Batch Processing Systems to analyze historic system trends\nPreferred Skills:\nExposure to cloud platforms (AWS, Azure) is a plus\nKnowledge of monitoring tools and infrastructure automation techniques\nExperience with scripting languages such as PowerShell or Bash\nOverall Responsibilities\nProvide Level 2 support for market data systems, addressing incidents, service requests, and operational issues\nTroubleshoot and resolve technical issues related to Windows and Unix/Linux server environments, databases, and network/configuration discrepancies\nConduct root cause analysis to identify recurrence patterns and develop strategies for systemic resolution\nAssist with system upgrades, patches, and deployment procedures, ensuring minimal impact on business operations\nMonitor system health, review logs, and generate reports on system performance, data accuracy, and incident trends\nDocument procedures, incident resolutions, and system configurations to facilitate ongoing knowledge sharing\nCollaborate closely with cross-functional teams, including application support, infrastructure, and security teams to resolve technical problems effectively\nSupport incident progress tracking and facilitate resolution through ITSM tools\nWork in rotational shifts from 11:00 am IST to Midnight IST, ensuring 24/7 operational support\nStrategic objectives:\nEnsure high availability, data integrity, and security of market data systems\nEnhance incident response processes and reduce recurring issues\nDrive continuous process improvements and operational efficiencies\nPerformance outcomes:\nTimely resolution of incidents with minimal business impact\nAccurate documentation and effective communication with stakeholders\nSuccessful implementation of upgrades and systemic enhancements\nTechnical Skills (By Category)\nOperating Systems (Essential):\nWindows Server (administration, troubleshooting)\nUnix/Linux distributions (server management, scripting, troubleshooting)\nDatabases & Data Management (Essential):\nSQL query development and troubleshooting\nData integrity checks and analysis\nIncident & Change Management (Essential):\nUse of ServiceNow and JIRA platforms for incident management and tracking\nInfrastructure & Network (Essential):\nBasic understanding of networking and system configurations\nAbility to troubleshoot connectivity issues related to server and network\nScripting & Automation (Preferred):\nPowerShell, Bash scripting for routine automation and data analysis\nAdditional Skills (Preferred):\nMonitoring tools and dashboards (e.g., Nagios, LogicMonitor)\nCloud environments experience (AWS, Azure)\nExperience Requirements\n3 to 7 years of experience in market data support, IT operations, or application support roles within capital markets or financial sectors\nProven experience troubleshooting Windows and Unix/Linux server environments\nFamiliarity with database query formulation, analysis, and data reconciliation\nStrong incident management experience using ITSM tools (ServiceNow, JIRA)\nExperience supporting mission-critical financial systems is preferred\nAlternative pathways:\nCandidates with extensive technical support in related financial support roles demonstrating problem-solving and troubleshooting skills may be considered\nDay-to-Day Activities\nMonitor market data system logs and dashboards for anomalies\nTroubleshoot and resolve hardware, OS, database, and network issues\nAnalyze incident tickets, perform root cause analysis, and escalate as needed\nAssist in deploying patches, upgrades, and system changes with minimal disruption\nGenerate performance and incident trend reports\nMaintain detailed documentation, runbooks, and knowledge base articles\nCoordinate with infrastructure, application support, and security teams for issue resolution and process improvements\nSupport system audits, security compliance, and performance testing\nEngage in shift handovers, communicate incident status, and support team collaboration\nQualifications\nBachelor's degree in Computer Science, Information Technology, or related field; equivalent work experience accepted\nRelevant certifications such as ITIL Foundation, Certified Support Engineer, or industry-specific certifications are a plus\nWillingness to work rotational shifts from 11:00 am IST to Midnight IST\nDemonstrated technical expertise in Windows, Unix/Linux, databases, and incident management\nStrong analytical and troubleshooting skills with attention to detail\nEffective communicator capable of liaising with technical and non-technical stakeholders\nProfessional Competencies\nCritical thinking and advanced problem-solving capabilities\nExcellent verbal and written communication skills\nStakeholder-focused mindset with an emphasis on service quality\nStrong organizational skills for managing multiple incidents and tasks\nFlexibility and adaptability to changing priorities and shift schedules\nInitiative for continuous learning and process improvement\nCollaborative approach to team working and cross-departmental cooperation",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Market Data Support', 'Batch Processing Systems', 'ServiceNow', 'Git', 'Linux', 'Windows Server management', 'Unix/Linux', 'ITSM tools', 'Windows', 'Incident Management', 'SQL']",2025-06-13 05:39:34
"Specialist, Data Architecture",Fiserv,8 - 12 years,Not Disclosed,['Noida'],"Responsibilities\nRequisition ID R-10358179 Date posted 06/11/2025 End Date 07/15/2025 City Noida State/Region Uttar Pradesh Country India Location Type Onsite\nCalling all innovators find your future at Fiserv.\nJob Title\nSpecialist, Data Architecture\nWhat does a successful Lead, Data Conversions do\nA Conversion Lead is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible to provide data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Lead plays a critical role in mapping in data to support project initiatives for new and existing banks. Leads provide a specialized service to the Project Manager teams developing custom reporting, providing technical assistance, and ensuring project timelines are met.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nWhat you will do\nA Conversion Lead is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible to provide data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Lead plays a critical role in mapping in data to support project initiatives for new and existing banks/clients. Lead provides a specialized service to the Project Manager teams developing custom reporting, providing technical assistance, and ensuring project timelines are met.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nThe person stepping in as the backup would need to review the specifications history and then review and understand the code that was being developed to resolve the issue and or change. This would also have to occur on the switch back to the original developer.\nToday, the associate handling the project would log back in to support the effort and address the issue and or change.\nWhat you will need to have\nBachelor s degree in programming or related field\nWorking Hours (IST):\n12:00 p.m. 09:00 p.m. (IST)\nMonday through Friday\nHighest attention to detail and accuracy\nTeam player with ability to work independently\nAbility to manage and prioritize work queue across multiple workstreams\nStrong communication skills and ability to provide technical information to non-technical colleagues\nWhat would be great to have\nExperience with Data Modelling, Informatica, Power BI, MS Visual Basic, Microsoft Access and Microsoft Excel required.\nExperience with Card Management systems, debit card processing is a plus\nUnderstanding Applications and related database features that can be leveraged to improve performance\nExperience of creating testing artifacts (test cases, test plans) and knowledge of various testing types.\n8 12 years Experience and strong knowledge of MS SQL/PSQL, MS SSIS and Data warehousing concepts\nShould have strong database fundamentals and Expert knowledge in writing SQL commands, queries and stored procedures\nExperience in Performance Tuning of SQL complex queries.\nStrong communication skills and ability to provide technical information to non-technical colleagues.\nAbility to mentor junior team members\nAbility to manage and prioritize work queue across multiple workstreams.\nTeam player with ability to work independently.\nExperience in full software development life cycle using agile methodologies.\nShould have good understanding of Agile methodologies and can handle agile ceremonies.\nEfficient in Reviewing, Analyzing, coding, testing, and debugging of application programs.\nShould be able to work under pressure while resolving critical issues in Prod environment.\nGood communication skills and experience in working with Clients.\nGood understanding in Banking Domain.\nMinimum 8 years relevant experience in data processing (ETL) conversions or financial services industry\nThank you for considering employment with Fiserv. Please:\nApply using your legal name\nComplete the step-by-step profile and attach your resume (either is acceptable, both are preferable).\nOur commitment to Diversity and Inclusion:\nFiserv is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, gender, gender identity, sexual orientation, age, disability, protected veteran status, or any other category protected by law.\nNote to agencies:\nFiserv does not accept resume submissions from agencies outside of existing agreements. Please do not send resumes to Fiserv associates. Fiserv is not responsible for any fees associated with unsolicited resume submissions.\nWarning about fake job posts:\nPlease be aware of fraudulent job postings that are not affiliated with Fiserv. Fraudulent job postings may be used by cyber criminals to target your personally identifiable information and/or to steal money or financial information. Any communications from a Fiserv representative will come from a legitimate Fiserv email address.\n\n\n\nShare this Job\nEmail\nLinkedIn\nX\nFacebook",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'MS SQL', 'Visual Basic', 'Coding', 'Debugging', 'Agile', 'Informatica', 'Stored procedures', 'SSIS', 'SQL']",2025-06-13 05:39:36
Lead Data Engineer - Azure,Blend360 India,7 - 12 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Lead Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n7+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-13 05:39:38
"Specialist, Data Architecture",Fiserv,3 - 5 years,Not Disclosed,['Pune'],"A Conversion Professional is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible for providing data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Professional plays a critical role in mapping in data to support project initiatives for new and existing banks.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nWhat will you do\nA Conversion Professional is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible for providing data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Professional plays a critical role in mapping in data to support project initiatives for new and existing banks.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nThe person stepping in as the backup would need to review the specifications history and then review and understand the code that was being developed to resolve the issue and or change. This would also have to occur on the switch back to the original developer.\nToday, the associate handling the project would log back in to support the effort and address the issue and or change.\nWhat you will need to have\nBachelor s degree in programming or related field\nMinimum 3 years relevant experience in data processing (ETL) conversions or financial services industry\n3 5 years Experience and strong knowledge of MS SQL/PSQL, MS SSIS and data warehousing concepts\nStrong communication skills and ability to provide technical information to non-technical colleagues.\nTeam players with ability to work independently.\nExperience in full software development life cycle using agile methodologies.\nShould have good understanding of Agile methodologies and can handle agile ceremonies.\nEfficient in Reviewing, coding, testing, and debugging of application/Bank programs.\nShould be able to work under pressure while resolving critical issues in Prod environment.\nGood communication skills and experience in working with Clients.\nGood understanding in Banking Domain.\nWhat would be great to have\nExperience with Informatica, Power BI, MS Visual Basic, Microsoft Access and Microsoft Excel required.\nExperience with Card Management systems, debit card processing is a plus\nStrong communication skills and ability to provide technical information to non-technical colleagues\nAbility to manage and prioritize work queue across multiple workstreams\nTeam player with ability to work independently\nHighest attention to detail and accuracy\nThank you for considering employment with Fiserv. Please:\nApply using your legal name\nComplete the step-by-step profile and attach your resume (either is acceptable, both are preferable).\nOur commitment to Diversity and Inclusion:\nFiserv is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, gender, gender identity, sexual orientation, age, disability, protected veteran status, or any other category protected by law.\nNote to agencies:\nFiserv does not accept resume submissions from agencies outside of existing agreements. Please do not send resumes to Fiserv associates. Fiserv is not responsible for any fees associated with unsolicited resume submissions.\nWarning about fake job posts:\nPlease be aware of fraudulent job postings that are not affiliated with Fiserv. Fraudulent job postings may be used by cyber criminals to target your personally identifiable information and/or to steal money or financial information. Any communications from a Fiserv representative will come from a legitimate Fiserv email address.\n\n\n\nShare this Job\nEmail\nLinkedIn\nX\nFacebook",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MS SQL', 'Data analysis', 'Visual Basic', 'Coding', 'Debugging', 'Agile', 'Informatica', 'SSIS', 'Financial services', 'Data architecture']",2025-06-13 05:39:39
Azure Cloud Data Engineering Consultant,Optum,7 - 10 years,17-27.5 Lacs P.A.,['Gurugram'],"Primary Responsibilities:\nDesign and develop applications and services running on Azure, with a strong emphasis on Azure Databricks, ensuring optimal performance, scalability, and security.\nBuild and maintain data pipelines using Azure Databricks and other Azure data integration tools.\nWrite, read, and debug Spark, Scala, and Python code to process and analyze large datasets.\nWrite extensive query in SQL and Snowflake\nImplement security and access control measures and regularly audit Azure platform and infrastructure to ensure compliance.\nCreate, understand, and validate design and estimated effort for given module/task, and be able to justify it.\nPossess solid troubleshooting skills and perform troubleshooting of issues in different technologies and environments.\nImplement and adhere to best engineering practices like design, unit testing, functional testing automation, continuous integration, and delivery.\nMaintain code quality by writing clean, maintainable, and testable code.\nMonitor performance and optimize resources to ensure cost-effectiveness and high availability.\nDefine and document best practices and strategies regarding application deployment and infrastructure maintenance.\nProvide technical support and consultation for infrastructure questions.\nHelp develop, manage, and monitor continuous integration and delivery systems.\nTake accountability and ownership of features and teamwork.\nComply with the terms and conditions of the employment contract, company policies and procedures, and any directives.\nRequired Qualifications:\nB.Tech/MCA (Minimum 16 years of formal education)\nOverall 7+ years of experience.\nMinimum of 3 years of experience in Azure (ADF), Databricks and DevOps.\n5 years of experience in writing advanced level SQL.\n2-3 years of experience in writing, reading, and debugging Spark, Scala, and Python code.\n3 or more years of experience in architecting, designing, developing, and implementing cloud solutions on Azure.\nProficiency in programming languages and scripting tools.\nUnderstanding of cloud data storage and database technologies such as SQL and NoSQL.\nProven ability to collaborate with multidisciplinary teams of business analysts, developers, data scientists, and subject-matter experts.\nFamiliarity with DevOps practices and tools, such as continuous integration and continuous deployment (CI/CD) and Teraform.\nProven proactive approach to spotting problems, areas for improvement, and performance bottlenecks.\nProven excellent communication, writing, and presentation skills.\nExperience in interacting with international customers to gather requirements and convert them into solutions using relevant skills.\nPreferred Qualifications:\nKnowledge of AI/ML or LLM (GenAI).\nKnowledge of US Healthcare domain and experience with healthcare data.\nExperience and skills with Snowflake.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Azure Databricks', 'ETL', 'SQL', 'Python', 'Airflow', 'Pyspark', 'Snowflake', 'SCALA', 'Spark', 'Data Bricks']",2025-06-13 05:39:41
Manager Data Science,Optum,12 - 17 years,Not Disclosed,['Noida'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together. \n\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.\n\n \n\n",,,,"['python', 'pyspark', 'machine learning', 'artificial intelligence', 'r', 'continuous integration', 'data analysis', 'scala', 'scikit-learn', 'presentation skills', 'ci/cd', 'microsoft azure', 'docker', 'tensorflow', 'data science', 'ai techniques', 'devops', 'pytorch', 'keras', 'software engineering', 'aws']",2025-06-13 05:39:43
Lead Data Engineer - Azure,Blend360 India,7 - 12 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Sr Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n7+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-13 05:39:45
Data & Analytics Specialist,Roche Diagnostics,5 - 10 years,Not Disclosed,['Pune'],"At Roche you can show up as yourself, embraced for the unique qualities you bring. Our culture encourages personal expression, open dialogue, and genuine connections, where you are valued, accepted and respected for who you are, allowing you to thrive both personally and professionally. This is how we aim to prevent, stop and cure diseases and ensure everyone has access to healthcare today and for generations to come. Join Roche, where every voice matters.\nThe Position The Position\nWe are looking for a Data & Analytics Specialist/ Business Analyst who will join us in the newly setup Integrated Informatics for a journey to drive transformation with data and foster automated and efficient decision making throughout the organisation\nThe Data and Analytics Specialist must be the big-picture thinker who understands the value of data to the organisation, has a strong focus on delivering high value, connecting the dots, investing in right initiatives with reusability at the heart of it.\nIn this position you will be acting as squad lead, have end to end ownership of Product delivery with setting up teams from multiple teams/areas with focus on Lifecycle management of the product\nResponsibilities\nYou will work on various aspects of Analytics Solution Development, Data Management, Governance and Information Architecture including but not limited to:\nCollaborate with business stakeholders to understand their data and analytics needs and develop a product roadmap that aligns with business goals.\nDefine and prioritise product requirements, user stories, and acceptance criteria for data and analytics products and ensure what was agreed gets delivered.\nWork with data engineers and data scientists to develop data pipelines, analytical models, and visualisations that meet business requirements.\nCollaborate with Infrastructure Teams and software developers to ensure that data and analytics products are integrated into existing systems and platforms in a sustainable way that still meets the needs of business to generate the insights necessary to drive their decisions.\nMonitor data and analytics product performance and identify opportunities for improvement.\nStay up-to-date with industry trends and emerging technologies related to data and analytics in the pharmaceutical industry.\nAct as a subject matter expert for data and analytics products and provide guidance to business stakeholders on how to effectively use these products.\nAccountable to Develop and maintain documentation, training materials, and user guides for data and analytics products.\nThe ideal candidate\nBachelors or Masters degree in computer science, information systems, or a related field.\n5+ years of experience in roles such as Senior Data & Analytics Specialist, Data Solutions Lead, Data Architect, or Data Consultant, with a focus on solution design and implementation. Alternatively, 3-4 years of experience in data streams (e.g., Data Science, Data Engineering, Data Governance) combined with a couple of years in Strategic Data Consultancy / Data Product Ownership. Experience in the pharmaceutical or healthcare industry is highly desirable.\nHigh Level understanding of data engineering, data science, Data governance and analytics concepts and technologies.\nExperience working with cross-functional teams, including data engineers, data scientists, and software developers.\nExcellent communication and interpersonal skills.\nStrong analytical and problem-solving skills.\nExperience with agile development methodologies.\nKnowledge of regulatory requirements related to data and analytics in the pharmaceutical industry.\nKnowledge of working with vendor and customer master data for different divisions - Pharmaceuticals, Diagnostic, & Diabetes care.\nUnderstanding of the transparency reporting landscape.\nHands-on experience of working on applications such as Jira, SQL, Postman, SAP GUI, Monday.com, Trello\nProficient in the knowledge of different CRM/Master Data Management systems such as SFDC, Reltio MDM\nUnderstanding data protection laws and consent processes applicable to healthcare professionals and organizations before transparency disclosure.\nWho we are\nAt Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we ve become one of the world s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\nBasel is the headquarters of the Roche Group and one of its most important centres of pharmaceutical research. Over 10,700 employees from over 100 countries come together at our Basel/Kaiseraugst site, which is one of Roche`s largest sites. Read more.\nBesides extensive development and training opportunities, we offer flexible working options, 18 weeks of maternity leave and 10 weeks of gender independent partnership leave. Our employees also benefit from multiple services on site such as child-care facilities, medical services, restaurants and cafeterias, as well as various employee events.\nWe believe in the power of diversity and inclusion, and strive to identify and create opportunities that enable all people to bring their unique selves to Roche.\nRoche is an Equal Opportunity Employer.\nWho we are\n.\n\nLet s build a healthier future, together.\nRoche is an Equal Opportunity Employer.\n""",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAP', 'Diagnostics', 'HP data protector', 'Analytical', 'Healthcare', 'JIRA', 'Analytics', 'SQL', 'CRM']",2025-06-13 05:39:47
Data & Analytics Specialist,Hoffmann La Roche,5 - 10 years,Not Disclosed,['Pune'],"At Roche you can show up as yourself, embraced for the unique qualities you bring. Our culture encourages personal expression, open dialogue, and genuine connections, where you are valued, accepted and respected for who you are, allowing you to thrive both personally and professionally. This is how we aim to prevent, stop and cure diseases and ensure everyone has access to healthcare today and for generations to come. Join Roche, where every voice matters.\nThe Position The Position\nWe are looking for a Data & Analytics Specialist/ Business Analyst who will join us in the newly setup Integrated Informatics for a journey to drive transformation with data and foster automated and efficient decision making throughout the organisation\nThe Data and Analytics Specialist must be the big-picture thinker who understands the value of data to the organisation, has a strong focus on delivering high value, connecting the dots, investing in right initiatives with reusability at the heart of it.\nIn this position you will be acting as squad lead, have end to end ownership of Product delivery with setting up teams from multiple teams/areas with focus on Lifecycle management of the product\nResponsibilities\nYou will work on various aspects of Analytics Solution Development, Data Management, Governance and Information Architecture including but not limited to:\nCollaborate with business stakeholders to understand their data and analytics needs and develop a product roadmap that aligns with business goals.\nDefine and prioritise product requirements, user stories, and acceptance criteria for data and analytics products and ensure what was agreed gets delivered.\nWork with data engineers and data scientists to develop data pipelines, analytical models, and visualisations that meet business requirements.\nCollaborate with Infrastructure Teams and software developers to ensure that data and analytics products are integrated into existing systems and platforms in a sustainable way that still meets the needs of business to generate the insights necessary to drive their decisions.\nMonitor data and analytics product performance and identify opportunities for improvement.\nStay up-to-date with industry trends and emerging technologies related to data and analytics in the pharmaceutical industry.\nAct as a subject matter expert for data and analytics products and provide guidance to business stakeholders on how to effectively use these products.\nAccountable to Develop and maintain documentation, training materials, and user guides for data and analytics products.\nThe ideal candidate\nBachelors or Masters degree in computer science, information systems, or a related field.\n5+ years of experience in roles such as Senior Data & Analytics Specialist, Data Solutions Lead, Data Architect, or Data Consultant, with a focus on solution design and implementation. Alternatively, 3-4 years of experience in data streams (e.g., Data Science, Data Engineering, Data Governance) combined with a couple of years in Strategic Data Consultancy / Data Product Ownership. Experience in the pharmaceutical or healthcare industry is highly desirable.\nHigh Level understanding of data engineering, data science, Data governance and analytics concepts and technologies.\nExperience working with cross-functional teams, including data engineers, data scientists, and software developers.\nExcellent communication and interpersonal skills.\nStrong analytical and problem-solving skills.\nExperience with agile development methodologies.\nKnowledge of regulatory requirements related to data and analytics in the pharmaceutical industry.\nKnowledge of working with vendor and customer master data for different divisions - Pharmaceuticals, Diagnostic, & Diabetes care.\nUnderstanding of the transparency reporting landscape.\nHands-on experience of working on applications such as Jira, SQL, Postman, SAP GUI, Monday.com, Trello\nProficient in the knowledge of different CRM/Master Data Management systems such as SFDC, Reltio MDM\nUnderstanding data protection laws and consent processes applicable to healthcare professionals and organizations before transparency disclosure.\nWho we are\n.\nBasel is the headquarters of the Roche Group and one of its most important centres of pharmaceutical research. Over 10,700 employees from over 100 countries come together at our Basel/Kaiseraugst site, which is one of Roche`s largest sites. Read more.\nBesides extensive development and training opportunities, we offer flexible working options, 18 weeks of maternity leave and 10 weeks of gender independent partnership leave. Our employees also benefit from multiple services on site such as child-care facilities, medical services, restaurants and cafeterias, as well as various employee events.\nWe believe in the power of diversity and inclusion, and strive to identify and create opportunities that enable all people to bring their unique selves to Roche.\nRoche is an Equal Opportunity Employer.\nWho we are\nA healthier future drives us to innovate. Together, more than 100 000 employees across the globe are dedicated to advance science, ensuring everyone has access to healthcare today and for generations to come. Our efforts result in more than 26 million people treated with our medicines and over 30 billion tests conducted using our Diagnostics products. We empower each other to explore new possibilities, foster creativity, and keep our ambitions high, so we can deliver life-changing healthcare solutions that make a global impact.\n\nLet s build a healthier future, together.\nRoche is an Equal Opportunity Employer.\n""",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAP', 'Diagnostics', 'HP data protector', 'Analytical', 'Healthcare', 'JIRA', 'Analytics', 'SQL', 'CRM']",2025-06-13 05:39:49
Data Engineer,AMERICAN EXPRESS,2 - 4 years,13-17 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Role & responsibilities\nUnderstanding business use cases and be able to convert to technical design\nPart of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners.\nYou will be designing scalable, testable and maintainable data pipelines\nIdentify areas for data governance improvements and help to resolve data quality problems through the appropriate choice of error detection and correction, process control and improvement, or process design changes",,,,"['Spark', 'SQL', 'Python', 'Hadoop', 'Big Data']",2025-06-13 05:39:50
"Associate Analyst, R Programmer-1",Mastercard,1 - 4 years,Not Disclosed,['Gurugram'],"We are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology.\nAn individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (eg Plotly, Highcharts, D3.js) or front-end frameworks (eg React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, we'll-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (eg roxygen2)\nfamiliar with version control concepts and tools (eg Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-13 05:39:52
"Associate Analyst, R Programmer-1",Dynamic Yield,1 - 4 years,Not Disclosed,['Gurugram'],"Our Purpose\nTitle and Summary\nAssociate Analyst, R Programmer-1\nOverview\nThe Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (e.g. Plotly, Highcharts, D3.js) or front-end frameworks (e.g. React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, well-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (e.g. roxygen2)\nfamiliar with version control concepts and tools (e.g. Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Software Product,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-13 05:39:54
Principal Machine Learning Engineer,Paypal,0 - 7 years,Not Disclosed,['Bengaluru'],"The Company\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\nOur beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do - and they push us to ensure we take care of ourselves, each other, and our communities.\nJob Summary:\nWhat you need to know about the role\n\nThis job will drive the strategic vision and development of cutting-edge machine learning models and algorithms to solve complex problems. You will work closely with data scientists, software engineers, and product teams to enhance services through innovative AI/ML solutions. Your role will involve building scalable ML pipelines, ensuring data quality, and deploying models into production environments to drive business insights and improve customer experiences.\n\nYour Way to Impact\n\nAs a Principal Machine Learning Engineer, you ll lead mission-critical initiatives that define PayPal s AI edge from large-scale model fine-tuning to the architecture of foundational AI systems. Your leadership will enable AI-native capabilities across personalization, fraud detection, customer experience, and internal productivity. You will shape how PayPal delivers trust, speed, and intelligence in every user interaction.\n\nMeet Our Team\nYou ll work within the core Applied Intelligence team, a cross-functional hub driving AI-first innovation across PayPal s product and platform landscape. Your team s work powers smarter workflows and more seamless experiences for our global customer base. This is a hands-on leadership role where you ll help align strategy, technology, and business outcomes.\nJob Description:\nYour Day to Day\nDefine and drive strategic vision for model development and ML applications across business domains.\nLead architecture and experimentation for foundational model pipelines.\nManage end-to-end lifecycle from data prep and training to deployment and monitoring.\nCollaborate with product, infra, and engineering leaders to ship impactful solutions.\nGuide model evaluation frameworks, bias detection, and performance monitoring practices.\nMentor technical leads and contribute to thought leadership internally and externally.\nWhat You Need to Bring\nMinimum of 15 years of relevant experience with a Bachelor s degree or equivalent.\nDeep expertise in building and fine-tuning advanced ML models at scale.\nStrong experience with cloud-native ML solutions (e.g., SageMaker, Vertex AI).\nProven success in leading multi-functional ML projects from research to production.\nStrong communication and strategic planning abilities to align tech with business.\nPreferred Qualification:\nSubsidiary:\nPayPal\nTravel Percent:\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits:\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com .\nWho We Are:\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talentaccommodations@paypal.com .\nBelonging at PayPal:\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: FinTech / Payments,Department: Other,"Employment Type: Full Time, Permanent","['Architecture', 'User interaction', 'Diversity and Inclusion', 'Machine learning', 'Strategic planning', 'Manager Technology', 'Wellness', 'Data quality', 'Customer experience', 'Fraud detection']",2025-06-13 05:39:56
It Recruiter,IonIdea,0 - 3 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nTalent Sourcing: Utilize various channels such as job boards, social media, LinkedIn, networking events, and internal databases to source and attract high-quality candidates for a variety of technical positions (software developers, systems engineers, data scientists, etc.).\nCandidate Screening: Review resumes, conduct initial phone screenings, and assess candidates technical skills, experience, and cultural fit.\nInterview Coordination: Schedule and facilitate interviews with hiring managers, ensuring a smooth and efficient process for all parties involved.\nCandidate Engagement: Build relationships with both active and passive candidates to maintain a strong pipeline of qualified talent. Keep candidates informed throughout the hiring process.\nOffer Management: Work with HR and hiring managers to present offers, negotiate terms, and ensure a positive candidate experience during the offer process.\n\nQualifications:\nExperience: Fresher-3years\n\nTechnical Knowledge: A solid understanding of IT roles, including knowledge of programming languages, software development frameworks, network infrastructure, cloud technologies, and emerging IT trends.\nRecruitment Tools: Proficient in using Applicant Tracking Systems (ATS), job boards (e.g., LinkedIn, Indeed), and social media platforms for sourcing candidates.\nCommunication Skills: Excellent written and verbal communication skills with the ability to engage with both technical and non-technical stakeholders.",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['IT Recruitment', 'C2H', 'Contract Hiring']",2025-06-13 05:39:57
"Data Scientist,VP",NatWest Markets,10 - 12 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Join us as a Data Scientist\nIn this role, you ll drive and embed the design and implementation of data science tools and methods, which harness our data to drive market-leading purpose customer solutions\nDay-to-day, you ll act as a subject matter expert and articulate advanced data and analytics opportunities, bringing them to life through data visualisation\nIf you re ready for a new challenge, and are interested in identifying opportunities to support external customers by using your data science expertise, this could be the role for you\nWere offering this role at vice president level\nWhat you ll do\nWe re looking for someone to understand the requirements and needs of our business stakeholders. You ll develop good relationships with them, form hypotheses, and identify suitable data and analytics solutions to meet their needs and to achieve our business strategy.\nYou ll be maintaining and developing external curiosity around new and emerging trends within data science, keeping up to date with emerging trends and tooling and sharing updates within and outside of the team.\nYou ll also be responsible for:\nProactively bringing together statistical, mathematical, machine-learning and software engineering skills to consider multiple solutions, techniques, and algorithms\nImplementing ethically sound models end-to-end and applying software engineering and a product development lens to complex business problems\nWorking with and leading both direct reports and wider teams in an Agile way within multi-disciplinary data to achieve agreed project and Scrum outcomes\nUsing your data translation skills to work closely with business stakeholders to define business questions, problems or opportunities that can be supported through advanced analytics\nSelecting, building, training, and testing complex machine models, considering model valuation, model risk, governance, and ethics throughout to implement and scale models\nThe skills you ll need\nTo be successful in this role, you ll need evidence of project implementation and work experience gained in a data-analysis-related field as part of a multi-disciplinary team. We ll also expect you to hold an undergraduate or a master s degree in Data science, Statistics, Computer science, or related field .\nYou ll also need an experience of 10 years with statistical software, database languages, big data technologies, cloud environments and machine learning on large data sets. And we ll look to you to bring the ability to demonstrate leadership, self-direction and a willingness to both teach others and learn new techniques.\nAdditionally, you ll need:\nExperience of deploying machine learning models into a production environment\nProficiency in Python and relevant libraries such as Pandas, NumPy, Scikit-learn coupled with experience in data visualisation tools.\nExtensive work experience with AWS Sage maker , including expertise in statistical data analysis, machine learning models, LLMs, and data management principles\nEffective verbal and written communication skills , the ability to adapt communication style to a specific audience and mentoring junior team members",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'data science', 'Data management', 'Machine learning', 'Agile', 'Scrum', 'SAGE', 'Business strategy', 'Python']",2025-06-13 05:39:59
Data Scientist,HMG Technology,3 - 8 years,10-20 Lacs P.A.,['Bengaluru( Banaswadi )'],"Job Title: AI/ML Engineer (with LLM, Azure, Python & PySpark expertise)\nJob Description:\nWe are looking for a skilled and experienced AI/ML Engineer to join our data science and AI team. The ideal candidate will have a strong foundation in machine learning, artificial intelligence, and large language models (LLMs), along with deep proficiency in Python, PySpark, and Microsoft Azure services. You will be responsible for developing and deploying scalable AI solutions, working with big data frameworks, and leveraging cloud platforms to operationalize machine learning models.\nKey Responsibilities:\nArtificial Intelligence (AI) & Machine Learning (ML):\nDesign, develop, and optimize machine learning and AI models to solve business problems.\nPerform exploratory data analysis and feature engineering for model development.\nUse supervised, unsupervised, and reinforcement learning techniques where appropriate.\nBuild AI pipelines and integrate models into production systems.\nLarge Language Models (LLM):\nFine-tune and deploy LLMs (e.g., OpenAI, Hugging Face, or custom-trained models).\nDevelop prompt engineering strategies for LLM applications.\nImplement RAG (Retrieval-Augmented Generation) systems or LLMOps workflows.\nEvaluate LLM outputs for accuracy, bias, and performance.\nPython Programming:\nWrite efficient, reusable, and testable Python code for data processing, modeling, and API services.\nBuild automation scripts for data pipelines and model training workflows.\nUse popular libraries such as Scikit-learn, TensorFlow, PyTorch, Pandas, and NumPy.\nPySpark and Big Data:\nWork with large datasets using PySpark for data wrangling, transformation, and feature extraction.\nOptimize Spark jobs for performance and scalability.\nCollaborate with data engineering teams to implement end-to-end data pipelines.\nMicrosoft Azure:\nDeploy models and applications using Azure ML, Azure Databricks, Azure Functions, and Azure Synapse.\nManage compute resources, storage, and data security on Azure.\nUse Azure DevOps for CI/CD of ML pipelines and automation.\nCross-Functional Collaboration & Documentation:\nCollaborate with data engineers, product managers, and business stakeholders to align technical solutions with business needs.\nMaintain clear documentation of models, code, and workflows.\nPresent technical findings and model outcomes to both technical and non-technical audiences.\nRequired Skills & Qualifications:\nBachelor's or Masters degree in Computer Science, Data Science, Engineering, or a related field.\n3+ years of experience in AI/ML and data engineering roles.\nProficient in Python and PySpark.\nExperience with cloud platforms, especially Microsoft Azure.\nHands-on experience with LLMs (e.g., GPT, BERT, Claude, etc.).\nFamiliarity with ML frameworks like Scikit-learn, TensorFlow, or PyTorch.\nSolid understanding of ML lifecycle, MLOps, and deployment strategies.\nNice to Have:\nExperience with LLMOps and vector databases (e.g., FAISS, Pinecone).\nKnowledge of data governance and responsible AI practices.\nAzure certifications (e.g., Azure AI Engineer Associate, Azure Data Scientist Associate).\nExperience with REST APIs and containerization (Docker, Kubernetes).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Large Language Model', 'Azure Cloud', 'Artificial Intelligence', 'Machine Learning', 'Pyspark', 'Deep Learning', 'Python']",2025-06-13 05:40:01
"Associate Scientist, Data Sourcing & Solutions",XL India Business Services Pvt. Ltd,1 - 5 years,Not Disclosed,"['Hyderabad', 'Ahmedabad', 'Bengaluru']","Associate Scientist - Data Sourcing & Solutions Gurgaon/Bangalore, India AXA XL recognises data and information as critical business assets, both in terms of managing risk and enabling new business opportunities\n\nThis data should not only be high quality, but also actionable - enabling AXA XLs executive leadership team to maximise benefits and facilitate sustained enterprise advantage\n\nOur Innovation, Data, and Analytics Office (IDA) is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market\n\nAs we develop an enterprise-wide data and digital strategy that moves us toward a greater focus on the use of data and data-driven insights, we are seeking an Associate Scientist for our Data Sourcing & Solutions team\n\nThe role sits across the IDA Department to make sure customer requirements are properly captured and transformed into actionable data specifications\n\nSuccess in the role will require a focus on proactive management of the sourcing and management of data from source through usage\n\nWhat you ll be DOING What will your essential responsibilities include? Accountable for documenting data requirements (Business and Function Requirements) and assessing the reusability of Axiom assets\n\nBuild processes to simplify and expedite data sourcing to focus on delivering data to AXA XL business stakeholders frequently\n\nDevelops and operationalizes strategic data products, and answers and proactively manages the sourcing and management of data from source through usage (reusable Policy and Claim Domain data assets)\n\nData Validation Testing of the data products in partnership with the AXA XL business to ensure the accuracy of the data and validation of the requirements\n\nAssesses all data required as part of the Data Ecosystem to make sure data has a single version of the truth\n\nRespond to ad-hoc data requests to support AXA XLs business\n\nInstill a customer-first attitude, prioritizing service for our business stakeholders above all else\n\nInternalize and execute IDA and company-wide goals to become a data-driven organization\n\nContribute to best practices and standards to make sure there is a consistent and efficient approach to capturing business requirements and translating them into functional, non-functional, and semantic specifications\n\nDevelop a comprehensive understanding of the data and our customers\n\nDrive root cause analysis for identified data deficiencies within reusable data assets delivered via IDA\n\nIdentify solution options to improve the consistency, accuracy, and quality of data when captured at its source\n\nYou will report to the Team Lead - Data Sourcing & Solutions\n\nWhat you will BRING We re looking for someone who has these abilities and skills: Required Skills and Abilities: Experience in a data role (business analyst, data analyst, analytics) preferably in the Insurance industry and within a data division\n\nA minimum of a bachelor s or masters degree (preferred) in a relevant discipline\n\nRobust SQL knowledge and technical ability to query AXA XL data sources to understand our data\n\nExcellent presentation, communication (oral & written), and relationship-building skills, across all levels of management and customer interaction\n\nInsurance experience in data, underwriting, claims, and/or operations, including influencing, collaborating, and leading efforts in complex, disparate, and interrelated teams with competing priorities\n\nPassion for data and experience working within a data-driven organization\n\nWork together internal data with external industry data to deliver holistic answers\n\nWork with unstructured data to unlock information needed by the business to create unique products for the insurance industry\n\nPossesses robust exploratory analysis skills and high intellectual curiosity\n\nDisplays exceptional organizational skills and is detail-oriented\n\nThe robust conceptual thinker who connects dots, and has critical thinking, and analytical skills\n\nDesired Skills and Abilities: Ability to work with team members across the globe and departments\n\nAbility to take ownership, work under pressure, and meet deadlines\n\nBuilds trust and rapport within and across groups\n\nApplies in-depth knowledge of business and specialized areas to solve business problems and understand integration challenges and long-term impact creatively and strategically\n\nAbility to manage data needs of an individual project(s) while being able to understand the broader enterprise data perspective\n\nExpected to recommend innovation and improvement to policies, and procedures, deploying resources, and performing core activities\n\nExperience with SQL Server, Azure Databricks Notebook, Qlikview, PowerBI, and Jira/Confluence a plus",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data validation', 'Claims', 'Underwriting', 'Agile', 'QlikView', 'Business strategy', 'JIRA', 'Analytics', 'SQL', 'Customer interaction']",2025-06-13 05:40:03
Data Scientist,Puresoftware Technology,8 - 13 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Title: Data Scientist(5 Positions)/ Lead OR Manager -Data Scientist (3 positions)\n\nExperience: Data scientist (8-10 years) / Lead Data scientist(14+ years)\n\nJob Location: Whitefield, Bangalore\nMode of working: Hybrid\n\nInterview Process: First Round: L1-Internal interview\nSecond Round: Assessment shared by us needs to be completed in 48 hours\nThird Round: Client discussion over the submitted assessment.\nFinal Round: HR Discussion\n\nPreferred Domain: Healthcare Insurance/ Insurance agencies / Health Insurance / Any Insurance\n\nWe are looking for a talented Data Scientist to join our growing team. In this role, you will lead efforts to develop, enhance, and optimize advanced AI and machine learning models with a particular focus on Generative AI, Large Language Models (LLMs), Langchain, and Prompt Engineering. You will oversee the application of statistical modeling techniques to derive insights, build models, and lead research initiatives that push the boundaries of AI technologies.\n\nKey Responsibilities:\nLeadership & Collaboration: Lead a team of data scientists, researchers, and engineers working on high-impact projects related to generative models, NLP, and statistical modeling. Collaborate with cross-functional teams, including engineering, product management, and research, to deliver AI-powered products and solutions.\nGenerative AI Development: Spearhead the development and deployment of Generative AI models and algorithms to address complex problems in areas like content generation, conversational AI, and creative automation.\nLLM Implementation & Optimization: Develop, fine-tune, and optimize large language models (LLMs) for diverse applications, ensuring they are robust, scalable, and accurate in real-world scenarios.\nLangchain Integration: Design and integrate Langchain for managing and deploying sophisticated language models with a focus on complex workflows, multi-agent systems, and real-time applications.\nPrompt Engineering: Lead prompt engineering efforts to optimize AI models' output quality, improve interactions, and enable more effective natural language understanding across a variety of use cases.\nStatistical Modeling: Utilize advanced statistical techniques to analyze and interpret data, build predictive models, and solve business-critical challenges through data-driven insights.\nResearch & Innovation: Stay ahead of trends in AI and ML, particularly in the fields of NLP, LLMs, and generative models. Drive innovation by exploring cutting-edge techniques and methodologies in the AI space.\nMentorship & Knowledge Sharing: Mentor junior team members and promote a collaborative, learning-oriented environment. Share knowledge and foster an atmosphere of continuous improvement within the data science team.\nPerformance Optimization: Ensure model performance meets or exceeds company and client expectations by identifying areas of improvement, testing new methods, and scaling the systems accordingly.\nEthical AI Development: Advocate for and implement ethical considerations in the development and deployment of AI models, including fairness, transparency, and privacy.\n\nQualifications:\nRequired:\nEducation: Ph.D. or Masters degree in Computer Science, Data Science, Mathematics, Statistics, or related field, or equivalent practical experience.\nExperience:\n8+ years of experience in data science, with at least 2-3 years in a leadership role.\nProven expertise in Generative AI, particularly in areas like content generation, deep learning, and language modeling.\nStrong background in Large Language Models (LLMs) such as GPT, T5, BERT, or similar architectures.\nHands-on experience with Langchain for building NLP workflows, pipelines, and integrating external systems with LLMs.\nHands-on experience of Prompt Engineering, including techniques to refine and optimize outputs for various NLP tasks.\nExpertise in statistical modeling and quantitative analysis, with the ability to apply techniques to solve real-world problems.\n\nPreferred:\nExperience working with transformer models and fine-tuning LLMs for specific tasks.\nExpertise in AI model evaluation and metrics (e.g., BLEU, ROUGE, perplexity).\nBackground in developing AI-driven products from concept to deployment.\nStrong publication record in AI research, particularly in NLP and machine learning.\n\nUsed cases( Any of them)\nAutomated Underwriting.\nCustomer experience enhancement.\nFraud detection.\nPredictive analytics.\nAccelerated claims processing.\nRisk assessment and premium calculation.\nCustomer profiling.\ncustomer segmentation.\nCredit Risk Assessment.\nPersonalised marketing .\nAnti-Money Laundering (AML).\nPersonalized patient care.\nMedical training and simulations.\nMedical Data Analysis.\n\nPlease share your updated resume at renuka.rathi@puresoftware.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'data scientist', 'statistical modelling', 'Predictive Modeling', 'Customer profiling', 'Healthcare Insurance', 'Customer Segmentation', 'Automated Underwriting', 'Insurance Domain', 'Credit Risk Assessment', 'insurance agency', 'Fraud detection', 'Healthcare Domain']",2025-06-13 05:40:04
Lead Data Scientist,Grab,8 - 13 years,Not Disclosed,['Bengaluru'],"Get to know the team\nGrabFin is an aggregate of FinTech businesses spread across 6 countries in S.E. Asia, in the Lending, Payments and Insurance domains. We are excited to provide innovative financial services to all participants of the Grab Ecosystem be it our Drivers, Consumers or Merchants. Our products are built on fundamental market insights combined with data science and engineering to bring the best product market fit across the cross section of our user base. This understanding of our ecosystem combined with world class engineering execution continues to create tremendous value for our customers.\nThe data scientist will work in a relatively flat team structure with an independent goal of building and manage critical data science models daily. You can expect to solve hard technical problems and grow into an expert on both batch and real-time Data Science use cases. You will have experience with technology and data science.\nYou will be reporting to Senior Manager, Data Science.\nThis role is onsite based in Bangalore.\nYoull develop credit risk scoring models for consumer loans, including PD, LGD, and collection models. Youll work with alternative data sources to boost model signal and accuracy. Your role will involve full ownership of the end-to-end model lifecycle from building and validation to deployment and maintenance. Youll collaborate with business, risk, and operations teams to shape solutions and influence product strategy with your insights. This is an individual contributor role suited for professionals with 8+ years of experience.\nThe Critical Tasks You Will Perform\nBuild predictive models using a mix of machine learning and traditional analytics methods to segregate between Good vs Bad borrowers\nBuild Machine learning & Deep learning models to estimate losses from of a given portfolio.\nValidate models on new datasets, based on in-market performance.\nEngineer predictive features from internal data assets to build refined customer profiles. Identify external data assets to bring into the model mix.\nDrive model governance by collaborating with risk policy, compliance, and audit teams to ensure adherence to regulatory expectations.\nIdentify model gaps or performance drifts and lead model refresh cycles.\nPresent findings to senior leadership with clear articulation of risk trade-offs and growth.\nTranslate model insights into strategic recommendations (e.g., policy changes, pricing levers, customer targeting strategies).\nSolve previously unsolved analytics problems using best in class data analytics and machine learning methodologies.\nRead more\nSkills you need\nThe Essential Skills You Need\n8+ years of experience.\nStrong understanding of credit business - lifecycle of a loan, collections process, and credit KPIs like NPL, ECL.\nExpert in building machine learning and predictive models in Python and Spark is an absolute must.\nSQL, Presto, Hive proficiency.\nSound knowledge of machine learning concepts. Illustrative machine learning concepts/methods are: Bagging, Boosting, Regularisation, Online Learning, Recommendation Engines\nExperience with LLMs, and Generative AI\nExperience with model deployment pipelines - using MLFlow, Airflow, or other MLOps tools.\nDemonstrated experience building machine learning models\nUnderstand the trade-offs between model performance and our needs.\nStrong problem-solving mindset is critical for success in this role.\nRead more\nWhat we offer\nAbout Grab and Our Workplace\nGrab is Southeast Asias leading superapp. From getting your favourite meals delivered to helping you manage your finances and getting around town hassle-free, weve got your back with everything. In Grab, purpose gives us joy and habits build excellence, while harnessing the power of Technology and AI to deliver the mission of driving Southeast Asia forward by economically empowering everyone, with heart, hunger, honour, and humility.\nRead more\nLife at Grab\nLife at Grab\nWe care about your well-being at Grab, here are some of the global benefits we offer:\nWe have your back with Term Life Insurance and comprehensive Medical Insurance.\nWith GrabFlex, create a benefits package that suits your needs and aspirations.\nCelebrate moments that matter in life with loved ones through Parental and Birthday leave, and give back to your communities through Love-all-Serve-all (LASA) volunteering leave\nWe have a confidential Grabber Assistance Programme to guide and uplift you and your loved ones through lifes challenges.\nWhat we stand for at Grab\nWe are committed to building an inclusive and equitable workplace that enables diverse Grabbers to grow and perform at their best. As an equal opportunity employer, we consider all candidates fairly and equally regardless of nationality, ethnicity, religion, age, gender identity, sexual orientation, family commitments, physical and mental impairments or disabilities, and other attributes that make them unique.\n#LI-DNI\nRead more",Industry Type: IT Services & Consulting,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent","['Loans', 'data science', 'Machine learning', 'Manager Technology', 'Medical insurance', 'Financial services', 'SQL', 'Python', 'Auditing', 'ECL']",2025-06-13 05:40:06
Data Scientist Specialist (GenAI),Rarr Technologies,7 - 12 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","Role & responsibilities:\nOutline the day-to-day responsibilities for this role.\n\nPreferred candidate profile:\nSpecify required role expertise, previous job experience, or relevant certifications.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Langchain', 'Artificial Intelligence', 'Natural Language Processing', 'Python', 'RAG', 'Machine Learning', 'Deep Learning']",2025-06-13 05:40:08
Data Scientist,Grid Dynamics,10 - 20 years,Not Disclosed,['Hyderabad'],"Role & responsibilitiMes\n\nCandiate needs to be 8+ Years of Experience\n\nDetails on tech stack\nPython\nPrompt engineering\nBest practices for prompt engineering\nHow LLM can be used in applications for a variety of tasks\nNLP\nUnderstanding of typical NLP problems: classification, NER, summarization, question answering, sentiment analysis, etc.\nTheoretical intuitive understanding of how Transformers work (tokenization, attention, etc).\nWord and sentence embeddings\nVector search\nVector databases, performance tuning\nDocument chunking techniques\nLLM applications development\nLangChain, LlamaIndex\nChain of Thoughts, DSP, and other techniques\nAgents and tools\nGoogle cloud (GCP)\nNice to have requirements to the candidate\nPreferable, the engineers are expected to have IT services/consulting experience.\nProficient in developing LLM-powered systems using advanced prompt engineering techniques, RAG and agentic design patterns. Experienced with frameworks like LangChain, LlamaIndex, and DSPy.\nFamiliar with evaluation approaches and metrics for different types of LLM-based systems.\nExperienced with keyword and vector search methods, including understanding of their underlying algorithms. Familiar with popular vector search engines.\nCompetent in various document understanding models and techniques to parse complex documents and implement effective chunking strategies for RAG systems.\nFamiliar with LLM and embedding models fine-tuning techniques.\nCompetent in using joint vision-language and generative models to solve various problems related to image generation, visual question answering, and multi-modal search. Familiar with diffusion models and associated techniques like LoRA, Dreambooth, and ControlNet.\nUnderstanding of the challenges and risks associated with the development of Generative AI systems and how to mitigate them.\nFamiliar with various architecture design patterns for different types of LLM-based applications such as chatbots, text2sql, document understanding, etc. Familiar with various approaches to scalability and cost reduction in Generative AI systems.\nAbility to stay updated with the latest advancements in Generative AI and integrate emerging technologies to drive innovation and improve the performance of AI systems.\nFamiliar with Responsible AI principles and Human-AI interaction design best practices.\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Lora', 'Natural Language Processing', 'Deep Learning', 'Python']",2025-06-13 05:40:10
Data Analytics/Scientists,Asb Resources Technology Solutions,4 - 9 years,Not Disclosed,['Bengaluru'],#Jobs\nTeam is looking for resources with a data analytics and data science background. Expert SQL skills.From the Data Science side must be able to write open source data models (not from scratch) but be able to talk through the process.\n\nSKILLS REQUIRED:\n\n1. SQL skills must be strong.\n2. Create Data Science operating models.\n3. must have experience with Looker or Tableau. (Both are preferable)\nIDEAL CANDIDATE: SQL/Tableau/looker and building forecasting and open so,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SIDE', 'tableau', 'data science', 'Data analytics', 'Open source', 'Forecasting', 'SQL']",2025-06-13 05:40:11
Data Scientist,Ltimindtree,6 - 11 years,Not Disclosed,['Bengaluru'],"F2F Weekend Drive - Bangalore- 14th June - DS Gen AI\n\nJob description\n\nWe are having a F2F weekend drive for the requirement of a Data Scientist + Gen AI at our LTIM Bangalore Whitefield office.\nDate - 14th June 2025\nExperience - 6+ Years\nMandatory Skills - Data Science, Gen AI, Python, RAG and Azure/AWS, AI/ML, NLPt\n\nLocation - LTIMindtree Bangalore Whitefield Office\n\nSecondary - (Any) Machine Learning, Deep Learning, ChatGPT, Langchain, Prompt, vector stores, RAG, llama, Computer vision, Deep learning, Machine learning, OCR, Transformer, regression, forecasting, classification, hyper parameter tunning, MLOps, Inference, Model training, Model Deployment\nGeneric JD-\nMore than 6 years of experience in Data Engineering, Data Science and AI / ML domain\nExcellent understanding of machine learning techniques and algorithms, such as GPTs, CNN, RNN, k-NN, Naive Bayes, SVM, Decision Forests, etc.\nExperience using business intelligence tools (e.g. Tableau, PowerBI) and data frameworks (e.g. Hadoop)\nExperience in Cloud native skills.\nKnowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset\nAnalytical mind and business acumen and Strong math skills (e.g. statistics, algebra)\nExperience with common data science toolkits, such as TensorFlow, KERAs, PyTorch, PANDAs, Microsoft CNTK, NumPy etc. Deep expertise in at least one of these is highly desirable.\nExperience with NLP, NLG and Large Language Models like BERT, LLaMa, LaMDA, GPT, BLOOM, PaLM, DALL-E, etc.\nGreat communication and presentation skills. Should have experience in working in a fast-paced team culture.\nExperience with AIML and Big Data technologies like AWS SageMaker, Azure Cognitive Services, Google Colab, Jupyter Notebook, Hadoop, PySpark, HIVE, AWS EMR etc.\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase, Vector databases\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression, etc.\nShould be a data-oriented person with analytical mind and business acumen.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-13 05:40:13
Data Scientist,Ltimindtree,8 - 13 years,19-34 Lacs P.A.,"['Pune', 'Bengaluru', 'Mumbai (All Areas)']",10 years of experience in Data ScienceML domain\nShould have experience in Python and libraries like pandas numpy scikitlearn etc\nHave worked on building ML models and integrating it with application end to end\nHave knowledge on Recommender engines and the ML models running behind it like ALS and LightFM\nHave experience in Azure Machine Learning and Azure Services\nHave experience in deploying models in cloud environment and exposing it as an API\nGood communication and presentation skill\nAbility to deliver ML projects as an individual contributor,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'Ml']",2025-06-13 05:40:15
Data Scientist,Ltimindtree,8 - 13 years,Not Disclosed,"['Chennai', 'Bengaluru', 'Mumbai (All Areas)']",We are looking for an experienced AI ML Developers experience in data science specializing in machine learning python statistical modelling and big data technologies pyspark sql.\n\nThe ideal candidate will have a strong background in developing and deploying machine learning models optimizing ML pipelines and handling largescale structured and unstructured data to drive business impact.\n\nDeep understanding of supervised and unsupervised learning including regression classification Multiclass classification clustering and NLP Proficiency in statistical analysis AB testing and causal inference techniques Experience with model deployment and MLOps in cloud environments AWS GCP \n\nKey Responsibilities\n\nDevelop and deploy machine learning models and predictive analytics solutions for business impact\nWork with largescale structured and unstructured data to extract insights and build scalable models\nDesign implement and optimize ML pipelines for realtime and batch processing\nCollaborate with engineering product and business stakeholders to translate business problems into data science solutions\nApply statistical modeling AB testing and causal inference techniques to evaluate business performance\nApply machine learning and statistical techniques for audience segmentation helping to identify patterns and optimise business strategies\nDrive research and innovation by staying updated with cuttingedge MLAI advancements and incorporating them into our solutions\nOptimize data science models for performance scalability and interpretability in production environments\nMentor junior data scientists and contribute to best practices in data science and engineering,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Aiml', 'Ab Testing']",2025-06-13 05:40:16
ML Engineer/Data Scientist,Altimetrik,6 - 8 years,15-30 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Role & responsibilities\nData Scientist /ML engineers : ML Engineer with Python, SQL, Machine Learning, Azure skills(Good to have)",Industry Type: IT Services & Consulting,,,"['Machine Learning', 'Python', 'SQL', 'Data Science', 'Ml', 'azure']",2025-06-13 05:40:18
Data Scientist,Acesoft,6 - 9 years,18-20 Lacs P.A.,['Bengaluru'],"Hi all,\nWe are hiring for the role Data Scientist AI ML\nExperience: 6 -9 Years\nLocation: Bangalore\nNotice Period: Immediate - 15 Days\nSkills:\nWe are looking for a Data Scientist to lead data-driven solutions across our business, from exploratory analysis, incremental hypothesis validation, model development, deployment and monitoring.\nSkills Needed:\nStrong knowledge of Applied AI ML & Deep Learning Data Science techniques, Hardcore in ANN /Deep Learning /Machine Learning/NLP\nDeep knowledge about machine learning algorithms such as tree-based methods, clustering, regression and classification, dimension reduction techniques, linear regression, Logistic regression, k-means, time series forecasting, Hypothesis testing (ANOVA, t-test, etc.), random forest, SVMs, Naive Bayes, gradient boosting, kNN, Deep learning algorithms like CNN, ANN and Reinforcement learning, Anomaly detection.\nIn-depth understanding of Statistical concepts e.g. Probability distributions, statistical tests, correlation analysis, descriptive statistics, kernels, ROC, F1-Score etc.\nAdvanced coding experience in at least one programming language (Python, Pyspark) & Strong experience in object-oriented concepts.\nGood to have advanced experience in one or more of the following: Spark, Databricks, Azure technical stack\nGood to have experience in model deployment to cloud/on-prem.\nGood Communication & presentation skills.\n\nIf you are interested drop your resume at mojesh.p@acesoftlabs.com\nCall: 9701971793",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Temporary/Contractual","['AI ML', 'Data Scientist', 'Machine Learning', 'Deep Learning', 'ANN', 'EDA', 'ANOVA', 'Hypothesis Testing', 'Model Building']",2025-06-13 05:40:20
Data Scientist - Immediate Joiners Only,Reyika,5 - 10 years,Not Disclosed,"['Pune', 'Gurugram', 'Bengaluru']","Role: Data Scientist\nExperience: 5+ years\nLocation: Any - Hybrid (Bangalore, Hyderabad, Pune, Chennai and Gurgaon)\nJob Summary:\nWe're seeking a highly skilled NLP Engineer with expertise in Large Language Models (LLMs) and text summarization to join our team. The ideal candidate will have hands-on experience with Amazon Bedrock, OpenAI, or Hugging Face transformers and a strong background in Python programming. This role involves working with unstructured audio-to-text data, such as call transcripts, and developing innovative solutions using LLMs.\n\nRequirements:\nStrong expertise in NLP, text summarization, semantic search, and LLM APIs.\nPractical experience with Amazon Bedrock, OpenAI, or Hugging Face transformers.\nFamiliar with prompt tuning and few-shot learning.\nPython (pandas, langchain, boto3, NumPy, etc.)\nExperience working with unstructured audio-to-text data (e.g., call transcripts).\n\nKey Responsibilities:\nDesign and Development: Design, develop, and deploy LLM-based solutions for text summarization, semantic search, and other NLP tasks\nLLM APIs: Integrate LLM APIs from Amazon Bedrock, OpenAI, or Hugging Face transformers into existing applications\nPrompt Tuning and Few-Shot Learning: Implement prompt tuning and few-shot learning techniques to improve LLM performance\nUnstructured Audio-to-Text Data: Work with unstructured audio-to-text data, such as call transcripts, to develop accurate and efficient NLP models\nPython Programming: Utilize Python libraries like pandas, LangChain, boto3, and NumPy for data processing and model development.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Large Language Model', 'Natural Language Processing', 'Python']",2025-06-13 05:40:21
Data Scientist,Devon Software Services,3 - 7 years,12-19 Lacs P.A.,['Bengaluru'],"What you will do\nBuild end-to-end machine learning models to solve business problems in Marketing\nPerform feature engineering and support data engineering to build robust data pipelines on large marketing datasets from different sources\nCollaborate with ML Engineering to build ML Pipelines to Train, Test, Deploy, Serve and Monitor models, Tune Hyperparameters, detect model and data drift and resolve issues\nPresent machine learning models outcomes, and help interpret model predictions to various stakeholders using standard data visualization tools",,,,"['Tensorflow', 'Ai Algorithms', 'Ml Algorithms', 'Machine Learning', 'Python', 'Pytorch', 'Model Development']",2025-06-13 05:40:23
Business Finance Professional,Purplle.com,0 - 2 years,Not Disclosed,['Mumbai'],"As an Assistant Manager Business Finance, you will play a pivotal role in driving revenue growth, optimizing costs, and managing financial resources. This position requires close collaboration with various teams to develop and execute financial strategies, as well as analyze key performance indicators (KPIs) to support business decisions.\n  Key Responsibilities:\n  Financial Planning Analysis (FPA):\nDevelop and manage budgets and forecasts for different business units.\nAnalyze variances between actuals and budgets; identify trends and provide actionable insights.\nSupport strategic planning with scenario modeling\nRevenue Cost Analysis:\nTrack and evaluate revenue streams (e.g., direct sales, subscription, advertising).\nAnalyze cost drivers including customer acquisition cost (CAC), fulfillment, logistics, and returns.\nEnsure unit economics and contribution margins are healthy.\nBusiness Partnering:\nCollaborate with marketing, operations, product, and tech teams to provide financial insights.\nHelp non-financial teams understand the financial implications of their initiatives.\nKPI Reporting Dashboards:\nDevelop and maintain financial dashboards and key performance indicators (KPIs), such as:-\nGross merchandise value (GMV)\nAverage order value (AOV)\nReturn on ad spend (ROAS)\nCustomer lifetime value (CLTV)\nQualifications:\nCA fresher or minimum 0.5 - 1 years of experience in Finance, Accounting, Economics, or a related field.\nProven experience in financial planning and analysis, preferably in a business finance role preferred\nStrong analytical skills with proficiency in financial modeling and data analysis tools.\nExcellent communication and interpersonal skills to collaborate with cross-functional teams.",Industry Type: Beauty & Personal Care,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['data analysis', 'modeling', 'kpi', 'business finance', 'accounting', 'budgeting', 'sales', 'economics', 'fpa', 'analysis tools', 'financial modelling', 'cost optimization', 'financial planning and analysis', 'cost analysis', 'finance', 'reporting', 'budget management', 'communication skills']",2025-06-13 05:40:25
Big Data Developer/Data Engineer,Grid Dynamics,5 - 10 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\nExperience: 5 - 8 years\nEmployment Type: Full-Time\n\nJob Summary:\nWe are looking for a highly skilled Scala and Spark Developer to join our data engineering team. The ideal candidate will have strong experience in building scalable data processing solutions using Apache Spark and writing robust, high-performance applications in Scala. You will work closely with data scientists, data analysts, and product teams to design, develop, and optimize large-scale data pipelines and ETL workflows.\n\nKey Responsibilities:\nDevelop and maintain scalable data processing pipelines using Apache Spark and Scala.\nWork on batch and real-time data processing using Spark (RDD/DataFrame/Dataset).\nWrite efficient and maintainable code following best practices and coding standards.\nCollaborate with cross-functional teams to understand data requirements and implement solutions.\nOptimize performance of Spark jobs and troubleshoot data-related issues.\nIntegrate data from multiple sources and ensure data quality and consistency.\nParticipate in design reviews, code reviews, and provide technical leadership when needed.\nContribute to data modeling, schema design, and architecture discussions.\nRequired Skills:\nStrong programming skills in Scala.\nExpertise in Apache Spark (Core, SQL, Streaming).\nHands-on experience with distributed computing and large-scale data processing.\nExperience with data formats like Parquet, Avro, ORC, and JSON.\nGood understanding of functional programming concepts.\nFamiliarity with data ingestion tools (Kafka, Flume, Sqoop, etc.).\nExperience working with Hadoop ecosystem (HDFS, Hive, YARN, etc.) is a plus.\nStrong SQL skills and experience working with relational and NoSQL databases.\nExperience with version control tools like Git.\nPreferred Qualifications:\nBachelor's or Masters degree in Computer Science, Engineering, or related field.\nExperience with cloud platforms like AWS, Azure, or GCP (especially EMR, Databricks, etc.).\nKnowledge of containerization (Docker, Kubernetes) is a plus.\nFamiliarity with CI/CD tools and DevOps practices.ndidate profile",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Scala', 'Pyspark', 'Spark']",2025-06-13 05:40:27
Sr. Manager - Finance Business Partner,Flipkart,3 - 8 years,Not Disclosed,['Bengaluru'],"Manager - Finance Business Partner\nTo Success in the role\nPossess strong analytical skills and a keen attention to detail.\nDemonstrate proficiency in financial analysis and modeling techniques.\nExhibit excellent communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams.\nDisplay a proactive and results-oriented mindset, with a drive for continuous improvement.\nHave a solid understanding of accounting principles and financial management concepts.\nBe adaptable and able to thrive in a fast-paced, dynamic environment.\nShow a willingness to learn and a passion for contributing to meaningful projects that drive organizational success.\nSkills Required :\nFinancial Analysis , Financial Modelling\nRole :\n1. Workforce Management: Coordinate hiring and firing activities based on demand fluctuations, ensuring optimal staffing levels at warehouses to meet operational requirements.\n2. Cost Optimization: Lead initiatives to drive cost-saving by optimizing order handling processes, enhancing productivity, and improving manpower engagement.\n3. Process Optimization: Analyze existing operational workflows and identify opportunities for improvement, implementing strategies to streamline operations and increase efficiency.\n4. Cross-Functional Collaboration: Collaborate with cross-functional stakeholders to execute programs aimed at streamlining operations and improving supply chain performance.\n5. Data Analysis: Utilize data analytics tools and techniques to gather insights, identify trends, and make data-driven decisions to enhance operational effectiveness.\nDesirable Skills :\nGood Communication , Analytics, Strategic Planning",Industry Type: Courier / Logistics,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Financial Analysis', 'Financial Modelling', 'Workforce Management', 'Data Analysis', 'Cost Optimization', 'Strategic Planning']",2025-06-13 05:40:28
Senior Analyst,National Australia Bank (NAB),3 - 8 years,Not Disclosed,['Gurugram'],"NAB is looking for Senior Analyst to join our dynamic team and embark on a rewarding career journey.\nThe Senior Analyst plays a crucial role in driving data-driven decision-making processes within the organization\nThis position involves analyzing complex data sets, generating actionable insights, and providing strategic recommendations to support key business initiatives\nKey Responsibilities:Data Analysis:Conduct in-depth analysis of large and complex datasets to extract meaningful insights",,,,"['Excel', 'Senior Analyst', 'Finance', 'Focus', 'Banking', 'Manager Technology', 'Recruitment']",2025-06-13 05:40:30
Senior Analyst - Change Management,Nium India,3 - 8 years,Not Disclosed,['Mumbai'],"Nium, the Leader in Real-Time Global Payments\nNium , the global leader in real-time, cross-border payments, was founded on the mission to deliver the global payments infrastructure of tomorrow, today. With the onset of the global economy, its payments infrastructure is shaping how banks, fintechs, and businesses everywhere collect, convert, and disburse funds instantly across borders.\n\nIts payout network supports 100 currencies and spans 220+ markets, 100 of which in real-time. Funds can be disbursed to accounts, wallets, and cards and collected locally in 35 markets. Niums growing card issuance business is already available in 34 countries. Nium holds regulatory licenses and authorizations in more than 40 countries, enabling seamless onboarding, rapid integration, and compliance - independent of geography. The company is co-headquartered in San Francisco and Singapore.\n\nAbout the Team:\n\nChange Management - The team plays a critical role in optimizing operational efficiency by managing the logical setup and administration of the ticketing system. They design and implement workflow automations to enhance end-user experience, develop and maintain KPI dashboards and reporting for performance tracking, and lead continuous process monitoring and improvement initiatives to drive sustained operational excellence.\nAbout the Role:\nWe are looking for a skilled Data Analyst to join our team. The ideal candidate should have strong expertise in data analysis, data maintenance, and automation, with hands-on experience in SQL, Python, and Excel (including VBA and Power Query automation). The role requires the ability to manage reports, maintain version control, and support business processes with data-driven insights.\nKey Responsibilities:\nTranslate business requirements into technical data specifications and manipulate larger datasets to support various data initiatives where data is capitalized as an asset.\nFocus on developing customizable reports, ad hoc analysis, and data visualizations in a business-friendly manner to drive adoption.\nOwn development of database structures, views, stored procedures, functions, and triggers.\nDevelop and test solutions using Access, VBA, SQL Server, or any other technology. Support existing developed automated tools and maintenance activities.\nDocument and communicate objectives, plans, status, issues and risks in a timely manner to team members, stakeholders, and senior management.\nWillingness to support critical business needs beyond standard working hours, if required.\nRequirements:\nHas a bachelor s degree with 3+ Years of Experience working with Reporting / Office Automation (VBA) and any Relations Database Management (SQL/MS Access/ MySQL/ Oracle etc).\nExperience in preparing Business Requirement Document (BRD) and working with Business subject matter experts to resolve data related queries.\nResponsible for end-to-end data analysis to understand and define how data is collected, transformed, and published to support the business users for their objectives.\nStrong proficiency in SQL for data analysis and reporting and knowledge of ETL processes and data warehousing.\nStrong analytical and problem-solving skills and ability to self-drive projects and work across multiple teams.\nExcellent verbal and written communication skills.\nWhat we offer at Nium\nWe Value Performance: Through competitive salaries, performance bonuses, sales commissions, equity for specific roles and recognition programs, we ensure that all our employees are well rewarded and incentivized for their hard work.\n\nWe Care for Our Employees: The wellness of Nium ers is our #1 priority. We offer medical coverage along with 24/7 employee assistance program, generous vacation programs including our year-end shut down. We also provide a flexible working hybrid working environment (3 days per week in the office).\n\nWe Upskill Ourselves: We are curious, and always want to learn more with a focus on upskilling ourselves. We provide role-specific training, internal workshops, and a learning stipend\n\nWe Constantly Innovate: Since our inception, Nium has received constant recognition and awards for how we approach both our business and talent opportunities.\n- 2022 Great Place To Work Certification\n- 2023 CB Insights Fintech 100 List of Most Promising Fintech Companies .\n- CNBC World s Top Fintech Companies 2024.\n\nWe Celebrate Together: We recognize that work is also about creating great relationships with each other. We celebrate together with company-wide social events, team bonding activities, happy hours, team offsites, and much more!\n\nWe Thrive with Diversity: Nium is truly a global company, with more than 33 nationalities, based in 18+ countries and more than 10 office locations. As an equal opportunity employer, we are committed to providing a safe and welcoming environment for everyone.\nFor more detailed region specific benefits : https: / / www.nium.com / careers#careers-perks\nFor more information visit www.nium.com\n\nDepending on your location, certain laws may regulate the way Nium manages the data of candidates. By submitting your job application, you are agreeing and acknowledging that you have read and understand our Candidate Privacy Notice located at www.nium.com / privacy / candidate-privacy-notice .",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAN', 'Data analysis', 'Change management', 'MS Access', 'MySQL', 'Workflow', 'Stored procedures', 'Oracle', 'SQL', 'Python']",2025-06-13 05:40:32
Data Analyst,FedEx,2 - 4 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nCollect, analyze, and interpret complex data sets using Python and SQL to support business objectives.\nCollaborate with stakeholders to understand business needs, formulate analytic solutions, and provide actionable insights.\nDevelop and maintain data models and reports to track key performance indicators (KPIs) and business metrics.\nCreate meaningful data visualizations to communicate findings, trends, and actionable insights to non-technical stakeholders.\nConduct exploratory data analysis and identify patterns, trends, and opportunities for business improvement.\nSupport data quality initiatives, ensuring accuracy and consistency across data sources.\nUtilize statistical and quantitative techniques to support problem-solving and business optimization efforts.\n\n\n\n\nPreferred candidate profile\n\nPython: Proficiency in data manipulation, data analysis libraries (Pandas, NumPy),and data visualization libraries (Matplotlib, Seaborn).\nSQL: Strong command of SQL for data extraction, transformation, and complex queries.\nBusiness Acumen: Ability to understand business context and objectives, aligning analytics with organizational goals.\nQuantitative Aptitude: Strong analytical and problem-solving skills, with a keen attention to detail.\nData Visualization: Basic skills in data visualization to effectively communicate insights.\nStatistical Analysis: Foundational understanding of statistical methods (e.g., regression, hypothesis testing).\nCommunication Skills: Ability to distill complex data insights into clear,actionable recommendations for stakeholders.",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'SQL', 'Python', 'Power Bi', 'Business Insights', 'Tableau', 'Data Analytics']",2025-06-14 05:24:32
Data Analyst (Python),Crisil,0 - 3 years,Not Disclosed,"['Hyderabad', 'Pune']","Tech Resources\nAny graduate/postgraduate (MBA)/BSc/BTech with sound grip on financial aspects\nGood communication skills, both written and oral\nWilling to work in 24*5 environment on rotational shifts (including night shifts)\nCertification or knowledge/experience in MS-office (Excel, Word, PowerPoint)\nPreferred with exposure of working on data analysis\nKnowledge in SQL, Python and VBA Macro is a must\nKnowledge of corporate finance / accountancy i.e., financial statements and annual reports is a plus",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['companies act', 'office', 'accounting', 'microsoft', 'corporate finance', 'sql', 'java', 'listing agreement', 'writing', 'powerpoint', 'communication skills', 'financial statements', 'python', 'data analysis', 'sebi', 'excel', 'r', 'vba', 'accountancy', 'compliance', 'secretarial activities', 'annual reports', 'word', 'finance', 'ms office']",2025-06-14 05:24:34
Data Analyst,Fraoula,3 - 5 years,Not Disclosed,"['Mumbai', 'Bengaluru', 'Delhi / NCR']","We are seeking a highly motivated and detail-oriented Data Analyst to join our growing team. The ideal candidate will be passionate about transforming raw data into actionable insights, helping us make informed strategic decisions. You will play a crucial role in collecting, processing, and performing statistical analyses on large datasets, translating complex findings into clear, concise reports and visualizations for various stakeholders.\n\nKey Responsibilities:\n-Data Collection & Cleaning: Source, collect, and clean data from various internal and external databases, ensuring data accuracy, completeness, and consistency.\n-Data Analysis & Modeling: Perform in-depth statistical analysis, identify trends, patterns, and anomalies in data. Develop and implement data models to predict outcomes and optimize performance.\n-Reporting & Visualization: Create compelling and intuitive dashboards, reports, and presentations using data visualization tools (e.g., Power BI, Tableau) to communicate insights to technical and non-technical audiences.\n\nLocation-Delhi NCR,Bangalore,Chennai,Pune,Kolkata,Ahmedabad,Mumbai,Hyderabad,Remote",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL', 'Python', 'Power BI', 'Data Analysis', 'Data Visualization', 'Tableau', 'Looker', 'Data Cleaning', 'Statistical Analysis']",2025-06-14 05:24:37
Data Analyst,Fiserv,3 - 5 years,Not Disclosed,['Thane'],"Hi,\n\nWe at Fiserv are actively looking for Data Analysts with expertise in Power BI, SQL and Python.\n\nBelow is the job description:\n\nWhat does a successful Data Analyst do at Fiserv ?\nData Analyst is responsible for identifying any issues or ways to improve the collection, distribution and consumption of data. The data analysts will also monitor performance and quality control plans to identify any issues or ways to improve data orchestrations. This role requires collaborating with architects and developers to implement effective automation processes.\n\nWhat will you do:\nAbility to manage time and priorities with multiple tasks and projects, to work with loosely defined requirements.\nAnalyze, query and manipulate financial and business level data.\nValidate data sets are in synch with sources. Perform reconciliations of defined data. Identify, compare, and resolve data quality problems. Evaluate large dataset for quality and accuracy.\nDetermine business impact level for data quality issues. Work with Programmers to correct data quality errors. Determine root cause for data quality errors and make recommendations for solutions.\nResearch and determine scope and complexity of issue to identify steps to fix issue.\nDevelop process improvements to enhance overall data quality and execute data cleanup measures. Maintain a record of original data and corrected data.\nEnsure adherence to data quality standards. Identify areas of improvement to achieve data quality.\nResolve all internal data exceptions in timely and accurate manner.\n\nWhat will you need to know:\nBachelors Degree or equivalent experience.\nMust have analytical, problem solving, and team building skills.\nAbility to work independently, prioritize tasks and solve problems.\nProficient in MS Power BI, SQL and Python.\nExcellent communication (verbal and written), interpersonal, organizational, collaboration, and trouble shooting skills.\n\nWhat would be great to have:\nExposure to Foundry or Snowflake a plus.\nExperience in VBA is a plus.\n\nWe welcome and encourage diversity in our workforce. Fiserv is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, colour, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protector veteran.\nExplore the possibilities of a career with Fiserv and Find your Forward with us !",Industry Type: FinTech / Payments,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Business Analytics', 'Data Analysis', 'SQL', 'Python', 'Analytics']",2025-06-14 05:24:39
Data Analysts,Mainetti,3 - 8 years,Not Disclosed,['Chennai'],"Core Competencies\n1. Attention to Detail\nEnsures data accuracy and consistency across all reports and datasets.\n2. Data Integrity & Accountability\nTakes ownership of data quality; trusted to manage business-critical data (e.g., rebate reports).\n3. Analytical Thinking\nCapable of identifying patterns, anomalies, and actionable insights through data review.",,,,"['Sales Analysis', 'Power Bi Dashboards', 'Data Analysis', 'SQL Queries', 'Advanced Excel']",2025-06-14 05:24:41
Data Analyst,Ramboll,6 - 10 years,Not Disclosed,['Gurugram'],"Transport Commercial / Data Analyst \nRole requires multitasking capabilities for effectively handling multiple opportunities at the same time, ensuring each preparation receives the necessary attention and meets the deadlines.\nWe are seeking motivated individuals to join the Transport Commercial team and help us to drive growth within the market. This position will involve a variety of tasks, working with the team to support: measuring and reporting on our performance, data analysis and supporting our market knowledge through CRM. \nKey responsibilities include:\nGathering and analyzing data from various sources such as CRM and additional databases to generate comprehensive reports and dashboards for the Transport Commercial team and the Transport Leadership Team\n Working with our team and Opportunity Owners to support and develop the use of tools and processes to support effective tendering, including the use of AI.\nConducting market intelligence tasks to support business decisions by performing online market research and developing tools to optimize this research turning data insights into effective business intelligence.\nImplementing automation processes to improve data quality and visualization through charts, views, and interactive dashboards, to support strategic planning and decision-making\n Supporting live tenders as necessary, in particular with the preparation of governance and progress report documentation.\nEstablish and nurture relationships with internal stakeholders.\n  Qualification\nThis role is ideal for an experienced Graduate passionate about managing business operations and driving growth within the Transport Commercial sector. If you have a proactive mindset, strong analytical skills, and a keen interest in this field, we encourage you to apply.\nBachelor's degree in Business Administration, Economics, Engineering, Data Science, or a related field.\nDemonstrated skills in Business development softwares such as MS Office, PowerBI and CRM systems. Experience on scripting tools (e.g., SQL, Python) would be advantageous.\nStrong writing and presentation skills.\nCapabilities to multitask, managing multiple opportunities simultaneously while meeting deadlines.\nExcellent networking skills and a global mindset to establish and nurture relationships.\nProactive approach and excellent collaboration skills.\nExperience in data analysis, market intelligence, and business decision support.\nFamiliarity with automation processes and data visualization techniques.\nPrevious experience in a similar role is preferred.\nInterest in business management and work-winning strategies.\nDemonstrate a global mindset and strong networking skills\nAdditional Information\nWhat we can offer you\nInvestment in your development\nLeaders you can count on, guided by our Leadership Principles\nBe valued for the unique person you are\nNever be short of inspiration from colleagues, clients, and projects\nThe long-term thinking of a foundation-owned company\nWork at the heart of sustainable change\nRamboll is a global architecture, engineering, and consultancy company. We believe that the purpose of sustainable change is to create a thriving world for both nature and people. So, that’s where we start – and how we work. At Ramboll, our core strength is our people, and our history is rooted in a clear vision of how a responsible company should act. Being open and curious is a cornerstone of our culture. We embrace an inclusive mindset that looks for fresh, diverse, and innovative perspectives. We respect, embrace, and invite diversity in all forms to actively cultivate an environment where everyone can flourish and realise their full potential.\nReady to join us?\nPlease submit your application. Be sure to include all relevant documents including your CV, cover letter, etc.\nThank you for taking the time to apply! We look forward to receiving your application.\nAbout Ramboll\nFounded in Denmark, Ramboll is a foundation-owned people company. We have more than 18,000 experts working across our global operations in 35 countries. Our experts are leaders in their fields, developing and delivering innovative solutions in diverse markets including Buildings, Transport, Planning & Urban Design, Water, Environment & Health, Energy, and Management Consulting. We invite you to contribute to a more sustainable future working in an open, collaborative, and empowering company. Combining local experience with global knowledge, we together shape the societies of tomorrow.\nEquality, diversity, and inclusion is at the heart of what we do\nWe believe in the strength of diversity and know that unique experiences and perspectives are vital for creating truly sustainable societies. Therefore, we are committed to providing an inclusive and supportive work environment where everyone can flourish and reach their potential. We welcome applications from candidates of all backgrounds and encourage you to contact our recruitment team to discuss any accommodations you need during the application process.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analysis', 'analytical', 'softwares', 'consulting', 'bi', 'presentation skills', 'power bi', 'business development', 'networking', 'tools', 'dashboards', 'business intelligence', 'research', 'sql', 'scripting', 'data quality', 'operations', 'data science', 'collaboration', 'writing', 'data visualization', 'ms office', 'crm']",2025-06-14 05:24:43
Data Analyst,Schneider Electric,2 - 3 years,7-8 Lacs P.A.,"['Gurugram', 'Chennai', 'Bengaluru']","Support the PIM Solutions at a Process standpoint on Run Operations - Open & consider assigned new tickets coming from Support tool (2929IT).\n\nStays updated on upcoming functionalities and enhancements, and keeps users informed.",Industry Type: Electronics Manufacturing (Electronic Manufacturing Services (EMS)),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Analysis', 'Data Analytics', 'SQL', 'Data Visualization']",2025-06-14 05:24:45
Data Analyst,Optum,1 - 3 years,3.25-7.5 Lacs P.A.,"['Noida', 'Gurugram']",Role & responsibilities\n\nLooking for 1+ year exp\nSQL\nAZURE\n\n\nPreferred candidate profile\n\nAI exposure\ngood communication,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'azure', 'SQL']",2025-06-14 05:24:47
Data Analyst,Avnet,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Summary:\nDesigns and prepares reports, dashboards, and summaries for statistical analysis and planning purposes. Analyzes business issues using data from internal and external sources to provide insight to decision-makers. Identifies and interprets trends and patterns.\n\nPrincipal Responsibilities:",,,,"['Training', 'Statistical analysis', 'Business analysis', 'Finance', 'Business process mapping', 'Data Analyst', 'Management', 'Business intelligence', 'Principal', 'Remedy']",2025-06-14 05:24:50
Data Analyst,Pripton Innovations,0 - 5 years,Not Disclosed,[],We are looking for a Data Analyst with expertise in ERP systems (NetSuite and Workday Financials) and data warehousing (Snowflake) to support our ongoing ERP migration and data-driven decision-making.,Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'ERP System', 'Netsuite', 'Snowflake']",2025-06-14 05:24:52
Data Analyst,Cushman Wakefield,1 - 2 years,Not Disclosed,['Gurugram'],"Job Title\nData Analyst\nJob Description Summary\nThis role focuses on developing advanced analytics systems, uncovering growth opportunities through data analysis, and creating insightful reports and visualizations. It will involve close collaboration with managers to understand business needs, define KPIs, and deliver actionable insights that enhance performance and efficiency.\nKey responsibilities include data mining, predictive modeling, system evaluation, and maintaining robust data infrastructure to support strategic decision-making.\n\n\n\n\n\n\nINCO: Cushman Wakefield",,,,"['data cleansing', 'advanced analytics', 'Data analysis', 'Scalability', 'Revenue enhancement', 'Infrastructure', 'Manager Technology', 'Predictive modeling', 'Data Analyst', 'Data mining']",2025-06-14 05:24:54
Data Analyst/ Excel Specialist,Appletech,3 - 8 years,Not Disclosed,['Vadodara'],"Must have at least 3 years of experience in working with MS Excel and excellent command over various functions and formulas viz. VLOOKUP, HLOOKUP, Pivot Table, etc.\nShould be able to understand data.\nExtract Excel and CSV data from other software, combine multiple files and massage the data.\nUse various tools and processes to complete data migrations from other software packages into our product in a timely and accurate manner.\nParticipate in detailed design and product test execution as required.\nShould have excellent written English and able to communicate directly with the US-based clients.\n\n*Only those candidates should apply who are ready to work from our Vadodara Office.",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Excel', 'VLOOKUP', 'Data Analysis', 'Pivot', 'HLOOKUP', 'Countif', 'Data Migration', 'Conditional Formatting']",2025-06-14 05:24:56
Data Analyst,C&W Services,1 - 4 years,Not Disclosed,['Gurugram'],"Job Title\nData Analyst\nJob Description Summary\nThis role focuses on developing advanced analytics systems, uncovering growth opportunities through data analysis, and creating insightful reports and visualizations. It will involve close collaboration with managers to understand business needs, define KPIs, and deliver actionable insights that enhance performance and efficiency.\nKey responsibilities include data mining, predictive modeling, system evaluation, and maintaining robust data infrastructure to support strategic decision-making.\nWork closely with the Program manager (s) and department heads to understand and maintain focus on their analytics needs, including critical metrics and KPIs, and deliver actionable insights to relevant decision-makers\nProactively analyze data to answer key questions for stakeholders or yourself, with an eye on what drives business performance, and investigate and communicate which areas need improvement in efficiency and productivity\nCreate and maintain rich insights to facilitate cross sell and upsell decisions through deep data mining\nDefine and implement data acquisition and integration logic, selecting an appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution\nDevelop and maintain databases by acquiring data from primary and secondary sources\nProviding technical expertise in data storage structures, data mining, and data cleansing.\nBuild predictive analysis and churn analysis to impact revenue enhancement and retention\n\n\n\n\n\n\nINCO: Cushman & Wakefield",Industry Type: Real Estate,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data cleansing', 'advanced analytics', 'Data analysis', 'Scalability', 'Revenue enhancement', 'Infrastructure', 'Manager Technology', 'Predictive modeling', 'Data Analyst', 'Data mining']",2025-06-14 05:24:58
Data Analyst,Vipany Management Consulting,3 - 5 years,Not Disclosed,['Pune'],"Summary\nIn this role, you will be a part of the centralised global office based in India and work closely with each of our markets globally to understand the clients communication objectives, access multiple data sources and visualise it using Tableau / Datorama, support on of ETL process using MSSQL / Alteryx Flow and has sound knowledge of Excel VBA.\nKey responsibilities\nOwn the design, development, and maintenance of ongoing metrics, reports, analyses, dashboards on the key drivers of our business\nPartner with operations/business teams to consult, develop and implement KPIs, automated reporting/process solutions and data infrastructure improvements to meet business needs\nEnable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format\nManage on-time delivery of regular client reports including:\no Building reports from data warehouse\no Review of completed reports for anomalies & discrepancies\no Troubleshooting data issues/discrepancies\no Ensure formatting & delivery parameters are met\nUpdating Tableau dashboards and Excel Dashboard as required for daily/weekly client reporting.\nInvestigate and understand the opportunities of new data sources in the context of integration into Tableau.\nUpdating Tableau/Excel/ or any similar dashboards for daily/weekly client reporting.\nSupport data cleansings & manipulation process including but not limited to:\no Taxonomy classification\no Conversion re-naming, grouping\no Removal of test/ghost impressions\nDesired Skills:-\n• Minimum 3 years of experience in Analytics\n• Strong verbal/written communication and data presentation skills, including an ability to effectively communicate with both business and technical teams.\n• Hands on experience in creating complex Excel reports, SQL Queries joining multiple datasets\n• Data Visualization tools such as Quick Sight / Tableau / Power BI / Datorama\n• An ability and interest in working in a fast-paced, ambiguous and rapidly-changing environment\n• Experience in developing requirements and formulating business metrics for reporting, familiarity with data visualization tools, e.g. Tableau, Power BI\nInterested candidates can reach out through:-\nKavya.p-8341137995/kavya.p@vipanyglobal.com\nHiring for only females",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Visualization', 'SQL', 'Power Bi', 'Data Analysis', 'Tableau', 'Data Reporting']",2025-06-14 05:25:00
Data Analyst,Avnet Emea,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Summary:\nDesigns and prepares reports, dashboards, and summaries for statistical analysis and planning purposes. Analyzes business issues using data from internal and external sources to provide insight to decision-makers. Identifies and interprets trends and patterns.\n\nPrincipal Responsibilities:\nCollects, compiles and analyzes data from various databases and performs statistical analysis for internal customer groups.\nDevelops reports and/or creates dashboards providing financial related information needed to make informed business decisions.\nDesigns, creates and implements templates to collect, display and analyze data for assigned projects\nCommunicates complex data in comprehensible ways. Evaluates information from multiple sources and clearly indicates quality of final analysis.\nDevelops reports and other tools to deliver internal company information enabling business users to make informed decisions.\nGathers, aggregates models, and analyzes information from multiple external sources regarding company financial performance, customer insights, competitor profiling, competitive threats, potential product or technical expansion, industry trends and other such business intelligence aspects.\nEstablishes standards and procedures for a variety of processes, conducting business analysis resulting in detailed creation and maintenance of business process mapping, requirements and training materials documentation.\nMay participate in or lead project teams.\nIdentifies, investigates and participates in opportunities to improve processes and procedures, to include various key performance metrics.\nOther duties as assigned.\n\nJob Level Specifications:\nFoundational knowledge of specialized disciplines, industry practices and standards, acquired via academic instruction and/or relevant work experience of substantially the same level.\nDevelops solutions to defined tasks, typical assignments and projects. May be solved by the application of specialized foundational knowledge, using existing approaches and solutions.\nWork is usually performed independently and requires the exercise of judgment and discretion. Receives initial direction although work may be reviewed for accuracy and quality.\nCollaborates with immediate management and team members within the department or function.\nActions typically affect own work assignments and department. Erroneous decisions or failure to accomplish work may require some assistance or resources to remedy.\n\nWork Experience:\nTypically less than 2 years with bachelors or equivalent.\n\nEducation and Certification(s):\nBachelors degree or equivalent experience from which comparable knowledge and job skills can be obtained.\n\nDistinguishing Characteristics:\nPosition may require the ability to travel.\nThe above statements are intended to describe the general nature and level of work being performed. They are not intended to be construed as an exhaustive list of all responsibilities, duties, and skills.",Industry Type: Electronics Manufacturing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Training', 'Statistical analysis', 'Business analysis', 'Finance', 'Business process mapping', 'Data Analyst', 'Management', 'Business intelligence', 'Principal', 'Remedy']",2025-06-14 05:25:02
Data Analyst,LTIMindtree,7 - 12 years,Not Disclosed,"['Chennai', 'Bengaluru', 'Delhi / NCR']","Role & responsibilities\nPrimary Skill SQL, Business Intelligence Tools, Banking products exp, DBMS( Redshift OR Oracle),Cloud Exp (AWS Preferred).\nSecondary Skill Data Management, Agile exp.\nTotal Exp 7+\nNotice Period : 30 Days\nJob Location : Pan India\n\nShare your CV on\npallavi.bhalerao@alphacom.in",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Intelligence Tools', 'DBMS', 'SQL', 'Banking Products']",2025-06-14 05:25:05
Data Analyst,Growing Soonicorn in Auto Components Spa...,3 - 5 years,Not Disclosed,['Bengaluru'],"Dear Candidates,\n\nGreetings!!\n\nWe are hiring for one of the Globalized Product Based & Motor Vehicle Manufacturing MNC.\n\nJob Type: FTE\nJob Role:- Data Analyst\nExperience: 3 to 5 Years\nLocation: Bangalore\nWork Mode: Work from office\nNotice Period: Immediate to 30 days\nBudget: As Per Market Standards\nMandatory Skills:- Azure Data bricks, Power BI, Tableau, SQL, Python\n\n\n\nInterested candidates can share their updated resume on Gurpreet@selectiveglobalsearch.com",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Power Bi', 'Azure Databricks', 'Tableau', 'SQL', 'Python', 'Data Visualization']",2025-06-14 05:25:07
Data Analyst - Intermediate,Equifax Credit Information Services Private Limited,3 - 8 years,Not Disclosed,['Pune'],"Equifax is looking for a Data Analyst to join our team in India supporting the Canada business unit. As a Data Analyst at Equifax, you will work with stakeholders to use data and analytics to provide key insights and drive business decisions.\nThe ideal candidate will possess strong technical skills and a passion for uncovering solutions, business insights hidden within vast datasets, and have the ability to communicate findings clearly and concisely to both technical and non-technical audiences.\nKey Responsibilities Include :\n\nIND-Pune-Equifax Analytics-PEC\nFunction - Data and Analytics\nFull time",,,,"['GCP', 'Project management', 'Analytical', 'Healthcare', 'Manager Quality Control', 'Project delivery', 'Analytics', 'Financial services', 'SQL', 'Python']",2025-06-14 05:25:09
"Data Eng, Mgmt & Governance Analyst",Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Data Management - Structured Query Language (SQL)\n\n\n\n\nDesignation: Data Eng, Mgmt & Governance Analyst\n\n\n\n\nQualifications:BE/BTech\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDomain-specific language used in programming and designed for querying and modifying data and managing databases.\n\n\n\n\nWhat are we looking for\nSQL Data Visualization Adaptable and flexible Commitment to quality Ability to work well in a team Strong analytical skills Agility for quick learning\n\n\n\nRoles and Responsibilities: Draft, review and negotiate the supplier/buyside agreements and similar/related documentation with Accenture suppliers, to procure various goods and services including but not limited to Contactors, Human Resources Support, IT & Telecom, Marketing & Communications, Workplace Support (Facilities & Services), Software as a Service etc. in accordance with Accentures suppliers contracting standards, applicable laws, and business requirements. Customize the existing templates in exceptional cases to suit the business requirements thereby ensuring compliance to applicable local laws and Accentures suppliers contracting standards. Review the supplier templates and ensure that the deviations to the Accentures suppliers contracting standards are timely identified and highlighted to the business whenever they pose as risks to Accenture operations. Participate in negotiations by representing company s interests and interface directly with client/ vendor negotiating teams with suppliers, third parties, subcontractors etc., to agree to contractual terms in accordance with Accentures suppliers contracting standards, applicable laws, and stakeholder requirements. Liaise and effectively collaborate with internal stakeholders such as deal teams, Solution Architects, Procurement, HR, Workplace, Finance, Marketing & Communications etc., as well as with external parties such as suppliers, external counsel etc. to ensure contractual risks are clearly identified and addressed in compliance with Accenture s policies and standards. Work closely with the stakeholders to help them understand the contractual clauses in terms of interpretation and its applicability in the contract basis the business opportunity. Advise the Business from legal perspective to address the potential contractual risks that may pose as risks to Accenture business operations. Conduct gap analysis and create legal risk assessment by identifying and flagging potential risks to Accenture and/or clauses which are non-negotiable. Provide recommendations to Business and other related stakeholders to sensitize them on the extent of risk Accenture exposes itself in context of the services and to minimize or mitigate such risks effectively. Structure the legal transactions to be most advantageous from a contracting and business perspective and escalate accordingly to the SME/leadership on the deal etc.\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data management', 'data analysis', 'gap analysis', 'sql', 'data visualization', 'project management', 'python', 'data analytics', 'documentation', 'business analysis', 'power bi', 'business intelligence', 'database management', 'tableau', 'saas', 'advanced excel', 'agile', 'business operations']",2025-06-14 05:25:11
Data Analyst with Python,Cenduit India Services,5 - 10 years,Not Disclosed,['Bengaluru'],"Job Description\nEssential Functions.\n\nResearches information for the creation of global data elements or information in variety of areas or in a complex area.\nAnalyses and interprets researched information in relation to agreed business rules.\nAnalyses changes in data or information and incorporates in data being maintained as needed.\nUpdates existing global data systems/stores correctly with new and changed information.\nEnsures the information created is correctly transferred into relevant systems, databases and client offerings.\nQuality assures a variety of global data elements or information, providing feedback to originators and answering their queries.\nMay assess impact of data changes on regular client offerings.\nMay answer queries on global data (client and internal).\nMay assist in training of new data analysts.\nMay assist with scheduling and tracking creation of global reference data.\n\nQualifications\nBachelors Degree or equivalent, in biomedical subject Req\n1.5+ year s experience working in Excel and SQL, creating BI dashboard.\nExperience in Python OR VBA\nExperience in Power BI or tableau\nWilling to work on UK shift\nGood understanding of how data being created is used in client offerings.\nIQVIA is a leading global provider of clinical research services, commercial insights and healthcare intelligence to the life sciences and healthcare industries. We create intelligent connections to accelerate the development and commercialization of innovative medical treatments to help improve patient outcomes and population health worldwide .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Healthcare', 'Clinical research', 'business rules', 'power bi', 'Scheduling', 'Life sciences', 'Data Analyst', 'biomedical', 'SQL', 'Python']",2025-06-14 05:25:13
Product Data Management / Data Analyst,eClerx,0 - 1 years,Not Disclosed,['Coimbatore'],"Greetings and Wishes from eClerx,\n\nCoimbatore | Full time\n\neClerx is hiring a Product Data Management Analyst who will work within our Product Data Management team to help our customers enhance online product data quality for Electrical, Mechanical & Electronics products. It will also involve creating technical specifications and product descriptions for online presentation. The candidate will also be working on consultancy projects on redesigning e-commerce customers website taxonomy and navigation.",,,,"['Communication Skills', 'Engineering', 'Technical Skills']",2025-06-14 05:25:15
Apprentice Analyst-Data Analytics (Only Be Mechanical or Electrical),eClerx,0 - 3 years,Not Disclosed,"['Thane', 'Navi Mumbai', 'Mumbai (All Areas)']","eClerx is hiring a Product Data Management Analyst who will work within our Product Data Management team to help our customers enhance online product data quality for Electrical, Mechanical & Electronics products. It will also involve creating technical specifications and product descriptions for online presentation. The candidate will also be working on consultancy projects on redesigning e-commerce customers website taxonomy and navigation.\nThe ideal candidate must possess strong communication skills, with an ability to listen and comprehend information and share it with all the key stakeholders, highlighting opportunities for improvement and concerns, if any. He/she must be able to work collaboratively with teams to execute tasks within defined timeframes while maintaining high-quality standards and superior service levels. The ability to take proactive actions and willingness to take up responsibility beyond the assigned work area is a plus.",,,,"['BE Mechanical', 'BE Electrical', 'Data Management', 'EXTC', 'Excel', 'Product data management', 'Data Analyst', 'Data Analytics', 'Freshers']",2025-06-14 05:25:18
Data Analyst,2070Health,2 - 3 years,10-12 Lacs P.A.,['Mumbai (All Areas)'],"Data Analyst to drive data-led decisions in healthcare. Build dashboards, manage CRM and billing data, generate insights, and support business reviews. Ideal for data-driven problem solvers with 2–3 yrs of experience.",Industry Type: Medical Services / Hospital (Diagnostics),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Bi Tools', 'Advanced Excel', 'SQL', 'Critical Thinking', 'Communication Skills']",2025-06-14 05:25:20
Senior Analyst-Data Analysis,Tesco Plc,3 - 8 years,Not Disclosed,['Bengaluru'],"Senior Analyst-Data Analysis\nBack to job search results\nTesco India Bengaluru, Karnataka, India Hybrid Full-Time Permanent Apply by 30-Jun-2025\nAbout the role\nAnalyse complex datasets and make it consumable using visual storytelling and visualization tools such as reports and dashboards built using approved tools (Tableau, PyDash)\nWhat is in it for you\nAt Tesco, we are committed to providing the best for you.\nAs a result, our colleagues enjoy a unique, differentiated, market- competitive reward package, based on the current industry practices, for all the work they put into serving our customers, communities and planet a little better every day.\nOur Tesco Rewards framework consists of pillars - Fixed Pay, Incentives, and Benefits.\nTotal Rewards offered at Tesco is determined by four principles - simple, fair, competitive, and sustainable.\nSalary - Your fixed pay is the guaranteed pay as per your contract of employment.\nPerformance Bonus - Opportunity to earn additional compensation bonus based on performance, paid annually\nLeave & Time-off - Colleagues are entitled to 30 days of leave (18 days of Earned Leave, 12 days of Casual/Sick Leave) and 10 national and festival holidays, as per the company s policy.\nMaking Retirement Tension-FreeSalary - In addition to Statutory retirement beneets, Tesco enables colleagues to participate in voluntary programmes like NPS and VPF.\nHealth is Wealth - Tesco promotes programmes that support a culture of health and wellness including insurance for colleagues and their family. Our medical insurance provides coverage for dependents including parents or in-laws.\nMental Wellbeing - We offer mental health support through self-help tools, community groups, ally networks, face-to-face counselling, and more for both colleagues and dependents.\nFinancial Wellbeing - Through our financial literacy partner, we offer one-to-one financial coaching at discounted rates, as well as salary advances on earned wages upon request.\nSave As You Earn (SAYE) - Our SAYE programme allows colleagues to transition from being employees to Tesco shareholders through a structured 3-year savings plan.\nPhysical Wellbeing - Our green campus promotes physical wellbeing with facilities that include a cricket pitch, football field, badminton and volleyball courts, along with indoor games, encouraging a healthier lifestyle.\nYou will be responsible for\nUnderstands business needs and in depth understanding of Tesco processes\n- Builds on Tesco processes and knowledge by applying CI tools and techniques.\n- Responsible for completing tasks and transactions within agreed KPIs\n- Solves problems by analyzing solution alternatives\n-Engage with market leaders to understand problems to be solved, translate the business problems to analytical problems, taking ownership of specified analysis and translate the answers back to decision makers in business\n- Manipulating, analyzing and synthesizing large complex data sets using different sources and ensuring data quality and integrity\n- Think beyond the ask and develop analysis and reports that will contribute beyond basic asks\n- Accountable for high quality and timely completion of specified work deliverables and ad-hocs business asks\n- Write codes that are well detailed, structured, and compute efficient\n- Drive value delivery through efficiency gain by automating repeatable tasks, report creation or dashboard refresh\n- Collaborate with colleagues to craft, implement and measure consumption of analysis, reports and dashboards\n- Contribute to development of knowledge assets and reusable modules on GitHub/Wiki\n- Understands business needs and in depth understanding of Tesco processes\n- Responsible for completing tasks and transactions within agreed metrics\n- Experience in handling high volume, time pressured business asks and ad-hocs requests\nYou will need\n2-4 years experience preferred in analysis oriented delivery in any one of domains like retail, cpg, telecom or hospitality and for one of the following functional areas - marketing, supply chain, customer, space range and merchandising, operations, finance or digital will be preferred\nStrong understanding of Business Decisions, Skills to develop visualizations, self-service dashboards and reports using Tableau & Basic Statistical Concepts (Correlation Analysis and Hyp. Testing), Good Skills to analyze data using Adv Excel, Adv SQL, Hive, Phython, Data Warehousing concepts (Hadoop, Teradata), Automation using alteryx, python\n\nAbout us\nTesco in Bengaluru is a multi-disciplinary team serving our customers, communities, and planet a little better every day across markets. Our goal is to create a sustainable competitive advantage for Tesco by standardising processes, delivering cost savings, enabling agility through technological solutions, and empowering our colleagues to do even more for our customers. With cross-functional expertise, a wide network of teams, and strong governance, we reduce complexity, thereby offering high-quality services for our customers.\nTesco in Bengaluru, established in 2004 to enable standardisation and build centralised capabilities and competencies, makes the experience better for our millions of customers worldwide and simpler for over 3,30,000 colleagues.\nTesco Business Solutions:\nEstablished in 2017, Tesco Business Solutions (TBS) has evolved from a single entity traditional shared services in Bengaluru, India (from 2004) to a global, purpose-driven solutions-focused organisation. TBS is committed to driving scale at speed and delivering value to the Tesco Group through the power of decision science. With over 4,400 highly skilled colleagues globally, TBS supports markets and business units across four locations in the UK, India, Hungary, and the Republic of Ireland. The organisation underpins everything that the Tesco Group does, bringing innovation, a solutions mindset, and agility to its operations and support functions, building winning partnerships across the business. TBSs focus is on adding value and creating impactful outcomes that shape the future of the business. TBS creates a sustainable competitive advantage for the Tesco Group by becoming the partner of choice for talent, transformation, and value creation\nApply",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Telecom', 'Automation', 'Data analysis', 'Analytical', 'Data quality', 'Teradata', 'Business solutions', 'SQL', 'Python']",2025-06-14 05:25:22
Senior Associate Director - Data Analyst,KPMG India,6 - 10 years,Not Disclosed,['Mumbai'],"KPMG India is looking for Senior Associate Director - Data Analyst to join our dynamic team and embark on a rewarding career journey\nManaging master data, including creation, updates, and deletion.\nManaging users and user roles.\nProvide quality assurance of imported data, working with quality assurance analysts if necessary.\nCommissioning and decommissioning of data sets.\nProcessing confidential data and information according to guidelines.\nHelping develop reports and analysis.\nManaging and designing the reporting environment, including data sources, security, and metadata.\nSupporting the data warehouse in identifying and revising reporting requirements.\nSupporting initiatives for data integrity and normalization.\nAssessing tests and implementing new or upgraded software and assisting with strategic decisions on new systems.\nGenerating reports from single or multiple systems.\nTroubleshooting the reporting database environment and reports.\nEvaluating changes and updates to source production systems.\nTraining end-users on new reports and dashboards.\nProviding technical expertise in data storage structures, data mining, and data cleansing.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent",['Senior Associate Director - Data Analyst'],2025-06-14 05:25:24
Freelance Online Data Analyst - Odia (IN),TELUS Digital,0 - 5 years,Not Disclosed,[],Job description\nAre you a detail-oriented individual with a passion for research and a good understanding of national and local geography? This freelance opportunity allows you to work at your own pace and from the comfort of your own home.\n\n\nA Day in the Life of an Online Data Analyst:,,,,"['Artificial Intelligence', 'Freelancing', 'Information Technology', 'Data Analytics']",2025-06-14 05:25:26
"Graduate Trainee, Business Insights Services Data Analyst",Calix,No fixed duration,Unpaid,['Bengaluru'],"Calix provides the cloud, software platforms, systems and services required for communications service providers to simplify their businesses, excite their subscribers and grow their value.\nBusiness Insights Services Intern Data Analyst\nDescription\nThis position is based in Bengaluru, India.\nAre you a business data analyst who wants to make a broad impact? Do you excel in telling data stories and creating compelling data visuals designed for decision makers? Business Insights Services will partner directly with Calix customers to leverage their business data to answer specific questions or solve unique business challenges. As an intern, you will assist in designing, prototyping, and managing an expanding catalog of defined business engagements leveraging a customer s data that results in a detailed action plan with compelling data visuals and actionable recommendations. You will support our success engagement experts in delivering Business Insights Services consultations to senior leadership audiences for our most valued customers.\nResponsibilities:\nSupport the technical design, development, and delivery of an expanding catalog of defined business engagements leveraging a customer s business data.\nAssist in recommending and implementing data analytics tools and frameworks.\nHelp with overall data governance, preparing and warehousing, as well as reporting and advanced delivery.\nContinuously improve our analytic processes and adopt relevant new technology.\nInnovate new concepts of how we can use analytics to drive positive business outcomes for Calix customers.\nDocument best practices in data visualization, data analysis, and user training.\nRequired Qualifications:\nStrong written and verbal communication skills combined with the ability to build meaningful and influential relationships with a broad range of stakeholders.\nGood communicator & coordinator with a design thinking approach to solving problems.\nAbility to translate complex needs into appropriate solutions while remaining sensitive to the complexities of the business.\nTechnically proficient with SQL and client reporting tools such as Excel, Power BI, or similar.\nProficient scripting coding skills.\nDetail-oriented with the ability to analyze and interpret data at very precise and low levels, but always with an eye for the bigger strategic picture and goals.\nAbility to work well within a team and collaborate with external groups.\nFlexibility/adaptability with a can-do attitude, and an ability to react quickly to identified opportunities.\nGraduate degree in Data Analytics and/or Data Science.\nAppreciation for a culture of not taking ourselves too seriously, while taking our work very seriously.\nKnowledge of a wide range of data models, algorithms, and statistical analysis techniques.\nExcellent data visual design thinking that chooses the right data visual for the audience and tells the data story clearly.\nAble to adapt to, and lead through change, driving clarity through ambiguity.\nStrong project management and program delivery.\nCollaborative and consultative work styl",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Coding', 'Project management', 'Program delivery', 'data governance', 'Data analytics', 'data visualization', 'Reporting tools', 'SQL', 'Visual Design']",2025-06-14 05:25:28
Data Analyst / Data Analyst Manager (Immediate Joiners),Millennium Organisation,1 - 4 years,3-6 Lacs P.A.,['Mumbai (All Areas)'],"Analyze data to find trends and insights\nCreate easy-to-understand reports and dashboards\nHelp teams make better decisions using data\nProficient in Advance Excel, Power BI and SQL\nEnsure data is accurate and up to data\nCall HR Drashti - 8169887699\n\nRequired Candidate profile\nExperience in data analysis, reporting and insights\n1+ years of relevant experience\nStrong leadership skills\nMumbai candidates preferred\nImmediate joiners required",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Advanced Excel', 'Data Analysis', 'Business Strategy', 'Sales Analysis', 'Team Handling', 'Team Coordination', 'Data Management', 'Formulas', 'Powerpoint', 'MIS Reporting', 'Leadership Skills', 'SQL', 'Business Planning', 'Marketing Operations', 'Team Leading', 'Dashboards', 'Operations Management']",2025-06-14 05:25:31
"Data Analyst - Urdu Speaker (No Experience Required, India)",Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Urdu.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Urdu', 'Data Analysis', 'Research Analysis', 'Data Interpretation', 'Analytical', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-14 05:25:33
Data Analyst - Odia Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\n\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\n\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\n\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Odia.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['Oriya', 'Data Analysis', 'Odia', 'English', 'Data Interpretation', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-14 05:25:35
Data Analyst (1yr+ exp) - Mumbai,Aeke Consultancy,1 - 2 years,1.5-2.25 Lacs P.A.,['Mumbai (All Areas)'],"Hiring: Data Analyst (Bcom candidates only)\nSeeking candidates with 1+ year experience in Power BI, Excel, and Macros.\nBudget: 18,000/month\nLocation: Mumbai\nKindly share your CV via WhatsApp at 9076492644. Calls will not be entertained.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Analysis', 'Excel Macros']",2025-06-14 05:25:37
Data Analyst,BP INCORPORATE INTERNATIONAL.,1 - 3 years,Not Disclosed,['Pune'],"Grade IResponsible for supporting the delivery of business analysis and consulting processes and procedures for the defined specialism using basic technical capabilities, developing working relationships to provide support with queries, issues and ad-hoc requests and assisting with quality assurance services. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.\nEntity:\nTechnology\n\nITS Group\n\nYou will work with\nBeing part of a digital delivery data group supporting bp Solutions, you will apply your domain knowledge and familiarity with domain data processes to support the organisation. Part of bp s Production Operations business, bp Solutions has hubs in London, Pune, and Houston. The data team provides daily operational data management, data engineering and analytics support to this organisation across a broad range of activity from facilities and subsea engineering to logistics.\nLet me tell you about the role\nA data analyst collects, processes, and performs analyses on a variety of datasets. Their key responsibilities include interpreting sophisticated data sets to identify trends and patterns, using analytical tools and methods to generate actionable insights, and crafting visualizations and reports to communicate those insights and recommendations to support decision-making. Data analysts collaborate closely with business domain collaborators to understand their data analysis needs, ensure data accuracy, write and recommend data-driven solutions and tackle value impacting business problems.\nYou might be a good fit for this role if you:\nHave strong domain knowledge in at least one of; facilities or subsea engineering, maintenance and reliability, operations, logistics.\nStrong analytical skills and proven capability in applying analytical techniques and Python scripting to solve practical problems.\nAre curious, and keen to apply new technologies, trends methods to improve existing standards and the capabilities of the Subsurface community.\nAre well organized and self-motivated, you balance proactive and reactive approaches and across multiple priorities to complete tasks on time.\nApply judgment and common sense - you use insight and good judgment to inform actions and respond to situations as they arise.\nWhat you will deliver\nBe a link between asset teams and Technology, combining in-depth understanding of one or more relevant domains with data analytics skills\nProvide actionable, data-driven insights by combining deep statistical skills, data manipulation capabilities and business insight.\nProactively identify impactful opportunities and autonomously complete data analysis.\nYou apply existing data analytics strategies relevant to your immediate scope.\nClean, pre-process and analyse both structured and unstructured data\nDevelop data visualisations to analyse and interrogate broad datasets (e.g. with tools such as Microsoft PowerBI, Spotfire or similar).\nPresent results to peers and senior management, influencing decision making\nWhat you will need to be successful (experience and qualifications)\nEssential\nMSc or equivalent experience in a quantitative field, preferably statistics.\nhave strong domain knowledge in at least one of; facilities or subsea engineering, maintenance and reliability, operations, logistics.\nHands-on experience carrying out data analytics, data mining and product analytics in complex, fast-paced environments.\nApplied knowledge of data analytics and data pipelining tools and approaches across all data lifecycle stages.\nDeep understanding of a few and a high-level understanding of several commonly available statistics approaches.\nAdvanced SQL knowledge.\nAdvanced scripting experience in R or python.\nAbility to write and maintain moderately sophisticated data pipelines.\nCustomer-centric and pragmatic approach. Focus on value delivery and swift execution, while maintaining attention to detail.\nGood communication and social skills, with the ability to effectively communicate ideas, expectations, and feedback to team members, partners, and customers. Foster collaboration and teamwork\nDesired\nAdvanced analytics degree.\nExperience applying analytics to support engineering turnarounds\nExperience with big data technologies (e.g. Hadoop, Hive, and Spark) is a plus.\nAbout bp\nOur purpose is to deliver energy to the world, today and tomorrow. For over 100 years, bp has focused on discovering, developing, and producing oil and gas in the nations where we operate. We are one of the few companies globally that can provide governments and customers with an integrated energy offering. Delivering our strategy sustainably is fundamental to achieving our ambition to be a net zero company by 2050 or sooner!\n\nTravel Requirement\nUp to 10% travel should be expected with this role\n\nRelocation Assistance:\nThis role is eligible for relocation within country\n\nRemote Type:\nThis position is a hybrid of office/remote working\n\nSkills:",Industry Type: Oil & Gas,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Data management', 'Business analysis', 'Consulting', 'microsoft', 'Data mining', 'Analytics', 'SQL', 'Logistics']",2025-06-14 05:25:39
Senior Data Research Analyst,Morningstar,0 - 7 years,Not Disclosed,['Mumbai'],"As a Senior Data Research Analyst , you will be responsible for acquiring and validating portfolio holdings data from various vendor sources. Your core responsibilities will involve standardizing this data into agreed formats using internal collection tools and resolving exceptions through thorough validation processes.\nWorking within the Portfolio Data Team, your role will focus on ensuring the accuracy and completeness of portfolio information, which is critical for downstream analytics and reporting. You will collaborate closely with leadership and cross-functional teams to support strategic goals, enhance operational performance, and contribute to the achievement of key KPIs.\nShift: UK/AU /US\nRoles Responsibilities:\nActively collect managed investment data using Morningstar collection systems, and ensure data timelines, completeness and accuracy to meet business goals.\nManage relationships between Morningstar and Asset Management companies, insurance companies and other data vendors.\nPartner with quality assurance, products, and technical departments to resolve clients data issues timely and effectively.\nP articipat e in the initiative s focused on consolidating global data collection platforms and supporting database integration projects.\nEstablish and achieve the set O bjectives K ey R esults (OKRs) with the direction of team lead.\nMonitor, analyze and execute summary reports including an investigation of potential data error to c ontinuously improve data collection and quality assurance process using L ean S ix S igma tools.\nActively discover and raise issues in work (including system, process, and collection methodology ) and propose enhancement suggestions to further improve system functionality, process efficiency and data quality.\nParticipate in data and process related projects such as industry/market research, market expansion, process certification, new product development support, etc.\nFacilitate cross-team projects to implement approved solutions based on priority and impact .\nDemonstrate a high sense of ownership of the process , u nderstand roles responsibilities by act ing as a process trainer and mentor\nRequirements:\n> 3 years experience in finance domain , w ith emphasis on collection systems and methodologies, senior data research analyst role or above .\nFund Portfolio experience would be preferred\nG ood command i n MS Office (Excel, PowerPoint etc.); advanced users preferred. SQL, Macro or Python and machine learning will be a plus.\nShould be critical thinker and should possess good communication skill .\nShould be equipped with understanding of data competencies like data content expertise , data analysis etc.\nStrong analytical, problem-solving capabilities, and excellent communication written as well as verbal reporting skills.\nShould be a good team player with good learning ability and equipped with self-motivation in an independent, fast-paced work environment.\nAbility to exercise control over the planned activities like training / mentoring new hires, doing quality checks etc .\nAble to work under tight deadlines and handle pressure during peak seasons.\nGood project management skills with proven track record of working on and delivering projects independently.\nRemote team working experience is a plus .\nFlexibility to work in shifts.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Analytical', 'Data collection', 'Market research', 'Data quality', 'Asset management', 'Operations', 'Analytics', 'SQL']",2025-06-14 05:25:42
Business Data Analyst,KGK Group,5 - 10 years,Not Disclosed,"['Hong Kong', 'Mumbai (All Areas)']","Position Title: Business Data Intelligence\nReports To: Functional Head\nJob Location: Jaipur / Mumbai / Hong Kong\nEmployment Type: Full-Time\nSalary: Best in Industry\n\n\nJob Summary:\nThe Data Analyst is responsible for collecting, analysing, and interpreting large datasets to support business decision-making. This role requires the ability to generate actionable insights, build data reports, and work with cross-functional teams to optimize business performance. The Data Analyst will collaborate closely with other departments to understand their data needs and deliver data-driven solutions that align with the company's strategic objectives.\n\nKey Responsibilities:\nData Collection & Management:\nCollect and aggregate data from various sources, including databases, spreadsheets, people and external platforms.\nEnsure data integrity and accuracy by organizing, and validating datasets.\nDevelop and maintain databases or data information systems as necessary.\nData Analysis:\nPerform detailed data analysis using statistical techniques to identify patterns, trends, and insights.\nUtilize data visualization tools to present data in a clear and understandable way for non-technical stakeholders.\nAnalyse large and complex datasets to solve business problems and inform decisions.\nReporting & Visualization:\nCreate reports, dashboards, and visualizations to track key performance indicators (KPIs) and business metrics.\nPresent findings to key stakeholders, making recommendations based on data insights.\nProvide ad-hoc reports and data queries as needed by different teams within the organization.\nCollaboration with Teams:\nWork closely with business units (Sales, finance, operations, etc.) to collect data on timely basis.\nWork closely with the existing MIS team to understand, analyse and interpret the data.\nHelp design and implement new analytical tools and processes that improve data-driven decision-making across the company.\nPredictive Analytics & Forecasting:\nUse statistical models and machine learning techniques to forecast trends and predict future outcomes.\nAssist in developing predictive models to support strategic planning and operational decisions.\nData Governance & Compliance:\nEnsure adherence to data privacy regulations and best practices in data security.\nWork with legal and compliance teams to ensure data is used ethically and in accordance with company policies.\nProcess Improvement:\nIdentify opportunities for process improvement through data-driven insights.\nRecommend data collection methods and tools to enhance the quality and efficiency of business processes.\nData Quality Assurance:\nRegularly review and assess the quality of data.\nImplement processes for ongoing data validation and verification to minimize errors.\n\nQualifications:\nEducation: Bachelors/Masters degree in Data Science, Computer Science, or a related field.\nExperience: 3 - 6+ years of experience in data analysis or a related field.\nSkills:\nExperience with statistical analysis and predictive modelling.\nAbility to interpret complex data sets and translate findings into actionable business insights.\nStrong communication and presentation skills, capable of conveying data findings to both technical and non-technical audiences.\nAdd On:\nStrong proficiency in data analysis tools such as Excel, SQL, Python, R, and data visualization tools like Power BI, Tableau or Oracle BI.Knowledge of databases and experience with relational databases (e.g., MySQL, PostgreSQL).",Industry Type: Gems & Jewellery,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['stackholder', 'Power Bi', 'Tableau', 'Business Intelligence', 'Data Visualization', 'Business Insights', 'Dashboards', 'Dashboard Development', 'SQL']",2025-06-14 05:25:44
Data Governance Analyst,HCLTech,4 - 6 years,Not Disclosed,"['Noida', 'Vijayawada', 'Chennai']","Key Responsibilities:\nUnderstand all of our data definitions and nuances (e.g., attribution window)\nMaintain and update glossary; Advise various internal stakeholders\nConsult data visualization team and analysts on what data to use for new reports and analyses\nRecommend development or enhancement of datasets for reporting and analyses questions\nDevelop and implement data governance policies and procedures to ensure data quality, availability, and integrity.",,,,"['Data Management', 'ETL', 'Data Governance', 'SQL', 'Python', 'Data Engineering', 'Data Modeling', 'Data Warehousing', 'Data Governance Analyst']",2025-06-14 05:25:47
Data Analyst-Having Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Analyst\n\nLocation: Bangalore\nExperience: 8 - 15 Yrs\nType: Full-time\n\nRole Overview\n\nWe are seeking a skilled Data Analyst to support our platform powering operational intelligence across airports and similar sectors. The ideal candidate will have experience working with time-series datasets and operational information to uncover trends, anomalies, and actionable insights. This role will work closely with data engineers, ML teams, and domain experts to turn raw data into meaningful intelligence for business and operations stakeholders.\n\nKey Responsibilities\n\nAnalyze time-series and sensor data from various sources\nDevelop and maintain dashboards, reports, and visualizations to communicate key metrics and trends.\nCorrelate data from multiple systems (vision, weather, flight schedules, etc) to provide holistic insights.\nCollaborate with AI/ML teams to support model validation and interpret AI-driven alerts (e.g., anomalies, intrusion detection).\nPrepare and clean datasets for analysis and modeling; ensure data quality and consistency.\nWork with stakeholders to understand reporting needs and deliver business-oriented outputs.\n\n\nQualifications & Required Skills\n\nBachelors or Masters degree in Data Science, Statistics, Computer Science, Engineering, or a related field.\n5+ years of experience in a data analyst role, ideally in a technical/industrial domain.\nStrong SQL skills and proficiency with BI/reporting tools (e.g., Power BI, Tableau, Grafana).\nHands-on experience analyzing structured and semi-structured data (JSON, CSV, time-series).\nProficiency in Python or R for data manipulation and exploratory analysis.\nUnderstanding of time-series databases or streaming data (e.g., InfluxDB, Kafka, Kinesis).\nSolid grasp of statistical analysis and anomaly detection methods.\nExperience working with data from industrial systems or large-scale physical infrastructure.\n\n\nGood-to-Have Skills\n\nDomain experience in airports, smart infrastructure, transportation, or logistics.\nFamiliarity with data platforms (Snowflake, BigQuery, Custom-built using open-source).\nExposure to tools like Airflow, Jupyter Notebooks and data quality frameworks.\nBasic understanding of AI/ML workflows and data preparation requirements.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Kafka', 'SQL', 'airports', 'InfluxDB', 'Airflow', 'structured Data', 'time-series', 'JSON', 'Tableau', 'Grafana', 'R', 'AI/ML', 'Kinesis', 'Snowflake', 'time-series databases', 'Data Preparation', 'Python', 'smart infrastructure', 'BigQuery', 'streaming data', 'Power BI', 'CSV', 'transportation', 'logistic', 'reporting tools']",2025-06-14 05:25:49
Data Analyst,Innovature Software Labs,2 - 4 years,Not Disclosed,"['Kochi', 'Chennai']",">\nJob Category: Software\nJob Type: Full Time\nJob Location: Infopark - Kochi\nExperience: 2 - 4 Years\nDesignation: Data Analyst\nKey Responsibilities\nAnalyze large volumes of analytical data (sales, customer, product) to identify patterns, trends, and insights.\nDevelop and maintain data reports and dashboards using business intelligence tools (e.g., Tableau, Power BI, etc.)\nCollaborate with business teams to understand key business objectives and data needs.\nAnalyze customer behavior, product usage, and historical purchase data to identify cross-selling opportunities.\nEnsure data models and structures are well-designed to facilitate analysis and reporting.\nAct as a bridge between data engineers and business stakeholders , ensuring data is aligned with business needs.\nSkill set\nProficient in data engineering tools and languages such as Python, SQL, and Java.\nStrong knowledge of business intelligence (BI) tools such as Tableau, Power BI or similar for creating reports and dashboards.\nAbility to work with databases(SQL NoSQL) and perform complex data queries.\nFamiliarity with data wrangling, ETL processes and data cleaning techniques.\nClear understanding of data warehousing cloud based analytics .\nAbility to apply data insights to influence marketing strategies, sales tactics, and product offerings.\nExperience\n2-4 years of experience in a data analyst role with experience in analyzing customer data, sales data, and product data.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Usage', 'Sales', 'Analytical', 'power bi', 'Data Analyst', 'Business intelligence', 'Data warehousing', 'Analytics', 'SQL', 'Python']",2025-06-14 05:25:51
Data Analyst,Vishanz Business Services,4 - 8 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","We are looking for ""Data Analyst"" with Minimum 4 years experience\nContact- Yashra (95001 81847)\n\nRequired Candidate profile\nHands-on Exp in Data Analyst’s role, Python, SQL, Power BI. Pref. Business domains: Telecom/CPG/Life Science\nAdvanced SQL with experience in writing optimized queries for large datasets.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Analysis', 'Python', 'SQL', 'Power Bi']",2025-06-14 05:25:53
"Senior Python Developer (Machine Learning,Data Analysis,Visualization)",Synechron,3 - 5 years,Not Disclosed,"['Pune', 'Hinjewadi']","Software Requirements\nRequired Skills:\nProficiency in Python (version 3.6+) with experience in data analysis, manipulation, and scripting\nKnowledge of SQL for data extraction, transformation, and database querying\nExperience with data visualization tools such as PowerBI, Tableau, or QlikView\nFamiliarity with AI and Machine Learning frameworks such as TensorFlow, Keras, PyTorch, or equivalent",,,,"['Python', 'PostgreSQL', 'MySQL', 'Data Analysis', 'Data Visualization', 'Oracle', 'ETL', 'Machine Learning']",2025-06-14 05:25:55
Senior Data Analyst,AstraZeneca India Pvt. Ltd,4 - 7 years,Not Disclosed,"['Chennai', 'Bengaluru']","Job Title: Senior Data Analyst\nCareer Level: D1\nIntroduction to role\nAre you ready to lead the charge in data management excellence? As a Senior Data Analyst, youll be instrumental in driving operational and technical proficiency for the US BBU. Your role is crucial in ensuring data accuracy and efficiency, supporting key business functions to achieve strategic goals. Youll bridge the gap between business collaborators and IT, translating sophisticated needs into actionable data solutions that enhance decision-making. Your analytical prowess will guide the development of innovative data products, influencing business strategy and fostering collaboration across teams. With a focus on leadership, youll mentor a team of data professionals, encouraging continuous improvement and innovation. Are you prepared to deliver clear, actionable insights and drive business transformation?\nAccountabilities\nProvide operational and technical support for US BBU data management activities - data quality management, business process workflows, and data management needs for downstream applications and tools.\nFix and triage operational issues related to data processing, business user queries, data investigation, and ad-hoc analytics.\nPerform data validation, reconciliation, and basic ad-hoc analyses to support business teams.\nAct as a liaison between Commercial/Medical collaborators and IT for customer concerns and issue resolution.\nAssist in handling access, user roles, and updates across platforms like Sharp.\nEssential Skills/Experience\nQuantitative bachelor s degree from an accredited college or university is required in one of the following or related fields: Engineering, Operations Research, Management Science, Economics, Statistics, Applied Math, Computer Science or Data Science. An advanced degree is preferred (Masters, MBA or PhD).\nProficient in PBI, PowerApps [development & fix], SQL, Python, Databricks, and AWS S3 operations.\nStrong understanding of data governance, privacy standards, and operational best practices.\nExcellent communication and influencing skills with consistent record to develop and efficiently.\nExperience working in a business support or operational data management environment.\nOrganization and time management skills.\nDefine and document detailed user stories, acceptance criteria, and non-functional requirements for the data products.\nEngage with cross-functional collaborators to understand their requirements, difficulties, and expectations.\nAdvocate for a user-centric design approach, ensuring that the data products are intuitive, accessible, and meet the needs of the target users.\nCollaborate with the development team to plan and implement agile sprints, ensuring timely delivery of high-quality features.\nSupervise the data product ecosystem s Business architecture, design, and development.\nSupervise industry trends and standard processes in data product development and management.\nCollaborate closely with business collaborators to understand their requirements and translate them into technical solutions.\nSupervise the end-to-end development lifecycle of the data products, from conceptualisation to deployment.\nStrong leadership and communication skills with demonstrated ability to work collaboratively with a significant number of business leaders and cross-functional business partners.\nPresent succinct, compelling reviews of independently developed analyses infused with insight and business implications/actions to be considered.\nStrategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team.\nStrong organizational skills and time management; ability to handle diverse range of simultaneous projects.\nDesirable Skills/Experience\nKnowledge of AZ brand and Science.\nExperience of working with multiple 3rd party providers, including information technology partners.\nStrategic and critical thinking with the ability to engage, build and maintain credibility with Commercial Leadership Team.\nUnderstanding of US BBU commercial and medical business functions.\nExperience with Sharp [Internal AZ platform] administration, Power Apps development or troubleshooting.\nWhen we put unexpected teams in the same room, we ignite ambitious thinking with the power to encourage life-changing medicines. In-person working gives us the platform we need to connect, work at pace and challenge perceptions. Thats why we work, on average, a minimum of three days per week from the office. But that doesnt mean were not flexible. We balance the expectation of being in the office while respecting individual flexibility. Join us in our outstanding and ambitious world.\nAt AstraZeneca, youll be part of a versatile distributed team that powers our enterprise to better serve patients every day. We demonstrate exciting new technology and digital innovations to accelerate our evolution. With an ambitious spirit that keeps us ahead of the rest, we apply creativity to every task we do. Our fast-paced environment grows with collaboration among bright minds who support each other while pushing forward. Here youll find countless opportunities to build an outstanding reputation while being rewarded for your successes.\nReady to make an impact? Apply now to join our dynamic team!\n11-Jun-2025\n19-Jun-2025",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Business transformation', 'Data management', 'Reconciliation', 'Data processing', 'Troubleshooting', 'Technical support', 'Analytics', 'Recruitment', 'SQL']",2025-06-14 05:25:58
Intern - Data Management & Analysis,Transasia Bio Medicals,0 - 1 years,Not Disclosed,"['Mumbai( Chandivali )', 'Mumbai Suburban']","Assist in maintaining and updating large data sets in Excel, ensuring accuracy and consistency. \nOrganize and clean data, ensuring it is structured for easy analysis and reporting. \nUtilize advanced Excel formulas to analyze data efficiently. \nApply conditional formatting and logical functions to automate repetitive tasks and improve data readability. \nUtilize PivotTables, Power Query, and Power Pivot to aggregate and analyze complex data. \nCreate and update visually appealing and insightful charts, graphs, and dashboards to represent data trends and key performance metrics.\n Collaborate with team members to understand data requirements and deliver on tasks related to reporting and analysis. \nProvide general support to the team in Excel-related tasks and projects.\n\nInterested candidates please mail their CVs at m.sneha@transasia.co.in",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Advanced Excel', 'Pivot Table', 'VLOOKUP']",2025-06-14 05:26:00
Associate Healthcare Research & Data Analyst-1,Clarivate,1 - 3 years,Not Disclosed,['Bengaluru'],"Job Responsibilities:\nProduces or updates sections of large, complex projects or produces small projects with minimal oversight .\nProduces routine and templated descriptions and summaries of a factual nature with minimal oversight .\nDrafts client responses for simple requests in a timely manner .",,,,"['Training', 'Data modeling', 'Client support', 'Market research', 'Healthcare', 'Life sciences', 'Data analytics', 'Data Analyst', 'Analyst 1', 'Forecasting']",2025-06-14 05:26:02
Financial Data Analyst,Moody's Analytics,1 - 5 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\nPrepare a variety of discrete credit process inputs, perform preliminary analyses to identify trends in data, and apply reasoning to the completed work product.\nPerform financial statement analysis using accounting and finance principles to read and understand financial statements and other disclosures related to debt issuers performance.\nApply Moodys relevant methodology standards and requirements to financial data and make appropriate adjustments.\nCreate a variety of standard initial work package items that serve as a starting point for the ratings and research process, including data, spreadsheets, charts, and tables.\nUpdate financial spreadsheets, charts, and tables.\nIdentify trends in data and apply reasoning to work being completed.\nInitiate/escalate deeper reviews when necessary.\nPrepare presentation materials for outreach activities.\nProvide support for RRS and R&R in monitoring/surveillance of Moody’s rated issuers.\nSupport monitoring of analyst credit portfolios through news and industry source tracking and highlight key issues requiring further analysis.\nUnderstand the application of accounting concepts on a particular entity.\nCreate documentation and provide guidance to support analysts and outsourcers.\nReview, adjust, and publish data to external market participants.\nSupport the credit administration process and perform other routine administrative and ad hoc tasks, as directed by RRS & R&R Teams.\nAbout the team: Our Research and Ratings Support team is responsible for providing a range of data and analytic services that contribute to the overall credit analysis functions performed by the MIS analytic teams. By joining our team, you will be part of exciting work in enhancing Moody's digital presence and improving customer engagement.\n\nPreferred candidate profile\n\nSolid accounting background with a strong focus on financial analysis.\nStrong organizational skills and attention to detail.\nAbility to work effectively in a team environment with matrix reporting.\nProficiency in MS Excel, Word, and PowerPoint.\nExcellent verbal, written communication, and interpersonal skills.\nAbility to adapt to a changing environment and prioritize tasks accordingly.\nEducation:\nPostgraduate degree in Accounting, Finance, Economics from a premium institution.\nCFA/FRM certification (preferred).",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['credit Analysis', 'Accounting', 'Ratio Analysis', 'Financial Analysis', 'Financial Statement Analysis']",2025-06-14 05:26:04
Data Analyst,Ornella Enterprises,0 - 2 years,2-4.25 Lacs P.A.,['Mumbai (All Areas)'],"A data analyst's primary role is to transform raw data into actionable insights that inform business decisions. They gather, clean, analyze, visualize, and present data to help businesses understand trends, identify patterns, and make informed choice",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Transformation', 'Data Manipulation', 'Data Analysis', 'Data Crunching', 'Data Reporting', 'Data Presentation', 'Data Research', 'Data Enrichment', 'Data Interpretation', 'Data Management', 'Data Extraction', 'Data Cleansing', 'Data Mining', 'Data Visualization', 'Data Processing', 'Data Analytics']",2025-06-14 05:26:07
Data Analysis - English Specialist Data Analysis - English Specialist,Zensar,2 - 6 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","Zensar Technologies is looking for Data Analysis - English Specialist Data Analysis - English Specialist to join our dynamic team and embark on a rewarding career journey A Data Analyst is responsible for collecting, analyzing, and interpreting data to identify trends, patterns, and insights that can drive informed business decisions\n\nThey play a crucial role in helping organizations understand their data, derive actionable insights, and optimize processes\n\nHere is a general job description for a Data Analyst:Data Collection and Preparation: Collect and gather relevant data from various sources, such as databases, spreadsheets, and external systems\n\nClean, validate, and transform the data to ensure accuracy and consistency\n\nData Analysis and Interpretation: Apply statistical techniques, data mining methods, and visualization tools to analyze large datasets\n\nIdentify trends, patterns, and correlations within the data and generate insights to support decision-making\n\nReporting and Visualization: Create clear and concise reports, dashboards, and visual representations of data using data visualization tools, such as Tableau, Power BI, or Excel\n\nPresent findings to stakeholders in a compelling and understandable manner\n\nData Quality and Integrity: Ensure data integrity and accuracy by conducting data validation, resolving discrepancies, and monitoring data quality\n\nImplement measures to maintain data privacy, security, and compliance with regulatory requirements\n\nBusiness Needs Assessment: Collaborate with stakeholders to understand their data analysis requirements and translate them into actionable analytics projects\n\nIdentify key performance indicators (KPIs) and metrics to measure business performance and success\n\nData-Driven Decision Making: Assist in making data-driven decisions by providing insights and recommendations based on data analysis\n\nSupport strategic planning, operational improvements, and process optimizations based on data-driven insights\n\nData Modeling and Forecasting: Develop and maintain data models, predictive models, and forecasting models to anticipate trends, predict outcomes, and support future planning\n\nUtilize statistical software, programming languages, or machine learning techniques as necessary\n\nContinuous Improvement: Stay updated with the latest data analysis techniques, tools, and trends\n\nContinuously improve data analysis processes, methodologies, and automation to enhance efficiency and effectiveness\n\nand Communication: Work closely with cross-functional teams, such as business analysts, data engineers, and data scientists, to align data analysis efforts with organizational goals\n\nCommunicate findings, insights, and recommendations to non-technical stakeholders in a clear and understandable manner\n\nDocumentation and Knowledge Sharing: Document data analysis methodologies, processes, and findings for future reference\n\nShare knowledge and best practices with the team to promote a culture of learning and data-driven decision-making\n\nSkills and Qualifications:Strong analytical skills with the ability to manipulate and analyze complex datasets\n\nProficiency in data analysis tools such as SQL, Excel, Python, R, or similar tools\n\nExperience with data visualization tools such as Tableau, Power BI, or similar tools\n\nKnowledge of statistical analysis techniques and methodologies\n\nFamiliarity with data modeling, predictive modeling, and forecasting techniques\n\nUnderstanding of database concepts and query languages\n\nExcellent attention to detail and problem-solving abilities\n\nStrong communication and presentation skills\n\nAbility to work independently and collaborate in a team environment\n\nFamiliarity with data privacy, security, and regulatory compliance\n\nPrior experience in data analysis or a related field is preferred",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Design engineering', 'Data analysis', 'Technology consulting', 'Focus', 'Agile', 'Conceptualization', 'Management']",2025-06-14 05:26:09
Data Analyst - Senior,FedEx,4 - 7 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nAct as a technical expert on complex and specialist subject(s).\nSupport management with the analysis, interpretation and application of complex information, contributing to the achievement of divisional and corporate goals. Supports or leads projects by applying area of expertise.\nLead and implement advanced analytical processes through data/text mining, model development, and prediction to enable informed business decisions.\nApply sound analytical expertise to examine structured and unstructured data from multiple disparate sources to provide insights and recommend high-quality solutions to leadership across levels.\nPlan initiatives from concept to execution with minimal supervision and communicate results to a broad range of audiences. Develops a superior understanding of pricing and revenue management through internal and external sources to creatively solve business problems and lead the team from concept to execution of projects.\nTypically uses data, statistical and quantitative analysis, modeling, and fact-based management to drive decision-making. Provides regular expert consultative advice to senior leadership.\nEffectively shares best practices and fosters knowledge sharing across teams. Provides crossteam and cross-org consultation and supports communities of practice excellence.\n\n\n\nPreferred candidate profile\n\nRelevant experience in analytics/consulting/informatics and statistics\nKey Skills - Data and Business Analytics, Advanced Statistics and Predictive Modelling,\nStakeholder Management, Project Management\nExperience in pricing and revenue management yield management, customer segmentation analytics, revenue impact analytics, etc. is a plus\nExposure to predictive analytics, ML/ AI techniques is an added advantage\nTools - Oracle, SQL Server, Teradata, SAS, Python, Tableau/PowerBI/Spotfire\nGood to have cloud computing, big data, Azure",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Business Insights', 'Python', 'SQL', 'Power Bi', 'Business Acumen', 'Tableau']",2025-06-14 05:26:11
Reference Data Analyst,JPMorgan Chase Bank,2 - 7 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","You are a strategic thinker passionate about driving solutions. You have found the right team.\nAs a Reference Data Analyst within our team, you will ensure all client queries and actioned and responded with utmost care and diligence. You will facilitate high quality and timely completion of all client requests. You must display great client service standards to define, analyse, to resolve inquiries and escalations. You should be able to closely manage day to day operations of the team/department, be able to proactively and strategically improve processes to ensure team members are high performing and meeting the firm wide quality standard.\nJob Responsibilities\nUnderstanding and implementation of custody initiations world overing custody and sub custody account opening and maintenance related activities.\nUnderstand the firm s requirements and various smart forms and articulate the same to end clients and guide them through completion.\nPartner with Clients, Sales, Solutions, Implementations, Client Service Managers and downstream teams for seamless completion of the assigned task.\nExhibit the highest standards of customer service to our internal and external customers (inclusive of confidentiality)\nCreate an effective and efficient team through continuous communication, timely feedback, and appropriate supervisory practices\nShowcase Process improvements and implement process changes as necessary\nRequired Qualifications, Capabilities, and skills\nYou must hold a Bachelor s Degree or above\nAt least 2 years experience in the Financial Services industry with a demonstrated track-record of delivery and/or relevant experience in custody domain.\nTechnical skills Microsoft Office including Excel, Word, and PowerPoint\nOutstanding client management, partnership building, leadership, and direct experience of dealing with stakeholders using effective communication, organization, prioritization and interpersonal skills\nAbility to identify risks, issues and successfully navigate through to completion\nSelf-reliance and willingness to ""own"" complications and creatively find solutions\nFoster and champion High Performance Culture where people are empowered to make decisions that affect their work/environment",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Interpersonal skills', 'Excel', 'Client servicing', 'Data Analyst', 'Customer service', 'MS Office', 'Powerpoint', 'Financial services', 'Client management', 'Downstream']",2025-06-14 05:26:14
Business Data Analyst,Lister Technologies Pvt Ltd,2 - 4 years,Not Disclosed,['Chennai'],"Roles and Responsibilities\nAccount Research Validation:\nAnalyze and validate new sales account and NASP requests, utilizing GCH, Salesforce CRM, DNB, SOS, and external research tools.\nEnsure requests meet the following criteria:\nNo duplicate accounts\nLegitimate business entities\nNot currently assigned to other sales team members across segments\nInitiate and manage DNB research inquiries.\nUpdate GCH and Salesforce records with validated information.\nData Integrity Maintenance:\nAssist with CLE (Customer Legal Entity) review, updates, and duplicate cleanup to maintain a single, accurate CLE per customer.\nSupport year-end sales city cleanup initiatives.\nChampion data quality best practices within the team.\nCollaboration Support:\nCollaborate with Sales and IT teams to report and resolve system issues.\nContribute to the development and implementation of GCH 2.0 in collaboration with the GCH team.\nAddress CLE inquiry requests.\nProvide support for OneView international sales requests.\nLV BAN Mapping Segmentation:\nReview LV BAN (Legal View Billing Account Number) mapping queues.\nLeverage GCH 2.0, DNB portal, CRM, Secretary of State data, and public records to research and establish accurate DUNS numbers.\nAdhere to GCH 2.0 and LV guidelines for segment, DUNS, and CLE determination.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Data Analyst', 'Billing', 'Legal', 'International sales', 'DNB', 'Data quality', 'data integrity', 'Research', 'CRM', 'Salesforce']",2025-06-14 05:26:16
"Data Analyst, Lead",Lam Research,5 - 10 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\nIn the Global Products Group, we are dedicated to excellence in the design and engineering of Lams etch and deposition products. We drive innovation to ensure our cutting-edge solutions are helping to solve the biggest challenges in the semiconductor industry.\nThe Impact You ll Make\nJoin Lam as an Operations Business Analyst, where youll spearhead process improvement initiatives. With your data expertise, you collect and analyze data through a range of Business Intelligence (BI) tools and apps, develop metrics, and identify root causes with data-driven indicators for future improvements. Organizing cross-functional project teams, you communicate team progress and survey best practices, showcasing your commitment to operational excellence at Lam.\nWhat You ll Do\nWho We re Looking For\nMinimum of 5 years of related experience with a Bachelor s degree; or 3 years and a Master s degree; or a PhD without experience; or equivalent work experience.\nPreferred Qualifications\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent","['Semiconductor', 'Operational excellence', 'Business Analyst', 'Process improvement', 'Flex', 'Data Analyst', 'Research', 'Business intelligence']",2025-06-14 05:26:18
Senior Data Management Analyst,Wells Fargo,4 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst in Corporate and Investment Banking ('CIB') to join the Applications Controls Execution & Services team, a subunit of the CIB Data Management organization.\nThe Application Controls Execution & Services team partners and supports CIB's wide network of Application Business Owners (ABO's) with identification, interpretation and/or implementation of governance processes or controls used to mitigate various compliance, operational, or data related risks.",,,,"['Data Management', 'Project Management', 'financial services management', 'operational risk', 'Analytics', 'business support', 'Business Analysis']",2025-06-14 05:26:21
Senior Data Analyst Bangalore,GSPANN,5 - 10 years,13-22.5 Lacs P.A.,['Bengaluru'],"Job Opportunity: Senior Data Analyst Bangalore\n\n\nLocation: Bangalore, India\n\n\nCompany: GSPANN Technologies\nApply: Send your resume to heena.ruchwani@gspann.com\n\n\nGSPANN is hiring a Senior Data Analyst with 57 years of experience to join our dynamic team in Bangalore!\n\n\nWhat Were Looking For:\n\nEducation:\nBachelor’s degree in Computer Science, MIS, or a related field\n\nExperience:\n5–7 years in data analysis, with a strong ability to translate business strategy into actionable insight\nAdvanced SQL expertise\nProficiency in Tableau, Power BI, or Domo\nExperience with AWS, Hive, Snowflake, Presto\nAbility to define and track KPIs across domains like Sales, Consumer Behavior, and Supply Chain\nStrong problem-solving skills and attention to detail\nExcellent communication and collaboration abilities\nExperience working in Agile environments\nRetail or eCommerce domain experience is a plus\n\nIf this sounds like the right fit for you, don’t wait—send your updated resume to heena.ruchwani@gspann.com today!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'SQL', 'Hive', 'Presto', 'Snowflake', 'Statistical Modeling', 'Data Visualization', 'Tableau', 'Data Analytics', 'AWS', 'Python']",2025-06-14 05:26:23
"Data Analyst, Program Lead",Lam Research,9 - 12 years,Not Disclosed,['Bengaluru'],"About LIDAS:\nLIDAS (Lam India Data Analytics and Sciences) team is responsible to provide best-in-class analytics solutions that help improve business decisions in Global Operations and other business sub-functions across Lam. This Organization, a Center of Excellence (CoE), consists of a high-performing team of experts who collaborate cross-functionally and provide analytics solutions to various business functions to suit their business needs. This team strives to improve the productivity & efficiency of business processes through business analytics, data science & automation projects. The resulting projects help accelerate businesses/stakeholders in decision-making by providing data insights. The team continuously develops the required technical skills and business acumen to help solve complex business problems & Use Cases in the semiconductor, manufacturing, and supply chain domains for the company.\nEligibility Criteria:\nYears of Experience : Minimum 9-12 years\nJob Experience: Experience with Power Platform (Power Apps, Power Automate & Power BI)\nExpert in Database and Data warehouse tech (Azure Synapse/ SQL Server/SAP HANA)\nData Analysis/Data Profiling/Data Visualization\nEducational : Bachelor s Degree: Math/Statistics/Operations Research/Computer Science\nMaster s Degree : Business Analytics (with a background in Computer Science)\nPrimary Responsibilities:\nAbility to interact closely with Business Stakeholder on understanding their business requirements and converting them into opportunity.\nLeading POCs to create break through technical solutions, performing exploratory and targeted data analyses.\nAbility to Manage and support existing applications and implementing the best practices on timely Manner.\nDesigns, Develops, and Tests Data Models to import data from source systems to meet Project requirements\nEffectively analyzes the heterogeneous source data and writes SQL scripts to integrate data from multiple data sources\nAnalyzes the results to generate actionable insights and presents the findings to the business users for informed decision making\nUnderstands business requirements and develops dashboards to meet business needs\nAdapts to the changing business requirements and supports the development and implementation of best-known methods with respect to data analytics\nPerforms Data mining which provides actionable data in response to changing business requirements\nMigrates data into standardized platforms (Power BI) and builds critical data models to improve process performance and product quality\nOwns technical implementation and documentation associated with datasets\nProvides updates on project progress, performs root cause analysis on completed projects and works on identified improvement areas (like process, product quality, performance, etc.)\nProvides post-implementation support and ensures the target project benefits are successfully delivered in a robust and sustainable fashion.\nBuilds relationships and partners effectively with cross-functional teams to ensure available data is accurate, consistent and timely\nIndependently manages expectations from stakeholders, optimally utilizes time for larger initiatives with minimal guidance on prioritization or dependencies\nProvides mentorship and guidance to peers and junior team members\nMandatory Skills required to perform the job:\nKnowledge on the software development lifecycle expert in translating business requirements into technical solutions; and fanatical about quality, usability, security and scalability\nStrong Knowledge on Python and PySpark.\nSpecialist in Power Platform (Power Apps & Power Automate)\nExpert in Reports & Dashboard development (Power BI) and ETL tools (SAP DS, SSIS)\nData Analysis skills, experience in extracting information from databases, Office 365\nKnowledge of SAP systems (SAP ECC T-Codes & Navigation)\nExpert in Data Base Development, Troubleshooting & Problem-solving skills (SQL Server, SAP HANA, Azure Synapse)\nExperience in project requirements gathering and converting business requirements into analytical & technical specs.\nGood understanding of business processes and experience in Manufacturing/Inventory Management domains\nKnowledge in performing Root cause analysis and Corrective actions\nExcellent verbal and written communication & presentation skills, able to communicate cross-functionally\nDesirable Skills:\nAgile/SCRUM development using any tools.\nUnderstanding of enterprise server architecture, cloud platforms\nExperience in advanced analytics techniques using Statistical analysis\nAbility to deliver training and presentations in the area of expertise\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Data analysis', 'Database', 'Flex', 'SSIS', 'Troubleshooting', 'Data mining', 'Data warehousing', 'SQL', 'Python']",2025-06-14 05:26:25
Senior Data Analyst III,Cleartrip,4 - 6 years,Not Disclosed,['Bengaluru'],Cleartrip Private Limited is looking for Senior Data Analyst III to join our dynamic team and embark on a rewarding career journey Leads data analysis and visualization projects\n\n\nDevelops predictive models and insights\n\n\nManages large datasets and SQL/Python scripts\n\n\nPresents findings to stakeholders,Industry Type: Travel & Tourism,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Senior Data Analyst', 'PLSQL', 'Python']",2025-06-14 05:26:27
Data Analyst - Power bi - Bangalore,people staffing solutions,5 - 10 years,10-20 Lacs P.A.,['Bengaluru'],"Required Skills:\nProficient in Power BI Desktop and Power BI Service\nStrong knowledge of DAX and Power Query (M Language)\nHands-on experience in SQL and data warehousing concepts\nAbility to create and optimize data models\nExperience in integrating Power BI with Excel, SharePoint, SQL Server, or APIs\nGood to Have:\nExperience with Power Automate and Power Apps\nKnowledge of Azure Synapse, Data Factory, or other Azure services\nExperience with Row-Level Security (RLS) and report sharing best practices\nUnderstanding of Agile/Scrum methodology",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'SQL', 'Sales Analytics', 'Dax Queries', 'Data Analytics', 'Business Intelligence', 'Dashboarding', 'business recommendation', 'Insight Generation', 'Business Intelligence Reporting', 'Power Bi Dashboards', 'Data Analysis', 'Data Visualization', 'Visualization Tools', 'Business Insights']",2025-06-14 05:26:30
Data Analyst with AI OR Machine learning,Teleperformance (TP),3 - 7 years,3-8 Lacs P.A.,['Hyderabad'],"Key Responsibilities:\nAnalyze large volumes of labeled and unlabeled data to identify trends, anomalies, and labeling patterns that can improve model training or operational efficiency.\nDesign and maintain automated dashboards and reporting frameworks to track labeling quality, throughput, and issue trends.\nPartner with Client leadership to understand data requirements and provide actionable insights for model optimization.\nDevelop scalable data pipelines for data validation, aggregation, and visualization.\nApply data mining techniques to evaluate annotation consistency, inter-rater reliability, and data quality.\nContribute to AI data evaluation strategies through analytical experimentation and feedback integration.\nCollaborate with cross-functional teams to enhance data annotation workflows and ensure metrics alignment.\nRequirements:\nBachelors degree in Statistics, Mathematics, Computer Science, Data Science, or a related field.\n3–8 years of hands-on experience in data analysis roles, preferably in AI/ML or data labeling environments.\nProficient in SQL and Python for data manipulation, analysis, and automation.\nUnderstanding of data labeling workflows and familiarity with metrics like accuracy, precision, recall, and inter-rater agreement.\nStrong analytical thinking with the ability to interpret large datasets and provide actionable insights.\nExcellent communication skills with the ability to present findings to both technical and non-technical audiences.\nSelf-starter with a keen eye for detail and a passion for working in AI-driven data environments.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data anayst', 'SQL', 'Artificial Intelligence', 'Google Suite', 'Data Analysis', 'Advanced Excel', 'MI', 'Machine Learning']",2025-06-14 05:26:33
Data Scientist Sr. Analyst,Accenture,5 - 10 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Big Data, Python or R\n\n\n\n\nGood to have skills:Scala, SQL\n\n\n\nJob\n\n\nSummary\n\nA Data Scientist is expected to be hands-on to deliver end to end vis a vis projects undertaken in the Analytics space. They must have a proven ability to drive business results with their data-based insights. They must be comfortable working with a wide range of stakeholders and functional teams. The right candidate will have a passion for discovering solutions hidden in large data sets and working with stakeholders to improve business outcomes.\n\n\n\nRoles and Responsibilities\nIdentify valuable data sources and collection processes\nSupervise preprocessing of structured and unstructured data\nAnalyze large amounts of information to discover trends and patterns for insurance industry.\nBuild predictive models and machine-learning algorithms\nCombine models through ensemble modeling\nPresent information using data visualization techniques\nCollaborate with engineering and product development teams\nHands-on knowledge of implementing various AI algorithms and best-fit scenarios\nHas worked on Generative AI based implementations\n\n\n\nProfessional and Technical Skills\n3.5-5 years experience in Analytics systems/program delivery; at least 2 Big Data or Advanced Analytics project implementation experience\nExperience using statistical computer languages (R, Python, SQL, Pyspark, etc.) to manipulate data and draw insights from large data sets; familiarity with Scala, Java or C++\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications\nHands on experience in Azure/AWS analytics platform (3+ years)\nExperience using variations of Databricks or similar analytical applications in AWS/Azure\nExperience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)\nStrong mathematical skills (e.g. statistics, algebra)\nExcellent communication and presentation skills\nDeploying data pipelines in production based on Continuous Delivery practices.\n\n\n\n\nAdditional Information\nMulti Industry domain experience\nExpert in Python, Scala, SQL\nKnowledge of Tableau/Power BI or similar self-service visualization tools\nInterpersonal and Team skills should be top notch\nNice to have leadership experience in the past\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'scala', 'sql', 'r', 'big data', 'advanced analytics', 'mathematics', 'data manipulation', 'presentation skills', 'microsoft azure', 'pyspark', 'power bi', 'machine learning', 'javascript', 'aws kinesis', 'tableau', 'decision tree', 'java', 'hadoop', 'data visualization', 'aws', 'statistics']",2025-06-14 05:26:35
Sr. Data Analyst -ETL,HTC Global Services,5 - 10 years,Not Disclosed,['Chennai'],"Seeking a highly skilled Sr. Data Analyst - ETL with 5 years of experience to join our dynamic team.\nRequirements:\nAt least 5 years of experience in Data Analyst is mandatory.\nExposure in ETL preferably DataStage.\nExtensive experience with Data Cleansing, Data validation, Data Mapping Solutioning, ETL QA.\nProficient in SQL (Snowflake, SQL server, Oracle SQL/ PL SQL).\nMust have experience in Autosys, Snowflake and AWS.",,,,"['data cleansing', 'Data validation', 'Regulatory reporting', 'Datastage', 'Senior Data Analyst', 'PLSQL', 'Data Analyst', 'Investment banking', 'Asset management', 'data mapping']",2025-06-14 05:26:37
Cloud Security Compliance and Data Analyst,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"Generate compliance reports from an existing dashboard or build requirements to create a new reporting dashboard\n\nProactively Monitor, track, and report on security compliance status across systems and processes.\n\nAnalyze large datasets to identify trends, anomalies, and compliance risks.\n\n\n\n\n\n\n\n\nRequired education\nBachelor's Degree\n\nRequired technical and professional expertise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreferred technical and professional experience",,,,"['project management', 'python', 'hipaa', 'sql', 'nist', 'soc', 'cmdb', 'cis', 'it asset', 'gdpr', 'configuration management', 'software development life cycle', 'data quality', 'firewall', 'pci', 'enterprise risk management', 'perl', 'iaas', 'fedramp', 'linux shell', 'inventory management']",2025-06-14 05:26:40
"Data Eng, Mgmt & Governance Sr Analyst",Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Data Management - Microsoft Fabric\n\n\n\n\nDesignation: Data Eng, Mgmt & Governance Sr Analyst\n\n\n\n\nQualifications:BE,BTech\n\n\n\n\nYears of Experience:5 - 8 Years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIEnd to end, unified analytics platform that brings together existing offerings like Data Factory, Synapse, and Power BI into a single unified product for all your data and analytics workloads.\n\n\n\n\nWhat are we looking for\nMicrosoft Fabric Microsoft Azure PySpark Strong analytical skills Adaptable and flexible Problem-solving skills Agility for quick learning Ability to meet deadlines\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of moderately complex problems May create new solutions, leveraging and, where needed, adapting existing methods and procedures The person would require understanding of the strategic direction set by senior management as it relates to team goals Primary upward interaction is with direct supervisor May interact with peers and/or management levels at a client and/or within Accenture Guidance would be provided when determining methods and procedures on new assignments Decisions made by you will often impact the team in which they reside Individual would manage small teams and/or work efforts (if in an individual contributor role) at a client or within Accenture\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data management', 'data analysis', 'pyspark', 'microsoft azure', 'power bi', 'python', 'data analytics', 'natural language processing', 'bi', 'data warehousing', 'machine learning', 'business intelligence', 'sql', 'tableau', 'r', 'data science', 'data modeling', 'data visualization', 'etl', 'ssis']",2025-06-14 05:26:42
Data Analysis - Japanese Specialist Data Analysis,Zensar,3 - 7 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","Zensar Technologies is looking for Data Analysis - Japanese Specialist Data Analysis - Japanese Specialist to join our dynamic team and embark on a rewarding career journey A Data Analyst is responsible for collecting, analyzing, and interpreting data to identify trends, patterns, and insights that can drive informed business decisions\n\nThey play a crucial role in helping organizations understand their data, derive actionable insights, and optimize processes\n\nHere is a general job description for a Data Analyst:Data Collection and Preparation: Collect and gather relevant data from various sources, such as databases, spreadsheets, and external systems\n\nClean, validate, and transform the data to ensure accuracy and consistency\n\nData Analysis and Interpretation: Apply statistical techniques, data mining methods, and visualization tools to analyze large datasets\n\nIdentify trends, patterns, and correlations within the data and generate insights to support decision-making\n\nReporting and Visualization: Create clear and concise reports, dashboards, and visual representations of data using data visualization tools, such as Tableau, Power BI, or Excel\n\nPresent findings to stakeholders in a compelling and understandable manner\n\nData Quality and Integrity: Ensure data integrity and accuracy by conducting data validation, resolving discrepancies, and monitoring data quality\n\nImplement measures to maintain data privacy, security, and compliance with regulatory requirements\n\nBusiness Needs Assessment: Collaborate with stakeholders to understand their data analysis requirements and translate them into actionable analytics projects\n\nIdentify key performance indicators (KPIs) and metrics to measure business performance and success\n\nData-Driven Decision Making: Assist in making data-driven decisions by providing insights and recommendations based on data analysis\n\nSupport strategic planning, operational improvements, and process optimizations based on data-driven insights\n\nData Modeling and Forecasting: Develop and maintain data models, predictive models, and forecasting models to anticipate trends, predict outcomes, and support future planning\n\nUtilize statistical software, programming languages, or machine learning techniques as necessary\n\nContinuous Improvement: Stay updated with the latest data analysis techniques, tools, and trends\n\nContinuously improve data analysis processes, methodologies, and automation to enhance efficiency and effectiveness\n\nand Communication: Work closely with cross-functional teams, such as business analysts, data engineers, and data scientists, to align data analysis efforts with organizational goals\n\nCommunicate findings, insights, and recommendations to non-technical stakeholders in a clear and understandable manner\n\nDocumentation and Knowledge Sharing: Document data analysis methodologies, processes, and findings for future reference\n\nShare knowledge and best practices with the team to promote a culture of learning and data-driven decision-making\n\nSkills and Qualifications:Strong analytical skills with the ability to manipulate and analyze complex datasets\n\nProficiency in data analysis tools such as SQL, Excel, Python, R, or similar tools\n\nExperience with data visualization tools such as Tableau, Power BI, or similar tools\n\nKnowledge of statistical analysis techniques and methodologies\n\nFamiliarity with data modeling, predictive modeling, and forecasting techniques\n\nUnderstanding of database concepts and query languages\n\nExcellent attention to detail and problem-solving abilities\n\nStrong communication and presentation skills\n\nAbility to work independently and collaborate in a team environment\n\nFamiliarity with data privacy, security, and regulatory compliance\n\nPrior experience in data analysis or a related field is preferred",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Design engineering', 'Data analysis', 'Technology consulting', 'Focus', 'Agile', 'Conceptualization', 'Management', 'Japanese']",2025-06-14 05:26:45
Data Research Analyst - Female candidate - Work from Home,Maxsource Technologies,0 - 3 years,Not Disclosed,[],"Conduct lead and contact research using LinkedIn, directories, company websites, and online databases\nBuild and maintain targeted prospect lists based on defined ICPs\nPerform competitor and market research\nDrop cv on WhatsApp - 7066224298 - No Calls",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Research', 'Communication Skills', 'Linkedin', 'Hunter', 'Presentation Skills', 'Excel', 'Zoominfo', 'Skrapp', 'Crunchbase']",2025-06-14 05:26:47
Financial Reporting Data Analyst,Vichara Technologies,7 - 12 years,20-30 Lacs P.A.,"['Pune', 'Bengaluru', 'Delhi / NCR']",Responsibilities:\nOwn data reporting:\nMonitoring for Financial Ratio Completeness: troubleshooting and investigation into why these ratios are blank or not tying out.\nTroubleshooting Power BI Issues\nTriaging Issues with the Data Vendors:\n\nRequired Candidate profile\nAdvanced (5+ years) Financial Data Analysis Experience\nIntermediate (3+ years) with Financial Concepts\nSome (1+ year) SQL Experience,Industry Type: Analytics / KPO / Research,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Financial Statements', 'Financial Reporting', 'Power Bi', 'SQL', 'Reconciliation', 'Cfa Level 1', 'Financial Analysis', 'Financial Reconciliation', 'Financial Data', 'Advanced Excel', 'JIRA', 'Power Query', 'Data Reconciliation', 'Excel', 'Financial Analytics', 'VBA', 'Data Analysis', 'Data Reporting']",2025-06-14 05:26:49
DATA ANALYST - MEDICAL AFFAIRS,Eli Lilly And Company,7 - 9 years,Not Disclosed,['Bengaluru'],"The purpose of this role is to serve as a trusted partner with Business Unit Medical Affairs and Internal Global Medical Affairs Organization (GMAO) teams to lead creation of high-quality data reporting and visualization support that can drive better customer experience and business impact. This role will champion our self-service reporting strategy and would play a key role in helping us automate and create scalable frameworks for our reporting and analytics. We are looking for a hands-on person who can help expand our analytics & reporting capabilities and drive business-critical initiatives.\n  Key Objectives/Deliverables:\nKnow Lilly TA business and our internal business partners.\nBuild and exhibit deep expertise on available data sets and supports data enabled decision making by developing data lakes, insights, reporting & visualization\nExecute and monitor operations tasks to ensure timely availability of data in a reporting / dashboard structure to the business.\nPerform thorough data validations to ensure data quality\nRespond to queries from internal stakeholders\nConsistently meet operations SLAs\nPerform incident resolution and root cause analysis to support data and reporting operations\nConsistent delivery of high quality, timely and insightful reports to enable stakeholders and senior leadership to take key decisions\nDevelop and publish regularly, different execution dashboard as per the business roadmap & requirements\nDescriptive analytics and visualization to provide data-based insights on planning, execution and outcomes\nDemonstrate deep understanding of information and material flows, processes, procedures, systems, and methods\nDemonstrate understanding of internal business partners people, processes, and technology\nPartner and collaborate with other site-level teams to identify synergies and implementation of best practices\nTechnical Skills\nExpertise in writing and debugging efficient SQL queries.\nStrong experience in data visualization tools - Power BI or Tableau (Power BI preferred) - Should be able to independently design and develop dashboards as per business requirement.\nAdvanced MS-office skills (MS-Excel and MS-PowerPoint)\nCoding: SQL mandatory and one of R, Python would be good to have\nAnalytical Skills\nExperience in business analytics\nData cleaning and preparation skill (database querying, descriptive statistics)\nProblem solving skills and lateral thinking ability and an eye for detail\nEducational Requirements:\nbachelors or masters degree in sciences or quantitative discipline ie Finance, Econometrics, Statistics, Engineering or Computer Sciences\nAdditional Preferences:\nAt least 7-9 years of evolving experience in data management, pharma market intelligence, performance reporting/visualization and/or descriptive analytics for leadership, with demonstrated results in understanding, structuring, and making sense of unfamiliar and messy datasets\nExperience with project management software (eg, Wrike, JIRA, Adobe Workfront) and proficiency in a variety of PC applications and multifunctional diagramming tools including Microsoft Project, Visio, Lucid Chart etc\nStrong work ethic and personal motivation\nInterpersonal and communication skills with ability to work across time zones.\nStrong stakeholder management skills\nAbility to operate effectively in an international matrix environment.\nStrong team player who is dynamic and result oriented\nProven planning and organizational skills\nProven ability to manage multiple projects at a time with flexibility to adjust quickly and effectively to frequent change and altered priorities\nProduct Launch experience\nDemonstrated enthusiasm and the ability to work under pressure to meet deadlines",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data management', 'Coding', 'Project management', 'Pharma', 'Business analytics', 'Healthcare', 'MS Office', 'Adobe', 'Analytics', 'SQL']",2025-06-14 05:26:52
Senior Analyst-Data Analytics,AMERICAN EXPRESS,9 - 11 years,Not Disclosed,['Gurugram'],"Here, your voice and ideas matter, your work makes an impact, and together, you will help us define the future of American Express.\nHow will you make an impact in this role?\nYou will be responsible for delivery of highly impactful analytics to understand and optimize our commercial acquisition site experience and increase digital conversion.\nDeliver strategic analytics focused on digital acquisition and membership experiences.\nDefine and build key KPIs to monitor the channel/product/ platform health and success",,,,"['Mining', 'Computer science', 'Career development', 'Finance', 'Analytical', 'Data processing', 'Wellness', 'Analytics', 'SQL', 'Python']",2025-06-14 05:26:54
Analyst - Direct Display,Merkle B2b,0 - 2 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:Focuses on day-to-day executionProactively reviews and manages client data to ensure optimal performance on all campaignsTracks and reports on campaign results, gathers data analysis and participates in weekly callsGenerates campaign reports and is responsible for pacing, QA and traffickingDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Other,"Employment Type: Full Time, Permanent","['digital marketing', 'data analysis', 'quality control', 'branding', 'business development', 'advertising', 'sales', 'brand management', 'assurance', 'quality analysis', 'marketing', 'promotions', 'qc', 'campaigns', 'quality assurance', 'marketing communication', 'social media marketing', 'reporting']",2025-06-14 05:26:57
S&C GN - Data&AI - Retail - Analyst,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],TBDQualification\nTBD,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['retail sales', 'retail', 'sales', 'marketing', 'store management', 'visual merchandising', 'retail operations', 'channel sales', 'customer service', 'store operations', 'business development', 'apparel', 'distribution', 'merchandising', 'retail store operations', 'selling', 'customer handling']",2025-06-14 05:27:00
Clinical Data Analyst,Theia New Consultancy,3 - 7 years,Not Disclosed,[],"To use advanced data analysis for providing actionable insights that support data-driven decision-making within teams by utilizing R programming language, developing automation tools for oversight and standardized reporting templates to enhance the efficiency and consistency of information across the organization.\n\nRole & responsibilities\nData Analytics and Reporting\nDesign and develop detailed reports leveraging various databases, using R language to generate meaningful insights.\nProactively develop automation tools, standardized reporting tools & templates (including slides) for use by stakeholders to enable consistent presentation of information across the teams.\nCreate visualizations and trend analysis to identify patterns in study performance or other relevant areas.\nMonitor and document any bugs or issues related to the reporting tools and work with the concerned teams for timely resolution.\n\nStakeholder Collaboration\nCollaborate with cross-functional teams proactively to gather and understand reporting requirements, translating them into programming Specifications.\nAssist leadership teams in data-driven decision making by providing actionable insights such as budget projections, resource allocation, Full Time Equivalent (FTE) predictions etc. through various reports.\nAct as the bridge between data teams and other departments, gathering requirements and output Specifications for new analytical tools or reports.\nUtilize data to perform analytics, thereby predicting future requirements, provide real-time analysis of study quality metrics, site performance metrics and generate reports for Source Data Verification (SDV).\n\nAnalytics Project Management\nMaintain clear documentation of methodologies, data processes, and report-generation protocols to ensure transparency and reproducibility of analyses.\nAssist in the development of performance metrics based on communicated requirements, contributing to the overall efficiency and effectiveness of clinical operations.\nDevelop clear and concise communication around project progress, key findings, and recommendations to various stakeholders.\nKeep track of the number of projects progress and provide regular reports to Associate Director, Biostatistics and Analytics.\n\nPolicies, Processes & Procedures\nConduct day to day activities & follow all relevant policies, processes, standard operating procedures and instructions so that work is carried out in a controlled and consistent manner.\nAssist in the updating departmental and role Specific programming standards, Standard Operating Procedures (SOPs), Working Procedural Documents (WPDs), and templates to reflect current practices and regulatory requirements.\nImplement new initiatives/ projects as per established policies to meet future requirements of the function.\nComply with the company's Quality and Information Security Management Systems and applicable national and international legislation, including legislation for data protection\n\nKey interactions\nClinical operations\nBiostatisticians\nClinical Informatics\nClinical Data Management\nProject Management\n\nFunctional / Behavioral Skills required to execute the role\nR Programming\nAutomation and Tool Development\nData Analysis and Interpretation\nDocumentation and Reporting\nProject Management\nCommunication\nDetail orientation\nProblem solving\nTime management\n\nHands on experience in data analysis, preferably within a clinical research or healthcare setting",Industry Type: Clinical Research / Contract Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Automation', 'Clinical Data Management', 'Tool Development', 'Interpretation', 'R Program', 'Biostatistics', 'Clinical Research', 'Data Analysis', 'Clinical Trials']",2025-06-14 05:27:02
Senior Data Management Analyst,Wells Fargo,4 - 8 years,Not Disclosed,['Hyderabad'],"In this role, you will:\nLead or participate in moderately complex programs and initiatives for data quality, governance, and metadata activities\nDesign and conduct moderately complex analysis to identify and remediate data quality, data integrity, process, and control gaps\nAnalyze, assess, and test data controls and data systems to ensure quality and risk compliance standards are met and adhere to data governance standards and procedures",,,,"['Data Management Analysis', 'Project Management', 'Data Management', 'data governance', 'Business Analysis']",2025-06-14 05:27:05
Sr. Data Analyst,Slintel,3 - 8 years,Not Disclosed,[],"Our Mission:\n6sense is on a mission to revolutionize how B2B organizations create revenue by predicting customers most likely to buy and recommending the best course of action to engage anonymous buying teams. 6sense Revenue AI is the only sales and marketing platform to unlock the ability to create, manage and convert high-quality pipeline to revenue.\nOur People:\nPeople are the heart and soul of 6sense. We serve with passion and purpose. We live by our Being 6sense values of Accountability, Growth Mindset, Integrity, Fun and One Team. Every 6sensor plays a part in de ning the future of our industry-leading technology. 6sense is a place where difference-makers roll up their sleeves, take risks, act with integrity, and measure success by the value we create for our customers.\nWe want 6sense to be the best chapter of your career.\nPosition Overview:\nWe are seeking a highly skilled Sr. Data Analyst to focus on backend data support and governance. The ideal candidate will have a strong background in data engineering principles, SQL, and data modeling within modern cloud data platforms. This individual will play a key role in building and maintaining a scalable and trusted data infrastructure that supports reporting across the customer journey. A working knowledge of data governance frameworks and the ability to collaborate cross-functionally is essential.\nKey Responsibilities:\nBuild, maintain, and optimize data pipelines and models within our data warehouse to enable trusted downstream analytics.\nDevelop scalable, clean, and joinable datasets to support reporting across sales, marketing, customer success, and finance functions.\nCollaborate closely with RevOps, data engineering, and analytics stakeholders to ensure data is structured and aligned to business needs.\nSupport data governance by enforcing data definitions, naming conventions, and ownership models.\nMonitor and improve data quality, lineage, and integrity through proactive checks and documentation.\nTranslate raw data into reusable, governed tables and metrics to support self-service and centralized reporting use cases.\nAssist in standardizing metrics and business definitions to drive consistent reporting across systems and teams.\nQualifications:\nBachelor s degree in Computer Science, Data Science, Information Systems, or a related field. Master s preferred.\n3+ years of experience in a data analytics, analytics engineering, or backend reporting role.\nExpert-level SQL skills and experience working with cloud data warehouses (Snowflake, Redshift, BigQuery, etc.).\nSolid understanding of dimensional modeling, data architecture, and ELT pipeline development.\nFamiliarity with data governance tools, policies, or best practices.\nExperience with BI platforms (Looker, Tableau, Power BI, Sigma) is a plus.\nStrong organizational and communication skills; ability to translate technical requirements into business impact.\nOur Benefits:\nFull-time employees can take advantage of health coverage, paid parental leave, generous paid time-off and holidays, quarterly self-care days off, and stock options. We ll make sure you have the equipment and support you need to work and connect with your teams, at home or in one of our o ces.\nWe have a growth mindset culture that is represented in all that we do, from onboarding through to numerous learning and development initiatives including access to our LinkedIn Learning platform. Employee well-being is also top of mind for us. We host quarterly wellness education sessions to encourage self care and personal growth. From wellness days to ERG-hosted events, we celebrate and energize all 6sense employees and their backgrounds.\nEqual Opportunity Employer:\n6sense is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. .\nWe are aware of recruiting impersonation attempts that are not affiliated with 6sense in any way. A ll email communications from 6sense will originate from the @6sense.com domain . We will not initially contact you via text message and will never request payments . If you are uncertain whether you have been contacted by an official 6sense employee, reach out to jobs@ 6sense.com",Industry Type: Internet,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Backend', 'Data modeling', 'Senior Data Analyst', 'data governance', 'Wellness', 'Data quality', 'Downstream', 'SQL', 'Data architecture']",2025-06-14 05:27:08
Data Scientist-Artificial Intelligence,IBM,5 - 7 years,Not Disclosed,['Bengaluru'],"Work with broader team to build, analyze and improve the AI solutions.\nYou will also work with our software developers in consuming different enterprise applications\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\nPreferred technical and professional experience",,,,"['algorithms', 'python', 'data analytics', 'tableau', 'ml', 'hive', 'data analysis', 'natural language processing', 'pyspark', 'data warehousing', 'machine learning', 'artificial intelligence', 'sql', 'pandas', 'deep learning', 'java', 'data science', 'spark', 'kafka', 'hadoop', 'big data', 'aws', 'etl']",2025-06-14 05:27:11
Sr. Data Research Analyst,Morningstar,3 - 7 years,Not Disclosed,"['Thane', 'Navi Mumbai', 'Mumbai (All Areas)']","Senior Data Research Analyst, Credit Operations Mumbai Analytics\nAbout Us: Morningstar DBRS is a leading provider of independent rating services and opinions for corporate and sovereign entities, financial institutions, and structured finance instruments globally. Currently with 700 employees in eight offices globally. Formed through the July 2019 acquisition of DBRS by Morningstar, Inc., the ratings business is the fourth-largest provider of credit ratings in the world. Morningstar DBRS is committed to empowering investor success, serving the market through leading-edge technology and raising the bar for the industry. Morningstar DBRS is a market leader in Canada, the U.S. and Europe in multiple asset classes. Morningstar DBRS rates more than 4,000 issuers and 60,000 securities worldwide and is driven to bringing more clarity, diversity of opinion, and responsiveness to the ratings process. Morningstar DBRS approach and size provide the agility to respond to customers needs, while being large enough to provide the necessary expertise and resources. Visit: htthttps://www.dbrsmorningstar.com/learn/dbrsmorningstar to learn more. About the Role: Morningstar DBRS is seeking a Senior Data Research Analyst to join the Credit Operations Mumbai Analytics.\nThe Senior Data Research Analyst is part of the team responsible for maintaining critical ratings and origination data. In this role, you will be asked to gather and interpret data requirements, perform research and analysis, and mappings from multiple sources. The Senior Data Research Analyst will partner with our technology team to assist in the development and testing of new requirements when necessary\n\nResponsibilities\n• Assisting with collection and organization of security level data from various data sources\n• Mapping of CUSIP and ISIN to corresponding Morningstar DBRS ratings\n• Maintenance and troubleshooting of scheduled and automated reports\n• Completing various data related inquiries and requests from internal and external parties\n• Collaborate with Global Team to ensure accuracy, quality and reliability of the security ratings database\n• Communicating with and maintaining a strong relationship with rating analysts to adhere with compliance and regulatory matters\n\nRequirements\n• Bachelor’s degree in Accounting, Economics, Finance or Management Studies\n• 3-4 years of Relevant Financial Data experience, experience at a rating agency is a plus\n• Proficient in using data collection and analytical tools\n• Experience working with SQL (MS SQL Server)\n• Experience working with large data sets\n• Exposure to database management\n• Excellent verbal and written communication and interpersonal skills\n• Strong attention to detail and accuracy\n• Highly motivated, self-starter who is keen to learn, has a positive attitude and a strong work ethic\n• Ability to manage multiple tasks at the same time and deliver results in a timely manner\n• Ability to participate/ contribute as a team player\nRecommended Skillsets:\n• Experience with Bloomberg and/or Thomson Reuters terminal\n• Knowledge of fixed income or capital markets\n• Experience with Python\n\nMorningstar DBRS is an equal opportunity employer",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Reference Data', 'Financial Data Extraction', 'Bloomberg', 'Data Management', 'Reuters', 'Fixed Income']",2025-06-14 05:27:13
Senior Analyst- Supplier Data Management,Oracle,5 - 8 years,Not Disclosed,['Bengaluru'],"Maintain general accounting systems, policies, and procedures to ensure that proper information is reported in accordance with Generally Accepted Accounting Principles.\nCareer Level - IC1\nAssists in accounting functions which may include general ledger, accounts payable, fixed assets, and inter-company transactions.\nMaintain the general ledger to include the preparation of journal entries, analysis, reconciliation and reporting.\nMaintain and implement general accounting systems.\nConduct account reconciliation periodically, ledger close activities, and provide accurate financial data to support management in decision making.\nDevelop and prepare financial reports including profit and loss, income and balance sheet statements.\nReview and analyze inter-company transactions.\nEnsure all journal entries comply with internal and external audit specifications.\nParticipate in the ongoing development and maintenance of internal procedures and processes.\nMay participate in special projects.",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Journal entries', 'Data management', 'Financial reporting', 'General accounting', 'Fixed assets', 'External audit', 'Senior Analyst', 'Reconciliation', 'Management', 'Balance Sheet']",2025-06-14 05:27:16
Data Engineer Sr. Analyst,Accenture,2 - 3 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python/Scala, Pyspark/Pytorch\n\n\n\n\nGood to have skills:Redshift\n\n\n\nJob\n\n\nSummary\n\nYoull capture user requirements and translate them into business and digitally enabled solutions across a range of industries. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\nCreating data products for analytics team members to improve productivity\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\nPreparing data to create a unified database and build tracking solutions ensuring data quality\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\nProfessional and Technical Skills\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 2-3 years of hands-on experience working on these technologies.\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\nExperience working in cloud Data warehouses like Redshift or Synapse\nCertification in any one of the following or equivalent\nAWS- AWS certified data Analytics- Speciality\nAzure- Microsoft certified Azure Data Scientist Associate\nSnowflake- Snowpro core- Data Engineer\nDatabricks Data Engineering\n\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'microsoft azure', 'glue', 'amazon redshift', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'scipy', 'snowflake', 'data analysis', 'azure data lake', 'power bi', 'data engineering', 'javascript', 'pandas', 'data bricks', 'tableau', 'lambda expressions', 'aws']",2025-06-14 05:27:19
Senior Analyst - Data Governance & Management,AMERICAN EXPRESS,3 - 7 years,Not Disclosed,['Gurugram'],"Here, your voice and ideas matter, your work makes an impact, and together, you will help us define the future of American Express.\nAt American Express, you ll be recognized for your contributions, leadership, and impact every colleague has the opportunity to share in the company s success. Together, we ll win as a team, striving to uphold our company values and powerful backing promise to provide the world s best customer experience every day. And we ll do it with the utmost integrity, and in an environment where everyone is seen, heard and feels like they belong.\nJoin Team Amex and lets lead the way together.",,,,"['Career development', 'metadata', 'Manager Quality Assurance', 'Data management', 'Finance', 'Shell scripting', 'Wellness', 'Data quality', 'Risk management', 'SQL']",2025-06-14 05:27:22
Senior Data Research Analyst,Morningstar,3 - 8 years,Not Disclosed,['Mumbai'],"As a Senior Data Research Analyst , you will be responsible for acquiring and validating portfolio holdings data from various vendor sources. Your core responsibilities will involve standardizing this data into agreed formats using internal collection tools and resolving exceptions through thorough validation processes.\nWorking within the Portfolio Data Team, your role will focus on ensuring the accuracy and completeness of portfolio information, which is critical for downstream analytics and reporting. You will collaborate closely with leadership and cross-functional teams to support strategic goals, enhance operational performance, and contribute to the achievement of key KPIs.\nShift: UK/AU/US\nRoles Responsibilities:\nActively collect managed investment data using Morningstar collection systems, and ensure data timelines, completeness and accuracy to meet business goals.\nManage relationships between Morningstar and Asset Management companies, insurance companies and other data vendors.\nPartner with quality assurance, products, and technical departments to resolve clients data issues timely and effectively.\nParticipate in the initiatives focused on consolidating global data collection platforms and supporting database integration projects.\nEstablish and achieve the set Objectives Key Results (OKRs) with the direction of team lead.\nMonitor, analyze and execute summary reports including an investigation of potential data error to continuously improve data collection and quality assurance process using Lean Six Sigma tools.\nActively discover and raise issues in work (including system, process, and collection methodology) and propose enhancement suggestions to further improve system functionality, process efficiency and data quality.\nParticipate in data and process related projects such as industry/market research, market expansion, process certification, new product development support, etc.\nFacilitate cross-team projects to implement approved solutions based on priority and impact.\nDemonstrate a high sense of ownership of the process, understand roles responsibilities by acting as a process trainer and mentor\nRequirements:\n> 3 years experience in finance domain, with emphasis on collection systems and methodologies, senior data research analyst role or above.\nFund Portfolio experience would be preferred\nGood command in MS Office (Excel, PowerPoint etc.); advanced users preferred. SQL, Macro or Python and machine learning will be a plus.\nShould be critical thinker and should possess good communication skill.\nShould be equipped with understanding of data competencies like data content expertise, data analysis etc.\nStrong analytical, problem-solving capabilities, and excellent communication written as well as verbal reporting skills.\nShould be a good team player with good learning ability and equipped with self-motivation in an independent, fast-paced work environment.\nAbility to exercise control over the planned activities like training / mentoring new hires, doing quality checks etc.\nAble to work under tight deadlines and handle pressure during peak seasons.\nGood project management skills with proven track record of working on and delivering projects independently.\nRemote team working experience is a plus.\nFlexibility to work in shifts.\nMorningstar is an equal opportunity employer",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Analytical', 'Data Research Analyst', 'Data collection', 'Market research', 'Asset management', 'Operations', 'Analytics', 'SQL']",2025-06-14 05:27:24
Data Engineer - Senior Analyst,Accenture,2 - 3 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python/Scala, Pyspark/Pytorch\n\n\n\n\nGood to have skills:Redshift\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)\n\n\n\nJob\n\n\nSummary\n\nYoull capture user requirements and translate them into business and digitally enabled solutions across a range of industries. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\nCreating data products for analytics team members to improve productivity\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\nPreparing data to create a unified database and build tracking solutions ensuring data quality\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\nProfessional and Technical Skills\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 2-3 years of hands-on experience working on these technologies.\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\nExperience working in cloud Data warehouses like Redshift or Synapse\nCertification in any one of the following or equivalent\nAWS- AWS certified data Analytics- Speciality\nAzure- Microsoft certified Azure Data Scientist Associate\nSnowflake- Snowpro core- Data Engineer\nDatabricks Data Engineering\n\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'microsoft azure', 'glue', 'amazon redshift', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'scipy', 'snowflake', 'data analysis', 'azure data lake', 'power bi', 'data engineering', 'javascript', 'pandas', 'data bricks', 'tableau', 'lambda expressions', 'aws']",2025-06-14 05:27:27
Supply Chain Analyst - Data Engineering,TE Connectivity,5 - 10 years,Not Disclosed,['Bengaluru'],,,,,"['azure databricks', 'supply chain', 'azure data factory', 'data engineering', 'data modeling', 'azure data warehouse', 'python', 'ssas', 'power bi', 'warehouse', 'dashboards', 'supply', 'sql server', 'sql', 'transportation', 'sql server integration services', 'data center', 'spark', 'ssrs', 'etl', 'ssis', 'msbi']",2025-06-14 05:27:29
Data Engineer Sr. Analyst,Accenture,5 - 7 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level:\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Databricks including Spark-based ETL, Delta Lake\n\n\n\n\nGood to have skills:Pyspark\n\n\n\nJob\n\n\nSummary\n\nWe are seeking a highly skilled and experienced Senior Data Engineer to join our growing Data and Analytics team. The ideal candidate will have deep expertise in Databricks and cloud data warehousing, with a proven track record of designing and building scalable data pipelines, optimizing data architectures, and enabling robust analytics capabilities. This role involves working collaboratively with cross-functional teams to ensure the organization leverages data as a strategic asset. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\nDesign, build, and maintain scalable data pipelines and ETL processes using Databricks and other modern tools.\nArchitect, implement, and manage cloud-based data warehousing solutions on Databricks (Lakehouse Architecture)\nDevelop and maintain optimized data lake architectures to support advanced analytics and machine learning use cases.\nCollaborate with stakeholders to gather requirements, design solutions, and ensure high-quality data delivery.\nOptimize data pipelines for performance and cost efficiency.\nImplement and enforce best practices for data governance, access control, security, and compliance in the cloud.\nMonitor and troubleshoot data pipelines to ensure reliability and accuracy.\nLead and mentor junior engineers, fostering a culture of continuous learning and innovation.\nExcellent communication skills\nAbility to work independently and along with client based out of western Europe.\n\n\n\nProfessional and Technical Skills\n3.5-5 years of experience in Data Engineering roles with a focus on cloud platforms.\nProficiency in Databricks, including Spark-based ETL, Delta Lake, and SQL.\nStrong experience with one or more cloud platforms (AWS preferred).\nHandson Experience with Delta lake, Unity Catalog, and Lakehouse architecture concepts.\nStrong programming skills in Python and SQL; experience with Pyspark a plus.\nSolid understanding of data modeling concepts and practices (e.g., star schema, dimensional modeling).\nKnowledge of CI/CD practices and version control systems (e.g., Git).\nFamiliarity with data governance and security practices, including GDPR and CCPA compliance.\n\n\n\n\nAdditional Information\nExperience with Airflow or similar workflow orchestration tools.\nExposure to machine learning workflows and MLOps.\nCertification in Databricks, AWS\nFamiliarity with data visualization tools such as Power BI\n\n(do not remove the hyperlink)Qualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data warehousing', 'sql', 'data modeling', 'python', 'data bricks', 'hive', 'kubernetes', 'catalog', 'pyspark', 'data architecture', 'docker', 'ansible', 'git', 'java', 'spark', 'devops', 'hadoop', 'etl', 'big data', 'data lake', 'airflow', 'power bi', 'cloud platforms', 'machine learning', 'data engineering', 'aws']",2025-06-14 05:27:31
Senior Data Management Analyst,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst.\n\nIn this role, you will:\nMust have strong experience (SME) in JIRA, Assets, Structure, Confluence, Groovy/Python scripting, Linux, Script Runner.\nIn-depth knowledge of Jira Software, JSM and Confluence administration, configuration, customizations and Automations.",,,,"['Data Management', 'Script Runner', 'Linux', 'Confluence', 'JSM', 'Python scripting', 'Groovy', 'Jira', 'REST APIs']",2025-06-14 05:27:33
Senior Data Engineering Analyst,Optum,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Description\n\nExperience 4 to 7 years.\nExperience in any ETL tools [e.g. DataStage] with implementation experience in large Data Warehouse\nProficiency in programming languages such as Python etc.\nExperience with data warehousing solutions (e.g., Snowflake, Redshift) and big data technologies (e.g., Hadoop, Spark).\nStrong knowledge of SQL and database management systems.\nFamiliarity with cloud platforms (e.g., AWS, Azure, GCP) and data pipeline orchestration tools (e.g. Airflow).\nProven ability to lead and develop high-performing teams, with excellent communication and interpersonal skills.\nStrong analytical and problem-solving abilities, with a focus on delivering actionable insights.\nResponsibilities\nDesign, develop, and maintain advanced data pipelines and ETL processes using niche technologies.\nCollaborate with cross-functional teams to understand complex data requirements and deliver tailored solutions.\nEnsure data quality and integrity by implementing robust data validation and monitoring processes.\nOptimize data systems for performance, scalability, and reliability.\nDevelop comprehensive documentation for data engineering processes and systems.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ETL', 'SQL', 'Python', 'Azure', 'Datastage', 'Snowflake', 'Ab Initio', 'Informatica', 'Teradata', 'AWS']",2025-06-14 05:27:36
Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures\nIdentify data quality metrics and execute data quality audits to benchmark the state of data quality",,,,"['Data Management', 'Project Management', 'Data Analytics', 'Data Governance', 'Business Analysis']",2025-06-14 05:27:38
Data Analyst - Operations,Battery Smart,2 - 5 years,Not Disclosed,['Gurugram'],"Key Responsibilities:\n\n1. Call Monitoring & Performance Management:\n- Monitor inbound and outbound calls to ensure quality, compliance, and customer\nsatisfaction.\n- Evaluate agents based on key metrics such as AHT (Average Handle Time), conversion\nrates, and success rates of calls.\n- Provide regular feedback and coaching to agents to improve performance and customer\nservice delivery.\n\n2. Agent Efficiency & Development:\n- Track and analyze agent performance to identify areas for improvement.\n- Work closely with agents to implement training plans and ensure optimal performance.\n- Provide consistent and constructive feedback to enhance agent skills and knowledge.\n\n3. Performance Metrics & Reporting:\n- Analyze performance data to assess team efficiency, AHT, call conversions, and overall\nsuccess rates.\n- Generate regular performance reports and present findings to senior management.\n- Recommend and implement strategies to improve operational efficiency and effectiveness.\n\n4. Roster & Shift Planning:\n- Develop and manage the rostering and shift planning for call center agents to ensure\nadequate staffing levels.\n- Ensure optimal staffing during peak hours and adjust schedules based on demand.\n- Handle shift changes, leave requests, and absenteeism to minimize operational\ndisruptions.\n\n5. Process Optimization & Continuous Improvement:\n- Work closely with the operations team to continuously identify and implement process\nimprovements to enhance team performance.\n- Lead initiatives to reduce AHT while maintaining quality customer service and improving\nconversion rates.\n- Conduct root cause analysis on underperformance or issues and develop strategies to\nresolve them.\n\nQualifications & Skills:\n\nEducation:\n- Graduate degree (Bachelor's or equivalent) in any field.\n\nExperience:\n- Minimum of 2-3 years of work experience in a similar role, preferably within a call center or\ncustomer service environment.\n- Proven experience in managing call center operations and understanding of key\nperformance metrics (AHT, conversion rates, etc.).\n\nSkills & Competencies:\n- Strong proficiency in Excel and Google Sheets (data analysis, reporting, creating\ndashboards).\n- In-depth understanding of call center metrics, including AHT, conversion rates, and agent\nperformance.\n- Excellent analytical and problem-solving skills to identify issues and implement solutions.\n- Strong communication and coaching abilities to manage and motivate a team of agents.\n- Experience in roster planning and shift scheduling to optimize staffing.\n- Ability to thrive in a fast-paced, high-pressure environment while maintaining a focus on\nquality.\n- Strong organizational skills with the ability to multitask and prioritize effectively.",Industry Type: Electronic Components / Semiconductors,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data Operations', 'Google Sheets', 'Spreadsheets', 'Analytics']",2025-06-14 05:27:40
Human Resource - Data Analyst,Suzlon Group,3 - 6 years,Not Disclosed,['Pune( Hadapsar )'],"Role & responsibilities\nKey Responsibilities:\nImplement strategies, including compensation, benefits, and recognition programs.\nConduct manpower budgeting and forecasting to ensure optimal workforce planning.\nUtilize advanced Excel skills to analyze HR data and generate insightful reports.\nCreate HR dashboards in Excel\nPrepare the presentations for Management",,,,"['HR Analytics', 'Communication Skills', 'Project Management', 'Data Management', 'Hr Practices']",2025-06-14 05:27:42
Business Analyst - Data Warehouse,Vichara Technologies,6 - 11 years,30-35 Lacs P.A.,"['Coimbatore', 'Bengaluru', 'Delhi / NCR']","Collaborate with business stakeholders to gather and validate requirements\nCreate and manage Jira tickets\nSupport sprint planning, backlog grooming\nCreate clear, structured requirements documentation and user stories\n\nRequired Candidate profile\nExperience in analytics, business intelligence, or data warehouse projects (Snowflake, Power BI, Streamlit\nWorking knowledge of Jira\nknowledge in Alternative Asset Management or Investment Banking.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Investment Banking', 'Power Bi', 'User Stories', 'Business Analysis', 'Snowflake', 'python', 'streamlit', 'JIRA', 'SQL', 'Capital Market', 'Hedge Funds', 'Private Equity', 'Credit', 'Private Debt', 'MDM', 'Asset Management', 'Data Warehousing']",2025-06-14 05:27:45
Associate Data Analyst- Contractual,Windows Consultants Pvt Ltd,4 - 8 years,Not Disclosed,['Gurugram'],"Job Title: Data Analytics Associate Finance Team\nContractual Role- 1 year\nWe are seeking a Data Analytics Associate to join our Finance team. This role is ideal\nfor an analytical thinker with a passion for data-driven insights and business\nperformance analysis.\nKey Responsibilities:\n• Collect, clean, and maintain datasets from multiple sources (sales, operations,\ncustomer data).\n• Ensure data accuracy and integrity across various platforms.\n• Assist in developing dashboards and reports to support business decision-\nmaking.\n• Analyze sales trends, inventory levels, and operational performance to\nprovide actionable insights.\n• Support in monitoring the effectiveness of marketing campaigns,\npromotions, and pricing strategies.\n• Utilize tools like Excel, SQL, Tableau, and Power BI to interpret data.\n• Collaborate with cross-functional teams (Marketing, Operations, Finance) to\nalign analytics initiatives with business objectives.\n• Identify operational inefficiencies and suggest improvements based on data\nanalysis.\n• Assist in automating and optimizing reporting processes to improve efficiency.\nWhat Were Looking For:\n• 1+ year of experience in data analytics, business intelligence, or financial\nanalytics.\n• Proficiency in Excel, SQL, Power BI (knowledge of Python/R is a plus).\n• Strong analytical skills with the ability to interpret complex datasets and\ngenerate insights.\n• A proactive and detail-oriented mindset with a problem-solving approach.\n• Strong communication skills to present findings in a clear and concise manner.\n• Ability to work collaboratively across teams and contribute to data-driven\ndecision-making.",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'R', 'Power Bi', 'Tableau', 'Dashboards', 'Python']",2025-06-14 05:27:47
AVP Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Agile Methodology', 'Funds Transfer Pricing', 'Financial Data Mapping', 'Big Data Query Techniques', 'Lineage Tracing', 'Data warehousing', 'Data Governance', 'Jira', 'Market Risks', 'SQL']",2025-06-14 05:27:49
Data Analyst - Investment Team,Blenheim Chalcot,1 - 4 years,Not Disclosed,['Mumbai'],"The role\nThe Data Analyst - Investment Team is a vital role within the Blenheim Chalcot portfolio and BCI Finance . A Data Analyst - Investment Team supports investment professionals by analyzing financial, market, and economic data to identify trends, risks, and opportunities. They build models, dashboards, and reports to guide investment decisions, ensuring strategies are data-driven and aligned with performance goals.. You will gain hands-on experience in a fast-paced and progressive environment, where you will support us in building our next generation of GenAI enabled tech businesses.",,,,"['Data analysis', 'Data management', 'Trend analysis', 'data integrity', 'Stakeholder management', 'Analytics', 'Monitoring', 'SQL', 'Data extraction', 'Python']",2025-06-14 05:27:51
S&C GN - Data&AI - Life Sciences - Analyst,Accenture,2 - 7 years,Not Disclosed,['Bengaluru'],"Management Level:Ind & Func AI Decision Science Analyst\n\n\n\n\nJob Location:Bangalore / Gurgaon\n\n\n\nMust-have\n\n\n\n\nSkills:\nLife Sciences/Pharma/Healthcare projects and delivering successful outcomes, commercial, clinical, Statistical Models/Machine Learning including Segmentation & predictive modeling, hypothesis testing, multivariate statistical analysis, time series techniques, and optimization.\n\n\n\nGood-to-have\n\n\n\n\nSkills:\nProficiency in Programming languages such as R, Python, SQL, Spark, AWS, Azure, or Google Cloud for deploying and scaling language models, Data Visualization tools like Tableau, Power BI\n\n\n\nJob\n\n\nSummary\n\nWe are seeking an experienced and visionary - Accenture S&C Global Network - Data & AI practice help our clients grow their business in entirely new ways. Analytics enables our clients to achieve high performance through insights from data - insights that inform better decisions and strengthen customer relationships. From strategy to execution, Accenture works with organizations to develop analytic capabilities - from accessing and reporting on data to predictive modelling - to outperform the competition.\n\n\n\nKey Responsibilities\nSupport delivery of small to medium-sized teams to deliver consulting projects for global clients.\nAn opportunity to work on high-visibility projects with top Pharma clients around the globe.\nPersonalized training modules to develop your strategy & consulting acumen to grow your skills, industry knowledge, and capabilities.\nResponsibilities may include strategy, implementation, process design, and change management for specific modules.\nWork with the team or as an Individual contributor on the project assigned which includes a variety of skills to be utilized from Data Engineering to Data Science\nDevelop assets and methodologies, point-of-view, research, or white papers for use by the team and the larger community.\nWork on variety of projects in Data Modeling, Data Engineering, Data Visualization, Data Science etc.,\nAcquire new skills that have utility across industry groups.\n\n\n\n\n\nAdditional Information\nAbility to solve complex business problems and deliver client delight.\nStrong writing skills to build points of view on current industry trends.\nGood communication, interpersonal, and presentation skills\n\n\nAbout Our Company | Accenture (do not remove the hyperlink)\n\n\nQualification\n\n\n\nExperience:Proven experience (2+ years) in working on Life Sciences/Pharma/Healthcare projects and delivering successful outcomes.\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Statistics, Data Science, Applied Mathematics, Business Analytics, Computer Science, Information Systems, or other Quantitative field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['pharmaceutical', 'python', 'sql', 'life sciences', 'aws', 'presentation skills', 'microsoft azure', 'power bi', 'time series', 'machine learning', 'artificial intelligence', 'tableau', 'r', 'data science', 'gcp', 'spark', 'predictive modeling', 'statistical modeling', 'data visualization', 'statistics']",2025-06-14 05:27:53
Lead Data Analyst,Farmjunction Marketing,4 - 8 years,10-15 Lacs P.A.,['Noida'],"Role & responsibilities :-\nStrong knowledge of data analysis tools such as Excel, SQL, Python, R, or similar.\nExperience with data visualisation tools such as Tableau, Power BI, or similar.\nProficiency in statistical analysis and data interpretation.\nStrong problem-solving skills and attention to detail.\nExcellent communication skills, with the ability to present complex data understandably.\nAbility to work both independently and collaboratively in a team environment.\nFamiliarity with cloud-based data platforms (e.g., AWS, Google Cloud).\nHaving good exposure to different types and flavours of Data sources like CSV, MySQL, PostgreSQL, MongoDB, XML, etc.\nShown good control over data cleaning and analysis with minimum anomalies and skipping.\nStrong Leadership skills.",Industry Type: Internet (E-Commerce),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Pandas', 'Tableau', 'SQL', 'Python', 'Numpy']",2025-06-14 05:27:56
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst. We believe in the power of working together because great ideas can come from anyone. Through collaboration, any employee can have an impact and make a difference for the entire company. Explore opportunities with us for a career in a supportive environment where you can learn and grow. This role requires a blend of technical expertise, analytical thinking, and strategic decision making to drive impactful insights.\nAt Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do. We are seeking candidates who embrace diversity, equity and inclusion in a workplace where everyone feels valued and inspired. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.",,,,"['Data Management', 'Hive', 'Power BI', 'DB2', 'SQL Server', 'Tableau', 'Oracle', 'Teradata', 'Analytics', 'Python', 'Business Analysis']",2025-06-14 05:27:58
Power BI - Data Analyst,Hakkda,3 - 6 years,Not Disclosed,['Jaipur'],"ABOUT HAKKODA\n\nHakkoda, an IBM Company, is a modern data consultancy that empowers data driven organizations to realize the full value of the Snowflake Data Cloud. We provide consulting and managed services in data architecture, data engineering, analytics and data science. We are renowned for bringing our clients deep expertise, being easy to work with, and being an amazing place to work! We are looking for curious and creative individuals who want to be part of a fast-paced, dynamic environment, where everyone s input and efforts are valued. We hire outstanding individuals and give them the opportunity to thrive in a collaborative atmosphere that values learning, growth, and hard work. Our team is distributed across North America, Latin America, India and Europe. If you have the desire to be a part of an exciting, challenging, and rapidly-growing Snowflake consulting services company, and if you are passionate about making a difference in this world, we would love to talk to you!.\n\nWe are looking for a skilled and motivated Data Analyst / Data Engineer to join our growing data team in Jaipur. The ideal candidate should have hands-on experience with SQL, Python, Power BI , and familiarity with Snowflake is a strong advantage. You will play a key role in building data pipelines, delivering analytical insights, and enabling data-driven decision-making across the organization.\nRole Description:\nDevelop and manage robust data pipelines and workflows for data integration, transformation, and loading.\nDesign, build, and maintain interactive Power BI dashboards and reports based on business needs.\nOptimize existing Power BI reports for performance, usability, and scalability .\nWrite and optimize complex SQL queries for data analysis and reporting.\nUse Python for data manipulation, automation, and advanced analytics where applicable.\nCollaborate with business stakeholders to understand requirements and deliver actionable insights .\nEnsure high data quality, integrity, and governance across all reporting and analytics layers.\nWork closely with data engineers, analysts, and business teams to deliver scalable data solutions .\nLeverage cloud data platforms like Snowflake for data warehousing and analytics (good to have).\nQualifications\n3-6 years of professional experience in data analysis or data engineering.\nBachelor s degree in computer science , Engineering, Data Science, Information Technology , or a related field.\nStrong proficiency in SQL with the ability to write complex queries and perform data modeling.\nHands-on experience with Power BI for data visualization and business intelligence reporting.\nProgramming knowledge in Python for data processing and analysis.\nGood understanding of ETL/ELT , data warehousing concepts, and cloud-based data ecosystems.\nExcellent problem-solving skills , attention to detail, and analytical thinking.\nStrong communication and interpersonal skills to work effectively with cross-functional teams .\nPreferred / Good to Have\nExperience working with large datasets and cloud platforms like Snowflake, Redshift, or BigQuery.\nFamiliarity with workflow orchestration tools (e.g., Airflow) and version control systems (e.g., Git).\nPower BI Certification (e.g., PL-300: Microsoft Power BI Data Analyst).\nExposure to Agile methodologies and end-to-end BI project life cycles.\nBenefits:\n\n- Health Insurance\n- Paid leave\n- Technical training and certifications\n- Robust learning and development opportunities\n- Incentive\n- Toastmasters\n- Food Program\n- Fitness Program\n- Referral Bonus Program\n\nHakkoda is committed to fostering diversity, equity, and inclusion within our teams. A diverse workforce enhances our ability to serve clients and enriches our culture. We encourage candidates of all races, genders, sexual orientations, abilities, and experiences to apply, creating a workplace where everyone can succeed and thrive.\n\nReady to take your career to the next level? Apply today and join a team that s shaping the future!!\n\nHakkoda is an IBM subsidiary which has been acquired by IBM and will be integrated in the IBM organization. Hakkoda will be the hiring entity. By Proceeding with this application, you understand that Hakkoda will share your personal information with other IBM subsidiaries involved in your recruitment process, wherever these are located. More information on how IBM protects your personal information, including the safeguards in case of cross-border data transfer, are available here.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Automation', 'Data modeling', 'Consulting', 'Agile', 'Workflow', 'microsoft', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-14 05:28:00
Quality Analyst I - Data Access Management,JPMorgan Chase Bank,3 - 6 years,Not Disclosed,['Bengaluru'],"Join our team to enhance your career in data management and governance.\nAs a member of the Data Use and Access Team within the Data Management and Governance organization, you will manage data access protocols across our Data and Analytics Platforms. You will ensure compliance with legal and contractual restrictions, partnering with product, engineering, and end users to maintain a seamless user experience while upholding a best-in-class risk posture.\nJob Responsibilities\nManage data access protocols ensuring compliance with legal, contractual, and regulatory standards.\nDevelop and implement strategic initiatives for consistent, holistic, and cloud-agnostic data access management.\nCollaborate with cross-functional teams to monitor access restrictions and permissions.\nRemediate and strengthen gaps in data access controls through role design, management, and oversight.\nImplement access administration and recertification programs across various data environments and platforms.\nProvide subject matter expertise on access-related matters to the larger CCB organization.\nUtilize project management tools like JIRA and leverage the AGILE framework to deliver value to the business.\nRequired Qualifications, Capabilities, and Skills\n5+ years of experience in data analytics and technology-related positions with Python scripting as a core competency.\nHands-on experience with Python, Alteryx, and Tableau related projects.\nWorking knowledge of JIRA, SharePoint, InfoPath, Confluence, SQL, Snowflake, Git (Bitbucket), and SSRS.\nAdvanced MS Office suite skills (Excel, Word, PowerPoint, Visio, Project).\nExcellent written and oral communication skills with the ability to present information in differing degrees of detail and form depending on the audience.\nPreferred Qualifications, Capabilities, and Skills\nKnowledge of access management ticketing systems.\nExperience with Cyber Security Tools and Identity Access Management tools.\nFamiliarity with data environments and platforms such as Teradata, Oracle, Snowflake, and cloud technologies.",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Ticketing', 'Data management', 'Access management', 'Project management', 'SSRS', 'Agile', 'Visio', 'Oracle', 'Teradata', 'SQL']",2025-06-14 05:28:02
Financial Data Analyst,IPS group,1 - 5 years,3.5-4.5 Lacs P.A.,"['Kolkata', 'Mumbai', 'Chennai']","Job Requirement\n* Domain / Accounting knowledge and skills\n* Basic understanding of accounting principles and Finance\n* Good verbal and written communication skills\n* Willingness to work in rotational and night shifts\n\nJob Description\n\n* Research, Review, Analyze and Interpret financial statements/Broker reports of large corporates from global markets.\n* Ensure compliance with global policies including US GAAP & IFRS.\n* Capture data points of interest from financial reports and tag the same from Income Statement, Balance Sheet & Cash flow through an application.\n* Transaction based activities, rule-based decision making, verifying for accuracy and completeness, formatting data, posting and preparing output (various types of reconciliations, system to system  reconciliations, balancing, open item management, reports etc)\n* Constant quality check on the finalization of statement.\n* Capture specific figures from Revenue, Net Income, EPS, Weighted Average Shares, Income before tax,\nIncome Tax & One-time charges & provide timely, relevant and accurate information for Earnings.\n* Capture the future estimated data as given in press release, earnings call & company presentation report for Guidance.\n* Number crunching on specific items of the Income Statement, Balance sheet & Cash Flow.\n* Understanding of financial processes and applications",Industry Type: BPM / BPO,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['US GAAP', 'Financial Data Analyst', 'financial analysis', 'financial research analyst', 'IFRS']",2025-06-14 05:28:05
Lead Data Analyst - Power BI,Bot Consulting,5 - 8 years,Not Disclosed,['Jaipur'],"We are seeking an experienced and proactive Lead Data Analyst \\u2013 Power BI to lead the development of scalable analytics solutions and guide our growing data team in Jaipur. The ideal candidate will bring strong expertise in Power BI, SQL, Python, and experience with cloud data platforms such as Snowflake. You will be responsible for designing data models, leading dashboard/reporting initiatives, mentoring junior analysts, and enabling business stakeholders to make data-driven decisions.\nRoles & Responsibilities:\nLead the development and enhancement of interactive Power BI dashboards, reports, and data visualizations tailored to business requirements.\nArchitect and optimize data models in Power BI for performance and scalability (including DAX and Power Query transformations).\nBuild and manage robust end-to-end data pipelines, including data extraction, transformation, and loading (ETL/ELT).\nCollaborate with cross-functional stakeholders to translate business needs into technical solutions and actionable insights.\nPerform advanced data analysis using SQL and Python to uncover trends, patterns, and opportunities.\nEnsure data governance, quality, and consistency across all reporting assets and data platforms.\nMentor junior analysts and contribute to best practices in reporting, documentation, and code review.\nAct as a bridge between business and engineering teams, ensuring alignment and impact from analytics projects.\nWork with cloud data warehouses such as Snowflake or similar platforms for scalable analytics.\nSkills & Qualifications\n6+ years of experience in Data Analytics, Business Intelligence, or Data Engineering roles.\nProven expertise in Power BI, including dashboard development, DAX, data modeling, and Power Query.\nAdvanced proficiency in SQL and ability to work with large, complex datasets.\nProgramming experience in Python for data manipulation, automation, or machine learning (preferred).\nStrong understanding of ETL/ELT concepts, data warehousing, and modern cloud data platforms (Snowflake preferred).\nBachelors or Masters degree in Computer Science, Data Science, Engineering, or a related field.\nExcellent analytical thinking, problem-solving, and attention to detail.\nStrong communication skills and the ability to present data insights to non-technical stakeholders.\nPreferred Qualifications\nHands-on experience with Snowflake, Redshift, or BigQuery.\nFamiliarity with Airflow, DBT, or other orchestration tools.\nPower BI Certification (eg, PL-300: Microsoft Power BI Data Analyst).\nExperience with Agile methodologies and managing sprint-based BI deliverables.\nExposure to version control (Git) and CI/CD practices in data analytics projects.\nSigns You May Be a Great Fit\nImpact: Play a pivotal role in shaping a rapidly growing venture studio.\nCulture: Thrive in a collaborative, innovative environment that values creativity and ownership.\nGrowth: Access professional development opportunities and mentorship.\nBenefits: Competitive salary, health/we'llness packages, and flexible work options",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['IT services', 'Data analysis', 'Automation', 'Data modeling', 'Analytical', 'microsoft', 'Business intelligence', 'Analytics', 'SQL', 'Data extraction']",2025-06-14 05:28:07
S&C Global Network - AI - CDI - Data Science Analyst,Accenture,1 - 6 years,Not Disclosed,['Bengaluru'],"Job Title Ind & Func AI Decision Science Analyst - S&C GN\n\n\n\nManagement Level :11 - Analyst\n\n\n\nLocation:Gurgaon\n\n\n\nMust have skills:Generative AI, Machine Learning, Large Language Models (LLMs), Python, SQL\n\n\n\n\nGood to have skills:Spark, Cloud Platforms (AWS, Azure, GCP), NLP, Computer Vision\n\n\n\nJob\n\n\nSummary: As an AI Decision Science Analyst, you will play a key role in designing, building, and deploying advanced AI models and solutions to address business challenges across various industries. You will leverage Generative AI, Machine Learning, and Large Language Models (LLMs) to drive innovation and deliver impactful insights for clients. Your work will involve collaborating with cross-functional teams, and contributing to the development of advanced analytics capabilities.\n\n\n\n\nRoles & Responsibilities:\nLeverage Advanced Data Science Techniques\nDevelop solutions using Generative AI, Machine Learning, and Large Language Models (LLMs).\nDefine data requirements, clean, aggregate, analyze, and interpret data while conducting data quality assessments.\nDevelop and Implement AI Models\nBuild and deploy AI models and Generative AI applications.\nTrain and fine-tune LLMs using large-scale datasets to optimize performance and accuracy.\nEvaluate model performance and implement iterative improvements.\nSolution Integration and Deployment\nCollaborate to integrate AI solutions into end-to-end workflows, ensuring scalability.\nUtilize cloud platforms like AWS, Azure, or GCP for model development and deployment.\nInnovation and Knowledge Sharing\nStay updated on advancements in AI and Data Science, exploring innovative techniques and frameworks.\nDocument methodologies and findings for effective knowledge sharing.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Generative AI, Machine Learning, LLMs, Python, SQL.\nSpark, Cloud platforms (AWS, Azure, GCP), NLP, Computer Vision.\nExperience in developing and AI/ML models.\n\n\n\n\nAdditional Information: - The ideal candidate will possess a strong educational background in computer science or a related field, along with a proven track record of delivering impactful solutions using data science and analytics.\nThis position is based at our Gurugram office.\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:Minimum 1+ years of experience in Data Science, preferably within a consulting environment\n\n\n\n\nEducational Qualification:Bachelors or Masters degree (BE/BTech/MBA) in Statistics, Computer Science, Mathematics, or related disciplines with an excellent academic record",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'sql', 'data science', 'advanced analytics', 'mathematics', 'microsoft azure', 'artificial intelligence', 'data quality', 'computer science', 'gcp', 'spark', 'computer vision', 'model development', 'aws', 'ml', 'statistics']",2025-06-14 05:28:09
Senior Analyst - Market Data Support MOOP Middle Office,Apex Group,2 - 6 years,Not Disclosed,['Bengaluru'],Apex Fund Services LLP is looking for Senior Analyst - Market Data Support MOOP Middle Office - Open to join our dynamic team and embark on a rewarding career journey Provides market data support for middle office operations\n\n\nValidates and troubleshoots data feeds\n\n\nCollaborates with traders and IT teams\n\n\nEnsures data accuracy and timeliness,,,,"['CVS', 'Talent acquisition', 'Senior Analyst', 'Fund administration', 'market data', 'Apex', 'Recruitment']",2025-06-14 05:28:12
Clinical Data Analyst,GM Analytics Solutions,3 - 5 years,Not Disclosed,['Gurugram'],"Roles and Responsibilities :\n1. Support effective clinical analysis through the development of enriched data, leveraging analytical experience to guide data selection, data visualization, and additional analysis as appropriate\n2. Work with internal and external partners to develop data and requirements in support of high quality clinical analytics\n3. Gather information for project-related research; analyze that information; and produce reports and analyses as appropriate\n4. Work with engineering team on the development of new data, quality control of reports\n5. Identify appropriate techniques for a given analysis; implement analysis through technical programming; assess results and adjust for future iterations\n6. Develop oral and written summaries of findings for internal and external audiences\n7. Communicate effectively with internal and external stakeholders on project design, progress, outcomes, and any related constraints\n8. Prioritize, plan, and track project progress.\n9. Perform other duties and responsibilities as required, assigned, or requested.\nJOB REQUIREMENTS\nQualifications\nAdvanced degree (Masters or PhD) in healthcare, computer science, finance, statistics, or analytics\nExperience with data visualization tools, including Tableau\nExperience with clinical trial design or evaluation\nCertifications to support technical skills\nPreferred 4-6 years of experience in analytics intensive role\nStrong proficiency with SQL and its variation among popular databases\nExperience in reporting tools like SSRS and/orPower BII\nSkilled at optimizing large, complicated T-SQL statements and index design.\nFamiliarity with data visualization tools like AWS QuickSight or Tableau\nFamiliarity with Data Analytics Platforms, data ingestion, ETL, Predictive model, AI, ML\nFamiliarity with healthcare file standards like HL7, FHIR ,and CCDA preferred.\nProficient understanding of code versioning tools such as GitHub, andframeworksk such as AWS, Azure, FTP/sFTP/VPN protocols\nFamiliarity with Software Development Life Cycle (SDLC), Agil,,,e and Waterfall processes.\nAbility to work in a fast-paced, result-driven, and complex healthcare setting.\nExcellent analytical problem-solving organization and time management skills.\nTakes accountability and ownership\nCapable of embracingunexpected changese in direction or priority.\nExcellent communication skills.\nDeep proficiency in standard applications such as Microsoft Word, Excel, and Project\nKnowledge of EHR systems specifically Athena Healthnet, Acume ,and EPIC,i beneficial.\n\nEmail hr@gmanalyticssolutions.in\nContact: 9205015655",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['US Healthcare', 'SQL', 'Microsoft Sql Server Database', 'Data Visualization', 'Python', 'Data Ingestion', 'Ccda', 'data analytics', 'Epic', 'SSRS', 'Tsql Development', 'Problem Solving', 'SDLC Life Cycle', 'EHR', 'system analysis', 'Communication Skills', 'Azure Functions', 'ETL', 'Athena']",2025-06-14 05:28:14
Data Analysis and Insight Lead,Tatvic Analytics,3 - 4 years,Not Disclosed,['Ahmedabad'],"Data Analysis and Insight Lead\nResponsibilities\nRole Overview\nIn this role:\nDevelop a digital analytics strategy, specific to your industry and organization KPIs. Tailor reporting system and dashboards to your business.\nSupport client team with ongoing business needs and analytics system maintenance.\nSetting up the required reporting system, timeframes, performance metrics, and dimensions. Providing Google Analytics consulting and Marketing Technology strategy.\nDevelop analysis and dashboards and have to communicate data-driven recommendations to improve customers business\nMandatory Qualifications:\nExcellent Time Management & Proactive approach for taking initiative and getting them executed by the team.\nAt least 3-4 years of experience working with major business verticals [BFSI, E-commerce, OTT, Publisher, Automobile] in servicing Indian, North American and APAC markets\nExceptional consulting and Advanced & Statistical analysis (\nsegregation analysis,\npre-post analysis,\nfeature attribution analysis,\nMedia Campaign Opportunity analysis(using DDA & Markov Chain)\nSeasonality Analysis\nMarket Basket Analysis to identify products/channels that drive value\nTV data analysis\nClustering, Linear & Logical Regression, Time Series expertise.\nSkills: Google Analytics, Adobe Analytics, Google Cloud Platform Exposure, Hands-on experience on Big Query [SQL expertise]. GAIQ,\nA tool-agnostic analytics consultant.\nGood to have: Pre-sales Business flavor",Industry Type: Film / Music / Entertainment,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'digital analytics', 'Google Analytics', 'adobe analytics', 'Statistical analysis', 'Bfsi', 'Consulting', 'Manager Technology', 'Analytics', 'SQL']",2025-06-14 05:28:16
Data Analyst (USA Healthcare System) - Technical Lead,BILVANTIS TECHNOLOGIES,8 - 13 years,Not Disclosed,['Hyderabad'],"Data Analyst (USA Healthcare System) - Technical Lead\nQualifications:\n8+ years of experience in data analysis, preferably in the healthcare or fintech industry, with a strong understanding of the US healthcare system, including the roles and interactions between providers, payers, and patients.\nStrong proficiency in SQL and experience with data visualization tools (e.g., Power BI, Sigma), with the ability to analyze and present complex healthcare data effectively.\nProficiency with Snowflake and DBT (40 % of the role), leveraging these tools to manage and analyze large datasets within the healthcare domain.\nBasic knowledge of Python for data analysis tasks (40 % of the role), including data manipulation and automation of routine tasks.\nExperience with Datawarehouse and MDM systems, particularly in managing provider data, including provider demographic services and credentialing services.\nExcellent analytical and problem-solving skills with keen attention to detail, particularly in identifying trends and patterns in healthcare data.\nStrong leadership and mentoring abilities. Ability to manage and prioritize multiple projects in a dynamic, fast-paced environment.\nUnderstanding of data privacy and compliance regulations, particularly in the healthcare industry, including key healthcare legislation and regulations such as the Affordable Care Act (ACA), Medicare, Medicaid, and the Health Insurance Portability and Accountability Act (HIPAA).\nKnowledge of third-party data systems such as Dun Bradstreet (DB) and the Centers for Medicare Medicaid Services (CMS) for provider data management.\nAbility to manage multiple tasks and projects simultaneously in a fast-paced environment, with a focus on improving provider data management processes and outcomes.\nAbility to manage multiple tasks and projects simultaneously in a fast-paced environment.\nKey Responsibilities:\nPartner with Product Owners, Product Managers, and the Director of DI (Provider) to define and prioritize data strategies that drive impactful product development in the US Healthcare Providers domain.\nAct as a data liaison, providing actionable insights to stakeholders and guiding the integration of diverse data sources into product workflows.\nPerform in-depth analyses of provider data to identify trends, patterns, and actionable insights that influence business strategies.\nImplement and lead comprehensive data quality assurance processes, ensuring the accuracy and consistency of provider data.\nSupport provider demographic services, network solutions and credentialing services by leveraging data from existing Datawarehouse, MDM data stores.\nWork closely with the IT and Data Engineering teams to ensure data is stored, processed, and accessed in a compliant and secure manner, incorporating data from identified sources.\nAssist in the development and implementation of data governance policies and procedures, ensuring the inclusion of data from relevant sources.\nMentor junior analysts and provide guidance on best practices in data analysis, governance, and visualization.\nStay up to date with industry trends and best practices in data analysis, provider data management, and healthcare fintech, and continuously identify new data sets to enhance outcomes.\nPreferred Qualifications:\nExperience with healthcare data standards and regulations (e.g., HIPAA), ensuring compliance and data integrity in all data management activities.\nFamiliarity with data governance frameworks and best practices, particularly in the context of healthcare data management.\nAdvanced degree in Data Science, Computer Science, Information Systems, or a related field.\nIn-depth knowledge of the US healthcare system, including:\nHealthcare Triangle: Understanding the roles and interactions between providers, payers, and patients.\nProvider Networks: Knowledge of how provider networks are structured and managed, including credentialing and contracting processes.\nRegulatory Environment: Awareness of key healthcare legislation and regulations, such as the Affordable Care Act (ACA), Medicare, Medicaid, and the Health Insurance Portability Act and Accountability Act (HIPAA).\nReimbursement Models: Understanding various reimbursement models, including fee-for-service, value-based care, and capitation.\nHealthcare Data Standards: Knowledge of standards such as ICD-10, CPT, and HL7.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Health insurance', 'Data analysis', 'Automation', 'Manager Quality Assurance', 'Data management', 'Analytical', 'Technical Lead', 'Healthcare', 'US healthcare', 'SQL']",2025-06-14 05:28:19
Hiring | Data Engineer- Azure | Sr Analyst/ Consultant | Bangalore,Global MNC,5 - 10 years,Not Disclosed,['Bengaluru'],"Skill required: Data Engineers- Azure\nDesignation: Sr Analyst/ Consultant\nJob Location: Bengaluru\nQualifications: BE/BTech\nYears of Experience: 4 - 11 Years\n\nOVERALL PURPOSE OF JOB\nUnderstand client requirements and build ETL solution using Azure Data Factory, Azure Databricks & PySpark. Build solution in such a way that it can absorb clients change request very easily. Find innovative ways to accomplish tasks and handle multiple projects simultaneously and independently. Works with Data & appropriate teams to effectively source required data. Identify data gaps and work with client teams to effectively communicate the findings to stakeholders/clients.\n\nResponsibilities:\nDevelop ETL solution to populate Centralized Repository by integrating data from various data sources.\nCreate Data Pipelines, Data Flow, Data Model according to the business requirement.\nProficient in implementing all transformations according to business needs.\nIdentify data gaps in data lake and work with relevant data/client teams to get necessary data required for dashboarding/reporting.\nStrong experience working on Azure data platform, Azure Data Factory, Azure Data Bricks.\nStrong experience working on ETL components and scripting languages like PySpark, Python.\nExperience in creating Pipelines, Alerts, email notifications, and scheduling jobs.\nExposure on development/staging/production environments.\nProviding support in creating, monitoring and troubleshooting the scheduled jobs.\nEffectively work with client and handle client interactions.\n\nSkills Required:\nBachelors' degree in Engineering or Science or equivalent graduates with at least 4-11 years of overall experience in data management including data integration, modeling & optimization.\nMinimum 4 years of experience working on Azure cloud, Azure Data Factory, Azure Databricks.\nMinimum 3-4 years of experience in PySpark, Python, etc. for data ETL.\nIn-depth understanding of data warehouse, ETL concept and modeling principles.\nStrong ability to design, build and manage data.\nStrong understanding of Data integration.\nStrong Analytical and problem-solving skills.\nStrong Communication & client interaction skills.\nAbility to design database to store huge data necessary for reporting & dashboarding.\nAbility and willingness to acquire knowledge on the new technologies, good analytical and interpersonal skills\nwith ability to interact with individuals at all levels.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Data Management', 'Data Engineer', 'Azure Data Platform', 'Azure Data Bricks', 'Pyspark', 'Data Modelling', 'ETL', 'Python']",2025-06-14 05:28:21
Data Management Analyst,Wells Fargo,2 - 6 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Project Management', 'data Analysis', 'Data governance', 'Business Analysis']",2025-06-14 05:28:23
Analyst,Merkle B2b,0 - 2 years,Not Disclosed,['Bengaluru'],"Key responsibilities:\nIntegrates disparate datasets, conducts data preparation for analyses\nApplies data science methods to provide insights and recommendations to clients\nDelivers analytic outcomes based on project timelines and key milestones\nMaintains knowledge of new trends in the data science industry\nDevelops and manages code used for analytics purposes\nCommunicates findings and insights\nKnowledge on SQL, Tableau\nLocation:\nBangalore\nBrand:\nIprospect\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['tableau', 'Usage', 'data science', 'Senior Analyst', 'Analytics', 'SQL']",2025-06-14 05:28:25
Data Scientist,Tesco,1 - 3 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Summary:\n\nEnable data driven decision making across the Tesco business globally by developing analytics solutions using a combination of math, tech and business knowledge\n\nRoles and Responsibilities:\n- Identifying operational improvements and finding solutions by applying CI tools and techniques\n- Responsible for completing tasks and transactions within agreed KPI's",,,,"['Data Science', 'Advanced Excel', 'Data Analytics', 'Python', 'SQL', 'Applied Mathematics', 'Machine Learning', 'Statistics']",2025-06-14 05:28:28
Data Analytic | Fresher | Business Analytics,Large-Sized Firm in IT Services Sector,0 - 5 years,2.5-6 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']",ANY DEGREE IS PREFERRED\n1>good Logical Skills.\n2>fresher Business Analytics\n3>fresher Data Analyst\n4>good Analytical Skills\nPlease apply for the job in Naukri.com. We will check & will update you. Do not search the number in Google and do not call us. The requirements are not yet active from Client's side.,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'excel', 'Business Research', 'Data Analyst', 'Market Research', 'Business Analysis']",2025-06-14 05:28:30
Sales Data Analytics Analyst,Vertiv Group Corp,No fixed duration,Unpaid,['Pune'],"POSITION SUMMARY\n\nThe Sales Data Analyst will work with business stakeholders to understand and improve existing datasets, assist with new data development, and support Americas Sales Operations. This role is ideal for someone early in their analytics career who is eager to grow their technical and business acumen in a supportive, global environment.",,,,"['Computer science', 'Automation', 'Operational excellence', 'Sales operations', 'Focus', 'Business analytics', 'Continuous improvement', 'Internship', 'SQL', 'Python']",2025-06-14 05:28:33
Intern - Business Analyst,Purplle.com,0 - 1 years,Not Disclosed,['Mumbai'],"As a Business Analyst within our Operations team, you will play a pivotal role in leveraging data-driven insights to optimize processes, enhance operational efficiency, and drive strategic decision-making. Your responsibilities will involve utilizing a mix of technical skills and business acumen to interpret complex data sets, generate actionable insights, and support operational improvements.\n\nKey Responsibilities:\nCollaborate closely with cross-functional teams to understand operational requirements, identify opportunities for improvement, and define key performance indicators (KPIs) to measure success.\n\nAnalyze large datasets using SQL, Python, and advanced Excel techniques to extract, transform, and visualize data for operational reporting and decision making purposes.\n\nDevelop and maintain automated reports and dashboards using Power BI, Power Query, Tableau, Data Studios, Looker, and other visualization tools to communicate insights effectively.\n\nConduct in-depth analysis and interpretation of operational data to identify trends, patterns, and anomalies, providing actionable recommendations to drive operational excellence.\n\nUtilize strong aptitude and logical thinking to solve complex operational challenges and contribute to strategic initiatives that optimize workflows and enhance overall business performance.\n\nFoster strong stakeholder relationships through effective communication, presenting insights, and collaborating on operational strategies and solutions.\n\nRequired Skills and Qualifications:\nBachelor's degree in Business Administration, Data Science, Computer Science, or a related field.\n\nProficiency in SQL, Python, and advanced Excel for data analysis and manipulation.\n\nHands-on experience with Power BI, Power Query, Tableau, Data Studios, Looker, or similar visualization tools.\n\nStrong analytical and problem-solving abilities with a sharp aptitude for logical thinking.\n\nExcellent communication skills and the ability to effectively engage with stakeholders at all levels.\n\nProven track record of successfully managing and prioritizing multiple projects simultaneously in a fast-paced environment.\n\nStrong collaborative skills and the ability to work effectively in a team-oriented culture.\n\nPreferred Qualifications:\nExperience in the e-commerce industry or within a high-growth, dynamic environment.\n\nKnowledge of additional programming languages, statistical tools, or data modeling techniques.\n\nCertifications in business analysis, data visualization, or related fields",Industry Type: Beauty & Personal Care,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analysis', 'power bi', 'business analysis', 'data warehousing', 'analysis', 'business intelligence', 'sql server', 'sql', 'data studio', 'excel', 'power query', 'tableau', 'data modeling', 'advanced excel', 'google analytics', 'data visualization', 'reporting', 'communication skills']",2025-06-14 05:28:35
Data Analytics and Reporting Analyst,Capgemini,3 - 8 years,Not Disclosed,"['Kolkata', 'Mumbai (All Areas)( Airoli )']","You will be part of the global Marketing & Creative Services team and will be responsible for working with marketing teams (onshore & offshore) to\n\nBuild enterprise data and analytics solutions generating meaningful KPI dashboards for Capgemini Group\nDrive BI and Data Analytics solutions for measuring strategies aligned to marketing and business objectives.\nUnderstand the overall digital landscape of the organization as well as that of key competitors.\n\nKey Responsibilities\nParticipate in marketing/campaign briefing, solution architecture building and design activities.\nManage the implementation of tracking tags using Google Tag Manager to measure web & marketing campaign performance\nDevelop integrated corporate visualization solutions derived from multiple data sources using state-of-the-art tools to enable insight and decision-making at various levels\nDevelop data models, including performance measures, to enable scorecard analysis\nPerform ad-hoc analysis and present results in a clear manner\nLearn and establish data visualization standards and explore new, cutting-edge tools to periodically raise those standards\nEnsure accuracy, completeness and timeliness of reporting through proactive awareness, alerts, testing and processes\nPerform exploratory data analysis and data pre-processing to arrive at patterns and trends.\n\nCommunication\nWorking closely with the platforms team, digital & marketing teams.\nCollaborate with wider business stakeholders from Group\nGood presentation skills for reports and dashboards\n\nSpecification / Skills / Experience\nMust have high level of proficiency in data visualization tools - Power BI and/or Looker Studio, and/ or Tableau, DOMO\nHands on experience in implementing and managing Google Tags solutions using GTM or other tag management tools\nExperience with JavaScript, HTML, and CSS for custom tag implementations will be an Add on\nStrong understanding of digital marketing KPIs & tracking methods. Capability to create data story with the help of dashboard in defined timelines\nStrong knowledge of data warehouse concepts including: data modelling, data quality, ETL, reporting, analytics, and visualization\nGood grasp over Amazon AWS/RedShift/Azure/GCP or other Datawarehouse providers\nKnowledge on data extraction and data cleansing methodologies\nMust have proficiency in SQL to write analytical queries, create filters and calculated data sets\nStrong critical thinking, analytical, organizational, interpersonal, verbal and written communication skills\nHighly motivated and able to work independently as well as in a team environment\nAbility to operate comfortably and effectively in a fast-paced, highly cross-functional, rapidly changing environment\nExcellent analytical skills with demonstrated ability to solve problems\nAgile mindset and good understanding of MVP / iterative development is desired",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Google Tag Manager', 'Tableau', 'Data Visualization', 'Looker Studio', 'Google Data Studio', 'CSS', 'Google Analytics', 'Data Extraction', 'Data Cleansing', 'Data Mining', 'HTML', 'Domo', 'SQL', 'Data Warehousing', 'ETL', 'Data Reporting']",2025-06-14 05:28:37
Data Science Analyst,ManipalCigna Health Insurance,2 - 4 years,Not Disclosed,['Bengaluru'],"Key responsibilities\nDeliver quality analytics, from data preparation, data analysis, data exploration, data quality assessment, data manipulation, method selection, design & application, insights generation and visualisation\nDevelop and implement basic machine learning models and algorithms under the guidance of senior data scientists to extract insights and solve business problems\nProactive learning and acquisition of key analytical, technical and commercial skills and business knowledge to become a proficient Analyst working under the supervision of the senior/lead data science analysts.\nKPIs: Timeliness, accuracy, manager and client feedback (Internal and external as required)\nCollaborate with internal stakeholders and demonstrate the ability to transform client questions and problems into analytical solutions\nActive team member in providing the required support to help business understand and optimise use of analytical products and / or solutions\nBuild industry knowledge on the advancements in the field of analytics, data science and GenAI\nComply with the IM Cigna and CHSI Policies, procedures and processes, and continuously demonstrate Cigna Data and Analytics culture.\nKey activities\nWorking in a team to support end-to-end analytical projects\nLiaising with stakeholders to determine objectives / scope of upcoming projects\nData exploration, cleansing and manipulation\nDetermining appropriate type of analysis and undertaking analysis/modelling\nExtracting insights\nClear presentation of insights via spreadsheets, PowerPoint presentations, self-service analytical visualisation tools\nParticipate in client meetings\nOngoing stakeholder interaction (internal and external as required) on project progress\nContribute to the Feedback process (between stakeholders and the team) to ensure continuous improvement with team\nParticipate and contribute in learning forums such as Analytics Community and sharing knowledge with wider team\nExperience and education required\n2-4+ years experience in a technical analytics environment, carrying out data analytics and data science/AI projects and initiatives\nTertiary qualifications in engineering, mathematics, actuarial studies, statistics, physics, or a related discipline\nKnowledge of technical analytics discipline, including data preparation and foundational analytics concepts\nExperience with successfully managing both internal and external stakeholders, delivering against projects, tasks and activities in a dynamic deadline driven environment\nCommercial acumen to understand business needs and be able to suggest the commercial impacts of different analytics solutions or approaches\nCoding and modelling experience in SQL / R / Python and / or Cloud data platforms e.g. AWS\nExperience in visualization and data management tools is an added advantage\nExperience in GenAI/ LLMs is an added advantage\nExperience working with complex datasets\nAttention to detail and self driven continuous learning\nParticipation in external data hackathons and competitions will be an added advantage",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Data management', 'Analytical', 'Machine learning', 'Healthcare', 'Actuarial', 'Data quality', 'Continuous improvement', 'Analytics', 'SQL']",2025-06-14 05:28:39
Data Science Assoc Analyst,Pepsico,2 - 4 years,Not Disclosed,['Hyderabad'],"Overview \n\nData Science Team works in developing Machine Learning (ML) and Artificial Intelligence (AI) projects. Specific scope of this role is to develop ML solution in support of ML/AI projects using big analytics toolsets in a CI/CD environment. Analytics toolsets may include DS tools/Spark/Databricks, and other technologies offered by Microsoft Azure or open-source toolsets. This role will also help automate the end-to-end cycle with Azure Pipelines.\n\nYou will be part of a collaborative interdisciplinary team around data, where you will be responsible of our continuous delivery of statistical/ML models. You will work closely with process owners, product owners and final business users. This will provide you the correct visibility and understanding of criticality of your developments.\n\n \n\n\n",,,,"['python', 'pyspark', 'machine learning', 'ml', 'statistics', 'hive', 'continuous integration', 'github', 'supply chain', 'natural language processing', 'ci/cd', 'microsoft azure', 'apache pig', 'artificial intelligence', 'sql', 'docker', 'data bricks', 'git', 'spark', 'gcp', 'devops', 'oracle adf', 'jenkins', 'aws']",2025-06-14 05:28:42
"Data Analyst-CRM tool (Must Be expert with ZOHO, Sales Force) Delhi",Indo Edge Human Resources Delhi,2 - 7 years,3-5.5 Lacs P.A.,"['New Delhi', 'Delhi / NCR']","hands on experience in CRM Tools especially ZOHO, Sales Force etc\n\nRequired Candidate profile\nMust have hands on experience in CRM Tools especially ZOHO, Sales Force etc",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Sales Force', 'ZOHO', 'Lead Squared', 'CRM tool', 'Data Analyst', 'Crm Software']",2025-06-14 05:28:44
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst\n\nIn this role, you will:\nOrganize and lead complex companywide initiatives to ensure that data quality is maintained so that data can effectively support business processes\nOversee analysis and reporting in support of regulatory requirements",,,,"['Data Management', 'metadata', 'Project Management', 'Teradata', 'Analytics', 'Business Analysis', 'SQL']",2025-06-14 05:28:47
S&C GN - Data&AI - Life Sciences - Analyst,Accenture,2 - 7 years,Not Disclosed,['Gurugram'],"Management Level:Ind & Func AI Decision Science Analyst\n\n\n\n\nJob Location:Bangalore / Gurgaon\n\n\n\nMust-have\n\n\n\n\nSkills:\nLife Sciences/Pharma/Healthcare projects and delivering successful outcomes, commercial, clinical, Statistical Models/Machine Learning including Segmentation & predictive modeling, hypothesis testing, multivariate statistical analysis, time series techniques, and optimization.\n\n\n\nGood-to-have\n\n\n\n\nSkills:\nProficiency in Programming languages such as R, Python, SQL, Spark, AWS, Azure, or Google Cloud for deploying and scaling language models, Data Visualization tools like Tableau, Power BI\n\n\n\nExperience:Proven experience (2+ years) in working on Life Sciences/Pharma/Healthcare projects and delivering successful outcomes.\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Statistics, Data Science, Applied Mathematics, Business Analytics, Computer Science, Information Systems, or other Quantitative field.\n\n\n\nJob\n\n\nSummary\n\nWe are seeking an experienced and visionary - Accenture S&C Global Network - Data & AI practice help our clients grow their business in entirely new ways. Analytics enables our clients to achieve high performance through insights from data - insights that inform better decisions and strengthen customer relationships. From strategy to execution, Accenture works with organizations to develop analytic capabilities - from accessing and reporting on data to predictive modelling - to outperform the competition.\n\n\n\nKey Responsibilities\nSupport delivery of small to medium-sized teams to deliver consulting projects for global clients.\nAn opportunity to work on high-visibility projects with top Pharma clients around the globe.\nPersonalized training modules to develop your strategy & consulting acumen to grow your skills, industry knowledge, and capabilities.\nResponsibilities may include strategy, implementation, process design, and change management for specific modules.\nWork with the team or as an Individual contributor on the project assigned which includes a variety of skills to be utilized from Data Engineering to Data Science\nDevelop assets and methodologies, point-of-view, research, or white papers for use by the team and the larger community.\nWork on variety of projects in Data Modeling, Data Engineering, Data Visualization, Data Science etc.,\nAcquire new skills that have utility across industry groups.\n\n\n\n\n\nAdditional Information\nAbility to solve complex business problems and deliver client delight.\nStrong writing skills to build points of view on current industry trends.\nGood communication, interpersonal, and presentation skills\n\n\nAbout Our Company | Accenture (do not remove the hyperlink)\n\n\nQualification\n\n\n\nExperience:Proven experience (2+ years) in working on Life Sciences/Pharma/Healthcare projects and delivering successful outcomes.\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Statistics, Data Science, Applied Mathematics, Business Analytics, Computer Science, Information Systems, or other Quantitative field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['pharmaceutical', 'python', 'sql', 'life sciences', 'aws', 'presentation skills', 'microsoft azure', 'power bi', 'time series', 'machine learning', 'artificial intelligence', 'tableau', 'r', 'data science', 'gcp', 'spark', 'predictive modeling', 'statistical modeling', 'data visualization', 'statistics']",2025-06-14 05:28:49
Enterprise Data Operations Analyst,Pepsico,4 - 9 years,Not Disclosed,['Gurugram'],"Overview \n\nAs a member of the data engineering team, you will be the key technical expert developing and overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be an empowered member of a team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems and help grow DevOps and DataOps culture.\n\n \n\n\n",,,,"['azure policy', 'azure devops', 'arm templates', 'api', 'rest', 'artifactory', 'kubernetes', 'sonar', 'docker', 'ansible', 'azure cli', 'pcf', 'git', 'gcp', 'devops', 'powershell', 'paas', 'jenkins', 'python', 'microsoft azure', 'groovy', 'automation engineering', 'infrastructure', 'scrum', 'terraform', 'agile', 'aws']",2025-06-14 05:28:51
Data Modeler,Synechron,0 - 2 years,Not Disclosed,['Bengaluru'],"Synechron is seeking a knowledgeable and proactive Data Modeler to guide the design and development of data structures that support our clients' business objectives. In this role, you will collaborate with cross-functional teams to translate business requirements into scalable and efficient data models, ensuring data accuracy, consistency, and integrity. You will contribute to creating sustainable and compliant data architectures that leverage emerging technologies such as cloud, IoT, mobile, and blockchain. Your work will be instrumental in enabling data-driven decision-making and operational excellence across projects.Software Required",,,,"['data modeling', 'modeling tools', 'relational databases', 'scrum', 'agile', 'confluence', 'hipaa', 'data warehousing', 'data architecture', 'erwin', 'sql', 'git', 'gcp', 'mysql', 'etl', 'mongodb', 'jira', 'python', 'oracle', 'microsoft azure', 'sql server', 'nosql', 'gdpr', 'cassandra', 'aws', 'data integration', 'sdlc']",2025-06-14 05:28:54
Senior Data Scientist | Snowflakes | Tableau | AI/ML,Cisco,0 - 2 years,Not Disclosed,['Bengaluru'],"Job posting may be removed earlier if the position is filled or if a sufficient number of applications are received.\n\nMeet the Team\n\nWe are a dynamic and innovative team of Data Engineers, Data Architects, and Data Scientists based in Bangalore, India. Our mission is to harness the power of data to provide actionable insights that empower executives to make informed, data-driven decisions. By analyzing and interpreting complex datasets, we enable the organization to understand the health of the business and identify opportunities for growth and improvement.\n\nYour Impact\n\nWe are seeking a highly experienced and skilled Senior Data Scientist to join our dynamic team. The ideal candidate will possess deep expertise in machine learning models, artificial intelligence (AI), generative AI, and data visualization. Proficiency in Tableau and other visualization tools is essential. This role requires hands-on experience with databases such as Snowflake and Teradata, as well as advanced knowledge in various data science and AI techniques. The successful candidate will play a pivotal role in driving data-driven decision-making and innovation within our organization.\n\nKey Responsibilities\nKey Technologies &\n\nMinimum Qualifications\nPreferred Qualifications (Provide up to five (5) bullet points these can include soft skills)",,,,"['machine learning', 'artificial intelligence', 'sql', 'tableau', 'data visualization', 'snowflake', 'scipy', 'python', 'scikit-learn', 'data warehousing', 'numpy', 'pandas', 'tensorflow', 'data integration tools', 'matplotlib', 'pytorch', 'keras', 'machine learning algorithms', 'etl', 'nosql databases']",2025-06-14 05:28:56
Data Quality Analyst,Yallas Technology Solutions Opc,5 - 10 years,Not Disclosed,[],"Title: Data Quality Analyst/Developer\nDuration: 6 months to 1 year contract\nLocation:  Remote\nNotice period - Immediate to 7 days\nUAN /EPFO Report Required\n\n\nWork Experience:\n5 + years of this experience - Experience doing Data Emendation\nDesign/Develop Rules, monitoring mechanisms, notification\nDesign/Develop UI, Workflows, security\nDesign/Develop analytics (overall DQ reporting, usage statistics, etc).\nDesign/Develop migration activities to migrate existing DQ assets between our existing DQ platform and new DQ platform.\nDesign integration with MDM & Catalog (as needed)\nMonitor system performance and suggest optimization strategies (as needed).\nWork with DT to maintain system - patches, backups, etc.\nWork with LYB's Data Stewards to support their governance activities.\nTesting\n\nThe DQ Analyst/Developer should have experience with IMDC (for the sake of our example) cloud DQ and observability, JSON (depending on tool) Deep SQL skills, Integration tools/methodologies - API as well as ETL, Data Analysis, Snowflake or Databricks knowledge (for lineage), Power BI (nice to have), SAP ECC knowledge (nice to have), experience with cloud platforms (Azure, AWS, Google).\nIf you are interested please share required details along with resume\nFull Name:\nCurrent or Previous organization:\nCurrent Location:\nTotal Experience:\nRelevant experience as Data Quality analyst:\nhow many years of experience In Azure, AWS, Google\nHow many years of experience in UI, Workflows, security\nWorking as full time or contract:\nReason for job change:\nAny other offers inhand:\nCurrent CTC:\nexpected CTC:\nNotice Period:\nemail id:\ncontact Number :\nDomain name:\nare you ok to work Cotractual role?:\nshare your aadhar or pan card for the verification",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Temporary/Contractual","['Data quality analyst', 'IMDC', 'WORKFLOWS', 'MDM']",2025-06-14 05:28:58
Data Engineer,Accenture,5 - 10 years,Not Disclosed,['Bengaluru'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL processes to migrate and deploy data across systems. Your day will involve working on data solutions and ensuring data integrity and quality.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Develop and maintain data pipelines for efficient data processing.- Implement ETL processes to migrate and deploy data across systems.- Ensure data quality and integrity throughout the data solutions.- Collaborate with cross-functional teams to optimize data processes.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of data engineering principles.- Experience with cloud-based data solutions like AWS or Azure.- Knowledge of SQL and NoSQL databases.- Hands-on experience with data modeling and schema design.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Bengaluru office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data engineering', 'sql', 'etl', 'aws', 'hive', 'python', 'data processing', 'microsoft azure', 'pyspark', 'data warehousing', 'data integrity', 'knowledge of sql', 'nosql', 'database design', 'data quality', 'data modeling', 'spark', 'hadoop', 'big data', 'etl process', 'nosql databases']",2025-06-14 05:29:01
Data Quality Analyst,Yallas Technology Solutions Opc,5 - 10 years,Not Disclosed,[],"Title: Data Quality Analyst/Developer\nDuration: 6 months to 1 year contract\nLocation:  Remote\nNotice period - Immediate to 7 days\nUAN /EPFO Report Required\n\nWork Experience:\n5 + years of this experience - Experience doing Data Emendation\nDesign/Develop Rules, monitoring mechanisms, notification\nDesign/Develop UI, Workflows, security\nDesign/Develop analytics (overall DQ reporting, usage statistics, etc).\nDesign/Develop migration activities to migrate existing DQ assets between our existing DQ platform and new DQ platform.\nDesign integration with MDM & Catalog (as needed)\nMonitor system performance and suggest optimization strategies (as needed).\nWork with DT to maintain system - patches, backups, etc.\nWork with LYB's Data Stewards to support their governance activities.\nTesting\n\nThe DQ Analyst/Developer should have experience with IMDC (for the sake of our example) cloud DQ and observability, JSON (depending on tool) Deep SQL skills, Integration tools/methodologies - API as well as ETL, Data Analysis, Snowflake or Databricks knowledge (for lineage), Power BI (nice to have), SAP ECC knowledge (nice to have), experience with cloud platforms (Azure, AWS, Google).\nIf you are interested please share required details along with resume\nFull Name:\nCurrent or Previous organization:\nCurrent Location:\nTotal Experience:\nRelevant experience as Python Developer:\nhow many years of experience In Azure, AWS, Google\nHow many years of experience in UI, Workflows, security\nWorking as full time or contract:\nReason for job change:\nAny other offers inhand:\nCurrent CTC:\nexpected CTC:\nNotice Period:\nemail id:\ncontact Number :\nDomain name:\nare you ok to work Cotractual role?:\nshare your aadhar or pan card for the verification",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Data quality analyst', 'cloud data quality', 'Azure', 'data quality developer', 'JSON', 'google', 'Informatica', 'AWS']",2025-06-14 05:29:03
Data Science Analyst (Standard),Infogain,3 - 8 years,Not Disclosed,['Gurugram'],"Job Description: Data Scientist\n1. Expertise in Data Science & AI/ML: 3-8 years experience designing, developing, and deploying scalable AI/ML solutions for Big Data, with proficiency in Python, SQL, TensorFlow, PyTorch, Scikit-learn, and Big Data ML libraries (e.g., Spark MLlib).\n2. Cloud Proficiency: Proven experience with cloud-based Big Data services (GCP preferred, AWS/Azure a plus) for AI/ML model deployment and Big Data pipelines.; understanding of data modeling, warehousing, and ETL in Big Data contexts.\n3. Analytical & Communication Skills: Ability to extract actionable insights from large datasets, apply statistical methods, and effectively communicate complex findings to both technical and non-technical audiences (visualization skills a plus).\n4. Educational Background: Bachelors or Masters degree in a quantitative field (Computer Science, Data Science, Engineering, Statistics, Mathematics).\nEXPERIENCE\n3-4.5 Years\nSKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science, SQL, TensorFlow, Pytorch",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'data services', 'data science', 'Data modeling', 'GCP', 'Analytical', 'Cloud', 'big data', 'SQL', 'Python']",2025-06-14 05:29:05
Senior Data Test Analyst,Exavalu,6 - 8 years,Not Disclosed,[],"We are seeking a detail-oriented and experienced Senior Data Test Analyst to join our team. The ideal candidate will have a strong background in testing large-scale data migration projects, along with hands-on experience in ETL testing, data quality validation, and test automation. The role requires designing and executing robust testing strategies to ensure data integrity, accuracy, and compliance.\nKey Responsibilities:\nExperience Range - 6 to 8 Years\nDevelop and execute test strategies for large-scale data migration using statistical sampling and verification techniques.\nDesign and implement test plans covering Data Migration, Obfuscation, Reconciliation, Data Quality, and Data Governance.\nConduct thorough testing of ETL processes using tools such as Ab Initio and Informatica.\nPerform report testing for both operational and regulatory reporting requirements.\nEnsure comprehensive test coverage through data profiling and validation techniques.\nCollaborate with data architects, business analysts, and developers to understand data requirements and transformation logic.\nDevelop and maintain automated test scripts for data validation and regression testing.\nPrepare detailed test plans, test cases, and defect reports for data migration and integration efforts.\nRequirements\nProven experience in data migration testing, including validation strategies and statistical sampling.\nStrong hands-on experience with ETL testing tools such as Ab Initio and/or Informatica.\nExpertise in data obfuscation, reconciliation, data quality, and governance testing.\nSolid understanding of regulatory and operational reporting testing.\nExperience in automation testing frameworks related to data validation.\nAbility to design and document test plans specifically tailored to data migration projects.\nFamiliarity with SQL for data querying and validation.\nExcellent analytical and problem-solving skills",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data migration', 'Test scripts', 'Testing tools', 'Analytical', 'Reconciliation', 'Regression testing', 'Data quality', 'Informatica', 'Test cases', 'SQL']",2025-06-14 05:29:07
"Quality Assurance - Analyst, Amazon",Amazon,0 - 3 years,Not Disclosed,['Chennai'],"Should have 0-3 years of experience in Data Analysis and Excel\nHe/She should have an eye for detail and data accuracy skills.\nHe/She should be able to find trends based on audit output and aggregate audit data based on the audit findings. Auditor should be proficient in MS-excel functions and preferably be proficient in VBA for MS-Excel. This will help is efficient data aggregation\nUnderstanding of basic statistics and distributions/ability to detect patterns in data a plus.\nHe/She should be able to identify root cause, work with Support Engineers/Developers to fix errors and prevent recurrence of the identified errors.\nShould be able to analyze and provide objective, actionable feedback based on the trend surfaced.\nExpected to create and maintain process documentations on an ongoing basis. He/She is also expected to mentor and help new recruits to ramp up quickly. Should be willing participator in team meetings and contribute to knowledge sharing.\nCommitment to meet Deadlines is expected as a behavior. He/She is expected to commit and deliver as expected.\nShould be able to work independently, prioritize & schedule work assignments based on deadlines.\n. Candidates should work from office location on all 5 days of the week Bachelors degree\nSpeak, write, and read fluently in English\nExperience with Microsoft Office products and applications\nExperience with Excel Able to write queries using SQL & Macros",,,,"['Quality Assurance Analyst', 'Auditor', 'Data analysis', 'Excel', 'MS Office', 'Macros', 'Statistics', 'SQL', 'Auditing', 'Recruitment']",2025-06-14 05:29:10
MIS Analyst,Data Marshall,1 - 4 years,Not Disclosed,['Hyderabad'],"Job Description\nThe MIS Analyst plays a crucial role in managing and optimizing the organizations information management system. This position involves pulling up pre-identified reports, validating the content, interpreting and formatting the data into details that provide insight, and sharing it in a timely manner or agreed upon TAT.\nWhat You Will Do: MIS Analyst\nData Management: Pulling, interpreting, processing, reporting, and storing specified data.\nRequirements Translation: Convert business requirements into specifications for reports and dashboards, integrating multiple data sources.\nCollaboration: Work with specialists, leads, and managers to understand reporting needs and develop solutions accordingly.\nStatistical Reporting: Compile, prepare, and present statistical information for both internal and external stakeholders.\nWhat You Will Need:\n\nAdded Advantage\nReporting Tools: Experience with Power BI for reporting and analysis will be an added advantage.\nAutomation: Knowledge of VBA for developing automation scripts using Excel Macros.\nDatabase Development: Familiarity with MS Access for database and application development.\nClient Communication: Ability to communicate effectively with client business lines, leadership teams, and other stakeholders.\nFamiliarity with Python, Power Automate, and Power Apps is a plus. Role & responsibilities\n\n\nPreferred candidate profile\n\nEducation: Bachelors degree\nHealthcare Experience; Minimum 1 year of RCM experience or US Medical Coding Experience.\nMIS Experience: Minimum One year of experience in MIS execution\nTechnical Skills: Proficiency in MS Office applications (Excel, Word, PowerPoint), Proficiency in SQL will be an advantage.\nCommunication: Excellent verbal and written communication skills to facilitate collaboration with internal, external, and customer teams.\nAnalytical Skills: Strong analytical, conceptual, and problem-solving abilities.\nPrioritization: Ability to manage multiple priorities and adapt quickly to changing demands.\nFor more Details Kindly reach out\n\nName: Pagidoju Dhana Laxmi\nContact No: 7995682418\nEmai: dhanalaxmi.pagidoju@datamarshall.com",Industry Type: Analytics / KPO / Research,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent","['Word', 'Excel', 'Excel Powerpoint', 'Power Bi', 'SQL', 'Excel Macros']",2025-06-14 05:29:12
Analyst - Healthcare and Lifescience COE,Bain,0 - 2 years,Not Disclosed,['New Delhi'],"About us\nBain & Company is a global consultancy that helps the world s most ambitious change makers define the future. Across 61 offices in 39 countries, we work alongside our clients as one team with a shared ambition to achieve extraordinary results, outperform the competition and redefine industries. Since our founding in 1973, we have measured our success by the success of our clients, and we proudly maintain the highest level of client advocacy in the industry.\nIn 2004, the firm established its presence in the Indian market by opening the Bain Capability Center (BCC) in New Delhi. The BCC is now known as BCN (Bain Capability Network) with its nodes across various geographies. BCN is an integral and largest unit of (ECD) Expert Client Delivery. ECD plays a critical role as it adds value to Bains case teams globally by supporting them with analytics and research solutioning across all industries, specific domains for corporate cases, client development, private equity diligence or Bain intellectual property. The BCN comprises of Consulting Services, Knowledge Services and Shared Services.",,,,"['Industry research', 'Data analysis', 'Pharma', 'Analytical', 'Consulting', 'Intellectual property', 'Healthcare', 'Life sciences', 'Analytics', 'Private equity']",2025-06-14 05:29:15
data scientist,Bluphlux,3 - 7 years,Not Disclosed,['Pune'],"Job Summary\nAs a Data Scientist at Bluphlux, you will play a pivotal role in leveraging advanced data analytics and machine learning techniques to enhance our AI-driven recruitment solutions. You will work closely with our engineering and product teams to develop and implement models that improve the accuracy and efficiency of our resume ranking system.\n\nKey Responsibilities\nDevelop and implement machine learning models to enhance our recruitment platform.\nAnalyze large datasets to extract meaningful insights and improve our algorithms.\nCollaborate with cross-functional teams to integrate data-driven solutions into our products.\nContinuously monitor and refine models to ensure optimal performance.\nStay updated with the latest advancements in data science and machine learning to drive innovation.\nRequired Qualifications\nBachelors or Masters degree in Data Science, Computer Science, Statistics, or a related field.\nProven experience as a Data Scientist or similar role.\nStrong knowledge of machine learning algorithms and data analysis techniques.\nProficiency in programming languages such as Python or R.\nExperience with data visualization tools and techniques.\nPreferred Skills\nExperience with natural language processing (NLP) and language models.\nFamiliarity with cloud platforms such as AWS or Azure.\nStrong problem-solving skills and attention to detail.\nExcellent communication and teamwork abilities.\nAlso important:\n\nIf the candidate says his notice period is more than 2 months then try to negotiate.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'data science', 'Machine learning', 'Programming', 'Natural language processing', 'Data analytics', 'data visualization', 'Python', 'Recruitment']",2025-06-14 05:29:17
Associate Analyst - Data Science,NOVARTIS,1 - 6 years,Not Disclosed,['Hyderabad'],Summary\n-Support the TA Head/Product Managers/Product Executives in the team -Provide enhanced marketing and secretarial support to team members. -Provide analytical and operational support. Associate are aligned to perform qualitative and quantitative analytics on data to enable the informed decision making.\nAbout the Role\nMajor accountabilities:,,,,"['Mobile marketing', 'operational support', 'Email marketing', 'Customer satisfaction', 'Social media', 'Analytical', 'Customer retention', 'Digital marketing', 'Adobe', 'Analytics']",2025-06-14 05:29:19
Data Annotation Specialist,Yamaha Motor Solutions,0 - 3 years,3-4.5 Lacs P.A.,['Faridabad'],"We are seeking a highly detail-oriented and technically adept 3D Data Annotation Specialist to join our growing team. This role is critical in shaping high-quality datasets for training cutting-edge AI and computer vision models, particularly in domains such as LiDAR data processing, and 3D object detection.\n\nRoles and Responsibilities\nQualifications:\nB.Tech in Computer Science, IT, or related field preferred (others may also apply strong analytical and software learning abilities required).\nStrong analytical and reasoning skills, with attention to spatial geometry and object relationships in 3D space.\nBasic understanding of 3D data formats (e.g., .LAS, .LAZ, .PLY) and visualization tools.\nAbility to work independently while maintaining high-quality standards.\nExcellent communication skills and the ability to collaborate in a fast-paced environment.\nAttention to detail and ability to work with precision in visual/manual tasks.\nGood understanding of basic geometry, coordinate systems, and file handling.\nPreferred Qualifications:\nPrior experience in 3D data annotation or LiDAR data analysis.\nExposure to computer vision workflows.\nComfortable working with large datasets and remote sensing data\nKey Responsibilities:\nAnnotate 3D point cloud data with precision using specialized tools [ Training would be provided]\nLabel and segment objects within LiDAR data, aerial scans, or 3D models.\nFollow annotation guidelines while applying logical and spatial reasoning to 3D environments.\nCollaborate with ML engineers and data scientists to ensure annotation accuracy and consistency.\nProvide feedback to improve annotation tools and workflow automation.\nParticipate in quality control reviews and conduct re-annotation as needed",Industry Type: Automobile,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['annotation', 'python', 'data analysis', 'data analytics', 'modeling', 'analytical', 'software', 'strong analytical skills', 'data processing', 'machine learning', 'sql', 'data cleansing', 'data entry operation', 'cloud', '3d', 'data extraction', 'automation', 'data science', 'data annotation', 'lidar', 'communication skills']",2025-06-14 05:29:21
Trade Support Analyst,JPMorgan Chase Bank,0 - 5 years,Not Disclosed,['Mumbai'],"Join our team as a Trading Services Analyst to drive operational excellence, support trading strategies, and ensure regulatory compliance. Collaborate with US traders, resolve trade discrepancies, and enhance process efficiency\nJob Summary\nAs a Trading Services Analyst in our dynamic team, you will play a crucial role in enhancing operational excellence and supporting strategic trading initiatives. You will execute and monitor operational tasks with precision, ensuring accuracy and timeliness. You will reconcile and resolve trade discrepancies, maintaining compliance with regulatory standards. You will collaborate with US traders and internal teams to support trading activities and strategies. You will contribute to process improvements to boost operational efficiency and provide expert support for trade-related inquiries from both internal and external stakeholders.\nJob Responsibilities\nPerform daily reconciliation of trades, positions, and cash balances to ensure accuracy\nInvestigate and resolve breaks or discrepancies promptly\nEnsure accurate and timely execution and settlement of trades\nMonitor trade flows and address discrepancies during settlement\nIdentify and implement process improvements to enhance efficiency\nCollaborate with technology teams to enhance trade systems\nMonitor and manage operational risks in trade processing\nImplement controls to mitigate risks and adhere to policies\nCommunicate effectively with internal teams and counterparties\nSupport traders and compliance teams in operational tasks\nAdapt to changing market conditions and operational demands\nRequired Qualifications, Capabilities, and Skills\nHold a Bachelor s degree in Finance, Business, or a related field\nDemonstrate experience in trade operations or financial services\nExhibit proficiency in trade management and settlement systems\nPossess strong computer skills, including Microsoft Office Suite\nCommunicate effectively both verbally and in writing\nCollaborate with traders, compliance, and technology teams\nAdapt to changing market conditions and operational demands\nPreferred Qualifications, Capabilities, and Skills\nHold a Master s degree in Finance, Business Administration, or a related field\nDemonstrate extensive experience in trade operations, especially within specific asset classes like equities or ETFs\nUtilize data analysis tools and programming languages such as SQL or Python for automation and data management\nPossess an in-depth understanding of financial markets and trading strategies\nApply strong critical thinking skills to develop innovative solutions to operational challenges\nExhibit strong interpersonal skills for effective negotiation and communication with stakeholders\nWork effectively in a global environment, adapting communication styles to cultural differences",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Operational excellence', 'Data management', 'Reconciliation', 'trade operations', 'Operations', 'Financial services', 'SQL', 'Python']",2025-06-14 05:29:24
"Market Data Operations, Analyst",Primetrace Technologies,3 - 5 years,Not Disclosed,['Gurugram'],"About this role\nAbout the role:\nThe user entitlement function is solely responsible for managing terminal access and data exchange within BlackRock, updating user permissions in the MDM system. This MDM information helps validate invoices and create declaration reports.\nOur team primarily handles requests received from the business or HR departments to change employee market data access due to events like additions, departures, or transfers. Apart from this, there are other job responsibilities as well, which include preparing weekly vendor reconciliations, working on Data Notifications and collaborate with vendors to update user access in accordance with requests.\nResponsibilities:\nResponsibility includes setting up new deals/contracts, user per missioning, inventory updating, customer invoicing, monthly accounting close, vendor reconciliations, and supporting/leading ad hoc projects.\nTimely entry of data and making corrections as required.\nReview and update contracts and users against the internal inventory of index and market data services.\nResearch and resolve discrepancies to ensure accurate and timely inventory updates.\nActively follow up with vendors and internal colleagues to ensure timely issue resolution.\nRespond to inquiries related to inventory, contracts management, and reporting.\nPrepare user reconciliations to explain differences between the inventory of services and invoices.\nAssist in maintaining the accuracy of internal inventory of services in use and corresponding fees.\nDevelop an understanding of factors that impact invoicing and utilize that knowledge to improve and streamline processes.\nPrepare index and market data usage reports for providers.\nPrepare financial reports and analytics for internal stakeholders.\nSkills:\n3-5 years of experience in inventory/contract management or user/vendor reconciliation is preferred.\nDemonstrated ability to optimize new operational processes and establish quality controls.\nBasic understanding of financial markets.\nAdvanced proficiency in Excel and knowledge of Microsoft Access is preferred.\nStrong problem-solving and analytical skills.\nExcellent time-management abilities.\nEffective communicator (both orally and in writing) with a self-starter attitude capable of overcoming challenges.\nHighly organized and adaptable, displaying a sense of urgency, able to manage multiple priorities, meet deadlines, and maintain composure and integrity.\nEnjoys working in and contributing to an inclusive and diverse environment.\nTeam player who enhances overall team performance and objectives.\nEducation: Degree in Business, Commerce or related field\n#EarlyCareers\nOur benefits\n\n.\nOur hybrid work model\n.\nAbout BlackRock\n.\nThis mission would not be possible without our smartest investment - the one we make in our employees. It s why we re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.\nFor additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com / company / blackrock\nBlackRock is proud to be an Equal Opportunity Employer. We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Analytical skills', 'Contract management', 'Time management', 'Finance', 'Healthcare', 'Issue resolution', 'market data', 'Operations', 'Analytics', 'Inventory']",2025-06-14 05:29:26
Data Engineer,Accenture,5 - 10 years,Not Disclosed,['Chennai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL processes to migrate and deploy data across systems. Your day will involve working on data architecture and engineering tasks to support business operations and decision-making.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Develop and maintain data pipelines for efficient data processing.- Implement ETL processes to ensure seamless data migration and deployment.- Collaborate with cross-functional teams to design and optimize data solutions.- Conduct data quality assessments and implement improvements for data integrity.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of data architecture principles.- Experience in designing and implementing data solutions.- Proficient in SQL and other data querying languages.- Knowledge of cloud platforms such as AWS or Azure.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Chennai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'sql', 'data architecture principles', 'etl', 'aws', 'hive', 'python', 'data processing', 'airflow', 'microsoft azure', 'pyspark', 'data warehousing', 'data integrity', 'data migration', 'data engineering', 'data quality', 'spark', 'hadoop', 'business operations', 'big data', 'etl process']",2025-06-14 05:29:29
FP&A Analyst / Sr. Analyst / Manager - Chennai,2coms,3 - 8 years,Not Disclosed,['Chennai'],"SUMMARY\nFP&A Analyst / Sr. Analyst / Manager\n\nExperience: 6+ Years\n\nLocation: Chennai\n\nWork Arrangement: On-site\n\nRESPONSIBILITIES:\n\nThis position offers a unique opportunity to support our Corporate FP&A team. You will be instrumental in maintaining data integrity, conducting financial reporting and analysis, and ensuring efficient process execution. Your role will be pivotal in upholding the accuracy of essential data resources that contribute to all FP&A reports and processes.\n\nThe ideal candidate for this role will:\n\nTake charge of administrative operational cadences and have the potential to enhance existing processes, which includes organizing static meetings, managing communications related to scenario updates, and conducting daily validation checks of data.\nCreate standard template views utilized by the Global FP&A teams to deliver key results and performance insights, such as ensuring all Anaplan GSheet saved views are up to date and refreshing, and sending the monthly Close review excel template to Int’l at the beginning of each month.\nPreserve and generate source of truth materials to maintain data integrity and alignment of results across the broader FP&A team, achieved by maintaining monthly validation files and collaborating with the US based Corporate FP&A analyst to create the quarterly E-Binder TOC for the earnings team to reference in SmartSheets.\nConduct preliminary forecast/trend analysis and schedule creation for processes driven by the Corporate FP&A team, including rolling forward and refreshing all Earnings P0/P1 schedules and driving the quarterly EBITDA, SBC, Gains/Losses forecasts through partnership with Accounting.\nServe as the initial point of contact for all Earnings, BOD, and annual Operating Plan deck summaries, including staging the first pass proposals for all decks and managing all processes associated with final touches.\n\nRequirements\nRequirements:\n\nBachelor’s degree in Finance, Accounting, Business, or related field\nDemonstrated experience in financial planning and analysis\nProficiency in data analysis and financial modeling\nStrong communication and presentation skills\nAdvanced proficiency in Microsoft Excel and other financial software\nAbility to thrive in a fast-paced, dynamic environment\nStrong attention to detail and accuracy\nRelevant certifications (e.g., CFA, CPA) preferred",Industry Type: Banking,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['data analysis', 'software', 'forecasting', 'presentation skills', 'accounting', 'analysis', 'budgeting', 'excel', 'planning', 'annual operating plan', 'fpa', 'financial reporting', 'financial modelling', 'financial planning', 'financial planning and analysis', 'reporting', 'finance', 'communication skills']",2025-06-14 05:29:31
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Bhubaneswar'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:34
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Hyderabad'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:37
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Indore'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:39
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Navi Mumbai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:41
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Navi Mumbai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:44
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Pune'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to effectively migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and contribute to the overall data strategy of the organization, ensuring that data solutions are efficient, scalable, and aligned with business objectives.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with stakeholders to gather and analyze data requirements.- Design and implement robust data pipelines to support data processing and analytics.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of data modeling and database design principles.- Experience with ETL tools and data integration techniques.- Familiarity with cloud platforms and services related to data storage and processing.- Knowledge of programming languages such as Python or Scala for data manipulation.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data analytics', 'database design', 'data modeling', 'design principles', 'hive', 'scala', 'data manipulation', 'data processing', 'pyspark', 'data warehousing', 'data engineering', 'sql', 'data quality', 'tableau', 'etl tool', 'spark', 'hadoop', 'etl', 'big data', 'data integration', 'etl process']",2025-06-14 05:29:46
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Bhubaneswar'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:49
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Chennai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:51
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Chennai'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:54
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Pune'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :Business AgilityMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions that facilitate data generation, collection, and processing. Your typical day will involve creating data pipelines, ensuring data quality, and implementing ETL processes to migrate and deploy data across various systems. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet business needs. Additionally, you will monitor and optimize data workflows to enhance performance and reliability, ensuring that data is accessible and actionable for stakeholders.\nRoles & Responsibilities:- Need Databricks resource with Azure cloud experience- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Collaborate with data architects and analysts to design scalable data solutions.- Implement best practices for data governance and security throughout the data lifecycle.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Good To Have\n\n\n\n\nSkills:\nExperience with Business Agility.- Strong understanding of data modeling and database design principles.- Experience with data integration tools and ETL processes.- Familiarity with cloud platforms and services related to data storage and processing.\nAdditional Information:- The candidate should have minimum 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data analytics', 'database design', 'data modeling', 'design principles', 'etl', 'hive', 'python', 'data warehousing', 'power bi', 'machine learning', 'data engineering', 'sql server', 'sql', 'data bricks', 'data quality', 'tableau', 'spark', 'data governance', 'hadoop', 'big data', 'aws', 'ssis', 'etl process']",2025-06-14 05:29:56
Data Entry (Fresher),Rapid Care,0 years,1-1.5 Lacs P.A.,['Chennai'],"Greetings from rapid care!!!!!!\n\nHiring Freshers and Experienced !!!!!!!!!\n\nwalkin interview\n\n\nJob Title: Data Analyst (Data Entry)\n\nLocation: Chennai\n\nShift: General and Rotational Shift\n\nGraduation: ( 10th, 12th, OR Any Diploma Qualification)\n\nInterview mode : walkin\n\n\nOffice Address : VLV Complex, 2nd floor, 41, SH 48, Little Mount, Saidapet, Chennai, Tamil Nadu 600015\n\nshare your resume : tag@rapidcare.ai\ncall , whatsapp : 9500170691, 9500170663.",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Typing Speed', 'Data Entry', 'Typing', 'Data Entry Operation']",2025-06-14 05:29:58
Analyst,HARMAN,2 - 7 years,Not Disclosed,['Bengaluru'],"JOB IDENTIFICATION\nBusiness Title: Analyst\nBusiness Unit: Symphony Health Solutions\nLocation: Bangalore\nJOB SUMMARY\nWe are looking for a candidate with relevant analytics experience including working with larger datasets with healthcare background as a preference, Basic SQL and Advance Excel skills.\nAnalyst performs complex data analysis independently, preparing comprehensive reports and presentations of data analysis findings for the client or data vendor per established service level agreements. Job functions include inputs to processes, executing programs, assessing data accuracy, drawing research conclusions, and formatting and presenting output. This position is an expert in researching, resolving and documenting client/vendor inquiries. Work in a fast paced dynamic environment.",,,,"['Data analysis', 'Service level', 'Senior Analyst', 'Process improvement', 'Agile', 'Healthcare', 'Manager Quality Control', 'Downstream', 'Auditing', 'SQL']",2025-06-14 05:30:01
Business Analyst,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work-related problems.- Develop detailed business requirements and user stories.- Conduct stakeholder interviews to gather business requirements.- Create process flow diagrams and business process models.- Collaborate with cross-functional teams to ensure project success.- Assist in the implementation and testing of business solutions.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis.- Strong understanding of business process modeling.- Experience with Agile methodologies.- Knowledge of data analysis and interpretation.- Hands-on experience with requirement gathering tools.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Business Analysis.- This position is based at our Bengaluru office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business process modeling', 'data analysis', 'business analysis', 'user stories', 'agile methodology', 'process flow diagram', 'project management', 'gap analysis', 'business solutions', 'wireframing', 'sql', 'product management', 'brd', 'fsd', 'flow diagrams', 'frd', 'agile', 'requirement analysis']",2025-06-14 05:30:03
Technical Business Analyst - Consutant,KPMG India,5 - 8 years,Not Disclosed,['Bengaluru'],"KPMG India is looking for Technical Business Analyst - Consutant to join our dynamic team and embark on a rewarding career journey Analyze the business requirements of the organization and develop solutions to improve business processes and systemsConduct market research and data analysis to support decision-makingCollaborate with cross-functional teams, including development, product management, and project management, to ensure the delivery of high-quality solutionsCommunicate findings and recommendations to stakeholders, including management and technical teamsDevelop business requirements documents, use cases, process flows, and other deliverables as neededDevelop and maintain a deep understanding of the organization's products, services, and business operationsParticipate in the implementation and testing of solutions to ensure that they meet business requirementsContinuously evaluate and improve business processes and systemsStrong analytical and problem-solving skillsExcellent written and verbal communication skills",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Networking', 'Focus', 'Manager Technology', 'professional services', 'Business Technical Analyst', 'international clients']",2025-06-14 05:30:05
Technical Business Analysis Specialist,Telstra,4 - 9 years,Not Disclosed,['Bengaluru'],"Employment Type Permanent\nClosing Date 29 June 2025 11:59pm\nJob Title Technical Business Analysis Specialist\nJob Summary\nAs a Technical Business Analysis Specialist, you thrive on collaborating with your team and providing valuable input to support stakeholders and team members to deliver technical analysis and research that enables successful business initiative/mission design and delivery, and ongoing technical capability operational performance. Job Description",,,,"['Data analysis', 'Business analysis', 'Agile', 'Data structures', 'Workflow', 'Gap analysis', 'Continuous improvement', 'JIRA', 'Operations', 'Business Technical Analyst']",2025-06-14 05:30:08
"Analyst, Provider Data Management",Evolent Health,2 - 4 years,Not Disclosed,['Pune'],"Are we growing? Absolutely and Globally. In 2021 we grew our teams by almost 50% and continue to grow even more in 2022. Are we recognized as a company you are supported by for your career and growth, and a great place to work? Definitely. Evolent Health International (Pune, India) has been certified as Great Places to Work in 2021. In 2020 and 2021 Evolent in the U.S. was both named Best Company for Women to Advance list by Parity.org and earned a perfect score on the Human Rights Campaign (HRC) Foundation s Corporate Equality Index (CEI). This index is the nations foremost benchmarking survey and report measuring corporate policies and practices related to LGBTQ+ workplace equality.\nWhat You ll Be Doing:\nJob Description\nEvolent Health is looking for a Provider Data Specialist to be a key member of the PDM Operations team. Reporting to the Supervisor of Provider Data Management, this individual will play a critical role in executing Evolent Health s mission by working directly with our partners, focused on coordinating, monitoring, trending and supporting report requirements of business operational and clinical programs within Provider Network Management. This Provider Data Analyst will work with both internal and external business partners to implement ongoing operational monitoring, resolve service barriers, develop solutions to improve effectiveness and identify continuous improvement initiatives to increase service levels.\n\nEssential functions\n\nServe as a liaison between the internal team members and partner organization providing support for provider data enrollment activities; acts as liaison with technology team and business product team members.\n\nDefines analysis methodology and provides analytic support.\n\nAnalyzes existing systems to recommend enhancements and creates new systems to reduce manual processes and maximize the business efficiencies.\n\nAnalyzes data from conceptualization through presentation and requires proficiency with analytical tools, knowledge of data analysis methodology, use of presentation software, and strong communication skills.\n\nIdentifies, evaluates, and implements new data-driven strategies and processes for the department\n\nDevelops tools and reports that lend valuable insights that capitalize on a combination of internal and external data.\n\nRecommends enhancements to existing systems in accordance to business needs by creating ad hoc and standard reports as well as information delivery technologies.\n\nPrepare reports in an accurate, concise and timely fashion.\n\nPerforms data collection, analysis, reporting.\n\nProvide guidance and support to all claims and operations personnel towards resolution of provider data and claims problems with an emphasis on root cause analysis and resolution of problems\n\nCompile, review and analyze management reports and take appropriate action\n\nIdentify and advise Claims, Provider Network Management, Medicare Operations and other operational areas of trends, problems, and issues as well as recommended course of action; ensure timely communication; participate in the development and implementation of solutions\n\nMonitor adherence to the efficiency and service level goals including volume, processing, timeliness, accuracy and other metrics.\n\nCompose, submit and track claim system questions and configuration requests to correct identified systemic issues\n\nPrioritize issues identified by TPA/BPO, internal team members and/or partner representatives and monitors progress in the resolution of the issues\n\nDevelop deep understanding of processing capabilities and limitations of claims and benefits with TPA/BPO systems, tools and resources; provide recommendations to meet plan requirements\n\nConfirm that all provider data elements have been set up within the claims payment system and are aligned with the requirements as specified by the plan materials.\n\nCreate and report operational tracking metrics and dashboards for monitoring claims, provider disputes and benefits performance.\n\nCoordinate corrective action plans with partner/client and TPA/BPO operations services administrator to resolve issues.\n\nSupport internal plan team members with the resolution of daily issues.\n\nWork with other departments to identify and resolve problems leading to incorrect provider data and issues regarding payment of claims.\n\nServe on various committees and attends required meetings.\n\nPerform other duties and projects as assigned\n\nKey competencies/skill/success factors:\n\nExperience working within a health plan, managed care organization, provider operated healthcare environment or third party administrator\nGood Knowledge on Python, SQL Server- SSMS, SSRS.\n\nExtensive knowledge of PCs and related software applications, such as Word, PowerPoint, Excel, Project\n\nDemonstrated exceptional active listening and communications skills\n\nExperience in systems and languages related to database lifecycle management such as MS Access, Visual Basic, etc\n\nQualification and Experience:\n\nRequired\n\nAssociates Degree or equivalent\n\n2-4 years of experience in collecting, analyzing, and presenting data and recommendations to management\n\nBig plus\n\nBachelor s degree in Computer Science, Statistics, Mathematics or related field\n\n1-3 years data analysis and business intelligence experience working with BI suites such as Power BI, SSRS or other enterprise class tools\nMandatory Requirements:\nEmployees must have a high-speed broadband internet connection with a minimum speed of 50 Mbps and the ability to set up a wired connection to their home network to ensure effective remote work. These requirements may be updated as needed by the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['BPO', 'Data analysis', 'Claims', 'Visual Basic', 'Data management', 'MS Access', 'Analytical', 'Data collection', 'Business intelligence', 'SQL']",2025-06-14 05:30:10
Technical Business Analysis Specialist,Telstra,4 - 9 years,Not Disclosed,"['Pune', 'Bengaluru']","Employment Type Permanent\nClosing Date 29 June 2025 11:59pm\nJob Title Technical Business Analysis Specialist\nJob Summary\nAs a Technical Business Analysis Specialist, you thrive on collaborating with your team and providing valuable input to support stakeholders and team members to deliver technical analysis and research that enables successful business initiative/mission design and delivery, and ongoing technical capability operational performance. Job Description Key Responsibilities",,,,"['Data analysis', 'Business analysis', 'Agile', 'Workflow', 'Data structures', 'business rules', 'Gap analysis', 'Continuous improvement', 'Operations', 'performance measurement']",2025-06-14 05:30:13
Data Scientist 1,Paypal,25 - 30 years,Not Disclosed,['Bengaluru'],"The Company\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\nOur beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do - and they push us to ensure we take care of ourselves, each other, and our communities.\nJob Summary:\nWhat you need to know about the role -\nWe are looking for Senior Data Scientist with experience of managing large portfolios to develop PayPal s Risk strategy within the Rewards, Loyalty and Honey Risk solutions team. This portfolio comprises PayPal s global marketing initiatives and campaigns, as well as customized experiences developed for the company s highest-priority strategic partnerships.\n\nMeet our team\nPayPal s Reward, Loyalty & Honey risk team fraud Risk team is responsible for assessing and managing buyer and seller side risk exposures for all global marketing initiatives. The team is also responsible for partnering with the corresponding Business Units and Product teams to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.\nJob Description:\nThis role will be the end-to-end owner of the Reward payout risk solutions and is responsible for end-to-end management of marketing budget loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, collaborate with ML engineering, product and technology teams on attribute, model and platform requirements, mentoring juniors in team, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.\nIf you re interested in enriching PayPal rewarding experiences and think customer back, then this is the right team for to join!\nYour day to day :\nEach Senior Data Scientist on this team has full ownership of Reward payout portfolio and is responsible for end-to-end management of loss and decline rates for marketing budget.\nDay-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, collaborate with ML engineering, product and technology teams on attribute, model and platform requirements, communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.\nWorks independently and proficiently. Accountable for own results. Reviews are mainly for consultation and sharing ideas.\nWorks on multiple assignments simultaneously and in all areas of a standard project in the area of responsibility.\nWhat do you need to bring\nStrong analytical skills -- ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.\nEnthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired Work experience at the management consulting firms is a plus.\nPolished communication and influence skills - risk decision scientists need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies. Demonstrated ability to influence groups and effectively resolve conflicts is required.\nAn innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas. You will be expected to become an expert in your specific domain.\nCan-do attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.\nIdentify typical problems and issues during normal course of work and take proactive actions to solve them with minimum guidance. Recommends changes to policies and establishes procedures that affect immediate organization(s).\nExercises discretion in resolving a variety of issues in imaginative as well as practical ways.\nImpact of decision has moderate to large reach\nOffers insight for and contributes to improving existing technology, tools, processes, and business solutions. Adds value to brainstorming sessions\nBS/BA degree with 6+ years of related professional experience or master s degree with 4+ years of related experience.\nFocuses primarily on how to achieve overall analytic objectives of a project with speed and quality.\nSuggests ideas for operational plans and objectives\nClear subject matter expert within group / geography\nWorks independently and proficiently on multiple assignments simultaneously with speed and quality\nManage junior decision/data scientists.\nPreferred Qualification:\nSubsidiary:\nPayPal\nTravel Percent:\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits:\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com .\nWho We Are:\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talentaccommodations@paypal.com .\nBelonging at PayPal:\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: FinTech / Payments,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Excel', 'Management consulting', 'Subject Matter Expert', 'Risk management', 'Business solutions', 'Forecasting', 'Operations', 'Monitoring', 'SQL']",2025-06-14 05:30:15
Data Entry And Content Editor (Non-Technical),IDZ Digital,0 - 1 years,1-1.5 Lacs P.A.,['Mumbai'],"Key responsibilities:\n1. Accurately cut, copy, paste, and manage data in internal sheets and tools.\n2. Proofread and edit written content to ensure it is free of errors and polished for final use.\n3. Maintain the consistency and accuracy of data records across platforms.\n4. Deliver tasks on time while ensuring quality standards are met.\n5. Communicate with team members to resolve any discrepancies or clarify instructions.\nWho Should Apply:\n1. Candidates with strong attention to detail.\n2. Those seeking non-technical positions focused on clerical or administrative work.\n3. Individuals with experience in data entry, record management, or content editing.\nImportant Note: This is NOT a technical database management or developer role. Candidates with SQL, programming, or data analytics expertise may find this position unrelated to their skills.",Industry Type: Software Product,Department: Other,"Employment Type: Full Time, Permanent","['Proof Reading', 'Data Extraction', 'Technical Documentation', 'User Support', 'Communication Skills', 'Process Documentation', 'Content Management', 'Documentation', 'Data Analysis', 'Technical Writing']",2025-06-14 05:30:17
"Business Analyst, INSLP",Amazon,1 - 6 years,Not Disclosed,['Bengaluru'],"The ideal candidate is an experienced analyst who has demonstrated proficiency in analytics driven business solutions. The person would be a Data resource for the team and would work to generate actionable intelligence and insights for the team through rigorous data analysis and structured reporting, ensuring their efforts are focused in the appropriate areas. The person would deep-dive and bring out pointers that will help bring in continuous improvement/changes in processes from the Loss Prevention standpoint, thereby helping in reducing the losses across Amazon network. They are comfortable in analyzing data from multiple sources to create strategic recommendations in a thoughtful, concise manner and obtaining organizational buy-in at senior levels. They are well-organized, can manage multiple analyses/projects simultaneously, and is intellectually curious. Successful candidates will be expected to demonstrate our leadership principles: a bias for action, deep-dive, ownership and customer-obsession.\n\n\nKey Responsibilities includes\n1.Converting data into digestible business intelligence and actionable information\n2.Writing high quality SQL codes to retrieve and analyze data.\n3.Working with large data sets, automate data extraction, and build monitoring/reporting dashboard\n4.Interacting with internal stakeholders to deep-dive outlier events\n5.Analyze and solve business problems with focus on understanding root causes and driving forward-looking opportunities\n6.Communicating complex analysis and insights to our stakeholders and business leaders, both verbally and in writing.\n7.Enable effective decision making by retrieving and aggregating data from multiple sources and compiling it into a digestible and actionable format 1+ years of tax, finance or a related analytical field experience\n2+ years of complex Excel VBA macros writing experience\nBachelors degree or equivalent\nExperience defining requirements and using data and metrics to draw business insights\nExperience with SQL or ETL Experience working with Tableau\nExperience using very large datasets",,,,"['Data analysis', 'Analytical', 'Business intelligence', 'Continuous improvement', 'Business solutions', 'Macros', 'Analytics', 'Monitoring', 'SQL', 'Data extraction']",2025-06-14 05:30:19
"Analyst II, Global Finacial Data Operations",Kroll,1 - 4 years,Not Disclosed,['Mumbai'],"We are looking for an analyst for our Client Services Operations team which performs, Data extraction, Data analysis on financial models and financial valuation reports along with report updates and various support services. The team undertakes research and collects financial and business data based on the request from the internal Kroll business units. The relevant financial and business data is collected through various publicly available sources and Kroll proprietary files. Pursuant to the collection, the data is summarized in the format prescribed by the Kroll business units. The team also undertakes subsequent analysis with respect to the completeness of the data and verification of accuracy of the information. This enables the business units to have easy access of information / data as available at various sources.",,,,"['Analytical skills', 'Data analysis', 'Due diligence', 'Consulting', 'Anti money laundering', 'Workflow', 'Support services', 'Corporate finance', 'Research', 'Data extraction']",2025-06-14 05:30:22
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Bengaluru'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Microsoft Dynamics 365 ERP Technical\n\n\n\n\nGood to have skills :Microsoft Dynamics AX TechnicalMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Develop and implement strategies for process improvement.- Conduct business process modeling and simulation.- Facilitate workshops and meetings to gather requirements.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Microsoft Dynamics 365 ERP Technical.- Good To Have\n\n\n\n\nSkills:\nExperience with Microsoft Dynamics AX Technical.- Strong understanding of ERP systems and business processes.- Knowledge of data analysis and interpretation.- Experience in system integration and customization.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Microsoft Dynamics 365 ERP Technical.- This position is based at our Hyderabad office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['erp', 'data analysis', 'microsoft dynamics', 'erp systems', 'microsoft dynamics ax', 'business process modeling', 'project management', 'business analysis', 'process improvement', 'user stories', 'sql', 'system integration', 'brd', 'frd', 'scrum', 'agile', 'requirement analysis']",2025-06-14 05:30:24
"Global Payplus, GPP SP, Business Analyst/Sr. BA",Hsbc,5 - 8 years,Not Disclosed,['Pune'],"Some careers shine brighter than others.\nIf you re looking for a career that will help you stand out, join HSBC and fulfil your potential. Whether you want a career that could take you to the top, or simply take you in an exciting new direction, HSBC offers opportunities, support and rewards that will take you further.\nHSBC is one of the largest banking and financial services organisations in the world, with operations in 64 countries and territories. We aim to be where the growth is, enabling businesses to thrive and economies to prosper, and, ultimately, helping people to fulfil their hopes and realise their ambitions.\nWe are currently seeking an experienced professional to join our team in the role of Consultant Specialist.\nIn payment domain with 5+ years of experience. The role of the SME is to create test strategy, supporting test engineer in testing activities, identifying the automation opportunities and able to do hands on GPP SP platform. Associate should have hands on knowledge of Global Payment plus (GPP SP). experience on bug tracking system like Jira, good knowledge of SQL queries, understanding of defect life cycle and good communication are essential for this role. Knowledge of any automation tool is preferable. It is expected that SME should be able to work on automation tool. This role will also require interaction with various teams, timely and quality deliveries of assigned task\nIn this role, you will:\nProcess and System Analysis\nRequirements Gathering and Documentation\nData Analysis and Reporting\nSolution Design and Implementation\nStakeholder Communication\nContinuous Improvement\n\n\n\n\n\n\n\n\n\n\nRequirements\n\n\n\nTo be successful in this role, you should meet the following requirements:\nHands on experience GPP product is MUST\nAnalytical Skills\nCommunication Skills\nProblem-Solving Skills\nTechnical Skills\nBusiness Acumen\nProject Management Skills\nGood communication skill\nHands on experience on Jira and Confluence.",Industry Type: Consumer Electronics & Appliances,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analytical skills', 'Automation', 'Data analysis', 'Test strategy', 'Project management', 'Defect life cycle', 'JIRA', 'Continuous improvement', 'System analysis', 'Financial services']",2025-06-14 05:30:26
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Navi Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Property and Casualty Insurance\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Additionally, you will research, gather, and synthesize information to contribute to the success of the organization.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Conduct thorough analysis of business processes and systems.- Identify areas for improvement and propose solutions.- Collaborate with stakeholders to gather and document business requirements.- Create and maintain project documentation.- Assist in the development and execution of test plans.- Conduct user acceptance testing and provide feedback.- Support the implementation of new processes and systems.- Provide training and support to end-users.- Stay up-to-date with industry trends and best practices.- Assist in the development and implementation of change management strategies.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Property and Casualty Insurance.- Strong understanding of business analysis methodologies and techniques.- Experience in conducting business process analysis and improvement.- Knowledge of requirements gathering and documentation.- Familiarity with project management principles and practices.- Good To Have\n\n\n\n\nSkills:\nExperience with Agile methodologies.- Experience with data analysis and visualization tools.- Knowledge of insurance industry regulations and compliance.- Excellent communication and interpersonal skills.- Ability to work independently and in a team environment.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Property and Casualty Insurance.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'business analysis', 'business process analysis', 'user acceptance testing', 'agile methodology', 'data analysis', 'project documentation', 'documentation', 'change management', 'sql', 'providing training', 'business requirement analysis', 'brd', 'frd', 'agile']",2025-06-14 05:30:29
"Sr Business Analyst (Process Modeling, and Stakeholder Collaboration)",Synechron,7 - 12 years,Not Disclosed,"['Pune', 'Hinjewadi']","Job Summary\nSynechron is seeking a highly experienced and detail-oriented Senior Business Analyst to join our dynamic team. In this role, you will serve as a key contributor to our business analysis function, translating complex business needs into effective solutions that support organizational goals. Your expertise will enable our teams to deliver value-driven projects efficiently and effectively, ensuring alignment with strategic objectives and stakeholder expectations.\nSoftware Requirements\nRequired Skills:",,,,"['Python', 'Azure', 'Kanban', 'NoSQL', 'Scrum', 'SQL Server', 'Oracle', 'AWS']",2025-06-14 05:30:31
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,5 - 7 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n5 to 7+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-14 05:30:34
Data Security Analyst 3-5 Yrs C2H Role,Greetings from BCforward INDIA TECHNOLOG...,3 - 5 years,3-7 Lacs P.A.,['Hyderabad'],"Greetings from BCforward INDIA TECHNOLOGIES PRIVATE LIMITED.\n\nContract To Hire(C2H) Role\nLocation: Hyderabad\nPayroll: BCforward\nWork Mode: Hybrid\n\nJD\n\nTitle: Data Security Analyst\nLocation: Hyderabad\nNo. of Positions: 1\nShift Timings: 2-11 PM\n\nKey Pointers\nExcellent Communication Skills (Final round with multiple US panel)\nBachelors Degree\nMinimum 3 - 4 years experience in the following:\nAdvance Excel is must.\nMicrosoft Office skills of PowerPoint, One Note, Word, Teams)\nKnowledge of the professional services industry preferred.\nKnowledge of Active Directory security groups and how they are applied for data security.\nKnowledge of VBA is good to have.\n\nPlease share your Updated Resume, PAN card soft copy, Passport size Photo & UAN History.\n\nInterested applicants can share updated resume to g.sreekanth@bcforward.com\n\nNote: Looking for Immediate to 15-Days joiners at most.\n\nAll the best",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Temporary/Contractual","['Advance Excel', 'Data Security Analyst', 'Microsoft Office', 'Data Security', 'Active Directory', 'VBA']",2025-06-14 05:30:36
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,8 - 9 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n8 to 9+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-14 05:30:39
Senior Business Systems Analyst,AMERICAN EXPRESS,2 - 3 years,Not Disclosed,['Gurugram'],"Here, your voice and ideas matter, your work makes an impact, and together, you will help us define the future of American Express.\nHow will you make an impact in this role?\nProvide comprehensive MI & Analytical support to Executive Leadership on key operations metrics across Servicing Functions within GSG.\nResponsibilities:\nProviding Analytical & Decision Support across GSG through advanced analytics (from sourcing to staging data, generating insights to exposing them for consumption via reporting platforms/strategy implementation)",,,,"['Relationship management', 'Data analysis', 'Finance', 'MIS', 'Business analytics', 'Analytical', 'Forecasting', 'Operations', 'Analytics', 'SQL']",2025-06-14 05:30:41
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Navi Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Property and Casualty Insurance\n\n\n\n\nGood to have skills :Business AnalysisMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Additionally, you will research, gather, and synthesize information to contribute to the success of the organization.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Conduct thorough analysis of business processes and systems.- Identify areas for improvement and propose solutions.- Collaborate with stakeholders to gather and document business requirements.- Create and maintain project documentation.- Assist in the development and execution of test plans.- Conduct user acceptance testing and provide feedback.- Support the implementation of new processes and systems.- Provide training and support to end-users.- Stay up-to-date with industry trends and best practices.- Assist in the development and implementation of change management strategies.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Property and Casualty Insurance, Business Analysis.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.- Strong understanding of business process modeling and analysis.- Experience in conducting stakeholder interviews and workshops.- Ability to translate business requirements into functional specifications.- Familiarity with data analysis and visualization tools.- Ability to work effectively in a cross-functional team environment.\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Property and Casualty Insurance and Business Analysis.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business process modeling', 'property and casualty insurance', 'business analysis', 'machine learning algorithms', 'statistics', 'data analysis', 'bi', 'power bi', 'machine learning', 'data cleansing', 'business requirement analysis', 'tableau', 'data visualization', 'data munging']",2025-06-14 05:30:43
Associate Analyst,NOVARTIS,No fixed duration,Unpaid,['Hyderabad'],"Summary\nNovartis is undergoing a data and digital transformation to harness the power of analytics in driving impactful decisions that touch the lives of over 500 million patients globally. As part of this journey, the Insights & Decision Science (IDS) team plays a critical role in centralizing insights and analytics across the organization eliminating silos, reducing systemic friction, and enabling more informed, connected decision-making. We are looking for passionate and curious individuals to join our team as Associate Analysts, contributing to this mission by transforming data into actionable insights that shape the future of healthcare.",,,,"['Claims', 'Diagnostics', 'Pharma', 'Pharmacy', 'Healthcare', 'Life sciences', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-14 05:30:46
Data Scientist,Ford,1 - 8 years,Not Disclosed,['Chennai'],"Ford/GDIA Mission and Scope:\n\n\nCreating the future of smart mobility requires the highly intelligent use of data, metrics, and analytics. That s where you can make an impact as part of our Global Data Insight & Analytics team. We are the trusted advisers that enable Ford to clearly see business conditions, customer needs, and the competitive landscape. With our support, key decision-makers can act in meaningful, positive ways. Join us and use your data expertise and analytical skills to drive evidence-based, timely decision-making.\n\nThe Global Data Insights and Analytics (GDI&A) department at Ford Motors Company is looking for qualified people who can develop scalable solutions to complex real-world problems using Machine Learning, Big Data, Statistics, Econometrics, and Optimization. The goal of GDI&A is to drive evidence-based decision making by providing insights from data. Applications for GDI&A include, but are not limited to, Connected Vehicle, Smart Mobility, Advanced Operations, Manufacturing, Supply chain, Logistics, and Warranty Analytics.\n\nAbout the Role:\n\nYou will be part of the FCSD analytics team, playing a critical role in leveraging data science to drive significant business impact within Ford Customer Service Division. As a Data Scientist, you will translate complex business challenges into data-driven solutions. This involves partnering closely with stakeholders to understand problems, working with diverse data sources (including within GCP), developing and deploying scalable AI/ML models, and communicating actionable insights that deliver measurable results for Ford.\nQualifications:\n\n\nAt least 2 years of relevant professional experience applying data science techniques to solve business problems. This includes demonstrated hands-on proficiency with SQL and Python.\n\nBachelors or Masters degree in a quantitative field (e. g. , Statistics, Computer Science, Mathematics, Engineering, Economics).\n\nHands-on experience in conducting statistical data analysis (EDA, forecasting, clustering, hypothesis testing, etc. ) and applying machine learning techniques (Classification/Regression, NLP, time-series analysis, etc. ).\n\n\n\n\n\nTechnical Skills:\n\n\nProficiency in SQL, including the ability to write and optimize queries for data extraction and analysis.\n\nProficiency in Python for data manipulation (Pandas, NumPy), statistical analysis, and implementing Machine Learning models (Scikit-learn, TensorFlow, PyTorch, etc. ).\n\nWorking knowledge in a Cloud environment (GCP, AWS, or Azure) is preferred for developing and deploying models.\n\nExperience with version control systems, particularly Git.\n\nNice to have: Exposure to Generative AI / Large Language Models (LLMs).\n\n\n\n\n\nFunctional Skills:\n\n\nProven ability to understand and formulate business problem statements.\n\nAbility to translate Business Problem statements into data science problems.\n\nStrong problem-solving ability, with the capacity to analyze complex issues and develop effective solutions.\n\nExcellent verbal and written communication skills, with a demonstrated ability to translate complex technical information and results into simple, understandable language for non-technical audiences.\n\nStrong business engagement skills, including the ability to build relationships, collaborate effectively with stakeholders, and contribute to data-driven decision-making.\n\n\n\nBuild an in-depth understanding of the business domain and data sources, demonstrating strong business acumen.\n\nExtract, analyze, and transform data using SQL for insights.\n\nApply statistical methods and develop ML models to solve business problems.\n\nDesign and implement analytical solutions, contributing to their deployment, ideally leveraging Cloud environments.\n\nWork closely and collaboratively with Product Owners, Product Managers, Software Engineers, and Data Engineers within an agile development environment.\n\nIntegrate and operationalize ML models for real-world impact.\n\nMonitor the performance and impact of deployed models, iterating as needed.\n\nPresent findings and recommendations effectively to both technical and non-technical audiences to inform and drive business decisions.",Industry Type: Auto Components,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Data analysis', 'Analytical', 'Customer service', 'Econometrics', 'Forecasting', 'Analytics', 'SQL', 'Logistics', 'Data extraction']",2025-06-14 05:30:48
Associate Analyst,NOVARTIS,0 - 2 years,Not Disclosed,['Hyderabad'],"Summary\nNovartis is looking for a Associate Analyst - Analytics for its International BA team. The Associate Analyst will be responsible for providing analytical support on high complexity reports to internal customers, contributing to business decision-making by analysing commercial analytics data and identifying trends. The role includes working in commercial analytics projects, maintaining the existing reports and supporting the development of reporting platforms based on business inputs. The Associate analyst will work collaboratively with various cross-functional teams to meet business requirements. They will also participate in performance tracking, knowledge sharing, and support day-to-day business-related tasks. The role requires being detail-oriented, having a knack for interpreting data trends and insights, and being adept at collaborative work.",,,,"['Statistical analysis', 'Pharmacy', 'Pharma', 'Healthcare', 'Market research', 'power bi', 'Life sciences', 'data integrity', 'SQL', 'Python']",2025-06-14 05:30:51
Data Scientist,Ford,1 - 8 years,Not Disclosed,['Chennai'],"Ford/GDIA Mission and Scope:\n\n\nCreating the future of smart mobility requires the highly intelligent use of data, metrics, and analytics. That s where you can make an impact as part of our Global Data Insight & Analytics team. We are the trusted advisers that enable Ford to clearly see business conditions, customer needs, and the competitive landscape. With our support, key decision-makers can act in meaningful, positive ways. Join us and use your data expertise and analytical skills to drive evidence-based, timely decision-making.\n\nThe Global Data Insights and Analytics (GDI&A) department at Ford Motors Company is looking for qualified people who can develop scalable solutions to complex real-world problems using Machine Learning, Big Data, Statistics, Econometrics, and Optimization. The goal of GDI&A is to drive evidence-based decision making by providing insights from data. Applications for GDI&A include, but are not limited to, Connected Vehicle, Smart Mobility, Advanced Operations, Manufacturing, Supply chain, Logistics, and Warranty Analytics.\n\nAbout the Role:\n\nYou would be part of FCSD analytics team.\n\nAs a Data Scientist on the team, you will collaborate within the team and work with business partners to understand business problems and explore data from various sources in GCP-Data Factory, wrangle them to develop solutions using AI/ML algorithms to provide actionable insights that deliver key results to Ford.\n\nThe potential candidate should have hands-on experience in building statistical/machine learning models adhering to the best practices of development and deployment in cloud environment. This role requires a solid problem-solving skill, business acumen, and passion for leveraging data science/AI skills to drive business results.\nQualifications:\n\n\nAt least 2 years of relevant work experience in solving business problems using data science\n\nBachelors/master s degree in quantitative domain, Statistics, Computer science, Mathematics, Engineering with MBA from a premier institute (BE, MS, MBA, BSc/MSc -Computer science/Statistics) or any other equivalent\n\n2+ years of experience with SQL, Python delivering analytical solutions in production environment.\n\nAt least 1 year of experience working in Cloud environment (GCP or AWS or Azure)\n\n2+ years of experience in conducting statistical data analysis (EDA, forecasting, clustering, etc. , ) and machine learning techniques (Classification/Regression, NLP)\n\n\nTechnical Skills:\n\n\nProficient in BigQuery/SQL, Python\n\nAdvanced SQL knowledge to handle large data, optimize queries.\n\nWorking knowledge in GCP environment (Big Query, Vertex AI) to develop and deploy machine Learning models\n\nNice to have: Exposure to Gen AI/LLM\n\n\nFunctional Skills:\n\n\nUnderstanding and formulating business problem statements\n\nConvert Business Problem statement into data science problems.\n\nSelf-motivated with excellent verbal and written skills\n\nHighly credible in organizational, time management and decision making.\n\nExcellent Problem-Solving and Interpersonal skills\n\nJob Responsibilities\n\n\nBuild an in-depth understanding of the business domain and data sources.\n\nExtract, Analyse data from database/data warehouse to gain insights, discover trends and patterns with clear objectives in mind.\n\nDesign and implement scalable analytical solutions in Google cloud environment.\n\nWork closely with Product Owner, Product Manager, Software engineers and Data engineers to build products in agile environment.\n\nOperationalize AI/ML/LLM models by integrating with upstream and downstream business processes.\n\nCommunicate results to business teams through effective presentations.\n\nWork with business partners through problem formulation, data management, solutions development, operationalization, and solutions management\n\nIdentify opportunities to build analytical solutions driving business value, leveraging various data sources.",Industry Type: Auto Components,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Computer science', 'Data analysis', 'Data management', 'Machine learning', 'Agile', 'Analytics', 'SQL', 'Python', 'Logistics']",2025-06-14 05:30:54
Data Scientist,Ford,1 - 8 years,Not Disclosed,['Chennai'],"The Global Data Insights and Analytics (GDI&A) department at Ford Motors Company is looking for qualified people who can develop scalable solutions to complex real-world problems using Machine Learning, Big Data, Statistics, Econometrics, and Optimization. The candidate should possess the ability to translate a business problem into an analytical problem, identify the relevant data sets needed for addressing the analytical problem, recommend, implement, and validate the best suited analytical algorithm(s), and generate/deliver insights to stakeholders. Candidates are expected to regularly refer to research papers and be at the cutting-edge with respect to algorithms, tools, and techniques. The role is that of an individual contributor; however, the candidate is expected to work in project teams of 2 to 3 people and interact with Business partners on regular basis.\n\nMasters degree in computer science, Operational research, Statistics, Applied mathematics, or in any other engineering discipline.\n\nProficient in querying and analyzing large datasets using BigQuery on GCP. Strong Python skills for data wrangling and automation.\n\n2+ years of hands-on experience in Python programming for data analysis, machine learning, and with libraries such as NumPy, Pandas, Matplotlib, Scikit-learn, TensorFlow, PyTorch, NLTK, spaCy, and Gensim.\n\n2+ years of experience with both supervised and unsupervised machine learning techniques.\n\n2+ years of experience with data analysis and visualization using Python packages such as Pandas, NumPy, Matplotlib, Seaborn, or data visualization tools like Dash or QlikSense.\n\n1+ years experience in SQL programming language and relational databases.\n\n\nUnderstand business requirements and analyze datasets to determine suitable approaches to meet analytic business needs and support data-driven decision-making by FCSD business team\n\nDesign and implement data analysis and ML models, hypotheses, algorithms and experiments to support data-driven decision-making\n\nApply various analytics techniques like data mining, predictive modeling, prescriptive modeling, math, statistics, advanced analytics, machine learning models and algorithms, etc. ; to analyze data and uncover meaningful patterns, relationships, and trends\n\nDesign efficient data loading, data augmentation and data analysis techniques to enhance the accuracy and robustness of data science and machine learning models, including scalable models suitable for automation\n\nResearch, study and stay updated in the domain of data science, machine learning, analytics tools and techniques etc. ; and continuously identify avenues for enhancing analysis efficiency, accuracy and robustness",Industry Type: Auto Components,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Data analysis', 'Analytical', 'Machine learning', 'Predictive modeling', 'data visualization', 'Data mining', 'SQL', 'Python']",2025-06-14 05:30:56
Assistant Data Scientist,Rocket Software,0 - 1 years,Not Disclosed,['Pune'],"Face to Face interview in Pune . Please apply only if you are available for a Face to Face interview .\n\nJob highlights\n\nRequired Qualifications . 0 -2 years of relevant industry experience or fresh graduates are welcome to apply.\nBasic experience or understanding in applying Data Science methodologies to extract, process, and transform data from multiple sources.\nPreferred Qualifications . Bachelors degree in Data Science , AI, Statistics ,Computer Science, Economics, or a directly related field.\n\nEssential Duties and Responsibilities\n\nAssist in developing, fine-tuning, and deploying machine learning models.\nAid in consulting with key internal and external stakeholders to understand and frame model requirements and potential applications.\nParticipate in the development of sound analytic plans based on available data sources, business partner needs, and required timelines.\nWork with software engineers in integrating trained models into end-user applications.\nHelp manage deliverables across multiple projects in a deadline-driven environment.\nPresent results, insights, and recommendations to both technical and non-technical stakeholders.\n\nRequired Qualifications\n\n0 -2 years of relevant industry experience or fresh graduates are welcome to apply.\nGood knowledge of Python and Linux, familiarity with ML frameworks, and a willingness to learn.\nDemonstrated problem-solving abilities and creative thinking.\nBasic experience or understanding in applying Data Science methodologies to extract, process, and transform data from multiple sources.\nExcellent communication and interpersonal skills.\nMust be comfortable working in a team-oriented environment.\n\nPreferred Qualifications\n\nBachelor's degree in Statistics, Computer Science, Economics, or a directly related field.\nMasters degree or current enrollment in a Masters program in Statistics, Computer Science, Mathematics, Economics, or directly related fields is a plus.\nDemonstrated passion for continued learning and innovation.\nAs a Data Science Assistant, we expect not just skills and qualifications, but also an enthusiasm for learning and growing within our team. We value those who are adaptable, innovative, and ready to take on challenges in a fast-paced work environment.\n\nDiversity, Inclusion & Equity\n\nAt Rocket we are committed to an inclusive workplace environment, where every Rocketeer can thrive by bringing their full selves to work. Being a Rocketeer means you are part of our movement to continually drive inclusivity, diversity and equity in our workforce.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'NLP', 'Natural Language Processing', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-14 05:30:58
Data Researcher & Email Marketing Executive,BTB Venture,0 - 1 years,Not Disclosed,['Pune'],"Role & res\nJob Title: Research Analyst (Fresher)\nCompany: BTB Venture Group\nLocation: Treza Business Hub, 105, Bengaluru - Mumbai Hwy, near Bitwise Tower, Baner, Pune, Maharashtra 411045\nWork Type: Work from Home\nWork Schedule: Monday to Friday (Saturday & Sunday fixed off)\nTimings: 09:30 AM 06:30 PM\nCompany Description:\nBTB Venture Group is a leading Forbes-listed demand generation and lead generation company operating globally. We specialize in delivering high-quality, targeted leads and boosting sales for businesses across various industries. Using advanced analytics, market expansion strategies, and real-time insights, we provide scalable, ROI-driven solutions to help our clients succeed. Join us to be part of a dynamic team that's shaping the future of global marketing.\nwww.btbventure.com\nEducation Qualification:\nBCA / BBA / MCA\nDiploma / BE / BTech in Computer Science or Information Technology\nRequired Skills:\nBasic understanding of Google Sheets\nFamiliarity with Email and Calendar tools\nExposure to tracking systems (e.g., Pivot tables, Filters)\nAbility to conduct effective online research\nKey Responsibilities:\nConduct market research and perform data analysis to identify trends and insights\nPrepare detailed research reports to support business strategies\nCollaborate with cross-functional teams to generate strategic insights\nWork on live projects to enhance practical analytical skills\nMaintain and regularly update the Campaign Spreadsheet to track performance metrics and research outcomes\nponsibilities\n\n\nPreferred candidate profile",Industry Type: Advertising & Marketing (Public Relations),Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Email Campaign', 'Database Marketing', 'Mass Mailing', 'Marketing Campaigns', 'Zoominfo', 'Email Marketing', 'Online Lead Generation', 'Online Research', 'Research', 'Demand Generation']",2025-06-14 05:31:01
"SENIOR, DATA SCIENTIST",Walmart,3 - 8 years,Not Disclosed,['Bengaluru'],"Position Summary...\nWhat youll do...\nAbout Team\nThe Catalog Data Science Team at Walmart Global Tech is focused on using the latest research in generative AI (GenAI), artificial intelligence (AI), machine learning (ML), statistics, deep learning, computer vision and optimization to implement solutions that ensure Walmart s product catalog is accurate, complete, and optimized for customer experience. Our team tackles complex data science and ML engineering challenges related to product classification, attribute extraction, trust & safety, and catalog optimization, empowering next-generation retail use cases.\nThe Data Science and ML Engineering community at Walmart Global Tech is active in most of the Hack events, utilizing the petabytes of data at our disposal, to build some of the coolest ideas. All the work we do at Walmart Global Tech will eventually benefit our operations & our associates, helping Customers Save Money to Live Better.\nWhat youll do:\nAs a Senior Data Scientist - ML Engineer, you ll have the opportunity to:\nDrive research initiatives and proof-of-concepts that push the state of the art in generative AI and large-scale machine learning.\nDesign and implement high-throughput, low-latency AI/ML pipelines and microservices that operate at global scale.\nOversee data ingestion, model training, evaluation, deployment and monitoring-ensuring performance, quality and reliability.\nCustomize and optimize LLMs for specific business use cases, balancing accuracy, latency and cost.\nPrototype novel generative AI solutions, integrate advancements into production, and collaborate with research partners.\nChampion best practices in data quality, lineage, governance and cost optimization across ML pipelines.\nMentor a team of ML engineers, establish coding standards, conduct design reviews, and foster a culture of continuous improvement.\nPresent your team s work at top-tier AI/ML conferences, publish scientific papers, and cultivate partnerships with universities and research labs.\nWhat youll bring\nPhD in Computer Science, Statistics, Applied Mathematics or related field with 3+ years experience in ML engineering-or Master s with 6+ years or Bachelor s with 8+ years.\nProven track record of leading and scaling AI/ML products in production environments.\nDeep expertise in generative AI, large-scale model deployment, and fine-tuning of transformer-based architectures.\nStrong programming skills in Python, or equivalent, and experience with big data frameworks (Spark, Hadoop) and ML platforms (TensorFlow, PyTorch).\nDemonstrated history of scientific publications or patents in AI/ML.\nExcellent communication skills, a growth mindset, and the ability to drive cross-functional collaboration.\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nMinimum Qualifications:Option 1- Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years experience in an analytics related field. Option 2- Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years experience in an analytics related field. Option 3 - 5 years experience in an analytics or related field.\nPreferred Qualifications...\nPrimary Location...\n\n\n",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Prototype', 'Networking', 'Coding', 'Machine learning', 'Continuous improvement', 'Information technology', 'Monitoring', 'Analytics', 'Python']",2025-06-14 05:31:03
"SENIOR, DATA SCIENTIST",Walmart,1 - 5 years,Not Disclosed,['Bengaluru'],"The Catalog Data Science Team at Walmart Global Tech is focused on using the latest research in generative AI (GenAI), artificial intelligence (AI), machine learning (ML), statistics, deep learning, computer vision and optimization to implement solutions that ensure Walmart s product catalog is accurate, complete, and optimized for customer experience. Our team tackles complex data science and ML engineering challenges related to product classification, attribute extraction, trust & safety, and catalog optimization, empowering next-generation retail use cases.\nThe Data Science and ML Engineering community at Walmart Global Tech is active in most of the Hack events, utilizing the petabytes of data at our disposal, to build some of the coolest ideas. All the work we do at Walmart Global Tech will eventually benefit our operations & our associates, helping Customers Save Money to Live Better.\nWhat youll do:\nAs a Senior Data Scientist - ML Engineer, you ll have the opportunity to:\nDrive research initiatives and proof-of-concepts that push the state of the art in generative AI and large-scale machine learning.\nDesign and implement high-throughput, low-latency AI/ML pipelines and microservices that operate at global scale.\nOversee data ingestion, model training, evaluation, deployment and monitoring-ensuring performance, quality and reliability.\nCustomize and optimize LLMs for specific business use cases, balancing accuracy, latency and cost.\nPrototype novel generative AI solutions, integrate advancements into production, and collaborate with research partners.\nChampion best practices in data quality, lineage, governance and cost optimization across ML pipelines.\nMentor a team of ML engineers, establish coding standards, conduct design reviews, and foster a culture of continuous improvement.\nPresent your team s work at top-tier AI/ML conferences, publish scientific papers, and cultivate partnerships with universities and research labs.\nWhat youll bring\nPhD in Computer Science, Statistics, Applied Mathematics or related field with 3+ years experience in ML engineering-or Master s with 6+ years or Bachelor s with 8+ years.\nProven track record of leading and scaling AI/ML products in production environments.\nDeep expertise in generative AI, large-scale model deployment, and fine-tuning of transformer-based architectures.\nStrong programming skills in Python, or equivalent, and experience with big data frameworks (Spark, Hadoop) and ML platforms (TensorFlow, PyTorch).\nDemonstrated history of scientific publications or patents in AI/ML.\nExcellent communication skills, a growth mindset, and the ability to drive cross-functional collaboration",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Prototype', 'Networking', 'Coding', 'Machine learning', 'Continuous improvement', 'Information technology', 'Monitoring', 'Analytics', 'Python']",2025-06-14 05:31:06
"SENIOR, DATA SCIENTIST",Walmart,1 - 5 years,Not Disclosed,['Bengaluru'],"Position Summary...\nWhat youll do...\nAbout Team\nThe Catalog Data Science Team at Walmart Global Tech is focused on using the latest research in generative AI (GenAI), artificial intelligence (AI), machine learning (ML), statistics, deep learning, computer vision and optimization to implement solutions that ensure Walmart s product catalog is accurate, complete, and optimized for customer experience. Our team tackles complex data science and ML engineering challenges related to product classification, attribute extraction, trust & safety, and catalog optimization, empowering next-generation retail use cases.\nThe Data Science and ML Engineering community at Walmart Global Tech is active in most of the Hack events, utilizing the petabytes of data at our disposal, to build some of the coolest ideas. All the work we do at Walmart Global Tech will eventually benefit our operations & our associates, helping Customers Save Money to Live Better.\nWhat youll do:\nAs a Senior Data Scientist for Walmart Global Tech, you ll have the opportunity to\nDesign, develop, and deploy AI/ML, NLP, LLM models into production environments with a focus on reliability and scalability\nIntegrate data science solutions into current business processes.\nDevelop and recommend process standards and best practices in Machine Learning as applicable to the retail industry.\nSpearhead collaborations with other senior team members and stakeholders, leveraging your data science expertise to drive strategic decision-making and optimize business operations\nPromote and support company policies, procedures, mission, values, and standards of ethics and integrity.\nWhat youll bring:\nQualifications\nPhD with >3 years of relevant experience / 4-year bachelor s degree with > 8 years of experience / Master s degree with > 6 years of experience. Educational qualifications should be preferably in Computer Science or a strongly quantitative discipline.\nDemonstrated history of strong hands-on experience in AI/ML modelling\nPrior Experience in building Vision-based models\nProven records of scientific publications or intellectual property generation\nPrior Experience in programming skills across data science, statistical analysis, big data and ML stack\nStrong communication skills with inclination to high ownership and commitment\nProven track record of delivering high-impact AI/ML solutions to Production\nMandatory Skills: Machine Learning, NLP, Computer Vision , Python, R\nAdditional Qualifications: Good to have experience in areas such as Graph Neural Networks, LLM Optimization\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nMinimum Qualifications:Option 1- Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 3 years experience in an analytics related field. Option 2- Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology, or related field and 1 years experience in an analytics related field. Option 3 - 5 years experience in an analytics or related field.\nPreferred Qualifications...\nPrimary Location...",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'Networking', 'Neural networks', 'Artificial Intelligence', 'Intellectual property', 'Machine learning', 'Information technology', 'Analytics', 'Python']",2025-06-14 05:31:08
Analyst-10,Aegis Media,0 - 3 years,Not Disclosed,['Bengaluru'],"The purpose of this role is to provide support for the collection, analysis, and dissemination of insights to our clients\nJob Description:\nKey responsibilities:\nIntegrates disparate datasets, conducts data preparation for analyses\nApplies data science methods to provide insights and recommendations to clients\nDelivers analytic outcomes based on project timelines and key milestones\nMaintains knowledge of new trends in the data science industry\nDevelops and manages code used for analytics purposes\nCommunicates findings and insights\nKnowledge on SQL, Tableau\nLocation:\nBangalore\nBrand:\nIprospect\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['tableau', 'Usage', 'data science', 'Senior Analyst', 'Analytics', 'SQL']",2025-06-14 05:31:11
Data Scientist,Leading Automobile Manufacturing Company...,5 - 10 years,Not Disclosed,['Chennai'],"Kindly share your resume on sv17@svmanagement.com\nResponsibility:\nWork with different user groups/ departments\nIdentify processes where Analytics driven decision making can create powerful impact\nDesign original analysis that helps generate relevant insights\nEstablishes credibility by thought partnering with business and service teams on analytics topics; takes positions and draws conclusions on a range of external and internal issues\nCommunicates analytical insights through sophisticated synthesis and packaging of results (including PPT slides, dashboards, mailers and alerts)\nCollect, synthesize, analyze team learning & inputs into new best practices and methodologies\nWork with IT teams for implementation of solutions in a production environment\nWork on development of internal capability on the subject\nKeep abreast of most recent developments in the Analytics space and identify new tools and capabilities relevant to company needs.\nAptitude to constantly learn and explore new analytical advancements\nContributes to development of new topic- and sector-related analytics products (development in scope for separate proprietary data & tools team)\nDevelops topic and content related to analytics work for trainings\nProfile:\nExperience in designing analytical solutions using machine learning algorithms\nKnowledge of advanced Excel for preliminary data analysis and good presentation skills\nProficient Coding Knowledge in Python is essential. Developing visualizations in Tableau is desirable\nAdditional coding knowledge in R & Visual Basic will be an advantage\nProficient in web analytics and predictive analytics\nGraduate/certificate in Business Analytics from premier Institute would be an advantage",Industry Type: Automobile,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'R', 'Visual Basic', 'Machine Learning', 'Python', 'Web Analytics', 'Tableau', 'Data Analytics', 'Predictive Analytics']",2025-06-14 05:31:13
Hiring Business Analyst with MSTR or Dataiku - Bangalore/ Chennai !!!!,Tech Mahindra,8 - 13 years,Not Disclosed,"['Chennai', 'Bengaluru']","A Business Analyst in the Financial Crime Surveillance Operations (FCSO) Data & Reporting PO Team understands the core concepts, principles, processes or procedures of Data & MI.\nExperienced in using MSTR reports & Dataiku. The FCSO Business Analyst gathers requirements from various stakeholders and creates user stories for the squad to understand and take it for delivery. They must have strong analytical skills, understand the strategic framework & make sense of data.\n\n1.Core Business Analysis Skills\nRequirement Gathering\nDocumentation\nGap analysis\n\n2. Data & MI Expertise\nData Analysis\nData mapping & Metrics understanding\nFCSO Process knowledge (Good to have)\n\n3. Technical Skills\nQuery Databases\nFamiliarity with BI Tools like Dataiku, MSTR\n\n4. Agile & Delivery management\n\nUnderstanding of Scrum for collaborating with Squads\nUser Story Creation\nBacklog Management\nStakeholder Management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Microstrategy', 'Business Analytics', 'Dataiku', 'Business Analysis']",2025-06-14 05:31:16
Business Systems Analyst,Lam Research,6 - 10 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\n[GOPS] [LIGO] [Spares Planning][Planning Systems]\nThe Impact You ll Make\nAs a Business Systems Analyst at Lam, you will be l eading strategic Programs that identify business problems and provide systems solutions/ systems improvement analysis in the Spares Planning function. In your role, you will be closely working on financial reporting of E&O for the spares planning organization and accounting for the worldwide spares inventory\nWhat You ll Do\nMonitoring and analyzing inventory levels, identifying trends, and forecasting demand to prevent excess buildup\nDetermining which parts are excess or obsolete, considering factors like shelf life, market demand, and potential for future use.\nCreating and implementing strategies to manage excess and obsolete inventory, including sell-off programs, returns, or disposal.\nDeveloping and implementing processes to optimize E&O management, including data analysis, reporting, and automation.\nShould be experienced in SAP. Have a good understanding of interfacing excel, SAP, external forecasting tool (SPM provided by PTC).\nProvides/defines input to Planning Systems Roadmap.\nWho We re Looking For\nEngineering degree in the field of Industrial Production/Mechanical (APICS CSCP/CPIM preferred). An MBA with experience in Financial reporting of E&O and exposure to inventory management is mandatory with 6-10 years of experience.\nProficiency in relevant software (e.g., SAP ERP, inventory management systems).\nHands-On technical skills (like Advanced Excel, SQL Programming, Power BI, Power Apps)\nStrong understanding of inventory management principles.\nExperience with E&O (Excess & obsolescence) processes and strategies.\nAbility to analyze data and identify trends.\nExcellent communication and collaboration skills.\nPreferred Qualifications\nHigh energy, strong work ethic, adaptive, able to meet tight deadlines\nProven ability and skill set to analyze, document and improve business processes with sustained results\nHigh level of customer interfacing skills, effective listener, professional and courteous\nExcellent verbal and written communication skills, able to communicate cross-functionally\nStrong interpersonal skills, with a desire to work as part of a team\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Product Management,"Employment Type: Full Time, Permanent","['Automation', 'Data analysis', 'SAP ERP', 'Financial reporting', 'Flex', 'Inventory management', 'Forecasting', 'Monitoring', 'Spares planning', 'SQL']",2025-06-14 05:31:19
Senior Business Analyst,Photon,6 - 10 years,Not Disclosed,['Chennai'],"Dear Candidate,\n\nAbout Photon:\n\nPhoton, a global leader in AI and digital solutions, helps clients accelerate AI adoption and embrace DigitalHyper-expansion to make tomorrow happen today. We work with 40% of the Fortune 100, enabling them to stay agile and future-ready in an era of converging digital and AI boundaries. Powering billions of touchpoints a day, Photon combines AI management, digital innovation, product design thinking, and engineering excellence to drive lasting transformation for F500 clients. We employ several thousand people across dozens of countries. Learn more at www.photon.com.",,,,"['E-commerce', 'Business analyst', 'Mobile Applications']",2025-06-14 05:31:21
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Bengaluru'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:31:23
Business Operations Analyst 3,Lam Research,5 - 10 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\nAs an Operations Analyst at Lam Research, you will play a pivotal role in enhancing the operational effectiveness and efficiency of the Global Operations team. By employing analytical methodologies, you will guide decision-makers towards achieving operational excellence. Your contributions will be critical in driving improvements and optimizing processes within the organization.\nThe Impact You ll Make\nAs an Operations Analyst at Lam Research, you will play a pivotal role in enhancing the operational effectiveness and efficiency of the Global Operations team. By employing analytical methodologies, you will guide decision-makers towards achieving operational excellence. Your contributions will be critical in driving improvements and optimizing processes within the organization.\nWhat You ll Do\nDevelop, automate, and maintain comprehensive reports and dashboards in both Excel & Power BI.\nAnalyze datasets to provide insights and create visualizations that tell a compelling data story.\nEnsure compliance with analytical standards and data governance policies to maintain data integrity and accuracy.\nChallenge stakeholders to prioritize long-term, data-driven decisions over quick fixes.\nIdentify and communicate process gaps, providing data-driven recommendations to leadership.\nFacilitate change management for data and process changes, ensuring smooth implementation and seamless rollout.\nMeasure and publish operational performance against established metrics and targets\nWho We re Looking For\nRequired Education:\nBachelor s degree in business administration, operations management, supply chain, project management, finance, engineering, or a related field.\nMinimum Qualifications:\nMinimum 5+ years of experience in operations, focused on extracting and analyzing operational data to generate meaningful insights.\nAdvanced capability in data analysis tools and software, particularly Excel (including advanced functions such as Pivot Tables and Power Query) and/or Power BI.\nDemonstrated ability to be a self-learner, continuously seeking out new knowledge and skills to overcome obstacles and enhance performance.\nExcellent written and verbal communication skills.\nProven ability to manage multiple tasks and prioritize effectively.\nDemonstrated ability to develop innovative, out-of-the-box solutions to complex business problems.\nBasic understanding of business operations and processes.\nRequired Skills:\nOperations, Excel (Advanced), Power BI, Data Analysis, Excellent Written and Verbal Communication Skills\nPreferred Qualifications\nExperience with Alteryx for data preparation, modelling, and advanced analytics.\nExceptional ability to analyze and optimize complex operational processes, driving significant improvements in efficiency and effectiveness.\nExtensive experience in process mapping and workflow analysis, with a proven track record of identifying and implementing process enhancements.\nStrong expertise in root cause analysis and corrective action planning, demonstrating the ability to resolve complex issues and prevent recurrence.\nPreferred Skills:\nData Modelling, Workflow Analysis, Corrective Action, Change Management, Root Cause Analysis, Data Governance, Metrics/KPIs, Project Management\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Supply chain', 'Root cause analysis', 'Data analysis', 'Change management', 'Operational excellence', 'Project management', 'Analytical', 'power bi', 'Operations', 'Business operations']",2025-06-14 05:31:26
Data Engineer - Databricks,KPI Partners,3 - 6 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","About KPI Partners.\nKPI Partners is a leading provider of data analytics solutions, dedicated to helping organizations transform data into actionable insights. Our innovative approach combines advanced technology with expert consulting, allowing businesses to leverage their data for improved performance and decision-making.\n\nJob Description.\nWe are seeking a skilled and motivated Data Engineer with experience in Databricks to join our dynamic team. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and data processing solutions that support our analytics initiatives. You will collaborate closely with data scientists, analysts, and other engineers to ensure the consistent flow of high-quality data across our platforms.",,,,"['python', 'data analytics', 'analytical', 'scala', 'pyspark', 'microsoft azure', 'data warehousing', 'data pipeline', 'data architecture', 'data engineering', 'sql', 'data bricks', 'cloud', 'analytics', 'data quality', 'data modeling', 'gcp', 'teamwork', 'integration', 'aws', 'etl', 'programming', 'communication skills', 'etl scripts']",2025-06-14 05:31:29
Senior Data Scientist,Ericsson,3 - 8 years,Not Disclosed,['Bengaluru'],"About this Opportunity\nThe complexity of running and optimizing the next generation of wireless networks, such as 5G with distributed edge compute, will require Machine Learning (ML) and Artificial Intelligence (AI) technologies. Ericsson is setting up an AI Accelerator Hub in India to fast-track our strategy execution, using Machine Intelligence (MI) to drive thought leadership, automate, and transform Ericsson s offerings and operations. We collaborate with academia and industry to develop state-of-the-art solutions that simplify and automate processes, creating new value through data insights.\n\nAs a Senior Data Scientist, you will apply your knowledge of data science and ML tools backed with strong programming skills to solve real-world problems.\nResponsibilities:\n1. Lead AI/ML features/capabilities in product/business areas\n2. Define business metrics of success for AI/ML projects and translate them into model metrics\n3. Lead end-to-end development and deployment of Generative AI solutions for enterprise use cases\n4. Design and implement architectures for vector search, embedding models, and RAG systems\n5. Fine-tune and evaluate large language models (LLMs) for domain-specific tasks\n6. Collaborate with stakeholders to translate vague problems into concrete Generative AI use cases\n7. Develop and deploy generative AI solutions using AWS services such as SageMaker, Bedrock, and other AWS AI tools. Provide technical expertise and guidance on implementing GenAI models and best practices within the AWS ecosystem.\n8. Develop secure, scalable, and production-grade AI pipelines\n9. Ensure ethical and responsible AI practices\n10. Mentor junior team members in GenAI frameworks and best practices\n11. Stay current with research and industry trends in Generative AI and apply cutting-edge techniques\n12. Contribute to internal AI governance, tooling frameworks, and reusable components\n13. Work with large datasets including petabytes of 4G/5G networks and IoT data\n14. Propose/select/test predictive models and other ML systems\n15. Define visualization and dashboarding requirements with business stakeholders\n16. Build proof-of-concepts for business opportunities using AI/ML\n17. Lead functional and technical analysis to define AI/ML-driven business opportunities\n18. Work with multiple data sources and apply the right feature engineering to AI models\n19. Lead studies and creative usage of new/existing data sources",,,,"['Wireless', 'Computer science', 'Data analysis', 'cassandra', 'Neural networks', 'Artificial Intelligence', 'Machine learning', 'Telecommunication', 'data visualization', 'Python']",2025-06-14 05:31:31
Senior Data Scientist - Multi-Agent AI Systems,Capgemini,9 - 14 years,Not Disclosed,"['Pune', 'Bengaluru']","Role & responsibilities\nWe are seeking an exceptional Data Scientist with specialized expertise in developing multi-agent AI systems. In this role, you will design, implement, and optimize complex AI ecosystems where multiple intelligent agents collaborate to solve sophisticated problems. You will leverage your deep understanding of generative AI, retrieval-augmented generation (RAG), and prompt engineering to create cutting-edge solutions that push the boundaries of artificial intelligence.\nKey Responsibilities\nDesign and develop generative AI-based multi-agent systems that can collaborate, communicate, and coordinate to achieve complex objectives\nArchitect and implement RAG-based chatbot solutions that effectively leverage knowledge bases and external data sources\nCreate sophisticated prompt engineering strategies to optimize AI agent behavior and inter-agent communication\nBuild, train, and fine-tune generative AI models for various applications within multi-agent systems\nDevelop robust evaluation frameworks to measure and improve multi-agent system performance\nImplement efficient knowledge sharing mechanisms between AI agents\nWrite clean, efficient, and well-documented Python code for production-ready AI systems\nCollaborate with cross-functional teams to integrate multi-agent systems into broader product ecosystems\nStay at the forefront of AI research and incorporate state-of-the-art techniques into our solutions\n\nPreferred candidate profile\nMaster's or PhD in Computer Science, Machine Learning, Artificial Intelligence, or related field\n4+ years of professional experience in data science or machine learning engineering\nExtensive experience with Python programming and related data science/ML libraries\nDemonstrated expertise in developing and deploying generative AI models (e.g., LLMs, diffusion models)\nProven experience building RAG-based systems and implementing vector databases\nStrong background in prompt engineering for large language models\nExperience designing and implementing generative AI-based multi-agent architectures\nExcellent problem-solving skills and ability to optimize complex AI systems\n\nPreferred Qualifications\nExperience with LangChain, AutoGPT, CrewAI, or similar frameworks for building agent-based systems\nFamiliarity with orchestration tools for managing complex AI workflows\nKnowledge of agent communication protocols and collaborative problem-solving frameworks\nExperience with distributed systems and cloud computing platforms (AWS, GCP, Azure)\nContributions to open-source AI projects or research publications in relevant fields\nExperience with knowledge graphs and semantic reasoning systems\nFamiliarity with MLOps practices and deployment of AI systems at scale",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Crewai', 'Langchain', 'AutoGPT']",2025-06-14 05:31:33
Data Entry Operator / Mis Executive,Talentlink Solutions,0 - 4 years,1-4 Lacs P.A.,[],"We Are looking For Computer Operator, Who can Perform defined tasks per documented instructions/process\n\nMale And Female Both Can apply\n\nFresher And Experience Both Can Apply\n\nBasic computer knowledge must\n\nHardworking\n\nWork from Home",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Back Office Processing', 'Non Voice Process', 'Data Entry', 'Back Office', 'Back Office Operations', 'Typing Speed', 'Computer Operating', 'Backend Operations', 'Chat Support', 'Non Voice', 'MS Office', 'Email Process', 'Chat Process', 'Data Processing', 'Data Entry Operation']",2025-06-14 05:31:36
Associate Analyst,Trigger Education Services,0 years,3.5-5 Lacs P.A.,['Mumbai (All Areas)'],"Roles and Responsibilities-\nReviewing new customer accounts and verifying their identities\nAssessing risks and compliance issues associated with customers or products\nStudying market trends and evaluating customer behavior\nAssisting efforts aimed at preventing money laundering, terrorist financing and other illicit financial activities\nCompiling accurate and up-to-date data on customers for compliance reasons\nLeveraging insights from customer behavioral research to improve customer experience\nLiaising with management to ensure compliance with internal policies and external regulations\nPreparing suspicious activity reports (SARs)\nReporting accounts with high risk or missing documentation to relevant officers\nPerforming complex data analysis to aid decision making\n\n\nDesired Candidate Profile -\nGraduate & Post Grdauates Freshers ( 2023-2024 Pass outs)\nExcellent reporting and observational skills\nStrong written and oral communication skills\nAbility to multi-task and coordinate multiple projects\nWell-developed IT skills\nInterpersonal skills\nData analysis\nManagement\nExcellent research skills and familiarity with online/offline research tools\n\n\nPerks and Benefits\nHigh incentives\nInternational Travel opportunity\n1side cab facility\nshuttle service\nlunch coupons",Industry Type: Investment Banking / Venture Capital / Private Equity,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Freshers', 'aml', 'KYC', 'Banking', 'Operations', 'communication skills']",2025-06-14 05:31:38
Business Analyst - Project Management Platforms Team,CBRE,1 - 3 years,Not Disclosed,"['Gurugram', 'Delhi / NCR']","Overview\n\nThe Project Management Platforms team at CBRE specializes in optimizing project delivery from concept to completion through innovative business enablement solutions. As a Business Analyst, you will assist in implementing various platforms and processes while collaborating with business leaders and team members across India.\n\nPrimary Responsibilities:\n\nStakeholder Management: Collaborate effectively with regional Business Development Teams and other service lines to gather requirements and drive initiatives.\nPitch Collateral Management: Manage and review pitch decks, ensuring high-quality power point presentations that effectively communicate complex data and concepts.\nPitch/Bid Management Support: Assist in the preparation and coordination of RFI/RFP responses, ensuring compliance with mandated formats and information.\nData Analysis and Reporting: Develop critical reports and dashboards, providing insights and commentary to support business goals. Utilize Excel for database modeling and analysis.\nSales Operations Technology Support: Integrate business processes with existing technology platforms, particularly Salesforce and other CRM/BI tools, to enhance efficiency.\nMarketing Coordination: Work closely with the Marketing team, providing relevant information for various initiatives to enhance project visibility and engagement.\n\nBasic Qualifications & Personal Attributes:\nBachelor's degree or equivalent.\n1 to 3 years of experience in Pre-Sales support, Platform, or Sales Operations.\nProficient in PowerPoint for creating impactful presentations.\nExcellent communication skills, both verbal and written, with the ability to articulate complex concepts clearly.\nStrong analytical, quantitative, and problem-solving abilities.\nProficient in Excel/Access for data modeling and analysis, with experience in Salesforce or similar CRM and BI platforms.\nCustomer service-oriented with a proactive attitude and high initiative.\nStrong attention to detail and the ability to manage timelines effectively.\n\nJoin our team and play a critical role in driving project management success through innovative solutions and exceptional stakeholder collaboration.",Industry Type: Real Estate,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Presales', 'Powerpoint', 'Presentation', 'Pitch Decks', 'CRM', 'Sales Operations', 'business analyst', 'Proposals', 'Business Analysis', 'Communication Skills', 'Real Estate', 'Data Analysis', 'RFP', 'Stakeholder Management', 'Salesforce']",2025-06-14 05:31:40
Strategy Analyst,Tex Corp,0 - 2 years,5-8 Lacs P.A.,['Gurugram'],"Responsibilities:\nData Coordination\nPresentation Development\nBusiness Insights Generation\nProblem Solving\nProject Support\nStakeholder Communication\nContinuous Improvement\nCollaborate with stakeholders on strategic initiatives\nAnalyze data, interpret insights & present findings\nSupport projects through analysis & coordination\nFacilitate continuous improvement processes",Industry Type: Textile & Apparel,Department: Strategic & Top Management,"Employment Type: Full Time, Permanent","['Presentation Preparation', 'Data Coordination', 'Business Insights', 'Project Support', 'Stakeholder Engagement', 'Continuous Improvement', 'Analytical', 'Data Interpretation', 'Problem Solving', 'Data Analysis', 'Coordination Skills']",2025-06-14 05:31:42
Technical Business Analysis Specialist,Telstra,4 - 9 years,Not Disclosed,['Pune'],"Employment Type Permanent\nClosing Date 29 June 2025 11:59pm\nJob Title Technical Business Analysis Specialist\nJob Summary\nAs a Technical Business Analysis Specialist, you thrive on collaborating with your team and providing valuable input to support stakeholders and team members to deliver technical analysis and research that enables successful business initiative/mission design and delivery, and ongoing technical capability operational performance. Job Description",,,,"['Data analysis', 'Business analysis', 'Agile', 'Data structures', 'Workflow', 'Gap analysis', 'Continuous improvement', 'JIRA', 'Operations', 'Business Technical Analyst']",2025-06-14 05:31:46
Sales & Marketing Intern (Data & CRM Support),Quick Heal Technologies,6 months duration,"15,000/month",['Pune( Viman Nagar )'],"About the Role:\nWe are looking for a passionate and motivated intern to join our Sales & Marketing team. This opportunity is ideal for fresh graduates or postgraduates, especially those with an MBA in Sales & Marketing, who are eager to gain hands-on experience in data analysis, company profiling, and CRM systems.\n\nPreferred Qualifications:",,,,"['Crm Tool', 'CRM Management', 'Marketing']",2025-06-14 05:31:48
Data Input & Management Executive,D&B Italiano,0 - 2 years,1.5-1.75 Lacs P.A.,['Ahmedabad'],"Position Overview:\nWe are seeking a diligent and organized professional to join our operations team. The ideal candidate will be responsible for accurate data entry, system management, and reporting processes that support our project and business workflows.\n\nKey Responsibilities:\nInput and manage project-related and administrative data with precision and consistency\nMaintain internal data systems and ensure regular updates across relevant platforms\nGenerate basic analytical reports to assist in operational decision-making\nCollaborate with design and procurement teams to ensure data accuracy across departments\nAssist in documentation of vendor, inventory.\n\nQualifications & Skills:\nBachelors degree in Business Administration, Information Systems, Statistics, or a related field\nStrong proficiency in Microsoft Excel, Google Sheets, and basic data visualization tools\nExcellent attention to detail, organizational, and time management skills\nAbility to work independently and in a cross-functional team environment\nPrior experience in data handling or operations support is advantageous but not mandatory",Industry Type: Architecture / Interior Design,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data Management', 'Data Analysis', 'Data Maintenance', 'Data Collection', 'Advanced Excel', 'Google Sheets', 'Records Management', 'Excel Sheet', 'Data Reporting', 'Excel Report Preparation']",2025-06-14 05:31:50
"Sr. Analyst, Business Analytics",Colgate-Palmolive (India),2 - 3 years,Not Disclosed,['Mumbai'],"Relocation Assistance Offered Within Country\nJob Number #167341 - Mumbai, Maharashtra, India\n\nWho We Are\n\nColgate-Palmolive Company is a global consumer products company operating in over 200 countries specialising in Oral Care, Personal Care, Home Care, Skin Care, and Pet Nutrition. Our products are trusted in more households than any other brand in the world, making us a household name!\n\nJoin Colgate-Palmolive, a caring, innovative growth company reimagining a healthier future for people, their pets, and our planet. Guided by our core values Caring, Inclusive, and Courageous we foster a culture that inspires our people to achieve common goals. Together, lets build a brighter, healthier future for all.\nTitle: Analyst / Sr. Analyst, Business Analytics\n\n\nBrief introduction - Role Summary/Purpose :\nThe candidate will support Colgate Business teams across the globe by providing Data & Analysis support. The role requires you to have understanding of Internal & external data (Syndicated Market Data, Point of Sales etc.) and ability to develop and support the Analytical / Insights based Service & Solutions\nGreat to have an understanding of necessary Data Transformation & Data Visualization Tools and Technologies to drive the service and solutions\nThe Person should be Analytical problem solver with the ability to work on large data sets, collaborative and customer focused (proactive and Responsive to Business needs) and Effective in Written and verbal communication skills\nResponsibilities :\nBuild Insights and Competition Intelligence solutions\nWith constantly evolving business environment, you will find out different ways to tackle the business problem through Analytics solutions and leveraging technology (Data transformation, Data Visualization, Data Insights) - Use of Python, R, Snowflake is a must\nAbility to Query Data from Snowflake and Big Query\nWork on different datasets & systems (Marketing, Customers, Product masters, Finance, Digital, Point of Sales) and link the business rationales to develop & support Analytics solutions\nBuild & support standard Business evaluation Trackers & Dashboards per agreed to SLAs and respond to ad hoc requests for reporting and first level analysis\nData Quality and Sanity is essential so validating the data, trackers and dashboards is critical\nYou will engage with Business teams in Corporate, Divisions, Hub (Cluster of Countries) and countries to understand business requirements and collaborate on solutions\nWork with Internal Analytics teams & Information technology teams to learn and advance on developing sustainable and standard reporting trackers\nPartner with external data vendors to ensure timely data availability with appropriate data sanity i.e. Nielsen, Kantar. Manage the contracts and set performance KPIs and conduct quarterly/annual reviews of data providers\n\n\nRequired Qualifications :\nGraduate in Engineering/Sciences/Statistics , MBA\nMinimum 2-3 years experience working in Data Insights / Analytics role\nExperience with third-party data i.e. syndicated market data (Nielsen, Kantar, IRI) Point of Sales, etc.\nShould have worked in a client facing / stakeholder management role to understand business needs and draw hypothesis\nKnowledge of Data Transformation tools - R, Python, Snowflake, DBT\nExpertise in either of visualization tools like Tableau, DOMO, Looker Studio, Sigma\nAbility to Read, Analyze and Visualize data\nStrong Verbal & Written Communication skills for Business engagement\n\n\nPreferred Qualifications :\nExperience with third-party data i.e. syndicated market data (Nielsen, Kantar, IRI) , Point of Sales, etc.\nCreated/worked on automation and developing Analytics solutions\nWorking knowledge of consumer packaged goods industry\nUnderstanding of Colgate s processes, and tools supporting analytics (for internal candidates)\nWillingness and ability to experiment with new tools and techniques\nGood facilitation and project management skills\n\nOur Commitment to Inclusion\nOur journey begins with our people developing strong talent with diverse backgrounds and perspectives to best serve our consumers around the world and fostering an inclusive environment where everyone feels a true sense of belonging. We are dedicated to ensuring that each individual can be their authentic self, is treated with respect, and is empowered by leadership to contribute meaningfully to our business.\n\nEqual Opportunity Employer\nColgate is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, colour, religion, gender, gender identity, sexual orientation, national origin, ethnicity, age, disability, marital status, veteran status (United States positions), or any other characteristic protected by law.\n\nPlease complete this request form should you require accommodation.",Industry Type: Industrial Equipment / Machinery,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Nutrition', 'Project management', 'Business analytics', 'Analytical', 'Data quality', 'Stakeholder management', 'Information technology', 'Analytics']",2025-06-14 05:31:53
Business Analyst,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis, Data Analysis & Interpretation, Scrum\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirement gathering sessions with stakeholders.- Create detailed business requirements documentation.- Conduct gap analysis to identify areas for process improvement.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis, Data Analysis & Interpretation, Scrum.- Strong understanding of project management methodologies.- Experience in process mapping and modeling.- Excellent communication and interpersonal skills.- Ability to prioritize and manage multiple tasks simultaneously.\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Business Analysis.- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'business analysis', 'project management process', 'scrum', 'gap analysis', 'documentation', 'program management', 'process improvement', 'process mapping', 'pmp', 'prince2', 'stakeholder management', 'delivery management', 'pmp trained', 'agile']",2025-06-14 05:31:55
Analyst - Direct Display,Merkle Science,1 - 2 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:Focuses on day-to-day executionProactively reviews and manages client data to ensure optimal performance on all campaignsTracks and reports on campaign results, gathers data analysis and participates in weekly callsGenerates campaign reports and is responsible for pacing, QA and traffickingDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-14 05:31:58
Business Analyst,Accenture,7 - 12 years,Not Disclosed,['Hyderabad'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :SAP CO Management Accounting\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead process improvement initiatives to enhance efficiency.- Conduct data analysis to identify trends and insights.- Develop and maintain project documentation.- Facilitate communication between stakeholders.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in SAP CO Management Accounting.- Strong understanding of financial analysis and reporting.- Experience in process optimization and business process reengineering.- Knowledge of SAP ERP systems.- Hands-on experience in data analysis and interpretation.\nAdditional Information:- The candidate should have a minimum of 7.5 years of experience in SAP CO Management Accounting.- This position is based at our Hyderabad office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['financial analysis', 'data analysis', 'sap erp', 'management accounting', 'sap co management', 'erp', 'hr generalist activities', 'project documentation', 'documentation', 'business analysis', 'process optimization', 'business process re-engineering', 'employee engagement', 'recruitment']",2025-06-14 05:32:02
Business Analyst,Highradius,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Summary:\nBusiness Analyst is responsible for delivering the HighRadius Cloud product implementations of Fortune 1000 clients. He/She will be owning solutioning for client engagements throughout the project life cycle. This is a highly visible and complex role since the candidate will be the main point of contact for project design and work with Client SMEs and stakeholders and Client users across client organization. The candidate must have strong solutioning skills, well organized, detail-oriented, quality-minded and possess excellent written and verbal communication skills. He/She will be responsible for guiding the team members, Associate Consultant and Data Analyst to implement the design and achieve project objectives.",,,,"['Software Implementation', 'Product Implementation', 'Integration', 'Treasury Management', 'Software Delivery', 'Software Solutions', 'SDLC', 'Business Analysis', 'Delivery Management', 'Software Development', 'ERP Implementation', 'Technical Delivery', 'Solutioning', 'IT Management', 'IT Projects']",2025-06-14 05:32:04
Business Analyst,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis, Data Analysis & Interpretation, Scrum\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirement gathering sessions with stakeholders.- Create detailed business requirements documentation.- Conduct gap analysis to identify areas for process improvement.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis, Data Analysis & Interpretation, Scrum.- Strong understanding of project management methodologies.- Experience in process mapping and modeling.- Excellent communication and interpersonal skills.- Ability to prioritize and manage multiple tasks simultaneously.- Hands-on experience in SQL- Strong experience using Jira and Confluence.- Strong analytic skills.- Knowledge of all phases of IT software development and implementation life cycle.- Capable to effectively interact with technical team.- Team spirit - Like to explain and share knowledge.- Proactive with continuous improvement mindset.- Hands-on experience in API testing.- At least one experience using Jira XRAY for test cases.- Experience writing feature files in Cucumber format.- Comfortable using process diagram design tools such as Draw.IO or Visio.- Financial/banking industry knowledge is a strong plus.\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Business Analysis.- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['confluence', 'data analysis', 'business analysis', 'scrum', 'jira', 'project management', 'gap analysis', 'documentation', 'test cases', 'process improvement', 'project management process', 'user stories', 'sql', 'process mapping', 'drawio', 'ms visio', 'brd', 'visio', 'fsd', 'frd', 'agile', 'api testing']",2025-06-14 05:32:07
Business Analyst,Accenture,5 - 10 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Finastra Fusion Loan IQ\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Strong Exposure to Credit Risk, Counterparty Risk, Financial product, Regulatory reporting, Accounting, Back-office processes within Lending Systems.- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirements gathering sessions with stakeholders.- Conduct data analysis to identify trends and insights.- Develop business process models and documentation.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nExperience with ACBS v8.0 Servicing application is a MUST- Other Lending systems experience such as Loan IQ would be plus.- Experience on additional ACBS components such as Datamart, Notifications, APIs, ATS is appreciated- Technical experience to be comfortable with data models, hands-on with SQL\nAdditional Information:- The candidate should have a minimum of 5 years of experienceas a Business Analyst in Financial Industry- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['credit risk', 'iq', 'regulatory reporting', 'accounting', 'financial products', 'project management', 'data analysis', 'lending', 'documentation', 'business analysis', 'loaniq', 'sql', 'fusion', 'loan operations', 'agile', 'loan syndication', 'acbs', 'finance', 'jira', 'agile methodology']",2025-06-14 05:32:09
Senior Business Analytics Analyst,"Godaddy Operating Company, Llc",5 - 10 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","At GoDaddy the future of work looks different for each team. Some teams work in the office full-time, others have a hybrid arrangement (they work remotely some days and in the office some days) and some work entirely remotely.\nThis is a remote position, so you ll be working remotely from your home. You may occasionally visit a GoDaddy office to meet with your team for events or meetings.\nJoin Our Team\nAs a data-driven company, GoDaddy is looking for a quick learner and result oriented Senior Analytics Engineer to join our Strategic Finance team. Strategic Finance is a part of GoDaddy s Finance Data, Analytics, and Technology team, and our overall mission is to optimize the power of data insights & automation solutions by enabling capabilities around technology, data, and people for improved efficiency & scalability. In Strategic Finance, we leverage business intelligence and financial models to derive data-driven insights that drive top-line, strategic growth. As part of this team, you will enable efficiency and velocity of insight discovery through data product development- velocity is key but be a good citizen!",,,,"['Automation', 'tableau', 'Business analytics', 'data governance', 'Data structures', 'Teradata', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-14 05:32:12
Business Analyst,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Business Analyst\n\n\n\n\n\nProject Role Description :Analyze an organization and design its processes and systems, assessing the business model and its integration with technology. Assess current state, identify customer requirements, and define the future state and/or business solution. Research, gather and synthesize information.\n\n\n\nMust have skills :Business Analysis, Cucumber (Software)\n\n\n\n\nGood to have skills : Hands-on Exp. on SQL , . Jira (XRAY) and ConfluenceMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Business Analyst, you will analyze an organization and design its processes and systems, assessing the business model and its integration with technology. You will assess the current state, identify customer requirements, and define the future state and/or business solution. Research, gather, and synthesize information to drive business decisions.\nRoles & Responsibilities:- Expected to be an SME, collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Lead requirement gathering sessions with stakeholders.- Create detailed business requirements documentation.- Conduct gap analysis to identify areas for process improvement.- Facilitate communication between business and technology teams.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Business Analysis, Data Analysis & Interpretation, Scrum.- Strong understanding of project management methodologies.- Experience in process mapping and modeling.- Excellent communication and interpersonal skills.- Ability to prioritize and manage multiple tasks simultaneously.- Hands-on experience in SQL- Strong experience using Jira and Confluence.- Strong analytic skills.- Knowledge of all phases of IT software development and implementation life cycle.- Capable to effectively interact with technical team.- Team spirit - Like to explain and share knowledge.- Proactive with continuous improvement mindset.- Hands-on experience in API testing.- At least one experience using Jira XRAY for test cases.- Experience writing feature files in Cucumber format.- Comfortable using process diagram design tools such as Draw.IO or Visio.- Financial/banking industry knowledge is a strong plus.\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Business Analysis.- This position is based at our Mumbai office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['confluence', 'data analysis', 'business analysis', 'scrum', 'jira', 'project management', 'cucumber', 'gap analysis', 'documentation', 'test cases', 'process improvement', 'project management process', 'user stories', 'sql', 'process mapping', 'drawio', 'brd', 'visio', 'fsd', 'frd', 'agile', 'api testing']",2025-06-14 05:32:14
Senior Business Analyst - Trade Finance,Luxoft,7 - 12 years,Not Disclosed,['Bengaluru'],"Project description\nTrade Team requires a strong Business Analyst having good knowledge on Trade finance and IMEX product.\n\nResponsibilities\n\nWork with stakeholders (business users, product owners, compliance teams) to gather and document business requirements.\n\nTranslate business needs into functional and technical specifications.\n\nAnalyze existing systems and data flows (e.g., core banking systems, trade finance platforms).\n\nCreate technical specifications for IT teams, including APIs, data mapping, and interface definitions.\n\nUnderstand and document system dependencies and integration touchpoints (e.g., with SWIFT, compliance , Accounting ).\n\nAnalyze current trade finance processes (e.g., letters of credit, guarantees, collections) and recommend improvements.\n\nUnderstand end-to-end trade finance products (e.g., LC, SBLC, BG, Forfaiting, Factoring).\n\nEnsure that solutions meet regulatory and operational requirements specific to trade finance.\n\nCollaborate with operations, product management, compliance, technology, and relationship management teams.\n\nWork with technology teams to design systems or process solutions.\n\nCreate functional specification documents (FSDs), user stories, or process flows.\n\nSupport User Acceptance Testing (UAT) by preparing test cases, validating results, and logging issues.\n\nParticipate in trade finance project planning, tracking milestones, and reporting status.\n\nSupport delivery and deployment activities for new systems or upgrades.\n\nEnsure proposed solutions adhere to compliance, risk management, and operational control standards.\n\nAssist with internal audits, risk assessments, and remediation activities.\n\nPrepare business cases, reports, and dashboards for management.\n\nMaintain documentation including process maps, SOPs, and training guides.\n\nAssist in managing change within the business due to system or process updates.\n\nProvide training or support materials to end-users on new systems or workflows.\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nSkills\nMust have\n\n7+ years of experience in Indian and International trade finance domain\n\nExperience in IMEX\n\nKnowledge in LC, BG, Bills, Loans, EDPMS, IDPMS , TRRACS, Core banking\n\nExperience on SWIFT messages like MT103 and MT202, MT 700, MT 400 and Nostro\n\nStrong knowledge of trade finance instruments and regulatory landscape.\n\nAnalyze business workflows and work with QA and dev teams to identify repetitive and high-impact test cases suitable for automation.\n\nProficiency in SQL, Data Analysis, and Database Management.\n\nProficient API testing (Postman, SoapUI, Swagger) knowledge\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nStrong communication, documentation, and stakeholder engagement skills.\n\nFamiliarity with Agile and/or Waterfall project methodologies.\n\nNice to have\n\nStrong Agile Knowledge.\n\nOther\n\nLanguages\n\nEnglishC2 Proficient\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'documentation', 'sql', 'database management', 'agile', 'trade finance', 'regulatory', 'international trade finance', 'soap ui', 'user stories', 'dashboards', 'swagger', 'instruments', 'postman', 'waterfall', 'stakeholder engagement', 'user acceptance testing', 'api testing', 'swift']",2025-06-14 05:32:16
Business Interlock Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Talent Development - Instructor-Led Training (ILT)\n\n\n\n\nDesignation: Business Interlock Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nImprove workforce performance and productivity, boosts business agility, increases revenue and reduces costsTalent Development processThe practice of training and learning material between an instructor and learners, either individuals or groups. Instructors can also be referred to as a facilitator, who may be knowledgeable and experienced in the learning material, but can also be used more for their facilitation skills and ability to deliver material to learners.\n\n\n\n\nWhat are we looking for\nTalent ManagementIncentive CompensationPayment Processing OperationsPayroll, Benefits, Performance Mgmt & Career DevelopmentAbility to meet deadlinesCollaboration and interpersonal skillsWritten and verbal communicationWFA, TA, CompensationAbility to perform under pressurePerformance Measurement Analysis and ImprovementHR Policy Development & Maintenance\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'business analysis', 'business analytics', 'capital market', 'performance measurement', 'financial analysis', 'data analysis', 'data analytics', 'team management', 'bloomberg', 'investment banking', 'training', 'business consulting', 'agile', 'performance management']",2025-06-14 05:32:19
Copywriting Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Content Creation\n\n\n\n\nDesignation: Copywriting Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires:Light Creative (Content Writer)Graduate, Post Graduate or Graduate in Fine ArtsThe role will include research, industry-related topics (combining online sources, interviews and studies), writing clear marketing copies to promote products/services, preparing well-structured drafts using CMS/tools, proofreading & editing content before publication, coordinating with marketing and design teams to illustrate articles, conducting simple keyword research, using SEO guidelines to increase web traffic and identifying customers needs and gaps in the content and updating on website.\n\n\n\n\nWhat are we looking for\nContent managementSearch Engine Optimization (SEO)Google AdsGood to have:Basic knowledge of SEO principles, including keyword research and optimization.Knowledge of digital ad platforms like Google Ads, Meta Ads, or LinkedIn Ads.Familiarity with social media analytics tools to gauge campaign performance.\n\n\n\nRoles and Responsibilities:\nRoles & Responsibilities:1.Content Creation:oDevelop high-quality, engaging, and SEO-optimized content for various channels, including websites, blogs, whitepapers, social media, email campaigns, and more.oCreate thought leadership articles, case studies, and product-centric content that aligns with brand goals.oCreate brochures and point of sales materials.2.Editing and Proofreading:oEdit and proofread content to ensure grammatical accuracy, clarity, and consistency with brand tone and style.oReview and refine user-facing content to meet high-quality standards and eliminate errors.3.Research and Analysis:oPerform thorough research on industry trends, topics, and competitors to deliver credible and relevant content.oAnalyze content performance metrics to iterate and improve strategies for better engagement.4.Collaboration:oWork closely with marketing, design, and product teams to ensure alignment between content and overall campaign goals.oPartner with designers to create visually appealing and content-rich assets, such as infographics and presentations.5.Content Optimization:oOptimize web content for search engines (SEO) using targeted keywords, metadata, and link-building strategies.oAdapt and repurpose content for different formats and platforms to maximize reach and impact.6.Project Management:oManage multiple content projects simultaneously, ensuring timely delivery while maintaining quality.oStay flexible and efficient in a fast-paced, deadline-driven environment.7.Compliance and Documentation:oEnsure all content complies with legal and brand standards, including accessibility and regulatory requirements.oMaintain organized project files, style guides, and documentation for easy handoff and collaboration.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'service operations', 'sales', 'seo', 'content optimization', 'ab initio', 'digital marketing', 'metadata', 'data analysis', 'data management', 'oracle', 'data warehousing', 'sql', 'data quality', 'campaigns', 'data governance', 'google analytics', 'etl', 'informatica', 'unix']",2025-06-14 05:32:22
Senior Business Analyst Healthcare (FHIR),Happiest Minds Technologies,10 - 15 years,Not Disclosed,['Bengaluru'],"Job Title: Senior Business Analyst Healthcare (FHIR)\nLocation: Bangalore, India\nExperience: 1015 years\nEmployment Type: Full-time\n\nAbout the Role:\nWe are seeking a skilled and experienced Senior Business Analyst Healthcare (FHIR) to drive the design and implementation of FHIR-based solutions that enable seamless interoperability across healthcare systems. This role requires close collaboration with stakeholders, technical teams, and healthcare domain experts to ensure robust, compliant, and scalable data exchange mechanisms.",,,,"['HL7', 'Business Analyst', 'FHIR']",2025-06-14 05:32:24
Data Scientist 1,Xoom,1 - 3 years,Not Disclosed,['Bengaluru'],"Job Summary\nWhat you need to know about the role -\nWe are looking for Senior Data Scientist with experience of managing large portfolios to develop PayPal s Risk strategy within the Rewards, Loyalty and Honey Risk solutions team. This portfolio comprises PayPal s global marketing initiatives and campaigns, as well as customized experiences developed for the company s highest-priority strategic partnerships.\n\nMeet our team\nPayPal s Reward, Loyalty & Honey risk team fraud Risk team is responsible for assessing and managing buyer and seller side risk exposures for all global marketing initiatives. The team is also responsible for partnering with the corresponding Business Units and Product teams to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.\nJob Description\nThis role will be the end-to-end owner of the Reward payout risk solutions and is responsible for end-to-end management of marketing budget loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, collaborate with ML engineering, product and technology teams on attribute, model and platform requirements, mentoring juniors in team, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.\nIf you re interested in enriching PayPal rewarding experiences and think customer back, then this is the right team for to join!\nYour day to day\nEach Senior Data Scientist on this team has full ownership of Reward payout portfolio and is responsible for end-to-end management of loss and decline rates for marketing budget.\nDay-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, collaborate with ML engineering, product and technology teams on attribute, model and platform requirements, communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.\nWorks independently and proficiently. Accountable for own results. Reviews are mainly for consultation and sharing ideas.\nWorks on multiple assignments simultaneously and in all areas of a standard project in the area of responsibility.\nWhat do you need to bring\nStrong analytical skills -- ability to build quick estimates using back-of-the-envelope analysis, structure (and, if needed, execute) more complex analyses, pull together business cases and forecasts to navigate through multi-dimensional sets of tradeoffs.\nEnthusiasm for data-driven problem solving within a fast-paced environment is a must. In addition, experience with Microsoft Excel or statistical software, working knowledge of SQL or other relational database languages, and hands-on experience in data analysis involving large data sets are strongly desired Work experience at the management consulting firms is a plus.\nPolished communication and influence skills - risk decision scientists need to collaborate cross-functionally with product managers, data scientists, business owners, and customers to learn from subject-matter experts, present findings in a clear and concise manner, and reach alignment on how to execute risk strategies. Demonstrated ability to influence groups and effectively resolve conflicts is required.\nAn innate intellectual curiosity, and a willingness to build awareness of current payments industry and risk management best practices. PayPal is constantly innovating by introducing new products and entering new markets, so successful risk analysts on this team must quickly get up speed on new content areas. You will be expected to become an expert in your specific domain.\nCan-do attitude, team player, energetic personality, ability to work well under pressure in a fast-paced and constantly changing environment to meet deadlines. The successful risk analyst is a self-starter who has the resilience to learn from their mistakes and reach their true potential.\nIdentify typical problems and issues during normal course of work and take proactive actions to solve them with minimum guidance. Recommends changes to policies and establishes procedures that affect immediate organization(s).\nExercises discretion in resolving a variety of issues in imaginative as well as practical ways.\nImpact of decision has moderate to large reach\nOffers insight for and contributes to improving existing technology, tools, processes, and business solutions. Adds value to brainstorming sessions\nBS/BA degree with 6+ years of related professional experience or master s degree with 4+ years of related experience.\nFocuses primarily on how to achieve overall analytic objectives of a project with speed and quality.\nSuggests ideas for operational plans and objectives\nClear subject matter expert within group / geography\nWorks independently and proficiently on multiple assignments simultaneously with speed and quality\nManage junior decision/data scientists.",Industry Type: Internet,Department: Other,"Employment Type: Full Time, Permanent","['Data analysis', 'Excel', 'Management consulting', 'Subject Matter Expert', 'Risk management', 'Business solutions', 'Forecasting', 'Operations', 'Monitoring', 'SQL']",2025-06-14 05:32:26
Training & Internship - Data Analytics,SSS Grameen Services,3 months duration,Unpaid,[],"This is a remote position.\n\nThere are internships and Projects for\n- Final Year University students (BBA/MBA)\n- Freshers & housewives\nPassionate students willing to learn and hone their skills are welcome to apply.\n\nRequirements\nWhat Next:\n- Apply with Resume, bonafide certificate, UID Aadhaar, Tentative area of project ( Analytics / AI / Sustainability / Cybersecurity etc.,))\nAppear for\nTechnical Screening #1 (Python or R Coding)\nTechnical Screening #2 (Coding test on ML algorithms like SVM and its implementation or similar)\nAptitude #3 (for Industry Usecases)\n\n- Technical assessment result\nPass - direct Project internship 2-3 months\n- Closure: Letter of internship, Project Report, Completion certificate (apply for respective UGC credits from your University)\n\n\nBenefits\nStipend: nil\nBenefits: Certificate of internship and Project\nMode: LIVE Virtual Remote\n",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Training', 'Technical training', 'LMS', 'Coding', 'Soft skills training', 'Data analytics', 'Internship', 'Python', 'Testing', 'Recruitment']",2025-06-14 05:32:29
Data Engineer,Amazon,1 - 6 years,Not Disclosed,['Hyderabad'],"Business Data Technologies (BDT) makes it easier for teams across Amazon to produce, store, catalog, secure, move, and analyze data at massive scale. Our managed solutions combine standard AWS tooling, open-source products, and custom services to free teams from worrying about the complexities of operating at Amazon scale. This lets BDT customers move beyond the engineering and operational burden associated with managing and scaling platforms, and instead focus on scaling the value they can glean from their data, both for their customers and their teams.\n\nWe own the one of the biggest (largest) data lakes for Amazon where 1000 s of Amazon teams can search, share, and store EB (Exabytes) of data in a secure and seamless way; using our solutions, teams around the world can schedule/process millions of workloads on a daily basis. We provide enterprise solutions that focus on compliance, security, integrity, and cost efficiency of operating and managing EBs of Amazon data.\n\n\nCORE RESPONSIBILITIES:\nBe hands-on with ETL to build data pipelines to support automated reporting\nInterface with other technology teams to extract, transform, and load data from a wide variety of data sources\nImplement data structures using best practices in data modeling, ETL/ELT processes, and SQL, Redshift.\nModel data and metadata for ad-hoc and pre-built reporting\nInterface with business customers, gathering requirements and delivering complete reporting solutions\nBuild robust and scalable data integration (ETL) pipelines using SQL, Python and Spark.\nBuild and deliver high quality data sets to support business analyst, data scientists, and customer reporting needs.\nContinually improve ongoing reporting and analysis processes, automating or simplifying self-service support for customers\nParticipate in strategic & tactical planning discussions\n\nA day in the life\nAs a Data Engineer, you will be working with cross-functional partners from Science, Product, SDEs, Operations and leadership to translate raw data into actionable insights for stakeholders, empowering them to make data-driven decisions. Some of the key activities include:\n\nCrafting the Data Flow: Design and build data pipelines, the backbone of our data ecosystem.\nEnsure the integrity of the data journey by implementing robust data quality checks and monitoring processes.\n\nArchitect for Insights: Translate complex business requirements into efficient data models that optimize data analysis and reporting. Automate data processing tasks to streamline workflows and improve efficiency.\n\nBecome a data detective! ensuring data availability and performance 1+ years of data engineering experience\nExperience with SQL\nExperience with data modeling, warehousing and building ETL pipelines\nExperience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)\nExperience with one or more scripting language (e.g., Python, KornShell) Experience with big data technologies such as: Hadoop, Hive, Spark, EMR\nExperience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.\nKnowledge of cloud services such as AWS or equivalent",,,,"['Data analysis', 'Data modeling', 'Datastage', 'PLSQL', 'Data structures', 'Informatica', 'SSIS', 'Open source', 'Monitoring', 'Python']",2025-06-14 05:32:31
Data Engineer-Business Intelligence,IBM,5 - 10 years,Not Disclosed,['Hyderabad'],"Provide expertise in analysis, requirements gathering, design, coordination, customization, testing and support of reports, in client’s environment\nDevelop and maintain a strong working relationship with business and technical members of the team\nRelentless focus on quality and continuous improvement\nPerform root cause analysis of reports issues\nDevelopment / evolutionary maintenance of the environment, performance, capability and availability.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\nPreferred technical and professional experience",,,,"['advance sql', 'sql', 'bi tools', 'debugging', 'troubleshooting', 'python', 'data analysis', 'data analytics', 'bi', 'data warehousing', 'power bi', 'business analysis', 'machine learning', 'business intelligence', 'sql server', 'qlikview', 'tableau', 'r', 'data visualization', 'etl', 'ssis']",2025-06-14 05:32:34
Data Engineer+ Subject Matter Expert- Data Mining,Newton School,0 - 2 years,Not Disclosed,['Pune'],"Newton School of Technology is on a mission to transform technology education and bridge the employability gap. As India s first impact university, we are committed to revolutionizing\nlearning, empowering students, and shaping the future of the tech industry. Backed by\nrenowned professionals and industry leaders, we aim to solve the employability challenge\nand create a lasting impact on society. We are currently looking for a Data Engineer + Subject Matter Expert - Data Mining to join our Computer Science Department. This is a full-time academic role focused on data mining, analytics, and teaching/mentoring students in core data science and engineering topics.\n\nKey Responsibilities:\nDevelop and deliver comprehensive and engaging lectures for the undergraduate\n""Data Mining"", BigData and Data Analytics courses, covering the full syllabus from\nfoundational concepts to advanced techniques.\nInstruct students on the complete data lifecycle, including data preprocessing,\ncleaning, transformation, and feature engineering.\nTeach the theory, implementation, and evaluation of a wide range of algorithms for\nClassification, Association rules mining, Clustering and Anomaly Detections.\nDesign and facilitate practical lab sessions and assignments that provide students\nwith hands-on experience using modern data tools and software.\nDevelop and grade assessments, including assignments, projects, and examinations,\nthat effectively measure the Course Learning Objectives (CLOs).\nMentor and guide students on projects, encouraging them to work with real-world or\nbenchmark datasets (e.g., from Kaggle).\nStay current with the latest advancements, research, and industry trends in data\nengineering and machine learning to ensure the curriculum remains relevant and\ncutting-edge.\nContribute to the academic and research environment of the department and the\nuniversity.\n\nRequired Qualifications:\nA Ph.D. (or a Masters degree with significant, relevant industry experience) in\nComputer Science, Data Science, Artificial Intelligence, or a closely related field.\nDemonstrable expertise in the core concepts of data engineering and machine\nlearning as outlined in the syllabus.\nStrong practical proficiency in Python and its data science ecosystem, specifically\nScikit-learn, Pandas, NumPy, and visualization libraries (e.g., Matplotlib, Seaborn).\nProven experience in teaching, preferably at the undergraduate level, with an ability to\nmake complex topics accessible and engaging.\nExcellent communication and interpersonal skills.\n\nPreferred Qualifications:\nA strong record of academic publications in reputable data mining, machine learning,\nor AI conferences/journals.\nPrior industry experience as a Data Scientist, Big Data Engineer, Machine Learning\nEngineer, or in a similar role.\nExperience with big data technologies (e.g., Spark, Hadoop) and/or deep learning\nframeworks (e.g., TensorFlow, PyTorch).\nExperience in mentoring student teams for data science competitions or hackathons.\n\nPerks & Benefits:\nCompetitive salary packages aligned with industry standards.\nAccess to state-of-the-art labs and classroom facilities.\nTo know more about us, feel free to explore our website: Newton School of Technology\nWe look forward to the possibility of having you join our academic team and help shape the\nfuture of tech education!\nNewton School of Technology is on a mission to transform technology education and bridge the employability gap. As India s first impact university,\n...",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Interpersonal skills', 'data science', 'Artificial Intelligence', 'Machine learning', 'Manager Technology', 'Data analytics', 'Subject Matter Expert', 'Data mining', 'Python']",2025-06-14 05:32:36
Data Engineer,Accenture,2 - 3 years,Not Disclosed,['Kochi'],"Job Title - Data Engineer Sr.Analyst ACS SONG\n\n\n\nManagement Level:Level 10 Sr. Analyst\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python/Scala, Pyspark/Pytorch\n\n\n\n\nGood to have skills:Redshift\n\n\n\n\n\n\n\nJob\n\n\nSummary\n\nYoull capture user requirements and translate them into business and digitally enabled solutions across a range of industries. Your responsibilities will include:\n\n\n\nRoles and Responsibilities\n\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\n\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\n\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\n\nCreating data products for analytics team members to improve productivity\n\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\n\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\n\nPreparing data to create a unified database and build tracking solutions ensuring data quality\n\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\n\n\nProfessional and Technical Skills\n\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\n\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 2-3 years of hands-on experience working on these technologies.\n\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\n\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\n\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\n\nExperience working in cloud Data warehouses like Redshift or Synapse\n\nCertification in any one of the following or equivalent\n\nAWS- AWS certified data Analytics- Speciality\n\nAzure- Microsoft certified Azure Data Scientist Associate\n\nSnowflake- Snowpro core- Data Engineer\n\nDatabricks Data Engineering\n\n\nAbout Our Company | Accenture (do not remove the hyperlink)\n\n\n\nQualification\n\n\n\nExperience:3.5 -5 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'microsoft azure', 'glue', 'amazon redshift', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'snowflake', 'scipy', 'data analysis', 'azure data lake', 'power bi', 'data engineering', 'javascript', 'data bricks', 'pandas', 'tableau', 'lambda expressions', 'aws']",2025-06-14 05:32:39
"Senior Analyst, Manufacturing Quality Applications",Schneider Electric India Pvt. Ltd.,3 - 5 years,Not Disclosed,['Bengaluru'],"Title : Senior Analyst, Manufacturing Quality Applications\nLocation: Bengaluru, KA\nWe are seeking a skilled Manufacturing Quality Application analyst with 3 - 5 years of experience Digital Project and/or Support organization, along with a strong understanding of discrete manufacturing processes. Candidate should have experienced applications among those categories : Statistical Process Control application, Incoming Goods Inspections application, Tools Calibration Management application, Product Inspections Management application, Manufacturing or Engineering Change Notice application, Quality Surveillance Plan application, Quality modules of Manufacturing Execution Systems. Knowledge experience on Manufacturing Execution System (MES), Agile Project execution Outsystems lowcode platform is a plus.\nResponsibilities :\nLead the continuous improvement, configuration, and maintenance of CSQ applications (Customer Satisfaction Quality) applied to Manufacturing domain to optimize manufacturing processes and data management.\nCollaborate with cross-functional teams to analyze, design, and improve Quality processes within applications and integrations to other systems\nProvide functional and technical guidance in Board of Change and provide functional specifications based on business requirements\nAnalyze Level 2 tickets, trouble shoot the issues and coordinate with Level 3 Application Developers (internal or 3rd parties) and other Digital Teams to ensure minimal disruptions to production.\nWork with Application developers Digital / Business teams on building functional specifications coordinate agile project releases.\nConduct training programs to educate end-users on system functionalities and best practices.\nStay updated on industry trends and best practices in manufacturing systems to recommend and implement continuous improvements.\nRequirements :\nBachelor s degree in engineering, Mechanical/Production, or related field.\nProven experience (3 -5 years) in implementing and supporting quality applications.\nKnowledge of discrete manufacturing processes and industry standards.\nProficiency in system integration, data analysis, and troubleshooting.\nExcellent communication skills and ability to collaborate with diverse teams.\nExposure to Agile Project execution (optional)\nExposure to Outsystems lowcode platform (optional)\n\n\nBachelor s degree in engineering, Mechanical/Production, or related field.\nProven experience (3 -5 years) in implementing and supporting manufacturing quality applications.\nExposure to",Industry Type: Industrial Equipment / Machinery,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'discrete manufacturing', 'Data management', 'Senior Analyst', 'Manufacturing quality', 'Manufacturing execution system', 'System integration', 'Agile', 'Continuous improvement', 'Project execution']",2025-06-14 05:32:41
Data Engineer - Databricks,KPI Partners,0 - 4 years,Not Disclosed,['Pune'],"About KPI Partners.\nKPI Partners is a leading provider of data analytics solutions, dedicated to helping organizations transform data into actionable insights. Our innovative approach combines advanced technology with expert consulting, allowing businesses to leverage their data for improved performance and decision-making.\n\nJob Description.\nWe are seeking a skilled and motivated Data Engineer with experience in Databricks to join our dynamic team. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and data processing solutions that support our analytics initiatives. You will collaborate closely with data scientists, analysts, and other engineers to ensure the consistent flow of high-quality data across our platforms.",,,,"['Computer science', 'Data modeling', 'Analytical', 'Consulting', 'Data processing', 'Data quality', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-14 05:32:44
S&C Global Network - AI - Healthcare Analytics - Senior Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title -\n\n\n\nS&C Global Network - AI - Healthcare Analytics - Senior Analyst\n\n\n\nManagement Level:\n\n\n\n10-Senior Analyst\n\n\n\nLocation:\n\n\n\nGurgaon/Bangalore/Mumbai\n\n\n\nMust-have skills:Phython, Spark,SQL, Tableau, Power BI\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\nWHATS IN IT FOR YOU\nConduct data wrangling and analysis on healthcare claims, provider datasets, and publicly available health data.\nDevelop predictive models using data science and AI techniques to address client needs.\nUtilize natural language processing (NLP) capabilities to extract insights from unstructured data sources.\nCollaborate with cross-functional teams to implement analytics solutions effectively.\nTranslate complex data findings into clear, concise, and actionable strategies.\n\n\n\nWhat you would do in this role\nWork with Managers to get Client's business requirements and deliver Analytics driven solution.\nDuties and Responsibilities\nSr. Data Scientist responsible for generating actionable recommendations well-supported by quantitative analysis to help our clients address their ongoing problems.\nPresent analytic findings & opportunities for improvement to senior management and summarize key findings, and aid in the dissemination of metrics throughout the organization.\nBuild knowledge base and disseminate information on applications of variety of analytical techniques.\nDevelop statistical models and delivery of analytic offerings and solutions in health domain areas.\n\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\nExperience in resolving complex data issues in creative and effective ways.\nStrong people management skills both at client site and an offshore environment\nExcellent communication skills and ability to interact with all levels of end users, stakeholders, and technical resources.\nAdept with using Statistical (like forecasting/modeling, optimization models), Machine Learning (GBM, Decision Trees etc.), AI techniques (Deep Learning)\nGood exposure to consulting experience/basic understanding of business problems and suggesting solutions.\n\n\nTechnical\n\n\n\n\nSkills:\nProficient in data handling suites PYTHON, Spark, SQL, or similar packages\nExcellent written and oral communication skills with ability to clearly communicate ideas and results to non-technical businesspeople.\nStrong aptitude, ability, motivation, and interest in placing quantitative analysis in the context of health care business for providers / payers/Public health systems\nExperience working with cloud providers (e.g. AWS, Azure, GCP)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5 Years in Healthcare Analytics\n\n\n\n\nEducational Qualification:\n\n\n\nBachelor's / masters degree in computer science, statistics, applied mathematics, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'power bi', 'sql', 'tableau', 'spark', 'switching', 'advanced analytics', 'network engineering', 'data analytics', 'data analysis', 'microsoft azure', 'networking', 'machine learning', 'data science', 'gcp', 'healthcare analytics', 'network analysis', 'data handling', 'aws', 'ccna']",2025-06-14 05:32:46
Senior Statistical Data Scientist,Pfizer,5 - 6 years,Not Disclosed,['Chennai'],"An Individual Contributor role\nProductive h ands on programming, supporting deliverables in the study / project / portfolio / standards team, of medium - high complex statistical programming deliverables to support assets and study teams\nPerforms tasks with limited supervision early in role and independently later in role.\nIs capable of handling standards/study programming specific activities independently including collaboration across stakeholders at various timezones\nEnsures adherence to high quality programming standards in their daily work\n\nWork Location Assignment: Flexible\n\nWork Location Assignment: Hybrid\nMedical\n#LI-PFE",,,,"['Statistical programming', 'Individual Contributor', 'Supervision']",2025-06-14 05:32:48
Senior Data Scientist,Capgemini,5 - 9 years,Not Disclosed,['Gurugram'],"At Capgemini Invent, we believe difference drives change. As inventive transformation consultants, we blend our strategic, creative and scientific capabilities,collaborating closely with clients to deliver cutting-edge solutions. Join us to drive transformation tailored to our client's challenges of today and tomorrow.Informed and validated by science and data. Superpowered by creativity and design. All underpinned by technology created with purpose.\n\n \n\nYour role \n\nAs a Senior Data Scientist, you are expected to develop and implement Artificial Intelligence based solutions across various disciplines for the Intelligent Industry vertical of Capgemini Invent. You are expected to work as an individual contributor or along with a team to help design and develop ML/NLP models as per the requirement. You will work closely with the Product Owner, Systems Architect and other key stakeholders right from conceptualization till the implementation of the project. You should take ownership while understanding the client requirement, the data to be used, security & privacy needs and the infrastructure to be used for the development and implementation.\n\nThe candidate will be responsible for executing data science projects independently to deliver business outcomes and is expected to demonstrate domain expertise, develop, and execute program plans and proactively solicit feedback from stakeholders to identify improvement actions. This role requires a strong technical background, excellent problem-solving skills, and the ability to work collaboratively with stakeholders from different functional and business teams.\nThe role also requires the candidate to collaborate on ML asset creation and eager to learn and impart trainings to fellow data science professionals. We expect thought leadership from the candidate, especially on proposing to build a ML/NLP asset based on expected industry requirements. Experience in building Industry specific (e.g. Manufacturing, R&D, Supply Chain, Life Sciences etc), production ready AI Models using microservices and web-services is a plus.\n\nProgramming Languages Python NumPy, SciPy, Pandas, MatPlotLib, Seaborne\nDatabases RDBMS (MySQL, Oracle etc.), NoSQL Stores (HBase, Cassandra etc.)\nML/DL Frameworks SciKitLearn, TensorFlow (Keras), PyTorch,\nBig data ML Frameworks - Spark (Spark-ML, Graph-X), H2O\nCloud Azure/AWS/GCP\n\n \n\nYour Profile \n\nPredictive and Prescriptive modelling using Statistical and Machine Learning algorithms including but not limited to Time Series, Regression, Trees, Ensembles, Neural-Nets (Deep & Shallow CNN, LSTM, Transformers etc.). Experience with open-source OCR engines like Tesseract, Speech recognition, Computer Vision, face recognition, emotion detection etc. is a plus.\nUnsupervised learning Market Basket Analysis, Collaborative Filtering, Dimensionality Reduction, good understanding of common matrix decomposition approaches like SVD. Various Clustering approaches Hierarchical, Centroid-based, Density-based, Distribution-based, Graph-based clustering like Spectral.\nNLP Information Extraction, Similarity Matching, Sentiment Analysis, Text Clustering, Semantic Analysis, Document Summarization, Context Mapping/Understanding, Intent Classification, Word Embeddings, Vector Space Models, experience with libraries like NLTK, Spacy, Stanford Core-NLP is a plus. Usage of Transformers for NLP and experience with LLMs like (ChatGPT, Llama) and usage of RAGs (vector stores like LangChain & LangGraps), building Agentic AI applications.\nModel Deployment ML pipeline formation, data security and scrutiny check and ML-Ops for productionizing a built model on-premises and on cloud.\n\nRequired Qualifications\nMasters degree in a quantitative field such as Mathematics, Statistics, Machine Learning, Computer Science or Engineering or a bachelors degree with relevant experience.\nGood experience in programming with languages such as Python/Java/Scala, SQL and experience with data visualization tools like Tableau or Power BI.\n\nPreferred Experience\nExperienced in Agile way of working, manage team effort and track through JIRA\nExperience in Proposal, RFP, RFQ and pitch creations and delivery to the big forum.\nExperience in POC, MVP, PoV and assets creations with innovative use cases\nExperience working in a consulting environment is highly desirable.\nPresupposition\n\nHigh Impact client communication\nThe job may also entail sitting as well as working at a computer for extended periods of time. Candidates should be able to effectively communicate by telephone, email, and face to face.\n\n \n\nWhat you will love about working here \nWe recognize the significance of flexible work arrangements to provide support. Be it remote work, or flexible work hours, you will get an environment to maintain healthy work life balance.\nAt the heart of our mission is your career growth. Our array of career growth programs and diverse professions are crafted to support you in exploring a world of opportunities.\nEquip yourself with valuable certifications in the latest technologies such as Generative AI.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['numpy', 'sql', 'java', 'python', 'pandas', 'scala', 'poc', 'nltk', 'dl', 'artificial intelligence', 'tensorflow', 'spacy', 'spark', 'gcp', 'pytorch', 'keras', 'mysql', 'hbase', 'ml', 'jira', 'scipy', 'rdbms', 'oracle', 'mvp', 'microsoft azure', 'power bi', 'nosql', 'tableau', 'cassandra', 'matplotlib', 'agile', 'aws']",2025-06-14 05:32:51
"Senior Data Scientist, Actimize",NICE,4 - 7 years,Not Disclosed,['Pune'],"So, what’s the role all about? \nWe are seeking a highly skilled and experienced Senior Data Scientist to join our dynamic team. The ideal candidate should have a minimum  4s of years of experience in  data science, with hands-on experience in developing and implementing Generative AI solutions. The Senior Data Scientist will be responsible for developing Machine Learning models and collaborating with cross-functional teams to solve complex business problems \nHow will you make an impact?",,,,"['algorithms', 'development', 'python', 'scikit-learn', 'methods', 'interpersonal skills', 'microsoft azure', 'power bi', 'engineering', 'numpy', 'machine learning', 'evaluation', 'pandas', 'analytics', 'deep learning', 'r', 'tableau', 'data science', 'gcp', 'science', 'machine learning algorithms', 'aws', 'programming', 'communication skills']",2025-06-14 05:32:54
S&C Global Network - AI - Responsible AI - Sr Analyst,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Entity:- Accenture Strategy & Consulting\n\n\n\nTeam:- Strategy & Consulting Global Network\n\n\n\nPractice:- Responsible AI COE\n\n\n\nTitle:- Responsible AI Specialist/ Sr. Analyst\n\n\n\nJob location:- Bangalore/Gurgaon/Pune/ Hyderabad/Chennai/Mumbai\n\nThe rapid development of AI is creating new opportunities to improve the lives of people around the world, from business to healthcare to education. As a result, it is also raising new questions about the best way to build fairness, interpretability, privacy and security into these systems.\n\nThe Data and AI revolution is changing everything. Its everywhere transforming how we work and play. Join Accenture and help transform leading companies and communities around the world.\n\nAccenture is driving these exciting changes and bringing them to life across 40 industries in more than 120 countries. The sheer scale of our capabilities and client engagements and the way we collaborate with the ecosystem, operate, and deliver value provides an unparalleled opportunity to grow and advance.\n\nAccentures S&C Global Network Data & AI team covers the range of skills, from Strategy, Data Science, Data Architecture, AI Engineering and Visual Insights. When combined with our broader Strategy and Consulting practice, we bring a unique ability to drive end to end business change through the application of Data and AI.\n\nAt the forefront of the industry, youll help make our Responsible AI vision a reality for clients looking to better serve their customers and operate always-on enterprises. Were not just focused on increasing revenues our technologies and innovations are making millions of lives easier and more comfortable. But above all, were doing this responsibly and inclusively to make sure AI technology is used equitably and in a way that is both ethically and technically sound.\n\nJoin us and become an integral part of our global Responsible AI team with the credibility, expertise and insight clients depend on. There will never be a typical day at Accenture, but thats why people love it here. You will be working with famous brands and household names no worrying about how to explain what you do to your family again!\n\nWe are looking for experienced and motivated individuals who will be a part of the\n\n\n\nResponsible AI\n\n\n\nCentre of Excellence (COE) within Accenture to join our multi-disciplinary Responsible AI team. We are committed to help people build AI products/solutions/services in a responsible and trustworthy manner.\n\n\n\nThe ideal candidate should have a strong client-facing consulting background in data science/analytics with an ability to pick up new technologies very quickly. He/she will be passionate about understanding the impact of AI systems on people and society and will have a track record in using tools to undertake assessments such as\n\n\n\nFairness/Bias, Explainability, Model Validation and Robustness, to assess model behaviour through a Responsibility lens.\n\nBeing a part of Accenture will help you grow both professionally and personally as you help shape our thinking and approaches to Responsible AI, working alongside world-class academics, industry leaders and practitioners. Responsible AI is a key strategic priority for Accenture and were looking for the very best in the field to help us meet our ambitious goals in this space.\n\n\n\nResponsibilities:\n\nAs a client-facing in Responsible AI, you will consult with Accentures clients on how todesign & develop reliable, effective user-centered AI systems in adherence to general best practices for software systems, together with practices that address responsibility considerations unique to AI & machine learning. You will also be expected to contribute to research on how AI systems can be designed holistically with fairness, interpretability, privacy, security, safety, and robustness built in by design.\n\nAs part of our team, you will:\nBe a subject matter expert on technical aspects of Responsible AI & Data\nCollaborate with colleagues to develop best practices, frameworks, tools for scalable implementation of Responsible AI in enterprises\nConduct research on Responsible AI policies, principles, issues, risk identification, risk remediation, regulatory requirements, latest trends etc.\nBring a strong conceptual understanding of Responsible AI, principles & tools with experience of using these tools in close collaboration with internal and external stakeholders/clients\nEvaluate and implement technical best practices and tools for fairness, explainability, transparency, accountability, and other relevant aspects of Responsible AI\nDevelop a clear understanding of clients business issues to adopt the best approach to implement the Responsible AI Framework\nEstablish a consistent and collaborative presence by partnering with clients to understand the wider business goals, objectives & competitive constraints\nProvide thought leadership by publishing in public forums/conferences/blogs on Responsible AI products, research or developments\nLeading diverse and well-qualified RAI team.\n\n\nQualification\n\n\n\nSkillset :\n\n\n\n\nEducation:- PhD / Masters / Bachelors degree in Statistics / Economics / Mathematics /Computer Science / Physics or related disciplines from Premier Colleges in India or Abroad. Specialization in Data Science.\n\n\n\nMust Have\n3 10 years of Hands-on Data science experience in solving real life complex business problems\nMinimum 1 years experience in enhancing AI systems to meet Responsible AI principles - Explainability, Fairness, Accountability, etc.\nPassionate about understanding the impact of AI systems on people and society\nHands-on experience of using techniques such as data bias testing (e.g. for under-represented groups, proxy variables, recall bias, skew etc), Explainability (e.g. SHAP values, LIME), sensitivity testing, repeatability and similar to understand model limitations.\nDemonstrated experience in writing reports that summarize analysis / assessments into simple and concise actionable points\nStrong conceptual knowledge and practical experience in the Development, Validation, and Deployment of ML/AL models such as:\nSupervised Learning - regression, classification techniques\nUnsupervised Learning clustering techniques\nRecommender Systems\nReinforcement Learning\nDeep Learning Sequence models (RNN, GRU, LSTM etc.), CNN, GAN etc\nEconometric models\nExploratory Data analysis, Hypothesis testing etc.\nComfortable in ingestion of technical whitepapers, legal policies, government regulations etc. in relation into Responsible AI and work with Academic partners to convert them into practice\nAbility to learn and develop new methods, strategies and frameworks to proactively identify potential loopholes.\nComfortable with ambiguity, believe in first principles and have the skill to transform broad ideas into action plans\nExcellent written and verbal communication skills with ability to clearly communicate ideas and results to both technical and non-technical business audience, such as senior leaders\nGood time management skills to manage day-to-day work progress and ensure timely and high-quality deliverables\nSelf-motivated with ability to work independently across multiple projects and set priorities and Strong analytical bent of mind.\n\n\n\n\nGood to have\nCloud Certifications (Azure / AWS / GCP)\nKnowledge of AWS SageMaker Clarify / Azure Responsible ML and Fairlearn SDK / GCP AI Explanations\nExperience in Chatbot Analytics, Web Crawling\nExperience in MLOps tools like MLflow or Kubeflow\nKnowledge of cybersecurity, vulnerability assessment, risk remediation etc.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'chatbot', 'network analysis', 'aws', 'web crawling', 'switching', 'eigrp', 'network engineering', 'load balancing', 'networking', 'bgp', 'network data', 'ccnp', 'f5', 'routing', 'vlan', 'mpls', 'cisco', 'network security', 'network administration', 'ospf', 'sdwan', 'firewall', 'cisco routers', 'ccna']",2025-06-14 05:32:57
Data Engineer,Accenture,3 - 8 years,Not Disclosed,['Coimbatore'],"Project Role :Data Engineer\n\n\n\n\n\nProject Role Description :Design, develop and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL (extract, transform and load) processes to migrate and deploy data across systems.\n\n\n\nMust have skills :Talend ETL\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Engineer, you will design, develop, and maintain data solutions for data generation, collection, and processing. Create data pipelines, ensure data quality, and implement ETL processes to migrate and deploy data across systems. Be involved in the end-to-end data management process.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work-related problems.- Develop and maintain data pipelines for efficient data processing.- Ensure data quality and integrity throughout the data lifecycle.- Implement ETL processes to extract, transform, and load data.- Collaborate with cross-functional teams to optimize data solutions.- Conduct data analysis to identify trends and insights.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Talend ETL.- Strong understanding of data integration and ETL processes.- Experience with data modeling and database design.- Knowledge of SQL and database querying languages.- Hands-on experience with data warehousing concepts.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Talend ETL.- This position is based at our Hyderabad office.- A 15 years full-time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'talend etl', 'etl', 'data integration', 'etl process', 'hive', 'python', 'data analysis', 'data management', 'talend', 'data processing', 'data warehousing', 'knowledge of sql', 'data engineering', 'database design', 'data quality', 'data modeling', 'spark', 'data warehousing concepts', 'hadoop']",2025-06-14 05:32:59
Measurement & Report Senior Analyst,Accenture,6 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Insurance Services - Property and Casualty Insurance\n\n\n\n\nDesignation: Measurement & Report Senior Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:6 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe help insurers redefine their customer experience while accelerating their innovation agenda to drive sustainable growth by transforming to an intelligent operating model. Intelligent Insurance Operations combines our advisory, technology, and operations expertise, global scale, and robust ecosystem with our insurance transformation capabilities. It is structured to address the scope and complexity of the ever-changing insurance environment and offers a flexible operating model that can meet the unique needs of each market segment.Insurance is a legal agreement between two parties the insurer and the insured, also known as insurance coverage or insurance policy. The insurer provides financial coverage for the losses of the insured that s/he may bear under certain circumstancesIn this role, you will be managing workflow process and inventory handle policy maintenance inclusive of, contract amendments, customer & policy maintenance, broker of record changes. You will be managing terminations as needed in internal systems issuance of policy certificates to agents within desired timelines for Property, Auto, Workers Comp, Inland Marine, Travel and Marine Insurance (Commercial & Personal lines in the English Language)\n\n\n\n\nWhat are we looking for\nAnalysis and ReportingDashboard ReportingMonth End ReportingReporting AnalyticsManagement ReportingAbility to work well in a teamPrioritization of workloadHands-on experience with trouble-shootingCommitment to qualityStrong analytical skillsAnalysis and ReportingDashboard ReportingMonth End ReportingReporting AnalyticsManagement ReportingAbility to work well in a teamPrioritization of workloadHands-on experience with trouble-shootingCommitment to qualityStrong analytical skills\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['macros', 'pivot table', 'vlookup', 'reporting analysis', 'advanced excel', 'data analysis', 'mis reporting', 'quality control', 'software testing', 'forecasting', 'power bi', 'business analysis', 'sql', 'tableau', 'vba', 'mis', 'quality assurance', 'data visualization']",2025-06-14 05:33:02
Capital Projects Management Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: IX Intelligent Capital Project Operations - Low Carbon Grid Capital Projects\n\n\n\n\nDesignation: Capital Projects Management Sr Analyst\n\n\n\n\nQualifications:BTech\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Power System Engineer Analyst is responsible for performing detailed analysis of electrical power systems, including transmission, distribution, and generation. The role involves modeling, simulation, and assessment of power systems to ensure their functionality, reliability, and efficiency. The individual will work closely with engineers and stakeholders to identify potential improvements and help design cost-effective solutions. This position requires an in-depth understanding of electrical systems, excellent analytical abilities, and an ability to work in a collaborative environment to ensure that power systems are efficient and reliable.Investment project management and control capabilities related to grid assets to enable the energy transition (e.g. transmission interconnections).\n\n\n\n\nWhat are we looking for\nEducation:Proficient Electrical Engineer with experience around power system modelling and study. A Masters degree in ""Power System Engineering"" is a plus. Technical Skills :Proficiency in power system analysis and simulation software (e.g., PSS/E, ETAP, DIgSILENT PowerFactory, MATLAB/Simulink).Solid understanding of power system components and their operations, including generators, transformers, circuit breakers, relays, and protection devices.Experience with load flow analysis, fault analysis, voltage stability, and other power system studies.Additional Skills :Knowledge of renewable energy integration and energy storage systems. Familiarity with SCADA systems and real-time monitoring of power systems.Experience with advanced automation or grid optimization techniques.Data Analysis and Reporting:Analyze large sets of electrical system data to identify trends, inefficiencies, and areas for improvement.Prepare detailed reports on power system performance, including recommendations for upgrades or modifications.Present findings to senior engineers, managers, and clients.Compliance and Standards:Ensure compliance with industry standards, regulations, and best practices for power system operations.Stay updated on emerging technologies, standards, and regulations related to power systems.\n\n\n\nRoles and Responsibilities: Power System Modeling and Simulation:Use software tools (e.g., MATLAB, PSCAD, PSS/E, ETAP, Digsilent Powerfactory) to model and simulate electrical power systems.Analyze the dynamic behavior of power systems under different operating conditions. Perform load flow analysis, short circuit analysis, stability analysis, and contingency studies.Power Grid Analysis:Assess grid reliability and performance through modeling of transmission and distribution systems. Identify potential risks, faults, and vulnerabilities in power systems. Evaluate and recommend solutions for system optimization, power factor correction, and fault tolerance.System Design and Optimization:Collaborate with electrical engineers to design power systems, including control systems, protection systems, and energy storage solutions. Provide technical support for power system design, including capacity planning, voltage regulation, and fault detection. Recommend improvements to power system components (transformers, circuit breakers, switches, etc.) to ensure efficiency.\n\nQualification\n\nBTech",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['pscad', 'power system', 'system analysis', 'electrical equipment', 'simulation software', 'matlab', 'simulink', 'project operations', 'project management', 'stability analysis', 'system design', 'circuit analysis', 'scada', 'fault analysis', 'power grid analysis', 'short circuit', 'load flow']",2025-06-14 05:33:04
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Delivery - Sales Reporting\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDesign, develop and provide reports of exports and representations of pipeline data, sales results and other relevant data points. Assess pipeline status, and sales performance, identify trends and analyze root causes.\n\n\n\n\nWhat are we looking for\nSales Reporting & Channel Analytics Sales Incentive Analytics and Reporting Power BI Adaptable and flexible Commitment to quality Ability to work well in a team Written and verbal communication Agility for quick learning Adhering to timelines\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day-to-day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['service operations', 'bi', 'power bi', 'root cause analysis', 'sales', 'python', 'project management', 'data analysis', 'data analytics', 'data warehousing', 'business analysis', 'business intelligence', 'sql server', 'sql', 'tableau', 'data modeling', 'data visualization', 'etl', 'ssis']",2025-06-14 05:33:07
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Delivery - Sprinklr\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIA social media management tool for enterprises. It provides social media marketing, social advertising, content management, collaboration, advocacy and social media monitoring for large enterprises.\n\n\n\n\nWhat are we looking for\nSprinklr Social Media Monitoring & Analytics Adaptable and flexible Written and verbal communication Ability to work well in a team Agility for quick learning Commitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day-to-day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['digital marketing', 'service operations', 'content management', 'sprinklr', 'seo', 'adobe analytics', 'data analysis', 'google adwords', 'power bi', 'social listening', 'radian6', 'sql', 'twitter', 'tableau', 'web analytics', 'social media marketing', 'google analytics', 'sem', 'brandwatch']",2025-06-14 05:33:09
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\nAbility to work well in a teamAgility for quick learningAbility to perform under pressureAdaptable and flexibleCommitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'macros', 'service operations', 'data analysis', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-14 05:33:12
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:Chartered Accountant\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Implementation of gen. ledger processes including yearend closing, journalizing. Creating and maintaining ledgers, ledger currencies, budgets, and journal entries, design to deliver a financial management solution including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry and reporting as well as dynamic allocations and the management of commitments and expenditures also run Interface reports and perform close books of accounts.\n\n\n\n\nWhat are we looking for\nAbility to perform under pressureAbility to establish strong client relationshipStrong analytical skillsProblem-solving skillsFinancial Consolidation, Reporting and month end close activities\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nChartered Accountant",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'budgeting', 'record to report', 'macros', 'service operations', 'data analysis', 'data analytics', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-14 05:33:14
"STAFF, DATA SCIENTIST",Walmart,4 - 9 years,Not Disclosed,['Bengaluru'],"Position Summary... Drives the execution of multiple business plans and projects by identifying customer and operational needs; developing and communicating business plans and priorities; removing barriers and obstacles that impact performance; providing resources; identifying performance standards; measuring progress and adjusting performance accordingly; developing contingency plans; and demonstrating adaptability and supporting continuous learning. Provides supervision and development opportunities for associates by selecting and training; mentoring; assigning duties; building a team-based work environment; establishing performance expectations and conducting regular performance evaluations; providing recognition and rewards; coaching for success and improvement; and ensuring Belonging awareness. Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity by training and providing direction to others in their use and application; ensuring compliance with them; and utilizing and supporting the Open Door Policy. Ensures business needs are being met by evaluating the ongoing effectiveness of current plans, programs, and initiatives; consulting with business partners, managers, co-workers, or other key stakeholders; soliciting, evaluating, and applying suggestions for improving efficiency and cost-effectiveness; and participating in and supporting community outreach events.\nWhat youll do...\nAbout the Team :\nCentroid team at Walmart serves as the backbone of Walmarts end-to-end supply chain strategy. They are entrusted with the task of designing and implementing a long-term supply chain strategy that uses advanced data analytics and data science. Their primary objective is to ensure that Walmart provides top-tier customer service while supporting the increasing demand over time and simultaneously operating at low and efficient costs.\nThe team utilizes sophisticated data analysis methods to understand patterns, identify potential bottlenecks, and predict future trends. This enables them to optimize processes, make informed business decisions, and enhance overall operational efficiency.\nOne of Centroids key responsibilities also includes the creation of a Digital Twin Simulation platform for Walmarts supply chain. This innovative tool allows the team to test and validate all future strategies and tactical decisions before they are launched operationally. It also enables a deep assessment of long-term strategic sensitivity.\nIn essence, the Centroid teams work is integral to ensuring Walmarts supply chain is robust, flexible, and capable of adapting to ever-changing market demands. Their work helps to keep Walmart at the forefront of retail supply chain management, delivering exceptional service to customers while maintaining efficient operational costs.\nWhat Youll do :\nDevelop and manage advanced data analytics models to optimize supply chain strategies, balancing customer satisfaction with operational cost and asset efficiency.\nLeverage data analytics to identify opportunities for improvement and drive impactful results through collaboration with cross-functional teams.\nEstablish relationships across Walmart functional areas to identify best practices, solicit data/input, coordinate interdisciplinary initiatives, and rally support for data-driven recommendations.\nSecure alignment and support from relevant business partners and management for data-centric projects, leading discussions to drive necessary change.\nUtilize all available data resources effectively to ensure successful project outcomes.\nCommunicate data insights clearly and persuasively through emails, verbal discussions, and presentations, tailoring communication methods to the audience for maximum impact.\nCollaborate with multiple supply chain business teams to proactively identify, assess, and leverage cost-saving and service improvement opportunities through advanced data analytics.\nUtilize advanced analytics models to derive insights that will inform policy design across various supply chain areas, laying out multiple scenarios and performing sensitivity analysis.\nCollaborate with Data Scientists and Engineers to productionize and scale advanced analytics models as needed.\nDevelop and present compelling data-driven narratives/documents/visuals to influence key stakeholders in their decision-making.\nProvide coaching and training support to other team members in the supply chain area, leveraging your expertise in advanced data analytics.\nWhat Youll bring :\nStrong analytical acumen with technical expertise in Advanced Data Analytics and modelling\nExpert in SQL, - BigQuery like cloud data platforms.\nExpert in programming in Python, (or R)\nExperience in using data visualization tools like Tableau and Looker and be able to drive powerful insights.\nExperience working with large data sets and distributed computing tools (Map/Reduce, Hadoop, Hive, and/or Spark)\nExperience in operating from a cloud environment such as Google Could Platform or Microsoft Azure.\nAbility to work in a fast-paced, iterative development environment.\nStrong communication skills, both written and verbal, plus ability to work with cross functional teams of technical and non-technical members.\nStrong ability to understand the business and have good stakeholder management capabilities.\nExperience of working in cross-functional environment and leading or mentoring teams.\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nMinimum Qualifications:Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years experience in an analytics related field. Option 3: 6 years experience in an analytics or related field.\nPreferred Qualifications...\nPrimary Location... G, 1, 3, 4, 5 Floor, Building 11, Sez, Cessna Business Park, Kadubeesanahalli Village, Varthur Hobli , India",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Data analysis', 'Supply chain management', 'Networking', 'Analytical', 'Consulting', 'Programming', 'Analytics', 'Python', 'SQL']",2025-06-14 05:33:17
Data Scientist,NatWest Markets,5 - 10 years,Not Disclosed,['Bengaluru'],"Join us as a Data Scientist\nYou ll design and implement data science tools and methods which harness our data in order to drive market leading purposeful customer solutions\nWe ll look to you to actively participate in the data community to identify and deliver opportunities to support the bank s strategic direction through better use of data\nThis is an opportunity to promote data literacy education with business stakeholders supporting them to foster a data driven culture and to make a real impact with your work\nWere offering this role at associate level\nWhat youll do\nAs a Data Scientist, you ll bring together statistical, mathematical, machine-learning and software engineering skills to consider multiple solutions, techniques and algorithms to develop and implement ethically sound models end-to-end. We ll look to you to understand the needs of business stakeholders, form hypotheses and identify suitable data and analytics solutions to meet those needs in order to support the achievement of our business strategy.\nYou ll also be:\nUsing data translation skills to work closely with business stakeholders to define detailed business questions, problems or opportunities which can be supported through analytics\nApplying a software engineering and product development lens to business problems, creating, scaling and deploying software driven products and services\nWorking in an Agile way within multi-disciplinary data and analytics teams to achieve agreed project and scrum outcomes\nSelecting, building, training and testing machine learning models considering model valuation, model risk, governance and ethics, making sure that models are ready to implement and scale\nIteratively building and prototyping data analysis pipelines to provide insights that will ultimately lead to production deployment\nThe skills youll need\nYou ll need a strong academic background in a STEM discipline such as Mathematics, Physics, Engineering or Computer Science. You ll have an experience of atleast five years with statistical modelling and machine learning techniques.\nWe ll also look for financial services knowledge, and an ability to identify wider business impact, risk or opportunities and make connections across key outputs and processes\nYou ll also demonstrate:\nThe ability to use data to solve business problems from hypotheses through to resolution\nExperience using Python, Tableau, SQL and software engineering fundamentals\nExperience of of analytics in fraud prevention and detection\nExperience of monitoring and maintaining model performance through developing new dashboards and reports, improve existing dashboards and in-house Python packages\nExperience of exploratory data analysis\nGood communication skills with the ability to proactively engage with a wide range of stakeholders",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Machine learning', 'Agile', 'Scrum', 'Analytics', 'Monitoring', 'Financial services', 'SQL', 'Python']",2025-06-14 05:33:19
Data Scientist (AI For Computer Vision),Philips,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Title Data Scientist (AI for Computer Vision)\nJob Description\nWe are seeking an experienced Data Scientist specializing in AI for Computer Vision to join our dynamic team. Your primary responsibilities will include developing, fine-tuning, and optimizing AI models for computer vision applications, driving innovation in various healthcare applications. You will work closely with cross-functional teams, including machine learning engineers, software developers, and product managers, to deliver state-of-the-art AI solutions.\nYour role:\nExplore and develop innovative Artificial Intelligence (AI) algorithms for healthcare applications\nCreate and refine AI algorithms for pre- and post-processing of images and videos, focusing on data from various imaging modalities\nDevelop and implement machine learning and deep learning techniques for segmentation, classification, and statistical modeling.\nDemonstrate expertise in image processing, object detection, segmentation, and classification.\nProficient in Python programming\nPossess a strong understanding of algorithms and frameworks such as TensorFlow, PyTorch, and Keras\nExperienced with version control systems (e.g., Git) and software development practices\nDevelop and Optimize Computer Vision Models: Design, train, and fine-tune DL models for real-world applications\nData Preparation & Engineering: Gather, clean, and preprocess large-scale image and video datasets for training and evaluation of computer vision models\nExperimentation & Model Evaluation: Conduct A/B testing and assess model performance using quantitative metrics (e.g., IoU, mAP, precision, recall)\nResearch & Innovation: Stay updated with the latest advancements in computer vision, deep learning, and related technologies\nDeployment & Scaling: Work with ML engineers to deploy models into production environments using cloud platforms (AWS, Azure) and frameworks like TensorFlow, PyTorch, and OpenCV\nCollaboration & Communication: Work closely with cross-functional teams to integrate computer vision solutions into business processes and applications.\n\nYoure the right fit if:\nBachelor s or master s Degree: In computer science, AI, Data Science, Machine Learning, or a related field\nExperience: 3+ years in machine learning, deep learning, or AI research, with at least 1 year of hands-on experience in developing computer vision-based AI applications\nProgramming Proficiency: Strong proficiency in Python and ML frameworks like TensorFlow and PyTorch\nDomain Knowledge: Knowledge of computer vision, natural language processing (NLP), or multimodal AI applications\nTechnical Skills: Familiarity with computer vision techniques and fine-tuning of models\nProblem-Solving Skills: Strong problem-solving skills and the ability to work in a fast-paced, research-driven environment\nMLOps Tools: Hands-on experience with MLOps tools (e.g., MLflow, Kubeflow, Docker, Kubernetes)\nEthical AI: Understanding of ethical AI and bias mitigation in computer vision models.\nPublications and Contributions: Strong publication record or contributions to open-source AI projects.\n\nHow we work together\nWe believe that we are better together than apart. For our office-based teams, this means working in-person at least 3 days per week.\nthis role is an office role.\n\nIf you re interested in this role and have many, but not all, of the experiences needed, we encourage you to apply. You may still be the right candidate for this or other opportunities at Philips. Learn more about our culture of impact with care here .\n#LI-EU\n#LI-Hybrid\n#LI-PHILIN",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'Version control', 'Image processing', 'Artificial Intelligence', 'Machine learning', 'Healthcare', 'Natural language processing', 'Open source', 'Python']",2025-06-14 05:33:21
Data Engineer,Luxoft,5 - 8 years,Not Disclosed,['Pune'],"Project description\nAre you passionate about leveraging the latest technologies for strategic changeDo you enjoy problem solving in clever waysAre you organized enough to drive change across complex data systemsIf so, you could be the right person for this role.\nAs an experienced data engineer, you will join a global data analytics team in our Group Chief Technology Officer / Enterprise Architecture organization supporting our strategic initiatives which ranges from portfolio health to integration.\n\nResponsibilities\n\nHelp Group Enterprise Architecture team to develop our suite of EA tools and workbenches\n\nWork in the development team to support the development of portfolio health insights\n\nBuild data applications from cloud infrastructure to visualization layer\n\nProduce clear and commented code\n\nProduce clear and comprehensive documentation\n\nPlay an active role with technology support teams and ensure deliverables are completed or escalated on time\n\nProvide support on any related presentations, communications, and trainings\n\nBe a team player, working across the organization with skills to indirectly manage and influence\n\nBe a self-starter willing to inform and educate others\n\nSkills\nMust have\n\nB.Sc./M.Sc. degree in computing or similar\n\n5-8+ years' experience as a Data Engineer, ideally in a large corporate environment\n\nIn-depth knowledge of SQL and data modelling/data processing\n\nStrong experience working with Microsoft Azure\n\nExperience with visualisation tools like PowerBI (or Tableau, QlikView or similar)\n\nExperience working with Git, JIRA, GitLab\n\nStrong flair for data analytics\n\nStrong flair for IT architecture and IT architecture metrics\n\nExcellent stakeholder interaction and communication skills\n\nUnderstanding of performance implications when making design decisions to deliver performant and maintainable software.\n\nExcellent end-to-end SDLC process understanding.\n\nProven track record of delivering complex data apps on tight timelines\n\nFluent in English both written and spoken.\n\nPassionate about development with focus on data and cloud\n\nAnalytical and logical, with strong problem solving skills\n\nA team player, comfortable with taking the lead on complex tasks\n\nAn excellent communicator who is adept in, handling ambiguity and communicating with both technical and non-technical audiences\n\nComfortable with working in cross-functional global teams to effect change\n\nPassionate about learning and developing your hard and soft professional skills\n\nNice to have\n\nExperience working in the financial industry\n\nExperience in complex metrics design and reporting\n\nExperience in using artificial intelligence for data analytics\n\nOther\n\nLanguages\n\nEnglishC1 Advanced\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data processing', 'microsoft azure', 'sql', 'data modeling', 'screening', 'it architecture', 'hiring', 'power bi', 'hrsd', 'knowledge of sql', 'data engineering', 'artificial intelligence', 'sourcing', 'qlikview', 'talent acquisition', 'tableau', 'git', 'recruitment', 'gitlab', 'sdlc', 'jira']",2025-06-14 05:33:23
Senior Functional Business Analyst,Luxoft,5 - 10 years,Not Disclosed,['Gurugram'],"Project description\nThis is a high-visibility opportunity for experienced Functional Business Analysts to work on transformation programs in the Corporate & Institutional Banking (C&IB) domain. The project is centered around enhancing client onboarding processes, strengthening credit and risk evaluation systems, and improving compliance with regulatory requirements, including AML and KYC. The initiative operates in a dynamic Agile environment and involves cross-functional collaboration between business, risk, operations, and technology teams.\n\nResponsibilities\n\nWork closely with business stakeholders to understand, document, and prioritize requirements.\n\nConduct detailed analysis of current-state processes for client onboarding, credit scoring, lending workflows, and compliance.\n\nDefine and document user stories, functional specifications, process flows, and data mappings.\n\nSupport the product owner with backlog refinement, sprint planning, and prioritization.\n\nFacilitate workshops and walkthroughs with subject matter experts.\n\nEnsure alignment between business requirements and technical deliverables.\n\nAssist with UAT planning, test case development, and defect triaging.\n\nMaintain strong communication with project managers, developers, testers, and stakeholders throughout the SDLC.\n\nSkills\nMust have\n\n5+ years of experience as a Functional Business Analyst in the banking or financial services domain.\n\nProven domain expertise in the following:\n\nC&IB Client Onboarding\n\nCredit and Risk Scoring\n\nLending Processes\n\nAML (Anti-Money Laundering)\n\nKYC\n\nStrong verbal and written communication skills in English.\n\nAbility to create structured and well-documented artefacts (resumes will be reviewed for documentation quality).\n\nExperience working in Agile delivery models (Scrum, SAFe).\n\nFamiliarity with tools like JIRA, Confluence, and MS Office Suite.\n\nNice to have\n\nExposure to regulatory change or transformation programs.\n\nKnowledge of GRC platforms or tools (e.g., Archer, ServiceNow GRC).\n\nPrior experience in data analysis or data mapping activities.\n\nFamiliarity with integration patterns between front-office and back-office systems.\n\nAwareness of global banking regulations and compliance frameworks.\n\nOther\n\nLanguages\n\nEnglishB2 Upper Intermediate\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Consulting,"Employment Type: Full Time, Permanent","['aml', 'client onboarding', 'ib', 'lending', 'kyc', 'confluence', 'user stories', 'data mapping', 'financial services', 'brd', 'grc', 'frd', 'jira', 'c', 'data analysis', 'software testing', 'documentation', 'dns', 'business analysis', 'process flow', 'servicenow', 'ms office suite', 'archer', 'scrum', 'agile', 'sdlc']",2025-06-14 05:33:26
Senior Business Analyst - Trade Finance,Luxoft,7 - 12 years,Not Disclosed,['Chennai'],"Project description\nTrade Team requires a strong Business Analyst having good knowledge on Trade finance and IMEX product.\n\nResponsibilities\n\nWork with stakeholders (business users, product owners, compliance teams) to gather and document business requirements.\n\nTranslate business needs into functional and technical specifications.\n\nAnalyze existing systems and data flows (e.g., core banking systems, trade finance platforms).\n\nCreate technical specifications for IT teams, including APIs, data mapping, and interface definitions.\n\nUnderstand and document system dependencies and integration touchpoints (e.g., with SWIFT, compliance , Accounting ).\n\nAnalyze current trade finance processes (e.g., letters of credit, guarantees, collections) and recommend improvements.\n\nUnderstand end-to-end trade finance products (e.g., LC, SBLC, BG, Forfaiting, Factoring).\n\nEnsure that solutions meet regulatory and operational requirements specific to trade finance.\n\nCollaborate with operations, product management, compliance, technology, and relationship management teams.\n\nWork with technology teams to design systems or process solutions.\n\nCreate functional specification documents (FSDs), user stories, or process flows.\n\nSupport User Acceptance Testing (UAT) by preparing test cases, validating results, and logging issues.\n\nParticipate in trade finance project planning, tracking milestones, and reporting status.\n\nSupport delivery and deployment activities for new systems or upgrades.\n\nEnsure proposed solutions adhere to compliance, risk management, and operational control standards.\n\nAssist with internal audits, risk assessments, and remediation activities.\n\nPrepare business cases, reports, and dashboards for management.\n\nMaintain documentation including process maps, SOPs, and training guides.\n\nAssist in managing change within the business due to system or process updates.\n\nProvide training or support materials to end-users on new systems or workflows.\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nSkills\nMust have\n\n7+ years of experience in Indian and International trade finance domain\n\nExperience in IMEX\n\nKnowledge in LC, BG, Bills, Loans, EDPMS, IDPMS , TRRACS, Core banking\n\nExperience on SWIFT messages like MT103 and MT202, MT 700, MT 400 and Nostro\n\nStrong knowledge of trade finance instruments and regulatory landscape.\n\nAnalyze business workflows and work with QA and dev teams to identify repetitive and high-impact test cases suitable for automation.\n\nProficiency in SQL, Data Analysis, and Database Management.\n\nProficient API testing (Postman, SoapUI, Swagger) knowledge\n\nExperience with trade finance platforms (e.g., Finastra, Surecomp, SWIFT interfaces).\n\nStrong communication, documentation, and stakeholder engagement skills.\n\nFamiliarity with Agile and/or Waterfall project methodologies.\n\nNice to have\n\nStrong Agile Knowledge.\n\nOther\n\nLanguages\n\nEnglishC2 Proficient\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'documentation', 'sql', 'database management', 'agile', 'trade finance', 'regulatory', 'international trade finance', 'soap ui', 'user stories', 'dashboards', 'swagger', 'instruments', 'postman', 'waterfall', 'stakeholder engagement', 'user acceptance testing', 'api testing', 'swift']",2025-06-14 05:33:28
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Pune'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:30
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Jaipur'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:32
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Indore'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:35
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,"['Mumbai', 'Any Location']","We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:36
Senior/Lead Data Scientist,Tiger Analytics,6 - 11 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Role & responsibilities\n\nCurious about the role? What your typical day would look like?As a Senior Data Scientist, your work is a combination of hands-on contribution to Loreum Ipsum, Loreum Ipsum, etc. More specifically, this will involve:\nLead and contribute to developing sophisticated machine learning models, predictive analytics, and statistical analyses to solve complex business problems.",,,,"['Data Science', 'Time Series Analysis', 'Machine Learning', 'Python', 'Time Series Forecasting', 'Regression', 'Clustering', 'neural nets', 'Optimization', 'SQL']",2025-06-14 05:33:39
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Nagpur'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:41
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Ahmedabad'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:44
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Surat'],"Job Description :\n\nWe are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:46
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Chennai'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:49
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Delhi / NCR'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:51
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Noida'],"Job Description :\n\nWe are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:53
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Lucknow'],"We are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:56
Data Engineer - Python Programming,Leading Client,5 - 7 years,Not Disclosed,['Kolkata'],"Job Description :\n\nWe are looking for a skilled Data Engineer with strong hands-on experience in Clickhouse, Kubernetes, SQL, Python, and FastAPI, along with a good understanding of PostgreSQL.\nThe ideal candidate will be responsible for building and maintaining efficient data pipelines, optimizing query performance, and developing APIs to support scalable data services.\n\n- Design, build, and maintain scalable and efficient data pipelines and ETL processes.\n\n- Develop and optimize Clickhouse databases for high-performance analytics.\n\n- Create RESTful APIs using FastAPI to expose data services.\n\n- Work with Kubernetes for container orchestration and deployment of data services.\n\n- Write complex SQL queries to extract, transform, and analyze data from PostgreSQL and Clickhouse.\n\n- Collaborate with data scientists, analysts, and backend teams to support data needs and ensure data quality.\n\n- Monitor, troubleshoot, and improve performance of data infrastructure.\n\n- Strong experience in Clickhouse - data modeling, query optimization, performance tuning.\n\n- Expertise in SQL - including complex joins, window functions, and optimization.\n\n- Proficient in Python, especially for data processing (Pandas, NumPy) and scripting.\n\n- Experience with FastAPI for creating lightweight APIs and microservices.\n\n- Hands-on experience with PostgreSQL - schema design, indexing, and performance.\n\n- Solid knowledge of Kubernetes managing containers, deployments, and scaling.\n\n- Understanding of software engineering best practices (CI/CD, version control, testing).\n\n- Experience with cloud platforms like AWS, GCP, or Azure.\n\n- Knowledge of data warehousing and distributed data systems.\n\n- Familiarity with Docker, Helm, and monitoring tools like Prometheus/Grafana.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Data Engineering', 'PostgreSQL', 'Data Modeling', 'Data Warehousing', 'Data Analytics', 'ETL', 'Python', 'SQL']",2025-06-14 05:33:58
"Senior Data Engineer ( T-SQL & SSIS,Data Warehousing & ETL Specialist)",Synechron,5 - 10 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Job Summary\nSynechron is seeking a highly skilled Senior Data Engineer specializing in T-SQL and SSIS to lead and advance our data integration and warehousing initiatives. In this role, you will design, develop, and optimize complex ETL processes and database solutions to support enterprise data needs. Your expertise will enable efficient data flow, ensure data integrity, and facilitate actionable insights, contributing to our organizations commitment to data-driven decision-making and operational excellence.\nSoftware Requirements\nOverall Responsibilities\nTechnical Skills (By Category)\nExperience Requirements\nDay-to-Day Activities\nQualifications\nProfessional Competencies",,,,"['Data Engineering', 'T-SQL', 'Azure Data Factory', 'query optimization', 'performance tuning', 'database security', 'AWS Glue', 'Data Warehousing', 'SSIS', 'ETL']",2025-06-14 05:34:01
"STAFF, DATA SCIENTIST",Walmart,5 - 10 years,Not Disclosed,['Bengaluru'],"Position Summary...\nWhat youll do...\nAbout Team\nThe Catalog Data Science Team at Walmart Global Tech is focused on using the latest research in generative AI (GenAI), artificial intelligence (AI), machine learning (ML), statistics, deep learning, computer vision and optimization to implement solutions that ensure Walmart s product catalog is accurate, complete, and optimized for customer experience. Our team tackles complex data science and ML engineering challenges related to product classification, attribute extraction, trust & safety, and catalog optimization, empowering next-generation retail use cases.\nThe Data Science and ML Engineering community at Walmart Global Tech is active in most of the Hack events, utilizing the petabytes of data at our disposal, to build some of the coolest ideas. All the work we do at Walmart Global Tech will eventually benefit our operations & our associates, helping Customers Save Money to Live Better.\nWhat youll do:\nWe are looking for a Staff Machine Learning Engineer who can help build large scale AI/ML/Optimization products. Expected qualities include ability to build, deploy, maintain and troubleshoot large scale systems.\nAs a Staff ML Engineer, you ll have the opportunity to\nDrive research initiatives and proof-of-concepts that push the state of the art in generative AI and large-scale machine learning.\nDesign and implement high-throughput, low-latency AI/ML pipelines and microservices that operate at global scale.\nOversee data ingestion, model training, evaluation, deployment and monitoring-ensuring performance, quality and reliability.\nCustomize and optimize LLMs for specific business use cases, balancing accuracy, latency and cost.\nPrototype novel generative AI solutions, integrate advancements into production, and collaborate with research partners.\nChampion best practices in data quality, lineage, governance and cost optimization across ML pipelines.\nMentor a team of ML engineers, establish coding standards, conduct design reviews, and foster a culture of continuous improvement.\nPresent your team s work at top-tier AI/ML conferences, publish scientific papers, and cultivate partnerships with universities and research labs.\nWhat youll bring:\nPhD in Computer Science, Statistics, Applied Mathematics or related field with 5+ years experience in ML engineering-or Master s with 8+ years or Bachelor s with 10+ years.\nProven track record of leading and scaling AI/ML products in production environments.\nDeep expertise in generative AI, large-scale model deployment, and fine-tuning of transformer-based architectures.\nStrong programming skills in Python, or equivalent, and experience with big data frameworks (Spark, Hadoop) and ML platforms (TensorFlow, PyTorch).\nDemonstrated history of scientific publications or patents in AI/ML.\nExcellent communication skills, a growth mindset, and the ability to drive cross-functional collaboration.\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and\nMinimum Qualifications...\nMinimum Qualifications:Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 4 years experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 2 years experience in an analytics related field. Option 3: 6 years experience in an analytics or related field.\nPreferred Qualifications...\nPrimary Location...",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Prototype', 'Networking', 'Coding', 'Machine learning', 'Continuous improvement', 'Information technology', 'Monitoring', 'Analytics', 'Python']",2025-06-14 05:34:04
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"As an Associate Data Scientist at IBM, you will work to solve business problems using leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites. You will prepare, analyze, and understand data to deliver insight, predict emerging trends, and provide recommendations to stakeholders.\n\nIn your role, you may be responsible for\nImplementing and validating predictive and prescriptive models and creating and maintaining statistical models with a focus on big data & incorporating machine learning. techniques in your projects\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\nPreferred technical and professional experience",,,,"['python', 'scikit-learn', 'tensorflow', 'pytorch', 'keras', 'natural language processing', 'neural networks', 'predictive', 'huggingface', 'machine learning', 'prototype', 'artificial intelligence', 'sql', 'pandas', 'deep learning', 'r', 'java', 'cobol', 'data science', 'matplotlib', 'big data', 'statistics']",2025-06-14 05:34:07
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"An AI Data Scientist at IBM is not just a job title - it’s a mindset. You’ll leverage the watsonx,AWS Sagemaker,Azure Open AI platform to co-create AI value with clients, focusing on technology patterns to enhance repeatability and delight clients.\n\nWe are seeking an experienced and innovative AI Data Scientist to be specialized in foundation models and large language models. In this role, you will be responsible for architecting and delivering AI solutions using cutting-edge technologies, with a strong focus on foundation models and large language models. You will work closely with customers, product managers, and development teams to understand business requirements and design custom AI solutions that address complex challenges. Experience with tools like Github Copilot, Amazon Code Whisperer etc. is desirable.\n\nSuccess is our passion, and your accomplishments will reflect this, driving your career forward, propelling your team to success, and helping our clients to thrive.\n\nDay-to-Day Duties:\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\n\n\nPreferred technical and professional experience",,,,"['python', 'machine learning', 'tensorflow', 'pytorch', 'keras', 'kubernetes', 'github', 'natural language processing', 'scikit-learn', 'pyspark', 'microsoft azure', 'artificial intelligence', 'text analytics', 'pandas', 'deep learning', 'java', 'code generation', 'cobol', 'gcp', 'matplotlib', 'aws']",2025-06-14 05:34:09
"PRINCIPAL, DATA SCIENTIST",Walmart,10 - 15 years,Not Disclosed,['Bengaluru'],"Position Summary...\nWhat youll do...\nAbout Team\nWalmart s Enterprise Business Services (EBS) is a powerhouse of several exceptional teams delivering world-class technology solutions and services making a profound impact at every level of Walmart.\nAs a key part of Walmart Global Tech, our teams set the bar for operational excellence and leverage emerging technology to support millions of customers, associates, and stakeholders worldwide. Each time an associate turns on their laptop, a customer makes a purchase, a new supplier is onboarded, the company closes the books, physical and legal risk is avoided, and when we pay our associates consistently and accurately, that is EBS. Joining EBS means embarking on a journey of limitless growth, relentless innovation, and the chance to set new industry standards that shape the future of Walmart.\nWhat you will do\nYou will work with the multiple teams and guide them on technical aspects, set quality standards and participate in design discussion and drive technical decisions\nLead the end-to-end lifecycle of AI/ML projects, from ideation to deployment, ensuring alignment with Walmarts strategic goals.\nDesign and implement scalable cloud-based machine learning and data science solutions, leveraging, GCP, or other cloud platforms.\nDevelop novel algorithms and leverage state-of-the-art AI frameworks (e.g., TensorFlow, PyTorch, HuggingFace) to solve complex problems in indirect procurement optimization, customer personalization, and operational efficiency.\nBuild highly parallelized compute environments for processing large-scale datasets, optimizing performance across CPU and GPU architectures.\nCollaborate with diverse teams across engineering, business, and operations to understand requirements and integrate data science solutions seamlessly.\nAdvocate for best practices in software development, including CI/CD, unit testing, and documentation, to ensure robust and reliable systems.\nMentor junior data scientists and contribute to building a culture of innovation and learning within the data science community at Walmart.\nCode Reviews across teams\nEngage with Product Management and Business to drive the agenda, set your priorities and deliver awesome products.\nDrive design, development, implementation and documentation\nBuild, test and deploy cutting edge solutions at scale, impacting associates of Walmart worldwide.\nInteract with Walmart engineering teams across geographies to leverage expertise and contribute to the tech community.\nDrive the success of the implementation by applying technical skills, to design and build enhanced processes and technical solutions in support of strategic initiatives.\nYou will use your engineering experience and technical skill to develop highly scalable and robust solutions. You will work with Engineering Lead/architect.\nWork closely with the Architects and cross functional teams and follow established practices for the delivery of solutions meeting QCD (Quality, Cost & Delivery). Within the established architectural guidelines.\nWork with senior leadership to chart out the future roadmap of the products\nParticipate in hiring and build teams enabling them to be high performing agile teams.\nYou will help and participate with the teams that leverage and contribute to open source technologies to Make impact on a global scale\nInteract closely for requirements with Business owners and technical teams both within India and across the globe.\nWhat you will bring\nB.Tech. / B.E. / M.Tech. / M.S. in Computer Science or relevant discipline\n10+ years of experience in design and development of highly -scalable applications and platform development\nWork in a highly collaborative environment with a multidisciplinary team.\nWork with senior data scientists to design, architect, and build AI/ML model and model systems.\nWork with machine learning engineers to deploy, operate, and optimize scalable solutions\nWork with product managers to design user journeys, feedback loop and analyze user telemetry.\nCreate opportunities to develop yourself with an end-to-end AI/ML product experience.\nWork with a set of robust work standards to ensure we build trustworthy AI/ML solutions\nHosted & Participated Architecture Review & Design/Code Review events.\nHands on System Designing experience.\nStrong computer science fundamentals: data structures, algorithms, design patterns.\nExtensive hands-on experience building services using these technologies (Scala, Java, Springboot, Microservices ,NodeJs)\nHands-on experience in web technologies like React JS/Angular Js, Java script, Type script, CSS\nGood Knowledge in messaging systems: Kafka/RabbitMQ\nWorking knowledge of SQL and NoSQL database technologies.\nKnowledge on Linux platform\nKnowledge on unit testing frameworks (Junit, Jest , Spock etc) and code quality control platforms like Sonar\nKnowledge on cloud platforms any cloud platforms like IAAS/PAAS\nCI/CD development environments/tools: Git, Maven, Gradle, Docker, Kubernetes, Jenkins, Azure DevOps\nExperience in implementing Distributed Cache(Redis/Hazlecast)\nWell-Versed with Logging and Metrics tools and technologies (ELK/Splunk/Grafana)\nKnowledge in search engines like Lucene/Solr\nDemonstrated end-to-end ownership for development and design of least one cloud based project.\nStrong hands on development skills to prototype technical solutions.\nStrong desire to drive change, and ability to adapt to change quickly. Willing to learn new and emerging technologies.\nExceptional communication and interpersonal skills - including negotiation, facilitation, and consensus building skills; ability to influence and persuade, without direct control.\nPractitioner of Agile (Scrum) methodology\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nEqual Opportunity Employer\nWalmart, Inc., is an Equal Opportunities Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.\nMinimum Qualifications...\nMinimum Qualifications:Option 1: Bachelors degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 5 years experience in an analytics related field. Option 2: Masters degree in Statistics, Economics, Analytics, Mathematics, Computer Science, Information Technology or related field and 3 years experience in an analytics related field. Option 3: 7 years experience in an analytics or related field.\nPreferred Qualifications...",Industry Type: Retail,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Maven', 'Linux', 'Networking', 'Data structures', 'Unit testing', 'Open source', 'Information technology', 'Analytics', 'SQL']",2025-06-14 05:34:12
Senior Business Analyst,BP INCORPORATE INTERNATIONAL.,1 - 4 years,Not Disclosed,['Pune'],"Grade HResponsible for supporting the delivery of business analysis and consulting processes and procedures for the defined specialism using sound technical capabilities, building and maintaining effective working relationships, ensuring relevant standards are defined and maintained, and supporting delivery of process and system improvements. Specialisms: Business Analysis; Data Management and Data Science; Digital Innovation.\nEntity:\nTechnology\n\nITS Group\n\nYou will work with\nThe AppSim team is responsible for driving application simplification across the organization, focusing on reducing operational complexity and technical debt. They work closely with the wider digital delivery and digital core teams to identify and pursue simplification opportunities. The team collaborates with business partners to align simplification efforts with broader transformation goals and drive measurable improvements in operational efficiency.\nLet me tell you about the role\nA Business Analyst at bp provides enduring deep domain expertise to bridge the gap between business goals and technology solutions. Using techniques such as data analysis, customer and partner interviews and workshops, they gather, refine, and define business requirements and then collaborate with technology colleagues to deliver solutions that meet both user and business needs, ensuring successful roll-out and adoption of solutions.\nWhat you will deliver\nUser research: Engage with users, observe and analyze their workflows, and extract meaningful insights about how they perform a process and interact with a product or system. This involves uncovering pain points, process mapping, pattern recognition, and connecting learnings to potential solutions.\nRequirements definition: Take responsibility for eliciting requirements through various techniques such as interviews, workshops, and document analysis. They lead workshops to assemble and refine requirements, consider tradeoffs, and ensure a clear understanding of system constraints. Additionally, they collaborate with design teams to develop solutions that meet both business and user needs.\nRelationship management: Build strong relationships with commercial and technology partners at all levels within a distributed team, ensuring effective communication, alignment and collaboration.\nBusiness process change: Lead business process workshops to analyze and map business processes, find opportunities for process improvements, and implements changes to enhance efficiency and effectiveness.\nData analysis: Analyze and model data requirements, understand data models and database design to support sophisticated datasets, and provide insights and recommendations based on data analysis to support decision-making.\nService delivery: Diagnose issues and work closely with other support teams across functions to understand defects, drive minor improvements, and document change requests clearly and concisely in order to bring quick resolution.\nWhat you will need to be successful (experience and qualifications)\nStrong analytical and problem-solving skills.\nSuperb oral and written communication skills.\nAbility to build positive relationships with a variety of domain experts.\nTechnical proficiency in areas such as data analysis and modeling, service design, and application design.\nAt this level, a business analyst is encouraged to have strong expertise in core business analysis principles, with extensive knowledge in areas such as requirements definition, stakeholder management, service delivery, testing, business process change, and data analysis. They independently tackle sophisticated problems, lead initiatives, and drive them to completion, demonstrating high skill and expertise in their domain!\nPreferred experience:\nBachelors degree in Business Administration, Information Technology, or a related field, or equivalent experience.\nDemonstrable experience as a Business Analyst or in a similar role.\nFamiliarity with business analysis tools (e.g., ADO, Power BI).\nAbout bp\nOur purpose is to deliver energy to the world, today and tomorrow. For over 100 years, bp has focused on discovering, developing, and producing oil and gas in the nations where we operate. We are one of the few companies globally that can provide governments and customers with an integrated energy offering. Delivering our strategy sustainably is fundamental to achieving our ambition to be a net zero company by 2050 or sooner!\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform crucial job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n\nTravel Requirement\nUp to 10% travel should be expected with this role\n\nRelocation Assistance:\nThis role is eligible for relocation within country\n\nRemote Type:\nThis position is a hybrid of office/remote working\n\nSkills:\nBusiness Analysis, Business Analysis Tools, Business Analytics, Business Requirements Documentation (BRD), Business Strategy Analysis, Functional Requirements Document (FRD), IT Business Analysis, Software Requirements Analysis, Software Requirements Specifications",Industry Type: Oil & Gas,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Relationship management', 'Data analysis', 'Data management', 'Business analysis', 'Business analytics', 'Analytical', 'Consulting', 'Business strategy', 'Information technology']",2025-06-14 05:34:14
Data Scientist-Artificial Intelligence,IBM,10 - 15 years,Not Disclosed,['Bengaluru'],"We're seeking a results-driven and collaborative Software Development Manager to lead the design and development of IBM Consulting Advantage Platform. As a management leader, you'll collaborate with peers and stakeholders to ensure business continuity. You'll also be responsible for building and leading an impactful team of Developers & QA engineers, focusing on software developments, productivity improvements and fostering a culture of continuous learning and improvement.\nIn this role, you will be responsible for:\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\nPreferred technical and professional experience",,,,"['continuous integration', 'ci/cd', 'microservices', 'java', 'project management', 'kubernetes', 'docker', 'ansible', 'sql', 'react.js', 'git', 'devops', 'linux', 'jenkins', 'html', 'shell scripting', 'rest', 'python', 'github', 'maven', 'microsoft azure', 'javascript', 'spring boot', 'node.js', 'saas', 'terraform', 'aws']",2025-06-14 05:34:17
Product Delivery Sr Analyst,Pepsico,7 - 12 years,Not Disclosed,['Hyderabad'],"Overview \n\nThis role will ensure the successful delivery of projects across the organization. This role involves providing project management support, ensuring compliance with project methodologies, collecting and analyzing project performance data, and contributing to the development and improvement of project management processes and tools.\n\n Responsibilities \n\n\n",,,,"['project management', 'pmo', 'waterfall', 'agile', 'jira', 'product strategy', 'data analysis', 'ms project', 'business analysis', 'business analytics', 'product analysis', 'user stories', 'dashboards', 'business administration', 'sql', 'tableau', 'product management', 'brd', 'project coordination']",2025-06-14 05:34:21
Senior Analyst - MBB,Merkle B2b,2 - 8 years,Not Disclosed,['Chennai'],"The purpose of this role is to provide support to the senior team in delivering innovative solutions that deliver client objectives whilst meeting our business objectives and financial targets.\nJob Description:\nKey responsibilities:Collects and reports buying performance achieved on nominated clients that have Global Buying commitmentsEnsures that accuracy of data supplied and the declared results meet with potential external scrutinyEffectively communicates benchmarking methodology and productivity targets to local marketsCollects data from specific markets using the agreed methodology (client specific) to quantify, measure, calibrate price performance compared to historical price benchmarks - across all media typesIdentifies data anomalies and also potential delivery issues in marketManages data to normalise benchmarks to maintain as high levels of measurability as possible within the reportsManages preparation and verification of the data for the client reports - both data analysis and supporting commentaryAssists local markets and client service teams in dealing with Media Auditor requests / validations\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Auditor', 'Analyst', 'Data analysis', 'Client servicing', 'Finance', 'MBB']",2025-06-14 05:34:23
Analyst - Internal Audit (Business & IT),SentinelOne,4 - 5 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","About Us\nAt SentinelOne, we re redefining cybersecurity by pushing the limits of what s possible leveraging AI-powered, data-driven innovation to stay ahead of tomorrow s threats.\nFrom building industry-leading products to cultivating an exceptional company culture, our core values guide everything we do. We re looking for passionate individuals who thrive in collaborative environments and are eager to drive impact. If you re excited about solving complex challenges in bold, innovative ways, we d love to connect with you.\nWho are we looking for?\nReporting to the Manager- Internal Audit, this position is a highly visible and an impactful role across the company. The Analyst- Internal Audit, based in India and will work with all levels of management to promote business integrity and robust internal control structures, compliance with Sarbanes-Oxley legislation, and recommendation for process improvements.\nEssential Functions/duties:\nAssist in both Business and IT SOX planning, scoping, and risk assessment process through close collaboration with external auditors and business process owners\nConduct Business & IT walkthroughs and controls testing according to established audit standards\nEngage in Internal audit projects, ERM, operational and financial audits.\nDevelop high-quality process and audit testing documentation for design effectiveness and operating effectiveness of Business process controls & ITGCs.\nPerform testing of application controls, key reports, interfaces, integrations, and segregations of duties rules\nSound understanding of GAAP, COSO, SOX and PCAOB rules; experience in the use of auditing and assessment frameworks and the application of professional standards.\nDevelop and maintain comprehensive documentation including flow charts, process narratives and risk and control matrices and any others required\nEvaluate audit findings and coordinate remediation of deficiencies\nDevelop business relationships and proactively interact with process owners to gather information, resolve problems, and make recommendations for improvement and optimization\nDemonstrate initiative and provide timely updates to internal audit management\nManage multiple tasks effectively and deliver projects timely\nDocumentation and activities remain current and in compliance with the IIA s IPPF Standards and are consistent with best practices. Develop metrics for ongoing operational activities and leverage technology and data analytics to enhance IA operations.\nHelp manage governance of the Internal Audit function and mature and evolve our audit methodology and operational audit program\nPerform other tasks and projects as assigned in support of the internal audit team and corporate objectives\nQualifications:\nBachelor s degree in Accounting, Finance, or related field preferred\nRecognized professional qualification(s): CA/CPA/CIA/CISA is preferred\nMinimum of 4-5 years of audit experience, preferably within the technology industry\nPositive attitude and willingness to learn\nAbility to take direction, learn quickly, work independently, and maintain a level of professional skepticism\nAbility to handle multiple priorities and deadlines, with high standards for quality, accuracy, and attention to detail\nDemonstrate basic research capabilities with strong analytical and creative problem-solving skills\nWorking knowledge of data analysis and business intelligence tools is a plus (PowerBI, Tableau).\nExperience with Big 4 accounting firms or global public companies is strongly preferred.\nStrong written and verbal communication skills",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'ERM', 'Data analysis', 'Cisa', 'Risk assessment', 'Analytical', 'GAAP', 'Coso', 'Business intelligence', 'Operations']",2025-06-14 05:34:26
Paid Social - Senior Analyst,Merkle B2b,3 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimization of Paid Social campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nProvide initial insights on campaign trends to executives and planners\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Other,"Employment Type: Full Time, Permanent","['QA', 'Analyst', 'Data analysis', 'Management']",2025-06-14 05:34:28
Senior Analyst - MBB,Merkle Science,1 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to provide support to the senior team in delivering innovative solutions that deliver client objectives whilst meeting our business objectives and financial targets.\nJob Description:\nKey responsibilities:Collects and reports buying performance achieved on nominated clients that have Global Buying commitmentsEnsures that accuracy of data supplied and the declared results meet with potential external scrutinyEffectively communicates benchmarking methodology and productivity targets to local marketsCollects data from specific markets using the agreed methodology (client specific) to quantify, measure, calibrate price performance compared to historical price benchmarks - across all media typesIdentifies data anomalies and also potential delivery issues in marketManages data to normalise benchmarks to maintain as high levels of measurability as possible within the reportsManages preparation and verification of the data for the client reports - both data analysis and supporting commentaryAssists local markets and client service teams in dealing with Media Auditor requests / validations\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Auditor', 'Analyst', 'Data analysis', 'Client servicing', 'Finance', 'MBB']",2025-06-14 05:34:30
Campaign Management Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Campaign Management\n\n\n\n\nDesignation: Campaign Management Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe B2B Sales and Event Support Specialist will play a critical role in enhancing business-to-business interactions and promoting products within the oil and gas industry.Role requires - B2B Sales and event Support (project Manager)Understanding client requirements for multichannel Campaign/content and cascading tasks to content authors/art workers etc.\nManaging and triaging tickets to relevant teams as per agreed timelinesEnsuring Standards and Data Privacy Compliance for every CampaignMaintain high quality standards for the campaign delivery and ensure timelines are met with Quality Execute Projects in line with project management principles of Communication, Stakeholder management, Risk & Issue Management etc.Campaign Management focuses on planning, executing, tracking and analysis of direct marketing campaigns. The team is responsible for the entire lifecycle of a marketing campaign, from inception to launch to evaluation of result. The team is accountable for analyzing the effectiveness of marketing campaigns using ROI calculations. The role may require for you to have a good understanding of digital marketing, email marketing and technologies like Salesforce Marketing Cloud, Salesforce CRM, Salesforce Automation studio, Google DV360 and Responsys.\n\n\n\n\nWhat are we looking for\nB2B Sales TransformationEnsure Process, Metrics & Reporting compliance for every Campaign throughout the various stages of campaign journey & delivery.\nMultitasking with wide range of responsibilities, including the creation of sales collateral, coordinating training programs, managing product demonstrations, and providing event support. Possess strong organizational skills, creativity, and the ability to communicate effectively with various stakeholders to ensure the successful execution of sales and event initiatives.\nStrong written and verbal communication skills.\nExcellent organizational and project management abilities.\nProficiency in Microsoft office especially PowerPoint and any other presentation tools.\nBasic knowledge of content creation and design software (e.g., Adobe Creative Suite, Microsoft Office).\nExperience in coordinating events and training programs.\nAbility to work collaboratively with sales and marketing teams.\nStrong attention to detail and problem-solving skills.\nWorked on Project management tools like Workfront, Jira Service Now etcBasic knowledge of graphic design principles and tools.\nProficiency in virtual communication platforms (e.g., Zoom, Microsoft Teams).\nFamiliarity with customer relationship management (CRM) systems.\nExperience with data analysis and reporting tools (e.g., Microsoft Excel, Google Analytics) will be good to have skills.\nBachelors degree in Business, Marketing, Communications, or a related field preferred.\nPrevious experience in sales support, event management, or a similar role within the oil and gas industry is an asset.\n\n\n\nRoles and Responsibilities: Sales Support ServicesWork with the team to create engaging sales materials, including brochures, presentations, and case studies, aligned with branding guidelines.\nSchedule and manage logistics for training sessions; develop customized training materials based on feedback from sales teams.\nCollaborate with client organize and conduct product demonstrations, ensuring alignment with client needs and effective communication of product value.\nManage client communications with multiple stakeholders.\nEvents Support ServicesCollaborate with event agencies to ensure smooth execution of events, managing timelines, logistics, and stakeholder communications.\nWork with team to develop promotional materials and event-specific content, ensuring alignment with branding and event objectives as per client briefings.\nManage invitations, Pre-event communication with target audience, registrations, and follow-up communications, including feedback collection and reporting.\nUnderstanding of compliance and safety standards relevant to event management.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'project management', 'salesforce', 'salesforce crm', 'design principles', 'email marketing', 'adobe creative suite', 'google', 'campaign management', 'salesforce marketing cloud', 'marketing campaigns', 'campaigns', 'google analytics', 'automation studio', 'jira']",2025-06-14 05:34:32
Paid Social - Senior Analyst,Merkle Science,2 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimization of Paid Social campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nProvide initial insights on campaign trends to executives and planners\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['QA', 'Analyst', 'Data analysis', 'Management']",2025-06-14 05:34:35
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Navi Mumbai'],"Skill required: Delivery - Warranty Management\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDefine warranty offerings; run outsourced after-sales warranty support and entitlement programs; evaluate customer feedback and planned versus actual costs of warranty coverage; use warranty data analytics to reduce cost and improve product quality; increase recoveries from suppliers and design and deploy warranty solutions.\n\n\n\n\nWhat are we looking for\nAutomotive Warranty / Warranty Analytics Data Analysis Business Intelligence Business logic Scripting Reporting Commitment to quality Adaptable and flexible Agility for quick learning Ability to work well in a team Written and verbal communication Python (Programming Language)/ SQL/ ML\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['warranty management', 'python', 'data analytics', 'data analysis', 'sql', 'service operations', 'field service', 'customer service', 'business development', 'business intelligence', 'customer support', 'service engineering', 'after sales service', 'after market service']",2025-06-14 05:34:37
I&F Decision Sci Practitioner Sr Analyst,Accenture,5 - 8 years,Not Disclosed,['Navi Mumbai'],"Skill required: Delivery - Warranty Management\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Sr Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIDefine warranty offerings; run outsourced after-sales warranty support and entitlement programs; evaluate customer feedback and planned versus actual costs of warranty coverage; use warranty data analytics to reduce cost and improve product quality; increase recoveries from suppliers and design and deploy warranty solutions.\n\n\n\n\nWhat are we looking for\nWarranty Analytics Automotive Warranty Scripting Data Analysis & Interpretation Business Intelligence Commitment to quality Adaptable and flexible Agility for quick learning Ability to work well in a team Written and verbal communication Data Engineering/SQL Databricks ML\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day-to-day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['warranty management', 'data analytics', 'data analysis', 'business intelligence', 'sql', 'hive', 'python', 'service operations', 'pyspark', 'data warehousing', 'microsoft azure', 'machine learning', 'data engineering', 'tableau', 'data science', 'data modeling', 'spark', 'hadoop', 'big data', 'aws', 'etl']",2025-06-14 05:34:40
Content Mgmt Advisory Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Hyderabad'],"Skill required: Marketing Operations - Content management\n\n\n\n\nDesignation: Content Mgmt Advisory Senior Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designOrganize, categorize and publish content and information using specific tools and channels, for use by different groups and individuals within the organization.\n\n\n\n\nWhat are we looking for\nCommitment to qualityProcess-orientationDetail orientationWritten and verbal communication - Strong writing and editing background, preferably with a portfolio of past work Experience in corporate communications and project management Experience with remote, cross-functional teams and communicating with shareholders Ability to analyze data that drives business decisions Excellent organization and communication skills, good at managing projects Proficiency with the Google suite a plus Ability to work in a fast-paced, deadline-driven environmentHigh school diploma required, Associates preferred. Will accept equivalent workexperience (2-3 years) in lieu of degree.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts Replicate/copy provided content, ensuring accurate transcription and duplication Create, edit and publish content for various topics, including strategy, organizationalmanagement, education and help center support Work closely with POCs and SMEs to formulate content relevant for the task/scope of theassignment Seeks opportunities to improve knowledge, skills, and performance by reviewingknowledge base content, practicing skills and being receptive to coaching andconstructive feedback Produce documents that convey strategy, status, reorganization, scope, timelines, taskplanning, action items, risks, issues, project dependencies, test planning, or rollout planning Monitor project performance and timelines, setting and meeting deadlines as necessary Maintain confidentiality of our partners content Able to function well with a team in a highly collaborative cross-functional environment, but still able to work as an individual contributor to track down answers to properlyformulate content Ability to think on your feet and adapt to changing circumstances and situations\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Content, Editorial & Journalism","Employment Type: Full Time, Permanent","['digital marketing', 'content management', 'editing', 'google suite', 'content analysis', 'data analysis', 'data analytics', 'mis reporting', 'dns', 'content editing', 'sql', 'creative writing', 'content development', 'tableau', 'active directory', 'advanced excel', 'content writing', 'dhcp']",2025-06-14 05:34:43
Risk and Compliance Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Gurugram'],"Skill required: Risk & Compliance - Sarbanes-Oxley Act (SOX)\n\n\n\n\nDesignation: Risk and Compliance Senior Analyst\n\n\n\n\nQualifications:BE/BTech\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Risk and Compliance vertical and help us perform compliance reviews, publish reports with actions and provide closure guidance as needed. We design & recommend effective controls to mitigate risks and help service delivery team prepare for upcoming client / external audits.You will be working as a part of the Risk & compliance team which is responsible for helping clients and organizations identify risks and create mitigation plans.United States federal law that set new or expanded requirements for all U.S. public company boards, management and public accounting firms. Assist in implementation of client-designed Sarbanes-Oxley controls into client s financial processes, enterprise resource planning system or supporting technology.\n\n\n\n\nWhat are we looking for\nIn this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shiftsIn this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['risk compliance', 'aml', 'auditing', 'compliance analysis', 'sox', 'risk management', 'risk assessment', 'due diligence', 'data analysis', 'anti money laundering', 'investment banking', 'information security', 'business analysis', 'internal audit', 'it audit', 'kyc', 'it governance']",2025-06-14 05:34:47
Measurement & Report Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Jaipur'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Senior Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nEffective communication and organization skills with Polished, professional presence Experience in reporting of contractual metrics and operational KPIs Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Candidate who is good in excel and MIS reports are looked at for these skillsPrepare management reports and analysis, both recurring and ad-hoc. It focuses on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nProficient in MS Office with advance knowledge in excel formulas. Ability to create Nice & User friendly excel dashboards. Ability to create meaningful presentation through PowerPoint. Working Knowledge in Power Automate, Power Apps, PowerBi Basic Automation abilities using VBA Macros Good Understanding of processes like (e.g., F&A, Marketing Operations, HR, Procurement and Supply Chain) Proficient in MS Office with advance knowledge in excel formulas. Ability to create Nice & User friendly excel dashboards. Ability to create meaningful presentation through PowerPoint. Working Knowledge in Power Automate, Power Apps, PowerBi Basic Automation abilities using VBA Macros Good Understanding of processes like (e.g., F&A, Marketing Operations, HR, Procurement and Supply Chain)\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Create and Design New Dashboard / Reports as required. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts. Connect with Stakeholders and drive governance around performance metrics. Play Individual Contributor or Manage a team dedicated for the assignment and drive performance.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business reporting', 'vlookup', 'reporting and analytics', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'business analysis', 'power bi', 'business analytics', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'powerapps', 'tableau', 'data visualization']",2025-06-14 05:34:50
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Gurugram'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nLanguage - Ability:English(International) - Proficient\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Implementation of gen. ledger processes including yearend closing, journalizing. Creating and maintaining ledgers, ledger currencies, budgets, and journal entries, design to deliver a financial management solution including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry and reporting as well as dynamic allocations and the management of commitments and expenditures also run Interface reports and perform close books of accounts.\n\n\n\n\nWhat are we looking for\nProblem-solving skillsAbility to perform under pressureStrong analytical skillsAbility to manage multiple stakeholdersThought leadership\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'business administration', 'record to report', 'macros', 'service operations', 'data analysis', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'budgeting', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:34:53
Record To Report Ops Senior Analyst,Accenture,5 - 8 years,Not Disclosed,['Hyderabad'],"Skill required: Record To Report - Balance Sheet Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Senior Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:5 to 8 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.\n\n\n\n\nWhat are we looking for\nInvolves balancing all balance sheet accounts against sub-ledger or other non-general ledger based source data to verify whether the balance sheet accounts are in balance with the source system feeding the general ledger. Differences which arise are addressed as reconciling items.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of increasingly complex problems Your day to day interactions are with peers within Accenture You are likely to have some interaction with clients and/or Accenture management You will be given minimal instruction on daily work/tasks and a moderate level of instruction on new assignments Decisions that are made by you impact your own work and may impact the work of others In this role you would be an individual contributor and/or oversee a small work effort and/or team Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['balance sheet', 'journal entries', 'general ledger', 'business administration', 'record to report', 'macros', 'service operations', 'data analysis', 'forecasting', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:34:57
Business Analyst,Kuku Fm,1 - 3 years,Not Disclosed,['Bengaluru'],"About the Role\nWe are looking for a data-driven Business Analyst to join our high-impact team. As a key enabler of data-backed decisions, you will work closely with cross-functional stakeholders product, marketing, operations, and leadership to drive insights and strategic initiatives in a fast-paced tech environment. This role demands strong analytical capabilities, an ownership mindset, and the ability to translate complex data into actionable business recommendations.\nResponsibilities:\nClosely work with business leaders and founders office to discover insights and solve high-impact problems across business verticals using data.\nLead day-to-day analysis requirements and present insights in a structured form.\nBe on top of data to help develop actionable insights from weekly / monthly business performance reviews.\nCollaborate across different teams to reach the root of a problem/insight.\nLeverage multiple sources of information (primary data analysis, qualitative research, etc.) to generate deeper insights.\nDesign, run and measure experiments to test the business hypotheses in collaboration with Product and Engineering teams.\nMonitor and forecast key business metrics regularly.\nRequirements:\nYou have 1-3 years of experience in high-growth tech startups, management consulting, PE/VC funds.\nYou have hands-on experience of using SQL on a daily basis to extract data and are comfortable with excel.\nYou have hands-on experience in building dashboards on visualization platforms like Tableau, Power BI, periscope data, cluvio etc.\nBreathe data and have exceptional problem-solving and presentation skills.\nPreferably have some basic knowledge of python / R (not a deal-breaker).\n\nWhy Join Us?\nOpportunity to work in a fast-growing audio and content platform.\nExposure to multi-language marketing and global user base strategies.\nA collaborative work environment with a data-driven and innovative approach.\nCompetitive salary and growth opportunities in marketing and growth strategy.\nAbout KUKU\nFounded in 2018, KUKU is India s leading storytelling platform, offering a vast digital library of audio stories, short courses, and microdramas. KUKU aims to be India s largest cultural exporter of stories, culture and history to the world with a firm belief in Create In India, Create For The World .\nWe deliver immersive entertainment and education through our OTT platforms: Kuku FM, Guru, Kuku TV, and more. With a mission to provide high-quality, personalized stories across genres from entertainment across multiple formats and languages, KUKU continues to push boundaries and redefine India s entertainment industry.\nWebsite: www.kukufm.com\nAndroid App: Google Play\niOS App: App Store\nLinkedIn: KUKU\nReady to make an impact? Apply now!",Industry Type: Film / Music / Entertainment,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Qualitative research', 'Data analysis', 'Analytical', 'Management consulting', 'IOS app', 'Marketing operations', 'Product marketing', 'SQL', 'Android', 'Python']",2025-06-14 05:35:01
COE Analyst,Career Guideline,1 - 6 years,9-18 Lacs P.A.,['Bengaluru'],Designation - COE Analyst\nJob Function - FP&A / Portfolio Management / Valuation Reporting .\nExperience - 1-3 years\nSalary - 9 - 13 Lpa\nLocation -Bengaluru\nNotice - Immediate Joiner,Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Excel', 'Dcf Valuation', 'Financial Modelling', 'MIS Reporting', 'Portfolio Analyst', 'Discounted Cash Flow', 'FPA', 'Data Analysis', 'Coe', 'Investment Analyst', 'Reporting And Analysis', 'Financial Analyst', 'Dashboard Development', 'Valuation Analysis']",2025-06-14 05:35:04
Analyst-10,Merkle Science,1 - 2 years,Not Disclosed,['Bengaluru'],"The purpose of this role is to provide support for the collection, analysis, and dissemination of insights to our clients\nJob Description:\nKey responsibilities:\nIntegrates disparate datasets, conducts data preparation for analyses\nApplies data science methods to provide insights and recommendations to clients\nDelivers analytic outcomes based on project timelines and key milestones\nMaintains knowledge of new trends in the data science industry\nDevelops and manages code used for analytics purposes\nCommunicates findings and insights\nKnowledge on SQL, Tableau\nLocation:\nBangalore\nBrand:\nIprospect\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'tableau', 'data science', 'Analytics', 'SQL']",2025-06-14 05:35:08
S&C Global Network - AI - Auto & Industrial - Analyst,Accenture,1 - 3 years,Not Disclosed,['Bengaluru'],"Management Level:Ind & Func AI Decision Science Analyst\n\n\n\nLocation:Bengaluru (Bangalore), Gurugram (Gurgaon), Hyderabad, Chennai.\n\n\n\nMust-have skills:Programming languages -Python/R, Generative AI, Large Language Models (LLMs), ML libraries such as Scikit-learn, TensorFlow, Torch, Lang Chain, or OpenAI API, RAG Applications.\n\n\n\n\nGood to have skills:Big data technologies such as Spark or Hadoop,AI model explainability(XAI),bias detection and AI ethics. Familiarity with Edge AI and deploying models on embedded devices for industrial automation. Experience with Reinforcement Learning (RL) and AI-driven optimization techniques.\n\n\n\nJob\n\n\nSummary\n\nWe are looking for a Data Scientist / AI Specialist with 1-3 years of experience to join our team and work on client projects in the Automotive & Industrial sectors. This role will involve leveraging traditional Machine Learning (ML), Generative AI (GenAI), Agentic AI, and Autonomous AI Systems to drive innovation, optimize processes, and enhance decision-making in complex industrial environments.\n\nPrior experience in the Auto/Industrial industry is a plus, but we welcome candidates from any domain with a strong analytical mindset and a passion for applying AI to real-world business challenges.\n\n\n\n\nRoles & Responsibilities:\nDevelop, deploy and monitor AI/ML models in production environments & enterprise systems, including predictive analytics, anomaly detection, and process optimization for clients.\nWork with Generative AI models (e.g., GPT, Stable Diffusion, DALLE) for applications such as content generation, automated documentation, code synthesis, and intelligent assistants.\nImplement Agentic AI systems, including AI-powered automation, self-learning agents, and decision-support systems for industrial applications.\nDesign and build Autonomous AI solutions for tasks like predictive maintenance, supply chain optimization, and robotic process automation (RPA).\nWork with structured and unstructured data from various sources, including IoT sensors, manufacturing logs, and customer interactions.\nOptimize and fine-tune LLMs (Large Language Models) for specific business applications, ensuring ethical and explainable AI use.\nUtilize MOps and AI orchestration tools to streamline model deployment, monitoring, and retraining cycles.\nCollaborate with cross-functional teams, including engineers, business analysts, and domain experts, to align AI solutions with business objectives.\nStay updated with cutting-edge AI research in Generative AI, Autonomous AI, and Multi-Agent Systems.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n1-3 years of experience in Data Science, Machine Learning, or AI-related roles.\nProficiency in Python (preferred) or R, and experience with ML libraries such as Scikit-learn, TensorFlow, Torch, Lang Chain, or OpenAI API.\nStrong understanding of Generative AI, Large Language Models (LLMs), and their practical applications.\nHands-on experience in fine-tuning and deploying foundation models (e.g., OpenAI, Llama, Claude, Gemini, etc.).\nExperience with Vector Databases (e.g., FAISS, Chroma, Weaviate, Pinecone) for retrieval-augmented generation (RAG) applications.\nKnowledge of Autonomous AI Agents (e.g., AutoGPT, BabyAGI) and multi-agent orchestration frameworks.\nExperience working with SQL and NoSQL databases.\nFamiliarity with cloud platforms (AWS, Azure, or GCP) for AI/ML model deployment.\nStrong problem-solving and analytical thinking abilities.\nAbility to communicate complex AI concepts to technical and non-technical stakeholders.\nBonus:Experience in Automotive, Industrial, or Manufacturing AI applications (e.g., predictive maintenance, quality inspection, digital twins).\n\n\n\n\nAdditional Information:\nBachelor/Masters degree in Statistics/Economics/ Mathematics/ Computer Science or related disciplines with an excellent academic record /MBA from top-tier universities.\nExcellent Communication and Interpersonal Skills.\n\n\n\n\n\nAbout Our Company | Accenture\n\n\n\n\n\nQualification\n\n\n\nExperience:Minimum 1-3 years of relevant Data Science, Machine Learning or AI-related roles., Exposure to Industrial & Automotive Firms or Professional Services.\n\n\n\n\nEducational Qualification: Bachelor/Masters degree in Statistics/Economics/ Mathematics/ Computer Science or related disciplines with an excellent academic record or MBA from top-tier universities.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'sql', 'tensorflow', 'data science', 'image processing', 'c++', 'scikit-learn', 'microsoft azure', 'artificial intelligence', 'nosql', 'deep learning', 'r', 'spark', 'gcp', 'computer vision', 'network analysis', 'hadoop', 'api', 'big data', 'aws', 'opencv']",2025-06-14 05:35:12
Full Stack Performance Analyst,IBM,5 - 10 years,Not Disclosed,['Bengaluru'],As a Full Stack Performance Analyst your responsibilities would be\n\n1. Study workloads characteristics on IBM Power and x86\n\n2. Executing & measuring performance of various PowerVM (Hypervisor) functions & features\n\n3. Using various performance tools to analyze performance & identify bottlenecks / opportunities for improving PowerVM (Hypervisor) stack/functions performance\n\n4. Provide tuning & performance optimizations suggestion to improve performance\n\n5. Working on client performance issues\n\n\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\n\n\n\n\nPreferred technical and professional experience,,,,"['data analysis', 'os internals', 'ai techniques', 'scrum', 'agile', 'load runner', 'c++', 'c', 'performance tuning', 'performance testing', 'hp performance center', 'presentation skills', 'dynatrace', 'neoload', 'nmon', 'jmeter', 'hypervisor', 'performance center', 'debugging', 'performance analysis']",2025-06-14 05:35:16
Senior Analyst - Projects,Microland,5 - 9 years,Not Disclosed,['Bengaluru'],"Required Skills\nBehavioral | Aptitude | Leadership Skills\nTechnology | Data Analytics Activities | Data Analysis\n\nEducation Qualification :\nAny Graduate\n\nCertification Mandatory / Desirable :\nTechnology | Certifications in Project Management | Agile Certification | CSM (Certified Scrum Master)\n\nSkills Required:\n\nHardware and Network:\n- Understand issues from a user perspective and isolate issues.\n- Decode the error/alarm status, understand the failed unit/device, and support hands and feet in resolution through strong Hardware and Network:king troubleshooting techniques. VPN\n- Manage VPN Client Groups. Manage exception requests to Groups and access as per guidelines.\n\nConfiguration:\n- Standard SSL and IPSEC\n- Modify access-list.\n\nTroubleshoot: - Access-Control issues and all escalated cases from Level 1 Proxy\n\nConfigure:\n- Content filtering (Black and Whitelisting) of URLs under respective categorizations.\n- User Group integration with Access Policies\n- Pull reports on intrusion and detect in the proxy level.\n- Capture and Evaluate TCP Dumps/ Wireshark on escalated incidents.\n- Define Reverse and Forward Proxy.\n\nFirewall:\n- Initial Configuration of the firewall as per standard rule set (permit and deny rules).\n- Basic routing: Static routing.\n- Perform Health Checks: failover testing/ HA d. NAT (Static, Dynamic and PAT)\n- NAT configuration and troubleshooting.\n- Troubleshoot firewall-related access issues and understand filter logs.\n- Load Balancing Troubleshoot LB issues, reading the various counters and logs that are available in the tool,\n- Configure: Nodes and members, virtual Servers, Load balancing method to be used as per instruction.\n\nTechnical Skills:\n- Network Components, Devices\n- Virtual Private Network (VPN) connection Security\n- Proxy\n- Firewalls\n- Network Load Balancing",,,,"['TCP', 'Data analysis', 'VPN', 'Project management', 'Agile', 'Scrum', 'Content filtering', 'Load balancing', 'SSL', 'Firewall']",2025-06-14 05:35:20
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,2 - 3 years,Not Disclosed,['Bengaluru'],"Entity:- Accenture Strategy & Consulting\n\n\n\nTeam:- Strategy & Consulting Global Network\n\n\n\nPractice:- Supply Chian Analytics\n\n\n\nTitle:- Ind & Func AI Decision Science Analyst\n\n\n\nJob location:- Bangalore/Gurgaon/Hyderabad/ Mumbai\n\n\n\nExplore an Exciting Career at Accenture\n\nDo you believe in creating an impactAre you a problem solver who enjoys working on transformative strategies for global clientsAre you passionate about being part of an inclusive, diverse, and collaborative culture\n\n\n\nThen, this is the right place for you! Welcome to a host of exciting global opportunities in Accenture Strategy and Consulting\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\nExperience and Education:\n2-3 years of experience in Machine Learning, Time series forecasting or Optimization Techniques.\nMasters degree in technology or engineering or quantitative field (e.g. MSc in Statistics and Operations Research, M.Tech. in Industrial Engineering, Applied Math/Statistics, Computer Science, MBA in Operations).\nCertifications in any one or two of the areas will be an added advantage:Python, AI/ML, Optimization, Simulation, any of the cloud platforms (Azure/ GCP/ AWS).\n\nQualification\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\nAbout Accenture:\nwww.accenture.com\n\nAbout Accenture Strategy & Consulting:\n\nAccenture Strategy shapes our clients future, combining deep business insight with the understanding of how technology will impact industry and business models. Our focus on issues such as digital disruption, redefining competitiveness, operating and business models as well as the workforce of the future helps our clients find future value and growth in a digital world. Today, digital is changing the way organizations engage with their employees, business partners, customers and communities. This is our unique differentiator. To bring this global perspective to our clients, Accenture Strategy's services include those provided by our Capability Network a distributed management consulting organization that provides management consulting and strategy expertise across the client lifecycle. Our Capability Network teams complement our in-country teams to deliver cutting-edge expertise and measurable value to clients all around the world.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'time series analysis', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'data preparation', 'artificial intelligence', 'tableau', 'descriptive analysis', 'data modeling', 'cloud applications', 'data visualization', 'ml']",2025-06-14 05:35:23
Technical Business Analyst,Holiday Inn Club Vacations,4 - 9 years,Not Disclosed,['Bengaluru'],"At Holiday Inn Club Vacations, we believe in strengthening families. And we look for people who exhibit the courage, caring and creativity to help us become the most loved brand in family travel. Were committed to growing our people, memberships, resorts, and guest love. Thats why we need individuals who are passionate in life and bring those qualities to work every day. Do you instill confidence, trust, and respect in those around you? Do you encourage success and build relationships? If so, were looking for you.\n\nPOSITION DESCRIPTION:\nWe are seeking a results-driven Technical Business Analyst with deep domain expertise in timeshare products, a strong technical foundation in SQL Server, experience with Salesforce CRM, and a solid understanding of API integrations. The ideal candidate will serve as the bridge between business stakeholders and development teams, enabling scalable and efficient solutions across systems in the vacation ownership lifecycle.\nOther responsibilities include assisting with complex operational and support concerns, ensuring alignment with development best practices and Agile/Scrum methodologies. The position requires a hands-on approach to resolving critical system issues, helping the team enhance their understanding of processes and software system challenges, and setting or adjusting team norms and SLAs.\n\nESSENTIAL DUTIES AND TASKS:\nAnalyze, document, and communicate business and functional requirements for enhancements and integrations related to timeshare products, including property management systems (PMS), reservations, owner portals, and inventory management.\nCollaborate with cross-functional teams to design and implement seamless Salesforce CRM integrations with internal systems and third-party platforms.\nUse SQL Server to perform data analysis, create queries and validate data integrity across systems.\nDesign and document API requirements, including payload structures, authentication, data mapping, and error handling.\nPartner with development and QA teams to ensure technical solutions align with business goals and maintain system reliability.\nSupport system integration efforts including testing, troubleshooting, & deployment of features & APIs.\nCreate user stories, process flows, data models, and integration diagrams to support technical specifications.\nParticipate in Agile ceremonies and help prioritize features based on business impact and technical complexity.\nContribute to architectural decisions and participate in code and design reviews.\nTroubleshoot, debug, and resolve issues in both development and production environments.\nContribute to improving team efficiency, development processes, and overall software quality.\nPROFESSIONAL SKILLSET QUALIFICATIONS\nBachelors degree in Information Technology, Business Analysis, Computer Science, or related field.\n5+ years of experience as a Technical Business Analyst, with at least 2 years in the timeshare or vacation ownership industry.\nStrong understanding of SQL Server and data analysis best practices.\nHands-on experience with Salesforce CRM, including objects, workflows, and custom integrations.\nWorking knowledge of RESTful APIs, including reading/writing API specs, JSON payloads, and integration testing tools (e.g., Postman).\nExperience in system integration projects, including third-party tools (e.g., booking engines, payment gateways, or marketing platforms).\nStrong documentation skills: user stories, BRDs, FRDs, use cases, sequence diagrams.\nFamiliarity with Agile/Scrum methodologies and tools like ServiceNow and Azure DevOps.\n\nSOFT SKILLS\nStrong analytical and problem-solving mindset.\nExcellent verbal and written communication skills.\nAbility to prioritize tasks and manage multiple projects in a fast-paced environment.\nTeam player with a proactive attitude and a high attention to detail.",Industry Type: Travel & Tourism,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Api Integration', 'Third Party Integration', 'Salesforce CRM', 'Scrum Agile Development Methodology', 'Documentation', 'SQL Server', 'Salesforce']",2025-06-14 05:35:26
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title -\n\n\n\nS&C Global Network - AI - Supply Chain Analytics - Analyst\n\n\n\nManagement Level:\n\n\n\n11-Analyst\n\n\n\nLocation:\n\n\n\nHyderabad, HDC2A\n\n\n\nMust-have skills:Data Analytics\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'anaplan', 'data analytics', 'sap', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'supply', 'data preparation', 'tableau', 'descriptive analysis', 'data modeling', 'sap ibp', 'cloud applications', 'ibp', 'data visualization']",2025-06-14 05:35:29
GN - SONG - Service - CX - Value Architect - Analyst,Accenture,2 - 5 years,Not Disclosed,['Bengaluru'],"Template\n\nJob Title - GN - SONG - Service - CX - Value Architect - Analyst\n\nManagement Level :11 - Analyst\n\nLocation:Delhi, Gurgaon, Mumbai, Bangalore, Chennai, Pune, Hyderabad\n\nMust have skills:Value Realization\n\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute\n\nJob\n\n\nSummaryAs part of the team, you will provide transformation services driven by key offerings like Living Marketing, Connected Commerce and Advanced Customer Engagement. These services help our clients become living businesses by optimizing their marketing, sales and customer service strategy, thereby driving cost reduction, revenue enhancement, customer satisfaction and impacting front end business metrics in a positive manner.\nRoles & ResponsibilitiesTranslate strategic objectives into high-impact use cases in the specific area of expertise.\nUnderstand clients business priorities and focus areas to identify the right business scenarios and impacted value levers (KPIs) to include in the business case.\nIdeate and execute on compelling value creation workshops.\nConduct detailed qualitative and quantitative research to lay the foundation of a strong business case.\nOwn every stage of the value creation process, from research and identification to value drafting and dashboarding.\nDefine value architecting requirements and work with Accenture teams to deliver solutions.\nAdvise clients on industry best practices (when appropriate).\nAccurately estimate time to complete work.\nContinually experiment with new tools, technologies and sharpen analytical skills.\nAbility to research and provide strategic, goal-driven solutions for clients.\nCollaborate with other value architects, both offshore & onshore, including client-side managers, business heads, and other stakeholders across the organization.\nProvide useful contributions to team meetings and conversations, actively participating in client meetings and workshops- Ability to create hypothesis based on understanding of clients issues.\nProfessional & Technical\n\n\n\n\nSkills:\nApply best of breed Excel practices- Deep-dive with solid knowledge of formulas & macros to bring in speed & efficiency.\nMaximize experience in developing interactive models:Use relevant dashboard creation platforms (Power BI, Tableau, etc.) to design and apply interactive dashboards.\nInnovate with Creativity:Demonstrate an ability to work in a fast-paced environment with the ability to abstract value into compelling business story.\nParticipate in pre-sales activities including response to RFPs, creating proofs of concept, creating effective presentations, demonstrating solutions during client orals, effort and cost estimation process, etc.\nParticipate in practice-specific initiatives including creating points of view, creating reusable assets on contact center space, performing analysis on industry research and market trends and bringing in innovative solutions, etc.\nAdditional InformationGood understanding of sales, service & marketing as a function\nSolid experience in developing quantitative models.\nConducting qualitative & quantitative research\nAnchoring client/senior stakeholder conversations\nCreating engaging storyboards using the best data visualization tools such as Power BI, Tableau, etc.\n\nAbout Our Company | AccentureQualification\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ssas', 'bi', 'power bi', 'sql', 'tableau', 'python', 'data analysis', 'oracle', 'data warehousing', 'pivot table', 'microsoft azure', 'business analysis', 'vlookup', 't-sql', 'business intelligence', 'sql server', 'plsql', 'data modeling', 'advanced excel', 'ssrs', 'data visualization', 'ssis', 'etl', 'msbi']",2025-06-14 05:35:31
S&C Global Network - AI - CDP - Analyst,Accenture,8 - 10 years,Not Disclosed,['Gurugram'],"Job Title -\n\n\n\nS&C Global Network - AI - RTCDP - Consultant\n\n\n\nManagement Level:\n\n\n\n9-Team Lead/Consultant\n\n\n\nLocation:\n\n\n\nBengaluru\n\n\n\nMust-have skills:Web Analytics Tools\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nTechnical\n\n\n\n\nSkills:\n\nAny CDP platforms experience e.g., Lytics CDP platform developer, or/and\nSegment CDP platform developer, or/and\nAdobe Experience Platform (Real time CDP) developer, or/and\nCustom CDP developer on any cloud\nGA4/GA360, or/and Adobe Analytics\nGoogle Tag Manager, and/or Adobe Launch, and/or any Tag Manager Tool\nGoogle Ads, DV360, Campaign Manager, Facebook Ads Manager, The Trading desk etc.\nDeep Cloud experiecne (GCP, AWS, Azure)\nAdvance level Python, SQL, Shell Scripting experience\nData Migration, DevOps, MLOps, Terraform Script programmer\n\n\n\nSoft\n\n\n\n\nSkills:\n\nStrong problem solving skills\nGood team player\nAttention to details\nGood communication skills\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\nWHATS IN IT FOR YOU\n\nAs part of our Analytics practice, you will join a worldwide network of over 20k+ smart and driven colleagues experienced in leading AI/ML/Statistical tools, methods and applications. From data to analytics and insights to actions, our forward-thinking consultants provide analytically-informed, issue-based insights at scale to help our clients improve outcomes and achieve high performance.\n\n\n\nWhat you would do in this role\n\nA Consultant/Manager for Customer Data Platforms serves as the day-to-day marketing technology point of contact and helps our clients get value out of their investment into a Customer Data Platform (CDP) by developing a strategic roadmap focused on personalized activation. You will be working with a multidisciplinary team of Solution Architects, Data Engineers, Data Scientists, and Digital Marketers.\n\n\n\nKey Duties and Responsibilities:\nBe a platform expert in one or more leading CDP solutions. Developer level expertise on Lytics, Segment, Adobe Experience Platform, Amperity, Tealium, Treasure Data etc. Including custom build CDPs\nDeep developer level expertise for real time even tracking for web analytics e.g., Google Tag Manager, Adobe Launch etc.\nProvide deep domain expertise in our clients business and broad knowledge of digital marketing together with a Marketing Strategist industry\nDeep expert level knowledge of GA360/GA4, Adobe Analytics, Google Ads, DV360, Campaign Manager, Facebook Ads Manager, The Trading desk etc.\nAssess and audit the current state of a clients marketing technology stack (MarTech) including data infrastructure, ad platforms and data security policies together with a solutions architect.\nConduct stakeholder interviews and gather business requirements\nTranslate business requirements into BRDs, CDP customer analytics use cases, structure technical solution\nPrioritize CDP use cases together with the client.\nCreate a strategic CDP roadmap focused on data driven marketing activation.\nWork with the Solution Architect to strategize, architect, and document a scalable CDP implementation, tailored to the clients needs.\nProvide hands-on support and platform training for our clients.\nData processing, data engineer and data schema/models expertise for CDPs to work on data models, unification logic etc.\nWork with Business Analysts, Data Architects, Technical Architects, DBAs to achieve project objectives - delivery dates, quality objectives etc.\nBusiness intelligence expertise for insights, actionable recommendations.\nProject management expertise for sprint planning\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n8 to 10 Years\n\n\n\n\nEducational Qualification:\n\n\n\nB.Com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['digital marketing', 'display video', 'google ads', 'campaign management', 'facebook ads manager', 'trading', 'python', 'adobe analytics', 'adobe', 'microsoft azure', 'sql', 'gcp', 'web analytics', 'devops', 'segmentation', 'web analytics tools', 'shell scripting', 'network analysis', 'aws', 'seo']",2025-06-14 05:35:34
I&F Decision Sci Practitioner Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Delivery - Sprinklr\n\n\n\n\nDesignation: I&F Decision Sci Practitioner Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIA social media management tool for enterprises. It provides social media marketing, social advertising, content management, collaboration, advocacy and social media monitoring for large enterprises.\n\n\n\n\nWhat are we looking for\nSprinklr Social Media Monitoring & Analytics Adaptable and flexible Written and verbal communication Ability to work well in a team Agility for quick learning Commitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day-to-day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['digital marketing', 'service operations', 'content management', 'sprinklr', 'seo', 'python', 'adobe analytics', 'data analysis', 'google adwords', 'power bi', 'social listening', 'radian6', 'sql', 'twitter', 'tableau', 'web analytics', 'social media marketing', 'google analytics', 'brandwatch']",2025-06-14 05:35:37
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Business Reporting & Governance - Microsoft SQL Server\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Customer Support vertical and help us in managing/ resolving customers query, handling escalations and complaints of the dissatisfied customers & giving best resolutions. You will also be responsible for closing the fault and complaints within SLA s.Candidate who is good in excel and MIS reports are looked at for these skillsA relational database management system which runs as a server and provides multiuser access to a number of databases. Provide database functionality through this relational database management system from Microsoft.\n\n\n\n\nWhat are we looking for\nStrong system skills including advanced proficiency with Microsoft Excel (Power Query) as well as a working knowledge of SQL, Data Analytics, and Relational Databases. Strong written and verbal communication skills including process documentation and system flowcharts along with the ability to work well in cross-functional teams. Excellent critical thinking, analytical and problem-solving skills including the ability to think outside of the box, deal with ambiguity and challenge informationKnowledge of POS Systems (Bulloch),JDE, PDI, ServiceNow, and Market Basket is considered an asset / MS Excel (Macros/VBA)\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'business reporting', 'relational databases', 'sql server', 'sql', 'macros', 'python', 'data analysis', 'power bi', 'javascript', 'power query', 'reporting analysis', 'spring', 'tableau', 'java', 'vba', 'mis', 'html', 'mysql', 'data structures', 'data visualization', 'aws']",2025-06-14 05:35:39
Functional Business Analyst - Guidewire Configuration,Ekloud Inc,4 - 7 years,Not Disclosed,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","Job Overview :\nWe are seeking a Functional Business Analyst with solid experience in the insurance domain, specifically with Guidewire platforms. The ideal candidate will be responsible for gathering and documenting business requirements, collaborating with technical teams, and ensuring that business goals are met through effective technology solutions. This is a remote, client-facing role requiring strong communication and technical documentation skills.\nKey Responsibilities :\n- Gather, analyze, and document business and functional requirements for insurance software solutions.\n- Work closely with business stakeholders, developers, and QA teams to ensure accurate and complete understanding of requirements.\n- Serve as a bridge between business users and technical teams to drive successful implementations.\n- Participate in design discussions and help translate business requirements into solution designs.\n- Support system testing and user acceptance testing (UAT).\n- Manage project documentation, workflows, and change requests.\n- Recommend enhancements to improve system efficiency and user experience.\nRequired Skills & Qualifications :\nDomain Expertise :\n- Strong understanding of insurance business processes (Property & Casualty preferred)\n- Experience working with Guidewire InsuranceSuite ideally PolicyCenter, BillingCenter, or\nClaimCenter\nTechnical Skills :\n- Guidewire Configuration and Integration knowledge (familiarity with Guidewire Data Model is a plus)\n- Proficient with SQL for data analysis and validation\n- Experience with JIRA, Confluence, or other project management tools\n- Strong skills in MS Excel, Visio, and PowerPoint for reporting and documentation\n- Understanding of API workflows, XML, and JSON is a plus\n- Exposure to Agile/Scrum methodologies\nSoft Skills :\n- Excellent verbal and written communication skills\n- Strong analytical and problem-solving abilities\n- Ability to manage multiple priorities and deadlines\n- Effective collaboration in cross-functional and remote team environments\nLocation: Remote- Bengaluru,Hyderabad,Delhi / NCR,Chennai,Pune,Kolkata,Ahmedabad,Mumbai",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Functional Business Analysis', 'Guidewire PolicyCenter', 'Business Analyst', 'Project Management', 'Confluence', 'Project Methodologies', 'Guidewire Integration', 'Guidewire ClaimCenter', 'Guidewire Configuration', 'Jira', 'Guidewire']",2025-06-14 05:35:41
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\n..\n\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:35:44
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\n..\n\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:35:46
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:Chartered Accountant\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Implementation of gen. ledger processes including yearend closing, journalizing. Creating and maintaining ledgers, ledger currencies, budgets, and journal entries, design to deliver a financial management solution including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry and reporting as well as dynamic allocations and the management of commitments and expenditures also run Interface reports and perform close books of accounts.\n\n\n\n\nWhat are we looking for\nAbility to perform under pressureAbility to establish strong client relationshipStrong analytical skillsProblem-solving skillsFinancial Consolidation, Reporting and month end close activities\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nChartered Accountant",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'budgeting', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:35:49
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\nAbility to perform under pressureAbility to work well in a teamAbility to establish strong client relationshipNA\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:35:52
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Balance Sheet Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe are looking to hire an Accountant on the Payroll Accounting Team that will play a critical role in the month-end close process. You will get the opportunity to work on a multitude of projects and streamline processes and will become a subject matter expert in processing accruals across multiple financial statement line items. This person will act as a cross-functional business partner to implement automation and create improvements to optimize the month-end close. You will work in a dynamic environment and be able to recommend and implement process improvements, work independently and handle multiple tasks simultaneously.\n\n\n\n\nWhat are we looking for\nThe Candidate should be well verse with accounting background and ground experience.The resource should understand of the core activities that we perform- Payroll journals and BS recons or the tools we use extensively.We need somebody who can easily grasp the subject matter with minimum instructions.Adaptable and flexibleProblem-solving skillsAbility to establish strong client relationshipAgility for quick learningAbility to work well in a team\n\n\n\nRoles and Responsibilities: Prepare and review journal entries and account reconciliations for various GL accounts.Analyze monthly variances across GL accounts and investigate discrepancies.Collaborate with Global Business Service (third party service provider) team to automate and streamline processes and review work product.Partner closely with financials statement line-item owners and business partners from various departmentsLead process improvement and automation initiativesEnhance existing processes and internal controls, perform and maintain assigned internal controls.Support external audit activities and ongoing internal auditsExecute special projects and complete other ad hoc assignments as required\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounting', 'journal', 'record to report', 'recon', 'payroll', 'accounts receivable', 'balance sheet', 'accounts payable', 'service operations', 'data analysis', 'mis reporting', 'journal entries', 'pivot table', 'vlookup', 'reporting analysis', 'advanced excel', 'mis', 'external audit', 'finance']",2025-06-14 05:35:54
GN - SONG - Design and Digital Products - UI/UX - Analyst,Accenture,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Title:GN - SONG - Design and Digital Products - UI/UX - Analyst\n\n\n\nManagement Level:11 Analyst\n\n\n\nLocation:Bangalore, Gurgaon, Hyderabad\n\n\n\nMust have skills:UX/UI Design, Figma, Sketch\n\n\n\n\nGood to have skills:Video editing tools, Motion design\n\n\n\nExperience:Minimum 4 years of experience is required .\n\n\n\n\nRoles & Responsibilities:\nCollaborate with product managers and stakeholders to gather and refine user requirements.\nConduct user studies, benchmark best practices, and create personas through research and data analysis.\nCreate wireframes, user flows, flow diagrams, and storyboards to communicate interaction and design concepts effectively.\nDevelop high-fidelity mockups and interactive prototypes using design tools like Figma.\nDesign and conduct UX testing sessions to evaluate usability, accessibility, and desirability of prototypes.\nDesign UI elements such as navigation components, search boxes, page ribbons, tabs, widgets, CTAs, carousels, in-app banners, etc.\nWork closely with developers to ensure designs are implemented accurately and according to design specifications.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\nMust have skills:Proficiency in UX/UI Design, Figma, Sketch.\nStrong understanding of UX/UI design concepts and principles.\nExperience in developing and maintaining UX/UI designs.\nExperience in debugging and troubleshooting UX/UI designs.\nExperience in working with digital products and services.\n\n\n\n\nAdditional Information:\nThe ideal candidate will possess a strong educational background in design or a related field, along with a proven track record of delivering impactful UX/UI solutions.\nThis position is based at our Bangalore, Gurgaon, or Hyderabad office.\n\n\n\n\nAbout Accenture: Accenture is a leading global professional services company, providing a broad range of services and solutions in strategy, consulting, digital, technology and operations. Combining unmatched experience and specialized skills across more than 40 industries and all business functions underpinned by the worlds largest delivery network Accenture works at the intersection of business and technology to help clients improve their performance and create sustainable value for their stakeholders. With 624,000 people serving clients in more than 120 countries, Accenture drives innovation to improve the way the world works and lives. Visit us atAbout Our Company | Accenture\n\n\n\nAbout Accenture Strategy & Consulting:\n\nAccenture Strategy shapes our clients future, combining deep business insight with the understanding of how technology will impact industry and business models. Our focus on issues such as digital disruption, redefining competitiveness, operating and business models as well as the workforce of the future helps our clients find future value and growth in a digital world. Today, digital is changing the way organizations engage with their employees, business partners, customers, and communities. This is our unique differentiator. To bring this global perspective to our clients, Accenture Strategy's services include those provided by our Global Network a distributed management consulting organization that provides management consulting and strategy expertise across the client lifecycle. Our Global Network teams complement our in-country teams to deliver cutting-edge expertise and measurable value to clients all around the world.For more information visit https://www.accenture.com/us-en/Careers/capability-network\n\nAccenture Global Network | Accenture in One Word\n\ncome and be a part of our team.\n\nQualification\n\n\n\n\nEducational Qualification:Bachelor's degree or Master's in Design\n\n\n\nJob\n\n\nSummary:As a UX/UI Designer, you will be responsible for designing, building, and implementing user experiences that enhance business performance and drive customer satisfaction. Your typical day will involve collaborating with product managers and stakeholders, conducting UX research, creating wireframes and prototypes, and working closely with developers to ensure accurate implementation of designs",Industry Type: IT Services & Consulting,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent","['ux', 'user interface designing', 'sketching', 'figma', 'ui/ux', 'persona', 'motion designing', 'user flows', 'video editing', 'gui testing', 'photoshop', 'prototype', 'banners', 'ux research', 'visual design', 'ui', 'wireframe', 'graphic designing', 'mockups', 'debugging', 'troubleshooting', 'html', 'illustrator']",2025-06-14 05:35:56
Senior Executive,Flipkart,0 - 1 years,Not Disclosed,['Kolkata'],Skills Required :\nBSc agri holder with Good communication and basic excel skills,Industry Type: Courier / Logistics,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['excel', 'Agricultural Science', 'Data Analysis', 'Agricultural Data Management', 'Agricultural Research']",2025-06-14 05:35:58
Data Scientist,Paypal,2 - 5 years,Not Disclosed,['Bengaluru'],"The Company\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\nOur beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do - and they push us to ensure we take care of ourselves, each other, and our communities.\nJob Summary:\nMeet your team:\n\nThis role sits within Credit card fraud risk strategy team of Global Fraud Prevention Org., focused on safeguarding our customers and business from evolving fraud threats. The team is responsible for developing and executing data-driven strategies to mitigate fraud in UK PPC portfolio.\n\nWhat do you need to know about the role:\n\nGlobal Fraud Prevention resides in the Global Risk Management (GRM) organization that supports various business lines in optimizing risk and rewards to enable profitable business growth.\n\nYou will be working closely with global fraud risk professionals focusing on managing and mitigating fraud risk in the UK PayPal Credit Portfolio,\n\nBe a part of this fraud revolution and enjoy the journey being with PayPal s growing team. Why You ll Love It here:\n\nImpact: Your work directly influences the success and growth of PayPal s credit offerings.\nLearning: Expect to level up your analytical and problem-solving skills every day with more challenges to solve\nGrowth: The credit card industry is constantly evolving, and you ll be right there on the cutting edge, sharpening your skills and new learnings along the way.\nCulture: We re a team of passionate professionals who love challenges and are always ready to celebrate a job well done.\nJob Description:\nYour way to impact:\nOwn the areas of Transaction Fraud risk policy: Work on Broad area of projects from Card risk strategies, acquisition and payment risk strategies, all depending on the business need.\nWork closely with Stakeholders: this includes Credit Risk, Product, finance teams to optimize fraud strategies and portfolio performance.\nProactively identify emerging fraud trends and propose mitigation strategies .\nMaintain and develop Monitoring and Alerting capabilities: to clearly monitor the PPC Card program health and simplify insights for key stakeholders.\nPresent regular updates to senior leaders: on Portfolio Health, highlights, lowlights, and actionable insights.\nYour day to day:\nIn this role you will have full ownership of portfolio and is responsible for end-to-end management of Fraud loss and decline rates.\nWorks independently and proficiently. Accountable for own results.\nCollaborate with different teams to develop strategies for fraud prevention, loss savings, and optimize transaction declines .\nAnalyze and assess risks to provide informed recommendations for mitigation strategies\nPrepare periodic KPI reports summarizing the business units risk and control environment for senior management\nWhat do you need to bring:\n2-5 years of domain expertise\nExcellent Problem-Solving Skills : Strong judgment and the ability to think strategically, creatively, and practically to address complex challenges.\nAdvanced Analytics expertise : Proficiency in SQL, Python, Advanced Excel, Tableau, and other analytics tools, with a proven track record of using them to solve real-world problems.\nExceptional communication skills : Outstanding written, verbal communication abilities, capable of translating complex technical concepts into clear, actionable insights for diverse audiences\nCollaboration Influence : Strong ability to collaborate across teams, build relationships, and drive results through influence and teamwork\nExperience in Payments / Transaction risk management / Credit / Fraud Risk is a strong plus.\n** We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please dont hesitate to apply.\nPreferred Qualification:\nSubsidiary:\nPayPal\nTravel Percent:\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits:\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com .\nWho We Are:\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talentaccommodations@paypal.com .\nBelonging at PayPal:\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: FinTech / Payments,Department: Other,"Employment Type: Full Time, Permanent","['advanced analytics', 'PPC', 'Analytical', 'Diversity and Inclusion', 'Wellness', 'Advanced Excel', 'Risk management', 'Analytics', 'Monitoring', 'SQL']",2025-06-14 05:36:01
Fund and Information Management - Analyst,Goldman Sachs,2 - 4 years,Not Disclosed,['Bengaluru'],"Asset Wealth Management (AWM):\nAWM invests in corporate equity and debt, real estate equity and debt, and infrastructure-related assets and companies around the world. AWM operates on a global platform and our team works in a fast-paced, exciting environment. We look for individuals with versatile skills and a passion for investing.\nWithin AWM, the Funds Information Management Group supports the division in a variety of functions, including standard and custom client reporting, data analysis and process management/oversight. The Funds Information Management Group also partners with Engineering and Product Management to assist in building automation and reporting solutions.\nThe Analyst/Associate will perform a variety of recurring tasks, project-based work and ad hoc analyses. The successful applicant will have an ability to understand financial information, draw relationships and raise issues or concerns.\nSpecific Responsibilities May Include:\nTracking/reporting/analyzing investor/investment/portfolio metrics\nGathering data and assisting with internal/external information requests\nSupporting AWM s quarterly portfolio company monitoring process using iLevel software\nDesigning/enhancing processes and supporting/furthering technology initiatives related to the above responsibilities\nAdditional responsibilities will be based on the needs of the division and the candidate s specific skills\nQualifications:\nBachelor s Degree in Accounting, Finance or other business discipline\nMinimum 2-4 years related work experience (May 2020 - December 2022 graduation dates)\nStrong analytical skills and detail orientation\nStrong interpersonal and communication skills, oral as well as written\nStrong coordination and organizational skills\nAbility to multi-task and meet tight deadlines\nAbility to work independently in a small team, exhibit initiative and be proactive\nAbility to organize and analyze large volumes of information\nFacility with and interest in working on technology initiatives\nTeam player, willing to help in areas not explicitly related to job duties\nComfortable working in a fast-paced, high-energy environment\nStrong Excel, Word, PowerPoint skills\nAbout Goldman Sachs",Industry Type: Banking,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Automation', 'Wealth management', 'Wellness', 'HTML', 'Investment banking', 'Information management', 'Monitoring', 'Process management']",2025-06-14 05:36:03
"Senior Analyst, Product Analytics",Cvent,4 - 6 years,Not Disclosed,['Gurugram'],"Overview: Cvent is a leading meetings, events, and hospitality technology provider with more than 4,800 employees and ~22,000 customers worldwide, including 53% of the Fortune 500\nFounded in 1999, Cvent delivers a comprehensive event marketing and management platform for marketers and event professionals and offers software solutions to hotels, special event venues and destinations to help them grow their group/MICE and corporate travel business\nOur technology brings millions of people together at events around the world\nIn short, we re transforming the meetings and events industry through innovative technology that powers human connection",,,,"['Hospitality', 'customer segmentation', 'Data analysis', 'Google Analytics', 'Customer satisfaction', 'MICE', 'Event marketing', 'Software solutions', 'Product marketing', 'SQL']",2025-06-14 05:36:05
Senior Analyst - (SQL & Power BI),Home Credit,1 - 5 years,Not Disclosed,['Gurugram'],"Role & responsibilities\n\nAs part of the Home Credit analytics team, the successful candidate will be responsible for developing, analyzing and executing ideas and initiatives designed to achieve business reports..\nWould need to learn HCIN data base, absorb current reporting and should be able to create new reports as per business requirement.\n\nShould have strong base in SQL and Power BI reporting",,,,"['Power Bi', 'Tableau', 'SQL', 'Communication Skills', 'Data Analysis', 'Data Visualization', 'Advanced Excel', 'SQL Coding', 'Advance Sql', 'Dashboards', 'Data Analytics', 'Analytics']",2025-06-14 05:36:07
AVP - Finance Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Finance Analyst\n\nIn this role, you will:\nParticipate in functions related to financial research and reporting\nForecast analysis of key metrics, as well as other financial consulting related to business performance, operating and strategic reviews",,,,"['financial research', 'Data analysis', 'Project management', 'documentation', 'Gap analysis', 'financial consulting', 'SQL']",2025-06-14 05:36:09
Analyst-Qlik Sense Developer,AstraZeneca India Pvt. Ltd,5 - 6 years,Not Disclosed,['Bengaluru'],"Job Title: Analyst-Qlik Sense Developer\nGlobal Career Level: C3\nIntroduction to role:\nAre you ready to transform raw data into actionable insights? As a Qlik Sense Data Reporting and Analytics Developer, youll be at the forefront of driving informed decision-making and strategic initiatives across Alexion. Your expertise in designing, developing, and maintaining data reporting solutions will empower our organization to make data-driven decisions. If you have a strong background in data analysis, proficiency in visualization tools, and excellent communication skills, this is the role for you!\nAccountabilities:\nSupport the Alexion team with field force reporting by designing, developing, validating, and maintaining Qlik Sense dashboards and supporting model tiers for various business units and indications.\nUnderstand business objectives, data sources, and key performance indicators (KPIs) to design effective solutions.\nDesign and implement data models in QlikSense, including ETL processes.\nWrite and optimize Qlik scripting language using SQL to transform raw data into actionable insights by creating QVDs; transforming source data into dimensions/factors for dashboards.\nIntegrate data from multiple sources, ensuring accuracy, consistency, and optimal performance.\nDevelop interactive dashboards, reports, and visualizations using Qlik Sense.\nIdentify and address performance bottlenecks in Qlik applications; optimize data models, load scripts, and front-end visualizations for fast user experiences.\nConduct thorough testing of Qlik applications to validate data accuracy, functionality, and usability.\nCollaborate with QA testers and business users to resolve issues promptly.\nDesign intuitive user interfaces that facilitate data exploration, analysis, and insight generation.\nWork closely with cross-functional teams to align Qlik development efforts with organizational goals.\nCommunicate project status, challenges, and recommendations to stakeholders clearly.\nInstill a culture of continuous improvement, testing, and deployment of new capabilities for the business.\nEssential Skills/Experience:\nAdvanced understanding/experience with SQL, Snowflake, and Veeva CRM.\nAbility to create new rules and adjust existing rules.\nExpertise in Qlik scripting language + data modelling concepts, including related skills in:\n- Data warehouse\n- Data architecture\n- Data visualization (inclusive of Vizlib extensions)\n- Section access (security)\n- N-printing for sending reports.\nRecent project experience with Qlik + experience with other BI tools\nDesirable Skills/Experience:\nBackground in computer science, information systems, or related field.\n5-6 years of experience in developing reporting and visualization applications.\nExperience in web-development (JavaScript and CSS)\nExcellent analytical and problem-solving skills, with keen attention to detail.\nAbility to work independently and collaboratively in a dynamic environment.\nStrong communication and interpersonal skills.\nAt AstraZenecas Alexion division, youll find an environment where work isnt ordinary. Our closeness to patients brings us closer to our work and each other. With a rapidly expanding portfolio, youll enjoy the entrepreneurial spirit of a leading biotech combined with the security of a global pharma. Here, your career is not just a path but a journey to making a difference where it truly counts. Youll be empowered with tailored development programs designed for skill enhancement and fostering a deep understanding of our patients journeys. Join us to innovate and grow in a culture that celebrates diversity, innovation, and connection.\nReady to make an impact? Apply now and be part of our journey!\n11-Jun-2025\n14-Jun-2025\nAlexion is proud to be an Equal Employment Opportunity and Affirmative Action employer. We are committed to fostering a culture of belonging where every single person can belong because of their uniqueness. The Company will not make decisions about employment, training, compensation, promotion, and other terms and conditions of employment based on race, color, religion, creed or lack thereof, sex, sexual orientation, age, ancestry, national origin, ethnicity, citizenship status, marital status, pregnancy, (including childbirth, breastfeeding, or related medical conditions), parental status (including adoption or surrogacy), military status, protected veteran status, disability, medical condition, gender identity or expression, genetic information, mental illness or other characteristics protected by law. Alexion provides reasonable accommodations to meet the needs of candidates and employees. To begin an interactive dialogue with Alexion regarding an accommodation, please contact accommodations@Alexion.com . Alexion participates in E-Verify.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Printing', 'Data analysis', 'Front end', 'Pharma', 'Web development', 'Javascript', 'Analytics', 'SQL', 'CRM']",2025-06-14 05:36:12
Data Techology Senior Associate,MSCI Services,4 - 8 years,Not Disclosed,['Pune'],"As data engineers, we build scalable systems to process data in various formats and volumes, ranging from megabytes to terabytes. Our systems perform quality checks, match data across various sources, and release it in multiple formats. We leverage the latest technologies, sources, and tools to process the data. Some of the exciting technologies we work with include Snowflake, Databricks, and Apache Spark.\nYour skills and experience that will help you excel\nCore Java, Spring Boot, Apache Spark, Spring Batch, Python. Exposure to sql databases like Oracle, Mysql, Microsoft Sql is a must. Any experience / knowledge / certification on Cloud technology preferrably Microsoft Azure or Google cloud platform is good to have. Exposures to non sql databases like Neo4j or Document database is again good to have.\n  What we offer you\nTransparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall we'llbeing.\nFlexible working arrangements, advanced technology, and collaborative workspaces.\nA culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\nA global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\nGlobal Orientation program to kickstart your journey, followe'd by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\nMulti-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\nWe actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women s Leadership Forum.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['CVS', 'Core Java', 'Bloomberg', 'spring batch', 'MySQL', 'Oracle', 'Analytics', 'Downstream', 'Python', 'Recruitment']",2025-06-14 05:36:14
Data Scientist - Python / Machine Learning,Blueberry Unicorn Services,6 - 11 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Working Hours : 2PM to 11PM IST\n\nMid-Level ML Engineers / Data Scientist Role : (4-5 years of experience )\n\n- Experience processing, filtering, and presenting large quantities (100K to Millions of rows) of data using Pandas and PySpark\n\n- Experience with statistical analysis, data modeling, machine learning, optimizations, regression modeling and forecasting, time series analysis, data mining, and demand modeling.\n\n- Experience applying various machine learning techniques and understanding the key parameters that affect their performance.\n\n- Experience with Predictive analytics (e.g., forecasting, time-series, neural networks) and Prescriptive analytics (e.g., stochastic optimization, bandits, reinforcement learning).\n\n- Experience with Python and Python packages like NumPy, Pandas and deep learning frameworks like TensorFlow, Pytorch and Keras\n\n- Experience in Big Data ecosystem with frameworks like Spark, PySpark , Unstructured DBs like Elasticsearch and MongoDB\n\n- Proficiency with TABLEAU or other web-based interfaces to create graphic-rich customizable plots, charts data maps etc.\n\n- Able to write SQL scripts for analysis and reporting (Redshift, SQL, MySQL).\n\n- Previous experience in ML, data scientist or optimization engineer role with a large technology company.\n\n- Experience in an operational environment developing, fast-prototyping, piloting, and launching analytic products.\n\n- Ability to develop experimental and analytic plans for data modeling processes, use of strong baselines, ability to accurately determine cause and effect relations.\n\n- Experience in creating data driven visualizations to describe an end-to-end system.\n\n- Excellent written and verbal communication skills. The role requires effective communication with colleagues from computer science, operations research, and business backgrounds.\n\n- Bachelors or Masters in Artificial Intelligence, Computer Science, Statistics, Applied Math, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'Data Scientist', 'Artificial Intelligence', 'Data Management', 'Big Data', 'Data Modeling', 'Spark', 'Numpy', 'Python', 'Predictive Analytics']",2025-06-14 05:36:17
Hiring Senior Data Scientist/ Data Science Manager,Tredence,5 - 10 years,Not Disclosed,"['Kolkata', 'Pune', 'Bengaluru']","Job Description:\n\nGraduate degree in a quantitative field (CS, statistics, applied mathematics, machine learning, or related discipline)\n• Good programming skills in Python with strong working knowledge of Pythons numerical, data analysis, or AI frameworks such as NumPy, Pandas, Scikit-learn, etc.\n• Experience with LMs (Llama (1/2/3), T5, Falcon, Langchain or framework similar like Langchain)\n• Candidate must be aware of entire evolution history of NLP (Traditional Language Models to Modern Large Language Models), training data creation, training set-up and finetuning",,,,"['Data Science', 'Tensorflow', 'Pytorch', 'generative', 'python', 'Artificial Intelligence', 'Natural Language Processing', 'Machine Learning', 'Deep Learning']",2025-06-14 05:36:19
Senior - AWS Data Engineering,KPMG India,4 - 8 years,Not Disclosed,['Gurugram'],"KPMG India is looking for Senior - AWS Data Engineering to join our dynamic team and embark on a rewarding career journey Designs and builds scalable data pipelines using AWS servicesOptimizes data ingestion, storage, and processingCollaborates with data scientists and analystsEnsures performance, security, and compliance",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Networking', 'Focus', 'Manager Technology', 'professional services', 'AWS', 'international clients']",2025-06-14 05:36:21
Senior Data Engineer - Azure,Blend360 India,6 - 11 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Senior Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Access control', 'Data analysis', 'Team leading', 'Architecture', 'Analytical', 'Agile', 'data governance', 'Data processing', 'Mentor', 'Data quality']",2025-06-14 05:36:23
Transitions Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Talent Acquisition -Enabling Functions - Data Analysis Reporting\n\n\n\n\nDesignation: Transitions Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nRole Overview:This role is part of the Recruitment Process Transformation Team for all of India. You will be responsible for supporting the WD stabilization and driving improvements in recruitment operations through effective project management, stakeholder engagement, and process optimization.Key Responsibilities:1.Agile Goal Setting:Create and manage short-term goals aligned with long-term objectives, ensuring an agile mindset for the team.2.Program Stewardship & Organization:Organize programs and activities aligned with business goals, supporting recruitment initiatives in India to enhance ways of working.3.Stakeholder Management:Handle complex stakeholder relationships, set expectations, and manage diverse asks from teams (including leadership). Work with extended stakeholders such as Legal, ER & Policies, Marcom, Audit, Compliance, Payroll, etc.4.Communication & Collaboration:Facilitate transparent communication with stakeholders through meetings, addressing project issues, and setting the program s operating structure for seamless collaboration and alignment across teams.5.Documentation & Updates:Regularly document meeting discussions, assign action owners, and track next steps to ensure stakeholders stay informed on project progress.6.Process Design:Design clear and effective process flows (as-is and to-be) to communicate ideas and decisions to stakeholders.7.Governance & Prioritization:Establish and manage governance models, define principles, and prioritize tasks to ensure smooth project execution.8.Change Management:Implement and manage changes to ensure projects meet their goals, managing interventions as necessary.9.Status Reporting:Ensure timely and accurate reporting on program status throughout the lifecycle, including ownership of executive conversations, decision boards, and steering committees.10.Risk Management:Proactively analyze risks and issues, facilitate change control discussions, and lead decision review boards.11.Milestone Tracking & Planning:Work closely with the business to define key priorities, milestones, and plans for delivery, change, and stabilization.12.Expectation Management:Track milestones, deliverables, and ensure consistent management of expectations with stakeholders.Preferred Skill - Automation & Data Analytics, Recruitment & WD Related knowledge, Process Design, Drawing As-Is & To-Be, Power BI knowledge, Storyboarding, Stakeholder management skills, MS Power Apps, Leveraging AI for regular work\n\n\n\n\nWhat are we looking for\nData AnalyticsData AutomationAdaptable and flexibleAgility for quick learningAbility to establish strong client relationshipWritten and verbal communication\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['data analysis', 'data analytics', 'power bi', 'talent acquisition', 'recruitment', 'c#', 'project management', 'css', 'process design', 'auditing', 'sharepoint', 'javascript', 'jquery', 'ms power apps', 'infopath', 'stakeholder management', 'asp.net', 'drawing', 'html', 'agile', 'angularjs']",2025-06-14 05:36:26
Risk and Compliance Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Risk & Compliance - Operational Audit & Compliance\n\n\n\n\nDesignation: Risk and Compliance Analyst\n\n\n\n\nQualifications:Chartered Accountant/Master of Business Administration/CA Inter\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Risk and Compliance vertical and help us perform compliance reviews, publish reports with actions and provide closure guidance as needed. We design & recommend effective controls to mitigate risks and help service delivery team prepare for upcoming client / external audits.You will be working as a part of the Risk & compliance team which is responsible for helping clients and organizations identify risks and create mitigation plans.Audit and manage effective implementation and delivery of functional processes within operations to mitigate risk. e.g. Policies; Anticorruption, BCM, InfoSec, P104, Records Management and Contractor controls. Establish processes to audit/validate current control effectiveness and drive improvements wherever required.\n\n\n\n\nWhat are we looking for\nAudit and manage effective implementation and delivery of functional processes within operations to mitigate risk. e.g. Policies; Anticorruption, BCM, InfoSec, P104, Records Management and Contractor controls. Establish processes to audit/validate current control effectiveness and drive improvements wherever required. Audit and manage effective implementation and delivery of functional processes within operations to mitigate risk. e.g. Policies; Anticorruption, BCM, InfoSec, P104, Records Management and Contractor controls. Establish processes to audit/validate current control effectiveness and drive improvements wherever required.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nChartered Accountant,Master of Business Administration,CA Inter",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['risk compliance', 'aml', 'auditing', 'compliance analysis', 'kyc', 'financial analysis', 'risk management', 'risk assessment', 'due diligence', 'data analysis', 'anti money laundering', 'sox compliance', 'internal control', 'internal audit', 'advanced excel', 'due diligence review']",2025-06-14 05:36:28
"Senior Workday Analyst, HR",Epiq Systems,8 - 9 years,Not Disclosed,['Hyderabad'],"Its fun to work at a company where people truly believe in what they are doing!\nJob Description:\nJob Summary:\nThe Senior HR Technology Analyst is responsible for developing, implementing and maintaining appropriate changes, configuration and processes within Workday, primarily focused on core Human Capital Management (HCM), Staffing, Help, or Reporting . This role will support leveraging technology solutions to meet the needs of human resources and users of Workday. This position will provide ongoing technical expertise and consultation on new functionality, system upgrades, configuration and testing efforts. This role will ensure a high level of data and process integrity in the day to day use of Workday, facilitate end user training, and provide effective and efficient customer service to internal Workday users globally. The Senior HR Technology Analyst will partner with IT, Finance, and external vendors to solve technical problems and manage and prioritize ongoing task list as well as work on continual process improvement with the HR Technology Manager.\nEssential Job Responsibilities\nServe as subject matter expert and act as a key resource of HR Systems projects including Workday system upgrade processes, deployment of new functionality, partnering with HR functional areas on system related process work, and major system implementation or integration project work.\nResponsible for system configuration and build work. Consult with functional users to identify best practice and strategy in configuration.\nWorkday Systems Support Administration - Handle day to day issue resolution; ensure delivery of high quality customer service to end users; work with HR Technology Manager to resolve high level production issues.\nDrive data integrity within Workday and between systems; develop audit, research and resolution processes. Ensures data follows compliance needs and governs data mapping.\nWork with HR Technology Manager to research and resource opportunities to extend and optimize Workday usage.\nIdentify efficiencies through automation in the areas of business processes, integrations, and data loads.\nProvide new user training to Workday and administrative processing for particular HR users.\nPartner with other team members to review training and change management needs with all projects. Facilitate system training and communication as needed.\nMaintain Workday standard integrations and provide basic integration troubleshooting.\nIdentify trends or root cause behaviors for frequently occurring audit issues or integrations errors.\nQualifications Requirements\nBachelor s degree in Human Resources, Business Management or related degree\n5+ years of experience in HRIS, 3+ years using Workday preferably with reporting experience.\nAbility to quickly learn concepts and understand process configuration in a system\nKnowledge of project management methodologies\nExperience managing multiple projects and priorities simultaneously\nGood teamwork interaction and leadership skills\nHighly self-motived, organized and methodical\nMust be experienced user of MS Office (Word, Excel, Outlook, Access, PowerPoint); In Excel, must have ability to create pivot tables, vlookups)\nProactive in achieving results and seeking improvements\nResults oriented with the ability to manage competing priorities and multiple stakeholders\nSolid understanding of overall HR functional areas and HR business processes, as well as interdependencies with Payroll, IT and Finance\nStrong analytical, problem solving and troubleshooting abilities; with strong data analysis acumen and focus on accuracy and attention to detail\nStrong verbal, written, and presentation skills. Ability to communicate effectively with all levels of the organizations\nIf you like wild growth and working with happy, enthusiastic over-achievers, youll enjoy your career with us!\nIt is Epiq s policy to comply with all applicable equal employment opportunity laws by making all employment decisions without unlawful regard or consideration of any individual s race, religion, ethnicity, color, sex, sexual orientation, gender identity or expressions, transgender status, sexual and other reproductive health decisions, marital status, age, national origin, genetic information, ancestry, citizenship, physical or mental disability, veteran or family status or any other basis protected by applicable national, federal, state, provincial or local law. Epiq s policy prohibits unlawful discrimination based on any of these impermissible bases, as well as any bases or grounds protected by applicable law in each jurisdiction. In addition Epiq will take affirmative action for minorities, women, covered veterans and individuals with disabilities. If you need assistance or an accommodation during the application process because of a disability, it is available upon request. Epiq is pleased to provide such assistance and no applicant will be penalized as a result of such a request. Pursuant to relevant law, where applicable, Epiq will consider for employment qualified applicants with arrest and conviction records.",Industry Type: Legal,Department: Human Resources,"Employment Type: Full Time, Permanent","['Data analysis', 'Payroll', 'Change management', 'Staffing', 'Project management', 'Process improvement', 'Analytical', 'Customer service', 'Troubleshooting', 'Auditing']",2025-06-14 05:36:30
Senior Data Engineer - Azure,Blend360 India,6 - 11 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Senior Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n5+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fie",Industry Type: Advertising & Marketing,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-14 05:36:33
"Senior Workday Analyst, HR",Epiq Softech,5 - 10 years,Not Disclosed,['Hyderabad'],"Its fun to work at a company where people truly believe in what they are doing!\nJob Description:\nJob Summary:\nThe Senior HR Technology Analyst is responsible for developing, implementing and maintaining appropriate changes, configuration and processes within Workday, primarily focused on core Human Capital Management (HCM), Staffing, Help, or Reporting . This role will support leveraging technology solutions to meet the needs of human resources and users of Workday. This position will provide ongoing technical expertise and consultation on new functionality, system upgrades, configuration and testing efforts. This role will ensure a high level of data and process integrity in the day to day use of Workday, facilitate end user training, and provide effective and efficient customer service to internal Workday users globally. The Senior HR Technology Analyst will partner with IT, Finance, and external vendors to solve technical problems and manage and prioritize ongoing task list as well as work on continual process improvement with the HR Technology Manager.",,,,"['Data analysis', 'Payroll', 'Change management', 'Staffing', 'Project management', 'Process improvement', 'Analytical', 'Customer service', 'Troubleshooting', 'Auditing']",2025-06-14 05:36:35
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Business Reporting and Governance vertical helps to deploy and deliver robust tracking mechanism for SLA/KPI or any other operations on a day-to-day basis. The Governance team will be responsible for contractual compliance of various aspects of contract like Governance, Reporting, Incident Management, Change Management and Survey Management along with driving automation and analytics. Assessing, managing, using, improving, monitoring, maintaining, and protecting organizational information through a system of decision rights and accountabilities for information related processes, executed according to agreed-upon models which describe who can take what actions, with what information, when, under what circumstances and using what methods. Candidate who is good in excel and MIS reports are looked at for these skillsIn Reporting and Analytics, you will have to prepare management reports and analysis, both recurring and ad-hoc. This includes focusing on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nEffective communication and organization skills with Polished, professional presence Experience in working on automation projects Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Proficient in MS Office with advance knowledge in excel formulas. Ability to simplify and automate manual intensive processes using basic VBA, MS Access Expertise in creating reports, and exposure to using PowerBI\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ms access', 'business reporting', 'vlookup', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'power bi', 'business analysis', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'reporting and analytics', 'tableau', 'advanced excel', 'data visualization']",2025-06-14 05:36:37
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Bengaluru'],"Skill required: Record To Report - Financial Consolidation & Close Operations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom/MCom/Master of Business Administration\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English(Domestic) - Expert\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.The Financial Consolidation & Close Operations team is responsible for general ledger processes including year-end closing, journalizing, etc. They help create & maintain ledgers, currencies, budgets, & journal entries, deliver solutions including a flexible accounting structure, comprehensive journal processing, hierarchical summaries, intuitive inquiry & reporting, dynamic allocations & the management of commitments & expenditures, run interface reports & perform close books of accounts. The team reviews P&L accounts errors, omissions, or inconsistencies and managing the preparation of all reports. They also work on posting journal entries, preparing balance sheet reconciliations, investigating and reporting open items, reviewing entries and reconciliations, supporting month-end closing, preparing various reports as required, and supporting audits. The team also oversees improvement projects, including automation, simplifications, and enhanced controls.\n\n\n\n\nWhat are we looking for\nAbility to establish strong client relationship\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,MCom,Master of Business Administration",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['balance sheet', 'journal entries', 'accounting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'forecasting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'budgeting', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:36:39
Senior PySpark Data Engineer,Synechron,7 - 12 years,Not Disclosed,"['Pune', 'Hinjewadi']","Job Summary\nSynechron is seeking an experienced and technically proficient Senior PySpark Data Engineer to join our data engineering team. In this role, you will be responsible for developing, optimizing, and maintaining large-scale data processing solutions using PySpark. Your expertise will support our organizations efforts to leverage big data for actionable insights, enabling data-driven decision-making and strategic initiatives.\nSoftware Requirements\nRequired Skills:",,,,"['PySpark', 'S3', 'Unix operating systems', 'Spark SQL', 'Luigi', 'HDFS', 'AWS EMR', 'Apache Airflow', 'Hive', 'Linux', 'Azure HDInsight', 'Apache Kafka', 'AWS']",2025-06-14 05:36:42
Junior Business Analyst,Innovature Software Labs,1 - 2 years,Not Disclosed,"['Kochi', 'Chennai']",">\nJob Category: Software\nJob Type: Full Time\nJob Location: Infopark - Kochi\nExperience: 1 - 2 Years\nDesignation: Junior Business Analyst\nKey Responsibilities\nCollaborate with stakeholders to gather, document, and analyze business requirements.\nConduct market research, competitive analysis, and feasibility studies for new projects.\nWork closely with development teams to translate business requirements into technical specifications.\nCreate business process models, workflows, and use case diagrams to illustrate system functionalities.\nDefine and maintain project documentation, including BRDs (Business Requirements Documents) and FRDs (Functional Requirements Documents).\nFacilitate meetings, presentations, and workshops with stakeholders, product managers, and developers.\nEnsure alignment between business objectives and technology solutions.\nAssist in UAT (User Acceptance Testing) and validate that the final product meets business needs.\nProvide ongoing support, training, and guidance to stakeholders on system enhancements.\nSkill set\nExperience as a Business Analyst in IT or related industries.\nGood understanding of the full software development lifecycle.\nStrong communication, stakeholder management, and presentation skills.\nProficiency in requirements gathering, process mapping, and data analysis.\nStrong understanding of Agile, Scrum, and Waterfall methodologies.\nAbility to analyze complex data sets and translate findings into actionable insights.\nUnderstanding of UI/UX principles and experience working with designers.\nExperience with tools like JIRA, Confluence, Backlog, and SQL.\nKnowledge of database queries, reporting tools, and BI (Business Intelligence) platforms is an advantage.\nExperience\n1-2 years of experience",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Business Analyst', 'Competitive analysis', 'Software development life cycle', 'Market research', 'Business intelligence', 'Stakeholder management', 'User acceptance testing', 'SQL']",2025-06-14 05:36:44
Data Product Owner,JPMorgan Chase Bank,5 - 12 years,Not Disclosed,['Bengaluru'],"Are you looking for an exciting opportunity to join a dynamic and growing team in a fast paced and challenging areaThis is a unique opportunity for you to work in the Product Owner team to partner with the Business.\n\nThe Data Product Owner for Data Modernization is responsible for executing critical data management activities that support strategic business and product objectives, process design, advanced analytics, and reporting, with a focus on the Work Capabilities Data Domain. This role involves collaborating with multiple stakeholders to ensure data is well-understood, documented, and effectively utilized across the organization. As a Data Owner in the work capabilities team, you will support the strategic direction led by the Work Capabilities Data Domain Owner to manage data quality, governance, and risk, while fostering strong relationships with data delivery partners and consumers.\n\nJob Responsibilities\n\n\n\nImplement strategic plans to deliver data solutions that effectively support business operations and strategic objectives, ensuring alignment with organization.\n\nManage discovery efforts and market research to uncover customer solutions and integrate them into the product roadmap.\n\nOwn, maintain, and develop a product backlog that enables development to support the overall strategic roadmap and value proposition.\n\nDefine, describe, and register data products and offerings, leveraging strategic data dictionary tools.\n\nWork closely with Product Owner and other product leadership to understand overall product priorities and champion data needs.\n\nEnsure data is described, available, and accessible to consumers where needed.\n\nPartner regularly with the Data Domain Owner to stay aligned with evolving strategies for the Data Domain.\n\nCommunicate regular updates and provide feedback on the effectiveness of data strategies and execution effectiveness.\n\nLead both deep delivery and level up to ascertain, formulate, and communicate a clear strategic plan and approach.\n\nAssess independently and proactively through data to ensure requirements are clear and forward-thinking as we modernize the platform.\n\nNavigate seamlessly through a complex web of products, teams, and infrastructure that has legacy burdens.\n\n\nRequired Qualifications, Capabilities, and Skills\n\n\n\n5 years of experience in product management or a related role.\n\nIn-depth understanding of data management principles, governance frameworks, and lifecycle management, including data protection, data quality and data classification and Experience managing delivery across multiple workstreams with varying timelines, priorities, and complexities. Experience with Agile methodologies and tools (e. g. , Scrum, JIRA).\n\nTechnical understanding of data management and governance, cloud-based data platforms, or data architecture required.\n\nInfluence a culture of data ownership and accountability across client domain functions, inclusive of sales, marketing, and client service.\n\nReview and monitor monthly data risk metrics and drive remediation efforts to address any metric breaches. and Familiarity with data modeling, BDM, and the ability to model decision models in Signavio.\n\nHands-on in large data analysis using Excel, Alteryx, etc. to provide actionable insights and Proficient in MS Office suite of applications and Project Management, Governance and collaboration tools including JIRA, SharePoint, Confluence etc.\n\nExperience with rules execution engines such as Drools and Ability to run ad-hoc reporting and write SQL queries.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Process design', 'Product management', 'Data analysis', 'Data management', 'Data modeling', 'Project management', 'Agile', 'Market research', 'Data quality', 'Business operations']",2025-06-14 05:36:46
IN_Associate-Data Transformation -TMT -Advisory-Bangalore,PwC Service Delivery Center,2 - 6 years,Not Disclosed,['Bengaluru'],"Management Level\nAssociate\n& Summary\nAt PwC, our people in strategy consulting focus on providing strategic guidance and insights to organisations. They analyse market trends, assess business performance, and develop recommendations to help clients achieve their goals. These individuals work closely with clients to identify opportunities for growth, optimise operations, and enhance overall business performance.\n\nAs a corporate and business strategy consultant at PwC, you will analyse client needs, provide consulting services across different strategic areas, and offer guidance and support to help clients develop and implement effective strategies that align with their business objectives and drive growth.\n& Summary\nPwC actively works as a management advisor to leading telecommunications and IT market players across the value chain, including fixed, cable and convergent service providers,mobile operators, tower operators telecom regulators, industry bodies etc. Our Management Consulting TMT practice in India focuses on bringing together our Indian and global network resources around our clients needs, creating teams to help respond to challenges around almost every dimension of their business. Our clients are majorly spread across India, Africa, Middle East and South East Asia.\nRoles & Responsibilities\nAs a Management Consulting professional specializing in the TMT domain, the candidate will play a vital role in advising our clients on leveraging the potential of their networks and to drive innovation, gain a competitive edge, and capture new market opportunities. He/she will work closely with senior executives and stakeholders, providing strategic counsel and datadriven insights to shape their network strategies. Typical roles and responsibilities for the role are as below Understanding of the leading data analytics systems such as tableau, power BI, Alteryx, python, Qlik etc. with proven track record of delivering analytics solutions such as data strategy, data modelling, monetization and architecture to clients in the telecommunications and technology sector across India and global markets. Understand and define the business problems and cocreate the proposed solution leveraging latest trends within AL and ML . Leverage essential knowledge of the leading practices in the industry to develop project scope and approach to solve client problems When tailoring the key responsibilities for a Data Models Expert in the context of supply chain and asset lifecycle management transformation in ERP environments, particularly with telecommunicationsspecific experience, its important to focus on both general data modeling skills and telecom industry nuances. Below are example key responsibilities that you might include in a job description Data Models Design Develop and maintain comprehensive data models tailored to support supply chain and asset lifecycle management processes within ERP systems, focusing on telecommunications industry requirements. Entity Relationship Diagrams (ERD) Create detailed ERDs that accurately represent the relationships between data entities, ensuring alignment with business processes and compliance with industry standards. Logical Data Models Design logical data models that define the structure and organization of data within ERP systems, optimizing for efficiency and scalability in telecom operations. TelecommunicationsSpecific Integration Ensure data models effectively integrate with telecommunicationsspecific ERP modules, such as network inventory management and customer relationship management. CrossFunctional Collaboration Work closely with supply chain, asset management, and IT teams to gather requirements and translate them into effective data model designs that address both business and technical needs. Data Governance Establish and enforce data governance policies to ensure data quality, consistency, and security across supply chain and asset lifecycle management processes. Process Optimization Analyze existing supply chain and asset management workflows to identify opportunities for improvement, leveraging data models to streamline operations and enhance decisionmaking. Stakeholder Engagement Engage with business stakeholders to understand their needs and provide insights on how data modeling can support organizational objectives and strategic initiatives.\nDocumentation Maintain comprehensive documentation of data models, ERDs, and related processes to facilitate ongoing maintenance and support. Industry Best Practices Stay updated on telecommunications industry trends and best practices in data modeling and ERP integration, applying this knowledge to enhance data models and processes. Training and Support Provide training and support to endusers and technical teams on new data models and ERP functionalities, ensuring effective adoption and utilization . These responsibilities emphasize the importance of industryspecific expertise , collaboration, and continuous improvement in the context of ERP systems for telecommunications. Adjust the wording and details to suit the specific organizational needs and job level (e.g., junior, senior) as necessary. Perform quantitative and qualitative analysis including data mining, analysis, visualization, perform market and secondary research to collect business intelligence and insights Develop use cases for enterprise businesses using large data sets and understanding of GenAI and automation use cases Work collaboratively with the team in developing project deliverables meeting PwCs client service and quality standards Stay abreast of industry developments, regulatory changes, and competitive dynamics impacting telecommunication networks, and incorporate this knowledge into client engagements. Contribute to business development opportunities by proactively Willing to travel internationally and work on site 5070% of the time at client locations.\nMandatory skill sets\nDeep knowledge of the leading data analytics systems along with AL and ML Expertise in data strategy , modelling, mining and other analytics solutions Familiarity with telecommunication industry trends preferred Excellent problemsolving abilities, with a strategic mindset and the capacity to think critically and creatively. Excellent communication and presentation skills, with the ability to articulate technical concepts to nontechnical audiences. Ability to thrive in a fastpaced, dynamic environment, managing multiple projects with competing priorities effectively. A passion for continuous learning, innovation, and staying ahead of TMT industry trends.\nPreferred skill sets\nProven experience in management consulting, with a focus on telecommunication networks and technology.\nAdvance working knowledge of with MSOffice tools (Visio, Excel, Power Point, and other tools).\nAdvance working knowledge with tools such as MySQL, Alteryx, python, Power BI, tableau etc.\nBachelors degree in Telecommunications, Electrical Engineering, Computer Science, Statistics or a related field.\nAdvanced degree (e.g., MBA) preferred.\nYears of experience required\n1 + years of relevant experience in data and analytics domain\nEducation qualification\nBachelors degree in Telecommunications, Electrical Engineering, Computer Science, Statistics or a related field.\nAdvanced degree (e.g., MBA) preferred.\nEducation\nDegrees/Field of Study required Master of Business Administration\nDegrees/Field of Study preferred\nRequired Skills\nData Transformation\nAccepting Feedback, Accepting Feedback, Active Listening, Business Analysis, Business Opportunities, Business Process Consulting, Business Process Improvement, Business Strategy, Business Transformation, Communication, Competitive Advantage, Competitive Analysis, Conducting Research, Consumer Behavior, Customer Experience (CX) Strategy, Customer Insight, Customer Strategy, Data Analytics, Emotional Regulation, Empathy, GotoMarket Strategies, Inclusion, Industry Trend Analysis, Intellectual Curiosity, Market Research {+ 9 more}\nTravel Requirements\nGovernment Clearance Required?",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Telecom', 'Business transformation', 'Business analysis', 'Management consulting', 'Market research', 'Business strategy', 'Business intelligence', 'Data mining', 'Secondary research']",2025-06-14 05:36:49
Mis Executive,Connected Value Health Solutions,1 - 3 years,Not Disclosed,['Coimbatore'],"Job Title: MIS Executive\n\nJob Location: Coimbatore\n\nJob Summary:\n\nThe MIS Executive will be responsible for the efficient handling, analysis, and presentation of data using advanced Excel and PowerPoint skills. The role requires a detail-oriented individual capable of generating insightful reports, dashboards, and presentations that support decision-making processes within the organization.\n\nResponsibilities:\n\nData Management:\nCollect, organize, and maintain large datasets from various sources.\nClean and validate data to ensure accuracy, consistency, and completeness.\nCreate and manage databases or spreadsheets for storing data securely.\n\nReporting & Analysis:\nDevelop and maintain daily, weekly, and monthly reports that provide actionable insights.\nAnalyse data trends and create statistical models to support business decisions.\nAutomate repetitive reporting tasks using Excel functions, macros, and VBA (Visual Basic for Applications).\n\nDashboard Creation:\nDesign and develop interactive dashboards in Excel to visualise key performance indicators (KPIs).\nImplement formulas, pivot tables, and conditional formatting to enhance data readability.\n\nPresentation Development:\nCreate professional and visually appealing PowerPoint presentations that summarize key findings.\nCollaborate with various departments to gather information and data for presentations.\nEnsure presentations align with the organizations branding and communication guidelines.\n\nProcess Improvement:\nIdentify opportunities to streamline data collection and reporting processes.\nImplement best practices for data management and reporting to improve efficiency and accuracy.\n\nSupport & Training:\nProvide support and training to team members on Excel and PowerPoint usage.\nTroubleshoot issues related to data, reports, and presentations.\n\nQualifications:\nBachelor’s degree in computer science, Information Technology, Business Administration, or a related field.\n\nExperience:\n2-4 years of experience in a similar role, with a strong emphasis on data analysis, Excel, and PowerPoint.\nExperience with VBA (Visual Basic for Applications) is a plus.\n\nPreferred Qualifications:\nAdvanced proficiency in Microsoft Excel (formulas, pivot tables, macros).\nProficient in Microsoft PowerPoint, with a focus on creating executive-level presentations.\nStrong analytical and problem-solving skills.\nAttention to detail and a high level of accuracy.\nExcellent communication and interpersonal skills.\nAbility to work independently and as part of a team.\n\nWorking Conditions:\nNight Shift or afternoon shifts (as per business requirements).\nAbility to commute/relocate to Coimbatore.\nThis position involves working from the office only. It may require occasional extension of work or weekend work to accommodate the client requests.",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Management Information System', 'Pivot Table', 'Visual Basic Application', 'Excel Dashboards', 'VLOOKUP', 'Data Analysis', 'Data Analytics', 'HLOOKUP', 'Information System']",2025-06-14 05:36:51
Data Scientist-Advanced Analytics,IBM,3 - 7 years,Not Disclosed,['Kochi'],"We are seeking a highly skilled Advanced Analytics Specialist to join our dynamic team. The successful candidate will be responsible for leveraging advanced analytics techniques to derive actionable insights, inform business decisions, and drive strategic initiatives. This role requires a deep understanding of data analysis, statistical modeling, machine learning, and data visualization.\nIn this role, you will be responsible for architecting and delivering AI solutions using cutting-edge technologies, with a strong focus on foundation models and large language models. You will work closely with customers, product managers, and development teams to understand business requirements and design custom AI solutions that address complex challenges. Experience with tools like Github Copilot, Amazon Code Whisperer etc. is desirable.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\nPreferred technical and professional experience",,,,"['data analysis', 'machine learning', 'statistical modeling', 'data visualization', 'machine learning algorithms', 'advanced analytics', 'python', 'github', 'natural language processing', 'power bi', 'microsoft azure', 'sql', 'r', 'tableau', 'java', 'data science', 'spark', 'hadoop', 'aws']",2025-06-14 05:36:53
Director - Data Governance & Management,AMERICAN EXPRESS,5 - 10 years,Not Disclosed,['Bengaluru'],"At American Express, our culture is built on a 175-year history of innovation, shared values and Leadership Behaviors, and an unwavering commitment to back our customers, communities, and colleagues. As part of Team Amex, youll experience this powerful backing with comprehensive support for your holistic well-being and many opportunities to learn new skills, develop as a leader, and grow your career.\nHere, your voice and ideas matter, your work makes an impact, and together, you will help us define the future of American Express.\nHow will you make an impact in this role?",,,,"['remediation', 'Career development', 'Cisa', 'Finance', 'data governance', 'Workflow', 'Wellness', 'Data quality', 'Information management', 'Continuous improvement']",2025-06-14 05:36:56
Senior Data Scientist,Hindustan Unilever (HUL),2 - 5 years,Not Disclosed,['Bengaluru'],"Job Title: Senior Data Scientist\nLocation: Bangalore\nJob Title: Assistant Manager - Security Engineering\nLocation: UniOps Bangalore\nABOUT UNILEVER:\nEvery individual here can bring their purpose to life through their work. Join us and you ll be surrounded by inspiring leaders and supportive peers. Among them, you ll channel your purpose, bring fresh ideas to the table, and simply be you. As you work to make a real impact on the business and the world, we ll work to help you become a better you.\nABOUT UNIOPS:\nUnilever Operations (UniOps) is the global technology and operations engine of Unilever offering business services, technology, and enterprise solutions. UniOps serves over 190 locations and through a network of specialized service lines and partners delivers insights and innovations, user experiences and end-to-end seamless delivery making Unilever Purpose Led and Future Fit\nBackground\nFor Unilever to remain competitive in the future, the business needs to continue on the path to become data intelligent. The Data Analytics team will persevere to make Unilever Data Intelligent, powering key decisions with data, insights, advanced analytics and AI. Our ambition is to enable democratization of data, information and insights as a completely agile organization that builds fantastic careers for our people and is accountable for delivering great work that maximizes impact and delivers growth.\nThis Data Analytics function endeavours to create clear accountability for all aspects of Data Strategy, Data Management, Information Management, Analytics, and Insights. We are accountable for impact of solutions, maintaining market relevance and minimising unnecessary overlaps in analytics products, ensuring simplicity and that our solutions better meet the needs of our users. We partner with the Digital and Data Legal Counsel to ensure that our Data Defence (Privacy, Governance, Quality, etc) is well structured and sufficiently robust to use data and AI correctly throughout the enterprise. We democratize information across the business, while supporting the culture shift required for data driven decision making.\nOur vision is to make Unilever data intelligent, partnering with the business to power key decisions with data, advanced analytics and AI to accelerate growth. Our 5 strategies to achieve this are:\nAccelerate simplify access to relevant data, information and insights Build in-house, leading-edge data, information, insights analytics capability Lead the data insights culture and careers to empower employees across Unilever Rapidly embed analytics products, solutions and services to drive growth Advance Information Automation at Scale\nThe Senior Data Scientist is an exciting role in the Data Foundation. This team builds state of the art machine learning algorithms, maximising the impact of analytic solutions in driving enterprise performance. Typical initiatives include optimizing trade promotion investments, accurately forecasting customer demand, using NLP to glean insight on consumer trends from search data, and making individual assortment recommendations for each of the millions of stores that sell Unilever products.\nMain Purpose of the Job:\nThe Senior Data Scientist improves business performance in the functional area of Unilever they serve, through the application of world class data science capability. They own delivery of data science on moderate projects or specific modules of a major global initiative.\nKey accountabilities:\nInteract with relevant teams to identify business challenges where data science can help\nApply comprehensive data science knowledge to propose optimal techniques for key business challenges\nCreate detailed data science proposals and project plans, flagging any limitations of proposed solution\nDesign and prototype experimental solutions, particularly machine learning models\nDesign scaled solutions and ensure high quality and timely delivery\nFacilitate industrialization and ongoing operation of solutions through well organised code, clear documentation and collaboration with ML Ops resources\nGovern the work of 3rd party vendors where needed to support delivery, while maximising creation of Unilever IP\nRepresent Data Science in cross-functional governance of projects, engaging with stakeholders up to Director level\nHighlight recent developments in data science capability which could solve additional challenges\nLead a team of up 1-2 data scientists / interns, providing career mentorship and line management\nProvide technical guidance to data scientists across DA, particularly on the projects you lead\nSupport the growth of DA s data science capability by contributing to activities such as tool and vendor selection, best practice definition, recruitment, and creation of training materials\nBuild the reputation of DA s data science capability within Unilever and externally, through activities such as community engagement (e. g. Yammer), publications or blogs\nProvide ad-hoc immediate support to the business when needed (for example Covid-19 crisis support)\nDepending on the specific project, the Senior Data Scientist can expect 60-90% of their work to be hands-on prototyping solutions, with the remainder spent planning and designing, overseeing and reviewing work of project staff, interfacing with stakeholders and managing team members.\nExperience and qualifications required:\nStandards of Leadership Required in This Role\nPersonal Mastery (Data-science and advanced analytics)\nAgility\nBusiness acumen\nPassion for High Performance\nKey Skills Required\nProfessional Skills\nMachine learning - Expert\nStatistical modelling - Expert\nForecasting - Expert\nOptimisation techniques and tools - Fully Operational\nPython coding - Fully Operational\nData science platform tools e. g. MS Azure, Databricks - Fully Operational\nDeep learning (and applications to NLP Computer Vision) - Fully Operational\nCollaborative development using Git repos - Fully Operational\nAutomated Machine Learning platforms - Foundational knowledge\nWhile a broad data science technical background is required, the role will benefit from deeper skills (for example graduate studies or prior work experience) in one of the following areas, optimization, simulation, forecasting, natural language processing, computer vision or geospatial analysis.\nGeneral Skills\nProject Management - Expert\nCommunication / presentation skills - Expert\n3rd party resource management - Expert\nCPG Industry analytics - Expert\nStrong communication and stakeholder engagement skills are essential, including the ability to influence peers and senior business stakeholders across Unilever.\nRelevant Experience:\nMinimum of B. E. in a relevant technical field (e. g. Computer Science, Engineering, Statistics, Operations Research); preferably a postgraduate (Masters or Doctorate) degree\nAt least 4 years building data science solutions to solve business problems, preferably in the CPG industry (less experience may be acceptable if balanced by strong post-grad qualifications)\nExperience with open source languages (eg. Python) and preferably with distributed computing (PySpark)\nExperience deploying solutions in a modern cloud-based architecture\nExperience managing the work of team members and 3rd party resource vendors\nExperience presenting insights and influencing decisions of senior non-technical stakeholders\nKey interfaces\nInternal\nUnilever operational, marketing, customer development, supply chain, product finance teams\nInternal DA teams (Engagement teams; Data CoE; Solution Factory; BDL Factory; Information Factory; Tech Transformation)\nWider Unilever analytics and data science professionals\nExternal\n3rd party Data Science vendors\nUniversities\nIndustry bodies",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Operations research', 'Automation', 'data science', 'Data management', 'Project management', 'Information management', 'Resource management', 'Forecasting', 'Recruitment']",2025-06-14 05:36:58
Data Management Associate,JPMorgan Chase Bank,5 - 10 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","You are a strategic thinker passionate about driving solutions in Data Management. You have found the right team.\nAs a Data Management Associate within the Client Account Services team at JPMorgan Chase, you ensure that client data is accessible, comprehensible, and of high quality. You will cross-reference client accounts with party identifiers to support data enrichment, map client accounts to JPM legal entities, hierarchies, and parties of interest, and engage in data analysis, creation, migration, and uplift for strategic and regulatory initiatives. You may also deploy tools and graphic concepts to facilitate data analysis and influence decision-making. The Client Account Services team is responsible for the timely and accurate setup and maintenance of client/counterparty static data, facilitating trading and settlement functions by managing client/counterparty account reference data and standard settlement instructions on core processing platforms. This includes handling reference data such as cash and stock settlement instructions, confirmations, account-level details like names, addresses, country of citizenship, and trading restriction flags. Additionally, you will support the setup and maintenance of other static data, including portfolio references, books, salesperson, trader, depots, commission updates, accounting tables, and monitoring exception queues.\nJob responsibilities\nExecute documented processes and procedures with minimal supervision.\nLead individuals through the data management lifecycle, utilizing data-related tools.\nValidate Standard Settlement Instructions with end-to-end SWIFT knowledge.\nAnalyze and document metadata using workflow tools for processing output.\nCollaborate with stakeholders to assess data quality impacts and ensure documentation accuracy.\nProvide status updates to measure performance using workflow tools.\nDirect activities, monitor details, and set priorities.\nEscalate process issues and risks appropriately.\nReview root cause analysis and identify best practices.\nCollaborate with team members to achieve common goals.\nDemonstrate dedication, strong work ethic, and willingness to learn and take feedback.\nRequired qualifications, capabilities and skills\nMinimum 5+ years of related experience\nBachelors degree required\nGood verbal and written communication skills\nGood problem solving and analytics skills\nAttention to Details and optimal accuracy rate in processing critical request.\nAbility to create workflows and BRD s for Automation Programs.\nUnderstanding of settlement instructions and set-up/enriching trade confirmations\nAdheres to CAS God Standards",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Root cause analysis', 'Data analysis', 'Automation', 'metadata', 'Data management', 'data management associate', 'Workflow', 'Data quality', 'Analytics', 'Monitoring']",2025-06-14 05:37:00
S&C GN - Data&AI - Retail - Consultant,Accenture,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Title - Retail Specialized Data Scientist Level 9 SnC GN Data & AI\n\n\n\nManagement Level:09 - Consultant\n\n\n\nLocation:Bangalore / Gurgaon / Mumbai / Chennai / Pune / Hyderabad / Kolkata\n\n\n\nMust have skills:\nA solid understanding of retail industry dynamics, including key performance indicators (KPIs) such as sales trends, customer segmentation, inventory turnover, and promotions.\nStrong ability to communicate complex data insights to non-technical stakeholders, including senior management, marketing, and operational teams.\nMeticulous in ensuring data quality, accuracy, and consistency when handling large, complex datasets.\nGather and clean data from various retail sources, such as sales transactions, customer interactions, inventory management, website traffic, and marketing campaigns.\nStrong proficiency in Python for data manipulation, statistical analysis, and machine learning (libraries like Pandas, NumPy, Scikit-learn).\nExpertise in supervised and unsupervised learning algorithms\nUse advanced analytics to optimize pricing strategies based on market demand, competitor pricing, and customer price sensitivity.\n\n\n\n\nGood to have skills:\nFamiliarity with big data processing platforms like Apache Spark, Hadoop, or cloud-based platforms such as AWS or Google Cloud for large-scale data processing.\nExperience with ETL (Extract, Transform, Load) processes and tools like Apache Airflow to automate data workflows.\nFamiliarity with designing scalable and efficient data pipelines and architecture.\nExperience with tools like Tableau, Power BI, Matplotlib, and Seaborn to create meaningful visualizations that present data insights clearly.\n\n\nJob\n\n\nSummary: The Retail Specialized Data Scientist will play a pivotal role in utilizing advanced analytics, machine learning, and statistical modeling techniques to help our retail business make data-driven decisions. This individual will work closely with teams across marketing, product management, supply chain, and customer insights to drive business strategies and innovations. The ideal candidate should have experience in retail analytics and the ability to translate data into actionable insights.\n\n\n\n\nRoles & Responsibilities:\nLeverage Retail Knowledge:Utilize your deep understanding of the retail industry (merchandising, customer behavior, product lifecycle) to design AI solutions that address critical retail business needs.\nGather and clean data from various retail sources, such as sales transactions, customer interactions, inventory management, website traffic, and marketing campaigns.\nApply machine learning algorithms, such as classification, clustering, regression, and deep learning, to enhance predictive models.\nUse AI-driven techniques for personalization, demand forecasting, and fraud detection.\nUse advanced statistical methods help optimize existing use cases and build new products to serve new challenges and use cases.\nStay updated on the latest trends in data science and retail technology.\nCollaborate with executives, product managers, and marketing teams to translate insights into business actions.\n\n\n\n\nProfessional & Technical Skills:\nStrong analytical and statistical skills.\nExpertise in machine learning and AI.\nExperience with retail-specific datasets and KPIs.\nProficiency in data visualization and reporting tools.\nAbility to work with large datasets and complex data structures.\nStrong communication skills to interact with both technical and non-technical stakeholders.\nA solid understanding of the retail business and consumer behavior.\nProgramming Languages:Python, R, SQL, Scala\nData Analysis Tools:Pandas, NumPy, Scikit-learn, TensorFlow, Keras\nVisualization Tools:Tableau, Power BI, Matplotlib, Seaborn\nBig Data Technologies:Hadoop, Spark, AWS, Google Cloud\nDatabases:SQL, NoSQL (MongoDB, Cassandra)\n\n\n\n\nAdditional Information: -\n\nQualification\n\n\n\nExperience:Minimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification:Bachelors or Master's degree in Data Science, Statistics, Computer Science, Mathematics, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'artificial intelligence', 'data visualization', 'statistics', 'algorithms', 'data manipulation', 'scikit-learn', 'scala', 'numpy', 'unsupervised learning', 'sql', 'pandas', 'tensorflow', 'spark', 'consumer behavior', 'keras', 'hadoop', 'aws', 'reporting tools', 'retail business']",2025-06-14 05:37:03
Data Bricks,PwC India,7 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary:\n\nWe are seeking a talented Data Engineer with strong expertise in Databricks, specifically in Unity Catalog, PySpark, and SQL, to join our data team. Youll play a key role in building secure, scalable data pipelines and implementing robust data governance strategies using Unity Catalog.\n\nKey Responsibilities:",,,,"['DataBricks', 'Data Bricks', 'Pyspark', 'Delta Lake', 'Databricks Engineer', 'Unity Catalog', 'SQL']",2025-06-14 05:37:05
S&C GN - Data&AI - CMT Eng - Consultant,Accenture,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Title - S&C Global Network - AI - CMT DE- Consultant\n\n\n\nManagement Level:9- Consultant\n\n\n\nLocation:Open\n\n\n\nMust-have skills:Data Engineering\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nWe are looking for a passionate and results-driven\n\n\n\nData Engineerto join our growing data team. You will be responsible for designing, building, and maintaining scalable data pipelines and infrastructure that support data-driven decision-making across the organization.\n\n\n\n\nRoles & Responsibilities:\n\nDesign, build, and maintain robust, scalable, and efficient data pipelines (ETL/ELT).\nWork with structured and unstructured data across a wide variety of data sources.\nCollaborate with data analysts, data scientists, and business stakeholders to understand data requirements.\nOptimize data systems and architecture for performance, scalability, and reliability.\nMonitor data quality and support initiatives to ensure clean, accurate, and consistent data.\nDevelop and maintain data models and metadata.\nImplement and maintain best practices in data governance, security, and compliance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n2+ years in data engineering or related fields\nProficiency in SQL and experience with relational databases (e.g., PostgreSQL, MySQL).\nStrong programming skills in Python, Scala, or Java.\nExperience with big data technologies such as Spark, Hadoop, or Hive.\nFamiliarity with cloud platforms like AWS, Azure, or GCP, especially services like S3, Redshift, BigQuery, or Azure Data Lake.\nExperience with orchestration tools like Airflow, Luigi, or similar.\nSolid understanding of data warehousing concepts and data modeling techniques.\nGood problem-solving skills and attention to detail.\nExperience with modern data stack tools like dbt, Snowflake, or Databricks.\nKnowledge of CI/CD pipelines and version control (e.g., Git).\nExposure to containerization (Docker, Kubernetes) and infrastructure as code (Terraform, CloudFormation).\n\n\n\n\nAdditional Information: - The ideal candidate will possess a strong educational background in quantitative discipline and experience in working with Hi-Tech clients\n\n- This position is based at our Bengaluru (preferred) and other AI Accenture locations.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:4+ years\n\n\n\n\nEducational Qualification:Btech/ BE",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'scala', 'data engineering', 'sql', 'java', 'hive', 'continuous integration', 'kubernetes', 'snowflake', 'amazon redshift', 'airflow', 'microsoft azure', 'ci/cd', 'aws cloudformation', 'docker', 'data bricks', 'data modeling', 'spark', 'gcp', 'data warehousing concepts', 'terraform', 'hadoop', 'aws']",2025-06-14 05:37:07
Sr. Data Scientist-Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist\n\nLocation: Onsite Bangalore\nExperience: 8+ years\n\nRole Overview\n\nWe are seeking a Senior Data Scientist with a strong foundation in machine learning, deep learning, and statistical modeling, with the ability to translate complex operational problems into scalable AI/ML solutions. In addition to core data science responsibilities, the role involves building production-ready backends in Python and contributing to end-to-end model lifecycle management. Exposure to computer vision is a plus, especially for industrial use cases like identification, intrusion detection, and anomaly detection.\n\nKey Responsibilities\n\nDevelop, validate, and deploy machine learning and deep learning models for forecasting, classification, anomaly detection, and operational optimization\nBuild backend APIs using Python (FastAPI, Flask) to serve ML/DL models in production environments\nApply advanced computer vision models (e.g., YOLO, Faster R-CNN) to object detection, intrusion detection, and visual monitoring tasks\nTranslate business problems into analytical frameworks and data science solutions\nWork with data engineering and DevOps teams to operationalize and monitor models at scale\nCollaborate with product, domain experts, and engineering teams to iterate on solution design\nContribute to technical documentation, model explainability, and reproducibility practices\n\n\nRequired Skills\n\nStrong proficiency in Python for data science and backend development\nExperience with ML/DL libraries such as scikit-learn, TensorFlow, or PyTorch\nSolid knowledge of time-series modeling, forecasting techniques, and anomaly detection\nExperience building and deploying APIs for model serving (FastAPI, Flask)\nFamiliarity with real-time data pipelines using Kafka, Spark, or similar tools\nStrong understanding of model validation, feature engineering, and performance tuning\nAbility to work with SQL and NoSQL databases, and large-scale datasets\nGood communication skills and stakeholder engagement experience\n\n\nGood to Have\n\nExperience with ML model deployment tools (MLflow, Docker, Airflow)\nUnderstanding of MLOps and continuous model delivery practices\nBackground in aviation, logistics, manufacturing, or other industrial domains\nFamiliarity with edge deployment and optimization of vision models\n\n\nQualifications\n\nMasters or PhD in Data Science, Computer Science, Applied Mathematics, or related field\n7+ years of experience in machine learning and data science, including end-to-end deployment of models in production",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scikit-learn', 'time-series modeling', 'ML/DL libraries', 'data science', 'Python', 'Airflow', 'Kafka', 'MLflow', 'logistics', 'anomaly detection', 'aviation', 'SQL', 'PyTorch', 'NoSQL', 'MLOps', 'forecasting techniques', 'Docker', 'manufacturing', 'FastAPI', 'Spark', 'TensorFlow', 'Flask']",2025-06-14 05:37:10
Specialist Data/AI Engineering,ATT Communication Services,3 - 4 years,Not Disclosed,['Bengaluru'],"Overall Purpose\nThis position will interact on a consistent basis with other developers, architects, data product owners and source systems. This position requires multifaceted candidates who have experience in data analysis, visualization, good hands-on experience with BI Tools and relational databases, experience in data warehouse architecture (traditional and cloud).\nKey Roles and Responsibilities\nDevelop, understand, and enhance code in traditional data warehouse environments, data lake, and cloud environments like Snowflake, Azure, Databricks\nBuild new end-to-end business intelligence solutions. This includes data extraction, ETL processes applied on data to derive useful business insights, and best representing this data through dashboards.\nWrite complex SQL queries used to transform data using Python/Unix shell scripting\nUnderstand business requirements and create visual reports and dashboards using Power BI or Tableau.\nUpskill to different technologies, understand existing products and programs in place\nWork with other development and operations teams.\nFlexible with shifts and occasional weekend support.\nKey Competencies\nFull life-cycle experience on enterprise software development projects.\nExperience in relational databases/ data marts/data warehouses and complex SQL programming.\nExtensive experience in ETL, shell or python scripting, data modelling, analysis, and preparation\nExperience in Unix/Linux system, files systems, shell scripting.\nGood to have knowledge on any cloud platforms like AWS, Azure, Snowflake, etc.\nGood to have experience in BI Reporting tools Power BI or Tableau\nGood problem-solving and analytical skills used to resolve technical problems.\nMust possess a good understanding of business requirements and IT strategies.\nAbility to work independently but must be a team player. Should be able to drive business decisions and take ownership of their work.\nExperience in presentation design, development, delivery, and good communication skills to present analytical results and recommendations for action-oriented data driven decisions and associated operational and financial impacts.\nRequired/Desired Skills\nCloud Platforms - Azure, Snowflake, Databricks, Delta lake (Required 3-4 years)\nRDBMS and Data Warehousing (Required 7-10 Years)\nSQL Programming and ETL (Required 7-10 Years)\nUnix/Linux shell scripting (Required 2-3 years)\nPower BI / Tableau (Desired 3 years)\nPython or any other programming language (Desired 4 years)\nEducation & Qualifications\nUniversity Degree in Computer Science and/or Analytics\nMinimum Experience required: 7-10 years in relational database design & development, ETL development\nJob ID R-68650 Date posted 06/11/2025",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Unix', 'Linux', 'RDBMS', 'Database design', 'Shell scripting', 'Business intelligence', 'Unix shell scripting', 'Analytics', 'SQL', 'Python']",2025-06-14 05:37:12
Specialist Data/AI Engineering,ATT Communication Services,3 - 4 years,Not Disclosed,['Bengaluru'],"Overall Purpose\nThis position will interact on a consistent basis with other developers, architects, data product owners and source systems. This position requires multifaceted candidates who have experience in data analysis, visualization, good hands-on experience with BI Tools and relational databases, experience in data warehouse architecture (traditional and cloud).\nKey Roles and Responsibilities\nDevelop, understand, and enhance code in traditional data warehouse environments, data lake, and cloud environments like Snowflake, Azure, Databricks\nBuild new end-to-end business intelligence solutions. This includes data extraction, ETL processes applied on data to derive useful business insights, and best representing this data through dashboards.\nWrite complex SQL queries used to transform data using Python/Unix shell scripting\nUnderstand business requirements and create visual reports and dashboards using Power BI or Tableau.\nUpskill to different technologies, understand existing products and programs in place\nWork with other development and operations teams.\nFlexible with shifts and occasional weekend support.\nKey Competencies\nFull life-cycle experience on enterprise software development projects.\nExperience in relational databases/ data marts/data warehouses and complex SQL programming.\nExtensive experience in ETL, shell or python scripting, data modelling, analysis, and preparation\nExperience in Unix/Linux system, files systems, shell scripting.\nGood to have knowledge on any cloud platforms like AWS, Azure, Snowflake, etc.\nGood to have experience in BI Reporting tools Power BI or Tableau\nGood problem-solving and analytical skills used to resolve technical problems.\nMust possess a good understanding of business requirements and IT strategies.\nAbility to work independently but must be a team player. Should be able to drive business decisions and take ownership of their work.\nExperience in presentation design, development, delivery, and good communication skills to present analytical results and recommendations for action-oriented data driven decisions and associated operational and financial impacts.\nRequired/Desired Skills\nCloud Platforms - Azure, Snowflake, Databricks, Delta lake (Required 3-4 years)\nRDBMS and Data Warehousing (Required 7-10 Years)\nSQL Programming and ETL (Required 7-10 Years)\nUnix/Linux shell scripting (Required 2-3 years)\nPower BI / Tableau (Desired 3 years)\nPython or any other programming language (Desired 4 years)\nEducation & Qualifications\nUniversity Degree in Computer Science and/or Analytics\nMinimum Experience required: 7-10 years in relational database design & development, ETL development\nJob ID R-68650 Date posted 06/11/2025",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Unix', 'Linux', 'RDBMS', 'Database design', 'Shell scripting', 'Business intelligence', 'Unix shell scripting', 'Analytics', 'SQL', 'Python']",2025-06-14 05:37:14
IN_Manager-Data Transformation -TMT -Advisory-Bangalore,PwC Service Delivery Center,4 - 8 years,Not Disclosed,['Bengaluru'],"& Summary\nAt PwC, our people in strategy consulting focus on providing strategic guidance and insights to organisations. They analyse market trends, assess business performance, and develop recommendations to help clients achieve their goals. These individuals work closely with clients to identify opportunities for growth, optimise operations, and enhance overall business performance.\n\nAs a corporate and business strategy consultant at PwC, you will analyse client needs, provide consulting services across different strategic areas, and offer guidance and support to help clients develop and implement effective strategies that align with their business objectives and drive growth.\n& Summary\nPwC actively works as a management advisor to leading telecommunications and IT market players across the value chain, including fixed, cable and convergent service providers,mobile operators, tower operators telecom regulators, industry bodies etc. Our Management Consulting TMT practice in India focuses on bringing together our Indian and global network resources around our clients needs, creating teams to help respond to challenges around almost every dimension of their business. Our clients are majorly spread across India, Africa, Middle East and South East Asia.\nRoles & Responsibilities\nAs a Management Consulting professional specializing in the TMT domain, the candidate will play a vital role in advising our clients on leveraging the potential of their networks and to drive innovation, gain a competitive edge, and capture new market opportunities. He/she will work closely with senior executives and stakeholders, providing strategic counsel and datadriven insights to shape their network strategies. Typical roles and responsibilities for the role are as below Understanding of the leading data analytics systems such as tableau, power BI, Alteryx, python, Qlik etc. with proven track record of delivering analytics solutions such as data strategy, data modelling, monetization and architecture to clients in the telecommunications and technology sector across India and global markets. Understand and define the business problems and cocreate the proposed solution leveraging latest trends within AL and ML . Leverage essential knowledge of the leading practices in the industry to develop project scope and approach to solve client problems When tailoring the key responsibilities for a Data Models Expert in the context of supply chain and asset lifecycle management transformation in ERP environments, particularly with telecommunicationsspecific experience, its important to focus on both general data modeling skills and telecom industry nuances. Below are example key responsibilities that you might include in a job description Data Models Design Develop and maintain comprehensive data models tailored to support supply chain and asset lifecycle management processes within ERP systems, focusing on telecommunications industry requirements. Entity Relationship Diagrams (ERD) Create detailed ERDs that accurately represent the relationships between data entities, ensuring alignment with business processes and compliance with industry standards. Logical Data Models Design logical data models that define the structure and organization of data within ERP systems, optimizing for efficiency and scalability in telecom operations. TelecommunicationsSpecific Integration Ensure data models effectively integrate with telecommunicationsspecific ERP modules, such as network inventory management and customer relationship management. CrossFunctional Collaboration Work closely with supply chain, asset management, and IT teams to gather requirements and translate them into effective data model designs that address both business and technical needs. Data Governance Establish and enforce data governance policies to ensure data quality, consistency, and security across supply chain and asset lifecycle management processes. Process Optimization Analyze existing supply chain and asset management workflows to identify opportunities for improvement, leveraging data models to streamline operations and enhance decisionmaking. Stakeholder Engagement Engage with business stakeholders to understand their needs and provide insights on how data modeling can support organizational objectives and strategic initiatives.\nDocumentation Maintain comprehensive documentation of data models, ERDs, and related processes to facilitate ongoing maintenance and support. Industry Best Practices Stay updated on telecommunications industry trends and best practices in data modeling and ERP integration, applying this knowledge to enhance data models and processes. Training and Support Provide training and support to endusers and technical teams on new data models and ERP functionalities, ensuring effective adoption and utilization . These responsibilities emphasize the importance of industryspecific expertise , collaboration, and continuous improvement in the context of ERP systems for telecommunications. Adjust the wording and details to suit the specific organizational needs and job level (e.g., junior, senior) as necessary. Perform quantitative and qualitative analysis including data mining, analysis, visualization, perform market and secondary research to collect business intelligence and insights Develop use cases for enterprise businesses using large data sets and understanding of GenAI and automation use cases Work collaboratively with the team in developing project deliverables meeting PwCs client service and quality standards Stay abreast of industry developments, regulatory changes, and competitive dynamics impacting telecommunication networks, and incorporate this knowledge into client engagements. Contribute to business development opportunities by proactively Willing to travel internationally and work on site 5070% of the time at client locations.\nMandatory skill sets\nDeep knowledge of the leading data analytics systems along with AL and ML Expertise in data strategy , modelling, mining and other analytics solutions Familiarity with telecommunication industry trends preferred Excellent problemsolving abilities, with a strategic mindset and the capacity to think critically and creatively. Excellent communication and presentation skills, with the ability to articulate technical concepts to nontechnical audiences. Ability to thrive in a fastpaced, dynamic environment, managing multiple projects with competing priorities effectively. A passion for continuous learning, innovation, and staying ahead of TMT industry trends.\nPreferred skill sets\nProven experience in management consulting, with a focus on telecommunication networks and technology.\nAdvance working knowledge of with MSOffice tools (Visio, Excel, Power Point, and other tools).\nAdvance working knowledge with tools such as MySQL, Alteryx, python, Power BI, tableau etc.\nBachelors degree in Telecommunications, Electrical Engineering, Computer Science, Statistics or a related field.\nAdvanced degree (e.g., MBA) preferred.\nYears of experience required\n6 + years of relevant experience in data and analytics domain\nEducation qualification\nBachelors degree in Telecommunications, Electrical Engineering, Computer Science, Statistics or a related field.\nAdvanced degree (e.g., MBA) preferred.\nEducation\nDegrees/Field of Study required Master of Business Administration\nDegrees/Field of Study preferred\nRequired Skills\nData Transformation\nAccepting Feedback, Accepting Feedback, Active Listening, Analytical Thinking, Business Analysis, Business Opportunities, Business Process Consulting, Business Process Improvement, Business Strategy, Business Transformation, Coaching and Feedback, Communication, Competitive Advantage, Competitive Analysis, Conducting Research, Consumer Behavior, Creativity, Customer Experience (CX) Strategy, Customer Insight, Customer Strategy, Data Analytics, Embracing Change, Emotional Regulation, Empathy, GotoMarket Strategies {+ 19 more}\nTravel Requirements\nGovernment Clearance Required?",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Telecom', 'Business transformation', 'Business analysis', 'Competitive analysis', 'Management consulting', 'Business strategy', 'Business intelligence', 'Data mining', 'Secondary research']",2025-06-14 05:37:16
Senior Data Scientist,eka.care,3 - 5 years,Not Disclosed,['Bengaluru'],"EkaCare (Orbi Health) is a well-funded startup working on a suite of technologies in the healthcare domain ranging from AI-powered EMR for doctors to one of the most comprehensive personal health record (PHR) applications for consumers. EkaCare seeks enthusiastic senior candidates to develop Large Language Models around medical/clinical data.\n\nWe look forward to a candidate with\nPassion for problem-solving and taking end-to-end ownership of projects\nExtensive knowledge and prior work experience in machine learning (specifically in developing LLMs)\nDesire for a high-paced start-up ride\n\nKey Responsibilities :\nFormulate and implement data-driven solutions in the HealthTech domain:\nBuilding LLMs around healthcare data, wherein the work would involve creating datasets, continual pre-training, supervised fine-tuning, and preference alignment of models.\nDeveloping product-led AI solutions for various healthcare entities.\n\nQualifications / Requirements\nMaster / PhD degree in a relevant academic discipline (Preferred)\n3-5 years of industry experience in building ML production-level pipelines.\nExtensive experience with LLMs (production-level deployment and fine-tuning)\nStrong track record of project delivery\n\nExperience Required: 3-5 years\n\nFull Time Employee Benefits:\nInsurance Benefits - Medical Insurance, Accidental Insurance\nParental Support - Maternity Benefit, Paternity Benefit Program\nMobility Benefits - Relocation benefits, Transfer Support Policy, Travel Policy\nRetirement Benefits - Employee PF Contribution, Flexible PF Contribution, Gratuity, NPS, Leave Encashment\nOther Benefits - Car Lease, Salary Advance Policy",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Training', 'Machine learning', 'Leasing', 'Healthcare', 'Deployment', 'Medical insurance', 'Project delivery', 'Supervision', 'clinical data']",2025-06-14 05:37:18
Senior Data Scientist,Cradlepoint,3 - 8 years,Not Disclosed,['Bengaluru'],"Join our Team\nAbout this Opportunity\nThe complexity of running and optimizing the next generation of wireless networks, such as 5G with distributed edge compute, will require Machine Learning (ML) and Artificial Intelligence (AI) technologies. Ericsson is setting up an AI Accelerator Hub in India to fast-track our strategy execution, using Machine Intelligence (MI) to drive thought leadership, automate, and transform Ericsson s offerings and operations. We collaborate with academia and industry to develop state-of-the-art solutions that simplify and automate processes, creating new value through data insights.\nWhat you will do\nAs a Senior Data Scientist, you will apply your knowledge of data science and ML tools backed with strong programming skills to solve real-world problems.\nResponsibilities:\n1. Lead AI/ML features/capabilities in product/business areas\n2. Define business metrics of success for AI/ML projects and translate them into model metrics\n3. Lead end-to-end development and deployment of Generative AI solutions for enterprise use cases\n4. Design and implement architectures for vector search, embedding models, and RAG systems\n5. Fine-tune and evaluate large language models (LLMs) for domain-specific tasks\n6. Collaborate with stakeholders to translate vague problems into concrete Generative AI use cases\n7. Develop and deploy generative AI solutions using AWS services such as SageMaker, Bedrock, and other AWS AI tools. Provide technical expertise and guidance on implementing GenAI models and best practices within the AWS ecosystem.\n8. Develop secure, scalable, and production-grade AI pipelines\n9. Ensure ethical and responsible AI practices\n10. Mentor junior team members in GenAI frameworks and best practices\n11. Stay current with research and industry trends in Generative AI and apply cutting-edge techniques\n12. Contribute to internal AI governance, tooling frameworks, and reusable components\n13. Work with large datasets including petabytes of 4G/5G networks and IoT data\n14. Propose/select/test predictive models and other ML systems\n15. Define visualization and dashboarding requirements with business stakeholders\n16. Build proof-of-concepts for business opportunities using AI/ML\n17. Lead functional and technical analysis to define AI/ML-driven business opportunities\n18. Work with multiple data sources and apply the right feature engineering to AI models\n19. Lead studies and creative usage of new/existing data sources\nWhat you will bring\n1. Bachelors/Masters/Ph.D. in Computer Science, Data Science, AI, ML, Electrical Engineering, or related disciplines from reputed institutes\n2. 3+ years of applied ML/AI production-level experience\n3. Strong programming skills (R/Python)\n4. Proven ability to lead AI/ML projects end-to-end\n5. Strong grounding in mathematics, probability, and statistics\n6. Hands-on experience with data analysis, visualization techniques, and ML frameworks (Python, R, H2O, Keras, TensorFlow, Spark ML)\n7. Experience with semi-structured/unstructured data for AI/ML models\n8. Strong understanding of building AI models using Deep Neural Networks\n9. Experience with Big Data technologies (Hadoop, Cassandra)\n10. Ability to source and combine data from multiple sources for ML models\nPreferred Qualifications:\n1. Good communication skills in English\n2. Certifying MI MOOCs, a plus\n3. Domain knowledge in Telecommunication/IoT, a plus\n4. Experience with data visualization and dashboard creation, a plus\n5. Knowledge of Cognitive models, a plus\n6. Experience in partnering and collaborative co-creation in a global matrix organization.\nWhy join Ericsson\n\n\nWhat happens once you apply\nPrimary country and city: India (IN) || Bangalore\nReq ID: 766481",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Wireless', 'Computer science', 'Data analysis', 'cassandra', 'Neural networks', 'Artificial Intelligence', 'Machine learning', 'Telecommunication', 'data visualization', 'Python']",2025-06-14 05:37:21
Sr Data Scientist,Johnson Controls,1 - 2 years,Not Disclosed,['Pune'],"Job Title Senior Data Scientist - Data Analytics\nHow you will do it\nAdvanced Analytics, LLMs Modeling\nDesign and implement advanced machine learning models including deep learning, time-series forecasting, recommendation engines, and LLM-based solutions (e. g. , GPT, LLaMA, Claude).\nDevelop use cases around enterprise search, document summarization, conversational AI, and automated knowledge retrieval using large language models.",,,,"['Computer science', 'Product engineering', 'orchestration', 'Artificial Intelligence', 'Machine learning', 'Forecasting', 'Monitoring', 'Analytics', 'SQL', 'Python']",2025-06-14 05:37:24
S&C Global Network - AI - CG&S - Data Engineer Consultant,Accenture,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Title:Industry & Function AI Data Engineer + S&C GN\n\n\n\nManagement Level:09 - Consultant\n\n\n\nLocation:Primary - Bengaluru, Secondary - Gurugram\n\n\n\nMust-Have Skills:Data Engineering expertise, Cloud platforms:AWS, Azure, GCP, Proficiency in Python, SQL, PySpark and ETL frameworks\n\n\n\nGood-to-Have Skills:LLM Architecture, Containerization tools:Docker, Kubernetes, Real-time data processing tools:Kafka, Flink, Certifications like AWS Certified Data Analytics Specialty, Google Professional Data Engineer,Snowflake,DBT,etc.\n\n\n\nJob\n\n\nSummary:\n\nAs a Data Engineer, you will play a critical role in designing, implementing, and optimizing data infrastructure to power analytics, machine learning, and enterprise decision-making. Your work will ensure high-quality, reliable data is accessible for actionable insights. This involves leveraging technical expertise, collaborating with stakeholders, and staying updated with the latest tools and technologies to deliver scalable and efficient data solutions.\n\n\n\n\nRoles & Responsibilities:\nBuild and Maintain Data Infrastructure:Design, implement, and optimize scalable data pipelines and systems for seamless ingestion, transformation, and storage of data.\nCollaborate with Stakeholders:Work closely with business teams, data analysts, and data scientists to understand data requirements and deliver actionable solutions.\nLeverage Tools and Technologies:Utilize Python, SQL, PySpark, and ETL frameworks to manage large datasets efficiently.\nCloud Integration:Develop secure, scalable, and cost-efficient solutions using cloud platforms such as Azure, AWS, and GCP.\nEnsure Data Quality:Focus on data reliability, consistency, and quality using automation and monitoring techniques.\nDocument and Share Best Practices:Create detailed documentation, share best practices, and mentor team members to promote a strong data culture.\nContinuous Learning:Stay updated with the latest tools and technologies in data engineering through professional development opportunities.\n\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\nStrong proficiency in programming languages such as Python, SQL, and PySpark\nExperience with cloud platforms (AWS, Azure, GCP) and their data services\nFamiliarity with ETL frameworks and data pipeline design\nStrong knowledge of traditional statistical methods, basic machine learning techniques.\nKnowledge of containerization tools (Docker, Kubernetes)\nKnowing LLM, RAG & Agentic AI architecture\nCertification in Data Science or related fields (e.g., AWS Certified Data Analytics Specialty, Google Professional Data Engineer)\n\n\n\n\n\nAdditional Information:\n\nThe ideal candidate has a robust educational background in data engineering or a related field and a proven track record of building scalable, high-quality data solutions in the Consumer Goods sector.\n\nThis position offers opportunities to design and implement cutting-edge data systems that drive business transformation, collaborate with global teams to solve complex data challenges and deliver measurable business outcomes and enhance your expertise by working on innovative projects utilizing the latest technologies in cloud, data engineering, and AI.\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:Minimum 3-7 years in data engineering or related fields, with a focus on the Consumer Goods Industry\n\n\n\n\nEducational Qualification:Bachelors or Masters degree in Computer Science, Information Systems, Engineering, or a related field",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'data engineering', 'sql', 'machine learning algorithms', 'kubernetes', 'snowflake', 'data analytics', 'microsoft azure', 'cloud platforms', 'machine learning', 'apache flink', 'artificial intelligence', 'docker', 'pipeline', 'data science', 'gcp', 'kafka', 'aws', 'etl', 'etl scripts']",2025-06-14 05:37:26
Senior Data Scientist with GCP,TVS Next,5 - 7 years,Not Disclosed,['Bengaluru'],"What you’ll do:\nUtilize advanced mathematical, statistical, and analytical expertise to research, collect, analyze, and interpret large datasets from internal and external sources to provide insight and develop data driven solutions across the company\nBuild and test predictive models including but not limited to credit risk, fraud, response, and offer acceptance propensity\nResponsible for the development, testing, validation, tracking, and performance enhancement of statistical models and other BI reporting tools leading to new innovative origination strategies within marketing, sales, finance, and underwriting",,,,"['analytical', 'scikit-learn', 'searching', 'bi', 'pyspark', 'numpy', 'sql', 'analytics', 'apache', 'automation', 'data science', 'spark', 'gcp', 'bigquery', 'data visualization', 'xgboost', 'programming', 'reporting', 'ml', 'advanced analytics', 'python', 'data processing', 'predictive', 'jupyter notebook', 'bert', 'pandas', 'matplotlib', 'statistics']",2025-06-14 05:37:28
Business Analyst(BA),Utopian Dreams Private Limited,1 - 3 years,Not Disclosed,['Noida( Sector-2 Noida )'],"Job Profile:\n\nWe are currently seeking for Business Analysts proficient in Business analysis, Data Analysis, Agile Methodology, Project Management. Collaborate with project team and support test planning and working on UAT. To work closely with development team to ensure requirements are accurately mapped as per clients requirements. Also Coordinate with stakeholders to ensure timely and accurate delivery of reports in the required formats. As a Business Analyst at DistrictD, you have to identify trends, deviations, and areas of improvement. Develop and finalize management report templates with the Management team.\n\nDesignation: Business Analyst\n\nTech Stack: Agile Methodology / Project Management / Stakeholder Management\n\nLocation: Noida\n\nRoles and Responsibilities\nCollaborate with stakeholders to understand business requirements and translate them into technical specifications.\nDevelop and maintain documentation of project plans, progress reports, and issue logs.\nUtilize advanced excel skills to analyze data and create insightful reports for decision-making purposes.\nWork closely with cross-functional teams to identify areas for improvement and implement changes using Agile methodologies.\nProvide effective communication management by ensuring timely updates on project status to stakeholders.\nDesired Candidate Profile\n1-3 years of experience in Business Analyst (BA) role or related field.\n\nStrong understanding of Business Analytics, Business Analysis, Communication Management, Documentation, Data Analysis, SDLC Life Cycle & Project Management principles.\n\nProficiency in tools such as Advanced Excel, SQL, Power BI, Tableau; ability to learn new technologies quickly.\n\nYou must be an excellent problem solver with a passion of self-learning.\n\nBe an innovative and creative thinker, somebody who is not afraid to try something new",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analytics', 'Advanced Excel', 'Power Bi', 'Documentation', 'Tableau', 'SDLC Life Cycle', 'SDLC', 'SQL', 'Business Analysis', 'Software Development Life Cycle', 'Agile Methodology', 'Excel', 'Project Management', 'Communication Management', 'Data Analysis', 'Agile', 'Stakeholder Management']",2025-06-14 05:37:31
Business Analyst,Technocrats Horizons Compusoft,1 - 3 years,Not Disclosed,['Hyderabad'],"Education Required\nGraduate: B.Tech/B.E. in Computers, BCA in Any Specialization.\nPG: MBA, MCA in Computers, MS/M.Sc in Any Specialization.\nBehavior & Character Attributes Required:\nUser-Focused Empathy: You naturally understand our customers' needs and view things from their perspective, always striving to create impactful solutions.\nTeam Player & Relationship Builder: You're great at building strong, trusting relationships with both colleagues and clients, fostering open communication.\nPositive Problem Solver: You maintain a positive attitude and always look for solutions, even when faced with difficulties.\nProactive & Forward-Thinking: You anticipate client needs and potential issues, always thinking a step ahead.\nAnalytical & Creative Thinker: You're skilled at breaking down problems and finding innovative, effective solutions.\nAttentive Listener: You actively listen to truly understand others, which is vital for effective collaboration and problem-solving.\nOrganized & Detail-Oriented: You work systematically and keep your documentation clear and tidy, showing attention to detail.\nEager to Learn & Adapt: You actively research global tech trends, always seeking new knowledge to keep us competitive.\nResponsibilities:\nClient & Requirement Management: Conduct sessions with clients and sales teams to gather requirements, define user stories, and propose tailored solutions aligned with business goals.\nProject & Process Oversight: Manage project scope, timelines, and sprints; coordinate stand-ups, retrospectives, and ensure quality deliverables.\nSystem & Workflow Documentation: Help design, document, and maintain system processes while facilitating smooth implementation of changes.\nTeam Coordination & Conflict Resolution: Guide development teams, support effective internal communication, resolve conflicts, and remove project obstacles.\nClient Relationship & Communication: Build and maintain strong client relationships, serving as the key contact to understand goals, challenges, and deliver consistent value.\nAccount & Performance Management: Oversee client accounts, ensure satisfaction and retention through regular reviews and collaboration with internal teams.\n\nGrowth & Business Development: Identify upsell/cross-sell opportunities, drive new business through referrals, and support backlog grooming with product owners.\nWhat you need to Bring:\nExperience: You've worked before as a Business Analyst or in a similar position.\nTech Know-How: You understand software products, their features, and related services.\nCommunication Skills: You can explain complex ideas clearly, both when speaking and writing (including technical documents).\nAgile & Scrum Familiarity: You're comfortable with Agile and Scrum ways of working.\nTool Proficiency: You know how to use project management tools.\nDocumentation Expertise: Proficient in creating and managing BRDs, FRDs, user stories, use cases, and process flow diagrams.\nOrganizational Strength: Strong organizational, time management, and multitasking skills to manage competing priorities efficiently.\nGood to Have:\n\nCertified in Business Analysis: Holding a certification like CBAP or CCBA is a plus.\nIndustry Software Knowledge: You're familiar with software and tools specific to our industry.\nData Analysis Skills: You can analyze data to find useful business insights and are good with data visualization tools.\nClient Interaction Experience: You have experience working directly with clients.\nSQL Knowledge: You know how to use SQL or other data querying languages.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analysis', 'CCBA', 'Client Management', 'CBAP', 'Data Analysis', 'Performance Management', 'Requirement Management', 'SQL']",2025-06-14 05:37:33
MIS Executive,Pleasant Inc,0 - 3 years,Not Disclosed,['Surat'],"Job Description:\nKey Responsibilities:\nDevelop, maintain, and generate MIS reports, dashboards, and presentations for various business functions.\nDesign and automate reports to enhance operational efficiency.\nEnsure the accuracy, consistency, and timeliness of data across all reporting tools.\nSupport various departments (sales, finance, operations, HR, etc.) by providing customized reports and data-driven insights.\nAnalyze trends, variances, and patterns in data to provide actionable insights to management.\nEnsure that all reports are delivered within agreed timelines and meet business requirements.\nMaintain and update internal databases and ensure proper data integrity and accuracy.\nCreate and maintain databases, spreadsheets, and reports using advanced Excel functions and other reporting tools (e.g., Power BI, Tableau).\nCoordinate with IT teams for data system updates and improvements.\nWork closely with team members to understand their data and reporting needs.\nTroubleshoot data-related issues and ensure effective solutions are in place.\nSupport audits and compliance activities by providing necessary data.\nKey Skills :\nMis Executive\nData Analysis\nCoomunication\nStrategic Planning",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MIS reporting', 'Data analysis', 'Strategic planning', 'Financial operations', 'power bi', 'data integrity', 'Advanced Excel', 'Operations', 'Reporting tools', 'MIS Executive']",2025-06-14 05:37:35
Analyst - Direct Display,Aegis Media,1 - 3 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-14 05:37:37
Hiring Alert- Product Owner/Technical Business Analyst- Trivandrum,Service based MNC,5 - 10 years,17-25 Lacs P.A.,['Thiruvananthapuram'],"Qualifications:\n5+ years of experience as a Product Owner or Technical Business Analyst.\nProven experience creating product roadmaps, user stories, and backlog management.\nStrong understanding of Agile methodologies and experience working in Agile environments.\nExperience in financial services or credit risk industry is a plus.\nExcellent communication skills, with the ability to engage stakeholders at various levels.\nCertification in Agile/Scrum or Cloud technologies is a plus.\nSkills:\nBacklog Management\nData Analysis\nAgile Methodologies\nCloud Technologies\nBanking and Lending Product Knowledge (preferred)\nSkills\nBacklog,Data Analysis,Agile Methodologies",Industry Type: Analytics / KPO / Research,Department: Product Management,"Employment Type: Full Time, Permanent","['product owner', 'Business Analytics', 'Brd', 'Requirement Gathering', 'FRD', 'Business Analysis']",2025-06-14 05:37:39
Business Analyst - D2C Ecommerce,Glan Management Consultancy,23 - 28 years,Not Disclosed,['Gurugram'],"Job Description:\nJob Title: Business Analyst\nLocation :Gurugram (On-site)\nExperienceRequired: 23 years in D2C/e-commerce sector\nSalary :Negotiable\nIndustry :Fashion/apparel/garment\nRole Overview:\nWere seeking a detail-oriented and data-driven BusinessAnalyst to join our team. Youll work closely with cross-functionalteamsmarketing, supply chain, tech, and operationsto drive insights, optimizeperformance, and support strategic decisions.\nKeyResponsibilities:\nAnalyze business data across channels (Shopify,GA4, Meta, Google Ads, marketplaces, CRM, WhatsApp, Insta, etc.) to identifytrends, gaps, and growth opportunities\nBuild dashboards and automated reports for keymetrics, including CAC, LTV, retention, inventory velocity, and marketing ROI\nCollaborate with marketing and product teams toevaluate the performance of campaigns, cohorts, and product launches\nDrive demand forecasting and supportchannel-wise distribution planning using historical data and market signals\nPrepare detailed reports and presentations forsenior leadership, highlighting key insights and recommendations.\nWork with finance and ops on margin analysis,pricing models, and contribution tracking\nConduct competitor benchmarking and consumerbehavior analysis to inform brand strategy\nConduct cost/benefit analysis, feasibilitystudies, and risk assessments for proposed solutions.\nRequirements;\n23 years of experience in a Business/DataAnalyst role, preferably in a D2C or e-commerce environment\nProficient in SQL, Excel/Google Sheets, and datavisualization tools (Looker Studio, Power BI)\nStrong grasp of e-commerce KPIs, retentionmetrics, and performance marketing analytics\nFamiliarity with tools like Shopify, GA4, MetaAds Manager, Google Ads Manager, Search Console, etc.\nExcellent communication and presentation skills\nKnowledge of CRM and marketing automationplatforms (e.g., WebEngage, MoEngage, Freshmarketer)\nComfortable working in a fast-paced, high-growthstartup environment\nMail updated resume with current salary-\nEmail: etalenthire@gmail.com\nSatish: 88O2749743\nWebsite: www.glansolutions.com\nGoogle search: Glan management Consultancy\nKey Skill:\nBusiness Analyst, Data Analyst, E-commerce Analytics, E-commerce Business Analyst, Digital Commerce Analyst, D2C (Direct-to-Consumer), Data Visualization, E-commerce KPIs, Retention Metrics\nPosted on: 10th Jun, 2025\nApply for Business Analyst - D2C Ecommerce\nSubmit\n\nApply Submit Resume Share with Friends (Mail)\n\n\nSee all Jobs",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business Analyst', 'Business Data Analyst', 'Demand forecasting', 'E-commerce', 'Data Analyst', 'data visualization', 'Analytics', 'CRM', 'SQL']",2025-06-14 05:37:42
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Bengaluru'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\n\nYour primary responsibilities include:\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\n\n\nPreferred technical and professional experience",,,,"['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-14 05:37:44
S&C GN - Data&AI - CMT Eng - Consultant,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Title - S&C Global Network - AI - CMT AI ML Consultant\n\n\n\nManagement Level:9- Consultant\n\n\n\nLocation:Open\n\n\n\nMust-have skills:Gen AI ML\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\nWHATS IN IT FOR YOU\nAccenture has committed to invest USD 3Billion into GenAI in the next 3 years. We will continually invest in your learning and growth. You'll work with Accentures highly skilled and experienced practitioners, and Accenture will support you in growing your own career path and interests.\nYoull be part of a diverse, vibrant, global Accenture Data and AI community, continually pushing the boundaries of business capabilities.\n\n\n\nWhat you would do in this role\n\n\n\nML Maturity Assessment:\nConduct comprehensive assessments of the organization's ML maturity, identifying strengths, weaknesses, and areas for improvement.\nProvide strategic recommendations to enhance the overall ML capability and align it with business objectives.\n\n\n\nML Ops Roadmap & Processes:\nDevelop ML Ops roadmaps and establish robust processes for the end-to-end machine learning lifecycle, including data preparation, model training, deployment, and monitoring.\nImplement best practices in ML Ops to ensure efficiency, scalability, and reliability of ML systems.\n\n\n\nImplementation of Gen AI Solutions:\nLead the design and implementation of state-of-the-art Generative AI solutions, leveraging deep learning frameworks such as TensorFlow and PyTorch.\nDrive innovation in Gen AI, staying abreast of the latest advancements and incorporating cutting-edge technologies into solutions.\n\n\n\nIncubating and Designing:\nProactively identify opportunities for ML and / or Gen AI applications within the organization.\nWork closely with cross-functional teams to incubate and design bespoke ML solutions tailored to business requirements.\n\n\n\nTechnical Leadership:\nProvide technical leadership and mentorship to data scientists, engineers, and other team members.\nCollaborate with stakeholders to ensure alignment between technical solutions and business objectives.\n\n\n\nCollaboration and Communication:\nCollaborate with business stakeholders to understand their needs and translate them into ML and Gen AI requirements.\nEffectively communicate complex technical concepts to non-technical audiences.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\nProven expertise in conducting ML maturity assessments and developing ML Ops roadmaps.\nHands-on experience in operationalizing the Machine learning system on a cloud and / or an On-Prem platform.\nExperience in implementing Generative AI solutions, including incubation, design, and deployment will be a big plus.\nProficiency in deep learning frameworks such as TensorFlow and PyTorch.\nGood knowledge of ML Ops best practices and processes.\nExcellent problem-solving skills and ability to design scalable and reliable ML architectures.\nStrong leadership and communication skills, with a track record of leading successful ML initiatives.\nExperience in Telecom or Hi Tech or Software and platform industry desirable\nTools & Techniques\nTensorFlow, PyTorch, Scikit-learn, Keras\nNumPy, Pandas\nMatplotlib, Seaborn\nTensorFlow Serving, Docker and Kubernetes\nGood software engineering practices, including code modularization, documentation, and testing.\nExperience with open API , Integration architecture , microservices\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:4+ years\n\n\n\n\nEducational Qualification:Btech/ BE",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['deep learning frameworks', 'machine learning', 'assessment', 'gen', 'ml', 'kubernetes', 'hi', 'python', 'scikit-learn', 'ai solutions', 'numpy', 'integration architecture', 'docker', 'microservices', 'pandas', 'deep learning', 'tensorflow', 'seaborn', 'matplotlib', 'open api', 'pytorch', 'keras', 'telecom']",2025-06-14 05:37:47
Programmer/Analyst 5,Lam Research,10 - 17 years,Not Disclosed,['Bengaluru'],"The Group You ll Be A Part Of\nLAM HR-Applications team is looking for a passionate, engaging Sr HR Applications Architect to join our growing team. This role will perform Technology evaluation, Identification, Solution Design, Execute the design for entire stack of HR-Applications echo-system and perform Production Support.\nThe Global Information Systems Group is dedicated to the success of Lam through providing best-in-class and innovative information system solutions and services. Together, we support users globally with data, information, and systems to achieve their business objectives.\nThe Impact You ll Make\nDesigns, develops, modifies, debugs and evaluates programs for functional areas, including but not limited to finance, human resources, manufacturing and marketing. Analyzes existing programs or formulates logic for new systems, devises logic procedures, prepares flowcharting, performs coding and tests/debugs programs. Develops conversion and system implementation plans. Prepares and obtains approval of system and programming documentation. Recommends changes in development, maintenance and system standards. Trains users in conversion and implementation of system. May be internal or external, client-focused, working in conjunction with Professional Services and outsourcing functions. May include company-wide, web-enabled solutions.\nWhat You ll Do\nLead design and implementation of the HR systems of the organization across HR technologies\nInterface with business stakeholders, assess feasibility of the requirements and guide the Technology Leads and Implementation teams to align the solution development\nFront-run the transformation and migration initiative in HR Applications COE ensuring a scalable solution to accommodate future enhancements and adoption to all BU s of Lam\nExplore new technologies and practices, be a part of the core team building an HR COE and define the standards and best practices\nAct as a SPOC/L3 for the current product support related activities and the\nHR-Echo System\nCross- training teams on knowledge transfer across business functions\nWho We re Looking For\nExcellent grasp of HR systems (both SAAS & On-Premises) technical and functional\nProven experience leading System Transformation, Integrations, Data Migrations, Implementations, Assessments and Process re-engineering.\n14+ years of experience as an HR Applications Architect\nVery strong communication and collaboration skills\nFlexible to travel and work hours.\nPreferred Qualifications",Industry Type: Electronic Components / Semiconductors,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Architect', 'Production support', 'Coding', 'Flex', 'Manager Technology', 'Process re-engineering', 'HR', 'Outsourcing', 'Product support', 'Team building']",2025-06-14 05:37:49
Business Analytics/Data Scientist - SAS & SQL with BFSI Domain,Khushboo,4 - 9 years,Not Disclosed,['Hyderabad'],"hands-on Analytics experience with 2+ years of experience.\nhands-on experience with one or more data analytics tools including Python, R, SAS, and SQL, SPARK\nGood understanding of credit card industry, financial\nProficiency in Tableau is a plus",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sas', 'Credit Risk Modelling', 'sql', 'Consumer Banking', 'Predictive Modeling', 'python', 'Credit Card Analytics', 'Statistical Modeling', 'credit card', 'Model Development']",2025-06-14 05:37:51
Audit Manager Vice President Data Analytics,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Analytics/Audit Manager, VP to lead audits within a dynamic environment. The person we seek will supervise audits and manage work within our CDO audit team, which is responsible for audit coverage of data management and data risk audit coverage strategy for Internal Audit. This is an individual contributor role.\nIn this role, you will:\nLead execution of the integrated audit process\nParticipate in audits in accordance with Wells Fargo Internal Audit policy",,,,"['Data Analytics', 'data management', 'Project management', 'data governance', 'data quality management', 'Risk management']",2025-06-14 05:37:54
Business Analyst,Centricity Wealth Tech,2 - 7 years,4-5 Lacs P.A.,"['Lucknow', 'Gurugram']","Job Description:\nWe are seeking an experienced MIS Executive with advanced Excel skills to join our team. The ideal candidate will have a minimum of 3 years of experience working with large datasets, creating complex reports, and developing interactive dashboards. This role is crucial in providing insights to management through detailed analysis and data-driven decision-making.\nKey Responsibilities:\nCollect, organize, and analyze large datasets to generate MIS reports.\nCreate and maintain advanced Excel reports, utilizing functions such as VLOOKUP, INDEX-MATCH, PivotTables, and Macros.\nDesign interactive dashboards and visualizations for easy data interpretation.\nTrack key performance indicators (KPIs) and provide actionable insights to stakeholders.\nAutomate reporting processes using Excel to improve efficiency.\nEnsure data integrity and consistency across reports and dashboards.\nCollaborate with various departments to understand their data requirements and deliver customized reports.\nConduct ad-hoc data analysis and assist with strategic decision-making by presenting data clearly.\nMonitor and analyze trends to help senior management make informed business decisions.\nQualifications:\nMinimum 3 years of experience in an MIS Executive or similar data-related role.\nAdvanced proficiency in Microsoft Excel, including PivotTables, VLOOKUP, INDEX-MATCH, advanced formulas, and Macros.\nStrong experience in data analysis, reporting, and dashboard creation.\nFamiliarity with other data visualization tools (e.g., Power BI, Tableau) is a plus.\nExcellent analytical, problem-solving, and organizational skills.\nStrong attention to detail and the ability to work with large datasets efficiently.\nEffective communication skills and ability to present complex data clearly.",Industry Type: Insurance,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['MIS Preparation', 'Advanced Excel', 'MIS Reporting']",2025-06-14 05:37:56
Data Science,Global Banking Organization,5 - 10 years,Not Disclosed,['Bengaluru'],"Key Skills: Machine Learning, Data Science, Azure, Python, Hadoop.\nRoles and Responsibilities:\nStrong understanding of Math, Statistics, and the theoretical foundations of Statistical & Machine Learning, including Parametric and Non-parametric models.\nApply advanced data mining techniques to curate, process, and transform raw data into reliable datasets.\nUse various statistical techniques and ML methods to perform predictive modeling/classification for problems related to clients, distribution, sales, client profiles, and segmentation, and provide actionable insights for business decision-making.\nDemonstrate expertise in the full Machine Learning lifecycle--feature engineering, training, validation, scaling, deployment, scoring, monitoring, and feedback loops.\nProficiency in Python visualization libraries such as matplotlib and seaborn.\nExperience with cloud computing infrastructure like Azure, including Machine Learning Studio, Azure Data Factory, Synapse, Python, and PySpark.\nAbility to develop, test, and deploy models on cloud/web platforms.\nExcellent knowledge of Deep Learning Architectures, including Convolutional Neural Networks and Transformer/LLM Foundation Models.\nStrong expertise in supervised and adversarial learning techniques.\nRobust working knowledge of deep learning frameworks such as TensorFlow, Keras, and PyTorch.\nExcellent Python coding skills.\nExperience with version control tools (Git, GitHub/GitLab) and data version control.\nExperience in end-to-end model deployment and productionization.\nDemonstrated proficiency in deploying, scaling, and optimizing ML models in production environments with low latency, high availability, and cost efficiency.\nSkilled in model interpretability and CI/CD for ML using tools like MLflow and Kubeflow, with the ability to implement automated monitoring, logging, and retraining strategies.\nExperience Requirement:\n5-12 years of experience in designing and deploying deep learning and machine learning solutions.\nProven track record of delivering AI/ML solutions in real-world business applications at scale.\nHands-on experience working in cross-functional teams including data engineers, product managers, and business stakeholders.\nExperience mentoring junior data scientists and providing technical leadership within a data science team.\nExperience working with big data tools and environments such as Hadoop, Spark, or Databricks is a plus.\nPrior experience in managing model lifecycle in enterprise production environments including drift detection and retraining pipelines.\nEducation: B.Tech.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure', 'Hadoop.', 'Machine Learning', 'Python']",2025-06-14 05:37:58
Data Platform Engineer,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models. You will play a crucial role in the development and maintenance of the data platform components, contributing to the overall success of the project.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist with the data platform blueprint and design.- Collaborate with Integration Architects and Data Architects to ensure cohesive integration between systems and data models.- Develop and maintain data platform components.- Contribute to the overall success of the project.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Hyderabad office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'tableau', 'machine learning algorithms', 'statistics', 'data munging', 'python', 'data analysis', 'natural language processing', 'power bi', 'machine learning', 'sql', 'data quality', 'r', 'data modeling', 'data science', 'predictive modeling', 'text mining', 'logistic regression']",2025-06-14 05:38:00
S&C GN - Data&AI - Hi Tech - Data Science - Consultant,Accenture,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Title - S&C Global Network - AI - Hi Tech - Data Science Consultant\n\n\n\nManagement Level:9-Team Lead/Consultant\n\n\n\nLocation:Hyderabad, HDC2A\n\n\n\nMust-have skills:Data Science\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\nWHATS IN IT FOR YOU\nWe are seeking a skilled and experienced Data Scientist to join our Hi-Tech practice.\nThe ideal candidate should have hands-on experience in data science within industries such as semiconductors, enterprise technology, consumer technology, medical technology.\nAs a Data Scientist, you will be responsible for developing AI models/applying GenAI techniques in areas such as marketing & consumer analytics, predictive asset maintenance, production optimization, supply chain, sales & channel partner program analytics, and connected products.\n\n\n\nWhat you would do in this role\nDevelop and implement AI models and GenAI applications to address business challenges in semiconductors, enterprise technology, consumer technology, medical technology and related industries.\nCollaborate with cross-functional teams to gather requirements, design solutions, and deploy models into production environments.\nDevelop and implement GenAI based solutions through contextual prompt engineering and prompt tuning and supporting solution architects on the design of GenAI-powered solutions/assets.\nUtilize your expertise in PLM/ERP/CRM/Contact Center systems to integrate data sources and ensure seamless operation of AI solutions.\nDesign and develop machine learning models using Python, with proficiency in NLP and Computer Vision techniques.\nArchitect functional solutions and provide technical guidance to enhance the performance and scalability of AI systems.\nLeverage cloud platforms, with preference for Azure/GCP, and experience with AWS is also valued.\nStay updated on emerging technologies and industry trends, contributing to continuous improvement initiatives within the organization.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\nProven track record of developing AI models in areas such as channel analytics, marketing & customer experience, supply chain analytics, predictive maintenance, production optimization, and connected products.\nStrong proficiency in Python programming, with experience in NLP and Computer Vision.\nExposure to PLM/ERP/CRM systems and understanding of their integration with AI solutions.\nExperience with cloud platforms, preferably Azure/GCP, and familiarity with AWS.\nKnowledge of LLM exposure and experience with tools such as ChatGPT, Llama 2, Claude 2, Hugging Face, etc. for prompt engineering, prompt tuning, etc will be an advantage.\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'erp', 'natural language processing', 'data science', 'computer vision', 'appium', 'ai solutions', 'cucumber', 'microsoft azure', 'machine learning', 'artificial intelligence', 'eclipse', 'plm', 'deep learning', 'tensorflow', 'java', 'gcp', 'ai techniques', 'aws', 'testng', 'bdd framework', 'crm']",2025-06-14 05:38:02
Data Platform Engineer,Accenture,12 - 15 years,Not Disclosed,['Bengaluru'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Collibra Data Governance\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, encompassing the relevant data platform components. Your typical day will involve collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models, while also engaging in discussions to refine and enhance the overall data architecture. You will be involved in various stages of the data platform lifecycle, ensuring that all components work harmoniously to support the organization's data needs and objectives.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Expected to provide solutions to problems that apply across multiple teams.- Facilitate knowledge sharing sessions to enhance team capabilities and foster a culture of continuous improvement.- Monitor and evaluate team performance, providing constructive feedback to ensure alignment with project goals.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Collibra Data Governance.- Strong understanding of data governance frameworks and best practices.- Experience with data integration tools and techniques.- Familiarity with data modeling concepts and methodologies.- Ability to analyze and interpret complex data sets to inform decision-making.\nAdditional Information:- The candidate should have minimum 12 years of experience in Collibra Data Governance.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data architecture', 'sql', 'data modeling', 'data governance', 'data analysis', 'oracle', 'data management', 'data warehousing', 'business analysis', 'machine learning', 'business intelligence', 'javascript', 'sql server', 'data quality', 'tableau', 'java', 'html', 'mysql', 'etl', 'informatica']",2025-06-14 05:38:05
Sales Excellence - COE - Data Engineering Specialist,Accenture,5 - 8 years,Not Disclosed,['Bengaluru'],"Job Title -\n\n\n\nSales Excellence - COE - Data Engineering Specialist\n\n\n\nManagement Level:\n\n\n\n9-Team Lead/Consultant\n\n\n\nLocation:\n\n\n\nMumbai, MDC2C\n\n\n\nMust-have skills:Sales\n\n\n\n\nGood to have skills:Data Science, SQL, Automation, Machine Learning\n\n\n\nJob\n\n\nSummary:\n\nApply deep statistical tools and techniques to find relationships between variables\n\n\n\n\nRoles & Responsibilities:\n\n- Apply deep statistical tools and techniques to find relationships between variables.\n\n- Develop intellectual property for analytical methodologies and optimization techniques.\n\n- Identify data requirements and develop analytic solutions to solve business issues.\n\nJob Title - Analytics & Modelling Specialist\n\nManagement Level :9-Specialist\n\nLocation:Bangalore/ Gurgaon/Hyderabad/Mumbai\n\nMust have skills:Python, Data Analysis, Data Visualization, SQL\nGood to have skills:Machine Learning\n\nJob\n\n\nSummary:\n\nThe Center of Excellence (COE) makes sure that the sales and pricing methods and offerings of Sales Excellence are effective.\n\n- The COE supports salespeople through its business partners and Analytics and Sales Operations teams.\n\nThe Data Engineer helps manage data sources and environments, utilizing large data sets and maintaining their integrity to create models and apps that deliver insights to the organization.\nRoles & Responsibilities:\n\nBuild and manage data models that bring together data from different sources.\n\nHelp consolidate and cleanse data for use by the modeling and development teams.\n\nStructure data for use in analytics applications.\n\nLead a team of Data Engineers effectively.\nProfessional & Technical\n\n\n\n\nSkills:\nA bachelors degree or equivalent\n\nTotal experience Range:5-8 years in the relevant field\n\nA minimum of 3 years of GCP experience with exposure to machine learning/data science\n\nExperience in configuration the machine learning workflow in GCP.\n\nA minimum of 5 years Advanced SQL knowledge and experience working with relational databases\n\nA minimum of 3 years Familiarity and hands on experience in different SQL objects like stored procedures, functions, views etc.,\n\nA minimum of 3 years Building of data flow components and processing systems to extract, transform, load and integrate data from various sources.\n\nA minimum of 3 years Hands on experience in advanced excel topics such as cube functions, VBA Automation, Power Pivot etc.\n\nA minimum of 3 years Hands on experience in Python\nAdditional Information:\n\nUnderstanding of sales processes and systems.\n\nMasters degree in a technical field.\n\nExperience with quality assurance processes.\n\nExperience in project management.\n\nYou May Also Need:\n\nAbility to work flexible hours according to business needs.\n\nMust have good internet connectivity and a distraction-free environment for working at home, in accordance with local guidelines.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | AccentureQualification\n\n\n\nExperience:8 to 10 Years\n\n\n\n\nEducational Qualification:\n\n\n\nB.Com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analysis', 'sales', 'sql', 'data visualization', 'hive', 'advance sql', 'ssas', 'dbms', 'machine learning', 'data engineering', 'power pivot', 'sql server', 'vba automation', 'data science', 'gcp', 'spark', 'advanced excel', 'hadoop', 'ssis', 'etl', 'big data', 'data flow', 'sql joins']",2025-06-14 05:38:07
Data Governance Practitioner,Accenture,3 - 8 years,Not Disclosed,['Bengaluru'],"Project Role :Data Governance Practitioner\n\n\n\n\n\nProject Role Description :Establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Collaborate with key stakeholders to define data standards, facilitate effective data collection, storage, access, and usage; and drive data stewardship initiatives for comprehensive and effective data governance.\n\n\n\nMust have skills :Snowflake Data Warehouse\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Governance Practitioner, you will establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Your typical day will involve collaborating with key stakeholders to define data standards, facilitating effective data collection, storage, access, and usage, and driving data stewardship initiatives for comprehensive and effective data governance. You will engage in discussions that shape the data governance framework and contribute to the overall data strategy of the organization.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist in the development and implementation of data governance frameworks and policies.- Monitor compliance with data governance policies and report on data quality metrics.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Snowflake Data Warehouse.- Strong understanding of data governance principles and best practices.- Experience with data quality assessment and improvement techniques.- Familiarity with data management tools and technologies.- Ability to communicate complex data concepts to non-technical stakeholders.\nAdditional Information:- The candidate should have minimum 3 years of experience in Snowflake Data Warehouse.- This position is based at our Bengaluru office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'data management', 'warehouse', 'sql', 'data governance', 'hive', 'python', 'data analysis', 'data analytics', 'data warehousing', 'business analytics', 'machine learning', 'business intelligence', 'tableau', 'data science', 'data modeling', 'hadoop', 'sqoop', 'etl', 'informatica']",2025-06-14 05:38:10
"Data Eng, Mgmt & Governance Assoc Mgr",Accenture,10 - 14 years,Not Disclosed,['Bengaluru'],"Skill required: Data Management - Microsoft Fabric\n\n\n\n\nDesignation: Data Eng, Mgmt & Governance Assoc Mgr\n\n\n\n\nQualifications:BE/BTech\n\n\n\n\nYears of Experience:10 to 14 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nData & AIEnd to end, unified analytics platform that brings together existing offerings like Data Factory, Synapse, and Power BI into a single unified product for all your data and analytics workloads.\n\n\n\n\nWhat are we looking for\nMicrosoft Fabric Microsoft Azure PySparkStrong analytical skillsAbility to establish strong client relationshipAbility to manage multiple stakeholdersAbility to perform under pressure\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of moderately complex problems Typically creates new solutions, leveraging and, where needed, adapting existing methods and procedures The person requires understanding of the strategic direction set by senior management as it relates to team goals Primary upward interaction is with direct supervisor or team leads Generally, interacts with peers and/or management levels at a client and/or within Accenture The person should require minimal guidance when determining methods and procedures on new assignments Decisions often impact the team in which they reside and occasionally impact other teams Individual would manage medium-small sized teams and/or work efforts (if in an individual contributor role) at a client or within Accenture\n\nQualification\n\nBE,BTech",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data management', 'data analysis', 'sql', 'data governance', 'etl', 'data analytics', 'data warehousing', 'power bi', 'business analysis', 'business intelligence', 'master data management', 'merchandising', 'data cleansing', 'garments', 'data quality', 'tableau', 'data modeling', 'data profiling']",2025-06-14 05:38:12
Logistics Analyst 4,Lam Research,8 - 12 years,Not Disclosed,['Bengaluru'],"Logistics Analyst, Program Lead\nThe Logistics Analyst will be the point of contact for all SAP TMS system implementation, Training internal team and enhancement as part of Digital transformation\nPrimary Job Responsibilities:\nOperations Support\nRouting guide management\nEnsure booking of shipments for respective Logistics Service Providers (LSP)\nTrack & tracing and exception handling : BN4L exception management\nAbility to quickly react to unforeseen events and communicate with stakeholders as needed\nFreight Rate tender & Freight audit\nBN4L exception management\nFollow SOPs (Standard Operations Procedures) with great attention to details\nSAP TMS Administration & Troubleshooting\nUser management (user set up, onboarding and ongoing support)\nWork with core technical team and Training internal teams on new SAP TMS tools\nMaster data maintenance as needed\nTMS troubleshooting and communication between the user base and TMS BSA/service provider regarding system performance and outages\nSupport standardization and documentation of processes (SOP creation) as needed\nAnalytics\nReport generation and analysis turning data into actionable insights (improving transportation provider selection, route optimization, identifying cost reduction opportunities, etc.)\nGain insight over carrier performance to evaluate trends and pursue advantageous alternatives\nThe Group You ll Be A Part Of\nThe Global Operations Group brings information systems, facilities, supply chain, logistics, and high-volume manufacturing together to drive the engine of our global business operations. We help Lam deliver industry-leading solutions with speed and efficiency, while actively supporting the resilient and profitable growth of Lams business.\nThe Impact You ll Make\nAs a Logistics Analyst at Lam, youll orchestrate and streamline material flow, ensuring efficient supply chain operations and maintaining optimal inventory levels. Your role encompasses a broad set of responsibilities, including supply chain services, inventory control, and ensuring critical parts availability through enterprise warehouse and inventory systems. Your skilled analysis will support production planning and volume studies. Your expertise will be pivotal in optimizing Lams logistics plans for seamless operations.\nWhat You ll Do\nWho We re Looking For\nMinimum 8-12 years working experience in any of the following areas: Global Logistics Project/Program mgt, Global Transportation, SAP TMS & Trade operations in global environment\nPreferred Qualifications\nOur Commitment\nWe believe it is important for every person to feel valued, included, and empowered to achieve their full potential. By bringing unique individuals and viewpoints together, we achieve extraordinary results.\nLam Research (""Lam"" or the ""Company"") is an equal opportunity employer. Lam is committed to and reaffirms support of equal opportunity in employment and non-discrimination in employment policies, practices and procedures on the basis of race, religious creed, color, national origin, ancestry, physical disability, mental disability, medical condition, genetic information, marital status, sex (including pregnancy, childbirth and related medical conditions), gender, gender identity, gender expression, age, sexual orientation, or military and veteran status or any other category protected by applicable federal, state, or local laws. It is the Companys intention to comply with all applicable laws and regulations. Company policy prohibits unlawful discrimination against applicants or employees.\nLam offers a variety of work location models based on the needs of each role. Our hybrid roles combine the benefits of on-site collaboration with colleagues and the flexibility to work remotely and fall into two categories - On-site Flex and Virtual Flex. On-site Flex you ll work 3+ days per week on-site at a Lam or customer/supplier location, with the opportunity to work remotely for the balance of the week. Virtual Flex you ll work 1-2 days per week on-site at a Lam or customer/supplier location, and remotely the rest of the time.",Industry Type: Electronic Components / Semiconductors,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAP', 'Production planning', 'Cost reduction', 'Logistics Analyst', 'Inventory control', 'Analytics', 'Freight', 'Auditing', 'Logistics', 'Business operations']",2025-06-14 05:38:14
Business Analyst,Purplle.com,1 - 4 years,Not Disclosed,['Mumbai'],"As a Business Analyst within our Operations team, you will play a pivotal role in leveraging data-driven insights to optimize processes, enhance operational efficiency, and drive strategic decision-making. Your responsibilities will involve utilizing a mix of technical skills and business acumen to interpret complex data sets, generate actionable insights, and support operational improvements.\n\nKey Responsibilities:\nCollaborate closely with cross-functional teams to understand operational requirements, identify opportunities for improvement, and define key performance indicators (KPIs) to measure success.\n\nAnalyze large datasets using SQL, Python, and advanced Excel techniques to extract, transform, and visualize data for operational reporting and decision making purposes.\n\nDevelop and maintain automated reports and dashboards using Power BI, Power Query, Tableau, Data Studios, Looker, and other visualization tools to communicate insights effectively.\n\nConduct in-depth analysis and interpretation of operational data to identify trends, patterns, and anomalies, providing actionable recommendations to drive operational excellence.\n\nUtilize strong aptitude and logical thinking to solve complex operational challenges and contribute to strategic initiatives that optimize workflows and enhance overall business performance.\n\nFoster strong stakeholder relationships through effective communication, presenting insights, and collaborating on operational strategies and solutions.\n\nRequired Skills and Qualifications:\nBachelor's degree in Business Administration, Data Science, Computer Science, or a related field.\n\nProficiency in SQL, Python, and advanced Excel for data analysis and manipulation.\n\nHands-on experience with Power BI, Power Query, Tableau, Data Studios, Looker, or similar visualization tools.\n\nStrong analytical and problem-solving abilities with a sharp aptitude for logical thinking.\n\nExcellent communication skills and the ability to effectively engage with stakeholders at all levels.\n\nProven track record of successfully managing and prioritizing multiple projects simultaneously in a fast-paced environment.\n\nStrong collaborative skills and the ability to work effectively in a team-oriented culture.\n\nPreferred Qualifications:\nExperience in the e-commerce industry or within a high-growth, dynamic environment.\n\nKnowledge of additional programming languages, statistical tools, or data modeling techniques.\n\nCertifications in business analysis, data visualization, or related fields.",Industry Type: Beauty & Personal Care,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analysis', 'bi', 'strong analytical skills', 'power bi', 'business analysis', 'analysis', 'dashboards', 'sql', 'business administration', 'data studio', 'excel', 'power query', 'tableau', 'data modeling', 'advanced excel', 'data visualization', 'communication skills']",2025-06-14 05:38:17
MIS Executive,Suguna Foods,0 - 5 years,Not Disclosed,['Coimbatore'],A minimum of one year??s experience in feed mill operations is required.\nAbility to work efficiently with MS Office is required.\nProficient in data management and analysis.\nAny Graduation\nUpto 3.5 LPA,,,,"['Data management', 'Corporate', 'MS Office', 'MIS Executive']",2025-06-14 05:38:19
"Analyst III, Technology Operations",Walmart,4 - 9 years,Not Disclosed,['Chennai'],"Position Summary... As an individual contributor, you will create market facing insights to help advertisers understand media performance, optimize media strategy, and generate incremental investment. The individual needs to be analytical and solution-driven with the ability to partner with the larger Strategic Insights & Media Analytics team as well as the Sales & Client Service teams to effectively communicate complex media and measurement insights internally and externally. You will play a critical role in analysing customer behaviour, measurement, and performance data across various channels. You will be responsible for leveraging data-driven insights to analyse client retail media strategy and drive value from long-term investment with Walmart Connect as a trusted strategic consultant and partner for our advertising partners.\nWhat youll do...\nAbout the team\nAt Walmart, we are committed to leading the business side of technology - how we operate, measure success and enact change. This team focuses on that and, areas such as strategic portfolio acceleration, cross-segment tech enablement, tech talent experience (TTX), portfolio foundations and technology business operations.\nWhat You ll Do\nData Analysis & Reporting: Oversee the creation of comprehensive media measurement deliverables in a timely manner, translating data analyses into actionable insights for suppliers and stakeholders.\nStrategic Insight Development: Provide strategic insights and performance reports to our SBU partners and ensure timely and efficient delivery.\nCross-functional Partnerships: Collaborate with cross-functional teams (sales, product marketing, operations, and client services) to align media strategies with overall business objectives.\nTechnical Innovation and Process Improvement: Drive innovation in analytics by implementing new solutions, streamlining processes, and ensuring alignment with industry best practices.\nDemonstrate Leadership Qualities: Provide mentorship and performance management for team members, fostering a culture of excellence and continuous improvement.\nWhat You ll bring\nBachelor s degree in a quantitative field (e.g., Mathematics, Statistics, Economics, Data Science) or equivalent professional experience.\n4+ years of experience in media measurement, digital advertising, or retail media, with a focus on data analytics and reporting.\nProficiency in SQL, Python and/or R as well as data visualization tools (e.g., Tableau, Power BI) to analyze and present insights effectively.\nProven track record in project management, balancing multiple priorities, and delivering high-quality results on time.\nExcellent communication and interpersonal skills, with experience in stakeholder engagement and cross-functional collaboration\nAbout Walmart Global Tech\n.\n.\nFlexible, hybrid work\n.\nBenefits\n.\nBelonging\n.\n.\nMinimum Qualifications...\nMinimum Qualifications:As permitted by applicable law, provide evidence of full vaccination as defined by CDC guidelines OR secure approval of medical or religious accommodation for the vaccination mandate. Option 1: Bachelors degree in computer science, management information systems, industrial engineering, engineering management, business, information systems, project/program management, information technology, finance, management, or related area and 2 years experience in project management, program management, program operations, or related area. Option 2: 4 years experience in project management, program management, program operations, or related area.\nPreferred Qualifications...\nPrimary Location... Rmz Millenia Business Park, No 143, Campus 1B (1St -6Th Floor), Dr. Mgr Road, (North Veeranam Salai) Perungudi , India",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Networking', 'Performance management', 'Project management', 'Process improvement', 'Analytical', 'Information technology', 'Product marketing', 'Business operations', 'SQL']",2025-06-14 05:38:22
Shopper Marketing Analyst,Pepsico,6 - 11 years,Not Disclosed,['Hyderabad'],Overview \n\nThis role will support the Shopper Marketing team in the tracking of agreed KPIs of shopper marketing campaigns as well as post campaign deep dives to develop recommendations needed to optimise performance and shopper targeting of future campaigns. Using the consistent tracking of KPIs and development of recommendations.\n\nThis role will need to be highly analytical and can identify growth driving insights as well as having strong communication and collaboration skills.\n\n \n\n\n,,,,"['marketing', 'marketing campaigns', 'campaigns', 'power bi dashboards', 'marketing analytics', 'data analysis', 'data analytics', 'power bi', 'business analysis', 'business analytics', 'dashboards', 'sql server', 'sql', 'power query', 'tableau', 'advanced excel', 'ssrs', 'dax', 'data visualization']",2025-06-14 05:38:24
"Sr. Analyst, Marketing Strategy & Analytics",Zscaler Softech,3 - 8 years,Not Disclosed,['Bengaluru'],"About Zscaler\nServing thousands of enterprise customers around the world including 40% of Fortune 500 companies, Zscaler (NASDAQ: ZS) was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. As the operator of the world’s largest security cloud, Zscaler accelerates digital transformation so enterprises can be more agile, efficient, resilient, and secure. The pioneering, AI-powered Zscaler Zero Trust Exchange™ platform, which is found in our SASE and SSE offerings, protects thousands of enterprise customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.\nWhat We're Looking for (Minimum Qualifications)\nWhat Will Make You Stand Out (Preferred Qualifications)",,,,"['snowflake', 'python', 'data analysis', 'hypothesis testing', 'insights', 'consulting', 'sfdc', 'roi', 'sql', 'marketing automation', 'analytics', 'salesforce', 'salesforce crm', 'marketing', 'tableau', 'marketing campaigns', 'data science', 'campaigns', 'marketo', 'marketing analytics', 'design', 'google analytics', 'organizing', 'crm']",2025-06-14 05:38:27
Advertising Sales Rep Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Digital Inside Sales - Inside Sales\n\n\n\n\nDesignation: Advertising Sales Rep Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nTransforming sales to become a future-ready and digital B2B revenue engine.The team helps assess, design, build and implement best practices on process, organization, and technology to create, execute, and run a collaborative sales and support roles.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\n\nWhat are we looking for\nProvide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['business development', 'sales', 'inside sales', 'marketing', 'sales analysis', 'data analysis', 'sales forecasting', 'mis reporting', 'market research', 'sales support', 'sales operations', 'lead generation', 'advanced excel', 'mis', 'sales coordination', 'sales planning']",2025-06-14 05:38:29
Advertising Sales Rep Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Digital Inside Sales - Inside Sales\n\n\n\n\nDesignation: Advertising Sales Rep Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nTransforming sales to become a future-ready and digital B2B revenue engine.The team helps assess, design, build and implement best practices on process, organization, and technology to create, execute, and run a collaborative sales and support roles.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\n\nWhat are we looking for\nProvide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.Provide support for lead/opportunity generation:conduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['business development', 'sales', 'inside sales', 'marketing', 'sales analysis', 'data analysis', 'sales forecasting', 'mis reporting', 'market research', 'sales support', 'sales operations', 'lead generation', 'advanced excel', 'mis', 'sales coordination', 'sales planning']",2025-06-14 05:38:31
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Job Title -\n\n\n\nS&C Global Network - AI - Supply Chain Analytics - Analyst\n\n\n\nManagement Level:\n\n\n\n11-Analyst\n\n\n\nLocation:\n\n\n\nPune, PDC6A\n\n\n\nMust-have skills:Data Analytics\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'anaplan', 'data analytics', 'sap', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'supply', 'data preparation', 'tableau', 'descriptive analysis', 'data modeling', 'sap ibp', 'cloud applications', 'ibp', 'data visualization']",2025-06-14 05:38:34
Business Analyst,Freight and Package Transportation,4 - 8 years,15-18 Lacs P.A.,['Kolkata'],"We are seeking an experienced and forward-thinking Senior Business Analyst with a deep understanding of courier logistics and intra-network operations. This role will drive automation  of our intra-branch payment system, support logistics network design, and build scalable  processes integrated with our IT backbone. \n\nKey Responsibilities  \nProcess Automation & Payment Systems  :-\nDesign, develop, and implement an automated intra-branch payment and settlement  system.  \nWork closely with finance, operations, and IT teams to streamline cash and digital  transaction workflows.  \nCreate audit-friendly digital trails and dashboards for real-time reconciliation.  \nLogistics Network Design & Optimization  :-\nCollaborate with leadership to design, redesign, and optimize branch-to-branch movement  and connectivity.  \nPropose cost-effective and time-efficient routing models for shipments across the national  network.  \nLeverage data to suggest new branch locations or closures based on traffic and profitability  analysis.  \nSystems Thinking & IT Collaboration  :-\nPartner with internal tech teams to ensure all operational processes are linked with IT  systems (ERP, CRMs, tracking platforms).  \nDraft user requirements, wireframes, and test cases for tech teams.  \nAdvocate for tech adoption across operations and help with change management.  \nOperational Excellence  :-\nConduct end-to-end mapping of booking, transit, and delivery operations and define  measurable KPIs.  \nIdentify process bottlenecks and recommend/implement solutions.  \nEstablish SOPs and training materials for new systems and processes.  \nData Analysis & Reporting  :-\nBuild and maintain dashboards for key operational and financial metrics.  \nUse insights to influence strategic decisions and operational changes. \nQualifications  \nBachelor's or Masters degree in Engineering, Logistics, Business, or related fields.  \n48 years of experience in business analysis, preferably in logistics/courier/e-commerce  operations.  \nStrong domain understanding of courier network dynamics, cash flow between branches,  and delivery routing.  \nProven experience in process automation, ERP/CRM system integration, and workflow  optimization.  \nAdvanced proficiency in Excel, SQL, Power BI/Tableau and familiarity with tech product  lifecycle.  \nExcellent communication and cross-functional collaboration skills.  \nPreferred Traits  \nEntrepreneurial mindset, thrives in ambiguity.  \nHands-on attitude, willing to visit hubs and branches for on-ground insights.  \nKeen interest in transforming legacy businesses with systems and data.  \nAbility to independently drive initiatives from concept to execution.\nWhy Join Us?  \nBe at the forefront of transforming a legacy logistics business.  \nWork directly with leadership to shape the future of courier logistics in India.  \nGet ownership of high-impact projects that touch operations across the country.",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power BI/Tableau', 'Excel', 'SQL', 'Process Automation', 'ERP/CRM system']",2025-06-14 05:38:36
Business Analyst - MDM,Leading Client,5 - 7 years,Not Disclosed,['Chennai'],"Business Analyst focused on designing and implementing a Data Governance strategy and Master Data Management (MDM) framework.\n\nThis role will support the high-level design and detailed design phases of a transformative project involving systems such as 3DS PLM, SAP, Team Centre, and Blue Yonder.\n\nThe ideal candidate will bring a blend of business analysis expertise, data governance knowledge, and automotive/manufacturing domain experience to drive workshops, map processes, and deliver actionable recommendations.\n\nWorking closely with the GM of Master Data and MDM technical resources, you will play a pivotal role in aligning people, processes, and technology to achieve M&M's data governance and MDM objectives.\n\nKey Responsibilities :\n\n- Requirements Gathering & Workshops: Lead and facilitate workshops with business and IT stakeholders to elicit requirements, define data governance policies, and establish MDM strategies for automotive specific data domains (e.g. , parts, engineering data, bill of material, service parts, supplier and dealer master data).\n\n- Process Mapping & Design: Document and design master data-related processes, including data flows between systems such as 3DS, SAP, Talend, and Blue Yonder, ensuring alignment with business needs and technical feasibility.\n\n- Analysis & Recommendations: Analyse existing data structures, processes, and system integrations to identify gaps and opportunities; provide clear, actionable recommendations to support Data Governance and MDM strategy.\n\n- Stakeholder Collaboration: Act as a bridge between business units, IT teams, and technical resources (e.g. , 3DS specialists) to ensure cohesive delivery of the project objectives.\n\n- Documentation & Communication: Create high-quality deliverables, including process maps, requirement specifications, governance frameworks, and summary reports, tailored to both technical and non-technical audiences.\n\n- Support Detailed Design: Collaborate with the 3DS/Talend technical resource to translate high-level designs into detailed MDM solutions, ensuring consistency across people, process, and technology components.\n\n- Project Support: Assist the MDM Leadership in planning, tracking, and executing project milestones, adapting to evolving client needs.\n\nExperience :\n\nRequired Skills & Qualifications :\n\n- 5+ years of experience as a Business Analyst, with a focus on data governance, master data management (MDM) such as Talend, Informatica, Reltio etc.\n\n- Proven track record of working on auto/manufacturing industry projects, ideally with exposure to systems like 3DS, Team Centre, SAP S/4HANA, MDG, or Blue Yonder.\n\nTechnical Knowledge :\n\n- Strong understanding of MDM concepts, data flows, and governance frameworks.\n\n- Familiarity with auto-specific data domains (e.g. , ECCMA/E-Class Schema).\n\n- Experience with process modelling tools (e.g. , Visio, Lucid chart, or BPMN) and documentation standards.\n\nSoft Skills :\n\n- Exceptional communication and facilitation skills, with the ability to engage diverse stakeholders and drive consensus in workshops.\n\n- Methodical and structured approach to problem-solving and project delivery.\n\n- Ability to summarize complex information into clear, concise recommendations.\n\n- Education: Bachelor's degree in business, Information Systems, or a related field (or equivalent experience).\n\n- Certifications: Relevant certifications (e.g. , CBAP, PMP, or MDM-specific credentials) are a plus but not required.\n\nPreferred Qualifications :\n\n- Prior consulting experience in a client-facing role.\n\n- Hands-on experience with MDG, Talend, Informatica, Reltio etc. or similar MDM platforms.\n\n- Exposure to data quality analysis or profiling (not required to be at a Data Analyst level).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MDM', 'PLM', 'BPMN', 'S/4 HANA', 'Project Management', 'SAP MDG', 'Informatica', 'Talend', 'Data Governance', 'Master Data Services', 'Business Analysis']",2025-06-14 05:38:38
Digital Mktg Advisory Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Marketing Operations - Campaign Analytics & Reporting\n\n\n\n\nDesignation: Digital Mktg Advisory Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English(International) - Proficient\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designEncompasses a set of technologies that enable the process of collecting & analyzing user behavioral activities with different marketing touch points, to reach on a web site or a mobile app with the ultimate aim of enhancing the targeted business goals. It comprises the processes and technologies that enable marketers to evaluate the success of their marketing initiatives, by measuring performance.\n\n\n\n\nWhat are we looking for\nDigital MarketingDigital Marketing CampaignsGoogle AdsMicrosoft ExcelCampaign ManagementStrong analytical skillsResults orientationProblem-solving skillsDetail orientationCommitment to quality\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'marketing', 'marketing operations', 'seo', 'campaign analytics', 'digital analytics', 'python', 'adobe analytics', 'data analysis', 'sas', 'google adwords', 'power bi', 'sql', 'tableau', 'web analytics', 'social media marketing', 'google analytics', 'data visualization']",2025-06-14 05:38:40
Content Mgmt Advisory Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Marketing Operations - Content management\n\n\n\n\nDesignation: Content Mgmt Advisory Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designOrganize, categorize and publish content and information using specific tools and channels, for use by different groups and individuals within the organization.\n\n\n\n\nWhat are we looking for\nCommitment to quality Process-orientation Detail orientation Written and verbal communication Strong writing and editing background, preferably with a portfolio of past work Experience in corporate communications and project management Experience with remote, cross-functional teams and communicating with shareholders Ability to analyze data that drives business decisions Excellent organization and communication skills, good at managing projects Proficiency with the Google suite a plus Ability to work in a fast-paced, deadline-driven environmentHigh school diploma required, Associates preferred. Will accept equivalent workexperience (2-3 years) in lieu of degree.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shiftsReplicate/copy provided content, ensuring accurate transcription and duplicationCreate, edit and publish content for various topics, including strategy, organizationalmanagement, education and help center supportWork closely with POCs and SMEs to formulate content relevant for the task/scope of theassignmentSeeks opportunities to improve knowledge, skills, and performance by reviewingknowledge base content, practicing skills and being receptive to coaching andconstructive feedbackProduce documents that convey strategy, status, reorganization, scope, timelines, taskplanning, action items, risks, issues, project dependencies, test planning, or rolloutplanningMonitor project performance and timelines, setting and meeting deadlines as necessaryMaintain confidentiality of our partners contentAble to function well with a team in a highly-collaborative cross-functional environment,but still able to work as an individual contributor to track down answers to properlyformulate contentAbility to think on your feet and adapt to changing circumstances and situations\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Content, Editorial & Journalism","Employment Type: Full Time, Permanent","['digital marketing', 'content management', 'editing', 'google suite', 'content analysis', 'data analysis', 'dns', 'content editing', 'content development', 'system administration', 'windows system administration', 'active directory', 'content writing', 'windows server', 'dhcp']",2025-06-14 05:38:43
Paid Search Analyst,Merkle Science,2 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Paid Search campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nProvides initial insights on campaign trends to executives and planners\nLocation:\nDGS India - Chennai - Anna Nagar Tyche Towers\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['QA', 'Analyst', 'Data analysis', 'Management']",2025-06-14 05:38:45
Business Analyst,Comunus Technologies,8 - 10 years,1-6 Lacs P.A.,"['Navi Mumbai', 'Pune', 'Mumbai (All Areas)']","ComUnus is #hiring Business Analyst NBFC !!\nExperience: 8+ Years\nLocation: Mumbai (Vikhroli)\nMax NP : Immediate Joiners are preferred\n\nPreferred Candidate : Mumbai\nKindly Note : Immediate Joiners are preferred !!\n\nInterested Candidates Share there CV on : vidhi.bhatti@comunus.in | 8591723284\n\nJob Description:\n\nAs a Business Analyst, you will play a crucial role in analyzing business requirements, optimizing financial processes, and supporting technology-driven solutions within the NBFC sector. You will collaborate with stakeholders, product teams, and IT professionals to enhance operational efficiency and drive business growth.\n\nKey Responsibilities:\n1. Requirement Gathering & Analysis: Work closely with stakeholders to understand business needs and translate them into functional specifications.\n2. Process Optimization: Identify inefficiencies in NBFC operations and propose solutions to improve workflow and financial services.\n3. Regulatory Compliance: Ensure adherence to RBI guidelines and other financial regulations applicable to NBFCs.\n4. Data Analysis & Reporting: Utilize data analytics to generate insights, track KPIs, and support decision-making.\n5. Technology Implementation: Collaborate with IT teams to implement digital solutions, including loan management systems, risk assessment tools, and customer portals.\n6. Stakeholder Communication: Act as a bridge between business teams and technical teams, ensuring smooth execution of projects.\n7. Product Development Support: Assist in designing and launching new financial products tailored for NBFC customers.\n\nRequired Skills:\n1. Strong knowledge of NBFC operations, lending, and financial products.\n2. Expertise in business analysis methodologies and process reengineering.\n3. Experience with data analytics tools (Excel, SQL, Power BI, etc.).\n4. Familiarity with loan management systems and financial software.\n5. Understanding of RBI regulations and compliance requirements.\n6. Excellent communication and stakeholder management skills.\n\nExperience Required:\n1. Prior experience in NBFCs, Banks, or FinTech companies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business analyst', 'excel', 'Power Bi', 'Brd', 'NBFC', 'FRD', 'SQL']",2025-06-14 05:38:47
GN - SONG - Service - CX - Value Architect - Analyst,Accenture,2 - 5 years,Not Disclosed,['Gurugram'],"Template\n\nJob Title - GN - SONG - Service - CX - Value Architect - Analyst\n\nManagement Level :11 - Analyst\n\nLocation:Delhi, Gurgaon, Mumbai, Bangalore, Chennai, Pune, Hyderabad\n\nMust have skills:Value Realization\n\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute\n\nJob\n\n\nSummaryAs part of the team, you will provide transformation services driven by key offerings like Living Marketing, Connected Commerce and Advanced Customer Engagement. These services help our clients become living businesses by optimizing their marketing, sales and customer service strategy, thereby driving cost reduction, revenue enhancement, customer satisfaction and impacting front end business metrics in a positive manner.\nRoles & ResponsibilitiesTranslate strategic objectives into high-impact use cases in the specific area of expertise.\nUnderstand clients business priorities and focus areas to identify the right business scenarios and impacted value levers (KPIs) to include in the business case.\nIdeate and execute on compelling value creation workshops.\nConduct detailed qualitative and quantitative research to lay the foundation of a strong business case.\nOwn every stage of the value creation process, from research and identification to value drafting and dashboarding.\nDefine value architecting requirements and work with Accenture teams to deliver solutions.\nAdvise clients on industry best practices (when appropriate).\nAccurately estimate time to complete work.\nContinually experiment with new tools, technologies and sharpen analytical skills.\nAbility to research and provide strategic, goal-driven solutions for clients.\nCollaborate with other value architects, both offshore & onshore, including client-side managers, business heads, and other stakeholders across the organization.\nProvide useful contributions to team meetings and conversations, actively participating in client meetings and workshops- Ability to create hypothesis based on understanding of clients issues.\nProfessional & Technical\n\n\n\n\nSkills:\nApply best of breed Excel practices- Deep-dive with solid knowledge of formulas & macros to bring in speed & efficiency.\nMaximize experience in developing interactive models:Use relevant dashboard creation platforms (Power BI, Tableau, etc.) to design and apply interactive dashboards.\nInnovate with Creativity:Demonstrate an ability to work in a fast-paced environment with the ability to abstract value into compelling business story.\nParticipate in pre-sales activities including response to RFPs, creating proofs of concept, creating effective presentations, demonstrating solutions during client orals, effort and cost estimation process, etc.\nParticipate in practice-specific initiatives including creating points of view, creating reusable assets on contact center space, performing analysis on industry research and market trends and bringing in innovative solutions, etc.\nAdditional InformationGood understanding of sales, service & marketing as a function\nSolid experience in developing quantitative models.\nConducting qualitative & quantitative research\nAnchoring client/senior stakeholder conversations\nCreating engaging storyboards using the best data visualization tools such as Power BI, Tableau, etc.\n\nAbout Our Company | AccentureQualification\nExperience:2-5 years of experience in strategy/value office & consulting roles with P&L exposure\nEducational Qualification:MBA from a tier 1 institute",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ssas', 'bi', 'power bi', 'sql', 'tableau', 'python', 'data analysis', 'oracle', 'data warehousing', 'pivot table', 'microsoft azure', 'business analysis', 'vlookup', 't-sql', 'business intelligence', 'sql server', 'plsql', 'data modeling', 'advanced excel', 'ssrs', 'data visualization', 'ssis', 'etl', 'msbi']",2025-06-14 05:38:50
Senior Analyst,Vestas,4 - 7 years,Not Disclosed,['Chennai'],"The main purpose of this position is to support Digital Procurement products and day-to-day handling of the L1/ L2 technical incidents, ensuring smooth operation, optimization, and continuous improvement of procurement systems such as SAP Ariba, ECC or similar platforms, reporting to Procurement System Support Team Manager. The Senior Analyst works with Digital Procurement Product owners, Direct/Indirect procurement buyers, Purchasers Sourcing responsible to support system bugs/errors or route enhancement requests from line of business in the production system such as SAP Ariba, Go Buy and Ariba buyer network. The successful person must be a self-starter and could work on their own with Digital Procurement Product Owners, Line of Business and technical teams. Its key that they could build up relationships with the business and gain credibility and respect to fully engage the business users in the Procurement operations.",,,,"['Automation', 'Data analysis', 'SAP', 'Social media', 'System integration', 'Incident management', 'MS Office', 'Information technology', 'Monitoring', 'Ariba']",2025-06-14 05:38:52
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Noida'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 - 5 Years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Business Reporting and Governance vertical helps to deploy and deliver robust tracking mechanism for SLA/KPI or any other operations on a day-to-day basis. The Governance team will be responsible for contractual compliance of various aspects of contract like Governance, Reporting, Incident Management, Change Management and Survey Management along with driving automation and analytics. Assessing, managing, using, improving, monitoring, maintaining, and protecting organizational information through a system of decision rights and accountabilities for information related processes, executed according to agreed-upon models which describe who can take what actions, with what information, when, under what circumstances and using what methods. Candidate who is good in excel and MIS reports are looked at for these skillsIn Reporting and Analytics, you will have to prepare management reports and analysis, both recurring and ad-hoc. This includes focusing on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nEffective communication and organization skills with Polished, professional presence Experience in reporting of contractual metrics and operational KPIs Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Proficient in MS Office with advance knowledge in excel formulas. Ability to create Nice & User friendly excel dashboards. Ability to create meaningful presentation through PowerPoint. Working Knowledge in Power Automate, Power Apps, PowerBi Basic Automation abilities using VBA Macros Good Understanding of processes like (e.g., F&A, Marketing Operations, HR, Procurement and Supply Chain)\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Create and Design New Dashboard / Reports as required. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts. Connect with Stakeholders and drive governance around performance metrics. Play Individual Contributor or Manage a team dedicated for the assignment and drive performance.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business reporting', 'vlookup', 'reporting and analytics', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'business analysis', 'power bi', 'business analytics', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'powerapps', 'tableau', 'data visualization']",2025-06-14 05:38:54
Software Engineering Lead Analyst,A Large Global Organization,6 - 7 years,Not Disclosed,['Hyderabad'],"Key Skills: Java, Change Management, Release Management, Build & Release.\nRoles and Responsibilities:\nAnalyze change and tool metrics to identify trends and automation opportunities for improved efficiency.\nUtilize professional knowledge to develop models, procedures, and monitor trends within Release and Change Management scope.\nDemonstrate an understanding of End-to-End Release and Change Management processes (including ITIL, SOX, and SOC1 Controls).\nApply systems analysis skills within an Agile development environment to deliver high-quality release management solutions.\nParticipate in daily team standups to provide and receive updates on backlog and challenges.\nWork closely with development teams to ensure seamless deployment of applications, minimizing disruptions.\nCollaborate with cross-functional teams to improve software reliability using Failure Modes and Effects Analysis (FMEA).\nMaintain release documentation, ensuring compliance with regulatory and business requirements.\nLeverage AI technologies and automation tools to optimize release processes.\nProvide expertise on cloud technologies, including AWS and OpenShift, to facilitate deployment and scalability.\nExperience Requirements:\n6-7 years of experience in software development, release management, or change management.\nStrong understanding of Release and Change Management frameworks and ITIL processes.\nHands-on experience with basic coding languages, including Java, Java Spring Boot, React JS.\nExposure to JSON and Python for automation and data analysis.\nExperience with cloud platforms, including AWS and OpenShift.\nKnowledge of AI technologies and their application in software release automation.\nFamiliarity with SOX, SOC1 compliance, and IT controls for regulated environments.\nUnderstanding of healthcare business processes and associated regulatory requirements.\nBasic knowledge of FMEA and software reliability principles.\nStrong analytical and problem-solving skills, with a focus on process improvement.\nExcellent communication and collaboration skills to work effectively across teams.\nPrior experience in healthcare IT is a strong plus.\nProven ability to work in an Agile development environment and participate in scrum ceremonies.\nEducation: Any Post Graduation, Any Graduation.",Industry Type: Medical Services / Hospital,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Change Management', 'Java', 'Build & Release.', 'Release Management']",2025-06-14 05:38:57
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Record To Report - Financial Analysis\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Design and implementation of tools and processes which enable the client to perform financial analysis of its statements. Involves the ability to assess materiality and volatility of financial statement line items and key metrics utilizing financial ratios to determine the financial health of the company.\n\n\n\n\nWhat are we looking for\nPosting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['financial analysis', 'journal entries', 'forecasting', 'reporting analysis', 'record to report', 'hlookup', 'tds', 'service operations', 'data analysis', 'mis reporting', 'pivot table', 'vlookup', 'accounting', 'autocad', 'sql', 'kaizen', 'tableau', 'solid works', 'advanced excel', 'mis']",2025-06-14 05:38:59
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Gurugram'],"Skill required: Reinsurance - Collections Processing\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom/Chartered Accountant/PGDBM\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English - Advanced\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe help insurers redefine their customer experience while accelerating their innovation agenda to drive sustainable growth by transforming to an intelligent operating model. Intelligent Insurance Operations combines our advisory, technology, and operations expertise, global scale, and robust ecosystem with our insurance transformation capabilities. It is structured to address the scope and complexity of the ever-changing insurance environment and offers a flexible operating model that can meet the unique needs of each market segment.Canceling and rewriting insurance policies and endorsementsThe Collections Operations team focuses on managing collections and disputes such as debt collection, reporting on aged debt, bad debt provisioning, trade promotions, and outperform cash reconciliations. The team is responsible for follow up for missing remittances, prepare refund package with accuracy and supply to clients, record all collections activities in a consistent manner as per client process (tool), delivery of process requirements to achieve key performance targets, and ensure compliance to internal controls, standards, and regulations.\n\n\n\n\nWhat are we looking for\nAccounting & Financial Reporting StandardsFinancial AnalysisFinancial Consolidation & Close OperationsBalance Sheet Account ReconciliationsAbility to manage multiple stakeholdersWritten and verbal communicationCommitment to qualityAbility to perform under pressure\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom,Chartered Accountant,PGDBM",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounting', 'reinsurance', 'reporting analysis', 'financial reporting', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'power bi', 'vlookup', 'dashboards', 'sql', 'tableau', 'trade', 'vba', 'advanced excel', 'mis']",2025-06-14 05:39:01
Financial Planning Analysis - Associate,JPMorgan Chase Bank,5 - 10 years,Not Disclosed,['Mumbai'],"You are a strategic thinker passionate about driving solutions in Finance. You have found the right team. As a Financial Analysis professional in our Corporate Investment Banking, you will spend each day defining, refining and delivering set goals for our firm\nYour team will be Sales PA Infrastructure team , which is responsible for managing core reference data, overseeing various data collection tools and driving standardized reporting initiatives. The team drives strategies to enhance the integration of core data across various platforms and drive our tools to state of the art technologies. The Infrastructure team acts in a broad array of roles that include business analysis, project management, report writing, database development, database management, system administration and end user training. Creative aspects of these responsibilities include creation of innovative solutions to management information, data analysis and reporting. The team is currently working a developing a data analysis platform built around Alteryx and a comprehensive data library which will drive the automation of numerous data intensive, repetitive and mundane tasks. Tools like Tableau, Alteryx, Qlikview Qliksense are also relied on to provide enhanced visualization and self-service reporting. You will act as a business liaison and subject matter expert responsible for the ongoing development and administration of various reporting initiatives and platforms (i. e. XIB Business Objects, WCP Cognos, Alteryx, Tableau) and various business tools (i. e. SCRIBE, Clover, iODS ( Team Workflow, Tagging, etc. ). You will require a strong understanding of the end to end business needs, alignment to tools and corresponding technical capabilities.\nJob Responsibilities\nServe as the subject matter expert for the Alteryx COE Integration Scheduling process.\nOversee the design, development, and delivery of standard reports, automation workflows, and dashboard tools.\nEnsure system management, administration, and testing. Manage reference data, user support, communications, training, and inquiry management.\nCreate innovative solutions to meet management reporting needs. Interact with technical teams to enhance and troubleshoot system issues and inefficiencies.\nCoordinate the collection of system requirements for the consolidated reporting initiative. Assist in QA UA testing.\nDevelop and manage proof of concept tools (Tableau, Alteryx, etc. ) to drive requirements for strategic solutions.\nSupport the heritage toolset and assume responsibilities for user support and data management.\nEnhance the efficiency and consistency of the reporting environment. Improve ad-hoc reporting capabilities for a broad user community.\nBuild commonly used formulas and variables into the reporting universe.\nOrganize, clearly label, and assign meaningful descriptions to reporting elements. Design supporting databases efficiently to maximize performance.\nCollaborate with broader sales support and business management teams to design effective solutions for management reporting needs.\nRequired qualifications, capabilities, and skills\nBachelor s Degree Required with minimum 4 years of experience in reporting, automation and/or dashboard development\nRequired technical skills Tableau and Alteryx, Pitchpro+, SAP Business objects, Cognos\nInnovative, self-motivated and solutions oriented. Extensive working knowledge of system management practices\nAbility to be flexible, follow tight deadlines, organize and prioritize work and multi-task in a fast paced environment.\nHighly motivated, able to thrive, comfortable with frequently changing priorities and think clearly under pressure and tight deadlines.\nAbility to work with all levels of employees and have a strong presence enabling effective influencing, interaction, and communication with senior management. Proven ability to work independently with minimal guidance. Excellent written and oral communication skills; and demonstrated ability to interact with technical, non-technical, and business members of the organization\nPreferred qualifications, capabilities, and skills\nAdditional Technical skills are a plus Superior skills in SQL, Python, or other scripting language Qlik Sense\nSubject matter knowledge of finance and business management functions and/or banking technologies/infrastructure a plus",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Data analysis', 'SAP', 'Data management', 'Financial analysis', 'Business analysis', 'Project management', 'Workflow', 'Scheduling', 'Investment banking', 'SQL']",2025-06-14 05:39:03
Business Analyst,Hidden Brains Infotech,4 - 9 years,Not Disclosed,['Ahmedabad'],Requirements Gathering and Analysis\nProcess Modeling & Improvement\nStakeholder Management\nSolution Evaluation & Validation\nData Analysis and Reporting\nDocumentation\nChange Management,Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Requirement Gathering', 'Business Analysis', 'Client Interaction', 'Post Sales']",2025-06-14 05:39:06
Project Management - Associate,JPMorgan Chase Bank,0 - 4 years,Not Disclosed,['Bengaluru'],"You are a strategic thinker passionate about driving solutions in financial analysis. You have found the right team.\nAs a Project Management Associate within the national branch team, you will coordinate the escheatment process outreach, manage cases for terminated advisors, handle rejected money movements, track and ensure compliance with penny stock procedures, and conduct EVP escalations resolutions. You will also serve as a backup for other critical processes, engaging directly with Advisors and Field Leaders to perform key tasks as part of the national branch book of work. You will work with market directors and regional directors to resolve queries, manage mailboxes, and report critical tasks for control requirements. You will influence partners to promote process improvement and collaborate with global teams to meet reporting and control task requirements.\nJob Responsibilities\nPerform key tasks assigned as part of national branch book of work\nWork with market directors and regional directors to resolve queries\nEnsure mailbox management and reporting of critical tasks for control requirements\nInfluence internal and external partners and promote process improvement\nCollaborate with global teams and SMEs to ensure adhoc requirements are met for reporting requirements and control task\nUpdate accounts to add or remove assigned restriction code\nPerform other need based remediation, reporting, reconciliation activities which support the field leaders\nRequired qualifications, capabilities, and skills\nMinimum 5 years experience with transaction processing, query resolution, stakeholder reporting and MIS\nCustomer service experience and strong understanding of operational controls\nExperience working with multiple global stakeholders in a banking or financial services function\nStrong problem-solving skills and relationship management skills\nStrong written and verbal communication skills\nHands on experience working with large data\nPreferred qualifications, capabilities, and skills\nBachelor s degree required, CFA/CMA/CA/MBA (Operations) an advantage\nExcellent communication (verbal and written) skills\nProficiency in Microsoft Office (especially Excel and PowerPoint)\nExperience in using Data extraction and Data analysis",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Data analysis', 'Financial analysis', 'MIS', 'Project management', 'CMA', 'Process improvement', 'Reconciliation', 'Customer service', 'Operations', 'Financial services']",2025-06-14 05:39:08
Data Scientist,Mastercard,4 - 8 years,Not Disclosed,['Gurugram'],"As consumer preference for digital payments continues to grow, ensuring a seamless and secure consumer experience is top of mind. Optimization Soltions team focuses on tracking of digital performance across all products and regions, understanding the factors influencing performance and the broader industry landscape. This includes delivering data-driven insights and business recommendations, engaging directly with key external stakeholders on implementing optimization solutions (new and existing), and partnering across the organization to drive alignment and ensure action is taken.\n\nThe Role:\n\nWork closely with global optimization solutions team to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data to support data insights and analytical needs across products, markets, and services\nThe candidate for this position will focus on Building solutions using Machine Learning and creating actionable insights to support product optimization and sales enablement.\nPrototype new algorithms, experiment, evaluate and deliver actionable insights.\nDrive the evolution of products with an impact focused on data science and engineering.\nDesigning machine learning systems and self-running artificial intelligence (AI) software to automate predictive models.\nPerform data ingestion, aggregation, and processing on high volume and high dimensionality data to drive and enable data unification and produce relevant insights.\nContinuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nA superior academic record at a leading university in Computer Science, Data Science, Technology, mathematics, statistics, or a related field or equivalent work experience\nExperience in data management, data mining, data analytics, data reporting, data product development and quantitative analysis\nStrong analytical skills with track record of translating data into compelling insights\nPrior experience working in a product development role.\nknowledge of ML frameworks, libraries, data structures, data modeling, and software architecture.\nproficiency in using Python/Spark, Hadoop platforms & tools (Hive, Impala, Airflow, NiFi), and SQL to build Big Data products & platforms\nExperience with Enterprise Business Intelligence Platform/Data platform ie Tableau, PowerBI is a plus.\nDemonstrated success interacting with stakeholders to understand technical needs and ensuring analyses and solutions meet their needs effectively.\nAbility to build a strong narrative on the business value of products and actively participate in sales enablement efforts.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data management', 'Data modeling', 'Information security', 'Machine learning', 'Data structures', 'Data mining', 'Business intelligence', 'SQL', 'Python']",2025-06-14 05:39:11
S&C - GN - CFO EV - RC - Analyst,Accenture,1 - 3 years,Not Disclosed,['Mumbai'],"Job Title Risk and Compliance- Analyst- S&C GN-CFO&EV\n\n\n\nManagement Level:11 Analyst\n\n\n\nLocation:Gurgaon, Mumbai, Bangalore, Pune, Hyderabad\n\n\n\nMust have skills:Risk modelling\n\n\n\n\nGood to have skills:Credit risk, Market risk, Liquidity risk\n\n\n\nExperience:1-3 years\n\n\n\n\nEducational Qualification:MBA(Finance) or CA or CMA\n\n\n\nJob\n\n\nSummary:\nAdvise financial and non-financial Institutions across risk management areas such as risk strategy, transformation programs, enterprise risk, portfolio management, capability maturity assessments, fraud and financial crime risk compliance.\nPartner with global deal teams in selling, shaping and solution development of client deals by providing subject matter expertise on risk related topics.\nShape thought capital around current and emerging risk management topics and contribute to development of Accenture points-of-view on risk trends and issues.\nSupport practice development through various activities such as staffing, quality management, capability development and knowledge management.\nBuild strong relationships with global Accenture Risk Management teams, and develop existing relationships based on mutual benefit and synergies.\n\n\n\n\nRoles & Responsibilities:\nGood project management skills and demonstrated experience in managing teams across functions and geographies\nStrong business acumen and knowledge of risk management process\nAbility to solve complex business problems and deliver client delight\nStrong writing skills to build point of views on current industry trends\nGood analytical and problem-solving skills with an aptitude to learn quickly\nExcellent communication, interpersonal and presentation skills\nCross-cultural competence with an ability to thrive in a dynamic consulting environment\n\n\nQualification\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\nMBA from Tier-1 B-schools with specialization in risk management\n2-5 years of risk management experience at one or more Financial Services institutions, Rating Agency or Professional Services OR Risk Advisory with an understanding of one or more of the following areas:\n\n\n\n\nCredit risk measurement for the purpose of financial instruments impairment and/or capital requirements calculation (PD, LGD, EAD methodologies), Credit Risk Underwriting Frameworks, Risk Based Pricing, Early Warning Systems, Credit Policy & Limit Management, Collections Frameworks, Counterparty credit risk management and experience on counterparty risk methodologies such as PFE, EPE.\n\n\n\n\nMarket risk measurement and management-related topics including operational processes, technologies, modelling approaches, risk aggregation and reporting, FRTB:Expected Shortfall, Default Risk Charge, NMRF; IBOR or LIBOR Transition experience.\n\n\n\n\nOperational risk management\n\n\n\nframework and methodology.\n\n\n\n\nLiquidity risk measurement, reporting and management, balance sheet framework, contingency funding requirement\n\n\nHands-on experience in VaR/SVaR/IRC/CRM calculations for variety of financial instruments across Currencies, Credit, Commodities and Rates; In-depth understanding of new/evolving regulations in the Market Risk management space including treatment of off-balance sheet exposures, proprietary trading, systemic risk, stress testing, capital calculations, reporting standards etc.\nTreasury experiences in areas such as Asset Liability Management, Fund Transfer Pricing, and Interest Rate Risk in Banking Book with FO touchpoints.\nHands-on experience in developing risk registers, conducting RCSAs, defining KRIs for risk management and control indicators, Risk Scenario Library & Analysis, Cyber and Tech Risk & Controls Assessment, SOX Compliance/ Internal Controls over Financial Reporting (ICOFR).\nRegulatory reporting compliance-European reg. reports:FINREP/COREP/Anacredit. Experience in platforms like Axiom, Wolters Kluwer etc.\nExperience in managing financial crime and compliance with a focus on fraud risk management, compliance/AML analytics, enterprise risk management (financial services and non-financial services), data analysis & aggregation, trade surveillance, robotic process automation. Experience in platforms like Quantexa, Actimize, Featurespace etc.\nUsing Open AI in Modelling\nEnterprise Risk Management experience\nStrong understanding of risk regulatory framework of one more of the major economies across globe\nKnowledge of Risk Platforms such as Sungard, Murex, Sungard , Calypso, OpenPage, Fenergo, PEGA, JIRA, SAP HANA, Bloomberg, Reuters, and so on\nExperience in third-party risk consulting will be preferred. Prior Risk Consulting experience at pre-eminent, global risk management consulting firms desirable\nIndustry certifications such as FRM, PRM, CFA preferred\n\n\n\n\n\nAdditional Information:\nAn opportunity to work on\n\n\n\ntransformative projects with key G2000 clients\nPotential to\n\n\n\nCo-create with leaders in strategy, industry experts, enterprise function practitioners and, business intelligence professionals to shape and recommend innovative solutions that leverage emerging technologies.\nAbility to embed\n\n\n\nresponsible business into everythingfrom how you service your clients to how you operate as a responsible professional.\nPersonalized training modules to develop your\n\n\n\nstrategy & consulting acumen to grow your skills, industry knowledge and capabilities\nOpportunity to thrive in a\n\n\n\nculture that is committed to accelerate equality for all. Engage in boundaryless collaboration across the entire organization.\n\nAbout Our Company | Accenture",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['risk management', 'risk modeling', 'regulatory', 'presentation skills', 'business acumen', 'financial analysis', 'project management', 'credit risk', 'bloomberg', 'risk consulting', 'sungard', 'murex', 'reuters', 'fenergo', 'calypso', 'financial reporting', 'actimize', 'pega', 'sap hana', 'ca', 'jira', 'cfa']",2025-06-14 05:39:13
Data Scientist,Dynamic Yield,5 - 10 years,Not Disclosed,['Gurugram'],"Our Purpose\nMastercard powers economies and empowers people in 200+ countries and territories worldwide. Together with our customers, we re helping build a sustainable economy where everyone can prosper. We support a wide range of digital payments choices, making transactions secure, simple, smart and accessible. Our technology and innovation, partnerships and networks combine to deliver a unique set of products and services that help people, businesses and governments realize their greatest potential.\nTitle and Summary\nData Scientist\nWho is Mastercard?\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships, and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOur Team:\nAs consumer preference for digital payments continues to grow, ensuring a seamless and secure consumer experience is top of mind. Optimization Soltions team focuses on tracking of digital performance across all products and regions, understanding the factors influencing performance and the broader industry landscape. This includes delivering data-driven insights and business recommendations, engaging directly with key external stakeholders on implementing optimization solutions (new and existing), and partnering across the organization to drive alignment and ensure action is taken.\nAre you excited about Data Assets and the value they bring to an organization?\nAre you an evangelist for data-driven decision-making?\nAre you motivated to be part of a team that builds large-scale Analytical Capabilities supporting end users across 6 continents?\nDo you want to be the go-to resource for data science & analytics in the company?\n\n\nThe Role:\n\nWork closely with global optimization solutions team to architect, develop, and maintain advanced reporting and data visualization capabilities on large volumes of data to support data insights and analytical needs across products, markets, and services\nThe candidate for this position will focus on Building solutions using Machine Learning and creating actionable insights to support product optimization and sales enablement.\nPrototype new algorithms, experiment, evaluate and deliver actionable insights.\nDrive the evolution of products with an impact focused on data science and engineering.\nDesigning machine learning systems and self-running artificial intelligence (AI) software to automate predictive models.\nPerform data ingestion, aggregation, and processing on high volume and high dimensionality data to drive and enable data unification and produce relevant insights.\nContinuously innovate and determine new approaches, tools, techniques & technologies to solve business problems and generate business insights & recommendations.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nA superior academic record at a leading university in Computer Science, Data Science, Technology, mathematics, statistics, or a related field or equivalent work experience\nExperience in data management, data mining, data analytics, data reporting, data product development and quantitative analysis\nStrong analytical skills with track record of translating data into compelling insights\nPrior experience working in a product development role.\nknowledge of ML frameworks, libraries, data structures, data modeling, and software architecture.\nproficiency in using Python/Spark, Hadoop platforms & tools (Hive, Impala, Airflow, NiFi), and SQL to build Big Data products & platforms\nExperience with Enterprise Business Intelligence Platform/Data platform i.e. Tableau, PowerBI is a plus.\nDemonstrated success interacting with stakeholders to understand technical needs and ensuring analyses and solutions meet their needs effectively.\nAbility to build a strong narrative on the business value of products and actively participate in sales enablement efforts.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor.\nCorporate Security Responsibility\n\nAll activities involving access to Mastercard assets, information, and networks comes with an inherent risk to the organization and, therefore, it is expected that every person working for, or on behalf of, Mastercard is responsible for information security and must:\nAbide by Mastercard s security policies and practices;\nEnsure the confidentiality and integrity of the information being accessed;\nReport any suspected information security violation or breach, and\nComplete all periodic mandatory security trainings in accordance with Mastercard s guidelines.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data management', 'Data modeling', 'Information security', 'Machine learning', 'Data structures', 'Data mining', 'Business intelligence', 'SQL', 'Python']",2025-06-14 05:39:15
"Data Scientist - Noida , Pune , Chennai",R Systems International,4 - 8 years,Not Disclosed,"['Noida', 'Pune', 'Chennai']","Looking for experienced Data Scientist Candidates.\nJob Description\nLeveraging knowledge in analytical and statistical algorithms to assist stakeholders in improving their business\nPartnering on the design and implementation of statistical data quality procedures for existing and new data sources\nCommunicating complex data science solutions, concepts, and analyses to team members and business leaders",,,,"['Data Scientist', 'Artificial Intelligence', 'Natural Language Processing', 'LLM', 'Data Science', 'Machine Learning', 'Deep Learning']",2025-06-14 05:39:18
Process QA Analyst,The Coca-Cola CompanyÂ,4 - 5 years,Not Disclosed,['Pune'],"Location(s):\nIndia\nCity/Cities:\nPune\nTravel Required:\n00% - 25%\nRelocation Provided:\nYes\nJob Posting End Date:\nJune 15, 2025\nShift:\nJob Description Summary:\nA. JOB SUMMARY: Describe the Purpose of this job in 2-3 Sentences.\nBuild a Total Quality Management culture by driving/developing the capabilities of the Associates on Quality aspects on the job and to evaluate process/equipment capabilities through the Validations and Process Monitoring.\nEnsure manufacturing processes/process quality activities are followed in compliance with KORE ISO, GMP and local regulation requirements by developing providing SOP s for plant processes and timely technical support and decision on the quality problem, observation to protect product s integrity and specification and final disposition of customer complains/feedback.\nEstablish and maintain an effective, governed and documented system for all company processes, which is integrated compliant to its entire applicable standard references and capable of meeting company requirements continually.\nEvaluate new packaging material and ensure the packaging fitness for use and handling of all packing material documentation which is part of quality system.\nShould be knowing digitals skills and data analysis skills.\nB. KEY DUTIES/RESPONSIBILITIES:\nBriefly describe the primary duties/responsibilities of this job in 5-8 bullet points. Please list these duties in order of importance and include the percentage of time spent or required for each activity.\nPrioritized Responsibilities\n% of Time\nProcess Quality Activities:\nEnsure plant s operations continue keeping pace with new KORE requirements, regulations, quality management methods and industry best practices.\nRegular conduct the risk assessment for plant key processes to mitigate the risk of failure to deliver Quality product.\nEnsure that quality is built into the process by training Associates on Quality monitoring aspects.\nValidate equipment and processes, routinely monitoring and adherence to Good Manufacturing Practices of the highest standard.\nCreate a technical library/database by compiling in an easy retrieval system all the technical information available in the plant post-commissioning and compiling the validation reports generated as a result of the Validation Master Plan implementation.\nEnsure all manufacturing instructions (SMI) are followed by production effectively.\nOrganize and support plant s associates to use the problem-solving tools for root-cause analysis and action plans to eliminate the recurrence of quality issue\nSupport Corrective/Preventive actions of PDR, TDQ, and analysis of manufacturing problems.\nPerform process validations and process capability studies to ensure the performance of production equipment meet KORE requirements and required actions are implemented if there is any deficiency\nInspect manufacturing equipment for use after maintenance (calibration, maintenance, etc).\nAssess existing processes/operations to seek the possibility to eliminate non-value activities by adopting OE concept and methodology\nTo review the completed analysis report against KO requirements and documents relating to food regulation for auxiliary material / processing aid to authorize the supplier finally\n60 %\nPlant GMP / Security Program\nRoutinely monitoring and adherence to Good Manufacturing Practices of the highest standard and ensure plant s security program are in-placed effective.\nFollow-up on the execution of the GMP programs in both general facilities by outsourced service contractor and manufacturing area by direct GMP housekeepers\nManagement of the pest control and housekeeping program by monitoring evaluating the service performance (contractors), controlling, and monitoring the housekeepers performance inside the manufacturing area to ensure total compliance with GMP standards.\n10 %\nManagement System\nImplement Quality requirements (KORE and ISO) and provide suggestions and recommendations for improvement based on food/pharmaceutical industry s experience.\nLead the team to play a key role in the implementation, assessment and improvement of Quality and Food Safety Management System\nSupport internal auditor team of quality system and actively participate the scheduled internal audit to continuously improve/upgrade plant s quality system and operations.\n15%\nNew Packaging development and routine incoming inspection\nWork with Asia packaging specialist to develop new packaging suppliers to meet the increased volume and introduced new process/equipment.\nContinuously optimize packaging material to improve the plant s performance on TDQ and OTIF and ensure the packaging material meet our spec prior to use.\nCollate packaging information to ensure completeness and accuracy in PICASSO and related databases.\n10%\nCapability\nIdentify training needs of the associates.\nResponsible to lead midyear/annual performance review, provide feedback and documenting the performance of associates.\n5 %\nD. COMMUNICATION COMPLEXITIES:\nAs indicated, the impact is on all manufacturing operations as far as quality is concerned and this applies to warehouse, distribution aspects, Customer Complaints investigation and resolutions.\nE. ANALYSIS:\nParticipate in visits to Customers to resolve alleged quality issues with manufacturing. Co-ordinate joint efforts with other CPS plants on quality initiatives and was identified to participate in cross audits with Corporate Quality. Daily contact with the Leadership Team, Wider Management Team and associates throughout the plant.\nF. JUDGMENT AND DECISION MAKING:\nThe job can recommend to stop production of beverage base if any potential process or product quality issue is noted during the manufacturing.\nG. INNOVATION:\nThe job has the responsibilities to suggest solution to the existing processes, package material to upgrade the quality of our products and processing/quality system\nH. SUPERVISORY RESPONSIBILITIES:\nConduct performance review of processes and equipments. Identify training need and train associate.\nI. QUALIFICATIONS / COMPENTENCIES / SKILLS:\nIs this position a:\nLeader of Others\nMinimum experience is 4-5 years prior experience in production supervision role in a food/beverage or pharmaceutical industry.\nFamiliar with ISO and Food Safety Quality System, understand KORE requirements will be preferred.\nKnowledge of concentrate manufacturing and quality system, project management experience; strong GMP experience, problem solving skills. strategic-thinking, planning, organizing and executing skills. Knowledge of local food laws/regulations.\nSix sigma methodology or certification\nJ. RELATED EXPERIENCE REQUIREMENTS/ QUALIFICATIONS:\nOf prime importance are communication and listening skills.\nTime management is a key considering the level of involvement in many simultaneous projects.\nK. EDUCATIONAL REQUIREMENTS: Indicate the minimum education level required to perform the job.\nEducation Required\nLevel of Certificate\nPostgraduate/Master s degree\nIn life sciences\nL. PREFERRED QUALIFICATIONS:\nBachelor of science or postgraduate degree, major in the subject of chemistry or food science, or biochemistry, Food technology and food engineering\nM. CULTURAL DIVERSITY:\nTargeting employment of local associates as much as practically possible, As part of communication skills with other CPS-Plants or Corporate Quality, both oral and written English language in fluent is required.\nN. WORKING CONDITIONS: Describe the risk of exposure to hazards in performing this job, and the types of hazards faced.\nHazards and risks are normal ones associated with a CPS manufacturing plant.\nO. TRAVEL REQUIREMENTS:\nTravel requirements are in response to problems for the most part and therefore no specifically planned up front. Approximate time is 10%.\nP. ADDITIONAL INFORMATION:\nThis document serves as a common job description for a Process QA role in a CPS Plant. The job scope of this position in the respective plant location is subject to complexity and scale of operating business in the Plant.\nSkills:\nOur Purpose and Growth Culture:\nWe are taking deliberate action to nurture an inclusive culture that is grounded in our company purpose, to refresh the world and make a difference. We act with a growth mindset, take an expansive approach to what s possible and believe in continuous learning to improve our business and ourselves. We focus on four key behaviors - curious, empowered, inclusive and agile - and value how we work as much as what we achieve. We believe that our culture is one of the reasons our company continues to thrive after 130+ years. Visit Our Purpose and Vision to learn more about these behaviors and how you can bring them to life in your next role at Coca-Cola.",Industry Type: Beverage,Department: Quality Assurance,"Employment Type: Full Time, Permanent","['Data analysis', 'ISO', 'Food technology', 'Project management', 'Risk assessment', 'Biochemistry', 'GMP', 'Technical support', 'Monitoring', 'Six sigma']",2025-06-14 05:39:20
Advertising Sales Rep Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Digital Inside Sales - Inside Sales\n\n\n\n\nDesignation: Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 Years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nTransforming sales to become a future-ready and digital B2B revenue engine. The team helps assess, design, build and implement best practices on process, organization, and technology to create, execute, and run a collaborative sales and support roles. Provide support for lead/opportunity generationconduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\n\nWhat are we looking for\nProvide support for lead/opportunity generationconduct calls / send emails / connect via social media to generate leads, schedule first meetings for sales/pre-sales, conduct customer surveys, identify participants for events, and bring awareness of the product or offering on behalf of sales/marketing teams.\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems. Your day to day interaction is with peers within Accenture before updating supervisors. In this role you may have limited exposure with clients and/or Accenture management. You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments. The decisions you make impact your own work and may impact the work of others. You will be an individual contributor as a part of a team, with a focused scope of work. Please note that this role may require you to work in rotational shifts. Your day to day interaction is with peers within Accenture before updating supervisors. In this role you may have limited exposure with clients and/or Accenture management. You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments. The decisions you make impact your own work and may impact the work of others. You will be an individual contributor as a part of a team, with a focused scope of work. Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['business development', 'sales', 'inside sales', 'marketing', 'sales analysis', 'data analysis', 'sales forecasting', 'team management', 'mis reporting', 'market research', 'sales support', 'sales operations', 'lead generation', 'advanced excel', 'mis', 'sales coordination', 'sales planning']",2025-06-14 05:39:22
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Skill required: Marketing Operations - Campaign Analytics & Reporting\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nLanguage - Ability:English(International) - Proficient\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designIn this role you will, define, implement and monitor Paid Campaigns. Generate Reports on the performance of campaigns\n\n\n\n\nWhat are we looking for\nAnalysis and ReportingData ReportingBusiness Data AnalysisDetail orientationAbility to manage multiple stakeholdersNumerical abilityWritten and verbal communicationResults orientationAnalytical ThinkingBusiness Intelligence (BI) Reporting Tools\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'reporting analysis', 'data reporting', 'marketing operations', 'campaign analytics', 'digital marketing', 'python', 'data analytics', 'sas', 'business analysis', 'power bi', 'business analytics', 'business intelligence', 'sql', 'tableau', 'vba', 'data visualization']",2025-06-14 05:39:24
Campaign Management Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Campaign Management\n\n\n\n\nDesignation: Campaign Management Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nWe are seeking a highly skilled and detail-oriented Ad Operations Specialist to join our dynamic team. The ideal candidate will be responsible for managing and optimizing the delivery of digital advertising campaigns, ensuring smooth execution, and maintaining the quality and performance of digital ad operations. The role requires a strong understanding of digital advertising platforms, analytics, and the ability to troubleshoot issues effectively1.Campaign Management:oSet up, monitor, and optimize digital ad campaigns across various platforms/products (display, video, social media, etc.).oEnsure proper targeting, scheduling, and creative deployment for optimal campaign delivery.oManage creative assets and ad trafficking, ensuring the correct formats and specifications are used.oWork closely with the client and provide analytical/campaign reports, track KPIs, and optimize campaigns based on performance metrics.oTroubleshoot and resolve campaign issues related to delivery, tracking, and ad quality.2.Technical Setup & Troubleshooting:oPerform ad trafficking tasks, ensuring that all campaigns are set up properly and execute without errors.oTroubleshoot technical issues, such as discrepancies in reporting, creative issues, or campaign performance problems.oCoordinate with vendors or partners to resolve any issues impacting campaign delivery.3.Client Servicing:oCollaborate with account managers/clients, and internal teams to align campaign objectives with ad execution.oCommunicate with Internal & External teams to ensure a smooth campaign delivery takes place.oExcellent written and verbal communication skills for internal and client-facing interactionsoGood at articulating the problems/challenges in simple wordsoProactive in identifying issues/challenges and use the technical knowledge to suggest solutions\n\n\n\n\nWhat are we looking for\n\nQualifications &\n\n\n\n\nSkills:\nEducation:Bachelors degree or Preferred in Marketing, Advertising or related field.Experience:2-3 years of experience in Campaign Management or Ad Operations or Digital marketing.Technical\n\n\n\n\nSkills:\nFamiliarity with ad-serving platforms (DoubleClick, Sizmek, Google Ad Manager, etc.) and analytics tools (Google Analytics, Magnite, Tableau, etc).Attention to Detail:Strong ability to manage and optimize campaigns with a focus on precision and accuracy.Analytical Mindset:Strong data analysis skills and comfort with numbers to make informed decisions.Communication\n\n\n\n\nSkills:\nExcellent written and verbal communication skills for internal and client-facing interactions.Problem-Solving:Ability to troubleshoot and resolve issues in a timely and efficient mannerPreferred\n\n\n\n\nSkills:\nExperience in Video, Audio, Mobile, or Display advertising.Knowledge in Microsoft Excel is must.Excellent written and verbal communication skills for internal and client-facing interactions.Experience with programmatic advertising and RTB (Real-Time Bidding) will be a plus point\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shiftsWork Environment:Working with dynamic team.Work from office or Hybrid depending on project requirementsThe role involves working in night shift catering to US client with 5-day work schedule with weekly 2 days week offs\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'data analysis', 'ad operations', 'digital advertising', 'campaign management', 'rtb', 'programmatic buying', 'bidding', 'google', 'advertising', 'sizmek', 'tableau', 'display advertising', 'vendor', 'google analytics', 'troubleshooting', 'marketing operations', 'doubleclick']",2025-06-14 05:39:27
S&C Global Network - AI - Supply Chain Analytics-Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"JR:\n\n\n\nR00244153\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree\n\n\n\n---------------------------------------------------------------------\n\n\n\nJob Title -\n\n\n\nS&C Global Network - AI - Supply Chain Analytics - Analyst\n\n\n\nManagement Level:\n\n\n\n11-Analyst\n\n\n\nLocation:\n\n\n\nMumbai, MC1 Building, NonSTPI\n\n\n\nMust-have skills:Data Analytics\n\n\n\n\nGood to have skills:Ability to leverage design thinking, business process optimization, and stakeholder management skills.\n\n\n\nJob\n\n\nSummary:\n\nThis role involves driving strategic initiatives, managing business transformations, and leveraging industry expertise to create value-driven solutions.\n\nCandidate should have good understanding of statistics/time series forecasting/Optimization methods and approaches. The candidate should be able to bring in meaningful data driven insights supporting with statistical concepts and apply the same in wider Supply Chain area. The candidate is expected to use data science skills to solve clients business problem in the supply chain area. Additionally, the role would require contributing towards asset development initiatives.\n\n\n\n\nRoles & Responsibilities:\n\nProvide strategic advisory services, conduct market research, and develop data-driven recommendations to enhance business performance.\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\n\n\n- Relevant experience in the required domain.\n\n- Strong analytical, problem-solving, and communication skills.\n\n- Ability to work in a fast-paced, dynamic environment.\n\n\n\nMandatory\n\n\n\n\nSkills:\n\n\nMust have:\nProficiency in data modeling developed through client projects.\nExtensive use of data-driven techniques including exploratory data analysis and data pre-processing to solve business problems.\nProficient in using Python/PySpark programming for data manipulation, data visualization, and machine learning models with good hands-on experience.\nProficiency in any one of the Cloud solutions Azure, GCP or AWS\nProficiency in SQL for data preparation, manipulation, and descriptive analysis\nProficient in supply chain domain\nExcellent written and oral communication skills\n\nGood to have:\nExperience on Simulation and Optimization\nVisualization packages like Tableau/ Power BI\nExposure to tools like BY/ Anaplan/ o9/ Kinaxis /SAP IBP\nExposure to Client interaction\nExposure to business platforms (o9/Kinaxis/BY)\n\n\n\n\n\nAdditional Information:\n\n- Opportunity to work on innovative projects.\n\n- Career growth and leadership exposure.\n\n\n\n\n\nAbout Our Company | Accenture\n\nQualification\n\n\n\nExperience:\n\n\n\n3-5Years\n\n\n\n\nEducational Qualification:\n\n\n\nAny Degree",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'sql', 'gcp', 'aws', 'anaplan', 'data analytics', 'sap', 'supply chain', 'data manipulation', 'microsoft azure', 'power bi', 'machine learning', 'supply', 'data preparation', 'tableau', 'descriptive analysis', 'data modeling', 'sap ibp', 'cloud applications', 'ibp', 'data visualization']",2025-06-14 05:39:29
Join us as a Data Scientist!!,Zensar,6 - 11 years,Not Disclosed,"['Hyderabad', 'Delhi / NCR']","-\nData Scientist\n\n-6+ years of experience in data science, with at least 2 years focused on LLMs or Generative AI.\n\n-Proven implementation experience in Data Science, Machine Learning, Deep Learning, and NLP for multiple domains.\n\n-Strong programming skills in Python, with experience in libraries such as Transformers (Hugging Face), PyTorch, or TensorFlow.\n\n-Hands-on experience with fine-tuning, prompt engineering, RAG (Retrieval-Augmented Generation), and LLM evaluation.\n\n-Familiarity with vector databases and embedding techniques.\n\n-Experience deploying models using APIs, Docker, and cloud platforms\n\n-Strong analytical, problem-solving, and communication skills.\n\n-Experience in ML Ops, Model deployment, Model lifecycle and management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Pytorch', 'NLP', 'Machine Learning', 'Deep Learning', 'Tensorflow', 'Cloud Deployment', 'ML Ops', 'Generative AI', 'Hugging Face', 'LLM', 'Python']",2025-06-14 05:39:31
Paid Search Analyst,Merkle B2b,3 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Paid Search campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nProvides initial insights on campaign trends to executives and planners\nLocation:\nDGS India - Chennai - Anna Nagar Tyche Towers\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Other,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-14 05:39:33
Digital Content Management Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Marketing Operations - Salesforce Marketing Cloud\n\n\n\n\nDesignation: Digital Content Management Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires:SFMC Campaign QA""HTML and CSS:Familiarity with HTML and CSS coding for email template customization and troubleshooting rendering issues.Digital Marketing:Understanding of broader digital marketing strategies and tactics to align SFMC campaigns with overall marketing objectives.UX/UI Design:Knowledge of user experience (UX) and user interface (UI) design principles to improve the visual appeal and usability of campaign assets.""You will help design, implement & manage Salesforce Marketing Cloud, a customer relationship management (CRM) platform for marketers that allows them to create and manage marketing relationships and campaigns with customers. You will help incorporate incorporates integrated solutions for customer journey management, email, mobile, social, web personalization, advertising, content creation and management, and data analysis.\n\n\n\n\nWhat are we looking for\nQuality Assurance (QA)Quality AuditingSalesforce Marketing CloudMust Have\n\n\n\n\nSkills:\nSalesforce Marketing Cloud Expertise:In-depth knowledge of SFMC functionalities, including Email Studio, Mobile Studio, Automation Studio, and Journey Builder. Knowledge of AMPscripts, SSJS personalization language along with Proficiency in SQL.Campaign Management:Experience in end-to-end campaign execution, including segmentation, audience targeting, content personalization, and journey automation.Quality Assurance:Strong attention to detail and ability to conduct rigorous testing and validation of campaign setups.Technical Troubleshooting:Proficiency in identifying and resolving technical issues related to SFMC configurations and data integration.Marketing Automation:Understanding of marketing automation principles and best practices for customer engagement and conversion.Data Analysis:Basic data analysis skills to interpret campaign performance metrics and make data-driven recommendations.Collaboration:Excellent communication skills to collaborate effectively with cross-functional teams and convey complex technical concepts to non-technical stakeholders.Requirement:Campaign Review:Conduct thorough reviews of marketing campaign requirements and specifications to understand the campaign objectives, target audience, segmentation rules, and personalization requirements.Quality Assurance Testing:Execute testing of campaign setups across different channels Email, SMS, Push, Direct mail, social, paid campaign etc., data queries, to validate the accuracy and functionality of the campaign components.Data Validation:Verify the integrity of data used in the campaigns, including audience lists, data extensions, and dynamic content personalization, to ensure that the right message is delivered to the right audience.Journey Testing:Validate customer journeys and automation workflows to ensure that subscribers progress through the intended paths and receive the appropriate messages at each stage.Compliance and Best Practices:Ensure email campaigns adhere to email marketing best practices, data privacy regulations, and anti-spam laws.Campaign Optimization:Provide insights and recommendations to optimize campaign performance, increase engagement, and achieve better conversion rates.A/B Testing:Support A/B testing efforts by setting up and validating test campaigns,\n\n\n\nRoles and Responsibilities: Documentation:Maintain comprehensive documentation of campaign testing processes, results, and issue resolutions.Collaboration:Work closely with marketing teams, project managers, data analysts, and developers to address campaign-related challenges and implement improvements.Collaborate with development team to ensure that creative build align with the campaign objectives and data build.Continuous Improvement:Stay updated with the latest SFMC features, best practices, and industry trends to enhance campaign build quality and overall marketing effectiveness.Work Orchestration and Data hygiene:Fully understand ticketing/request management tool and accurately record updates, data points, timestamps etc. to provide seamless experience to both internal and external stakeholders.Adhere to all Desktop Procedures (DTPs) / Standard Operating Procedures (SOP) along with checklist and other important process document to carry out all required tasks.Complete all required reports so that accurate numbers are reported to both client and leadership.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Content, Editorial & Journalism","Employment Type: Full Time, Permanent","['css', 'sql', 'salesforce marketing cloud', 'html', 'sfmc', 'standard operating procedures', 'digital marketing', 'project management', 'data analysis', 'digital content', 'content management', 'content creation', 'salesforce', 'marketing', 'desktop', 'content writing', 'marketing operations']",2025-06-14 05:39:35
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Navi Mumbai'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\n""Campus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard doneCampus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard doneCampus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard done""\n\n\n\n\nWhat are we looking for\n""Campus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard doneCampus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard done""\n\n\n\nRoles and Responsibilities: Campus JR is now withdrawn coz candidate rejected the office hence as per discussion with Recruitment team & RMG raising external demand to get the necessary onboard done\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'service operations', 'vlookup', 'reporting analysis', 'record to report', 'hlookup', 'macros', 'data analysis', 'data analytics', 'mis reporting', 'ms access', 'pivot table', 'power bi', 'sql', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-14 05:39:38
Measurement & Report Analyst,Accenture,3 - 5 years,Not Disclosed,['Mumbai'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement & Report Analyst\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Business Reporting and Governance vertical helps to deploy and deliver robust tracking mechanism for SLA/KPI or any other operations on a day-to-day basis. The Governance team will be responsible for contractual compliance of various aspects of contract like Governance, Reporting, Incident Management, Change Management and Survey Management along with driving automation and analytics. Assessing, managing, using, improving, monitoring, maintaining, and protecting organizational information through a system of decision rights and accountabilities for information related processes, executed according to agreed-upon models which describe who can take what actions, with what information, when, under what circumstances and using what methods. Candidate who is good in excel and MIS reports are looked at for these skillsIn Reporting and Analytics, you will have to prepare management reports and analysis, both recurring and ad-hoc. This includes focusing on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nEffective communication and organization skills with Polished, professional presence Experience in working on automation projects Demonstrate ability to achieve customer satisfaction through a managed service framework. Facilitation skills and Virtual teaming experience Adaptability to change. Effective collaboration skills and experience Adept in working across a heavily matrixed organization. Proficient in MS Office with advance knowledge in excel formulas. Ability to simplify and automate manual intensive processes using basic VBA, MS Access Expertise in creating reports, and exposure to using PowerBI\n\n\n\nRoles and Responsibilities: Create and Publish Daily / Weekly / Monthly Reports on time with accuracy. Deliver ad hoc reports. Find trends in data to spot any anomaly / provide data insights to the stake holders. Automate reports to reduce manual efforts.\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ms access', 'business reporting', 'vlookup', 'vba', 'mis', 'macros', 'data analysis', 'data analytics', 'power bi', 'business analysis', 'dashboards', 'business intelligence', 'sql', 'reporting analysis', 'reporting and analytics', 'tableau', 'advanced excel', 'data visualization']",2025-06-14 05:39:40
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Chennai'],"Skill required: Record To Report - Fixed Asset Accounting\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.Design and implement process and solutions to record and process all aspects of fixed assets accounting. Includes chart of accounts alignment, back office integration, folio management, payment processing, transfer & retirement of assets, physical inventory and Construction In Process (CIP) project accounting.\n\n\n\n\nWhat are we looking for\nWritten and verbal communicationAbility to handle disputesStrong analytical skillsCommitment to qualityRisk management\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'accounting', 'payment processing', 'record to report', 'fixed asset accounting', 'hlookup', 'macros', 'service operations', 'data analysis', 'forecasting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:39:42
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Chennai'],"Skill required: Record to Report- Tax - Tax Process Design\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits. Posting direct tax and indirect tax and GST s and returnsDesign and implement processes for direct Tax/income tax. Includes direct tax/income tax planning, income tax accounting, income tax compliance and income tax audit.\n\n\n\n\nWhat are we looking for\nWritten and verbal communicationAbility to handle disputesStrong analytical skillsCommitment to qualityRisk management\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['journal entries', 'forecasting', 'accounting', 'record to report', 'taxation', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'pivot table', 'vlookup', 'dashboards', 'indirect taxation', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis', 'data visualization']",2025-06-14 05:39:44
Record To Report Ops Analyst,Accenture,3 - 5 years,Not Disclosed,['Chennai'],"Skill required: Record To Report - Account Reconciliations\n\n\n\n\nDesignation: Record to Report Ops Analyst\n\n\n\n\nQualifications:BCom\n\n\n\n\nYears of Experience:3 to 5 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nYou will be aligned with our Finance Operations vertical and will be helping us in determining financial outcomes by collecting operational data/reports, whilst conducting analysis and reconciling transactions.Posting journal entries, preparing balance sheet reconciliations, reviewing entries and reconciliations, preparing cash forecasting statement, supporting month end closing, preparing reports and supports in audits.A type of general ledger account which contains a summary of sub-ledger accounts. Because the reconciliation account only provides a summary, no transactions are directly posted to the account.\n\n\n\n\nWhat are we looking for\nAbility to establish strong client relationshipAbility to handle disputesAbility to manage multiple stakeholdersAbility to meet deadlinesAbility to perform under pressure\n\n\n\nRoles and Responsibilities: In this role you are required to do analysis and solving of lower-complexity problems Your day to day interaction is with peers within Accenture before updating supervisors In this role you may have limited exposure with clients and/or Accenture management You will be given moderate level instruction on daily work tasks and detailed instructions on new assignments The decisions you make impact your own work and may impact the work of others You will be an individual contributor as a part of a team, with a focused scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nBCom",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['accounts reconciliation', 'journal entries', 'forecasting', 'general ledger', 'record to report', 'hlookup', 'macros', 'service operations', 'data analysis', 'mis reporting', 'ms access', 'pivot table', 'vlookup', 'dashboards', 'sql', 'reporting analysis', 'tableau', 'vba', 'advanced excel', 'mis']",2025-06-14 05:39:46
Analyst - Projects,Microland,4 - 6 years,Not Disclosed,['Bengaluru'],"Microland Limited is looking for Analyst - Projects to join our dynamic team and embark on a rewarding career journey Supports project planning, tracking, and performance monitoring\n\nAssists in data analysis, documentation, and coordination\n\nPrepares reports for stakeholders and leadership\n\nEnsures project timelines and deliverables are met",,,,"['Data analysis', 'Master Analyst', 'Project management', 'Agile', 'Manager Technology', 'Scrum', 'Data analytics']",2025-06-14 05:39:48
Associate - Analyst,Myntra,1 - 3 years,Not Disclosed,['Bengaluru'],"Department: Product / Growth / Analytics\nReports To: Storefront Product Manager / Analytics Lead\n\nRole Overview\n\nWe re looking for a highly analytical, detail-oriented, and curious Analyst to join the\nStorefront team. This role will be key in driving data-driven decisions to improve user\nexperience, engagement, and revenue through real-time analysis of customer behavior on\nthe app and website.\n\nKey Responsibilities\n\nAnalyze performance of key sections of the Myntra storefront (home page, navigation, banners, personalization zones).\n\nDevelop and maintain dashboards to monitor daily/weekly metrics (CTR, CVR,\nbounce rates, etc.).\n\nIdentify trends, anomalies, and opportunities through data analysis to optimize\nmerchandising and UX strategies.\n\nPartner with Product Managers, UX designers, and Category teams to test and\nvalidate hypotheses.\n\nSupport A/B testing initiatives: design experiments, analyze results, and make\nactionable recommendations.\n\nCreate periodic reports and deep-dives on campaign performance, seasonal spikes,\nand traffic sources.\n\nLeverage user segmentation and behavioral analytics to suggest personalization\nstrategies.",,,,"['SQL', 'R', 'Excel', 'Google Analytics', 'Power BI', 'Tableau', 'Looker', 'Adobe Analytics', 'Python']",2025-06-14 05:39:50
Data Engineer,Luxoft,5 - 10 years,Not Disclosed,['Pune'],"Project description\nYou'll be working in the GM Business Analytics team located in Pune. The successful candidate will be a member of the global Distribution team, which has team members in London and Pune.\n\nWe work as part of a global team providing analytical solutions for IB distribution/sales people. Solutions deployed should be extensible globally with minimal localization.\n\nResponsibilities\n\nAre you passionate about data and analyticsAre you keen to be part of the journey to modernize a data warehouse/ analytics suite of application(s). Do you take pride in the quality of software delivered for each development iteration\n\nWe're looking for someone like that to join us and\n\nbe a part of a high-performing team on a high-profile project.\n\nsolve challenging problems in an elegant way\n\nmaster state-of-the-art technologies\n\nbuild a highly responsive and fast updating application in an Agile & Lean environment\n\napply best development practices and effectively utilize technologies\n\nwork across the full delivery cycle to ensure high-quality delivery\n\nwrite high-quality code and adhere to coding standards\n\nwork collaboratively with diverse team(s) of technologists\n\nYou are:\n\nCurious and collaborative, comfortable working independently, as well as in a team\n\nFocused on delivery to the business\n\nStrong in analytical skills. For example, the candidate must understand the key dependencies among existing systems in terms of the flow of data among them. It is essential that the candidate learns to understand the 'big picture' of how IB industry/business functions.\n\nAble to quickly absorb new terminology and business requirements\n\nAlready strong in analytical tools, technologies, platforms, etc. The candidate must also demonstrate a strong desire for learning and self-improvement.\n\nOpen to learning home-grown technologies, support current state infrastructure and help drive future state migrations. imaginative and creative with newer technologies\n\nAble to accurately and pragmatically estimate the development effort required for specific objectives\n\nYou will have the opportunity to work under minimal supervision to understand local and global system requirements, design and implement the required functionality/bug fixes/enhancements. You will be responsible for components that are developed across the whole team and deployed globally.\n\nYou will also have the opportunity to provide third-line support to the application's global user community, which will include assisting dedicated support staff and liaising with the members of other development teams directly, some of which will be local and some remote.\n\nSkills\nMust have\n\nA bachelor's or master's degree, preferably in Information Technology or a related field (computer science, mathematics, etc.), focusing on data engineering.\n\n5+ years of relevant experience as a data engineer in Big Data is required.\n\nStrong Knowledge of programming languages (Python / Scala) and Big Data technologies (Spark, Databricks or equivalent) is required.\n\nStrong experience in executing complex data analysis and running complex SQL/Spark queries.\n\nStrong experience in building complex data transformations in SQL/Spark.\n\nStrong knowledge of Database technologies is required.\n\nStrong knowledge of Azure Cloud is advantageous.\n\nGood understanding and experience with Agile methodologies and delivery.\n\nStrong communication skills with the ability to build partnerships with stakeholders.\n\nStrong analytical, data management and problem-solving skills.\n\nNice to have\n\nExperience working on the QlikView tool\n\nUnderstanding of QlikView scripting and data model\n\nOther\n\nLanguages\n\nEnglishC1 Advanced\n\nSeniority\n\nSenior",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'data management', 'big data technologies', 'sql', 'spark', 'python', 'scala', 'mathematics', 'business analytics', 'data engineering', 'azure cloud', 'qlikview', 'data bricks', 'computer science', 'database creation', 'data transformation', 'agile', 'big data', 'agile methodology']",2025-06-14 05:39:53
Process Executive - B&L,Cognizant,0 - 2 years,Not Disclosed,['Coimbatore'],Job Summary\nThe Process Executive - B&L role is designed for individuals with 0 to 2 years of experience focusing on tasks related to consumer lending cards and payments. This position requires proficiency in MS Excel and offers a hybrid work model with day shifts. The role does not require travel allowing for a balanced work-life integration.,,,,"['cards', 'data analysis', 'analytical', 'workflow', 'lending', 'documentation', 'policies', 'business analysis', 'monitoring', 'process improvements', 'sql', 'plsql', 'excel', 'flexcube', 'operations', 'customer satisfaction', 'service delivery', 'compliance', 'onboarding', 'core banking', 'consumer lending', 'communication skills']",2025-06-14 05:39:56
Senior Data Scientist,Reuters,3 - 8 years,Not Disclosed,"['Mumbai', 'Hyderabad']","Senior Data Scientist - Enterprise Analytics\nWant to be part of the Data & Analytics organization, whose strategic goal is to create a world-class Data & Analytics company by building, embedding, and maturing a data-driven culture across Thomson Reuters.\nWe are looking for a highly motivated individual with strong organizational and technical skills for the position of Senior Data Scientist. You will play a critical role working on cutting edge of analytics, leveraging predictive models, machine learning and generative AI to drive business insights and facilitating informed decision-making and help Thomson Reuters rapidly scale data-driven initiatives.\nAbout the Role\nIn this opportunity as Senior Data Scientist, you will:\nEngage with stakeholders, business analysts and project team to understand the data requirements.\nWork in multiple business domain areas including Customer Service, Finance, Sales and Marketing.\nDesign analytical frameworks to provide insights into a business problem.\nExplore and visualize multiple data sets to understand data available and prepare data for problem solving.\nBuild machine learning models and/or statistical solutions.\nBuild predictive models, generative AI solutions.\nUse Natural Language Processing to extract insight from text.\nDesign database models (if a data mart or operational data store is required to aggregate data for modeling).\nDesign visualizations and build dashboards in Tableau and/or PowerBI.\nExtract business insights from the data and models.\nPresent results to stakeholders (and tell stories using data) using power point and/or dashboards.\nAbout You\nYoure a fit for the role of Senior Data Scientist if your background includes:\nExperience- 6-8 Years in the field of Machine Learning & AI\nMust have a minimum of 3 years of experience working in the data science domain\nDegree preferred in a quantitative field (Computer Science, Statistics, etc.)\nBoth technical and business acumen is required\nTechnical skills\nProficient in machine learning, statistical modelling, data science and generative AI techniques\nHighly proficient in Python and SQL\nExperience with Tableau and/or PowerBI\nHas worked with Amazon Web Services and Sagemaker\nAbility to build data pipelines for data movement using tools such as Alteryx, GLUE\nExperience Predictive analytics for customer retention, upsell/cross sell products and new customer acquisition, Customer Segmentation, Recommendation engines (customer and AWS Personalize), POC s in building Generative AI solutions (GPT, Llama etc.,)\nHands on with Prompt Engineering\nExperience in Customer Service, Finance, Sales and Marketing\nAdditional Technical skills include Familiarity with Natural Language Processing including Feature Extraction techniques, Word Embeddings, Topic Modeling, Sentiment Analysis, Classification, Sequence Models and Transfer Learning\nKnowledgeable of AWS APIs for Machine Learning\nHas worked with Snowflake extensively.\nGood presentation skills and the ability to tell stories using data and Powerpoint/Dashboard Visualizations.\nAbility to communicate complex results in a simple and concise manner at all levels within the organization.\nConsulting Experience with a premier consulting firm.\n#LI-SS5\nWhat s in it For You?\nHybrid Work Model: We ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.\nFlexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.\nCareer Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.\nIndustry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.\nCulture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.\nSocial Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives.\nMaking a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.\nAbout Us\nThomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.\nWe are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound exciting? Join us and help shape the industries that move society forward.\nAs a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.\nWe also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here .\nLearn more on how to protect yourself from fraudulent job postings here .\nMore information about Thomson Reuters can be found on thomsonreuters.com.",Industry Type: Internet,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Customer acquisition', 'Career development', 'Analytical', 'Consulting', 'Machine learning', 'Customer retention', 'Customer service', 'Operations', 'SQL']",2025-06-14 05:39:58
Data Engineer,Invitusdata,1 - 4 years,Not Disclosed,['Chennai'],"Strong understanding of Data Warehousing concepts and data modeling techniques and columnar databases\n\nStrong Hands on experience in Data Analysis, preprocessing and validation of the engineered dataset in SQL/NoSQL databases\n\nHands-on Experience in data cleansing,processing and loading using Big-data tools mainly (Py)Spark and Hive/Presto\n\nExposure to any workflow scheduling & Orchestration tools Airflow/Prefect/SQS would be helpful\n\nComfortable working with any programming/scripting language like Python(Preferred)/Scala/Shell scripting\n\nStrong data engineering skills on any Cloud Platform is essential(Preferred: AWS)\n\nExposure to data lake and data lake house would be an added advantage\n\nSolid Understanding of data structures and algorithms\n\nKnowledge of distributed/MPP systems pertaining to data storage and computing\n\nAbility to effectively communicate with both business and technical teams\n\nGood interpersonal skills and positive attitude\n\nExperience in working with agile methodology in a fast paced environment\n\n""] , keyResponsibilities:Design , Develop and implement ETL data pipelines that load data into an information product that helps the organization in reaching strategic goals\n\nWork on ingesting, storing, cleansing, processing and analyzing large data sets from heterogeneous data sources\n\nFinalizing the scope of the system and delivering Big Data solutions\n\nTranslate complex technical and functional requirements into detailed designs\n\nSchedule, orchestrate and Implement data pipelines and processes that scale with increase in data volume\n\nInvestigate and analyze alternative solutions to data storing, processing etc\n\nto ensure most streamlined approaches are implemented\n\nCollaborate with business consultants, data scientists, and application developers to develop analytics solutions\n\nHelp define data governance policies and support data versioning processes\n\nMaintain security & data privacy working closely with the Data Protection Officer internally\n\nAnalyze a vast number of data stores and uncover insights\n\nCreate data tools for business team members that assist them in analysis that gives them the competitive edge\n\nMonitor data application performance for potential bottlenecks and resolve performance issues\n\nIdentify and implement cost-saving strategies to reduce ongoing Big Data and Cloud costs/expenses",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Data modeling', 'Shell scripting', 'Data structures', 'Workflow', 'Scheduling', 'Agile methodology', 'Analytics', 'SQL', 'Python']",2025-06-14 05:40:00
Senior/Lead Data Scientist,Tezo,6 - 10 years,Not Disclosed,['Hyderabad'],"Tezo is a new generation Digital & AI solutions provider, with a history of creating remarkable outcomes for our customers. We bring exceptional experiences using cutting-edge analytics, data proficiency, technology, and digital excellence.\nTezo is seeking passionate AI Engineers who are excited about harnessing the power of Generative AI to transform our company and provide cutting-edge solutions for our clients. Join us in revolutionizing enterprises by building intelligent, generative solutions that leverage AI/ML. If you've ever dreamed of contributing to impactful projects on a large scale, this is the opportunity for you! \nIn this role, you will be an integral part of the Machine Learning Platforms/Data Science team, focusing on developing, testing, and deploying generative AI models. \n\nWhat Makes Our AI/ML Practice Unique:\nPurpose-driven: We actively respond to our customers' evolving needs with innovative solutions. \nCollaborative: We foster a positive and engaging work environment where collective ideas thrive. \nAccountable: We take ownership of our performance, both individually and as a team. \nService Excellence: We maximize our potential through continuous learning and improvement. \nTrusted: We empower individuals to make informed decisions and take calculated risks. \n\nJob Summary:\nWe are looking for a dedicated Lead Data Scientist with a strong background in Generative AI to join our team. You will support product, leadership, and client teams by providing insights derived from advanced data analysis and generative modeling. \nIn this role, you will collaborate closely with the development team, architects, and product owners to build efficient generative models and manage their lifecycle using the appropriate technology stack. \n\nCore Requirements:\n\nAt least 6 years of experience working with geographically distributed teams \n2+ years of experience working in a client-facing role on AI/ML .\nDemonstrable experience in leading a substantive area of work, or line management of a team.\nProven experience in building production grade Retrieval-Augmented Generation (RAG) solutions with hands on experience with advanced RAG techniques for retrieval, re-ranking etc. \nBuild GenAI applications using LangChain, LlamaIndex and familiarity with Vector Stores and Large Language Models. \nExperience in fine-tuning Large Language Models (LLMs) for business use cases will be preferred. \nMinimum of 4 years of experience in developing end-to-end classical machine learning and NLP projects. \nDemonstrated experience in deploying ML solutions in production using cloud services like Azure,AWS. \nBusiness Understanding, Stakeholder management and Team leading skills. \nStrong practical expertise in Python and SQL needed for data science projects. \n\nJoin us at Tezo to be part of a dynamic team committed to driving innovation through Generative AI solutions!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'Large Language Model', 'Machine Learning', 'NLP', 'Solutioning', 'Retrieval Augmented Generation']",2025-06-14 05:40:02
Senior Data Scientist,Cimet,5 - 10 years,Not Disclosed,['Jaipur'],"Purpose Of The Position:\nWe are looking for a highly experienced Senior Data Scientist with a deep understanding of AI/ML technologies, including Recommendation Systems, Chatbots, Generative AI, and Large Language Models (LLMs). The ideal candidate will have hands-on experience in applying these technologies to solve real-world problems, working with large datasets, and collaborating with cross-functional teams to deliver innovative data-driven solutions..\n\nKey Responsibilities:\nDesign, develop, and optimize recommendation systems to enhance user experience and engagement across platforms.\nBuild and deploy chatbots with advanced NLP capabilities for automating customer interactions and improving business processes.\nLead the development of Generative AI solutions, including content generation and automation.\nResearch and apply Large Language Models (LLMs) like GPT, BERT, and others to solve business-specific problems and create innovative solutions.\nCollaborate with engineering teams to integrate machine learning models into production systems, ensuring scalability and reliability.\nPerform data exploration, analysis, and feature engineering to improve model performance.\nStay updated on the latest advancements in AI and ML technologies, proposing new techniques and tools to enhance our product capabilities.\nMentor junior data scientists and engineers, providing guidance on best practices in AI/ML model development and deployment.\nCollaborate with product managers and business stakeholders to translate business goals into AI-driven solutions.\nWork on model interpretability, explainability, and ensure models are built in an ethical and responsible manner.\nRequired Skills And Qualifications:\n5+ years of experience in data science or machine learning, with a focus on building and deploying AI models.\nStrong expertise in designing and developing recommendation systems and working with collaborative filtering, matrix factorization, and content-based filtering techniques.\nHands-on experience with chatbots using Natural Language Processing (NLP) and conversational AI frameworks.\nIn-depth understanding of Generative AI, including transformer-based models and GANs (Generative Adversarial Networks).\nExperience working with Large Language Models (LLMs) such as GPT, BERT, T5, etc.\nProficiency in machine learning frameworks such as TensorFlow, PyTorch, and Scikit-learn.\nStrong programming skills in Python and libraries such as NumPy, Pandas, Hugging Face, and NLTK.\nExperience with cloud platforms like AWS, GCP, or Azure for deploying and scaling machine learning models.\nSolid understanding of data pipelines, ETL processes, and working with large datasets using SQL or NoSQL databases.\nKnowledge of MLOps and experience deploying models in production environments.\nStrong problem-solving skills and a deep understanding of statistical methods and algorithms.\nPreferred Qualifications:\nExperience with Reinforcement Learning and Recommender Systems personalization techniques.\nExperience of working with AWS Bedrock services.\nFamiliarity with ethical AI and model bias mitigation techniques.\nExperience with A/B testing, experimentation, and performance tracking for AI models in production.\nPrior experience mentoring junior data scientists and leading AI/ML projects.\nStrong communication and collaboration skills, with the ability to convey complex technical concepts to non-technical stakeholders.\n\nWhy Join Us?\nOpportunity to be part of a rapidly growing, innovative product-based company.\nCollaborate with a talented, driven team focused on building high-quality software solutions.\nCompetitive compensation and benefits package.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Tensorflow', 'Generative Ai', 'Natural Language Processing', 'Scikit-Learn', 'Nltk', 'Pytorch', 'MLOps', 'Cloud Computing', 'Statistical Modeling', 'Bert', 'Deploying Models', 'Ab Testing', 'AWS']",2025-06-14 05:40:04
Senior Data Scientist,Codetru Software Solutions,8 - 12 years,Not Disclosed,['Hyderabad'],"Senior Data ScientistLocation: Hyderabad, IndiaExperience: 8-10 YearsWe are seeking a highly motivated, driven, and experienced Senior Data Scientist to join our dynamic team. As a go-getter with a passion for uncovering insights from complex data, you will play a pivotal role in shaping our data strategy and driving business decisions. The ideal candidate is a proactive problem-solver who thrives in a fast-paced environment and possesses a deep understanding of the entire data lifecycle, from extraction to model deployment.\n\nNote: This is purely a Technical role not Managerial.\n\nKey Responsibilities\nLead and execute end-to-end data science projects, from conception and data collection to model building and delivering actionable insights.\nDesign, build, and maintain robust and scalable ETL pipelines to process large volumes of structured and unstructured data from our data lake.\nUtilize advanced SQL and Python (Pandas, NumPy) for data extraction, manipulation, and in-depth analysis to identify critical trends, patterns, and opportunities.\nDevelop and implement a variety of machine learning algorithms, such as regression, classification, clustering, and forecasting models, to solve key business challenges.\nCreate compelling and intuitive data visualizations and dashboards using tools like Tableau or Power BI to communicate complex findings to both technical and non-technical stakeholders.\nMentor junior data scientists and contribute to the team's technical growth and best practices.\n\nMust-Have Qualifications & Skills\n\nExperience: A minimum of 8-10 years of hands-on experience in a data science or related role.\nSQL and Visualization: Expert-level proficiency in SQL for complex querying and proven experience with data visualization tools such as Tableau, Power BI, or Looker.\nData Engineering: Strong, hands-on experience building and managing ETL processes and working extensively within a data lake environment.\nPython and Data Analysis: Mastery of Python and its core data science libraries, especially Pandas, for data wrangling, exploration, and identifying hidden patterns.\nMachine Learning: In-depth theoretical knowledge and practical application of various ML algorithms, including supervised and unsupervised learning techniques. A portfolio of successfully deployed models is a strong plus.\nAttitude: A proactive, self-starting go-getter with excellent problem-solving skills and the drive to take ownership of projects from start to finish.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pandas', 'Fast Api', 'Machine Learning', 'Numpy', 'Python', 'Power Bi', 'Tableau', 'SQL', 'Flask']",2025-06-14 05:40:06
Senior Software Engineer: Data Science,Enphase Energy,3 - 5 years,Not Disclosed,['Bengaluru'],"Description\nOur mission at Enphase Energy is to advance a sustainable future for all.\n\nToday, our intelligent microinverters, which turn sunlight into an affordable, safe, reliable, and scalable source of energy, work with virtually every solar panel made, and when paired with our award-winning smart battery technology, we engineer one of the industrys best-performing clean energy systems. To date, we have installed more than 48 million microinverters on more than 2.5 million systems across 140 countries and well over 50 thousand homes use our energy storage products.\n\nLike our customers, our innovative teams are also worldwide, making Enphase Energy a truly global company. We are one of the fastest growing and most dynamic energy companies in the world. Nimble and acutely focused on developing ground-breaking solar energy management technology, each of our teams has a shared goal of creating a carbon-free future.\nDo you want to help change the worldLearn more about the role:\nFor our Customer Experience team, we seek Hands-On AI/M L Staff Engineer who can work on designing implementing high quality scalable AI/ML applications and platforms, while providing technical leadership/mentoring to a small team of talented developers in agile environment. Your ability to lead the architecture, design, and implementation of maintainable, high-quality, and high-performing Machine Learning systems and AI applications is essential for success in this role.\nProvide hands-on technical expertise to design, engineer, deploy, and deliver highly scalable machine learning applications. Drive improvements in technical architecture, standards, and processes. Drive engineering excellence while managing/mentoring talented team of developers in agile environment. Work closely with product management and other stakeholders for system design and delivery.\nWhat you will be doing:\nUnderstanding the customer experience business use cases and technical requirements and being able to convert them into a technical design that elegantly meets the requirements.\nImplementation of sophisticated analytics programs, machine learning, and statistical methods to prepare enterprise data for use in predictive and prescriptive modeling.\nAccountable for the data science platform design in addition to the use of case-based application solution design.\nWork on complex unstructured datasets using advanced statistical and analytical methods.\nWork closely with other technical and operational functions to gather, organize and analyze datasets to extract meaningful insights.\nWho you are and what you bring:\nMS or Bachelors in Computer Science, Math, Machine Learning, or a relevant field with 4 + yrs. of experience in industry and/or academic research\nStrong Experience in Python for Data Science, Data Science on AWS, Data Science solutions, Communication and Collaboration, Statistics Probability.\nAbility to design and implement workflows of Linear Logistic Regression, Ensemble Models (Random Forest, Boosting) using R/Python or Optimisation methodologies\nDemonstrable competency in Probability Statistics, ability to use ideas of Data Distributions, Hypothesis Testing, and other Statistical Tests.\nDemonstrable competency in Data Visualisation using the Python/R Data Science Stack.\nHands-on experience in using statistical and analytical techniques to complex business problems.\nHands-on experience in solving regression, prediction, classification, clustering, neural networks, and Bayesian problems.\nAdvanced knowledge of statistical techniques, machine learning algorithms, Bayesian Models, data mining, and text mining.\nExperience in handling large datasets on cloud and on-premises setup, using distributed computing.\nAble to understand various data structures and common methods in data transformation.\nStrong Programming background and expertise in building models in languages like Python, R, Scala, etc.\nGood knowledge of visual techniques for data analysis and presentation skills\nStrong troubleshooting skills in different disparate technologies and environments\nEnthusiastic about different areas of work and exploring new technologies\nClarity of thought and strong communication skills to effectively pitch solutions\nAbility to explore and grasp new technologies\nMentoring your team members in projects and helping them keep up with new technologies\nEmpowering the team members to be solution providers and enable a flat environment where every ones point of view is considered, and feedback is encouraged.",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Agile', 'Data structures', 'System design', 'Troubleshooting', 'Data mining', 'Analytics', 'Python']",2025-06-14 05:40:09
Sr. Data Scientist,SoulPage IT,3 - 5 years,Not Disclosed,['Hyderabad'],"Sr.Data Scientist - Soulpage IT Solutions\nHome\nSr.Data Scientist\nMay 28, 2024\nJob Title: Data Scientist\nWork Exp: 3+ yrs\nApproximate CTC: Industry Standards\nLocation: Hyderabad\nFunctional Area: IT Software System Programming\nQualification: B.Tech/B.E/M.Tech/B.Sc(math or statistics)/MSc(Statistics)\nJob Description:\nWe are looking for an experienced Data Scientist with a strong hold on Machine Learning and Deep Learning model building, deployment and has problem solving skills.\nSkills & Responsibilities:\nExcellent skills in Deep learning-based algorithms with image and text data and ML algorithms with structured datasets.\nStrong hold on computer vision libraries like OpenCV and Pillow and NLP libraries like Huggingface and Spacy.\nAbility to conceptualize and implement different deep neural network architectures in Python using Pytorch and Tensorflow.\nStrong mathematical statistical understanding behind the algorithms.\nIdeate, conceptualize and formulate Data Science use case of significant impact for the business\nDevelop and evaluate various Machine Learning models before zeroing in on the best one and ability to run Machine Learning models on huge amount of data\nDrive discussions with Business to ensure the complete understanding with respect to the data science use case; Gain and demonstrate Data and Domain knowledge\nEvaluate the Data Quality and Metadata information of Key Data Elements before any modelling effort to ensure minimal surprises in the later part of the project\nDesign holistic data science solution covering Descriptive, Predictive & Prescriptive analytics\nBuild reusable ML code for faster turnaround time to business problem solving\nExplain the Machine Learning model implementation to business stakeholders in a way that they can understand and appreciate the solution\nBuild storytelling dashboards to make all insights and model output available to end users in a form which is highly helpful for decision making\nManage relationship with business stakeholders acting as embedded data scientist constantly thinking about data science solutions to make business better\nKey Skills Required:\nPython, Pytorch, Tensorflow, OpenCV, Scikit Learn, Pandas and Numpy, Flask, Django, AWS, Deep Learning including CNNs, Transformers, and RNNs, and Statistical Modelling.\nAbout Company:\nSoulpage IT Solutions Pvt. Ltd.\nSOULPAGE is a Data Science Technology company based in Hyderabad, India. A simple organization with a strong commitment to customer service. We are committed to helping enterprises explore unventured technical avenues to tap unprecedented value creation. Our effort is to provide innovative software solutions using the latest technological advancements in the areas of automation, Data Science, AI, and application development for our clients to stay relevant and adapt to changing times.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer vision', 'Automation', 'metadata', 'Machine learning', 'System programming', 'Application development', 'Data quality', 'Customer service', 'Analytics', 'Python']",2025-06-14 05:40:11
Senior Data Scientist,Growby Exx Services,5 - 10 years,Not Disclosed,['Ahmedabad'],"Growexx is looking for smart and passionateData Scientist/Analyst, who will empower Marketing, Product, Sales teams to make strategic, data-driven decisions.\nKey Responsibilities\nMine, process, and analyse hit/event level web, product, sales, and digital marketing data. \nLeverage LLMs (Large Language Models) and traditional machine learning to mine, process, and analyze web, product, sales, and digital marketing event-level data.\nDevelop and fine-tune LLM-driven solutions for tasks such as text summarization, customer support automation, personalization, and user journey understanding.\nBuild and deploy predictive models and ML algorithms across structured and unstructured customer profile, journey, and usage datasets.\nDeploy LLM and ML models into production environments for activation across websites, product applications, and sales/marketing channels.\nDesign and implement model activation strategies, including A/B testing plans, benchmarking studies, and measurement of final business impact.\nConduct comprehensive evaluation of LLMs, including performance benchmarking (accuracy, latency, token usage, cost), prompt effectiveness testing, fine-tuning impact analysis, and safety/bias assessments.\nDesign, build, and deploy LLM-based agentic systems using frameworks such as LangChain, AutoGen, CrewAI, or custom orchestration for complex workflows (e.g., multi-agent collaboration, function-calling pipelines, dynamic task execution).\nIntegrate LLM agents with APIs, internal knowledge bases, retrieval systems (RAG architectures), and external tools to enable autonomous or semi-autonomous decision-making.\nPartner with data engineering teams to enhance and maintain the Customer360 data model, including creating new feature engineering requirements, improving taxonomy, and identifying and resolving data quality issues.\nCollaborate with cross-functional teams (Enterprise Data Warehouse, Salesforce MOPS, IT, Product, Marketing) to continuously improve data integration and quality for advanced modeling use cases.\nBuild a deep understanding of business models, objectives, challenges, and opportunities by working closely with leadership and key stakeholders.\nDocument model methodologies, evaluation frameworks, agent workflows, deployment architectures, and post-activation performance results in a structured and reproducible format.\nStay current with advancements in LLMs, agentic AI, retrieval-augmented generation (RAG), and ML technologies to recommend and implement innovative solutions.\nKey Skills\nExperience using Python, SciKit, SQL, Snowflake, product usage data, Jupyter Notebooks, Amazon SageMaker, Airflow, Github.\nProficient in data mining, advanced statistical analysis, feature engineering, and mathematical modeling.\nDeep experience with machine learning techniques including supervised, unsupervised, reinforcement learning, causal inference, and predictive modeling.\nSkilled across the full ML lifecycle: data preparation, feature creation and selection, model training, hyperparameter tuning, evaluation, and deployment for inference/prediction.\nExtensive hands-on experience with cookie-level advertising and digital marketing data (Google Ads, Bing, Epsilon, LinkedIn, Facebook) for demand generation KPIs such as ROAS, CTRs, impressions, multi-touch attribution (MTA).\nProven experience designing, fine-tuning, evaluating, and deploying Large Language Models (LLMs) and generative AI applications.\nExperience designing and deploying agentic systems using frameworks such as LangChain, AutoGen, CrewAI, and custom function-calling pipelines.\nExpertise integrating LLM agents with APIs, knowledge bases, retrieval systems (RAG architecture), and orchestrating dynamic multi-agent workflows.\nStrong understanding of evaluation metrics for LLMs, including prompt testing, token optimization, bias/safety analysis, latency, and cost benchmarks.\nDeep familiarity with cookie-level web and product behavior data (usage metrics, conversion funnels, bounce rates, sessions, hits/events, journey optimization).\nExpertise in designing and executing A/B, multivariate, and lift tests to measure activated ML/LLM model performance across digital and offline channels.\nSkilled in gathering business requirements, translating them into ML use cases, and clearly communicating methodologies and results to both technical and non-technical stakeholders.\nContinuous learner, keeping up-to-date with the latest advances in transformers, generative AI models, retrieval-augmented generation (RAG), and agentic AI frameworks.\nPreferred: practical experience in an engineering capacity building, testing, deploying, and optimizing ensemble ML and LLM solutions in production environments.\nEducation and Experience\nB Tech or B. E. (Computer Science / Information Technology)\n5 + years as a Data Scientist or similar roles.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'LLM', 'Machine Learning', 'Deep Learning']",2025-06-14 05:40:15
Senior Data Scientist,Virtana Corp,6 - 11 years,Not Disclosed,"['Pune', 'Chennai']","We are seeking a Senior Data Scientist Engineer with experience bringing highly scalable enterprise SaaS applications to market. This is a uniquely impactful opportunity to help drive our business forward and directly contribute to long-term growth at Virtana.\nIf you thrive in a fast-paced environment, take initiative, embrace proactivity and collaboration, and you re seeking an environment for continuous learning and improvement, we d love to hear from you!\nVirtana is a remote first work environment so you ll be able to work from the comfort of your home while collaborating with teammates on a variety of connectivity tools and technologies.\nRole Responsibilities:\nResearch and test machine learning approaches for analyzing large-scale distributed computing applications.\nDevelop production-ready implementations of proposed solutions across different models AI and ML algorithms, including testing on live customer data to improve accuracy, efficacy, and robustness\nWork closely with other functional teams to integrate implemented systems into the SaaS platform\nSuggest innovative and creative concepts and ideas that would improve the overall platform.\nJob Location - Pune, Chennai or Remote\nQualifications:\nThe ideal candidate must have the following qualifications:\n6 + years experience in practical implementation and deployment of large customer-facing ML based systems.\nMS or M Tech (preferred) in applied mathematics/statistics; CS or Engineering disciplines are acceptable but must have with strong quantitative and applied mathematical skills\nIn-depth working, beyond coursework, familiarity with classical and current ML techniques, both supervised and unsupervised learning techniques and algorithms\nImplementation experiences and deep knowledge of Classification, Time Series Analysis, Pattern Recognition, Reinforcement Learning, Deep Learning, Dynamic Programming and Optimization\nExperience in working on modeling graph structures related to spatiotemporal systems\nProgramming skills in Python is a must\nExperience in understanding and usage of LLM models and Prompt engineering is preferred.\nExperience in developing and deploying on cloud (AWS or Google or Azure)\nGood verbal and written communication skills\nFamiliarity with well-known ML frameworks such as Pandas, Keras, TensorFlow",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Time series analysis', 'Artificial Intelligence', 'IT operations management', 'Machine learning', 'Cloud', 'Cash flow', 'Pattern recognition', 'Performance monitoring', 'Python']",2025-06-14 05:40:17
Senior Consultant - Data Science,Arcadis,8 - 13 years,Not Disclosed,['Bengaluru'],"Qualification & Experience:\nMinimum of 8 years of experience as a Data Scientist/Engineer with demonstrated expertise in data engineering and cloud computing technologies.\nTechnical Responsibilities\nExcellent proficiency in Python, with a strong focus on developing advanced skills.\nExtensive exposure to NLP and image processing concepts.\nProficient in version control systems like Git.\nIn-depth understanding of Azure deployments.\nExpertise in OCR, ML model training, and transfer learning.\nExperience working with unstructured data formats such as PDFs, DOCX, and images. O\nStrong familiarity with data science best practices and the ML lifecycle.\nStrong experience with data pipeline development, ETL processes, and data engineering tools such as Apache Airflow, PySpark, or Databricks.\nFamiliarity with cloud computing platforms like Azure, AWS, or GCP, including services like Azure Data Factory, S3, Lambda, and BigQuery.\nTool Exposure: Advanced understanding and hands-on experience with Git, Azure, Python, R programming and data engineering tools such as Snowflake, Databricks, or PySpark.\nData mining, cleaning and engineering: Leading the identification and merging of relevant data sources, ensuring data quality, and resolving data inconsistencies.\nCloud Solutions Architecture: Designing and deploying scalable data engineering workflows on cloud platforms such as Azure, AWS, or GCP.\nData Analysis: Executing complex analyses against business requirements using appropriate tools and technologies.\nSoftware Development: Leading the development of reusable, version-controlled code under minimal supervision.\nBig Data Processing: Developing solutions to handle large-scale data processing using tools like Hadoop, Spark, or Databricks.\nPrincipal Duties & Key Responsibilities:\nLeading data extraction from multiple sources, including PDFs, images, databases, and APIs.\nDriving optical character recognition (OCR) processes to digitize data from images.\nApplying advanced natural language processing (NLP) techniques to understand complex data.\nDeveloping and implementing highly accurate statistical models and data engineering pipelines to support critical business decisions and continuously monitor their performance.\nDesigning and managing scalable cloud-based data architectures using Azure, AWS, or GCP services.\nCollaborating closely with business domain experts to identify and drive key business value drivers.\nDocumenting model design choices, algorithm selection processes, and dependencies.\nEffectively collaborating in cross-functional teams within the CoE and across the organization.\nProactively seeking opportunities to contribute beyond assigned tasks.\nRequired Competencies:\nExceptional communication and interpersonal skills.\nProficiency in Microsoft Office 365 applications.\nAbility to work independently, demonstrate initiative, and provide strategic guidance.\nStrong networking, communication, and people skills.\nOutstanding organizational skills with the ability to work independently and as part of a team.\nExcellent technical writing skills.\nEffective problem-solving abilities.\nFlexibility and adaptability to work flexible hours as required.\nKey competencies / Values:\nClient Focus: Tailoring skills and understanding client needs to deliver exceptional results.\nExcellence: Striving for excellence defined by clients, delivering high-quality work.\nTrust: Building and retaining trust with clients, colleagues, and partners.\nTeamwork: Collaborating effectively to achieve collective success.\nResponsibility: Taking ownership of performance and safety, ensuring accountability.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Big Data Processing', 'Software Development', 'Data cleaning', 'Data engineering', 'Data mining', 'cloud computing', 'OCR']",2025-06-14 05:40:19
Plant Operations and Sales Analyst Manager,Our clients are leading MNC & Industrial...,3 - 6 years,Not Disclosed,"['Middle East', 'Asia']","Res. 4 data analysis, sales support, & Oprs. insights to improve efficiency & Perf. within a Mfg. Env. Analyses sales data, tracks plant oprs., identifies trends, & make recom. 2 optimize processes, improve forecasting,& enhance overall sales perf.\n\nRequired Candidate profile\nBE & MBA with Exp. Of 3-5 Yrs in Analyst Role or related field in Mfg. inds. & Strong ability to analyze data, identify trends, & draw conclusions. Proficiency in creating reports & dashboards.",Industry Type: FMCG,Department: Strategic & Top Management,"Employment Type: Full Time, Permanent","['Ebitda', 'Sales', 'Strategy', 'Operations', 'Growth', 'Revenue', 'profit', 'PNL']",2025-06-14 05:40:21
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Bengaluru'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:40:23
Senior Consultant Data Science,Arcadis,8 - 13 years,Not Disclosed,['Bengaluru'],"Qualification & Experience:\nMinimum of 8 years of experience as a Data Scientist/Engineer with demonstrated expertise in data engineering and cloud computing technologies.\nTechnical Responsibilities\nExcellent proficiency in Python, with a strong focus on developing advanced skills.\nExtensive exposure to NLP and image processing concepts.\nProficient in version control systems like Git.\nIn-depth understanding of Azure deployments.\nExpertise in OCR, ML model training, and transfer learning.\nExperience working with unstructured data formats such as PDFs, DOCX, and images. O\nStrong familiarity with data science best practices and the ML lifecycle.\nStrong experience with data pipeline development, ETL processes, and data engineering tools such as Apache Airflow, PySpark, or Databricks.\nFamiliarity with cloud computing platforms like Azure, AWS, or GCP, including services like Azure Data Factory, S3, Lambda, and BigQuery.\nTool Exposure: Advanced understanding and hands-on experience with Git, Azure, Python, R programming and data engineering tools such as Snowflake, Databricks, or PySpark.\nData mining, cleaning and engineering: Leading the identification and merging of relevant data sources, ensuring data quality, and resolving data inconsistencies.\nCloud Solutions Architecture: Designing and deploying scalable data engineering workflows on cloud platforms such as Azure, AWS, or GCP.\nData Analysis: Executing complex analyses against business requirements using appropriate tools and technologies.\nSoftware Development: Leading the development of reusable, version-controlled code under minimal supervision.\nBig Data Processing: Developing solutions to handle large-scale data processing using tools like Hadoop, Spark, or Databricks.\nPrincipal Duties & Key Responsibilities:\nLeading data extraction from multiple sources, including PDFs, images, databases, and APIs.\nDriving optical character recognition (OCR) processes to digitize data from images.\nApplying advanced natural language processing (NLP) techniques to understand complex data.\nDeveloping and implementing highly accurate statistical models and data engineering pipelines to support critical business decisions and continuously monitor their performance.\nDesigning and managing scalable cloud-based data architectures using Azure, AWS, or GCP services.\nCollaborating closely with business domain experts to identify and drive key business value drivers.\nDocumenting model design choices, algorithm selection processes, and dependencies.\nEffectively collaborating in cross-functional teams within the CoE and across the organization.\nProactively seeking opportunities to contribute beyond assigned tasks.\nRequired Competencies:\nExceptional communication and interpersonal skills.\nProficiency in Microsoft Office 365 applications.\nAbility to work independently, demonstrate initiative, and provide strategic guidance.\nStrong networking, communication, and people skills.\nOutstanding organizational skills with the ability to work independently and as part of a team.\nExcellent technical writing skills.\nEffective problem-solving abilities.\nFlexibility and adaptability to work flexible hours as required.\nKey competencies / Values:\nClient Focus: Tailoring skills and understanding client needs to deliver exceptional results.\nExcellence: Striving for excellence defined by clients, delivering high-quality work.\nTrust: Building and retaining trust with clients, colleagues, and partners.\nTeamwork: Collaborating effectively to achieve collective success.\nResponsibility: Taking ownership of performance and safety, ensuring accountability.\nPeople: Creating an inclusive environment that fosters individual growth and development.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure Data Factory', 'S3', 'Apache Airflow', 'Azure', 'BigQuery', 'Git', 'PySpark', 'Lambda']",2025-06-14 05:40:26
Senior Consultant Data Science,Arcadis,8 - 13 years,Not Disclosed,['Bengaluru'],"Qualification & Experience:\nMinimum of 8 years of experience as a Data Scientist/Engineer with demonstrated expertise in data engineering and cloud computing technologies.\nTechnical Responsibilities\nExcellent proficiency in Python, with a strong focus on developing advanced skills.\nExtensive exposure to NLP and image processing concepts.\nProficient in version control systems like Git.\nIn-depth understanding of Azure deployments.\nExpertise in OCR, ML model training, and transfer learning.\nExperience working with unstructured data formats such as PDFs, DOCX, and images. O\nStrong familiarity with data science best practices and the ML lifecycle.\nStrong experience with data pipeline development, ETL processes, and data engineering tools such as Apache Airflow, PySpark, or Databricks.\nFamiliarity with cloud computing platforms like Azure, AWS, or GCP, including services like Azure Data Factory, S3, Lambda, and BigQuery.\nTool Exposure: Advanced understanding and hands-on experience with Git, Azure, Python, R programming and data engineering tools such as Snowflake, Databricks, or PySpark.\nData mining, cleaning and engineering: Leading the identification and merging of relevant data sources, ensuring data quality, and resolving data inconsistencies.\nCloud Solutions Architecture: Designing and deploying scalable data engineering workflows on cloud platforms such as Azure, AWS, or GCP.\nData Analysis: Executing complex analyses against business requirements using appropriate tools and technologies.\nSoftware Development: Leading the development of reusable, version-controlled code under minimal supervision.\nBig Data Processing: Developing solutions to handle large-scale data processing using tools like Hadoop, Spark, or Databricks.\nPrincipal Duties & Key Responsibilities:\nLeading data extraction from multiple sources, including PDFs, images, databases, and APIs.\nDriving optical character recognition (OCR) processes to digitize data from images.\nApplying advanced natural language processing (NLP) techniques to understand complex data.\nDeveloping and implementing highly accurate statistical models and data engineering pipelines to support critical business decisions and continuously monitor their performance.\nDesigning and managing scalable cloud-based data architectures using Azure, AWS, or GCP services.\nCollaborating closely with business domain experts to identify and drive key business value drivers.\nDocumenting model design choices, algorithm selection processes, and dependencies.\nEffectively collaborating in cross-functional teams within the CoE and across the organization.\nProactively seeking opportunities to contribute beyond assigned tasks.\nRequired Competencies:\nExceptional communication and interpersonal skills.\nProficiency in Microsoft Office 365 applications.\nAbility to work independently, demonstrate initiative, and provide strategic guidance.\nStrong networking, communication, and people skills.\nOutstanding organizational skills with the ability to work independently and as part of a team.\nExcellent technical writing skills.\nEffective problem-solving abilities.\nFlexibility and adaptability to work flexible hours as required.\nKey competencies / Values:\nClient Focus: Tailoring skills and understanding client needs to deliver exceptional results.\nExcellence: Striving for excellence defined by clients, delivering high-quality work.\nTrust: Building and retaining trust with clients, colleagues, and partners.\nTeamwork: Collaborating effectively to achieve collective success.\nResponsibility: Taking ownership of performance and safety, ensuring accountability.\nPeople: Creating an inclusive environment that fosters individual growth and development.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure Data Factory', 'S3', 'Big Query', 'Azure', 'GCP', 'Hadoop', 'Spark', 'Databricks', 'ETL', 'Lambda', 'AWS']",2025-06-14 05:40:29
Senior Data Governance Engineer,Aviatrix Systems,5 - 10 years,Not Disclosed,['Bengaluru'],"As a Senior Data Governance Engineer with 5+ years of relevant experience, you will be instrumental in designing, building, and maintaining Aviatrixs data governance framework. This position will have a significant impact on our data infrastructure by promoting best practices, enhancing data transparency, and establishing policies that enable seamless cross-functional collaboration. You will work independently with various teams to implement data governance solutions and ensure our data meets the highest standards of quality and compliance. The role requires flexibility to align with USA working hours (including until midnight IST) to effectively collaborate with global teams.",,,,"['Python', 'SQL', 'Azure Cloud']",2025-06-14 05:40:31
Senior Manufacturing Data Engineer,Analog Devices,3 - 8 years,Not Disclosed,['Bengaluru'],"About Analog Devices\nAnalog Devices, Inc. (NASDAQ: ADI ) is a global semiconductor leader that bridges the physical and digital worlds to enable breakthroughs at the Intelligent Edge. ADI combines analog, digital, and software technologies into solutions that help drive advancements in digitized factories, mobility, and digital healthcare, combat climate change, and reliably connect humans and the world. With revenue of more than $9 billion in FY24 and approximately 24,000 people globally, ADI ensures todays innovators stay Ahead of Whats Possible . Learn more at www.analog.com and on LinkedIn and Twitter (X) .\nResponsibilities\nAs a Senior Manufacturing Data Engineer, you will collaborate with cross-functional teams, including data analysts, product managers, data scientists, and engineers, to deliver impactful data solutions for semiconductor manufacturing and automation.\nTranslate business and functional requirements into scalable data solutions aligned with Data Architecture guidelines for manufacturing and test environments.\nDevelop and maintain data pipelines to process manufacturing data, including formats such as STDF files, wafer metrology data, wafer sort results, tool logs, MES data, and FDC data, ensuring seamless integration into enterprise data systems.\nWrite scripts and programs to parse, extract, and transform data from diverse sources, improving data accessibility and quality across systems.\nSupport the integration of manufacturing and test data into cloud-based platforms such as Snowflake and Azure Data Lake, enabling advanced analytics and scalable processing.\nContribute to the standardization and optimization of data flows from tool logs, wafer tracking systems, and test equipment to improve reporting and analytics accuracy.\nPartner with senior team members to enhance data quality and completeness across MES, SPC, and test systems.\nPerform root cause analysis on data issues, ensuring timely resolution and adherence to SLA requirements.\nAssist in building subject matter expertise in MES platforms like Camstar/OpCenter and PROMIS, SPC tools, and data analytics platforms.\nParticipate in the development of frameworks for data pipeline observability, including alerting and monitoring systems.\nQualifications\n3+ years in Data Engineering, Data Science, or Data Analytics roles, with a preference for candidates with experience in semiconductor manufacturing.\nDegree in Computer Science, Electrical Engineering, Computer Engineering, or a related field.\nProficiency in SQL and Python.\nExperience with data modeling, ELT processes, and data integration techniques.\nFamiliarity with big data tools (e.g., Spark, Hadoop), containerization (e.g., Kubernetes), and cloud platforms like Snowflake, Azure, and DBT.\nExposure to analytics and visualization tools like Spotfire, Power BI, or Tableau.\nBasic understanding of statistical methods and techniques for anomaly detection and root cause analysis.\nExperience with scripting and programming for data parsing and transformation.",Industry Type: Consumer Electronics & Appliances,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Analog', 'Metrology', 'Healthcare', 'Licensing', 'Monitoring', 'Analytics', 'SQL', 'Python']",2025-06-14 05:40:33
Company Data - Associate,MSCI Services,3 - 6 years,Not Disclosed,['Mumbai'],"Overview\nCompany data team (CDO) of MSCI is responsible for the processing, maintenance, and quality control of various Issuer level data points pertaining to Fundamental data (Balance sheet, Income statement & Cashflow), Segment Data and GICS assignment to the company. These datapoints and the derived ratios based on these data in turn serve as inputs to its various products related to Equity, Fixed income and ESG & Climate of MSCI.\nThe Quality, Process & Transformation (QPT) Team within the Company Data vertical is responsible for driving projects and efficiency initiatives across Company Data’s internal teams. It played an instrumental role in leading and shaping transformation efforts within company data by using their financial concepts, AI fundamentals, machine learning, prompt engineering, and technical skills like Python, Power BI, and SQL It is a techno-functional profile which has a perfect blend of functional knowledge of capital markets and technical expertise.\nAs a member of this dynamic team, you will be responsible for identifying opportunities to automate and optimize manual processes, fostering a culture of continuous improvement. You will guide your peers in leveraging automation to streamline operations and deliver tangible results. If you’re passionate about AI, thrive in a fast-paced, self-driven environment, and want to leave a lasting impact on the business, this is the perfect role for you.\nWe seek a highly skilled member with a proven track record in developing large-scale, reliable platforms from the ground up, not just applications or solutions. Experience in delivering multiple successful versions of platforms over time is a key advantage. You’ll collaborate closely with teams across product, research, operations, and program management, ensuring that the platforms you build are not only built to last but deliver immediate and long-term value.\nThis is a highly visible and impactful role that offers the opportunity for long-term growth within MSCI.\nResponsibilities\nYour Responsibilities\nTake the lead in finding panic areas where processes can be improved and automated through advanced AI tools and programming solutions.\nSpearhead key projects aimed at upgrading outdated systems, introducing innovative methods to boost operational performance.\nOffer support and guidance to colleagues in utilizing tools such as Python, Power BI, SQL, and machine learning to enhance the team's technical capabilities.\nPartner with various teams, including product development, research, and operations, to ensure cohesive project execution and solution delivery.\nContribute to the creation and implementation of reliable, scalable systems that meet both immediate needs and long-term goals.\nEncourage ongoing assessment of existing processes and recommend new strategies to improve operational efficiency and effectiveness.\nUse data analytics and visualization techniques to support informed decision-making and drive strategic initiatives.\nQualifications\nSkills and experience that will help you excel\n2-4 Years of relevant experience with solid understanding of financial principles and their application in capital markets\nProficiency in AI fundamentals, prompt engineering, and machine learning techniques.\nStrong programming skills for automation, data analysis, and database management. Expertise in data visualization and reporting using Power BI.\nSolid understanding of financial principles and their application in capital markets.\nExperience in automating manual processes to improve efficiency.\nProven track record of building scalable, reliable platforms from the ground up.\nAbility to guide teams in driving transformation and identifying optimization opportunities.\nStrong cross-functional teamwork with product, research, operations, and management teams.\nSkilled in identifying inefficiencies and creating innovative solutions.\nAbility to thrive in fast-paced, evolving environments with long-term commitment to projects.\n What we offer you\nTransparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\nFlexible working arrangements, advanced technology, and collaborative workspaces.\nA culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\nA global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\nGlobal Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\nMulti-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\nWe actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women’s Leadership Forum.\nAt MSCI we are passionate about what we do, and we are inspired by our purpose – to power better investment decisions. You’ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n To all recruitment agencies\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n Note on recruitment scams\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['fundamentals', 'python', 'data analysis', 'data analytics', 'access', 'data', 'bi', 'power bi', 'engineering', 'capital market', 'machine learning', 'research', 'sql', 'analytics', 'excel', 'database management', 'automation', 'operations', 'data science', 'data visualization', 'machine learning algorithms', 'reporting', 'programming']",2025-06-14 05:40:35
Lead Generation-Data Management-Biotechnology (off role)-Mumbai,Leading B2B Pharma & Life Sciences Compa...,2 - 7 years,4-6 Lacs P.A.,['Mumbai (All Areas)( Powai )'],"We are hiring for one of our multinational client for the role of Lead Generation based out at Mumbai (Powai). PFB the details:\n\n\nIndustry: Biotechnology (MNC)\nPayroll Company: Randstad India\nContract duration - 1 year & Extendable\nLocation: Mumbai (Powai)\nMin Qualification - BSc/MSc - Chemistry\nOther Requirements -\nGood in verbal & written english communication.\nData management will be part of the job & need good MS excel skills.\nLearning attitude.\nInter-team connection, Sales support & check on revenue generation\n\n\nInterested candidates may share their CV at: anisha.rana@randstad.in OR WhatsApp: 7973641471",Industry Type: Biotechnology,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Data Research', 'Lead Generation', 'Sales Support', 'Data Management', 'MS Office', 'Communication Skills', 'Presentation Skills', 'Data Analysis', 'Data Collection']",2025-06-14 05:40:38
Associate Specialist Data Science,Merck Sharp & Dohme (MSD),1 - 3 years,Not Disclosed,['Pune'],"We are seeking candidates with prior experience in the healthcare analytics or consulting sectors, prior hands-on experience in Data Science (building end-to-end ML models). It is preferred that you have a good understanding of Physician and Patient-level data (PLD) from leading vendors such as IQVIA, Komodo, and Optum. Familiarity with HCP Analytics, PLD analytics, concepts like persistence, compliance, line of therapy, etc., or Segmentation & Targeting is highly desirable. You will be part of a dynamic team that collaborates with our partners across therapeutic areas. Furthermore, effective communication skills are crucial, as this role requires interfacing with executive and business stakeholders.\nWho you are:\nYou understand the foundations of statistics and machine learning and can work in high performance computing/cloud environments, with experience/knowledge in aspects across statistical analysis, machine learning, model development, data engineering, data visualization, and data interpretation\nYou are self-motivated, and have demonstrated abilities to think independently as a data scientist\nYou structure your data science approach according to the necessary task, while appropriately applying the correct level of model complexity to the problem at hand\nYou have an agile mindset of continuous learning and will focus on integrating enterprise value into team culture\nYou are kind, collaborative, and capable of seeking and giving candid feedback that effectively contributes to a more seamless day-to-day execution of tasks\nKey Responsibilities:\nUnderstand the business requirements and support the manager to translate those to analytical problem statements.\nImplement the solution steps through SQL/Python, appropriate ML techniques without rigorous handholding.\nFollow technical requirements (Datasets, business rules, technical architecture) and industry best practices in every task.\nCollaborate with cross-functional teams to design and implement solutions that meet business requirements.\nPresent the findings to US DS stakeholders in a clear and concise manner and address feedback.\nAdopt a continuous learning mindset, both technical and functional.\nDevelop deep expertise in therapeutic area, with clear focus on commercial aspects.\nMinimum Qualifications:\nBachelor s degree with at least 1-3 years industry experience\nStrong Python/R, SQL, Excel skills\nStrong foundations of statistics and machine learning\nPreferred Qualifications:\nAdvanced degree in STEM (MS, MBA, PhD)\n2-3 years experience in healthcare analytics and consulting\nFamiliarity with Physician and Patient-Level data (e.g., claims, electronic health records) and data from common healthcare data vendors (IQVIA, Optum, Komodo, etc.)\nExperience in HCP & Patient Level Data analytics (e.g., HCP Segmentation & targeting, Patient Cohorts, knowledge of Lines of Therapy, Persistency, Compliance, etc.)\nProficiency in Data Science Concepts, Microsoft Excel and PowerPoint, and familiarity with Dataiku\nCurrent Employees apply HERE\nCurrent Contingent Workers apply HERE\nSearch Firm Representatives Please Read Carefully\nEmployee Status:\nRegular .",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Relationship management', 'Claims', 'Data modeling', 'Pharma', 'Analytical', 'Consulting', 'Healthcare', 'healthcare analytics', 'Business intelligence', 'SQL']",2025-06-14 05:40:41
Data Engineer,Capgemini,6 - 9 years,Not Disclosed,['Hyderabad'],"\nDesign, implement, and maintain data pipelines for data ingestion, processing, and transformation in Azure.\nWork together with data scientists and analysts to understand the needs for data and create effective data workflows.\nCreate and maintain data storage solutions including Azure SQL Database, Azure Data Lake, and Azure Blob Storage.\nUtilizing Azure Data Factory or comparable technologies, create and maintain ETL (Extract, Transform, Load) operations.\nImplementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.\nImprove the scalability, efficiency, and cost-effectiveness of data pipelines.\nMonitoring and resolving data pipeline problems will guarantee consistency and availability of the data.\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'azure data factory', 'sql', 'azure blob storage', 'sql azure', 'hive', 'azure databricks', 'python', 'data validation', 'pyspark', 'data warehousing', 'power bi', 'data engineering', 'spark', 'data ingestion', 'software engineering', 'hadoop', 'etl', 'big data', 'aws', 'sql database']",2025-06-14 05:40:44
Data Annotation Specialist,Yamaha Motor Solutions,1 - 3 years,3-4.5 Lacs P.A.,['Faridabad'],"We are seeking a highly detail-oriented and technically adept 3D Data Annotation Specialist to join our growing team. This role is critical in shaping high-quality datasets for training cutting-edge AI and computer vision models, particularly in domains such as LiDAR data processing, and 3D object detection.\n\nRoles and Responsibilities\nQualifications:\nB.Tech in Computer Science, IT, or related field preferred (others may also apply strong analytical and software learning abilities required).\nStrong analytical and reasoning skills, with attention to spatial geometry and object relationships in 3D space.\nBasic understanding of 3D data formats (e.g., .LAS, .LAZ, .PLY) and visualization tools.\nAbility to work independently while maintaining high-quality standards.\nExcellent communication skills and the ability to collaborate in a fast-paced environment.\nAttention to detail and ability to work with precision in visual/manual tasks.\nGood understanding of basic geometry, coordinate systems, and file handling.\nPreferred Qualifications:\nPrior experience in 3D data annotation or LiDAR data analysis.\nExposure to computer vision workflows.\nComfortable working with large datasets and remote sensing data\nKey Responsibilities:\nAnnotate 3D point cloud data with precision using specialized tools [ Training would be provided]\nLabel and segment objects within LiDAR data, aerial scans, or 3D models.\nFollow annotation guidelines while applying logical and spatial reasoning to 3D environments.\nCollaborate with ML engineers and data scientists to ensure annotation accuracy and consistency.\nProvide feedback to improve annotation tools and workflow automation.\nParticipate in quality control reviews and conduct re-annotation as needed",Industry Type: Automobile,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['annotation', 'python', 'data analysis', 'data analytics', 'modeling', 'analytical', 'software', 'strong analytical skills', 'data processing', 'machine learning', 'sql', 'data cleansing', 'data entry operation', 'cloud', '3d', 'data extraction', 'automation', 'data science', 'data annotation', 'lidar', 'communication skills']",2025-06-14 05:40:46
Real Assets Data Operations and Research Specialist,MSCI Services,6 - 9 years,Not Disclosed,['Mumbai'],"Overview\nWe are seeking an experienced and detail-oriented Senior Associate to join our Real Estate Data Team. This role will focus on ensuring the accuracy, completeness, and reliability of real estate data within our systems, supporting decision-making, compliance, and reporting functions. The ideal candidate has a strong background in real estate data management, quality control, and analytics, with a keen eye for detail and a passion for data integrity.\nResponsibilities\nWorking as part of a growing team of real estate performance analysts who provide real estate direct property indexes, benchmarks, performance analysis reports, and custom/ bespoke analysis to global real estate asset managers and asset owners\nKey Responsibilities:\nData Quality Assurance:\nImplement and oversee data quality controls for real estate data, including validation, cleansing, and verification processes.\nPerform regular audits of data to ensure accuracy and compliance with internal and external standards.\nDevelop and maintain data quality metrics and KPIs to track and improve data quality over time.\nData Management & Improvement:\nCollaborate with cross-functional teams to understand data needs and requirements.\nIdentify and address data quality issues and root causes by designing and implementing solutions that improve data reliability.\nCoordinate with data providers and vendors to ensure timely and accurate delivery of real estate data.\nReporting & Analytics:\nGenerate periodic reports on data quality performance, trends, and improvement areas for senior management.\nSupport data-driven decisions by providing accurate data and insights to stakeholders across the organization.\nAssist in the development of dashboards and visualization tools for real-time monitoring of data quality metrics.\nProcess Optimization & Automation:\nIdentify opportunities to streamline and automate data quality processes, reducing manual intervention and enhancing efficiency.\nParticipate in system upgrades, data migrations, and other initiatives, ensuring data integrity and smooth transitions.\nCompliance & Governance:\nEnsure adherence to data governance policies and industry regulations for real estate data.\nAssist in the development and implementation of data governance frameworks, standards, and best practices.\nTrain team members and other stakeholders on data quality policies and protocols.\nQualifications\n6-9 years of experience in the financial services industry\nProficiency in data quality tools and software (e.g., SQL, Python, R) and familiarity with data visualization tools (e.g., Tableau, Power BI).\nStrong analytical, problem-solving, and attention-to-detail skills.\nAbility to communicate complex data concepts to non-technical stakeholders effectively.\nCollaborative team player with a proactive approach to improving data quality processes.\n What we offer you\nTransparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\nFlexible working arrangements, advanced technology, and collaborative workspaces.\nA culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\nA global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\nGlobal Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\nMulti-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\nWe actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women’s Leadership Forum.\nAt MSCI we are passionate about what we do, and we are inspired by our purpose – to power better investment decisions. You’ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n To all recruitment agencies\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n Note on recruitment scams\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data management', 'data analysis', 'analytical', 'quality control', 'real estate', 'data research', 'web research', 'power bi', 'pivot table', 'research analysis', 'vlookup', 'market research', 'research', 'sql', 'analytics', 'excel', 'data quality', 'tableau', 'r', 'advanced excel', 'web technologies', 'quality tools', 'ms office']",2025-06-14 05:40:48
Data Quality Management & Configuration,Capgemini,4 - 7 years,Not Disclosed,['Coimbatore'],"\nThis role involves the development and application of engineering practice and knowledge in defining, configuring and deploying industrial digital technologies (including but not limited to PLM and MES) for managing continuity of information across the engineering enterprise, including design, industrialization, manufacturing and supply chain, and for managing the manufacturing data.\n\n - Grade Specific \nFocus on Digital Continuity and Manufacturing. Develops competency in own area of expertise. Shares expertise and provides guidance and support to others. Interprets clients needs. Completes own role independently or with minimum supervision. Identifies problems and relevant issues in straight forward situations and generates solutions. Contributes in teamwork and interacts with customers.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['project management', 'supply chain', 'data quality management', 'manufacturing', 'industrialization', 'npd', 'data analytics', 'data analysis', 'program management', 'new product development', 'manufacturing engineering', 'process engineering', 'sql', 'industrial engineering']",2025-06-14 05:40:51
Data Engineer,Capgemini,6 - 9 years,Not Disclosed,['Gurugram'],"\nesign, implement, and maintain data pipelines for data ingestion, processing, and transformation in Azure.\nWork together with data scientists and analysts to understand the needs for data and create effective data workflows.\nCreate and maintain data storage solutions including Azure SQL Database, Azure Data Lake, and Azure Blob Storage.\nUtilizing Azure Data Factory or comparable technologies, create and maintain ETL (Extract, Transform, Load) operations.\nImplementing data validation and cleansing procedures will ensure the quality, integrity, and dependability of the data.\nImprove the scalability, efficiency, and cost-effectiveness of data pipelines.\nMonitoring and resolving data pipeline problems will guarantee consistency and availability of the data.\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'azure data factory', 'sql', 'azure blob storage', 'sql azure', 'hive', 'azure databricks', 'python', 'data validation', 'pyspark', 'data warehousing', 'power bi', 'data engineering', 'spark', 'data ingestion', 'software engineering', 'hadoop', 'etl', 'big data', 'aws', 'sql database']",2025-06-14 05:40:54
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Mumbai'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\nYour primary responsibilities include\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\nStrive for continuous improvements by testing the build solution and working under an agile framework.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\n\n\nPreferred technical and professional experience",,,,"['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-14 05:40:57
Lead Data Engineer,Jio,6 - 11 years,Not Disclosed,['Mumbai (All Areas)'],"Overview of the Company:\nJio Platforms Ltd. is a revolutionary Indian multinational tech company, often referred to as India's biggest startup, headquartered in Mumbai. Launched in 2019, it's the powerhouse behind Jio, India's largest mobile network with over 400 million users. But Jio Platforms is more than just telecom. It's a comprehensive digital ecosystem, developing cutting-edge solutions across media, entertainment, and enterprise services through popular brands like JioMart, JioFiber, and JioSaavn.\nJoin us at Jio Platforms and be part of a fast-paced, dynamic environment at the forefront of India's digital transformation. Collaborate with brilliant minds to develop next-gen solutions that empower millions and revolutionize industries.\n\nTeam Overview:\nThe Data Platforms Team is the launchpad for a data-driven future, empowering the Reliance Group of Companies. We're a passionate group of experts architecting an enterprise-scale data mesh to unlock the power of big data, generative AI, and ML modelling across various domains. We don't just manage data we transform it into intelligent actions that fuel strategic decision-making. Imagine crafting a platform that automates data flow, fuels intelligent insights, and empowers the organization that's what we do.\nJoin our collaborative and innovative team, and be a part of shaping the future of data for India's biggest digital revolution! About the role.\n\nTitle: Lead Data Engineer\nLocation: Mumbai\n\nResponsibilities:\nEnd-to-End Data Pipeline Development: Design, build, optimize, and maintain robust data pipelines across cloud, on-premises, or hybrid environments, ensuring performance, scalability, and seamless data flow.\nReusable Components & Frameworks: Develop reusable data pipeline components and contribute to the team's data pipeline framework evolution.\nData Architecture & Solutions: Contribute to data architecture design, applying data modelling, storage, and retrieval expertise.\nData Governance & Automation: Champion data integrity, security, and efficiency through metadata management, automation, and data governance best practices.\nCollaborative Problem Solving: Partner with stakeholders, data teams, and engineers to define requirements, troubleshoot, optimize, and deliver data-driven insights.\nMentorship & Knowledge Transfer: Guide and mentor junior data engineers, fostering knowledge sharing and professional growth.\n\nQualification Details:\nEducation: Bachelor's degree or higher in Computer Science, Data Science, Engineering, or a related technical field.\nCore Programming: Excellent command of a primary data engineering language (Scala, Python, or Java) with a strong foundation in OOPS and functional programming concepts.\nBig Data Technologies: Hands-on experience with data processing frameworks (e.g., Hadoop, Spark, Apache Hive, NiFi, Ozone, Kudu), ideally including streaming technologies (Kafka, Spark Streaming, Flink, etc.).\nDatabase Expertise: Excellent querying skills (SQL) and strong understanding of relational databases (e.g., MySQL, PostgreSQL). Experience with NoSQL databases (e.g., MongoDB, Cassandra) is a plus.\nEnd-to-End Pipelines: Demonstrated experience in implementing, optimizing, and maintaining complete data pipelines, integrating varied sources and sinks including streaming real-time data.\nCloud Expertise: Knowledge of Cloud Technologies like Azure HDInsights, Synapse, EventHub and GCP DataProc, Dataflow, BigQuery.\nCI/CD Expertise: Experience with CI/CD methodologies and tools, including strong Linux and shell scripting skills for automation.\n\nDesired Skills & Attributes:\nProblem-Solving & Troubleshooting: Proven ability to analyze and solve complex data problems, troubleshoot data pipeline issues effectively.\nCommunication & Collaboration: Excellent communication skills, both written and verbal, with the ability to collaborate across teams (data scientists, engineers, stakeholders).\nContinuous Learning & Adaptability: A demonstrated passion for staying up-to-date with emerging data technologies and a willingness to adapt to new tools.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Azure Cloud', 'Kafka', 'Python']",2025-06-14 05:40:59
Specialist Digital Supply Chain Datamodeler/Data Engineer,Merck Sharp & Dohme (MSD),4 - 8 years,Not Disclosed,['Hyderabad'],"Our company is an innovative, global healthcare leader that is committed to improving health and well-being around the world with a diversified portfolio of prescription medicines, vaccines and animal health products. We continue to focus our research on conditions that affect millions of people around the world - diseases like Alzheimers, diabetes and cancer - while expanding our strengths in areas like vaccines and biologics.\nOur ability to excel depends on the integrity, knowledge, imagination, skill, diversity and teamwork of an individual like you. To this end, we strive to create an environment of mutual respect, encouragement and teamwork. As part of our global team, you ll have the opportunity to collaborate with talented and dedicated colleagues while developing and expanding your career.\nAs a Digital Supply Chain Data Modeler/Engineer, you will work as a member of the Digital Manufacturing Division team supporting Enterprise Orchestration Platform. You will be responsible for identifying, assessing, and solving complex business problems related to manufacturing and supply chain. You will receive training to achieve this, and you ll be amazed at the diversity of opportunities to develop your potential and grow professionally. You will collaborate with business stakeholders and determine analytical capabilities that will enable the creation of Insights-focused solutions that align to business needs and ensure that delivery of these solutions meet quality requirements.\nThe Opportunity\nBased in Hyderabad, joining a global healthcare biopharma company and be part of a 130- year legacy of success backed by ethical integrity, forward momentum, and an inspiring mission to achieve new milestones in global healthcare.\nBe part of an organization driven by digital technology and data-backed approaches that support a diversified portfolio of prescription medicines, vaccines, and animal health products.\nDrive innovation and execution excellence. Be a part of a team with passion for using data, analytics, and insights to drive decision-making, and which creates custom software, allowing us to tackle some of the worlds greatest health threats.\nOur Technology Centers focus on creating a space where teams can come together to deliver business solutions that save and improve lives. An integral part of our company s IT operating model, Tech Centers are globally distributed locations where each IT division has employees to enable our digital transformation journey and drive business outcomes. These locations, in addition to the other sites, are essential to supporting our business and strategy.\nA focused group of leaders in each Tech Centre helps to ensure we can manage and improve each location, from investing in growth, success, and well-being of our people, to making sure colleagues from each IT division feel a sense of belonging to managing critical emergencies. And together, we must leverage the strength of our team to collaborate globally to optimize connections and share best practices across the Tech Centers.\nAs Data modeler lead, you will be responsible for following\nDeliver divisional analytics initiatives with primary focus on datamodeling for all analytics, advanced analytics and AI/ML uses cases e,g Self Services , Business Intelligence & Analytics, Data exploration, Data Wrangling etc.\nHost and lead requirement/process workshop to understand the requirements of datamodeling .\nAnalysis of business requirements and work with architecture team to deliver & contribute to feasibility analysis, implementation plans and high-level estimates.\nBased on business process and analysis of data sources, deliver detailed ETL design with mapping of data model covering all areas of Data warehousing for all analytics use cases .\nCreation of data model & transformation mapping in modeling tool and deploy in databases including creation of schedule orchestration jobs .\nDeployment of Data modeling configuration to Target systems (SIT , UAT & Prod ) .\nUnderstanding of Product owership and management.\nLead Data model as a product for focus areas of Digital supply chain domain.\nCreation of required SDLC documentation as per project requirements.\nOptimization/industrialization of existing database and data transformation solution\nPrepare and update Data modeling and Data warehousing best practices along with foundational platforms.\nWork very closely with foundational product teams, Business, vendors and technology support teams to build team to deliver business initiatives .\nPosition Qualifications :\nEducation Minimum Requirement: - B.S. or M.S. in IT, Engineering, Computer Science, or related field.\nRequired Experience and Skills**:\n5+ years of relevant work experience, with demonstrated expertise in Data modeling in DWH, Data Mesh or any analytics related implementation; experience in implementing end to end DWH solutions involving creating design of DWH and deploying the solution\n3+ years of experience in creating logical & Physical data model in any modeling tool ( SAP Power designer, WhereScape etc ).\nExperience in creating data modeling standards, best practices and Implementation process.\nHigh Proficiency in Information Management, Data Analysis and Reporting Requirement Elicitation\nExperience working with extracting business rules to develop transformations, data lineage, and dimension data modeling\nExperience working with validating legacy and developed data model outputs\nDevelopment experience using WhereScape and various similar ETL/Data Modeling tools\nExposure to Qlik or similar BI dashboarding applications\nHas advanced knowledge of SQL and data transformation practices\nHas deep understanding of data modelling and preparation of optimal data structures\nIs able to communicate with business, data transformation team and reporting team\nHas knowledge of ETL methods, and a willingness to learn ETL technologies\nCan fluently communicate in English\nExperience in Redshift or similar databases using DDL, DML, Query optimization, Schema management, Security, etc\nExperience with Airflow or similar various orchestration tools\nExposure to CI/CD tools\nExposure to AWS modules such as S3, AWS Console, Glue, Spectrum, etc management\nIndependently support business discussions, analyze, and develop/deliver code\nPreferred Experience and Skills:\nExperience working on projects where Agile methodology is leveraged Understanding of data management best practices and data analytics Ability to lead requirements sessions with clients and project teams Strong leadership, verbal and written communication skills with ability to articulate results and issues to internal and client teams Demonstrated experience in the Life Science space Exposure to SAP and Rapid Response domain data is a plus",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['CVS', 'Data analysis', 'SAP', 'Database administration', 'Data structures', 'Healthcare', 'Business intelligence', 'Information technology', 'SDLC', 'SQL']",2025-06-14 05:41:01
Data Engineer-Data Integration,IBM,2 - 5 years,Not Disclosed,['Pune'],"As Data Engineer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You'll contribute to data gathering, storage, and both batch and real-time processing.\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\n\nIn this role, your responsibilities may include:\n\n\n \n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\nPreferred technical and professional experience",,,,"['information management', 'data warehousing', 'business intelligence', 'etl', 'data integration', 'python', 'informatica powercenter', 'power bi', 'relational sql', 'data migration', 'azure cloud', 'sql', 'elastic search', 'unix shell scripting', 'splunk', 'agile', 'big data', 'informatica']",2025-06-14 05:41:04
Data Engineer Specialist,Accenture,3 - 4 years,Not Disclosed,['Kochi'],"Job Title - + +\n\n\n\nManagement Level :\n\n\n\nLocation:Kochi, Coimbatore, Trivandrum\n\n\n\nMust have skills:Python, Pyspark\n\n\n\n\nGood to have skills:Redshift\n\n\n\nJob\n\n\nSummary: We are seeking a highly skilled and experienced Senior Data Engineer to join our growing Data and Analytics team. The ideal candidate will have deep expertise in Databricks and cloud data warehousing, with a proven track record of designing and building scalable data pipelines, optimizing data architectures, and enabling robust analytics capabilities. This role involves working collaboratively with cross-functional teams to ensure the organization leverages data as a strategic asset. Your responsibilities will include:\n\n\n\n\nRoles & Responsibilities\nDesign, build, and maintain scalable data pipelines and ETL processes using Databricks and other modern tools.\nArchitect, implement, and manage cloud-based data warehousing solutions on Databricks (Lakehouse Architecture)\nDevelop and maintain optimized data lake architectures to support advanced analytics and machine learning use cases.\nCollaborate with stakeholders to gather requirements, design solutions, and ensure high-quality data delivery.\nOptimize data pipelines for performance and cost efficiency.\nImplement and enforce best practices for data governance, access control, security, and compliance in the cloud.\nMonitor and troubleshoot data pipelines to ensure reliability and accuracy.\nLead and mentor junior engineers, fostering a culture of continuous learning and innovation.\nExcellent communication skills\nAbility to work independently and along with client based out of western Europe\n\n\n\n\nProfessional & Technical\n\n\n\n\nSkills:\nDesigning, developing, optimizing, and maintaining data pipelines that adhere to ETL principles and business goals\nSolving complex data problems to deliver insights that helps our business to achieve their goals.\nSource data (structured unstructured) from various touchpoints, format and organize them into an analyzable format.\nCreating data products for analytics team members to improve productivity\nCalling of AI services like vision, translation etc. to generate an outcome that can be used in further steps along the pipeline.\nFostering a culture of sharing, re-use, design and operational efficiency of data and analytical solutions\nPreparing data to create a unified database and build tracking solutions ensuring data quality\nCreate Production grade analytical assets deployed using the guiding principles of CI/CD.\n\n\n\nProfessional and Technical Skills\nExpert in Python, Scala, Pyspark, Pytorch, Javascript (any 2 at least)\nExtensive experience in data analysis (Big data- Apache Spark environments), data libraries (e.g. Pandas, SciPy, Tensorflow, Keras etc.), and SQL. 3-4 years of hands-on experience working on these technologies.\nExperience in one of the many BI tools such as Tableau, Power BI, Looker.\nGood working knowledge of key concepts in data analytics, such as dimensional modeling, ETL, reporting/dashboarding, data governance, dealing with structured and unstructured data, and corresponding infrastructure needs.\nWorked extensively in Microsoft Azure (ADF, Function Apps, ADLS, Azure SQL), AWS (Lambda,Glue,S3), Databricks analytical platforms/tools, Snowflake Cloud Datawarehouse.\n\n\n\n\nAdditional Information\nExperience working in cloud Data warehouses like Redshift or Synapse\nCertification in any one of the following or equivalent\nAWS- AWS certified data Analytics- Speciality\nAzure- Microsoft certified Azure Data Scientist Associate\nSnowflake- Snowpro core- Data Engineer\nDatabricks Data Engineering\n\nQualification\n\n\n\nExperience:5-8 years of experience is required\n\n\n\n\nEducational Qualification:Graduation (Accurate educational details should capture)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'pyspark', 'pytorch', 'python', 'data bricks', 'glue', 'amazon redshift', 'data warehousing', 'sql', 'tensorflow', 'sql azure', 'spark', 'keras', 'big data', 'etl', 'snowflake', 'scipy', 'data analysis', 'azure data lake', 'microsoft azure', 'power bi', 'javascript', 'pandas', 'tableau', 'lambda expressions', 'aws']",2025-06-14 05:41:07
"Specialist, Data Architecture",Fiserv,8 - 12 years,Not Disclosed,['Noida'],"Responsibilities\nRequisition ID R-10358179 Date posted 06/11/2025 End Date 07/15/2025 City Noida State/Region Uttar Pradesh Country India Location Type Onsite\nCalling all innovators find your future at Fiserv.\nJob Title\nSpecialist, Data Architecture\nWhat does a successful Lead, Data Conversions do\nA Conversion Lead is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible to provide data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Lead plays a critical role in mapping in data to support project initiatives for new and existing banks. Leads provide a specialized service to the Project Manager teams developing custom reporting, providing technical assistance, and ensuring project timelines are met.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nWhat you will do\nA Conversion Lead is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible to provide data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Lead plays a critical role in mapping in data to support project initiatives for new and existing banks/clients. Lead provides a specialized service to the Project Manager teams developing custom reporting, providing technical assistance, and ensuring project timelines are met.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nThe person stepping in as the backup would need to review the specifications history and then review and understand the code that was being developed to resolve the issue and or change. This would also have to occur on the switch back to the original developer.\nToday, the associate handling the project would log back in to support the effort and address the issue and or change.\nWhat you will need to have\nBachelor s degree in programming or related field\nWorking Hours (IST):\n12:00 p.m. 09:00 p.m. (IST)\nMonday through Friday\nHighest attention to detail and accuracy\nTeam player with ability to work independently\nAbility to manage and prioritize work queue across multiple workstreams\nStrong communication skills and ability to provide technical information to non-technical colleagues\nWhat would be great to have\nExperience with Data Modelling, Informatica, Power BI, MS Visual Basic, Microsoft Access and Microsoft Excel required.\nExperience with Card Management systems, debit card processing is a plus\nUnderstanding Applications and related database features that can be leveraged to improve performance\nExperience of creating testing artifacts (test cases, test plans) and knowledge of various testing types.\n8 12 years Experience and strong knowledge of MS SQL/PSQL, MS SSIS and Data warehousing concepts\nShould have strong database fundamentals and Expert knowledge in writing SQL commands, queries and stored procedures\nExperience in Performance Tuning of SQL complex queries.\nStrong communication skills and ability to provide technical information to non-technical colleagues.\nAbility to mentor junior team members\nAbility to manage and prioritize work queue across multiple workstreams.\nTeam player with ability to work independently.\nExperience in full software development life cycle using agile methodologies.\nShould have good understanding of Agile methodologies and can handle agile ceremonies.\nEfficient in Reviewing, Analyzing, coding, testing, and debugging of application programs.\nShould be able to work under pressure while resolving critical issues in Prod environment.\nGood communication skills and experience in working with Clients.\nGood understanding in Banking Domain.\nMinimum 8 years relevant experience in data processing (ETL) conversions or financial services industry\nThank you for considering employment with Fiserv. Please:\nApply using your legal name\nComplete the step-by-step profile and attach your resume (either is acceptable, both are preferable).\nOur commitment to Diversity and Inclusion:\nFiserv is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, gender, gender identity, sexual orientation, age, disability, protected veteran status, or any other category protected by law.\nNote to agencies:\nFiserv does not accept resume submissions from agencies outside of existing agreements. Please do not send resumes to Fiserv associates. Fiserv is not responsible for any fees associated with unsolicited resume submissions.\nWarning about fake job posts:\nPlease be aware of fraudulent job postings that are not affiliated with Fiserv. Fraudulent job postings may be used by cyber criminals to target your personally identifiable information and/or to steal money or financial information. Any communications from a Fiserv representative will come from a legitimate Fiserv email address.\n\n\n\nShare this Job\nEmail\nLinkedIn\nX\nFacebook",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'MS SQL', 'Visual Basic', 'Coding', 'Debugging', 'Agile', 'Informatica', 'Stored procedures', 'SSIS', 'SQL']",2025-06-14 05:41:09
Data Consultant_Strategy & Consulting,Capgemini,8 - 10 years,Not Disclosed,['Pune'],"Capgemini Invent \n\nCapgemini Invent is the digital innovation, consulting and transformation brand of the Capgemini Group, a global business line that combines market leading expertise in strategy, technology, data science and creative design, to help CxOs envision and build whats next for their businesses.\n\n Your Role \n Client Engagement & Advisory: \nPartner with clients to understand their business goals, CX challenges, and data needs.\nProvide strategic recommendations on how to leverage data to enhance customer engagement, satisfaction, and retention.\n Data Strategy Development: \nDesign comprehensive data strategies tailored to client objectives, including customer segmentation, predictive modelling, and personalization.\nDefine KPIs and metrics to measure the success of CX initiatives.\n Data Analysis & Insights: \nAnalyze structured and unstructured data to derive actionable insights.\nLeverage advanced analytics techniques, including machine learning and AI, to identify trends and opportunities.\n Solution Design & Implementation: \nCollaborate with technical teams to design and implement data platforms, dashboards, and analytics solutions.\nDrive the implementation of customer data platforms (CDPs), marketing automation tools, and analytics systems.\n Stakeholder Management: \nAct as a trusted advisor to business stakeholders.\nPresent findings, recommendations, and reports in a clear, compelling manner\n\n\n Your Profile \n8-10 years of experience in data analytics, data strategy, or consulting roles, with a focus on customer experience, marketing, or business transformation.\nMinimum of 5-8 years of experience in omni-channel marketing, data analytics, or marketing automation implementation, with at least 2 years in a consulting role.\n3+ years of experience in marketing orchestration, preferably with hands-on experience using marketing automation platforms (e.g., Salesforce Marketing Cloud, Adobe Campaign, Braze, Marketo, etc.) and leveraging customer data for personalized, cross-channel campaigns.\nBachelors degree in data science, Business Analytics, Computer Science, Marketing, or related fields. Masters degree preferable.\n Technical\n\nSkills:\n Proficiency in analytics tools (e.g., Python, R, SQL).\nFamiliarity with visualization tools (e.g., Tableau, Power BI).\nExperience implementing CDP tools (Salesforce CDP, Adobe CDP, Segment etc)\nKnowledge of cloud platforms (e.g., AWS, Azure, Google Cloud) is a plus.\nData Analytics\nData modelling\nDigital Marketing\nDigital Technology Consulting\nData-Driven Marketing\nProven track record of contributing to client engagements and delivering data-driven solutions.\nStrong communication, problem-solving, and interpersonal skills.\n\n\n What you will love about working here \nWe recognize the significance of flexible work arrangements to provide support. Be it remote work, or flexible work hours, you will get an environment to maintain healthy work life balance.\nAt the heart of our mission is your career growth. Our array of career growth programs and diverse professions are crafted to support you in exploring a world of opportunities.\nEquip yourself with valuable certifications in the latest technologies such as Generative AI.\n\n\n About Capgemini \n\nCapgemini is a global business and technology transformation partner, helping organizations to accelerate their dual transition to a digital and sustainable world, while creating tangible impact for enterprises and society. It is a responsible and diverse group of 340,000 team members in more than 50 countries. With its strong over 55-year heritage, Capgemini is trusted by its clients to unlock the value of technology to address the entire breadth of their business needs. It delivers end-to-end services and solutions leveraging strengths from strategy and design to engineering, all fueled by its market leading capabilities in AI, cloud and data, combined with its deep industry expertise and partner ecosystem. The Group reported 2023 global revenues of 22.5 billion",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'analytics tool', 'channel marketing', 'marketing automation', 'marketing', 'digital marketing', 'python', 'power bi', 'microsoft azure', 'adobe', 'omni', 'cdp', 'sql', 'salesforce', 'tableau', 'r', 'salesforce marketing cloud', 'data modeling', 'gcp', 'adobe campaign', 'aws']",2025-06-14 05:41:12
Azure Cloud Data Engineering Consultant,Optum,7 - 10 years,17-27.5 Lacs P.A.,['Gurugram'],"Primary Responsibilities:\nDesign and develop applications and services running on Azure, with a strong emphasis on Azure Databricks, ensuring optimal performance, scalability, and security.\nBuild and maintain data pipelines using Azure Databricks and other Azure data integration tools.\nWrite, read, and debug Spark, Scala, and Python code to process and analyze large datasets.\nWrite extensive query in SQL and Snowflake\nImplement security and access control measures and regularly audit Azure platform and infrastructure to ensure compliance.\nCreate, understand, and validate design and estimated effort for given module/task, and be able to justify it.\nPossess solid troubleshooting skills and perform troubleshooting of issues in different technologies and environments.\nImplement and adhere to best engineering practices like design, unit testing, functional testing automation, continuous integration, and delivery.\nMaintain code quality by writing clean, maintainable, and testable code.\nMonitor performance and optimize resources to ensure cost-effectiveness and high availability.\nDefine and document best practices and strategies regarding application deployment and infrastructure maintenance.\nProvide technical support and consultation for infrastructure questions.\nHelp develop, manage, and monitor continuous integration and delivery systems.\nTake accountability and ownership of features and teamwork.\nComply with the terms and conditions of the employment contract, company policies and procedures, and any directives.\nRequired Qualifications:\nB.Tech/MCA (Minimum 16 years of formal education)\nOverall 7+ years of experience.\nMinimum of 3 years of experience in Azure (ADF), Databricks and DevOps.\n5 years of experience in writing advanced level SQL.\n2-3 years of experience in writing, reading, and debugging Spark, Scala, and Python code.\n3 or more years of experience in architecting, designing, developing, and implementing cloud solutions on Azure.\nProficiency in programming languages and scripting tools.\nUnderstanding of cloud data storage and database technologies such as SQL and NoSQL.\nProven ability to collaborate with multidisciplinary teams of business analysts, developers, data scientists, and subject-matter experts.\nFamiliarity with DevOps practices and tools, such as continuous integration and continuous deployment (CI/CD) and Teraform.\nProven proactive approach to spotting problems, areas for improvement, and performance bottlenecks.\nProven excellent communication, writing, and presentation skills.\nExperience in interacting with international customers to gather requirements and convert them into solutions using relevant skills.\nPreferred Qualifications:\nKnowledge of AI/ML or LLM (GenAI).\nKnowledge of US Healthcare domain and experience with healthcare data.\nExperience and skills with Snowflake.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Azure Databricks', 'ETL', 'SQL', 'Python', 'Airflow', 'Pyspark', 'Snowflake', 'SCALA', 'Spark', 'Data Bricks']",2025-06-14 05:41:15
Data Engineer-Data Platforms,IBM,5 - 10 years,Not Disclosed,['Navi Mumbai'],"As a Big Data Engineer, you will develop, maintain, evaluate, and test big data solutions. You will be involved in data engineering activities like creating pipelines/workflows for Source to Target and implementing solutions that tackle the clients needs.\n\nYour primary responsibilities include:\nDesign, build, optimize and support new and existing data models and ETL processes based on our clients business requirements.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\nPreferred technical and professional experience",,,,"['scala', 'hadoop spark', 'spark', 'big data', 'python', 'hive', 'cloudera', 'pyspark', 'sql', 'java', 'git', 'postgresql', 'devops', 'jenkins', 'data ingestion', 'mysql', 'hadoop', 'etl', 'hbase', 'data analysis', 'dynamo db', 'oozie', 'microsoft azure', 'impala', 'data engineering', 'lambda expressions', 'kafka', 'sqoop', 'aws']",2025-06-14 05:41:17
Senior Data Engineer,PulseData labs Pvt Ltd,7 - 10 years,Not Disclosed,['Bengaluru'],"Company name: PulseData labs Pvt Ltd (captive Unit for URUS, USA)\n\nAbout URUS\nWe are the URUS family (US), a global leader in products and services for Agritech.\n\nSENIOR DATA ENGINEER\nThis role is responsible for the design, development, and maintenance of data integration and reporting solutions. The ideal candidate will possess expertise in Databricks and strong skills in SQL Server, SSIS and SSRS, and experience with other modern data engineering tools such as Azure Data Factory. This position requires a proactive and results-oriented individual with a passion for data and a strong understanding of data warehousing principles.\n\nResponsibilities\nData Integration\nDesign, develop, and maintain robust and efficient ETL pipelines and processes on Databricks.\nTroubleshoot and resolve Databricks pipeline errors and performance issues.\nMaintain legacy SSIS packages for ETL processes.\nTroubleshoot and resolve SSIS package errors and performance issues.\nOptimize data flow performance and minimize data latency.\nImplement data quality checks and validations within ETL processes.\nDatabricks Development\nDevelop and maintain Databricks pipelines and datasets using Python, Spark and SQL.\nMigrate legacy SSIS packages to Databricks pipelines.\nOptimize Databricks jobs for performance and cost-effectiveness.\nIntegrate Databricks with other data sources and systems.\nParticipate in the design and implementation of data lake architectures.\nData Warehousing\nParticipate in the design and implementation of data warehousing solutions.\nSupport data quality initiatives and implement data cleansing procedures.\nReporting and Analytics\nCollaborate with business users to understand data requirements for department driven reporting needs.\nMaintain existing library of complex SSRS reports, dashboards, and visualizations.\nTroubleshoot and resolve SSRS report issues, including performance bottlenecks and data inconsistencies.\nCollaboration and Communication\nComfortable in entrepreneurial, self-starting, and fast-paced environment, working both independently and with our highly skilled teams.\nCollaborate effectively with business users, data analysts, and other IT teams.\nCommunicate technical information clearly and concisely, both verbally and in writing.\nDocument all development work and procedures thoroughly.\nContinuous Growth\nKeep abreast of the latest advancements in data integration, reporting, and data engineering technologies.\nContinuously improve skills and knowledge through training and self-learning.\nThis job description reflects managements assignment of essential functions; it does not prescribe or restrict the tasks that may be assigned.\n\nRequirements\nBachelor's degree in computer science, Information Systems, or a related field.\n7+ years of experience in data integration and reporting.\nExtensive experience with Databricks, including Python, Spark, and Delta Lake.\nStrong proficiency in SQL Server, including T-SQL, stored procedures, and functions.\nExperience with SSIS (SQL Server Integration Services) development and maintenance.\nExperience with SSRS (SQL Server Reporting Services) report design and development.\nExperience with data warehousing concepts and best practices.\nExperience with Microsoft Azure cloud platform and Microsoft Fabric desirable.\nStrong analytical and problem-solving skills.\nExcellent communication and interpersonal skills.\nAbility to work independently and as part of a team.\nExperience with Agile methodologies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Etl Development', 'Azure Databricks', 'Spark', 'SQL Server', 'Databricks Engineer', 'Data Warehousing', 'Pythonspark']",2025-06-14 05:41:19
Senior Data Engineer -Bangalore,Happiest Minds Technologies,6 - 10 years,Not Disclosed,['Bengaluru'],"Job Overview:\nThe primary purpose of this role is to translate business requirements and functional specifications into logical program designs and to deliver dashboards, schema, data pipelines, and software solutions. This includes developing, configuring, or modifying data components within various complex business and/or enterprise application solutions in various computing environments. You will partner closely with multiple Business partners, Product Owners, Data Strategy, Data Platform, Data Science and Machine Learning (MLOps) teams to drive innovative data products for end users. Additionally, you will help shape overall solution & data products, develop scalable solutions through best-in-class engineering practices.",,,,"['NoSQL', 'big data systems', 'Data Pipeline', 'MongoDB', 'SQL', 'Hive', 'GIT', 'Hadoop', 'Kafka', 'Agile', 'MQL', 'Ci/Cd']",2025-06-14 05:41:22
Sr. Data Science,Disa Consulting Services,7 - 9 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Title: SR DATA SCIENCE\nExperience: 7 - 9 Years\nNotice Period: Immediate to 15 days\nWork Mode: Remote, Hybrid\nLocation: Hyderabad & Chennai\n\nRequirements:\nExperience designing and developing automated pipelines that utilize some combination of RAG pipelines, automated generation of prompts to LLMs, and/or multi-agent Agentic inference engines.\nAll skills / experience of above listed data scientist roles plus:\nArchitected and designed end to end pipelines that utilize LLMs and Autonomous Agents.\nDesigned and implemented methods for assuring quality and governing the output of Gen AI or Agentic solutions.\nDesigned and developed APIs exposing services of services that consume LLMs.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Restfull Api', 'Azure Cloud', 'LLM', 'Machine Learning', 'SQL', 'Python']",2025-06-14 05:41:24
"People Operations, Associate",Synopsys,0 - 2 years,Not Disclosed,['Bengaluru'],"People Operations, Associate Bengaluru, Karnataka, India Apply Now Save\nCategory: People Hire Type: Employee\nJob ID 10255 Date posted 06/11/2025 Share this job\nEmail\nLinkedIn\nX\nFacebook",,,,"['Design verification', 'Data analysis', 'ASIC', 'HR processes', 'HR operations', 'HRIS', 'Chip design', 'Project management', 'Wellness', 'Continuous improvement']",2025-06-14 05:41:26
Data Scientist,Spearhead Professional,11 - 20 years,27.5-42.5 Lacs P.A.,"['New Delhi', 'Bengaluru', 'Mumbai (All Areas)']",Responsibilities:\nDevelop machine learning models using Python & PyTorch.\nOptimize data architecture for efficiency & accuracy.\nCollaborate with cross-functional teams on AI projects.,Industry Type: Not mentioned,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Architecture', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning', 'Pytorch', 'Data Science', 'Natural Language Processing', 'Python']",2025-06-14 05:41:28
Principal Machine Learning Engineer,Paypal,0 - 7 years,Not Disclosed,['Bengaluru'],"The Company\nPayPal has been revolutionizing commerce globally for more than 25 years. Creating innovative experiences that make moving money, selling, and shopping simple, personalized, and secure, PayPal empowers consumers and businesses in approximately 200 markets to join and thrive in the global economy.\nWe operate a global, two-sided network at scale that connects hundreds of millions of merchants and consumers. We help merchants and consumers connect, transact, and complete payments, whether they are online or in person. PayPal is more than a connection to third-party payment networks. We provide proprietary payment solutions accepted by merchants that enable the completion of payments on our platform on behalf of our customers.\nOur beliefs are the foundation for how we conduct business every day. We live each day guided by our core values of Inclusion, Innovation, Collaboration, and Wellness. Together, our values ensure that we work together as one global team with our customers at the center of everything we do - and they push us to ensure we take care of ourselves, each other, and our communities.\nJob Summary:\nWhat you need to know about the role\n\nThis job will drive the strategic vision and development of cutting-edge machine learning models and algorithms to solve complex problems. You will work closely with data scientists, software engineers, and product teams to enhance services through innovative AI/ML solutions. Your role will involve building scalable ML pipelines, ensuring data quality, and deploying models into production environments to drive business insights and improve customer experiences.\n\nYour Way to Impact\n\nAs a Principal Machine Learning Engineer, you ll lead mission-critical initiatives that define PayPal s AI edge from large-scale model fine-tuning to the architecture of foundational AI systems. Your leadership will enable AI-native capabilities across personalization, fraud detection, customer experience, and internal productivity. You will shape how PayPal delivers trust, speed, and intelligence in every user interaction.\n\nMeet Our Team\nYou ll work within the core Applied Intelligence team, a cross-functional hub driving AI-first innovation across PayPal s product and platform landscape. Your team s work powers smarter workflows and more seamless experiences for our global customer base. This is a hands-on leadership role where you ll help align strategy, technology, and business outcomes.\nJob Description:\nYour Day to Day\nDefine and drive strategic vision for model development and ML applications across business domains.\nLead architecture and experimentation for foundational model pipelines.\nManage end-to-end lifecycle from data prep and training to deployment and monitoring.\nCollaborate with product, infra, and engineering leaders to ship impactful solutions.\nGuide model evaluation frameworks, bias detection, and performance monitoring practices.\nMentor technical leads and contribute to thought leadership internally and externally.\nWhat You Need to Bring\nMinimum of 15 years of relevant experience with a Bachelor s degree or equivalent.\nDeep expertise in building and fine-tuning advanced ML models at scale.\nStrong experience with cloud-native ML solutions (e.g., SageMaker, Vertex AI).\nProven success in leading multi-functional ML projects from research to production.\nStrong communication and strategic planning abilities to align tech with business.\nPreferred Qualification:\nSubsidiary:\nPayPal\nTravel Percent:\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits:\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https://www.paypalbenefits.com .\nWho We Are:\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. If you are unable to submit an application because of incompatible assistive technology or a disability, please contact us at talentaccommodations@paypal.com .\nBelonging at PayPal:\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: FinTech / Payments,Department: Other,"Employment Type: Full Time, Permanent","['Architecture', 'User interaction', 'Diversity and Inclusion', 'Machine learning', 'Strategic planning', 'Manager Technology', 'Wellness', 'Data quality', 'Customer experience', 'Fraud detection']",2025-06-14 05:41:31
Data Insights & Visualization Practition,Accenture,3 - 5 years,Not Disclosed,['Hyderabad'],"Project Role :Data Insights & Visualization Practition\n\n\n\n\n\nProject Role Description :Create interactive interfaces that enable humans to understand, interpret, and communicate complex data and insights. Wrangle, analyze, and prepare data to ensure delivery of relevant, consistent, timely, and actionable insights. Leverage modern business intelligence, storytelling, and web-based visualization tools to create interactive dashboards, reports and emerging VIS/BI artifacts. Use and customize (Gen)AI and AI-powered VIS/BI capabilities to enable a dialog with data.\n\n\n\nMust have skills :Data Analytics\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n2 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education:**Position\n\n\nSummary:**The Data Visualization Specialist will transform complex datasets into clear, actionable visualizations that support decision-making.**Key Responsibilities:**- Design and develop interactive dashboards and reports.- Collaborate with analysts and stakeholders to gather visualization requirements.- Ensure data visualizations are accurate, intuitive, and impactful.- Stay updated on best practices in data visualization.- Create visually compelling dashboards and reports to communicate insights.- Work closely with stakeholders to understand visualization requirements.- Ensure consistency in visual design and adherence to branding guidelines.- Optimize visualizations for performance and scalability.- Train end-users on interpreting and utilizing visual analytics tools.**\nQualifications:**- Bachelor's degree in Data Science, Computer Science, or a related field.- 3-5 years of experience in data visualization.- Proficiency in Power BI, Tableau, or similar tools.- Strong design sense and attention to detail.- Excellent communication and collaboration skills.\nAdditional Information:- The candidate should have minimum 2 years of experience in Data Analytics.- This position is based at our Hyderabad office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'power bi', 'business intelligence', 'tableau', 'data visualization', 'python', 'data analysis', 'bi', 'data warehousing', 'business analysis', 'business analytics', 'machine learning', 'dashboards', 'sql server', 'sql', 'r', 'data science', 'data modeling', 'advanced excel', 'etl', 'ssis']",2025-06-14 05:41:33
"Data Scientist,VP",NatWest Markets,10 - 12 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Join us as a Data Scientist\nIn this role, you ll drive and embed the design and implementation of data science tools and methods, which harness our data to drive market-leading purpose customer solutions\nDay-to-day, you ll act as a subject matter expert and articulate advanced data and analytics opportunities, bringing them to life through data visualisation\nIf you re ready for a new challenge, and are interested in identifying opportunities to support external customers by using your data science expertise, this could be the role for you\nWere offering this role at vice president level\nWhat you ll do\nWe re looking for someone to understand the requirements and needs of our business stakeholders. You ll develop good relationships with them, form hypotheses, and identify suitable data and analytics solutions to meet their needs and to achieve our business strategy.\nYou ll be maintaining and developing external curiosity around new and emerging trends within data science, keeping up to date with emerging trends and tooling and sharing updates within and outside of the team.\nYou ll also be responsible for:\nProactively bringing together statistical, mathematical, machine-learning and software engineering skills to consider multiple solutions, techniques, and algorithms\nImplementing ethically sound models end-to-end and applying software engineering and a product development lens to complex business problems\nWorking with and leading both direct reports and wider teams in an Agile way within multi-disciplinary data to achieve agreed project and Scrum outcomes\nUsing your data translation skills to work closely with business stakeholders to define business questions, problems or opportunities that can be supported through advanced analytics\nSelecting, building, training, and testing complex machine models, considering model valuation, model risk, governance, and ethics throughout to implement and scale models\nThe skills you ll need\nTo be successful in this role, you ll need evidence of project implementation and work experience gained in a data-analysis-related field as part of a multi-disciplinary team. We ll also expect you to hold an undergraduate or a master s degree in Data science, Statistics, Computer science, or related field .\nYou ll also need an experience of 10 years with statistical software, database languages, big data technologies, cloud environments and machine learning on large data sets. And we ll look to you to bring the ability to demonstrate leadership, self-direction and a willingness to both teach others and learn new techniques.\nAdditionally, you ll need:\nExperience of deploying machine learning models into a production environment\nProficiency in Python and relevant libraries such as Pandas, NumPy, Scikit-learn coupled with experience in data visualisation tools.\nExtensive work experience with AWS Sage maker , including expertise in statistical data analysis, machine learning models, LLMs, and data management principles\nEffective verbal and written communication skills , the ability to adapt communication style to a specific audience and mentoring junior team members",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'data science', 'Data management', 'Machine learning', 'Agile', 'Scrum', 'SAGE', 'Business strategy', 'Python']",2025-06-14 05:41:35
"Specialist, Data Architecture",Fiserv,3 - 5 years,Not Disclosed,['Pune'],"A Conversion Professional is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible for providing data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Professional plays a critical role in mapping in data to support project initiatives for new and existing banks.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nWhat will you do\nA Conversion Professional is responsible for timely and accurate conversion of new and existing Bank/Client data to Fiserv systems, from both internal and external sources. This role is responsible for providing data analysis for client projects and to accommodate other ad hoc data updates to meet client requests.\nAs part of the overall Service Delivery organization, a Conversion Professional plays a critical role in mapping in data to support project initiatives for new and existing banks.\nWorking with financial services data means a high priority on accuracy and adherence to procedures and guidelines.\nThe person stepping in as the backup would need to review the specifications history and then review and understand the code that was being developed to resolve the issue and or change. This would also have to occur on the switch back to the original developer.\nToday, the associate handling the project would log back in to support the effort and address the issue and or change.\nWhat you will need to have\nBachelor s degree in programming or related field\nMinimum 3 years relevant experience in data processing (ETL) conversions or financial services industry\n3 5 years Experience and strong knowledge of MS SQL/PSQL, MS SSIS and data warehousing concepts\nStrong communication skills and ability to provide technical information to non-technical colleagues.\nTeam players with ability to work independently.\nExperience in full software development life cycle using agile methodologies.\nShould have good understanding of Agile methodologies and can handle agile ceremonies.\nEfficient in Reviewing, coding, testing, and debugging of application/Bank programs.\nShould be able to work under pressure while resolving critical issues in Prod environment.\nGood communication skills and experience in working with Clients.\nGood understanding in Banking Domain.\nWhat would be great to have\nExperience with Informatica, Power BI, MS Visual Basic, Microsoft Access and Microsoft Excel required.\nExperience with Card Management systems, debit card processing is a plus\nStrong communication skills and ability to provide technical information to non-technical colleagues\nAbility to manage and prioritize work queue across multiple workstreams\nTeam player with ability to work independently\nHighest attention to detail and accuracy\nThank you for considering employment with Fiserv. Please:\nApply using your legal name\nComplete the step-by-step profile and attach your resume (either is acceptable, both are preferable).\nOur commitment to Diversity and Inclusion:\nFiserv is proud to be an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, national origin, gender, gender identity, sexual orientation, age, disability, protected veteran status, or any other category protected by law.\nNote to agencies:\nFiserv does not accept resume submissions from agencies outside of existing agreements. Please do not send resumes to Fiserv associates. Fiserv is not responsible for any fees associated with unsolicited resume submissions.\nWarning about fake job posts:\nPlease be aware of fraudulent job postings that are not affiliated with Fiserv. Fraudulent job postings may be used by cyber criminals to target your personally identifiable information and/or to steal money or financial information. Any communications from a Fiserv representative will come from a legitimate Fiserv email address.\n\n\n\nShare this Job\nEmail\nLinkedIn\nX\nFacebook",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MS SQL', 'Data analysis', 'Visual Basic', 'Coding', 'Debugging', 'Agile', 'Informatica', 'SSIS', 'Financial services', 'Data architecture']",2025-06-14 05:41:37
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Pune'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\nYour primary responsibilities include:\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\nStrive for continuous improvements by testing the build solution and working under an agile framework.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\n\n\nPreferred technical and professional experience",,,,"['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-14 05:41:40
Data Engineer-Data Platforms,IBM,2 - 5 years,Not Disclosed,['Navi Mumbai'],"As a Data Engineer at IBM, you'll play a vital role in the development, design of application, provide regular support/guidance to project teams on complex coding, issue resolution and execution.\n\nYour primary responsibilities include:\nLead the design and construction of new solutions using the latest technologies, always looking to add business value and meet user requirements.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n\n\n\nPreferred technical and professional experience",,,,"['python', 'data processing', 'pyspark', 'data modeling', 'spark', 'data analysis', 'microsoft azure', 'data warehousing', 'cloud platforms', 'numpy', 'data engineering', 'sql', 'pandas', 'spring boot', 'etl pipelines', 'java', 'gcp', 'kafka', 'data warehousing concepts', 'hadoop', 'big data', 'aws', 'etl']",2025-06-14 05:41:42
Data Modeler,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Data Modeler\n\n\n\n\n\nProject Role Description :Work with key business representatives, data owners, end users, application designers and data architects to model current and new data.\n\n\n\nMust have skills :Data Building Tool\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n7.5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Modeler, you will engage with key business representatives, data owners, end users, application designers, and data architects to model both current and new data. Your typical day will involve collaborating with various stakeholders to understand their data needs, analyzing existing data structures, and designing effective data models that support business objectives. You will also be responsible for ensuring that the data models are aligned with best practices and organizational standards, facilitating smooth data integration and accessibility across different systems. This role requires a proactive approach to problem-solving and a commitment to delivering high-quality data solutions that enhance decision-making processes within the organization.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Provide solutions to problems for their immediate team and across multiple teams.- Facilitate training sessions and workshops to enhance team capabilities.- Continuously evaluate and improve data modeling processes to ensure efficiency.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Building Tool.- Strong understanding of data modeling techniques and methodologies.- Experience with data integration and ETL processes.- Familiarity with database management systems and SQL.- Ability to translate business requirements into technical specifications.\nAdditional Information:- The candidate should have minimum 7.5 years of experience in Data Building Tool.- This position is based in Mumbai.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'database management', 'data modeling', 'etl', 'data integration', 'python', 'oracle', 'data analysis', 'data warehousing', 'sme', 'data architecture', 'business intelligence', 'sql server', 'plsql', 'unix shell scripting', 'etl tool', 'modeler', 'informatica', 'unix', 'etl process']",2025-06-14 05:41:45
Data Scientist- Credit Risk Modelling,TransOrg,3 - 5 years,Not Disclosed,"['Bengaluru', 'Mumbai (All Areas)']","Domain: Retail Banking / Credit Cards\nLocation: Mumbai/ Bengaluru\nExperience: 3-5 years\nIndustry: Banking / Financial Services (Mandatory)\n\nWhy would you like to join us?\nTransOrg Analytics specializes in Data Science, Data Engineering and Generative AI, providing advanced analytics solutions to industry leaders and Fortune 500 companies across India, US, APAC and the Middle East. We leverage data science to streamline, optimize, and accelerate our clients' businesses.\nVisit at www.transorg.com to know more about us.\n\nWhat do we expect from you?\nBuild and validate credit risk models, including application scorecards and behavior scorecards (B-score), aligned with business and regulatory requirements.\nUse advanced machine learning algorithms such as Logistic Regression, XGBoost, and Clustering to develop interpretable and high-performance models.\nTranslate business problems into data-driven solutions using robust statistical and analytical methods.\nCollaborate with cross-functional teams including credit policy, risk strategy, and data engineering to ensure effective model implementation and monitoring.\nMaintain clear, audit-ready documentation for all models and comply with internal model governance standards.\nTrack and monitor model performance, proactively suggesting recalibrations or enhancements as needed.\n\nWhat do you need to excel at?\nWriting efficient and scalable code in Python, SQL, and PySpark for data processing, feature engineering, and model training.\nWorking with large-scale structured and unstructured data in a fast-paced, banking or fintech environment.\nDeploying and managing models using MLFlow, with a strong understanding of version control and model lifecycle management.\nUnderstanding retail banking products, especially credit card portfolios, customer behavior, and risk segmentation.\nCommunicating complex technical outcomes clearly to non-technical stakeholders and senior management.\nApplying a structured problem-solving approach and delivering insights that drive business value.\nWhat are we looking for?\nBachelors or masters degree in Statistics, Mathematics, Computer Science, or a related quantitative field.\n35 years of experience in credit risk modelling, preferably in retail banking or credit cards.\nHands-on expertise in Python, SQL, PySpark, and experience with MLFlow or equivalent MLOps tools.\nDeep understanding of machine learning techniques including Logistic Regression, XGBoost, and Clustering.\nProven experience in developing Application Scorecards and behavior Scorecards using real-world banking data.\nStrong documentation and compliance orientation, with an ability to work within regulatory frameworks.\nCuriosity, accountability, and a passion for solving real-world problems using data.\nCloud Knowledge, JIRA, GitHub(good to have)",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Natural Language Processing', 'Machine Learning', 'Python', 'SQL', 'Predictive Modeling', 'Logistic Regression', 'Linear Regression', 'Time Series Analysis', 'Statistical Modeling', 'Credit Risk Modelling', 'Deep Learning', 'Predictive Analytics']",2025-06-14 05:41:47
Data Management Practitioner,Accenture,12 - 17 years,Not Disclosed,['Kolkata'],"Project Role :Data Management Practitioner\n\n\n\n\n\nProject Role Description :Maintain the quality and compliance of an organizations data assets. Design and implement data strategies, ensuring data integrity and enforcing governance policies. Establish protocols to handle data, safeguard sensitive information, and optimize data usage within the organization. Design and advise on data quality rules and set up effective data compliance policies.\n\n\n\nMust have skills :Data Architecture Principles\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :any graduate\n\n\nSummary:As a Data Management Practitioner, you will be responsible for maintaining the quality and compliance of an organization's data assets. Your role involves designing and implementing data strategies, ensuring data integrity, enforcing governance policies, and optimizing data usage within the organization.\nRoles & Responsibilities:- Expected to be an SME- Collaborate and manage the team to perform- Responsible for team decisions- Engage with multiple teams and contribute on key decisions- Design and advise on data quality rules- Set up effective data compliance policies- Ensure data integrity and enforce governance policies- Optimize data usage within the organization\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Architecture Principles- Strong understanding of data management best practices- Experience in designing and implementing data strategies- Knowledge of data governance and compliance policies- Ability to optimize data usage for organizational benefit\nAdditional Information:- The candidate should have a minimum of 12 years of experience in Data Architecture Principles- This position is based at our Kolkata office- A degree in any graduate is required\n\nQualification\n\nany graduate",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data management', 'data architecture', 'sql', 'data architecture principles', 'hive', 'data analysis', 'oracle', 'data warehousing', 'machine learning', 'business intelligence', 'sql server', 'plsql', 'tableau', 'data science', 'data modeling', 'hadoop', 'sqoop', 'etl', 'etl development']",2025-06-14 05:41:50
Data Modeler,Accenture,12 - 15 years,Not Disclosed,['Kolkata'],"Project Role :Data Modeler\n\n\n\n\n\nProject Role Description :Work with key business representatives, data owners, end users, application designers and data architects to model current and new data.\n\n\n\nMust have skills :Data Building Tool\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n12 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Modeler, you will engage with key business representatives, data owners, end users, application designers, and data architects to model both current and new data. Your typical day will involve collaborating with various stakeholders to understand their data needs, analyzing existing data structures, and designing effective data models that support business objectives. You will also be responsible for ensuring that the data models are aligned with best practices and organizational standards, facilitating smooth data integration and accessibility across different systems. This role requires a proactive approach to problem-solving and a commitment to delivering high-quality data solutions that enhance decision-making processes within the organization.\nRoles & Responsibilities:- Expected to be an SME.- Collaborate and manage the team to perform.- Responsible for team decisions.- Engage with multiple teams and contribute on key decisions.- Expected to provide solutions to problems that apply across multiple teams.- Facilitate workshops and meetings to gather requirements and feedback from stakeholders.- Develop and maintain comprehensive documentation of data models and architecture.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Building Tool.- Strong understanding of data modeling techniques and methodologies.- Experience with data integration and ETL processes.- Familiarity with database management systems and SQL.- Ability to translate business requirements into technical specifications.\nAdditional Information:- The candidate should have minimum 12 years of experience in Data Building Tool.- This position is based at our Kolkata office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sql', 'database management', 'data modeling', 'etl', 'data integration', 'python', 'oracle', 'data analysis', 'data warehousing', 'sme', 'data architecture', 'business intelligence', 'sql server', 'plsql', 'unix shell scripting', 'etl tool', 'modeler', 'informatica', 'unix', 'etl process']",2025-06-14 05:41:52
Data Scientist- Large Language Models,Fortune Global 500 IT Services Firm,5 - 10 years,Not Disclosed,['Bengaluru'],"Project Role : Responsible AI Engineer\nProject Role Description : Assess AI systems for adherence to predefined thresholds and benchmarks related to responsible, ethical and sustainable practices. Design and implement technology mitigation strategies for systems to ensure ethical and responsible standards are achieved.\nMust have skills : Large Language Models\nGood to have skills : NA\nMinimum 5 year(s) of experience is required\nEducational Qualification : 15 years full time education\nSummary:\nAs an AI Platform Engineer, you will be responsible for developing applications and systems that utilize AI to improve performance and efficiency. Your typical day will involve working with Large Language Models, deep learning, neural networks, chatbots, and natural language processing.\n\nRoles & Responsibilities:\n- Design and develop scalable and efficient AI-based applications and systems using Large Language Models, deep learning, neural networks, chatbots, and natural language processing.\n- Collaborate with cross-functional teams to identify and prioritize AI use cases, and develop solutions that meet business requirements.\n- Implement and maintain AI models and algorithms, and ensure their accuracy, reliability, and scalability.\n- Develop and maintain AI infrastructure, including data pipelines, model training and deployment pipelines, and monitoring and logging systems.\n- Stay updated with the latest advancements in AI and machine learning, and integrate innovative approaches for sustained competitive advantage.\n\nProfessional & Technical Skills:\n- Must To Have Skills: Experience with Large Language Models.\n- Strong understanding of deep learning, neural networks, chatbots, and natural language processing.\n- Experience with AI infrastructure, including data pipelines, model training and deployment pipelines, and monitoring and logging systems.\n- Proficiency in programming languages such as Python, Java, or C++.\n- Experience with cloud platforms such as AWS, Azure, or GCP.\n- Experience with containerization technologies such as Docker and Kubernetes.\n\nAdditional Information:\n- The ideal candidate will possess a strong educational background in computer science, artificial intelligence, or a related field, along with a proven track record of delivering impactful AI-driven solutions.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Large Language Models', 'Java', 'C++', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Machine Learning', 'Deep Learning', 'Data Science', 'Azure Cloud', 'GCP', 'Image Processing', 'Computer Vision', 'AWS', 'Python']",2025-06-14 05:41:55
Data Platform Engineer,Accenture,2 - 7 years,Not Disclosed,['Pune'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models. You will play a crucial role in the development and maintenance of the data platform components, contributing to the overall success of the project.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist with the data platform blueprint and design.- Collaborate with Integration Architects and Data Architects to ensure cohesive integration between systems and data models.- Develop and maintain data platform components.- Contribute to the overall success of the project.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.\nAdditional Information:- The candidate should have a minimum of 2 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'tableau', 'machine learning algorithms', 'statistics', 'data munging', 'python', 'data analysis', 'natural language processing', 'power bi', 'machine learning', 'sql', 'data quality', 'r', 'data modeling', 'data science', 'predictive modeling', 'text mining', 'logistic regression']",2025-06-14 05:41:57
Data Platform Engineer,Accenture,3 - 8 years,Not Disclosed,['Pune'],"Project Role :Data Platform Engineer\n\n\n\n\n\nProject Role Description :Assists with the data platform blueprint and design, encompassing the relevant data platform components. Collaborates with the Integration Architects and Data Architects to ensure cohesive integration between systems and data models.\n\n\n\nMust have skills :Databricks Unified Data Analytics Platform\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n3 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Platform Engineer, you will assist with the data platform blueprint and design, collaborating with Integration Architects and Data Architects to ensure cohesive integration between systems and data models. You will play a crucial role in the development and maintenance of the data platform components, contributing to the overall success of the project.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist with the data platform blueprint and design.- Collaborate with Integration Architects and Data Architects to ensure cohesive integration between systems and data models.- Develop and maintain data platform components.- Contribute to the overall success of the project.\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Databricks Unified Data Analytics Platform.- Strong understanding of statistical analysis and machine learning algorithms.- Experience with data visualization tools such as Tableau or Power BI.- Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms.- Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity.\nAdditional Information:- The candidate should have a minimum of 3 years of experience in Databricks Unified Data Analytics Platform.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'tableau', 'machine learning algorithms', 'statistics', 'data munging', 'python', 'data analysis', 'natural language processing', 'power bi', 'machine learning', 'sql', 'data quality', 'r', 'data modeling', 'data science', 'predictive modeling', 'text mining', 'logistic regression']",2025-06-14 05:42:00
"Level 2 Market Data Support Engineer (Windows, Linux, SQL, IM)",Synechron,3 - 7 years,Not Disclosed,['Pune'],"Job Summary\nSynechron is seeking a technically skilled and proactive Level 2 Market Data Support Engineer specializing in Market Data operations to join our dedicated back-office support team. This role is pivotal in maintaining the stability, security, and efficiency of our market data systems and related infrastructure. The ideal candidate will deliver advanced technical support, troubleshoot complex issues, and contribute to process improvements, ensuring seamless access and data accuracy in a highly regulated financial environment.\nThis position provides an opportunity to work with cross-functional teams, implement best practices, and support critical business functions. It requires a combination of technical expertise, analytical acumen, and effective communication skills to sustain the integrity of our market data platform and ensure high service standards.",,,,"['Market Data Support', 'Batch Processing Systems', 'ServiceNow', 'Git', 'Linux', 'Windows Server management', 'Unix/Linux', 'ITSM tools', 'Windows', 'Incident Management', 'SQL']",2025-06-14 05:42:02
Data Governance Practitioner,Accenture,5 - 10 years,Not Disclosed,['Pune'],"Project Role :Data Governance Practitioner\n\n\n\n\n\nProject Role Description :Establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Collaborate with key stakeholders to define data standards, facilitate effective data collection, storage, access, and usage; and drive data stewardship initiatives for comprehensive and effective data governance.\n\n\n\nMust have skills :Collibra Data Governance\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\n\n\nSummary:As a Data Governance Practitioner, you will establish and enforce data governance policies to ensure the accuracy, integrity, and security of organizational data. Collaborate with key stakeholders to define data standards, facilitate effective data collection, storage, access, and usage; and drive data stewardship initiatives for comprehensive and effective data governance.\nRoles & Responsibilities:- Expected to be an SME- Collaborate and manage the team to perform- Responsible for team decisions- Engage with multiple teams and contribute on key decisions- Provide solutions to problems for their immediate team and across multiple teams- Lead data governance initiatives within the organization- Develop and implement data governance policies and procedures- Ensure compliance with data governance standards and regulations\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Collibra Data Governance- Strong understanding of data governance principles- Experience in implementing data governance frameworks- Knowledge of data quality management- Familiarity with data privacy regulations\nAdditional Information:- The candidate should have a minimum of 5 years of experience in Collibra Data Governance.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['data stewardship', 'data quality management', 'regulations', 'data governance', 'data privacy', 'python', 'data analysis', 'data analytics', 'data management', 'data warehousing', 'data collection', 'sql', 'data cleansing', 'data quality', 'tableau', 'data modeling', 'informatica', 'data profiling']",2025-06-14 05:42:04
Lead Data Engineer - Azure,Blend360 India,7 - 12 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Lead Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n7+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-14 05:42:07
Data Modeler,Accenture,15 - 20 years,Not Disclosed,['Mumbai'],"Project Role :Data Modeler\n\n\n\n\n\nProject Role Description :Work with key business representatives, data owners, end users, application designers and data architects to model current and new data.\n\n\n\nMust have skills :Data Modeling Techniques and Methodologies\n\n\n\n\nGood to have skills :NAMinimum\n\n\n\n5 year(s) of experience is required\n\n\n\n\nEducational Qualification :15 years full time education\nProject Role :Data Architect & Modeler\n\nProject Role Description Data Model, Design, build and lead the complex ETL data integration pipelines to meet business process and application requirements. Management Level :9Work Experience :6+ yearsWork Location :AnyMust have skills :Data Architecture Principles\nGood to have skills :Data Modeling, Data Architect, Informatica PowerCenter, Informatica Data Quality, SAP BusinessObjects Data Services, SQL, PL/SQL, SAP HANA DB, MS Azure, Python, ErWin, SAP Power Designer Job :Data Architect, Modeler, and data Integration LeadKey Responsibilities:1) Working on building Data models, Forward and Reverse Engineering.2) Working on Data and design analysis and working with data analysts team on data model design.3) Working on presentations on design, end to end flow and data models.4) Work on new and existing data models using Power designer tools and other designing tools like Visio5) Work with functional SMEs, BAs to review requirements, mapping documents\nTechnical Experience:1) Should have good understanding of ETL design concepts like CDC, SCD, Transpose/ pivot, Updates, Validation2) Should have strong understanding of SQL concepts, Data warehouse concepts and can easily understand data technically and functionally.3) Good understanding of various file formats like xml, delimited, fixed width etc.4) Understand the concepts of data quality, data cleansing, data profiling5) Good to have Python and other new data technologies and cloud exposure.6) Having Insurance background is a plus.\nEducational Qualification :15 years of fulltime education with BE/B Tech or equivalent\nProfessional & Technical\n\n\n\n\nSkills:\n- Must To Have\n\n\n\n\nSkills:\nProficiency in Data Modeling Techniques and Methodologies.- Strong understanding of relational and non-relational database design principles.- Experience with data integration and ETL processes.- Familiarity with data governance and data quality frameworks.- Ability to translate business requirements into technical specifications.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sql', 'data architecture principles', 'data modeling', 'data warehousing concepts', 'sql joins', 'python', 'ms azure', 'sap', 'informatica powercenter', 'informatica data quality', 'data warehousing', 'erwin', 'data architecture', 'plsql', 'modeler', 'hana db', 'etl', 'sap hana', 'data integration']",2025-06-14 05:42:09
Data Scientist with GCP Cloud,Foreign MNC,6 - 11 years,Not Disclosed,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","Project Role : AI / ML Engineer\nProject Role Description : Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing.\nMust have skills : Google Cloud Machine Learning Services\nGood to have skills : NA\nMinimum 5+ year(s) of experience is required\nEducational Qualification : BE\nSummary:\nAs an AI/ML Engineer, you will be responsible for developing applications and systems that utilize AI tools and Cloud AI services. Your typical day will involve applying GenAI models, developing cloud or on-prem application pipelines, and ensuring production-ready quality. You will also work with deep learning, neural networks, chatbots, and image processing.\n\nKey Responsibilities :\nA: Demonstrate various Google specific Designs using effective POCs, as per client requirements.\nB: Identifying applicability of Google Cloud AI services to use cases with ability to project both the business and tech benefits.\nC: Design, build and productionizes ML models to solve business challenges using Google Cloud technologies\nD: Lead and guide team of data scientists\nE: Coordinating and collaborating with cross-functional teams\n\nTechnical Experience :\nA: Min 3 + years of experience on GCP AWS ML\nB: Exposure to Google Gen AI Services\nC: Exposure to GCP and its Compute, Storage, Data, Network, Security services\nD: Expert programming skills in any one of Java, Python, Spark\nE: Knowledge of GKE, Kubeflow on GCP would be good to have\nG: Experience in Vertex AI for building and managing the ML models\nH: Experience in implementing MLOps\nAdditional Information:\n- The candidate should have a minimum of 5 +years of experience in Google Cloud Machine Learning Services.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Science', 'GCP', 'Natural Language Processing', 'Aws Sagemaker', 'Aiml', 'Computer Vision', 'Machine Learning', 'Deep Learning', 'Python']",2025-06-14 05:42:11
Business Finance Professional,Purplle.com,0 - 2 years,Not Disclosed,['Mumbai'],"As an Assistant Manager Business Finance, you will play a pivotal role in driving revenue growth, optimizing costs, and managing financial resources. This position requires close collaboration with various teams to develop and execute financial strategies, as well as analyze key performance indicators (KPIs) to support business decisions.\n  Key Responsibilities:\n  Financial Planning Analysis (FPA):\nDevelop and manage budgets and forecasts for different business units.\nAnalyze variances between actuals and budgets; identify trends and provide actionable insights.\nSupport strategic planning with scenario modeling\nRevenue Cost Analysis:\nTrack and evaluate revenue streams (e.g., direct sales, subscription, advertising).\nAnalyze cost drivers including customer acquisition cost (CAC), fulfillment, logistics, and returns.\nEnsure unit economics and contribution margins are healthy.\nBusiness Partnering:\nCollaborate with marketing, operations, product, and tech teams to provide financial insights.\nHelp non-financial teams understand the financial implications of their initiatives.\nKPI Reporting Dashboards:\nDevelop and maintain financial dashboards and key performance indicators (KPIs), such as:-\nGross merchandise value (GMV)\nAverage order value (AOV)\nReturn on ad spend (ROAS)\nCustomer lifetime value (CLTV)\nQualifications:\nCA fresher or minimum 0.5 - 1 years of experience in Finance, Accounting, Economics, or a related field.\nProven experience in financial planning and analysis, preferably in a business finance role preferred\nStrong analytical skills with proficiency in financial modeling and data analysis tools.\nExcellent communication and interpersonal skills to collaborate with cross-functional teams.",Industry Type: Beauty & Personal Care,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['data analysis', 'modeling', 'kpi', 'business finance', 'accounting', 'budgeting', 'sales', 'economics', 'fpa', 'analysis tools', 'financial modelling', 'cost optimization', 'financial planning and analysis', 'cost analysis', 'finance', 'reporting', 'budget management', 'communication skills']",2025-06-14 05:42:13
Data Scientist,Barclays,1 - 7 years,Not Disclosed,['Pune'],"Join us as a Data Scientist at Barclays, where youll take part in the evolution of our digital landscape, driving innovation and excellence. Youll harness cutting-edge technology to revolutionise our digital offerings, ensuring unparalleled customer experiences. As a part of the Service Operations team, you will deliver technology stack, using strong analytical and problem solving skills to understand the business requirements and deliver quality solutions. Youll be working on complex technical problems that will involve detailed analytical skills and analysis. This will be done in conjunction with fellow engineers, business analysts and business stakeholders.\nTo be successful as a Data Scientist you should have experience with:\nEssential Skills\nSolid understanding of machine learning concepts and model deployment.\nPrior experience in a data science role, indicating a strong foundation in the field.\nAdvanced coding proficiency in Python, with the ability to design, test, and correct complex scripts.\nProficiency in SQL, for managing and manipulating data.\nWorking in an Agile manner and leading Agile teams using Jira.\nSome other highly valued skills include:\nExcellent modelling skills, as evidenced by an advanced degree or significant experience.\nStrong quantitative and statistical skills, enabling logical and methodical problem-solving.\nGood understanding and experience of big data technologies and the underlying approach.\nGood interpersonal skills for maintaining relationships with multiple business areas, including senior leadership and compliance.\nAbility to manage laterally and upwards across multiple discipline technical areas.\nVersion control using Bitbucket, Gitlab, etc.\nCloud experience (AWS, Azure or GCP)\nYou may be assessed on key critical skills relevant for success in role, such as risk and controls, change and transformation, business acumen, strategic thinking and digital and technology, as well as job-specific technical skills.\nThis role is based in Pune.\nPurpose of the role\nTo use innovative data analytics and machine learning techniques to extract valuable insights from the banks data reserves, leveraging these insights to inform strategic decision-making, improve operational efficiency, and drive innovation across the organisation.\nAccountabilities\nIdentification, collection, extraction of data from various sources, including internal and external sources.\nPerforming data cleaning, wrangling, and transformation to ensure its quality and suitability for analysis.\nDevelopment and maintenance of efficient data pipelines for automated data acquisition and processing.\nDesign and conduct of statistical and machine learning models to analyse patterns, trends, and relationships in the data.\nDevelopment and implementation of predictive models to forecast future outcomes and identify potential risks and opportunities.\nCollaborate with business stakeholders to seek out opportunities to add value from data through Data Science.\nAssistant Vice President Expectations\nTo advise and influence decision making, contribute to policy development and take responsibility for operational effectiveness. Collaborate closely with other functions/ business divisions.\nLead a team performing complex tasks, using well developed professional knowledge and skills to deliver on work that impacts the whole business function. Set objectives and coach employees in pursuit of those objectives, appraisal of performance relative to objectives and determination of reward outcomes\nIf the position has leadership responsibilities, People Leaders are expected to demonstrate a clear set of leadership behaviours to create an environment for colleagues to thrive and deliver to a consistently excellent standard. The four LEAD behaviours are: L - Listen and be authentic, E - Energise and inspire, A - Align across the enterprise, D - Develop others.\nOR for an individual contributor, they will lead collaborative assignments and guide team members through structured assignments, identify the need for the inclusion of other areas of specialisation to complete assignments. They will identify new directions for assignments and/ or projects, identifying a combination of cross functional methodologies or practices to meet required outcomes.\nConsult on complex issues; providing advice to People Leaders to support the resolution of escalated issues.\nIdentify ways to mitigate risk and developing new policies/procedures in support of the control and governance agenda.\nTake ownership for managing risk and strengthening controls in relation to the work done.\nPerform work that is closely related to that of other areas, which requires understanding of how areas coordinate and contribute to the achievement of the objectives of the organisation sub-function.\nCollaborate with other areas of work, for business aligned support areas to keep up to speed with business activity and the business strategy.\nEngage in complex analysis of data from multiple sources of information, internal and external sources such as procedures and practises (in other areas, teams, companies, etc). to solve problems creatively and effectively.\nCommunicate complex information. Complex information could include sensitive information or information that is difficult to communicate because of its content or its audience.\nInfluence or convince stakeholders to achieve outcomes.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Coding', 'Analytical', 'Machine learning', 'Agile', 'Business strategy', 'Assistant Vice President', 'Operations', 'SQL', 'Service operations', 'Python']",2025-06-14 05:42:16
"Senior Analyst, Product Analytics",Cvent,4 - 6 years,Not Disclosed,['Gurugram'],"Partner with Product team to define KPIs, build hypothesis & analyze product data to understand user engagement, feature adoption, and other key metrics. Analyzing results, identifying trends & patterns in data, and interpreting findings to draw actionable insights. Working with other analysts in the team to define and build data frameworks like customer segmentation to support targeted product & marketing strategies. Partner with Product & Sales leadership to support revenue generating initiatives like customer onboarding, upsell & cross sell opportunities, promotion campaigns and measuring its impact on business KPIs. Create and deliver reports and presentations to communicate findings and insights to Product, Sales, CS, and other stakeholders. Develop and Design scalable market insights and customer insights content that can be used for internal office hours, webinars, and industry publications. Research led approach to identify internal and external factors that have an impact on customer performance. Own end-to-end management and deliver periodic deliverables (repeatable, scalable short analysis for stakeholders) and ensure project success and quality. Overview: Cvent is a leading meetings, events, and hospitality technology provider with more than 4,800 employees and ~22,000 customers worldwide, including 53% of the Fortune 500. Founded in 1999, Cvent delivers a comprehensive event marketing and management platform for marketers and event professionals and offers software solutions to hotels, special event venues and destinations to help them grow their group/MICE and corporate travel business. Our technology brings millions of people together at events around the world. In short, we re transforming the meetings and events industry through innovative technology that powers human connection. The DNA of Cvent is our people, and our culture has an emphasis on fostering intrapreneurship - a system that encourages Cventers to think and act like individual entrepreneurs and empowers them to take action, embrace risk, and make decisions as if they had founded the company themselves. At Cvent, we value the diverse perspectives that each individual brings. Whether working with a team of colleagues or with clients, we ensure that we foster a culture that celebrates differences and builds on shared connections. Cvent Analytics team is looking to hire Analyst/ Senior Analyst who can work on data-driven insights to optimize the performance and user experience of our products. This role will play a critical role in making informed decisions about product features, user engagement, and overall strategy, with the goal of enhancing customer satisfaction and driving growth for the business. They must possess strong analytical skills, proficiency in data analysis tools, and the ability to translate complex data into actionable recommendations for product development and enhancement. In This Role, You Will: Partner with Product team to define KPIs, build hypothesis & analyze product data to understand user engagement, feature adoption, and other key metrics. Analyzing results, identifying trends & patterns in data, and interpreting findings to draw actionable insights. Working with other analysts in the team to define and build data frameworks like customer segmentation to support targeted product & marketing strategies. Partner with Product & Sales leadership to support revenue generating initiatives like customer onboarding, upsell & cross sell opportunities, promotion campaigns and measuring its impact on business KPIs. Create and deliver reports and presentations to communicate findings and insights to Product, Sales, CS, and other stakeholders. Develop and Design scalable market insights and customer insights content that can be used for internal office hours, webinars, and industry publications. Research led approach to identify internal and external factors that have an impact on customer performance. Own end-to-end management and deliver periodic deliverables (repeatable, scalable short analysis for stakeholders) and ensure project success and quality. Heres What You Need: 4-6 years of experience in analytics domain with focus on Product & Digital Analysis. Bachelor s Degree (in technology, statistics, sciences, or mathematics) and/or Engineering with good academic record. Experience working on SQL or Snowflake, Advance Excel, and Product Analytics tools such as Mix panel, Amplitude, Pendo, Google Analytics. Familiarity with Digital Analytics & Clickstream data. Good presentations and storytelling skills to deliver insights to the larger audience. Understanding BI tools like Sigma, Tableau, PowerBI to create visualizations and dashboards to uncover data insights. Experience with A/B testing and segmentation strategies will be a plus. Excellent project and time management skills; proven competence for meeting deadlines, multi-tasking under pressure and managing work under ambiguity. Self-driven and can work with geographically spread teams.",,,,"['Hospitality', 'customer segmentation', 'Data analysis', 'Google Analytics', 'Customer satisfaction', 'MICE', 'Event marketing', 'Revenue generation', 'Product marketing', 'SQL']",2025-06-14 05:42:19
Sr Manager -Data Analytics,Parle Agro,8 - 11 years,19-27.5 Lacs P.A.,['Mumbai (All Areas)'],"•Develop and execute the data analytics strategy aligned with business objectives.\n•Work closely with the Sales team to analyze historical sales data, market trends, and consumer behavior to generate accurate sales forecasts.\n\nRequired Candidate profile\n7-10 years of experience of tools such as Power BI/Advance excel/SFA op",Industry Type: FMCG,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'Sales Analytics', 'Sales Analysis', 'Tableau', 'FMCG Operations', 'Python']",2025-06-14 05:42:21
Senior Analyst,National Australia Bank (NAB),3 - 8 years,Not Disclosed,['Gurugram'],"NAB is looking for Senior Analyst to join our dynamic team and embark on a rewarding career journey.\nThe Senior Analyst plays a crucial role in driving data-driven decision-making processes within the organization\nThis position involves analyzing complex data sets, generating actionable insights, and providing strategic recommendations to support key business initiatives\nKey Responsibilities:Data Analysis:Conduct in-depth analysis of large and complex datasets to extract meaningful insights",,,,"['Excel', 'Senior Analyst', 'Finance', 'Focus', 'Banking', 'Manager Technology', 'Recruitment']",2025-06-14 05:42:23
Data Scientist (Supply Chain),Sparkcognition,5 - 10 years,Not Disclosed,['Bengaluru'],"Who We Are & Why Join Us\nAvathon is revolutionizing industrial AI with a powerful platform that enables businesses to harness the full potential of their operational data. Our technology seamlessly integrates and contextualizes siloed datasets, providing a 360-degree operational view that enhances decision-making and efficiency. With advanced capabilities like digital twins, natural language processing, normal behavior modeling, and machine vision, we create real-time virtual replicas of physical assets, enabling predictive maintenance, performance simulation, and operational optimization. Our AI-driven models empower companies with scalable solutions for anomaly detection, performance forecasting, and asset lifetime extension all tailored to the complexities of industrial environments.\nCutting-Edge AI Innovation - Join a team at the forefront of AI, developing groundbreaking solutions that shape the future.\nHigh-Growth Environment - Thrive in a fast-scaling startup where agility, collaboration, and rapid professional growth are the norm.\nMeaningful Impact - Work on AI-driven projects that drive real change across industries and improve lives.\n\nLearn more at: Avathon\nThe Applied Research team addresses hard, novel challenges that arise in product development or customer engagements. As a Data Scientist, Supply Chain , youll bring your knowledge and proven data science expertise to conduct research in machine learning-based solutions that improve our products and help our customers. Qualified candidates are deeply analytical with a keen understanding of artificial intelligence, machine learning, and data science. They are experienced researchers who know how to design worthwhile experiments and empirically derive conclusions. They have the ability, inclination, and experience to conduct research that solves practical problems. They have the communication skills to work closely with both research colleagues and customers.\n\nYou will:\nIndependently and effectively engage with internal product developers, external customers, and subject matter experts to understand and solve critical technical challenges through the application of cutting-edge artificial intelligence\nConduct research and design technical solutions that improve models for commercial and industrial applications, such as forecasting stochastic demand, economics based inventory optimization, manufacturing and network planning, transportation routing and resource scheduling, anomaly detection and prescriptive maintenance based on IOT data, and fraud detection\nConduct research across artificial intelligence areas including reinforcement learning, foundation models, graph neural networks, causal modeling, transferability and continuous learning\nPioneer procedures and/or automated toolsets to more efficiently and effectively perform data science activities\nContribute to AI product development and key data science research areas, internally and externally\nPropose new projects or initiatives that will yield business benefits and evaluate project plans and proposals\nEvaluate and respond to RFPs related to artificial intelligence\nConduct research and write patent applications and technical publications\nYou ll Have:\nExperience with research-level innovation in Data Science and ML, preferably with an advanced degree.\n5+ years of experience in one or more of Forecasting, Optimisation ( Inventory/ Supply chain/ Network/ Transportation),Procurement, experience on economic and Probabilistic modeling is a plus.\nStrong understanding of Data Science, including machine learning, statistics, probability, and modeling.\nSignificant experience with Data Science programming languages, such as Python, R, Matlab\nSignificant experience with machine learning frameworks, such as PyTorch, TensorFlow, Theano, and Keras.\nApplied knowledge of ML techniques/algorithms including linear models, neural networks, decision trees, Bayesian techniques, clustering, and anomaly detection\nSignificant experience managing large volumes of data (terabytes or more)\nExperience with leading project teams, specifically data science teams\nStrong written and verbal communications, ability to translate complex technical topics to internal and external stakeholders.\nAvathon is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, pregnancy, genetic information, disability, status as a protected veteran, or any other protected category under applicable federal, state, and local laws.\nAvathon is committed to providing reasonable accommodations throughout the recruiting process. If you need a reasonable accommodation, please contact us to discuss how we can assist you.",Industry Type: Emerging Technologies,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Procurement', 'Supply chain', 'Simulation', 'Neural networks', 'Analytical', 'Machine learning', 'Scheduling', 'MATLAB', 'Forecasting', 'Python']",2025-06-14 05:42:26
Senior Analyst,National Australia Bank (NAB),4 - 10 years,Not Disclosed,['Gurugram'],"NAB is looking for Senior Analyst to join our dynamic team and embark on a rewarding career journey\nThe Senior Analyst plays a crucial role in driving data-driven decision-making processes within the organization\nThis position involves analyzing complex data sets, generating actionable insights, and providing strategic recommendations to support key business initiatives\nKey Responsibilities:Data Analysis:Conduct in-depth analysis of large and complex datasets to extract meaningful insights",,,,"['Automation', 'Data analysis', 'SAP', 'Social media', 'System integration', 'Incident management', 'MS Office', 'Information technology', 'Monitoring', 'Ariba']",2025-06-14 05:42:28
Data Consultant-Data Scientist,Kyndryl,10 - 15 years,Not Disclosed,['Bengaluru'],"Who We Are\nAt Kyndryl, we design, build, manage and modernize the mission-critical technology systems that the world depends on every day. So why work at Kyndryl? We are always moving forward – always pushing ourselves to go further in our efforts to build a more equitable, inclusive world for our employees, our customers and our communities.\n\nThe Role\nAs a Data Scientist at Kyndryl you are the bridge between business problems and innovative solutions, using a powerful blend of well-defined methodologies, statistics, mathematics, domain expertise, consulting, and software engineering. You'll wear many hats, and each day will present a new puzzle to solve, a new challenge to conquer.\n\nYou will dive deep into the heart of our business, understanding its objectives and requirements – viewing them through the lens of business acumen, and converting this knowledge into a data problem. You’ll collect and explore data, seeking underlying patterns and initial insights that will guide the creation of hypotheses.",,,,"['python', 'transformers', 'natural language processing', 'data mining', 'consulting', 'microsoft azure', 'numpy', 'machine learning', 'artificial intelligence', 'nosql', 'cloud', 'r', 'tensorflow', 'data science', 'gcp', 'optimization techniques', 'pytorch', 'mysql', 'aws', 'programming', 'architecture', 'nosql databases', 'ml', 'statistics']",2025-06-14 05:42:31
Snowflake Data Engineer,LatentView,3 - 6 years,Not Disclosed,"['Chennai', 'Bengaluru']","Job Description:\n\nWe are seeking a highly experienced and skilled Senior Data Engineer to join our dynamic team. This role requires hands-on experience with databases such as Snowflake and Teradata, as well as advanced knowledge in various data science and AI techniques. The successful candidate will play a pivotal role in driving data-driven decision-making and innovation within our organization.",,,,"['Data Engineering', 'Snowflake', 'Tableau', 'Data Warehousing', 'Data Modeling', 'ETL']",2025-06-14 05:42:33
Data/Applied Scientist (Search),BAY Area Technology Solutions,3 - 5 years,Not Disclosed,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","Strong in Python and experience with Jupyter notebooks, Python packages like polars, pandas, numpy, scikit-learn, matplotlib, etc.\nMust have: Experience with machine learning lifecycle, including data preparation, training, evaluation, and deployment Must have: Hands-on experience with GCP services for ML & data science Must have: Experience with Vector Search and Hybrid Search techniques Must have: Experience with embeddings generation using models like BERT, Sentence Transformers, or custom models Must have: Experience in embedding indexing and retrieval (e.g., Elastic, FAISS, ScaNN, Annoy) Must have: Experience with LLMs and use cases like RAG (Retrieval-Augmented Generation) Must have: Understanding of semantic vs lexical search paradigms Must have: Experience with Learning to Rank (LTR) techniques and libraries (e.g., XGBoost, LightGBM with LTR support) Should be proficient in SQL and BigQuery for analytics and feature generation Should have experience with Dataproc clusters for distributed data processing using Apache Spark or PySpark Should have experience deploying models and services using Vertex AI, Cloud Run, or Cloud Functions Should be comfortable working with BM25 ranking (via Elasticsearch or OpenSearch) and blending with vector-based approaches Good to have: Familiarity with Vertex AI Matching Engine for scalable vector retrieval Good to have: Familiarity with TensorFlow Hub, Hugging Face, or other model repositories Good to have: Experience with prompt engineering, context windowing, and embedding optimization for LLM-based systems Should understand how to build end-to-end ML pipelines for search and ranking applications Must have: Awareness of evaluation metrics for search relevance (e.g., precision@k, recall, nDCG, MRR) Should have exposure to CI/CD pipelines and model versioning practices GCP Tools Experience: ML & AI: Vertex AI, Vertex AI Matching Engine, AutoML, AI Platform Storage: BigQuery, Cloud Storage, Firestore Ingestion: Pub/Sub, Cloud Functions, Cloud Run Search: Vector Databases (e.g., Matching Engine, Qdrant on GKE), Elasticsearch/OpenSearch Compute: Cloud Run, Cloud Functions, Vertex Pipelines, Cloud Dataproc (Spark/PySpark) CI/CD & IaC: GitLab/GitHub Actions\nLocation: Remote- Bengaluru,Hyderabad,Delhi / NCR,Chennai,Pune,Kolkata,Ahmedabad,Mumbai",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'pandas', 'Jupyter notebooks', 'machine learning lifecycle', 'scikit-learn', 'Sentence Transformers', 'matplotlib', 'polars', 'BERT', 'numpy']",2025-06-14 05:42:36
Senior Analyst,Inspira Enterprise India,2 - 9 years,Not Disclosed,"['Mumbai', 'Nagpur', 'Thane', 'Nashik', 'Pune', 'Aurangabad']","Inspira Enterprise India Pvt. Ltd. is looking for Senior Analyst to join our dynamic team and embark on a rewarding career journey The Senior Analyst plays a crucial role in driving data-driven decision-making processes within the organization\n\nThis position involves analyzing complex data sets, generating actionable insights, and providing strategic recommendations to support key business initiatives\n\nKey Responsibilities:Data Analysis:Conduct in-depth analysis of large and complex datasets to extract meaningful insights\n\nUtilize statistical and data visualization tools to present findings in a clear and concise manner\n\nStrategic Planning:Collaborate with cross-functional teams to understand business objectives and provide analytical support for strategic initiatives\n\nDevelop and maintain models to support forecasting, budgeting, and other planning processes\n\nReporting and Dashboards:Design and create comprehensive reports and dashboards to track key performance indicators (KPIs) and metrics\n\nAutomate reporting processes to improve efficiency and accuracy\n\nTrend Analysis:Identify trends and patterns in data to help anticipate opportunities and challenges\n\nProvide insights on market trends, competitor analysis, and industry benchmarks\n\nDecision Support:Assist senior management in making informed decisions by providing data-driven recommendations\n\nEvaluate the impact of proposed strategies on business outcomes\n\nProcess Improvement:Identify areas for process improvement and efficiency gains based on data analysis\n\nCollaborate with teams to implement changes and measure the impact",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['cyber security', 'Senior Analyst', 'SOC']",2025-06-14 05:42:38
AWS Data Engineer,Redserv Global Solutions,3 - 6 years,10-15 Lacs P.A.,[],"Roles and Responsibilities:\n\nWe are looking for an experienced AWS Cloud Data Engineer to join our Data Science & Analytics team to build, optimize, and maintain cloud-based data solutions. The ideal candidate will possess strong technical knowledge in data engineering on AWS, expertise in data integration, pipeline creation, performance optimization, and a strong understanding of DevOps methodologies.\nDesign, develop, and deploy scalable, high-performance data pipelines on AWS and scalable AWS infrastructure solutions.",,,,"['Data Engineer', 'AWS', 'Python']",2025-06-14 05:42:40
Senior Analyst - US Healthcare,Aptia Group India,1 - 4 years,Not Disclosed,['Gurugram'],"We will count on you for :\n\nDaily Work Management and delivery of schemes\nWritten and Verbal communication with onshore business partners\nProcess reporting and training\nEnsuring compliance of all internal and client policies\nProviding timely updates to AM and Onshore counterparts\nDriving Process improvements\nAssist in analyzing and evaluating Benefits data files. Review data to identify issues and\ndiscrepancies and provides resolution of errors.\nMaintains operation systems and tools and provides system support.\nPerforms daily operational assignments and activities, including data analysis, system support and reporting.\n\nWhat you need to have?\n\nGraduate with minimum 1 year experience overall\nStrong health knowledge and experience in global and regional benefits\nProficient with MS Word, PowerPoint, and Excel\nExperience in process building, best practices and/or efficiency projects\nStrong oral and written communication & presentation skills\nGood analytical skills\nAbility to work within a team environment\nStrong self-starter, fast learner, quality conscious, committed to deadlines\nStrong attention to detail\nStrong teamwork skills combined with the ability to work independently with minimal supervision.\nLanguage skills are a plus and highly desired, but not required.\nknowledge of H&B domain\n\nWhat is in it for you?\n\nMedical insurance, personal accident insurance, group term life insurance from the day you join us\nHolidays (As Per the location)\nShared Transport (Provided the address falls in service zone)\n\nWhat makes you stand out?\n\nAdaptable communicator, facilitator, influencer and problem solver\nHigh attention to detail\nGood relationship skills, Proven ability to work on own initiative as well as in a team\nAdaptable communicator, facilitator and problem solver\nHigh attention to detail\nAbility to multi-task and prioritize time effectively",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Communication Skills', 'US Healthcare', 'H&B Domain', 'Benefits Analyst', 'Health Claims', 'Claims Adjudication', 'Claims Processing']",2025-06-14 05:42:44
Data Scientist Specialist (GenAI),Rarr Technologies,7 - 12 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","Role & responsibilities:\nOutline the day-to-day responsibilities for this role.\n\nPreferred candidate profile:\nSpecify required role expertise, previous job experience, or relevant certifications.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Langchain', 'Artificial Intelligence', 'Natural Language Processing', 'Python', 'RAG', 'Machine Learning', 'Deep Learning']",2025-06-14 05:42:47
Sr. GTM Analytics Analyst,Slintel,3 - 8 years,Not Disclosed,[],"Our Mission:\n6sense is on a mission to revolutionize how B2B organizations create revenue by predicting customers most likely to buy and recommending the best course of action to engage anonymous buying teams. 6sense Revenue AI is the only sales and marketing platform to unlock the ability to create, manage and convert high-quality pipeline to revenue.\nOur People:\nPeople are the heart and soul of 6sense. We serve with passion and purpose. We live by our Being 6sense values of Accountability, Growth Mindset, Integrity, Fun and One Team. Every 6sensor plays a part in de ning the future of our industry-leading technology. 6sense is a place where difference-makers roll up their sleeves, take risks, act with integrity, and measure success by the value we create for our customers.\nWe want 6sense to be the best chapter of your career.\nPosition Overview:\nWe are seeking a detail-oriented and strategic Sr. Analyst to focus on data storytelling, dashboarding, and insight generation. This role will partner closely with business stakeholders to develop data products that guide decisions across the customer lifecycle. In addition to analysis and visualization work, this person will support data governance efforts to ensure the consistency and accuracy of reporting outputs.\nKey Responsibilities:\nPartner with GTM and cross-functional teams to translate business needs into clear metrics, dashboards, and reports.\nCreate data visualizations that bring clarity to trends, performance, and strategic opportunities.\nPerform deep-dive analyses to inform go-to-market strategies, pipeline health, churn, and revenue performance.\nSupport data governance efforts by defining and documenting standard metrics, KPIs, and data sources.\nEnsure analytic outputs are built on clean, governed data and communicate data integrity issues when necessary.\nCollaborate with backend and data engineering teams to iterate on models and datasets that power business-facing reports.\nProactively identify data gaps and opportunities to improve self-serve access and decision-making.\nQualifications:\nBachelor s degree in Business Analytics, Statistics, Economics, or a related field. Master s preferred.\n3+ years of experience in a data analyst or insights role, preferably supporting GTM functions (Sales, Marketing, CS).\nProficiency in SQL and experience working with modern BI tools (Looker, Tableau, Power BI, Sigma).\nStrong communication skills; able to tailor insights to technical and non-technical audiences.\nExperience with or exposure to data governance and metric standardization.\nFamiliarity with customer journey metrics and revenue performance reporting is a plus.\nOur Benefits:\nFull-time employees can take advantage of health coverage, paid parental leave, generous paid time-off and holidays, quarterly self-care days off, and stock options. We ll make sure you have the equipment and support you need to work and connect with your teams, at home or in one of our o ces.\nWe have a growth mindset culture that is represented in all that we do, from onboarding through to numerous learning and development initiatives including access to our LinkedIn Learning platform. Employee well-being is also top of mind for us. We host quarterly wellness education sessions to encourage self care and personal growth. From wellness days to ERG-hosted events, we celebrate and energize all 6sense employees and their backgrounds.\nEqual Opportunity Employer:\n6sense is an Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. .\nWe are aware of recruiting impersonation attempts that are not affiliated with 6sense in any way. A ll email communications from 6sense will originate from the @6sense.com domain . We will not initially contact you via text message and will never request payments . If you are uncertain whether you have been contacted by an official 6sense employee, reach out to jobs@ 6sense.com",Industry Type: Internet,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Selection process', 'Backend', 'Sales', 'Business analytics', 'data governance', 'Wellness', 'power bi', 'data integrity', 'Data Analyst', 'SQL']",2025-06-14 05:42:51
"Senior Workday Analyst, HR","Epiq Systems, Inc.",5 - 10 years,Not Disclosed,['Hyderabad'],"Its fun to work at a company where people truly believe in what they are doing!\nJob Description:\nJob Summary:\nThe Senior HR Technology Analyst is responsible for developing, implementing and maintaining appropriate changes, configuration and processes within Workday, primarily focused on core Human Capital Management (HCM), Staffing, Help, or Reporting . This role will support leveraging technology solutions to meet the needs of human resources and users of Workday. This position will provide ongoing technical expertise and consultation on new functionality, system upgrades, configuration and testing efforts. This role will ensure a high level of data and process integrity in the day to day use of Workday, facilitate end user training, and provide effective and efficient customer service to internal Workday users globally. The Senior HR Technology Analyst will partner with IT, Finance, and external vendors to solve technical problems and manage and prioritize ongoing task list as well as work on continual process improvement with the HR Technology Manager.\nEssential Job Responsibilities\nServe as subject matter expert and act as a key resource of HR Systems projects including Workday system upgrade processes, deployment of new functionality, partnering with HR functional areas on system related process work, and major system implementation or integration project work.\nResponsible for system configuration and build work. Consult with functional users to identify best practice and strategy in configuration.\nWorkday Systems Support & Administration - Handle day to day issue resolution; ensure delivery of high quality customer service to end users; work with HR Technology Manager to resolve high level production issues.\nDrive data integrity within Workday and between systems; develop audit, research and resolution processes. Ensures data follows compliance needs and governs data mapping.\nWork with HR Technology Manager to research and resource opportunities to extend and optimize Workday usage.\nIdentify efficiencies through automation in the areas of business processes, integrations, and data loads.\nProvide new user training to Workday and administrative processing for particular HR users.\nPartner with other team members to review training and change management needs with all projects. Facilitate system training and communication as needed.\nMaintain Workday standard integrations and provide basic integration troubleshooting.\nIdentify trends or root cause behaviors for frequently occurring audit issues or integrations errors.\nQualifications & Requirements\nBachelor s degree in Human Resources, Business Management or related degree\n5+ years of experience in HRIS, 3+ years using Workday preferably with reporting experience.\nAbility to quickly learn concepts and understand process configuration in a system\nKnowledge of project management methodologies\nExperience managing multiple projects and priorities simultaneously\nGood teamwork interaction and leadership skills\nHighly self-motived, organized and methodical\nMust be experienced user of MS Office (Word, Excel, Outlook, Access, PowerPoint); In Excel, must have ability to create pivot tables, vlookups)\nProactive in achieving results and seeking improvements\nResults oriented with the ability to manage competing priorities and multiple stakeholders\nSolid understanding of overall HR functional areas and HR business processes, as well as interdependencies with Payroll, IT and Finance\nStrong analytical, problem solving and troubleshooting abilities; with strong data analysis acumen and focus on accuracy and attention to detail\nStrong verbal, written, and presentation skills. Ability to communicate effectively with all levels of the organizations\nIf you like wild growth and working with happy, enthusiastic over-achievers, youll enjoy your career with us!",Industry Type: Legal,Department: Human Resources,"Employment Type: Full Time, Permanent","['Data analysis', 'Payroll', 'Change management', 'Staffing', 'Project management', 'Process improvement', 'Analytical', 'Customer service', 'Troubleshooting', 'Auditing']",2025-06-14 05:42:55
Senior PV Programmer Analyst,Thermo Fisher Scientific,5 - 10 years,Not Disclosed,['Hyderabad'],"Work Schedule\nSecond Shift (Afternoons)\nEnvironmental Conditions\nOffice\nJob Description\nPurpose:\nSubject matter expert of day-to-day application configuration and maintenance activities of the Pharmacovigilance (PV) Safety database Oracle Argus, ensuring that performed tasks comply with SOPs and policies, industry standards, and applicable regulations. Provides technical solutions, support systems implementation and testing following change control procedures and provide systems administration to support the requirements and initiatives of the PV Safety group.\nResponsibilities include but are not limited to:\nCollaborates with PV business users to understand the requirements and recommend solutions.\nCreates custom and ad-hoc reports from the PV Safety database using built in tools, OBIEE, or SQL.\nDevelops and validates aggregate safety reports.\nAssists with internal and external audits of the PV Safety database.\nInteracts with project team or client and seeks feedback on deliverables.\nProvides programming support to project teams and clients for safety data review, ad-hoc reports and other activities.\nLeads project initiatives as needed, ensures desired outcome is achieved on time and in scope.\nReviews and makes recommendations for process development and improvement.\nManages assignment to meet timelines and deliver high quality work.\nEstimates effort to assist in bidding activities or cost construction.\nQualifications:\nEducation and Experience:\nBachelors degree or equivalent and relevant formal academic / vocational qualification\nPrevious experience that provides the knowledge, skills, and abilities to perform the job (comparable to 5+ years)\nKnowledge, Skills and Abilities:\nSystem administration experience in Oracle Argus including current knowledge of safety system configuration, database structure, mappings requirements and transformation rules\nStrong experience generating reports\nStrong SQL programming skills\nKnowledge of relational data base structure and experience working with complex data systems\nProficient of one or more programming languages\nStrong attention to detail\nProblem solving skills\nGood written and verbal communications skills\nAbility to independently and effectively organize and manage multiple assignments with challenging timelines\nAbility to adapt and adjust to changing priorities\nDemonstrated leadership, initiative and motivation\nAbility to mentor and direct the work of junior staff\nAbility to communicates effectively within a multi-disciplinary team\nAbility to complete assigned tasks on time and within budget",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Bidding', 'Data management', 'Management audit', 'Project management', 'Process improvement', 'Pharmacovigilance', 'Oracle', 'SQL', 'System administration']",2025-06-14 05:43:03
Data Scientist,Grid Dynamics,10 - 20 years,Not Disclosed,['Hyderabad'],"Role & responsibilitiMes\n\nCandiate needs to be 8+ Years of Experience\n\nDetails on tech stack\nPython\nPrompt engineering\nBest practices for prompt engineering\nHow LLM can be used in applications for a variety of tasks\nNLP\nUnderstanding of typical NLP problems: classification, NER, summarization, question answering, sentiment analysis, etc.\nTheoretical intuitive understanding of how Transformers work (tokenization, attention, etc).\nWord and sentence embeddings\nVector search\nVector databases, performance tuning\nDocument chunking techniques\nLLM applications development\nLangChain, LlamaIndex\nChain of Thoughts, DSP, and other techniques\nAgents and tools\nGoogle cloud (GCP)\nNice to have requirements to the candidate\nPreferable, the engineers are expected to have IT services/consulting experience.\nProficient in developing LLM-powered systems using advanced prompt engineering techniques, RAG and agentic design patterns. Experienced with frameworks like LangChain, LlamaIndex, and DSPy.\nFamiliar with evaluation approaches and metrics for different types of LLM-based systems.\nExperienced with keyword and vector search methods, including understanding of their underlying algorithms. Familiar with popular vector search engines.\nCompetent in various document understanding models and techniques to parse complex documents and implement effective chunking strategies for RAG systems.\nFamiliar with LLM and embedding models fine-tuning techniques.\nCompetent in using joint vision-language and generative models to solve various problems related to image generation, visual question answering, and multi-modal search. Familiar with diffusion models and associated techniques like LoRA, Dreambooth, and ControlNet.\nUnderstanding of the challenges and risks associated with the development of Generative AI systems and how to mitigate them.\nFamiliar with various architecture design patterns for different types of LLM-based applications such as chatbots, text2sql, document understanding, etc. Familiar with various approaches to scalability and cost reduction in Generative AI systems.\nAbility to stay updated with the latest advancements in Generative AI and integrate emerging technologies to drive innovation and improve the performance of AI systems.\nFamiliar with Responsible AI principles and Human-AI interaction design best practices.\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Lora', 'Natural Language Processing', 'Deep Learning', 'Python']",2025-06-14 05:43:07
Data Scientist - GEN AI,Rarr Technologies,6 - 8 years,Not Disclosed,['Bengaluru'],"At least 6 - 8 years overall experience\nAt least 4-5 years experience in Machine Learning / Deep Learning\nExtensive experience working on NLP\nConversant with Python programming\nGood knowledge of and experience working on Generative AI\nAdept in Prompt Engineering\nShould have a good understanding of microservices architecture and Data Engineering\nShould be able to understand user needs and map with corresponding technologies\nShould be able to architect Generative AI based solutions\nShould be able to guide the team technically\nShould be able to highlight technical limitations and shortcomings well in advance and suggest alternative approaches / solutions\nShould have working experience on Azure Cognitive Services\nExperience working on client facing roles and direct client interactions\nGood communication skills\nAi Ml, Nlp & Deep Learning, Data Science",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['deep learning', 'Architect', 'data science', 'Architecture', 'Machine learning', 'Programming', 'Python', 'microservices']",2025-06-14 05:43:09
Senior Tax Analyst,Avalara Technologies,3 - 8 years,Not Disclosed,['Pune'],"What You'll Do\n\nAs a Returns Experience Automation Analyst, you will report to Lead/Manager and partner with the tax compliance to deliver process and product automation solutions. You will contribute to Avalara's tax and compliance automation strategies while enhancing the overall experience of the service.\n\nWhat Your Responsibilities Will Be\n\nWhat You'll Need to be Successful",,,,"['Tax Analysis', 'rpa', 'data analysis', 'tax returns', 'uipath', 'accounting', 'taxation', 'artificial intelligence', 'tax compliance']",2025-06-14 05:43:12
Trainee,Wipro,0 years,Not Disclosed,['Gurugram'],Designation - Trainee\nWork Location - Gurugram\nEducation Qualification - B. Tech (CS / IT / ECE ) / MCA (2024 pass out only)\n5 days' work from office\nSaturday & Sunday fixed off\nBoth side transport\n\nJob Description:,,,,"['Manual Testing', 'SDLC', 'SQL', 'STLC']",2025-06-14 05:43:15
Hiring Fresher - Back office - MS Excel - Night shift -Mumbai,Trigent Software,0 years,1-2 Lacs P.A.,['Mumbai'],"Hi,\n\nGreetings from Trigent!!!\n\nHiring for fresher with good excel knowledge.\nJob Summary:\nWe are seeking a detail-oriented and analytical professional with strong communication skills and expertise in Microsoft Excel. The ideal candidate will be responsible for handling data analysis, generating reports, and effectively communicating insights.\nKey Responsibilities:\nWork with large data sets to clean, analyze, and present insights.\nPrepare and maintain reports using Excel (pivot tables, VLOOKUP, charts, etc.).\nCommunicate findings effectively with stakeholders.\nCollaborate with teams to optimize processes and improve efficiency.\nAdhere to rotational evening shift schedules as required.\nRequired Skills & Qualifications:\nProficiency in Microsoft Excel (advanced formulas, pivot tables, data visualization).\nStrong verbal and written communication skills.\nAnalytical mindset with attention to detail.\nAbility to work independently and as part of a team.\n\nWork location: Airoli\nOnly Immediate joiners are preferred.\nBoth pick & drop cab facility is provided.\nOnly graduates can apply (Bcom/ BBA/ BBI, BMS, BA).",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['ms excel', 'VLOOKUP', 'MIS Reporting']",2025-06-14 05:43:17
Digital Mktg Advisory New Associate,Accenture,0 - 1 years,Not Disclosed,['Gurugram'],"Skill required: Marketing Operations - Campaign Analytics & Reporting\n\n\n\n\nDesignation: Digital Mktg Advisory New Associate\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:0 to 1 years\n\n\n\nLanguage - Ability:English(International) - Proficient\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nHelp balance increased marketing complexity and diminishing marketing resources. Drive marketing performance with deep functional and technical expertise, while accelerating time-to-market and operating efficiencies at scale through Data and Technology, Next Generation Content Services, Digital Marketing Services & Customer Engagement and Media Growth Services.Role requires Digital Marketing Ads & Promotion creation/designEncompasses a set of technologies that enable the process of collecting & analyzing user behavioral activities with different marketing touch points, to reach on a web site or a mobile app with the ultimate aim of enhancing the targeted business goals. It comprises the processes and technologies that enable marketers to evaluate the success of their marketing initiatives, by measuring performance.\n\n\n\n\nWhat are we looking for\nGoogle AdsDigital MarketingDigital Marketing CampaignsCampaign ManagementCampaign OptimizationsAbility to establish strong client relationshipAbility to manage multiple stakeholdersCommitment to qualityStrong analytical skillsDetail orientation\n\n\n\nRoles and Responsibilities: In this role you are required to solve routine problems, largely through precedent and referral to general guidelines Your primary interaction is within your own team and your direct supervisor In this role you will be given detailed instructions on all tasks The decisions that you make impact your own work and are closely supervised You will be an individual contributor as a part of a team with a predetermined, narrow scope of work Please note that this role may require you to work in rotational shifts\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'sql', 'marketing', 'marketing operations', 'campaign analytics', 'email marketing', 'python', 'data analytics', 'data analysis', 'sas', 'google adwords', 'business analysis', 'machine learning', 'tableau', 'marketing analytics', 'social media marketing', 'google analytics']",2025-06-14 05:43:19
Measurement and Reporting New Associate,Accenture,0 - 1 years,Not Disclosed,['Noida'],"Skill required: Business Reporting & Governance - Reporting Analytics\n\n\n\n\nDesignation: Measurement and Reporting New Associate\n\n\n\n\nQualifications:Any Graduation\n\n\n\n\nYears of Experience:0 to 1 years\n\n\n\nAbout AccentureCombining unmatched experience and specialized skills across more than 40 industries, we offer Strategy and Consulting, Technology and Operations services, and Accenture Song all powered by the worlds largest network of Advanced Technology and Intelligent Operations centers. Our 699,000 people deliver on the promise of technology and human ingenuity every day, serving clients in more than 120 countries. Visit us at www.accenture.com\n\n\n\n\nWhat would you do\nThe Business Reporting and Governance vertical helps to deploy and deliver robust tracking mechanism for SLA/KPI or any other operations on a day-to-day basis. The Governance team will be responsible for contractual compliance of various aspects of contract like Governance, Reporting, Incident Management, Change Management and Survey Management along with driving automation and analytics. Assessing, managing, using, improving, monitoring, maintaining, and protecting organizational information through a system of decision rights and accountabilities for information related processes, executed according to agreed-upon models which describe who can take what actions, with what information, when, under what circumstances and using what methods. Candidate who is good in excel and MIS reports are looked at for these skillsPrepare management reports and analysis, both recurring and ad-hoc. It focuses on tracking business performance through trusted data and insights while actively managing employee behaviors.\n\n\n\n\nWhat are we looking for\nDecent communication skills with professional presence Experience in reporting of contractual metrics and operational KPIs Adaptability to change. Adept in working across a heavily matrixed organization. Proficient in MS Office with advance knowledge in excel formulas. Ability to create meaningful presentation through PowerPoint.\n\n\n\nRoles and Responsibilities: Publish Daily / Weekly / Monthly Reports on time with accuracy. Support in delivery of ad hoc reports. Identify opportunities to automate reports\n\nQualification\n\nAny Graduation",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['business reporting', 'vlookup', 'sql', 'reporting and analytics', 'mis', 'project management', 'data analysis', 'data analytics', 'mis reporting', 'team management', 'power bi', 'business analysis', 'business intelligence', 'tableau', 'vba', 'advanced excel', 'data visualization', 'finance']",2025-06-14 05:43:22
Data Scientist,Dwplacesolutions,3 - 5 years,Not Disclosed,['Bengaluru'],We are seeking an experienced Data Scientist to join our team.\nThe ideal candidate will have a strong background in developing and deploying\nconversational AI solutions using Large Language Models (LLMs) and RASA\nframework.,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Machine Learning', 'Tensorflow', 'R', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Chatbot', 'Deep Learning', 'Python']",2025-06-14 05:43:25
Hiring - Junior MIS Executive - ( Preferred female candidates only),TYA Business Solutions,0 - 3 years,"70,000-2.25 Lacs P.A.",['Bengaluru( Koramangala )'],"Responsibilities:\nCheck the pending tasks of employees.\nCommunicate with employees to ensure the completion of their tasks in a timely manner.\nEscalate any unresolved issues to the management.\nHandle any other ad hoc tasks as assigned.\n\nExperience: 0 - 3 years\nJob Title: Employee Tasks Coordinator\nLocation: Bangalore (Koramangala)\n\nQualifications:\nBachelor's degree in a relevant field.\nGood communication and interpersonal skills.\nGood organizational and problem-solving skills.\nAbility to multitask, prioritize, and manage time efficiently.\nFamiliarity with computer applications such as MS Office Suite (MS Excel and MS Word, specifically).\n\nAge Below 40 years.\n\nPlease e-mail us to schedule your interview & drop your resume at hr@tyagroup.co.in\n\nNote: If already Attended the interview, Please ignore the mail or call before you apply. Also, refer your friends.",Industry Type: Accounting / Auditing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Good Communication In English', 'Advanced Excel', 'Email Communication', 'Follow Ups']",2025-06-14 05:43:27
Mis Executive,Aarti Industries,0 - 1 years,1.75-3 Lacs P.A.,['Mumbai( Vikhroli West )'],"- Responsible for upkeep of the organization's structure as displayed in google sheets\n- To cater to the data requirements as and when needed by the team\n- Responsible to maintain the integrity of the live Org Structure Sheets as a tool for depicting organization level organogram structure\n- Responsible for ensuring the integrity of the HRMS configured masters,custom workflows by regularly improvising them as and wherever required\n- Responsible to ensure the quality and integrity of data imported to form the employee database masters\n- Responsible to facilitate creation of user interfaces over HRMS in order to fetch real time data analytics and dashboards related to manpower status like RAG etc.",Industry Type: Chemicals,Department: Human Resources,"Employment Type: Full Time, Temporary/Contractual","['Excel', 'Pivot Table', 'VLOOKUP']",2025-06-14 05:43:29
Team Lead - Line Haul,Amazon,0 - 6 years,Not Disclosed,['New Delhi'],"At Amazon, were working to be the most customer-centric company on earth. To get there, we need exceptionally talented, bright and driven people. Amazon is one of the most recognizable brand names in the world and we distribute millions of products each year to our loyal customers.\nAmazon is seeking Operation Team Lead for its Transportation team. In this role you will working closely with fulfillment centers (FCs) and sort centers (SCs), last mile (LMs) logistic partners and other stakeholders for smooth management of line haul operations across Amazons middle mile network. Team Lead will be the first POC for any operational escalation and will engage with the right stakeholders to resolve the issue & prevent recurrence. Apart from handling people (team of L2 and PA), the Team Lead will also drive deployment of solutions coming out from various improvement initiatives viz. VRID hygiene, Accruals improvement, In-transit loss reduction, Developing safety culture for Drivers, Truck Utilization improvement, New projects (Totes, PFS) etc. at zonal level. In BAU, he/she will be rostered in shifts for keeping a tab on operations & work on improvement projects.\nEssential Functions\nCarrier manager for coordination with NOC & carriers\nGB development initiatives\nDriving improvement Opportunities:\no Truck utilization\no Carrier arrival performance at destination\no Accident analysis\nPrepare bridge for WBR\nBAU Ad-hoc Planning & analysis\nCoordinate with SLP & carrier to reduce in-transit losses\nEngage with Safety to improve yard & road safety\nDrive R4D training & adoption with carriers\nManage and raise MR PO process\nResolution of invoice queries (both Vendor/Amazon)\nPO Fund additions for on-time payments\nMaintain distance annexure & route codes\nAccruals Preparation\nDrive R4C adoption to improve carrier experience\no Pre-registration compliance\no LTR coding\no Load board\no Self-invoicing\no Driver assignment for R4D\nAlign vehicle fleet plan with stakeholders (FC, SC, LM, SF)\nInput preparation for Automated Planning (such as MRO)\no Distance & Transit time inputs for all OD pairs\no Prepare manual vehicle plan as an input\no Run tool to optimize routes\no Analyze tool output for execution feasibility\no Re-configure vehicle run plan\no Work with NDC for necessary truck filter changes\nLane level cube analysis to improve planning accuracy\nPrime Now & WHT Management\no Fleet planning based on forecast\no Accruals preparation\no Launch of new arc movements\nData analysis & Execution of New Projects SFC, Totes, etc.\nNew SC, FC, Station Launches\no Pilot run & feasibility check\no Prepare vehicle fleet plan\no Carrier allocation\nART Event execution\no GB training and ramp up before peak\no Re-routing of vehicles to increase vehicle turns\no In-transit break-down recovery/rescue planning\no Mechanic arrangement at Origins\no Vendor Control Tower Manning Bachelors degree\nSpeak, write, and read fluently in English\nExperience with Microsoft Office products and applications Bachelors degree in Executive Assistant or Business Administration",,,,"['Business administration', 'Data analysis', 'LMS', 'Coding', 'Deployment', 'Management', 'MS Office', 'road safety', 'Operations', 'Network Team Lead']",2025-06-14 05:43:31
Customer Success Analyst,Boomi Software,3 - 8 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","About Boomi and What Makes Us Special\nAre you ready to work at a fast-growing company where you can make a difference? Boomi aims to make the world a better place by connecting everyone to everything, anywhere. Our award-winning, intelligent integration and automation platform helps organizations power the future of business. At Boomi, you ll work with world-class people and industry-leading technology. We hire trailblazers with an entrepreneurial spirit who can solve challenging problems, make a real impact, and want to be part of building something big. If this sounds like a good fit for you, check out boomi.com or visit our Boomi Careers page to learn more.\nAbout the Role\nWe are looking for dynamic, detail-oriented and data driven professionals to join our newly established advisory team in Bangalore, India. Partnering with Customer Success and Account Managers, this team will play a pivotal role in strategic business development by scaling operational and high value engagements for our global customer base. The Advisors in this role will focus on supporting Operational Reviews, Quarterly Business Reviews (QBRs), and Value Assessments (VAs) by demonstrating qualitative and quantitative benefits of the Boomi platform to various stakeholders within a customer s IT organization. They will possess strong data acumen to product data, platform usage, adoption trends, and value metrics to create insights-driven customer deliverables that focus on enabling informed decision-making and continuous optimization of their Boomi implementation.\nLocation - Bangalore\nKey Responsibilities\nData Preparation and Analysis:\nExtract and analyze platform usage, adoption trends, and value metrics to create insights-driven customer deliverables.\nPrepare data-backed presentations by collaborating with Customer Success and Account Managers highlighting usage trends, platform benefits, cost savings and maturity assessments.\nOperational Support for Reviews:\nPrepare slides and data points for Monthly Adoption Reviews and QBRs.\nCollaborate with account teams to tailor content based on customer-specific needs.\nValue Assessments:\nConduct structured value assessments to showcase the business outcomes achieved through Boomi.\nDevelop and curate findings tied to documented outcomes using reference metrics like cost avoidance and ROI.\nInsights and Contextual Updates:\nProvide commentary on trends, usage updates, and contextualized feature recommendations based on customer activity and platform changes as well as industry trends and point of views.\nScalable Processes:\nWork on a mix of automated and augmented processes to ensure consistent high-value engagement across accounts.\nLeverage tools and processes to streamline data-driven insights and support scaled success initiatives.\nStandardize best practices for adoption and value realization discussions.\nRequirements\nExperience\n3+ years of background in Customer Success, Advisory, Data or Business Analysis, or related roles.\nProficiency in data analysis and creating presentations for executive-level discussions.\nAnalytical mindset with attention to detail and the ability to contextualize data into actionable insights.\nExcellent collaboration, communication and organizational skills to work with cross-functional teams.\nFamiliarity with SaaS platforms and value realization methodologies including tools like PowerBI/Tableau, Gainsight, Salesforce and business intelligence platforms\nKnowledge of cost optimization and ROI analysis in technology solutions.\nQualifications\nEducation: Bachelor s degree or diploma in fields such as Business Administration, Computer Science, Information Systems, or related disciplines.\nCertifications\nHave or achieve full Boomi Developer, Architect, and Administrator certifications within the first two months of employment.\nCertifications in Data Analysis or Data Science vocational courses\nWhy Join Us?\nThis is an exciting opportunity to shape a new team and directly contribute to scaling Boomi s Customer Success operations globally. You will play a critical role in driving measurable value for customers and enabling their long-term success with the Boomi platform.\n#LI-NR1\nBe Bold. Be You. Be Boomi. We take pride in our culture and core values and are committed to being a place where everyone can be their true, authentic self. Our team members are our most valuable resources, and we look for and encourage diversity in backgrounds, thoughts, life experiences, knowledge, and capabilities.\nAll employment decisions are based on business needs, job requirements, and individual qualifications.\nBoomi strives to create an inclusive and accessible environment for candidates and employees. . This inbox is strictly for accommodations, please do not send resumes or general inquiries.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Usage', 'operational support', 'Business analysis', 'Analytical', 'boomi', 'VAS', 'Business intelligence', 'Salesforce']",2025-06-14 05:43:34
Customer Success Analyst,Boomi Software,11 - 16 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","About Boomi and What Makes Us Special\nAre you ready to work at a fast-growing company where you can make a difference? Boomi aims to make the world a better place by connecting everyone to everything, anywhere. Our award-winning, intelligent integration and automation platform helps organizations power the future of business. At Boomi, you ll work with world-class people and industry-leading technology. We hire trailblazers with an entrepreneurial spirit who can solve challenging problems, make a real impact, and want to be part of building something big. If this sounds like a good fit for you, check out boomi.com or visit our Boomi Careers page to learn more.\nAbout the Role\nWe are looking for dynamic, detail-oriented and data driven professionals to join our newly established advisory team in Bangalore, India. Partnering with Customer Success and Account Managers, this team will play a pivotal role in strategic business development by scaling operational and high value engagements for our global customer base. The Advisors in this role will focus on supporting Operational Reviews, Quarterly Business Reviews (QBRs), and Value Assessments (VAs) by demonstrating qualitative and quantitative benefits of the Boomi platform to various stakeholders within a customer s IT organization. They will possess strong data acumen to product data, platform usage, adoption trends, and value metrics to create insights-driven customer deliverables that focus on enabling informed decision-making and continuous optimization of their Boomi implementation.\nKey Responsibilities\nData Preparation and Analysis:\nExtract and analyze platform usage, adoption trends, and value metrics to create insights-driven customer deliverables.\nPrepare data-backed presentations by collaborating with Customer Success and Account Managers highlighting usage trends, platform benefits, cost savings and maturity assessments.\nOperational Support for Reviews:\nPrepare slides and data points for Monthly Adoption Reviews and QBRs.\nCollaborate with account teams to tailor content based on customer-specific needs.\nValue Assessments:\nConduct structured value assessments to showcase the business outcomes achieved through Boomi.\nDevelop and curate findings tied to documented outcomes using reference metrics like cost avoidance and ROI.\nInsights and Contextual Updates:\nProvide commentary on trends, usage updates, and contextualized feature recommendations based on customer activity and platform changes as well as industry trends and point of views.\nScalable Processes:\nWork on a mix of automated and augmented processes to ensure consistent high-value engagement across accounts.\nLeverage tools and processes to streamline data-driven insights and support scaled success initiatives.\nStandardize best practices for adoption and value realization discussions.\nRequirements\nExperience\n11+ years of background in Customer Success, Advisory, Data or Business Analysis, or related roles.\nProficiency in data analysis and creating presentations for executive-level discussions.\nAnalytical mindset with attention to detail and the ability to contextualize data into actionable insights.\nExcellent collaboration, communication and organizational skills to work with cross-functional teams.\nFamiliarity with SaaS platforms and value realization methodologies including tools like PowerBI/Tableau, Gainsight, Salesforce and business intelligence platforms\nKnowledge of cost optimization and ROI analysis in technology solutions.\nQualifications\nEducation: Bachelor s degree or diploma in fields such as Business Administration, Computer Science, Information Systems, or related disciplines.\nCertifications\nHave or achieve full Boomi Developer, Architect, and Administrator certifications within the first two months of employment.\nCertifications in Data Analysis or Data Science vocational courses\nWhy Join Us?\nThis is an exciting opportunity to shape a new team and directly contribute to scaling Boomi s Customer Success operations globally. You will play a critical role in driving measurable value for customers and enabling their long-term success with the Boomi platform.\nBe Bold. Be You. Be Boomi. We take pride in our culture and core values and are committed to being a place where everyone can be their true, authentic self. Our team members are our most valuable resources, and we look for and encourage diversity in backgrounds, thoughts, life experiences, knowledge, and capabilities.\nAll employment decisions are based on business needs, job requirements, and individual qualifications.\nBoomi strives to create an inclusive and accessible environment for candidates and employees. . This inbox is strictly for accommodations, please do not send resumes or general inquiries.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Usage', 'operational support', 'Business analysis', 'Analytical', 'boomi', 'VAS', 'Business intelligence', 'Salesforce']",2025-06-14 05:43:36
Product Operations Analyst,Aptos Labs,1 - 5 years,Not Disclosed,['Bengaluru'],"Making a career change is a big decision. Why consider Aptos\nBecome a part of a team that is passionate about creating and delivering cutting-edge solutions for retailers worldwide. At our company, we re dedicated to supporting your career aspirations and helping you exceed your goals. You ll benefit from industry-leading training, global development opportunities, and the chance to collaborate within a diverse culture across our offices in nine countries. Our inclusive culture reflects our purpose: to make a difference for every colleague, every client, every day .\nAs a leading provider of Unified Commerce solutions for retail, our technology empowers top retail brands by optimizing product management, promotions, merchandising, and store operations. With the global shift toward our cloud-native, microservices architecture, opportunities for career growth have never been more exciting. Today, more than 100,000 retail stores in fashion, grocery, footwear, general merchandise, discount, and sporting goods rely on our solutions to generate nearly $2 trillion in annual revenue.",,,,"['Product management', 'Process automation', 'Data analysis', 'Operations Analyst', 'Analytical', 'Agile', 'JIRA', 'Python', 'Business operations']",2025-06-14 05:43:39
Data & Analytics Strategy Executive,Aegis Media,1 - 4 years,Not Disclosed,"['Mumbai', 'Bengaluru']","The purpose of this role is data analysis/guided deliverable development in support of assessment/strategic deliverables.\nJob Description:\nKey responsibilities:\nAggregates data, prepares and analyses as it relates to assessment and roadmap development and execution\nProduces detailed analysis that facilitates internal team discussion and client facing deliverables\nUses, evaluates and improves internal templates, tools and processes\nExecutes and progresses project timeline\nSkills: Tableau, SQL, EXCEL, Media Domain Knowledge, Python(good to have).\nLocation:\nMumbai\nBrand:\nMerkle\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'tableau', 'Excel', 'Executive', 'Data analytics', 'SQL', 'Python']",2025-06-14 05:43:41
Hiring MBA/PGDM graduates For Retail Operations,MALABAR GOLD & DIAMONDS,0 - 5 years,3.75-4.75 Lacs P.A.,"['Ernakulam', 'Kannur', 'Malappuram']","Contact HR:- Anjitha CM\nSenior HR Executive\n8714506916\nMALABAR GROUP HEAD QUARTERS\n\nJob Description\nTo effectively manage the sales, operations, marketing & administration of the Showroom &",,,,"['Communication Skills', 'Presentation Skills', 'Management Skills', 'Interpersonal Skills', 'Team Skills', 'Convincing Power', 'Leadership Skills']",2025-06-14 05:43:43
Sr. Manager - Finance Business Partner,Flipkart,3 - 8 years,Not Disclosed,['Bengaluru'],"Manager - Finance Business Partner\nTo Success in the role\nPossess strong analytical skills and a keen attention to detail.\nDemonstrate proficiency in financial analysis and modeling techniques.\nExhibit excellent communication and interpersonal skills, with the ability to collaborate effectively with cross-functional teams.\nDisplay a proactive and results-oriented mindset, with a drive for continuous improvement.",,,,"['Financial Analysis', 'Financial Modelling', 'Workforce Management', 'Data Analysis', 'Cost Optimization', 'Strategic Planning']",2025-06-14 05:43:47
IN-Specialist 2_Finance_BEST Operations_IFS_Gurgaon,PwC Service Delivery Center,0 - 1 years,Not Disclosed,['Gurugram'],"Internal Firm Services\nIndustry/Sector\nManagement Level\nSpecialist\n& Summary\nAt PwC, our people in finance focus on providing financial advice and strategic guidance to clients, helping them optimise their financial performance and make informed business decisions. These individuals handle financial analysis, budgeting, forecasting, and risk management.\n\nIn financial operations at PwC, you will focus on managing financial processes and confirming compliance with regulations. You will handle tasks such as financial reporting, budgeting, and risk management.\nWhy PWC\nAt PwC, you will be part of a vibrant community of solvers that leads with trust and creates distinctive outcomes for our clients and communities. This purposeled and valuesdriven work, powered by technology in an environment that drives innovation, will enable you to make a tangible impact in the real world. We reward your contributions, support your wellbeing, and offer inclusive benefits, flexibility programmes and mentorship that will help you thrive in work and life. Together, we grow, learn, care, collaborate, and create a future of infinite experiences for each other. Learn more about us .\n& Summary A career in Finance, within Internal Firm Services, will provide you with the opportunity to help PwC in all aspects of our Finance internal function including financial planning and reporting, data analysis, and assisting leadership with overall strategy. You ll focus on recording and analysing financial transactions, paying and receiving invoices, maintaining financial statement ledger accounts, and preparing analysis and reconciliations of bills to detect fraud.\nResponsible for the daytoday activities assigned transaction processing for a specific process or group of processes with the teams.\nMeeting the SLA s and assigned volume on daily basis\nEnsuring compliances/ adherence to internal policies as per Internal Controls\nUnderstand the overall ERP system and Shared services system interfaces and processes, suggesting improvements in the existing system and processes\nEnsure successful delivery of the services and confirm the qualityofservice delivery\nDiscuss operational concerns (if any) with the team leader\nMaintaining a good level of relationship, education, and resolution of issues\nMandatory skill sets\nAccounts receivable, accounts payable, excel, generation of invoices.\nPreferred skill sets\nFinance, accounts\nYears of experience required\n01 year\nEducation qualification\nB.Com, BBA, MBA, M.Com, PGDM\nEducation\nDegrees/Field of Study required Bachelor of Commerce, Master of Business Administration, Bachelor in Business Administration\nDegrees/Field of Study preferred\nRequired Skills\nAccounts Payable (AP)\nAccepting Feedback, Accepting Feedback, Accounting Policies, Accounting Practices, Active Listening, Balance Sheet Analysis, Budgetary Management, Cash Flow Analysis, Communication, Emotional Regulation, Empathy, Escalation Management, Financial Budgeting, Financial Close Process, Financial Data Mining, Financial Forecasting, Financial Management, Financial Policy, Financial Reporting, Financial Statement Analysis, Generating Financial Reports, Inclusion, Intellectual Curiosity, Internal Controls, Key Performance Indicators (KPIs) {+ 4 more}\nNo",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Data analysis', 'Financial analysis', 'Financial planning', 'Cash flow', 'Financial statement analysis', 'Budgeting', 'Risk management', 'Data mining', 'Forecasting', 'Operations']",2025-06-14 05:43:49
"Principal Analyst, Insights",Zeta Global,3 - 4 years,Not Disclosed,['Bengaluru'],"Description: Principal Data Analyst will be responsible for analyzing complex datasets, identifying opportunities for process improvements, and implementing automation solutions to streamline workflows. This role requires a deep understanding of data analytics, process automation tools, and excellent problem-solving skills. The ideal candidate will be proactive, detail-oriented, and able to work collaboratively with cross-functional teams to drive data-driven initiatives.\nWhat you ll do:\nAnalyze large and complex datasets to identify trends, patterns, and insights that drive business decisions.\nDevelop, implement, and maintain automated processes to improve data accuracy, efficiency,and reporting capabilities.\nCollaborate with stakeholders to understand business requirements and translate them into technical solutions.\nDesign and build automated dashboards and reports to provide real-time insights to various departments.\nUtilize data visualization tools to present findings in a clear and actionable manner.\nContinuously monitor and refine automated processes to ensure optimal performance and scalability.\nStay updated with industry trends and best practices in data analytics and process automation.\nMentor and provide guidance to junior data analysts on best practices and technical skills.\nWho you are:\nA great communicator who can convey complex technical features in simple terms.\nAble to multitask and prioritize among several high-profile clients.\nHave a high degree of creativity, self-motivation, and drive.\nEagerness to work in a startup team environment that will be rapidly changing.\nEnthusiastic team player with a penchant for collaboration and knowledge sharing.\nWillingness to do whatever it takes to get the job done.\nNerdy but loveable.\nData driven, technical, self-starting and curious.\nWhat you need:\nBachelor s or Master s degree in data science, Computer Science, Statistics, or a related field.\nMinimum of 3-4 years of experience in data analysis, with a focus on process automation.\nA minimum of 2 years of work experience in analytics (minimum of 1 year with a Ph.D.)\nExperience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Experience with combining and consolidating disparate datasets in apps such as Big Query, Data Bricks\nProficiency in programming languages such as Python, R, or SQL.\nExtensive experience with data visualization tools such as Tableau, Power BI or similar.\nStrong knowledge of process automation tools and platforms (e.g., Alteryx, UiPath, Microsoft Power Automate).\nExperience with database management systems (e.g., SQL Server, MySQL, PostgreSQL).\nExcellent analytical and problem-solving skills.\nAbility to work effectively in a fast-paced, collaborative environment.\nStrong communication skills, with the ability to convey complex data insights to non-technical stakeholders.\nExperience with machine learning and predictive analytics is a plus.\nBonus if you have:\nMaster s or Ph.D. Degree in a quantitative field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL', 'UiPath', 'R', 'Power BI', 'PostgreSQL', 'MySQL', 'Alteryx', 'Tableau', 'Python']",2025-06-14 05:43:52
Senior Analyst - MBB,Aegis Media,4 - 8 years,Not Disclosed,['Chennai'],"The purpose of this role is to provide support to the senior team in delivering innovative solutions that deliver client objectives whilst meeting our business objectives and financial targets.\nJob Description:\nKey responsibilities:Collects and reports buying performance achieved on nominated clients that have Global Buying commitmentsEnsures that accuracy of data supplied and the declared results meet with potential external scrutinyEffectively communicates benchmarking methodology and productivity targets to local marketsCollects data from specific markets using the agreed methodology (client specific) to quantify, measure, calibrate price performance compared to historical price benchmarks - across all media typesIdentifies data anomalies and also potential delivery issues in marketManages data to normalise benchmarks to maintain as high levels of measurability as possible within the reportsManages preparation and verification of the data for the client reports - both data analysis and supporting commentaryAssists local markets and client service teams in dealing with Media Auditor requests / validations\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Auditor', 'Analyst', 'Data analysis', 'Client servicing', 'Finance', 'MBB']",2025-06-14 05:43:54
Senior Analyst - Change Management,Nium India,3 - 8 years,Not Disclosed,['Mumbai'],"Nium, the Leader in Real-Time Global Payments\nNium , the global leader in real-time, cross-border payments, was founded on the mission to deliver the global payments infrastructure of tomorrow, today. With the onset of the global economy, its payments infrastructure is shaping how banks, fintechs, and businesses everywhere collect, convert, and disburse funds instantly across borders.\n\nIts payout network supports 100 currencies and spans 220+ markets, 100 of which in real-time. Funds can be disbursed to accounts, wallets, and cards and collected locally in 35 markets. Niums growing card issuance business is already available in 34 countries. Nium holds regulatory licenses and authorizations in more than 40 countries, enabling seamless onboarding, rapid integration, and compliance - independent of geography. The company is co-headquartered in San Francisco and Singapore.\n\nAbout the Team:\n\nChange Management - The team plays a critical role in optimizing operational efficiency by managing the logical setup and administration of the ticketing system. They design and implement workflow automations to enhance end-user experience, develop and maintain KPI dashboards and reporting for performance tracking, and lead continuous process monitoring and improvement initiatives to drive sustained operational excellence.\nAbout the Role:\nWe are looking for a skilled Data Analyst to join our team. The ideal candidate should have strong expertise in data analysis, data maintenance, and automation, with hands-on experience in SQL, Python, and Excel (including VBA and Power Query automation). The role requires the ability to manage reports, maintain version control, and support business processes with data-driven insights.\nKey Responsibilities:\nTranslate business requirements into technical data specifications and manipulate larger datasets to support various data initiatives where data is capitalized as an asset.\nFocus on developing customizable reports, ad hoc analysis, and data visualizations in a business-friendly manner to drive adoption.\nOwn development of database structures, views, stored procedures, functions, and triggers.\nDevelop and test solutions using Access, VBA, SQL Server, or any other technology. Support existing developed automated tools and maintenance activities.\nDocument and communicate objectives, plans, status, issues and risks in a timely manner to team members, stakeholders, and senior management.\nWillingness to support critical business needs beyond standard working hours, if required.\nRequirements:\nHas a bachelor s degree with 3+ Years of Experience working with Reporting / Office Automation (VBA) and any Relations Database Management (SQL/MS Access/ MySQL/ Oracle etc).\nExperience in preparing Business Requirement Document (BRD) and working with Business subject matter experts to resolve data related queries.\nResponsible for end-to-end data analysis to understand and define how data is collected, transformed, and published to support the business users for their objectives.\nStrong proficiency in SQL for data analysis and reporting and knowledge of ETL processes and data warehousing.\nStrong analytical and problem-solving skills and ability to self-drive projects and work across multiple teams.\nExcellent verbal and written communication skills.\nWhat we offer at Nium\nWe Value Performance: Through competitive salaries, performance bonuses, sales commissions, equity for specific roles and recognition programs, we ensure that all our employees are well rewarded and incentivized for their hard work.\n\nWe Care for Our Employees: The wellness of Nium ers is our #1 priority. We offer medical coverage along with 24/7 employee assistance program, generous vacation programs including our year-end shut down. We also provide a flexible working hybrid working environment (3 days per week in the office).\n\nWe Upskill Ourselves: We are curious, and always want to learn more with a focus on upskilling ourselves. We provide role-specific training, internal workshops, and a learning stipend\n\nWe Constantly Innovate: Since our inception, Nium has received constant recognition and awards for how we approach both our business and talent opportunities.\n- 2022 Great Place To Work Certification\n- 2023 CB Insights Fintech 100 List of Most Promising Fintech Companies .\n- CNBC World s Top Fintech Companies 2024.\n\nWe Celebrate Together: We recognize that work is also about creating great relationships with each other. We celebrate together with company-wide social events, team bonding activities, happy hours, team offsites, and much more!\n\nWe Thrive with Diversity: Nium is truly a global company, with more than 33 nationalities, based in 18+ countries and more than 10 office locations. As an equal opportunity employer, we are committed to providing a safe and welcoming environment for everyone.\nFor more detailed region specific benefits : https: / / www.nium.com / careers#careers-perks\nFor more information visit www.nium.com\n\nDepending on your location, certain laws may regulate the way Nium manages the data of candidates. By submitting your job application, you are agreeing and acknowledging that you have read and understand our Candidate Privacy Notice located at www.nium.com / privacy / candidate-privacy-notice .",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAN', 'Data analysis', 'Change management', 'MS Access', 'MySQL', 'Workflow', 'Stored procedures', 'Oracle', 'SQL', 'Python']",2025-06-14 05:43:57
Paid Social - Senior Analyst,Aegis Media,1 - 4 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimization of Paid Social campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nProvide initial insights on campaign trends to executives and planners\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Advertising & Marketing,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['QA', 'Analyst', 'Data analysis', 'Management']",2025-06-14 05:43:59
Salesforce Quality Analyst - Manual/Automation Testing,Emperen Technologies,5 - 7 years,Not Disclosed,['Bengaluru'],"Contract duration : 6 months\n\nKey Responsibilities :\n\n- Solid grasp of Salesforce core functionalities, including Sales Cloud, Service Cloud, and other relevant clouds.\n\n- Familiarity with Salesforce configurations, customizations, and data models and administration concepts.\n\n- Ability to perform various testing types, including functional, integration, regression, and performance testing.\n\n- Familiarity with testing tools like Selenium or other Salesforce testing tools with experience in GIT and Jira.\n\n- Excellent communication skills to report defects and collaborate with developers and other stakeholders.\n\n- Ability to analyze requirements and translate them into testable scenarios.\n\n- 5+ year experience in Salesforce testing and creating regression scripts on regular basis.\n\n- Conduct manual and automated testing of Salesforce applications to ensure high-quality deliverables.\n\n- Collaborate with development and product teams to understand requirements and define test strategies.\n\n- Perform API testing to validate integrations and data flow between Salesforce and external systems.\n\n- Write and execute SQL queries to analyze data, ensuring data integrity and accuracy.\n\n- Use tools like Salesforce Inspector, Workbench or Dev console for daily testing needs.\n\n- Identify, document, and troubleshoot defects, working closely with development teams to resolve issues.\n\n- Develop and maintain automated test scripts using tools such as Selenium or similar frameworks.\n\n- Participate in code reviews and provide feedback to improve testability and quality.\n\n- Stay updated with Salesforce releases and best practices to enhance testing processes.\n\n- Proven experience in Salesforce administration, SQL, data analysis and QA testing.\n\n- Strong understanding of API testing concepts and tools (e.g., Postman, SoapUI).\n\n- Experience with automation testing frameworks and tools.\n\n- Excellent analytical and problem-solving skills with strong communication and collaboration abilities.\n\n- Salesforce certification (e.g., Salesforce Administrator or any QA related certification",Industry Type: Automobile,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Salesforce', 'POSTMAN', 'Salesforce Service Cloud', 'API Testing', 'Integration Testing', 'Automation Testing', 'Salesforce Testing', 'Manual Testing', 'Functional Testing', 'Testing', 'SFDC Sales Cloud']",2025-06-14 05:44:02
"Risk Analyst, E-commerce - Top Indian Conglomerate",Top Indian Conglomerate,3 - 5 years,20-25 Lacs P.A.,['Bengaluru'],"Job Title: Risk Analyst - Commerce\n\nReports To: Lead Fraud Risk Commerce\n\n""LOOKING FOR CANDIDATES ONLY FROM E-COMMERCE COMPANIES""\n\nAbout the Role:\nWe are seeking a skilled and detail-oriented Risk Analyst to join our Commerce Risk team. This role is critical in driving risk intelligence through data-backed insights and timely analysis. The ideal candidate will not only work with large datasets and analytical models but will also be responsible for translating technical findings into clear, actionable summaries for leadership and crossfunctional stakeholders.\nThe analyst is expected to identify risks, uncover patterns in user behavior, and support strategic risk mitigation decisions across the platform, particularly in the areas of customer abuse, promotional misuse, and trust violations.\n\nKey Responsibilities:\nPrepare and analyze complex datasets to identify risk patterns, surface anomalies, and validate business hypotheses.\nBuild concise summaries and visualizations that simplify technical data for diverse audiences, enabling informed decision-making across Risk, Product, and Business teams.\nCommunicate insights through clear narratives, providing actionable recommendations and highlighting associated risks and trade-offs.\nDesign and execute BI and reporting frameworks to monitor key metrics, rule performance, and customer impact across commerce brands.\nCollaborate with data engineering teams to maintain robust data pipelines and models for risk signal generation.\nContribute to data modeling efforts and manage risk-centric data structures within the data warehouse.\nSupport development and refinement of risk rules and machine learning models to strengthen detection of fraudulent or abusive behaviors.\nMaintain documentation and continuously evolve analysis SOPs based on the latest business rules, thresholds, and ecosystem learnings.\n\nRole Requirements:\nBachelors degree in a quantitative discipline such as Statistics, Mathematics, Economics, Computer Science, or a related field.\n3 - 5 years of hands-on experience in risk analytics, fraud detection, or business intelligence, preferably within eCommerce or fintech domains.\nProficient in SQL and Python for data extraction, transformation, and visualization; exposure to tools like R, Tableau, Power BI is a plus.\nStrong understanding of data warehousing, data modeling, and performance monitoring techniques.\nExperience working with rule-based and predictive risk frameworks is preferred.\nExcellent communication and storytelling skills, with the ability to present insights to nontechnical audiences in a structured and impactful manner.\nProven experience working in cross-functional environments, balancing business priorities and analytical rigor.\n\nBasic Qualifications:\nBachelor's degree in a quantitative discipline such as Statistics, Mathematics, Economics, Computer Science, or a related field.",Industry Type: Internet (E-Commerce),Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['Risk Intelligence', 'Risk Analytics', 'Predictive Modeling', 'Cross Functional Coordination', 'Power Bi', 'E-commerce', 'Tableau', 'SQL', 'Anomaly Detection', 'Risk Mitigation', 'Communication Skills', 'Data Analysis', 'Data Visualization', 'Data Warehousing', 'Data Modeling', 'Fraud Detection', 'Python']",2025-06-14 05:44:04
Resource Planning System Analyst,ManipalCigna Health Insurance,2 - 5 years,Not Disclosed,['Hyderabad'],"This role will be responsible for data gathering analysis and requirement visualization that will support driving new Intradiem functionality from conception to delivery. The position will also involve a level of innovative thought and execution to contribute to continued expansion of the software, and ongoing optimization to refine systemic rules to continuously meet the needs of supported businesses.\nThis role requires an understanding of call center concepts and challenges, and the ability to collect, analyze, and interpret data to identify trends that will inform business decisions. The goal is to provide best-in-class strategy and support across multiple product lines to identify the most effective processes, configuration, and user experience.\nSpecific Responsibilities:\nServe as point of contact for businesses utilizing Intradiem software to maintain existing strong relationships.\nDuring new use case or new business deployment, responsible for supporting efforts to identify and gather requirements, provide insight and recommendations, and offer implementation support, all to drive the deployment from conception to delivery. Post-deployment, conduct regular data analysis to validate effectiveness of Intradiem software and identify additional opportunities.\nIdentify business metrics and reporting needs to accurately resolve communicated issues and identify project performance.\nEffectively support application with multiple WFM and ACD providers, and champion design and strategy to streamline functions and processes as providers are consolidated.\nOther duties as assigned.\nQualifications:\nIntermediate to Advanced Excel and Power Point knowledge required.\nClear understanding of workforce management concepts, challenges, and goals.\nStrong execution, strategic-thinking, and influencing skills.\nAbility to work with a high sense of urgency.\nAbility to turn data into a compelling story with a call to action.\nAbout Evernorth Health Services",Industry Type: Insurance,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Automation', 'Data analysis', 'Workforce management', 'Pharmacy', 'Deployment', 'System Analyst', 'Advanced Excel', 'Resource planning', 'Powerpoint', 'WFM']",2025-06-14 05:44:06
Product Operations Analyst,Aptos,1 - 5 years,Not Disclosed,['Bengaluru'],"Making a career change is a big decision. Why consider Aptos\nBecome a part of a team that is passionate about creating and delivering cutting-edge solutions for retailers worldwide. At our company, we re dedicated to supporting your career aspirations and helping you exceed your goals. You ll benefit from industry-leading training, global development opportunities, and the chance to collaborate within a diverse culture across our offices in nine countries. Our inclusive culture reflects our purpose: to make a difference for every colleague, every client, every day .\nAs a leading provider of Unified Commerce solutions for retail, our technology empowers top retail brands by optimizing product management, promotions, merchandising, and store operations. With the global shift toward our cloud-native, microservices architecture, opportunities for career growth have never been more exciting. Today, more than 100,000 retail stores in fashion, grocery, footwear, general merchandise, discount, and sporting goods rely on our solutions to generate nearly $2 trillion in annual revenue.",,,,"['Product management', 'Process automation', 'Data analysis', 'Operations Analyst', 'Analytical', 'Agile', 'JIRA', 'Python', 'Business operations']",2025-06-14 05:44:09
Revenue Operations Analyst,YourStory,1 - 2 years,Not Disclosed,['Bengaluru'],"YourStory is seeking entrepreneurial talent for high-ownership roles in a fast-paced environment, focusing on revenue performance data. As the data custodian, youll collaborate closely with various stakeholders to manage and optimize revenue operations and will own the complete data journey from building data warehouses and ensuring data sanctity to developing robust reporting systems. Your insights will drive business performance, fuel revenue growth, and enhance operational excellence across the organization.\nKey Responsibilities:\nRevenue Forecasting : Analyze revenue trends to develop and maintain accurate revenue forecasts for overall business and specific avenues\nPipeline Management : Monitor pipeline dynamics to deliver actionable insights into deal progression, identify key revenue indicators and conduct audits to ensure data accuracy and enforce platform guideline adherence.\nOperational Efficiency : Streamline operational processes by leveraging automation tools and best practices to reduce manual tasks, enhance accuracy, accelerate revenue cycle execution. ensure seamless integration across systems, providing real-time insights that drive effective decision-making and continuous improvements in revenue operations.\nMarket Research : Conduct market research to monitor industry trends and identify potential growth avenues to ensure our revenue strategy remains innovative and pricing competitive.\nProgram Management Cross-functional collaboration : Ownership of business growth operational efficiency improvement initiatives in collaboration with key teams Sales, Operations. Product, Editorial, Marketing Growth to deliver data-driven/informed insights that optimize revenue operational performance to foster business brand growth.\nWhat are we looking for\nExperience : 1-2 years in data analysis and database querying.\nTechnical Tools/Platforms : Proficiency in Google Sheets or Excel, familiarity with data visualization tools like Looker, Tableau, or PowerBI, SQL for querying databases like BigQuery, AWS etc.\nCommunication : Excellent written and verbal communication skills.\nAnalytical Skills : Strong analytical and logical thinking abilities.\nCRM Experience : Preferred experience with CRM analytics and process implementation.\nImportant Note Before You Apply: (Only Applications Submitted through below mentioned form will be considered)",Industry Type: Internet,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data analysis', 'Operational excellence', 'Sales operations', 'Analytical', 'Market research', 'Forecasting', 'Operations', 'Analytics', 'CRM', 'SQL']",2025-06-14 05:44:11
Sales Analyst,NetApp,5 - 8 years,Not Disclosed,['Bengaluru'],"Job Summary\nPerforms administrative and clerical support tasks for a sales team.\nJob Requirements\nCreating reports for the sales force regarding market conditions, labor costs, expense control, sales results, and team earnings.\nResponding to customer inquiries and providing customer service regarding products and services.",,,,"['data analysis', 'sales forecasting', 'mis reporting', 'team management', 'customer service', 'business development', 'market research', 'sales support', 'sales', 'sales operations', 'marketing', 'advanced excel', 'mis', 'key account management', 'sales coordination', 'sales planning', 'sales analysis']",2025-06-14 05:44:15
Network Reporting Analyst,Systal Technology Solutions,7 - 12 years,Not Disclosed,['Bengaluru'],"The Network Reporting Analyst is responsible for managing, maintaining, and delivering accurate and timely monthly reports covering availability, capacity, and usage metrics for various customers.\n\nThis role plays a critical part in ensuring service performance visibility and operational efficiency through meticulous data validation and reporting. The role carries significant responsibility for on-time delivery, with failure to meet deadlines incurring business and contractual penalties.",,,,"['Excel', 'Power Bi', 'Reporting', 'Network Analysis']",2025-06-14 05:44:18
Senior Data Engineer,Infraveo Technologies,3 - 6 years,Not Disclosed,[],"We are seeking a Senior Data Engineer (PostgreSQL and d SQL syntax) to join our team.\n\nResponsibilties:\nWork closely with other talented database professionals & software engineer. Our vetting process means you can count on your team members to know what they are talking about.\nWork from home or work remotely from anywhere.\nFlexible work schedule: meaning you can work regular hours or whenever you work best\nWork-life balance is essential and highly valued at company. If you choose to work more than 40 hours, youll be compensated for the\nextra work.\nWork on interesting projects solving complex business problems with custom software.\n100 hours per year to focus on your professional development. We invest in your growth.\nProfit sharing bonus means as were successful, youre successful.\nVariable compensation opportunities for being part of on-call team rotation and performing client focused work outside of normal business hours.\nExcellent benefits package including medical insurance, dental, vision, 401(k) matching, FSA, disability, life insurance, and paid parental leave.\nRequirements\nBasic understanding of data modeling design patterns such as 3NF and star-schema.\nData warehouse design experience using medallion architecture and/or snowflake methodologies.\nExperience with Microsoft Fabric, Synapse or Snowflake.\nReporting tools such as Power BI.\nETL tools such as Azure Data Factory.\nPerformance tuning databases and long running queries.\nStored procedure development.\nDatabase migrations and/or database server consolidations, including Azure SQL solutions.\nConfigure Azure SQL databases, elastic pools, and Managed Instances.\nPerform health checks, assessments, and security audits for client databases.\nImplement replication and/or log shipping for disaster recovery or reporting scenarios.\nEvaluate disk I/O and network throughput for SQL performance.\n\nNice to Have Experience:\n\nAdvanced SQL syntax.\nSQL Server installation & configuration in production environments using best practices.\nAvailability Group & failover cluster configuration.\nExposure to MySQL and/or PostgreSQL environments.\nFamiliarity with Red Gate SQL Monitor or similar tools.\nRight-sizing VM for SQL Server.\nDevelop and maintain robust backup, recovery, and maintenance plans.\nHolding Microsoft certification(s) in the Data & AI solutions field are a plus.\nMicrosoft Certified: Fabric Analytics Engineer Associate (DP-600).\nMicrosoft Certified: Fabric Data Engineer Associate (DP-700).\nMicrosoft Certified: Power BI Data Analyst Associate (PL-300).\nMicrosoft Certified: Administering Microsoft Azure SQL Solutions (DP-300).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'Data modeling', 'Postgresql', 'MySQL', 'Database', 'power bi', 'Medical insurance', 'microsoft', 'Warehouse design', 'SQL']",2025-06-14 05:44:20
IND_Senior Analyst-Tax Technology,Lowes Services India Private limited,3 - 5 years,Not Disclosed,['Bengaluru'],"Lowe s Companies, Inc. (NYSE: LOW) is a FORTUNE 50 home improvement company serving approximately 16 million customer transactions a week in the United States. With total fiscal year 2023 sales of more than $86 billion, Lowe s operates over 1,700 home improvement stores and employs approximately 300,000 associates. Based in Bengaluru, Lowe s India develops innovative technology products and solutions and delivers business capabilities to provide the best omnichannel experience for Lowe s customers. Lowe s India employs over 4,200 associates across technology, analytics, merchandising, supply chain, marketing, finance and accounting, product management and shared services. Lowe s India actively supports the communities it serves through programs focused on skill-building, sustainability and safe homes. For more information, visit, www.lowes.co.in .\nJob Summary:\nThe primary purpose of this role is to automate processes for the Point-of-Sale Indirect Tax Team, with the opportunity to support the broader Indirect Tax Team as needed. Using Alteryx, SQL, Python, Vertex (AI), LLM, and PySpark to build artificial intelligence through machine learning . Key responsibilities include:\nDesign and implement ML models using Python to automate and enhance the accuracy of item classification processes\nCreate sophisticated, forward-looking Alteryx solutions to streamline processes and support strategic business objectives\nLeveraging advanced data lake capabilities to drive data-driven decisions and optimize processes\nProactively supporting team initiatives, embracing new challenges, and contributing to the success of projects\nMentor and support team development, providing technical guidance in Python, PySpark, and SQL to elevate team capability and performance.\nRoles & Responsibilities:\nCore Responsibilities:\nSupport Automation of Item Taxability Assignment: Collaborate with the item assignment team to automate and streamline the item taxability process.\nCommunicate effectively within the Tax Business Team, IT Tax Team, and across other functions.\nData Analysis and Issue Resolution: Work with applications to manage large datasets , utilizing tools such as Alteryx, SQL, Python, Vertex (AI), LLM, and PySpark to analyze and resolve issues efficiently .\nAutomate Job Procedures: Perform process analysis to identify opportunities for automation, enhancing overall workflow efficiency.\nDevelop Sophisticated Alteryx Workflows: Build and optimize Alteryx workflows as required to meet business needs.\nIn-Office Availability: Available for in-office work from 2:30 PM to 10:30 PM IST.\nREQUIRED EDUCATION/EXPERIENCE :\nBachelors Degree in Technology or related field; and 3-5 years of experience in Alteryx workflow development, Python, and LLM experience\nAdvanced experience with Alteryx, Python, Machine Learning, Large Language Models, and SQL\n2-4 years experience with process automation\nAdvanced skills in MS office programs (Excel, Word, Access)\nSkill Set Required\nAdvanced experience with Alteryx, Python, Machine Learning, Large Language Models, and SQL\nBalances practical problem-solving with long-term vision. Makes data-driven decisions that align short-term actions with scalable, high-impact outcomes\nAbility to\nThink independently\nWork well autonomously and in a team setting\nBe open to learning new technologies and adapting to rapidly changing tech environments\nBalance multiple projects, deadlines, and responsibilities in a fast-paced environment\nUnderstand and manage emotions to foster strong team dynamics\nBounce back from setbacks and maintain productivity under pressure\nEffectively communicating technical information to both technical and non-technical stakeholders\nApply innovative thinking to design, develop, and improve products or solutions.\nEnsure accuracy and precision in coding, troubleshooting, and testing.\nStay updated on industry trends, tools, and best practices to remain competitive in the field.",Industry Type: Retail,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Supply chain', 'Product management', 'Data analysis', 'Coding', 'Workflow', 'Troubleshooting', 'MS Office', 'Information technology', 'Analytics', 'SQL']",2025-06-14 05:44:22
Senior Azure Data Engineer,Bit Wave Solutions,7 - 12 years,Not Disclosed,[],"Position : Sr Azure Data Engineer\nLocation: Remote\nTime : CET Time\nRole & responsibilities\n\nWe are seeking a highly skilled Senior Data Engineer to join our dynamic team. The ideal candidate will have extensive experience in Microsoft Azure, Fabric Azure SQL, Azure Synapse, Python, and Power BI. Knowledge of Oracle DB and data replication tools will be preferred. This role involves designing, developing, and maintaining robust data pipelines and ensuring efficient data processing and integration across various platforms.\n\nCandidate understands stated needs & requirements of the stakeholders and produce high quality deliverables Monitors own work to ensure delivery within the desired performance standards. Understands the importance of delivery within expected time, budget and quality standards and displays concern in case of deviation. Good communication skills and a team player\n\nDesign and Development: Architect, develop, and maintain scalable data pipelines using Microsoft Fabric and Azure services, including Azure SQL and Azure Synapse.\n\nData Integration: Integrate data from multiple sources, ensuring data consistency, quality, and availability using data replication tools.\nData Management: Manage and optimize databases, ensuring high performance and reliability.\nETL Processes: Develop and maintain ETL processes to transform data into actionable insights.\nData Analysis: Use Python and other tools to analyze data, create reports, and provide insights to support business decisions.\nVisualization: Develop and maintain dashboards and reports in Power BI to visualize complex data sets.\nPerformance Tuning: Optimize database performance and troubleshoot any issues related to data processing and integration\n\nPreferred candidate profile\n\nMinimum 7 years of experience in data engineering or a related field.\nProven experience with Microsoft Azure services, Fabrics including Azure SQL and Azure Synapse.\nStrong proficiency in Python for data analysis and scripting.\nExtensive experience with Power BI for data visualization.\nKnowledge of Oracle DB and experience with data replication tools.\nProficient in SQL and database management.\nExperience with ETL tools and processes.\nStrong understanding of data warehousing concepts and architectures.\nFamiliarity with cloud-based data platforms and services.\nAnalytical Skills: Ability to analyze complex data sets and provide actionable insights.\nProblem-Solving: Strong problem-solving skills and the ability to troubleshoot data-related issues.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Azure Synapse', 'Microsoft Fabric', 'Python', 'Power Bi', 'Powerapps', 'SQL']",2025-06-14 05:44:25
"Senior data engineer - Python, Pyspark, AWS - 5+ years Gurgaon",One of the largest insurance providers.,5 - 10 years,Not Disclosed,['Gurugram'],"Senior data engineer - Python, Pyspark, AWS - 5+ years Gurgaon\n\nSummary: An excellent opportunity for someone having a minimum of five years of experience with expertise in building data pipelines. A person must have experience in Python, Pyspark and AWS.\n\nLocation- Gurgaon (Hybrid)\n\nYour Future Employer- One of the largest insurance providers.\n\nResponsibilities-\nTo design, develop, and maintain large-scale data pipelines that can handle large datasets from multiple sources.\nReal-time data replication and batch processing of data using distributed computing platforms like Spark, Kafka, etc.\nTo optimize the performance of data processing jobs and ensure system scalability and reliability.\nTo collaborate with DevOps teams to manage infrastructure, including cloud environments like AWS.\nTo collaborate with data scientists, analysts, and business stakeholders to develop tools and platforms that enable advanced analytics and reporting.\n\nRequirements-\nHands-on experience with AWS services such as S3, DMS, Lambda, EMR, Glue, Redshift, RDS (Postgres) Athena, Kinesics, etc.\nExpertise in data modeling and knowledge of modern file and table formats.\nProficiency in programming languages such as Python, PySpark, and SQL/PLSQL for implementing data pipelines and ETL processes.\nExperience data architecting or deploying Cloud/Virtualization solutions (Like Data Lake, EDW, Mart ) in the enterprise.\nCloud/hybrid cloud (preferably AWS) solution for data strategy for Data lake, BI and Analytics.\nWhat is in for you-\nA stimulating working environment with equal employment opportunities.\nGrowing of skills while working with industry leaders and top brands.\nA meritocratic culture with great career progression.\n\nReach us- If you feel that you are the right fit for the role please share your updated CV at randhawa.harmeen@crescendogroup.in\n\nDisclaimer- Crescendo Global specializes in Senior to C-level niche recruitment. We are passionate about empowering job seekers and employers with an engaging memorable job search and leadership hiring experience. Crescendo Global does not discriminate on the basis of race, religion, color, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Pipeline', 'AWS', 'Data Ingestion', 'Data Engineering', 'Data Processing']",2025-06-14 05:44:27
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Jaipur'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:29
Digital Operations Analyst,Johnson Controls,3 - 10 years,Not Disclosed,['Pune'],"Digital Operations Analyst\nOur employees are the most important part of our business. Thank you for your interest in applying to new opportunities with us.\nWhat you will do\nThe Digital Operations Analyst is part of our Building Technologies Solutions business at Johnson Controls. We are looking for a person to support Commercial Sales in our digital solutions business with data analytics. This person will create solutions, drive insights and be a part of our business transformation. This is a Pune or Banglore, India based position.",,,,"['Operations Analyst', 'Data analysis', 'SAS', 'Test cases', 'Unit testing', 'Business intelligence', 'Risk management', 'Analytics', 'SQL', 'Python']",2025-06-14 05:44:32
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Noida'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:34
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Chennai'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:36
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Lucknow'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:38
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Surat'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:41
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Kolkata'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:43
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Nagpur'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:45
Senior Data Science Consultant - Optimization Projects,Leading Client,8 - 10 years,Not Disclosed,['Delhi / NCR'],"Role Summary :\n\nWe are seeking a highly skilled Senior Data Science Consultant with 8+ years of experience to lead an internal optimization initiative.\n\nThe ideal candidate should have a strong background in data science, operations research, and mathematical optimization, with a proven track record of applying these skills to solve complex business problems.\n\nThis role requires a blend of technical depth, business acumen, and collaborative communication.\n\nA background in internal efficiency/operations improvement or cost/resource optimization projects is highly desirable.\n\nKey Responsibilities :\n\n- Lead and contribute to internal optimization-focused data science projects from design to deployment.\n\n- Develop and implement mathematical models to optimize resource allocation, process performance, and decision-making.\n\n- Use techniques such as linear programming, mixed-integer programming, heuristic and metaheuristic algorithms.\n\n- Collaborate with business stakeholders to gather requirements and translate them into data science use cases.\n\n- Build robust data pipelines and use statistical and machine learning methods to drive insights.\n\n- Communicate complex technical findings in a clear, concise manner to both technical and non-technical audiences.\n\n- Mentor junior team members and contribute to knowledge sharing and best practices within the team.\n\nRequired Skills And Qualifications :\n\n- Masters or PhD in Data Science, Computer Science, Operations Research, Applied Mathematics, or related fields.\n\n- Minimum 8 years of relevant experience in data science, with a strong focus on optimization.\n\n- Expertise in Python (NumPy, Pandas, SciPy, Scikit-learn), SQL, and optimization libraries such as PuLP, Pyomo, Gurobi, or CPLEX.\n\n- Experience with end-to-end lifecycle of internal optimization projects.\n\n- Strong analytical and problem-solving skills.\n\n- Excellent communication and stakeholder management abilities.\n\nPreferred Qualifications :\n\n- Experience working on internal company projects focused on logistics, resource planning, workforce optimization, or cost reduction.\n\n- Exposure to tools/platforms like Databricks, Azure ML, or AWS SageMaker.\n\n- Familiarity with dashboards and visualization tools like Power BI or Tableau.\n\n- Prior experience in consulting or internal centers of excellence (CoE) is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Operations Research', 'Pandas', 'Numpy', 'Scikit-Learn', 'Python', 'SQL']",2025-06-14 05:44:47
Sr Data Engineer,Algoleap Technologies,10 - 15 years,Not Disclosed,['Hyderabad'],"We are looking for a Senior Data Engineer to lead the design and implementation of scalable data infrastructure and engineering practices. This role will be critical in laying down the architectural foundations for advanced analytics and AI/ML use cases across global business units. Youll work closely with the Data Science Lead, Product Manager, and other cross-functional stakeholders to ensure data systems are robust, secure, and future-ready.\nKey Responsibilities:",,,,"['orchestration', 'Architecture', 'GCP', 'Data modeling', 'Machine learning', 'Data processing', 'Data quality', 'Open source', 'SQL', 'Python']",2025-06-14 05:44:49
