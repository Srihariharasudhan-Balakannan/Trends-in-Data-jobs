title,company,experience,salary,locations,description,industry,department,employment_type,skills,scraped_at
Data Analyst,FedEx,2 - 4 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nCollect, analyze, and interpret complex data sets using Python and SQL to support business objectives.\nCollaborate with stakeholders to understand business needs, formulate analytic solutions, and provide actionable insights.\nDevelop and maintain data models and reports to track key performance indicators (KPIs) and business metrics.\nCreate meaningful data visualizations to communicate findings, trends, and actionable insights to non-technical stakeholders.\nConduct exploratory data analysis and identify patterns, trends, and opportunities for business improvement.\nSupport data quality initiatives, ensuring accuracy and consistency across data sources.\nUtilize statistical and quantitative techniques to support problem-solving and business optimization efforts.\n\n\n\n\nPreferred candidate profile\n\nPython: Proficiency in data manipulation, data analysis libraries (Pandas, NumPy),and data visualization libraries (Matplotlib, Seaborn).\nSQL: Strong command of SQL for data extraction, transformation, and complex queries.\nBusiness Acumen: Ability to understand business context and objectives, aligning analytics with organizational goals.\nQuantitative Aptitude: Strong analytical and problem-solving skills, with a keen attention to detail.\nData Visualization: Basic skills in data visualization to effectively communicate insights.\nStatistical Analysis: Foundational understanding of statistical methods (e.g., regression, hypothesis testing).\nCommunication Skills: Ability to distill complex data insights into clear,actionable recommendations for stakeholders.",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'SQL', 'Python', 'Power Bi', 'Business Insights', 'Tableau', 'Data Analytics']",2025-06-12 14:02:16
Data Analyst (English Required),Peroptyx,0 - 4 years,Not Disclosed,[],"Role & responsibilities\n\nFor thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.As part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.So, whether you are a student looking to earn as you learn, a retiree looking for a new challenge a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\nIdeal Candidate\nFluent in English (Strictly Required)\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\nApply Online Today!\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['Data Analysis', 'English', 'Mapping', 'Data Analytics']",2025-06-12 14:02:18
Client Data Analyst,JPMorgan Chase Bank,0 - 7 years,Not Disclosed,['Hyderabad'],"Take a lead role in acquiring, managing and retaining meaningful relationships that deliver outstanding experience to our customers\nJob Summary\nAs a Client Data Analyst within our client management team, you will engage with clients and assist the client-facing teams to ensure all client KYC records are compliant with regulatory standards. You will take ownership to execute end-to-end operational activities needed through the periodic renewal process of all clients. You will also own the accuracy and sanctity of information with drafting and gathering of client documents and verification of client data via publicly available and internal sources at a client level prior to final review by a KYC Quality Reviewer and the client-facing team.\nJob Responsibilities\nManage and drive KYC (Renewal/New Business/Ad hoc) book of work and the process end to end.\nCollect and verify confidential client data via publicly available and internal sources to ensure compliance with regulatory requirements for US, APAC, and EU local due diligence.\nExpose yourself to renewal work in an international KYC banking environment.\nWork on records renewals end to end - i. e. , outreach and sourcing, record enrichment, follow-ups with support departments and clients.\nUnderstand the firm s KYC requirements when completing documentation inclusive of Customer Identification Program (CIP), Enhanced Due Diligence (EDD), Local Due Diligence (LDD), Specialized Due Diligence (SpDD), and Product Due Diligence requirements (PDD).\nGain knowledge of multiple client types (i. e. , Corporates, Non-Banking Financial Institutions, Non-Operating/Asset Holding Companies, Governments, Organizations, Publicly Traded Companies, Small and Large Privately Held Operating Companies).\nUnderstand product ranges from Markets - Derivatives, Equities, Funds, FX, Trusts, Treasury Services, etc. , and other investment banking products.\nMaintain clear and professional communication with clients to address any KYC-related queries or concerns.\nSupport the front-line manager with day-to-day operations, creating an effective and efficient team through continuous communication, timely feedback, and appropriate supervisory practices.\nWork closely with the clients and KYC Relationship Officer as required, to obtain all necessary supporting evidence to fulfill KYC.\nRequired Qualifications, Skills, and Capabilities\nHave 8+ years of experience in KYC / AML client-facing / middle office role managing Investment banking.\nLearn quickly and adapt to the dynamic KYC process.\nDemonstrate strong research, analytical, and comprehension skills with the ability to analyze large amounts of data.\nExhibit excellent communication skills - both verbal and written.\nComprehend and analyze information received from the client.\nPromptly escalate and resolve issues, taking end-to-end ownership of records and their dependencies.\nProactively manage and drive forward your own career, identifying personal and team training needs for development.\nPreferred Qualifications, Skills, and Capabilities\nBe detail-oriented and possess analytical skills.\nDemonstrate a strong sense of ownership and responsibility, self-reliance, and willingness to ""own"" problems and creatively find solutions.\nDevelop an environment of continuous focus on quantifiable productivity and quality.",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Analytical skills', 'Training', 'Due diligence', 'Focus', 'Data Analyst', 'Investment banking', 'Management', 'banking products', 'Operations', 'Client management']",2025-06-12 14:02:21
Client Data Analyst,JPMorgan Chase Bank,0 - 7 years,Not Disclosed,['Bengaluru'],"Take a lead role in acquiring, managing and retaining meaningful relationships that deliver outstanding experience to our customers\nJob Summary\nAs a Client Data Analyst within our client management team, you will engage with clients and assist the client-facing teams to ensure all client KYC records are compliant with regulatory standards. You will take ownership to execute end-to-end operational activities needed through the periodic renewal process of all clients. You will also own the accuracy and sanctity of information with drafting and gathering of client documents and verification of client data via publicly available and internal sources at a client level prior to final review by a KYC Quality Reviewer and the client-facing team.\nJob Responsibilities\nManage and drive KYC (Renewal/New Business/Ad hoc) book of work and the process end to end.\nCollect and verify confidential client data via publicly available and internal sources to ensure compliance with regulatory requirements for US, APAC, and EU local due diligence.\nExpose yourself to renewal work in an international KYC banking environment.\nWork on records renewals end to end - i. e. , outreach and sourcing, record enrichment, follow-ups with support departments and clients.\nUnderstand the firm s KYC requirements when completing documentation inclusive of Customer Identification Program (CIP), Enhanced Due Diligence (EDD), Local Due Diligence (LDD), Specialized Due Diligence (SpDD), and Product Due Diligence requirements (PDD).\nGain knowledge of multiple client types (i. e. , Corporates, Non-Banking Financial Institutions, Non-Operating/Asset Holding Companies, Governments, Organizations, Publicly Traded Companies, Small and Large Privately Held Operating Companies).\nUnderstand product ranges from Markets - Derivatives, Equities, Funds, FX, Trusts, Treasury Services, etc. , and other investment banking products.\nMaintain clear and professional communication with clients to address any KYC-related queries or concerns.\nSupport the front-line manager with day-to-day operations, creating an effective and efficient team through continuous communication, timely feedback, and appropriate supervisory practices.\nWork closely with the clients and KYC Relationship Officer as required, to obtain all necessary supporting evidence to fulfill KYC.\nRequired Qualifications, Skills, and Capabilities\nHave 8+ years of experience in KYC / AML client-facing / middle office role managing Investment banking.\nLearn quickly and adapt to the dynamic KYC process.\nDemonstrate strong research, analytical, and comprehension skills with the ability to analyze large amounts of data.\nExhibit excellent communication skills - both verbal and written.\nComprehend and analyze information received from the client.\nPromptly escalate and resolve issues, taking end-to-end ownership of records and their dependencies.\nProactively manage and drive forward your own career, identifying personal and team training needs for development.\nPreferred Qualifications, Skills, and Capabilities\nBe detail-oriented and possess analytical skills.\nDemonstrate a strong sense of ownership and responsibility, self-reliance, and willingness to ""own"" problems and creatively find solutions.\nDevelop an environment of continuous focus on quantifiable productivity and quality.",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Analytical skills', 'Training', 'Due diligence', 'Focus', 'Data Analyst', 'Investment banking', 'Management', 'banking products', 'Operations', 'Client management']",2025-06-12 14:02:23
Data Analyst,PwC India,4 - 8 years,Not Disclosed,"['Bengaluru', 'Mumbai (All Areas)']","If Interested, please apply in the given link : https://forms.office.com/r/h5Qzqnb1Kr\n\nJob Title: Data Analyst (4 - 8 Years Experience)\nLocation: Bengaluru/ Mumbai\nType: Full-Time\nAbout the Role:\nWe are on the lookout for a sharp, self-driven Data Analyst with a strong command of SQL, Python, and relational databases. If solving complex data problems, building efficient data pipelines, and collaborating across teams excites you - youll thrive in this role.",,,,"['Python', 'SQL', 'Data analyst']",2025-06-12 14:02:25
Data Analyst - L3,Wipro,3 - 5 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of this role is to interpret data and turn into information (reports, dashboards, interactive visualizations etc) which can offer ways to improve a business, thus affecting business decisions.\nDo\n1. Managing the technical scope of the project in line with the requirements at all stages\na. Gather information from various sources (data warehouses, database, data integration and modelling) and interpret patterns and trends\nb. Develop record management process and policies\nc. Build and maintain relationships at all levels within the client base and understand their requirements.\nd. Providing sales data, proposals, data insights and account reviews to the client base\ne. Identify areas to increase efficiency and automation of processes\nf. Set up and maintain automated data processes\ng. Identify, evaluate and implement external services and tools to support data validation and cleansing.\nh. Produce and track key performance indicators\n2. Analyze the data sets and provide adequate information\na. Liaise with internal and external clients to fully understand data content\nb. Design and carry out surveys and analyze survey data as per the customer requirement\nc. Analyze and interpret complex data sets relating to customers business and prepare reports for internal and external audiences using business analytics reporting tools\nd. Create data dashboards, graphs and visualization to showcase business performance and also provide sector and competitor benchmarking\ne. Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool\nf. Develop predictive models and share insights with the clients as per their requirement\n\nDeliver\n\nNo Performance Parameter Measure\n1. Analyses data sets and provide relevant information to the clientNo. Of automation done, On-Time Delivery, CSAT score, Zero customer escalation, data accuracy\n\nMandatory Skills: Tableau.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Tableau', 'data warehouses', 'data integration', 'Data modelling']",2025-06-12 14:02:28
Data Analyst - L3,Wipro,4 - 8 years,Not Disclosed,['Bengaluru'],"? \n\nDo\n\n1. Managing the technical scope of the project in line with the requirements at all stages\n\na. Gather information from various sources (data warehouses, database, data integration and modelling) and interpret patterns and trends\n\nb. Develop record management process and policies\n\nc. Build and maintain relationships at all levels within the client base and understand their requirements.\n\nd. Providing sales data, proposals, data insights and account reviews to the client base\n\ne. Identify areas to increase efficiency and automation of processes\n\nf. Set up and maintain automated data processes\n\ng. Identify, evaluate and implement external services and tools to support data validation and cleansing.\n\nh. Produce and track key performance indicators\n\n2. Analyze the data sets and provide adequate information\n\na. Liaise with internal and external clients to fully understand data content\n\nb. Design and carry out surveys and analyze survey data as per the customer requirement\n\nc. Analyze and interpret complex data sets relating to customer’s business and prepare reports for internal and external audiences using business analytics reporting tools\n\nd. Create data dashboards, graphs and visualization to showcase business performance and also provide sector and competitor benchmarking\n\ne. Mine and analyze large datasets, draw valid inferences and present them successfully to management using a reporting tool\n\nf. Develop predictive models and share insights with the clients as per their requirement",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'data mining', 'data warehousing', 'business analytics', 'data integration', 'python', 'data analytics', 'data validation', 'business analysis', 'dbms', 'dashboards', 'cleansing', 'business intelligence', 'sales', 'sql', 'analytics reporting', 'tableau', 'reporting tools']",2025-06-12 14:02:30
Data Analyst,Wiley,0 - 3 years,Not Disclosed,['Noida'],"Job Description:\nData Analyst\nLocation:\nNoida, Uttar Pradesh, IND\nOur mission is to unlock human potential. We welcome you for who you are, the background you bring, and we embrace individuals who get excited about learning. Bring your experiences, your perspectives, and your passion; it s in our differences that we empower the way the world learns.\nAbout the Role:\n\n\n\n\n\n\n\n\n\n\n#LI",,,,"['Product management', 'Publishing', 'Business reporting', 'Analytical', 'Data processing', 'Data Analyst', 'data visualization', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:02:32
Data Analyst,Insuredmine Infotech India PVT LTD,1 - 4 years,3-5 Lacs P.A.,['Bengaluru( HSR Layout )'],"We are seeking a skilled Data Analyst with a preference for candidates holding any degree. The ideal candidate will possess exceptional analytical capabilities, particularly in sales analysis, financial analysis, and other business operations data analysis. Proficiency in Excel and data presentation at an advanced level is a must for this role. The incumbent will be responsible for extracting, analyzing, and interpreting data to provide actionable insights that drive strategic decision-making across various business functions.\n\nKey Responsibilities:\nConduct in-depth sales analysis to identify trends, opportunities, and areas for improvement.\nPerform financial analysis to support budgeting, forecasting, and financial planning processes.\nUtilize advanced Excel functions to manipulate and analyze large datasets efficiently.\nDevelop and maintain dashboards, reports, and data visualizations to communicate key findings effectively.\nCollaborate with cross-functional teams to understand business requirements and provide data-driven solutions.\nConduct ad-hoc analysis to address specific business questions and challenges.\nIdentify opportunities for process optimization and automation to streamline\ndata analysis workflows.\nStay updated with industry trends and best practices in data analysis and\nbusiness intelligence.\nQualifications:\nBachelor's degree in Business Administration, Statistics, Economics, Computer Science, or a related field. MBA preferred.\nProven experience (2 years) in a data analysis role, preferably within sales, finance, or business operations.\nAdvanced proficiency in Microsoft Excel, including complex formulas, pivot tables, and data visualization techniques.\nStrong analytical and problem-solving skills, with the ability to translate data into actionable insights.\nExperience working with BI tools (e.g., Tableau, Power BI) is a plus.\nExcellent communication skills with the ability to present findings and\nrecommendations to stakeholders at all levels.\nAbility to work independently and manage multiple projects simultaneously.\nAttention to detail and a commitment to delivering high-quality, accurate results.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'Data Reporting', 'Data Visualization']",2025-06-12 14:02:34
Data Analyst,Primary Healthtech,1 - 5 years,2.5-4.5 Lacs P.A.,['Noida'],"Roles and Responsibilities\nCollect data from various sources, clean it, and analyze it using statistical tools.\nCreate reports based on analysis findings to present insights to stakeholders.\nDevelop dashboards and visualizations to effectively communicate results.\nManage databases by designing schema, writing queries, and optimizing performance.\nEnsure accuracy of data through quality control measures.\nDesired Candidate Profile\n1-5 years of experience in Data Analysis or related field (Data Analytics).\nB.Tech/B.E. degree in Any Specialization.\nProficiency in SQL programming language with knowledge of database management systems like MySQL or PostgreSQL.\nStrong understanding of statistics, data interpretation, and data visualization techniques.",Industry Type: Medical Devices & Equipment,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Interpretation', 'Data Analysis', 'Data Analytics', 'Data Management', 'Data Visualization', 'Data Reporting']",2025-06-12 14:02:37
Data Analyst,HARMAN,3 - 5 years,Not Disclosed,['Bengaluru'],"Introduction: Digital Transformation Solutions (DTS)\n.\nCombine the physical and digital, making technology a more dynamic force to solve challenges and serve humanity s needs\nWork at the convergence of cross channel UX, cloud, insightful data, IoT and mobility\nEmpower companies to create new digital business models, enter new markets, and improve customer experiences\nIntroduction: Corporate",,,,"['Supply chain', 'Data analysis', 'Change management', 'DTS', 'Manager Technology', 'Agile', 'Healthcare', 'Data analytics', 'Secondary research', 'SQL']",2025-06-12 14:02:39
Data Analyst,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Bengaluru'],"Req ID: 327898\n\nWe are currently seeking a Data Analyst to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesKey Responsibilities:\nConduct in-depth revenue analysis to identify trends and opportunities for growth.\nPerform P&L attribution, analyzing variances and providing detailed insights to stakeholders.\nExecute Independent Price Verification (IPV) processes to ensure the accuracy and consistency of financial data.\nLead data reconciliation efforts by identifying and resolving discrepancies in financial datasets.\nCollaborate with finance, operations, and IT teams to develop efficient processes and reporting mechanisms.\nDocument business requirements, workflows, and processes, translating them into technical specifications where necessary.\nDevelop and maintain financial models to support decision-making processes.\nMonitor financial performance and prepare detailed reports for senior management.\n\nMinimum Skills RequiredQualifications:\nBachelor's degree in Finance, Economics, Business, or a related field (Master""™s preferred).\nProven experience as a Business Analyst in the finance domain, with expertise in revenue, P&L attribution, IPV, and data reconciliation.\nStrong knowledge of financial principles, data analysis, and reporting tools.\nProficiency in data analytics platforms such as Excel, SQL, or Tableau.\nExcellent problem-solving skills and attention to detail.\nStrong communication and interpersonal skills for effective stakeholder management.\nAbility to work in a fast-paced, deadline-driven environment.\nPreferred\n\nSkills:\n\nCertification in Business Analysis (e.g., CBAP, CCBA) or related field is a plus.\nFamiliarity with financial systems and accounting software.\nExperience in Agile or Scrum methodologies.""",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data analysis', 'data reconciliation', 'stakeholder management', 'reporting tools', 'cbap', 'business analysis', 'variance analysis', 'ipv', 'sql', 'business requirement analysis', 'revenue', 'tableau', 'workflow analysis', 'scrum', 'technical specifications', 'agile']",2025-06-12 14:02:41
Data Analyst,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Bengaluru'],"Req ID: 327858\n\nWe are currently seeking a Data Analyst to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nJob DutiesKey ResponsibilitiesConduct in-depth revenue analysis to identify trends and opportunities for growth. Perform P&L attribution, analyzing variances and providing detailed insights to stakeholders. Execute Independent Price Verification (IPV) processes to ensure the accuracy and consistency of financial data. Lead data reconciliation efforts by identifying and resolving discrepancies in financial datasets. Collaborate with finance, operations, and IT teams to develop efficient processes and reporting mechanisms. Document business requirements, workflows, and processes, translating them into technical specifications where necessary. Develop and maintain financial models to support decision-making processes. Monitor financial performance and prepare detailed reports for senior management. Minimum Skills RequiredQualificationsBachelor's degree in Finance, Economics, Business, or a related field (Master""™s preferred). Proven experience as a Business Analyst in the finance domain, with expertise in revenue, P&L attribution, IPV, and data reconciliation. Strong knowledge of financial principles, data analysis, and reporting tools. Proficiency in data analytics platforms such as Excel, SQL, or Tableau. Excellent problem-solving skills and attention to detail. Strong communication and interpersonal skills for effective stakeholder management. Ability to work in a fast-paced, deadline-driven environment. Preferred\n\nSkills:\nCertification in Business Analysis (e.g., CBAP, CCBA) or related field is a plus. Familiarity with financial systems and accounting software. Experience in Agile or Scrum methodologies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analytics', 'data analysis', 'data reconciliation', 'stakeholder management', 'reporting tools', 'cbap', 'revenue analysis', 'business analysis', 'ipv', 'sql', 'business requirement analysis', 'revenue', 'tableau', 'workflow analysis', 'scrum', 'technical specifications', 'agile']",2025-06-12 14:02:44
Data Analyst,Brunel,4 - 8 years,Not Disclosed,['Bengaluru'],"Position: Data Analyst.\nContract: On Contract Role.\nDesign and develop dashboards and automation tools by programing in MS Access, MS Excel, and Tableau/Power BI dashboards for solutions in conjunction with multiple data sources such as SQL Database, SAP Hana, SharePoint etc.\nMaintain all supported solutions as defined by requestors located globally (AP, EU and NA zones).\nWork effectively with the business with regards to fixing breaks in the process and support changes.\nDemonstrate initiatives to identify process efficiencies.\nUnderstand business process changes and impact on the tools design.\nEscalate any design issues or conflicting priorities to ensure timely product delivery.\nWe are recruiting a Data Analyst to join one of our leading multinational clients and their expanding team. This position is based in Bangalore and offers an excellent opportunity for experienced proposal management professionals in the Conventional Energy sector.\nShould possess strong verbal communication and writing skills in English.\nKeen attention to details, strong analytical skills and problem-solving skills.\nProficient in MS Excel and Sharepoint.\nGood technical understanding of database/application design, development cycles and structural principles.\nAdvanced programming skills in Microsoft products: Access, advance Excel: (powerpivot, power query, power view), VBA Programming.\nGood technical knowledge or able to learn on Data Analytics platforms and auto process workflow: ServiceNow, PowerBI, Tableau.\nGood technical knowledge or able to learn on SQL Database server, Stored Procedures.",Industry Type: Power,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'tableau', 'Excel', 'MS Access', 'SQL database', 'Workflow', 'Data Analyst', 'Data analytics', 'Stored procedures', 'microsoft']",2025-06-12 14:02:46
"Data Analyst-Mapping, Modelling",Capco,1 - 8 years,Not Disclosed,['Bengaluru'],"Data warehousing migration programs that involve cross geography and multi-functional delivery\nTo align project timeline to ensure project success delivery.\nProvide support to Data Analysis, Mapping and Profiling\nPerform data requirement gathering, analysis and documentation.\nMapping of data attributes from different source systems to the target data models and ensuring the same business rules are followed\ninterpreting use case requirement and design of target data model/ data mart\nProfiling of data attributes to assess data quality that affects referential integrity and provide remediation recommendations.\nEnsures that data use is complies to the data architecture principles including golden sources and standard reference data.\nData modelling for better data integration within the data warehouse platform\nKey responsibilities are:\nTo work together with squad members for success delivery of projects that includes managing different stakeholders like business, other technology teams and internal development teams; Ensuring delivery is align to the timeline for each milestone.\nTo work closely with various stakeholders in analyzing the user requirements, profiling data, and finalizing the requirements for delivery (Do the right thing).\nTransforming data requirements into data models through design and modelling aligning to the data warehousing standards and processes.\nCreate data mapping templates for Data Model mapping.\nProfile data to assess data quality, suitability, and cardinality.\nSupport data store s inbound and/or outbound development activities - provide guidance and clarification to development team on the mapping developed.\nResponsible to provide direction on solution from a standard product / architecture perspective Participate in key decision-making discussions liaising with business stakeholders\nPerform SIT and support UAT.\nResponsible to manage the change request effectively and efficiently during the project delivery with all agreed controls\nAlign with the bank process and standards and ensure there are no deviations Deliver Functional documentation to the development team while collating the requirements from various stakeholders To ensure alignment to Data Quality Management Framework that includes Data Management through lineage documentation, data control to ensure data quality securities.",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Outbound', 'Data analysis', 'Data management', 'Management consulting', 'Data Analyst', 'Data quality', 'data mapping', 'Project delivery', 'Financial services', 'Data architecture']",2025-06-12 14:02:49
Data Analyst,Capgemini,4 - 6 years,Not Disclosed,['Bengaluru'],"Overview\nWe are seeking a highly motivated Data Analyst with strong technical and analytical skills to join our ADAS (Advanced Driver Assistance Systems) team. This role involves working with large-scale data from vehicle systems to drive insights, support data science initiatives, and contribute to the development of safer and smarter automotive technologies.\n\nResponsibilities:\nPerform data cleansing, aggregation, and analysis on large, complex datasets related to ADAS components and systems.\nBuild, maintain, and update dashboards and data visualizations to communicate insights effectively (Power BI preferred).\nDevelop and optimize data pipelines and ETL processes.\nCreate and maintain technical documentation, including data catalogs and process documentation.\nCollaborate with cross-functional teams including data scientists, software engineers, and system engineers.\nContribute actively to the internal data science community by sharing knowledge, tools, and best practices.\nWork independently on assigned projects, managing priorities and delivering results in a dynamic, unstructured environment.Required Qualifications:\nBachelors degree or higher in Computer Science, Data Science, or a related field.\nMinimum 3 years of experience in the IT industry, with at least 2 years in data analytics or data engineering roles.\nProficient in Python or Pyspark with solid software development fundamentals.\nStrong experience with SQL and relational databases.\nHands-on experience with data science, data engineering, or machine learning techniques.\nKnowledge of data modeling, data warehousing concepts, and ETL processes.\nFamiliarity with data visualization tools (Power BI preferred).\nBasic understanding of cloud platforms such as Azure or AWS.\nFundamental knowledge of ADAS functionalities is a plus.\nStrong problem-solving skills, self-driven attitude, and the ability to manage projects independently.Preferred Skills:\nExperience in automotive data or working with sensor data (e.g., radar, lidar, cameras).\nFamiliarity with agile development methodologies.\nUnderstanding of big data tools and platforms such as Databricks or Spark. Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.- Grade SpecificIs fully competent in it's own area and has a deep understanding of related programming concepts software design and software development principles. Works autonomously with minimal supervision. Able to act as a key contributor in a complex environment, lead the activities of a team for software design and software development. Acts proactively to understand internal/external client needs and offers advice even when not asked. Able to assess and adapt to project issues, formulate innovative solutions, work under pressure and drive team to succeed against its technical and commercial goals. Aware of profitability needs and may manage costs for specific project/work area. Explains difficult concepts to a variety of audiences to ensure meaning is understood. Motivates other team members and creates informal networks with key contacts outside own area.Skills (competencies)Verbal Communication",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'software development', 'pyspark', 'relational databases', 'sql', 'data analytics', 'software design', 'data warehousing', 'microsoft azure', 'power bi', 'machine learning', 'data engineering', 'data bricks', 'data science', 'data modeling', 'spark', 'adas', 'agile', 'etl', 'aws', 'big data']",2025-06-12 14:02:52
Data Analyst,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Pune'],"Req ID: 324676\n\nWe are currently seeking a Data Analyst to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nKey Responsibilities:\n\nExtract, transform, and load (ETL) data from various sources, ensuring data quality, integrity, and accuracy.\n\nPerform data cleansing, validation, and preprocessing to prepare structured and unstructured data for analysis.\n\nDevelop and execute queries, scripts, and data manipulation tasks using SQL, Python, or other relevant tools.\n\nAnalyze large datasets to identify trends, patterns, and correlations, drawing meaningful conclusions that inform business decisions.\n\nCreate clear and concise data visualizations, dashboards, and reports to communicate findings effectively to stakeholders.\n\nCollaborate with clients and cross-functional teams to gather and understand data requirements, translating them into actionable insights.\n\nWork closely with other departments to support their data needs.\n\nCollaborate with Data Scientists and other analysts to support predictive modeling, machine learning, and statistical analysis.\n\nContinuously monitor data quality and proactively identify anomalies or discrepancies, recommending corrective actions.\n\nStay up-to-date with industry trends, emerging technologies, and best practices to enhance analytical techniques.\n\nAssist in the identification and implementation of process improvements to streamline data workflows and analysis.\n\nBasic Qualifications:\n\n3 + years of proficiency in data analysis tools such as [Tools - e.g., Excel, SQL, R, Python].\n\n3+ years of experience supporting Software Engineering, Data Engineering, or Data Analytics projects.\n\n2+ years of experience leading a team supporting data related projects to develop end-to-end technical solutions.\n\nUndergraduate or Graduate degree preferred\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nStrong proficiency in data analysis tools such as Python, SQL, Talend (any ETL).\n\nExperience with data visualization tools like PowerBI.\n\nExperience with cloud data platforms .\n\nFamiliarity with ETL (Extract, Transform, Load) processes and tools.\n\nKnowledge of machine learning techniques and tools.\n\nExperience in a specific industry (e.g., financial services, healthcare, manufacturing) can be a plus.\n\nUnderstanding of data governance and data privacy regulations.\n\nAbility to query and manipulate databases and data warehouses.\n\nExcellent analytical and problem-solving skills.\n\nStrong communication skills with the ability to explain complex data insights to non-technical stakeholders.\n\nDetail-oriented with a commitment to accuracy.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'data analytics', 'data engineering', 'analysis tools', 'software engineering', 'python', 'data manipulation', 'talend', 'power bi', 'data warehousing', 'machine learning', 'dashboards', 'sql', 'data cleansing', 'data quality', 'r', 'predictive modeling', 'data visualization', 'etl']",2025-06-12 14:02:54
Data Analyst -Python,Sopra Steria,3 - 5 years,Not Disclosed,['Chennai'],"Experience working in large Software Development Teams\nKnowledge and experience in Agile Delivery mechanisms \nWork with business stakeholders, SCRUM masters, Designers and testers in SCRUM team.\nProficient in English language with ability to lead stakeholder conversations.\nExperience in generating insights through data and articulating stories addressing business problems.\nTotal Experience Expected: 6-8 years\n",,,,"['data mining', 'vlookup', 'sql', 'analytics', 'data science', 'advanced excel', 'data visualization', 'technical skills', 'python', 'macros', 'data analysis', 'data analytics', 'sas', 'insights', 'predictive analytics', 'business analysis', 'machine learning', 'excel', 'tableau', 'r', 'vba', 'predictive modeling', 'scrum', 'agile', 'statistics']",2025-06-12 14:02:57
Data Analyst (8+ years of experience),Western Digital,0 - 7 years,Not Disclosed,['Bengaluru'],"ESSENTIAL DUTIES AND RESPONSIBILITIES\nGathering data from diverse sources, including databases, APIs, and web scraping.\nPossessing deep knowledge of data analytics principles, tools, and technologies.\nHandling missing values, correcting errors, and ensuring data consistency, data quality, and optimizing data performance.\nCreate and maintain data models that structure and organize data within a domain, ensuring clarity and consistency.\nCreate data products, designed to solve specific business problems within a domain.\nPerforming statistical analysis and modeling to identify trends, patterns, and relationships in the data.\nPreparing reports, presentations, and dashboards to communicate insights and findings.\nUsing data to identify and solve business problems, improve processes, and make data-driven decisions.\nCollaborating with cross-functional teams including, Data Engineers, Data scientists, Business Analysts, Solution Architects, IT & Business teams.\nDocument and maintain end to end data flows, Data Lineage, Data Catalog for various data marts.\nBe a liaison between solution architects, BSA s and data engineers to ensure compliance to standards of Data integrations, data management and review the data solutions.\nStay updated with the latest industry trends and best practices, sharing knowledge and encourage team to continuously improve their skill s",Industry Type: Electronic Components / Semiconductors,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Data analysis', 'ERP', 'Data management', 'Data modeling', 'Data quality', 'Data mining', 'Business intelligence', 'CRM', 'SQL']",2025-06-12 14:02:59
Data Analyst III,Sadup Soft,5 - 8 years,Not Disclosed,['Bengaluru'],"- Minimum of 5 years of experience in data analysis with a strong SQL background.\n\n- Solid experience in creating and extracting metrics, and writing complex SQL scripts.\n\n- Hands-on experience with Tableau, Looker, or any equivalent data visualization tools.\n\n- Strong skills in SQL and Excel, with the ability to quickly learn other analytic tools.\n\n- Knowledge of Python and ML algorithms is a plus.\n\nResponsibilities :\n\n- Perform detailed data analysis and validation to ensure data integrity and accuracy.\n\n- Extract and create meaningful metrics to support business decisions\n\n- Design, develop, and maintain interactive dashboards using Tableau, Looker, or equivalent tools.\n\n- Translate complex data into visually appealing and actionable insights.\n\n- Document queries, reports, and analytical processes clearly and accurately.\n\n- Create detailed reports and presentations to communicate findings to stakeholders.\n\n- Work closely with cross-functional teams to understand data requirements and provide analytical support.\n\n- Communicate findings effectively and provide actionable recommendations.\n\n- Utilize SQL and Excel extensively for data analysis and reporting.\n\n- Apply Python and ML algorithms as needed for advanced analytics (preferred but not mandatory)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Data Integrity', 'Data Analyst', 'Data Visualization Tools', 'Tableau', 'Data Analytics', 'Looker']",2025-06-12 14:03:01
"Data Analytics Fresher , Data Analyst Fresher",Ablycon Global Angalore,0 - 1 years,4.25-6.5 Lacs P.A.,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","NOTE- Please do not call. Apply through Naukri or email your resume at ankit@ablyconglobal.com. or whatsapp on 9821833955 - Don't CALL Please .\n\n\nJob Title: Data Analytics Fresher\nEmployment Type: Full-Time\nExperience: 0 - 1 Year\nQualification- ANY UG , ANY PG\n\n\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented individual to join our Data Analytics team as a Data Analyst Fresher. This position offers a launchpad into the world of data analytics. Youll work on structured and unstructured datasets, assist in building dashboards and models, and get practical exposure to tools like SQL, Python, and BI platforms. Ideal for someone with a strong analytical foundation and a hunger to grow into a full-stack data professional.\n\nKey Responsibilities:\n\nCollect, organize, and analyze large datasets from various internal and external sources.\nAssist in preparing dashboards, reports, and visualizations to present insights and findings.\nSupport the team in identifying trends, anomalies, and patterns that impact business performance.\nWork with different departments (marketing, sales, operations, etc.) to understand data requirements.\nPerform exploratory data analysis (EDA) to help refine business strategies.\nMaintain and ensure data integrity and consistency across databases and reporting tools.\nSupport the automation of repetitive reporting processes using scripting or BI tools.\n\nRequired Skills & Qualifications:\n\nStrong analytical and problem-solving skills.\nProficiency in Excel and a basic understanding of SQL.\nFamiliarity with data visualization tools (e.g., Tableau, Power BI) is a plus.\nKnowledge of programming languages such as Python or R is an advantage.\nStrong communication skills to explain technical results to non-technical audiences.\nAttention to detail and a strong sense of responsibility.\nEagerness to learn new tools, technologies, and business domains.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Data Analytics', 'Business Analytics', 'Power Bi', 'Artificial Intelligence', 'Data Interpretation', 'Data Management', 'Data Extraction', 'Tableau', 'Machine Learning', 'Statistics', 'data analyst', 'SQL', 'Data Science', 'Excel', 'MySQL', 'Data Analysis', 'Data Visualization', 'Data Processing', 'Python']",2025-06-12 14:03:03
"Data Analyst, Staff",Qualcomm,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Miscellaneous Group, Miscellaneous Group > Data Analyst\n \n\nQualcomm Overview: \nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.\n\nGeneral Summary:\n\nAbout the Team\n\nQualcomm's People Analytics team plays a crucial role in transforming data into strategic workforce insights that drive HR and business decisions. As part of this lean but high-impact team, you will have the opportunity to analyze workforce trends, ensure data accuracy, and collaborate with key stakeholders to enhance our data ecosystem. This role is ideal for a generalist who thrives in a fast-paced, evolving environment""”someone who can independently conduct data analyses, communicate insights effectively, and work cross-functionally to enhance our People Analytics infrastructure.\n\nWhy Join Us\n\n\nEnd-to-End ImpactWork on the full analytics cycle""”from data extraction to insight generation""”driving meaningful HR and business decisions.\n\n\nCollaboration at ScalePartner with HR leaders, IT, and other analysts to ensure seamless data integration and analytics excellence.\n\n\nData-Driven CultureBe a key player in refining our data lake, ensuring data integrity, and influencing data governance efforts.\n\n\nProfessional GrowthGain exposure to multiple areas of people analytics, including analytics, storytelling, and stakeholder engagement.\n\n\nKey Responsibilities\n\n\nPeople Analytics & Insights\nAnalyze HR and workforce data to identify trends, generate insights, and provide recommendations to business and HR leaders.\nDevelop thoughtful insights to support ongoing HR and business decision-making.\nPresent findings in a clear and compelling way to stakeholders at various levels, including senior leadership.\n\n\nData Quality & Governance\nEnsure accuracy, consistency, and completeness of data when pulling from the data lake and other sources.\nIdentify and troubleshoot data inconsistencies, collaborating with IT and other teams to resolve issues.\nDocument and maintain data definitions, sources, and reporting standards to drive consistency across analytics initiatives.\n\n\nCollaboration & Stakeholder Management\nWork closely with other analysts on the team to align methodologies, share best practices, and enhance analytical capabilities.\nAct as a bridge between People Analytics, HR, and IT teams to define and communicate data requirements.\nPartner with IT and data engineering teams to improve data infrastructure and expand available datasets.\n\n\nQualifications\n\nRequired4-7 years experience in a People Analytics focused role\n\n\nAnalytical & Technical Skills\nStrong ability to analyze, interpret, and visualize HR and workforce data to drive insights.\nExperience working with large datasets and ensuring data integrity.\nProficiency in Excel and at least one data visualization tool (e.g., Tableau, Power BI).\n\n\nCommunication & Stakeholder Management\nAbility to communicate data insights effectively to both technical and non-technical audiences.\nStrong documentation skills to define and communicate data requirements clearly.\nExperience collaborating with cross-functional teams, including HR, IT, and business stakeholders.\n\n\nPreferred:\n\n\nTechnical Proficiency\nExperience with SQL, Python, or R for data manipulation and analysis.\nFamiliarity with HR systems (e.g., Workday) and cloud-based data platforms.\n\n\nPeople Analytics Expertise\nPrior experience in HR analytics, workforce planning, or related fields.\nUnderstanding of key HR metrics and workforce trends (e.g., turnover, engagement, diversity analytics).\n\n\nAdditional Information\nThis is an office-based position (4 days a week onsite) with possible locations that may include India and Mexico",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'people analytics', 'documentation', 'tableau', 'data integration tools', 'hiring', 'data warehousing', 'data architecture', 'sourcing', 'jquery', 'staffing', 'plsql', 'oracle 10g', 'java', 'etl tool', 'html', 'etl', 'mongodb', 'python', 'oracle', 'power bi', 'hrsd', 'r', 'node.js', 'hr analytics', 'angularjs']",2025-06-12 14:03:06
Analyst - Data Analytics,AMERICAN EXPRESS,0 - 4 years,Not Disclosed,['Gurugram'],The American Express Enterprise Digital Experimentation & Analytics (EDEA) leads the Enterprise Product Analytics and Experimentation charter for Brand & Performance Marketing and Digital Acquisition & Membership experiences as we'll as Enterprise Platforms. The focus of this collaborative team is to drive growth by enabling efficiencies in paid performance channels & evolve our digital experiences with actionable insights & analytics. The team specializes in using data around digital product usage to drive improvements in the acquisition customer experience to deliver higher satisfaction and business value.\n,,,,"['Mining', 'Career development', 'Finance', 'Analytical', 'Data processing', 'Analytics', 'SQL']",2025-06-12 14:03:08
Data Analyst - Odia Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\n\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\n\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\n\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Odia.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['Data Analysis', 'English', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:10
Data Analyst - Urdu Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Urdu.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Urdu', 'Data Analysis', 'Research Analysis', 'Data Interpretation', 'Analytical', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:12
Data Analyst - Marathi Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Marathi.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['English', 'Data Analysis', 'Marathi', 'Research Analysis', 'Data Management', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:14
Data Analyst - Bangla Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\nIdeal Candidate\nFluent in English and Bangla.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Bangla', 'Data Analysis', 'Data Research', 'Research Analysis', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:16
Data Analyst - Gujarati Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Gujarati.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply.\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Freelance/Homebased","['English', 'Gujarati', 'Data Interpretation', 'Data Analysis', 'Research Analysis', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:19
Data Analyst - Marathi Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"O)For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Marathi.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Data Interpretation', 'Data Analysis', 'Marathi', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:21
Data Analyst - Malayalam Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Malayalam.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Malayalam', 'Data Analysis', 'Data Extraction', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:23
Business Data Analyst,CGI,5 - 8 years,Not Disclosed,['Hyderabad'],"Business Data Analyst - HealthCare\n\nJob Summary\nWe are seeking an experienced and results-driven Business Data Analyst with 5+ years of hands-on experience in data analytics, visualization, and business insight generation. This role is ideal for someone who thrives at the intersection of business and datatranslating complex data sets into compelling insights, dashboards, and strategies that support decision-making across the organization.\nYou will collaborate closely with stakeholders across departments to identify business needs, design and build analytical solutions, and tell compelling data stories using advanced visualization tools.\nKey Responsibilities\nData Analytics & Insights Analyze large and complex data sets to identify trends, anomalies, and opportunities that help drive business strategy and operational efficiency.\n• Dashboard Development & Data Visualization Design, develop, and maintain interactive dashboards and visual reports using tools like Power BI, Tableau, or Looker to enable data-driven decisions.\n• Business Stakeholder Engagement Collaborate with cross-functional teams to understand business goals, define metrics, and convert ambiguous requirements into concrete analytical deliverables.\n• KPI Definition & Performance Monitoring Define, track, and report key performance indicators (KPIs), ensuring alignment with business objectives and consistent measurement across teams.\n• Data Modeling & Reporting Automation Work with data engineering and BI teams to create scalable, reusable data models and automate recurring reports and analysis processes.\n• Storytelling with Data Communicate findings through clear narratives supported by data visualizations and actionable recommendations to both technical and non-technical audiences.\n• Data Quality & Governance Ensure accuracy, consistency, and integrity of data through validation, testing, and documentation practices.\nRequired Qualifications\nBachelor’s or Master’s degree in Business, Economics, Statistics, Computer Science, Information Systems, or a related field.\n• 5+ years of professional experience in a data analyst or business analyst role with a focus on data visualization and analytics.\n• Proficiency in data visualization tools: Power BI, Tableau, Looker (at least one).\n• Strong experience in SQL and working with relational databases to extract, manipulate, and analyze data.\n• Deep understanding of business processes, KPIs, and analytical methods.\n• Excellent problem-solving skills with attention to detail and accuracy.\n• Strong communication and stakeholder management skills with the ability to explain technical concepts in a clear and business-friendly manner.\n• Experience working in Agile or fast-paced environments.\nPreferred Qualifications\nExperience working with cloud data platforms (e.g., Snowflake, BigQuery, Redshift).\n• Exposure to Python or R for data manipulation and statistical analysis.\n• Knowledge of data warehousing, dimensional modeling, or ELT/ETL processes.\n• Domain experience in Healthcare is a plus.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Bigquery', 'Snowflake', 'Data Warehousing', 'Redshift', 'Python', 'ETL']",2025-06-12 14:03:25
Business Partner Master Data Analyst Associate,Westlake Epoxy,2 - 7 years,Not Disclosed,['Bengaluru'],"Westlake offers you the potential to enrich your work life and career experience in an entrepreneurial environment. We work together to enhance peoples lives through our products and presence in the communities in which we operate.\nBusiness Partner Master Data Analyst Associate\nBusiness Partner Master Data Analyst is part of a global team who establishes and follows procedures that maintain the integrity of data for Customer and Vendor master data in SAP. These procedures allow business objectives to be met and to be compliant to (regional) Government regulations and Westlake Epoxy regulations. The Customer and Vendor Master Analyst role is the key for setting up a good foundation for further execution of the business processes.\nEssential Functions\nTasks:\nCreate, change, or delete Customer/Supplier records following approval workflows and document verification.\nManage partner functions and ensure compliance with SOPs and Westlake Safety & Integrity policies.\nSystem Skills:\nProficiently use systems like ECC, S4 HANA, and Fiori.\nData Quality:\nMaintain high-quality master data according to KPIs.\nRegularly check and verify system parameters against process updates.\nPerform mass changes to master data under supervision.\nKey Relationships / Collaboration:\nWork closely with Customer Service, Master Data, IT, Procurement Operations, Procurement, and Finance.\nSupport:\nCommunicate with internal customers based on business needs.\nValidate active accounts according to business rules.\nBlock inactive accounts in SAP during Annual block/deletion program.\nBusiness Support:\nProactively address system errors or process gaps by escalating to relevant key users for resolution.\nQualification:\nAny degree with minimum 2 years experience in a functional area.\nFluent language skills in English, both verbal and written.\nProficient in Microsoft Office and Outlook.\nSAP functional knowledge required i.e. Master Data.\nIntermediate skills in Microsoft Excel.\nPositive attitude and strong customer focus.\nGood organizational and communication skills.\nProactive and solution focused.\nAttentive to details, able to work accurately.\nAbility to work under pressure, time sensitive environment showing high level of flexibility.\nTeam player.\nWestlake is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to any characteristics protected by applicable legislation.\nIf you are an active Westlake employee (or an employee of any Westlake affiliates), please do not apply here. You will apply via the Jobs Hub application in Workday.",Industry Type: Chemicals,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Master Analyst', 'SAP', 'Excel', 'IT procurement', 'business rules', 'document verification', 'Data quality', 'Data Analyst', 'Customer service', 'MS Office']",2025-06-12 14:03:27
"Senior Python Developer (Machine Learning,Data Analysis,Visualization)",Synechron,3 - 5 years,Not Disclosed,"['Pune', 'Hinjewadi']","Software Requirements\nRequired Skills:\nProficiency in Python (version 3.6+) with experience in data analysis, manipulation, and scripting\nKnowledge of SQL for data extraction, transformation, and database querying\nExperience with data visualization tools such as PowerBI, Tableau, or QlikView\nFamiliarity with AI and Machine Learning frameworks such as TensorFlow, Keras, PyTorch, or equivalent\nHands-on experience in developing, deploying, and optimizing machine learning models\nPreferred Skills:\nExperience with R for data analysis\nFamiliarity with cloud platforms like AWS, Azure, or GCP for deploying AI solutions\nKnowledge of version control systems such as Git\nOverall Responsibilities\nAnalyze, interpret, and visualize large and complex datasets to extract actionable insights\nDesign, develop, and implement machine learning and AI models for predictive and prescriptive analytics\nCollaborate with cross-functional teams to understand business requirements and translate them into data-driven solutions\nCommunicate findings, insights, and recommendations via reports, dashboards, and presentations to stakeholders\nEvaluate and refine models and algorithms to maximize accuracy, efficiency, and impact\nStay informed on emerging AI, Data Science, and analytics trends and incorporate best practices into projects\nSupport automation efforts, optimize data pipelines, and enhance existing analytical workflows\nContribute to organizational learning by sharing knowledge and mentoring team members\nStrategic objectives:\nDrive innovation through the application of AI and machine learning\nEnable data-driven decision-making across business units\nImprove operational efficiencies and business outcomes\nPerformance outcomes:\nAccurate, robust, and scalable AI models\nHigh-quality insights delivered on time and aligned with business needs\nWell-documented solutions and knowledge-sharing artifacts\nTechnical Skills (By Category)\nProgramming Languages (Essential):\nPython (required); experience with R is a plus\nSQL (required); experience with data manipulation and querying\nData Analysis & Visualization Tools (Essential):\nPowerBI, Tableau, or QlikView\nFrameworks & Libraries (Essential):\nTensorFlow, Keras, PyTorch, or similar frameworks for AI/ML development\nData Management & Databases (Essential):\nRelational databases (e.g., MySQL, PostgreSQL, Oracle)\nData extraction and transformation (ETL processes)\nCloud & Deployment (Preferred):\nExperience deploying models on cloud platforms such as AWS, Azure, GCP\nDevelopment & Version Control (Preferred):\nGit for code versioning\nOther Skills:\nStrong statistical knowledge and experience with data preprocessing, feature engineering\nFamiliarity with agile development methodologies\nExperience Requirements\n3 to 5 years of relevant experience in AI, Data Science, or Data Analytics roles\nProven track record applying machine learning techniques to real-world problems\nExperience working with large datasets and scalable data pipelines\nExperience collaborating with cross-functional teams to deliver analytics-driven solutions\nIndustry experience in finance, healthcare, retail, or similar data-rich sectors is preferred\nAlternative pathways:\nCandidates with extensive AI & ML project experience, strong programming skills, and relevant certifications can be considered with slightly varied years of experience\nDay-to-Day Activities\nCollect, clean, and explore large datasets to identify patterns and insights\nDevelop and tune machine learning models to address business problems\nCollaborate with business analysts, data engineers, and product owners to align technical solutions with organizational goals\nDocument methodologies, code, and analytical findings to ensure reproducibility and knowledge sharing\nCreate dashboards, visualizations, and reports to communicate insights effectively\nEvaluate model performance regularly and optimize models for accuracy and efficiency\nParticipate in team meetings, project planning, and review sessions\nKeep abreast of advancements in AI/ML technologies, tools, and best practices\nQualifications\nBachelors degree in Computer Science, Data Science, Statistics, or related field\nMasters degree or higher in AI, Data Science, or related disciplines is a plus\nProfessional certifications in AI/ML (e.g., TensorFlow Developer, AWS Machine Learning Specialty) are advantageous\nWilling to learn new tools and stay updated with emerging AI trends\nAbility to work independently and collaborate effectively in a dynamic environment\nProfessional Competencies\nAnalytical and problem-solving mindset with a focus on actionable insights\nExcellent verbal and written communication skills for diverse audiences\nStrong interpersonal skills and stakeholder management\nAdaptability to fast-changing technology landscapes\nGrowth mindset with continuous learning enthusiasm\nOrganizational skills to handle multiple projects and priorities simultaneously\nInnovation-driven approach and proactive problem resolution",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'PostgreSQL', 'MySQL', 'Data Analysis', 'Data Visualization', 'Oracle', 'ETL', 'Machine Learning']",2025-06-12 14:03:30
Business Data Analyst,NetApp,8 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary\nWe are seeking a highly skilled and experienced Senior Business Data Analyst to join our Entitlement and Install Base Master team. You will play a crucial role in driving the Install Base (IB) data strategy and vision. Your deep understanding of Install Base and Renewals business processes will be instrumental in ensuring accurate and efficient management of our Install Base Data.\nJob Requirements\nDrive the Install Base data strategy and vision, collaborating with cross-functional teams to define and implement data management processes and standards.\nDevelop a comprehensive understanding of the Install Base and Renewals business, including key metrics, processes, and customer lifecycles.\nDrive Enterprise projects ensuring alignment with organizational goals and objectives.\nCollaborate with stakeholders to gather requirements and translate business needs into technical solutions for Install Base data management.\nCollaborate with cross-functional teams to define and implement data governance policies and procedures.\nPerform in-depth data analysis and validation to identify trends, patterns, and insights that drive business decision-making.\nCollaborate with IT teams to enhance data systems and tools supporting Install Base data management, ensuring data quality and accessibility.\nProvide guidance and support to cross-functional teams on Install Base data-related matters, acting as a subject matter expert.\nIdentify opportunities for process improvements and automation to streamline Install Base data management and enhance operational efficiency.\nStay up-to-date with industry trends and best practices in Install Base and Renewals business processes and data management.\nCoach and mentor team members to foster their professional growth and ensure smooth operations, promoting a collaborative and high-performing environment.\n",,,,"['data analysis', 'data management', 'analytical', 'workflow', 'business requirements', 'install base', 'sql querying', 'renewals', 'relational databases', 'sql', 'data cleansing', 'data quality', 'business process', 'management', 'collaboration', 'business data analysis', 'data governance', 'communication skills']",2025-06-12 14:03:32
MDM Data Analyst / Steward Lead,Gallagher Service Center (GSC),3 - 7 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\n\nThe MDM Analyst / Data Steward works closely with business stakeholders to understand and gather data requirements, develop data models and database designs, and define and implement data standards, policies, and procedures. This role also implements any rules inside of the MDM tool to improve the data, performs deduplication projects to develop golden records, and overall works towards improving the quality of data in the domain assigned.\n\nRequired skills :\nTechnical Skills: Proficiency in MDM tools and technologies such as Informatica MDM, CluedIn, or similar platforms is essential. Familiarity with data modeling, data integration, and data quality control techniques is also important. Experience with data governance platforms like Collibra and Alation can be beneficial1.\nAnalytical Skills: Strong analytical and problem-solving skills are crucial for interpreting and working with large volumes of data. The ability to translate complex business requirements into practical MDM solutions is also necessary.\nData Management: Experience in designing, implementing, and maintaining master data management systems and solutions. This includes conducting data cleansing, data auditing, and data validation activities.\nCommunication and Collaboration: Excellent communication and interpersonal skills to effectively collaborate with business stakeholders, IT teams, and other departments.\nData Governance: In-depth knowledge of data governance, data quality, and data integration principles. The ability to develop and implement data management processes and policies is essential.\nEducational Background: A Bachelor's or Master's degree in Computer Science, Information Systems, Data Science, or a related field is typically required1.\nCertifications: Certification in the MDM domain (e.g., Certified MDM Professional) can be a plus\n\nKey Skills:\nBecome the expert at the assigned domain of data\nUnderstand all source systems feeding into the MDM\nWrite documentation of stewardship for the domain\nDevelop rules and standards for the domain of data\nGenerate measures of improvement to demonstrate to the business the quality of the data\n\nWe are seeking candidates who can join immediately or within a maximum of 30 days' notice.\nMinimum of 3+ years of relevant experience is required.\nCandidates who are willing to relocate to Bangalore or are already based in Bangalore.\nCandidates should be flexible with working UK/US shifts.",Industry Type: Analytics / KPO / Research,Department: Other,"Employment Type: Full Time, Permanent","['Informatica Mdm', 'Data Modeling', 'Data Integration']",2025-06-12 14:03:34
"Senior Data Scientist (AI/ML, Data Analysis, Cloud (AWS), and Model",Synechron,8 - 13 years,Not Disclosed,['Pune'],"job requisition idJR1027352\n\nJob Summary\nSynechron is seeking an analytical and innovative Senior Data Scientist to support and advance our data-driven initiatives. The ideal candidate will have a solid understanding of data science principles, hands-on experience with AI/ML tools and techniques, and the ability to interpret complex data sets to deliver actionable insights. This role contributes to the organizations strategic decision-making and technology innovation by applying advanced analytics and machine learning models in a collaborative environment.\n\nSoftware\n\nRequired\n\nSkills:\nPython (including libraries such as pandas, scikit-learn, TensorFlow, PyTorch) proficiency in developing and deploying models\nR (optional, but preferred)\nData management tools (SQL, NoSQL databases)\nCloud platforms (preferably AWS or Azure) for data storage and ML deployment\nJupyter Notebooks or similar interactive development environments\nVersion control tools such as Git\nPreferred\n\nSkills:\nBig data technologies (Spark, Hadoop)\nModel deployment tools (MLflow, Docker, Kubernetes)\nData visualization tools (Tableau, Power BI)\nOverall Responsibilities\nAnalyze and interpret large and complex data sets to generate insights for business and technology initiatives.\nAssist in designing, developing, and implementing AI/ML models and algorithms to solve real-world problems.\nCollaborate with cross-functional teams including data engineers, software developers, and business analysts to integrate models into production systems.\nStay current with emerging trends, research, and best practices in AI/ML/Data Science and apply them to ongoing projects.\nDocument methodologies, modeling approaches, and insights clearly for technical and non-technical stakeholders.\nSupport model validation, testing, and performance monitoring to ensure accuracy and reliability.\nContribute to the development of data science workflows and standards within the organization.\nPerformance Outcomes:\nAccurate and reliable data models that support strategic decision-making.\nClear documentation and communication of findings and recommendations.\nEffective collaboration with technical teams to deploy scalable models.\nContinuous adoption of best practices in AI/ML and data management.\nTechnical Skills (By Category)\n\nProgramming Languages:\nEssential: Python (best practices in ML development), SQL\nPreferred: R, Java (for integration purposes)\nDatabases/Data Management:\nSQL databases, NoSQL (MongoDB, Cassandra)\nCloud data storage solutions (AWS S3, Azure Blob Storage)\nCloud Technologies:\nAWS (S3, EC2, SageMaker, Lambda)\nAzure Machine Learning (preferred)\nFrameworks & Libraries:\nTensorFlow, PyTorch, scikit-learn, Keras, XGBoost\nDevelopment Tools & Methodologies:\nJupyter Notebooks, Git, CI/CD pipelines\nAgile and Scrum processes\nSecurity Protocols:\nBest practices in data security and privacy, GDPR compliance\nExperience\n8+ years of professional experience in AI, ML, or Data Science roles.\nProven hands-on experience designing and deploying ML models in real-world scenarios.\nDemonstrated ability to analyze complex data sets and translate findings into business insights.\nPrevious experience working with cloud-based data science solutions is preferred.\nStrong portfolio showcasing data science projects, models developed, and practical impact.\nAlternative Pathways:\nCandidates with extensive research or academic experience in AI/ML can be considered, provided they demonstrate practical application of skills.\n\nDay-to-Day Activities\nConduct data exploration, cleaning, feature engineering, and model development.\nCollaborate with data engineers to prepare data pipelines for model training.\nBuild, validate, and refine machine learning models.\nPresent insights, models, and recommendations to technical and business stakeholders.\nSupport deployment of models into production environments.\nMonitor model performance and iterate to improve effectiveness.\nParticipate in team meetings, project planning, and reviewing progress.\nDocument methodologies and maintain version control of codebase.\nQualifications\nBachelors degree in Computer Science, Mathematics, Statistics, Data Science, or a related field; Masters or PhD highly desirable.\nEvidence of relevant coursework, certifications, or professional training in AI/ML.\nProfessional certifications (e.g., AWS Certified Machine Learning Specialty, Microsoft Certified Data Scientist) are a plus.\nCommitment to ongoing professional development in AI/ML methodologies.\nProfessional Competencies\nStrong analytical and critical thinking to solve complex problems.\nEffective communication skills for technical and non-technical audiences.\nDemonstrated ability to work collaboratively in diverse teams.\nAptitude for learning new tools, techniques, and technologies rapidly.\nInnovation mindset with a focus on applying emerging research.\nStrong organizational skills to manage multiple projects and priorities.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['java', 'data science', 'python', 'deploying models', 'aws', 'continuous integration', 'kubernetes', 'scikit-learn', 'ci/cd', 'artificial intelligence', 'sql', 'docker', 'tensorflow', 'spark', 'pytorch', 'keras', 'hadoop', 'big data', 'mongodb', 'microsoft azure', 'nosql', 'pandas', 'amazon ec2', 'r', 'cassandra', 'agile']",2025-06-12 14:03:37
Data Analyst - Kannada Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Kannada.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you.\nAnti-virus solution that is kept up to date, with regular scans performed.\nOnly one member per household may apply.\nNB: All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\n\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['English', 'Kannada', 'Data Interpretation', 'Data Analysis', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:39
Data Analyst - Kannada Speaker (India),Peroptyx,0 - 5 years,Not Disclosed,[],"For thousands of years, maps have provided humans with the knowledge they need to make decisions. As a Maps Evaluator, you will have the opportunity to provide ground truth for your town, city or country.\nAt Peroptyx, we are looking for Data Analysts who will review mapping data for digital mapping applications. Your research capabilities will validate and ensure that the navigation of certain routes are accurate and safe.\nAs part of this role you will verify that business names and opening hours are correct. You will check that the distance from a starting point to an end destination is listed accurately, resulting in better user experiences.\nWith this job you can plan your days around this highly flexible working schedule, work weekends or late evenings, all from the comfort of your own office. The flexibility of our roles minimizes the impact on your daily routine.\nSo, whether you are a student looking to earn as you learn, a retiree looking for a new challenge, a part-time/full time professional or a work from home parent, Peroptyx has the right role for you!\n\nIdeal Candidate\nFluent in English and Kannada.\nExcellent research skills.\nExcellent local knowledge of India.\nGood understanding and general knowledge of the geography and culture of India.\nAnalytical mindset.\n\nJob Requirements\nMust be living in India for a minimum of 5 consecutive years.\nMust pass an online open-book exam that can verify your full understanding of the material and concepts.\nMust be willing to work a minimum of 10 hours and up to 20 hours per week depending on task availability.\nGood working knowledge of search engines, map applications and familiarity with social media platforms.\nStrong ability to learn, understand and apply multiple sets of different instructions.\nAll work must be of an independent nature.\n\nTechnical requirements to perform the work\nAccess to a laptop or computer which uses:\nA logon account unique to you\nAnti-virus solution that is kept up to date, with regular scans performed\nOnly one member per household may apply\nNB. All products should be provided at your own expense.\n\nBenefits\nWork up to 20 hours per week.\nEarn a competitive rate of pay.\nDevelop your research skills.\nAvoid the long commute.\nWork from the comfort of your home office.\nEnjoy the flexibility of setting your own working hours!\n\nApply Online Today!\nThis is an independent contractor position.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['English', 'Kannada', 'Data Analysis', 'Data Collection', 'Research', 'Data Analytics', 'Research And Development', 'Data Mapping']",2025-06-12 14:03:42
"Senior Data Analyst - Power BI, Data Modeling, Data Visualization",IT Services & Consulting,7 - 10 years,Not Disclosed,"['Mumbai', 'Delhi / NCR', 'Bengaluru']","Job Overview:\nYoull design and implement scalable solutions for award-winning platforms like LMX and MAX, automating media transactions and bridging media buyers and sellers. Work in an Agile, POD-based model to revolutionize the role of data and technology in OOH advertising.\n\nWhat Youll Do:\nArchitect scalable solutions aligned with business goals and market needs.\nLead Agile POD teams to deliver iterative, high-impact solutions.\nEnhance products with advanced features like dynamic rate cards and inventory mapping.\nEnsure best practices in security, scalability, and performance.\n\nWhat You Bring:\nStrong expertise in cloud-based architectures, API integrations, and data analytics.\nProven experience in Agile environments and POD-based execution.\nTechnical proficiency in Java, Angular, Python, and AWS.\n\nRequired Skills:\n8+ years of experience as a Solution Architect.\nBachelors/Masters in Computer Science or related field.\nProficiency in Java, Angular, Python, MongoDB, SQL, NoSQL, and AWS.\nStrong understanding of Agile methodologies and POD-based execution.\n\nTech Stack:\nLanguages: Java, Python\nFrontend: Angular\nDatabases: MongoDB, SQL, NoSQL\nCloud: AWS\nLocation-Remote,Delhi NCR, Bangalore, Chennai, Pune, Kolkata, Ahmedabad, Mumbai, Hyderabad",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Visualization', 'Java', 'NoSQL', 'Power BI', 'Data Analysis', 'MongoDB', 'AWS', 'SQL', 'Python']",2025-06-12 14:03:44
Senior Data Analyst-Azure Data Factory,Lumen Technologies,8 - 12 years,Not Disclosed,['Bengaluru'],"Were looking for a Senior Data Analyst with a strong foundation in Azure-based data engineering and Machine Learning to design, develop, and optimize robust data pipelines, applications, and analytics infrastructure. This role demands deep technical expertise, cross-functional collaboration, and the ability to align data solutions with dynamic business needs.\nKey Responsibilities:\nData Pipeline Development:\nDesign and implement efficient data pipelines using Azure Databricks with PySpark to transform and process large datasets.\nOptimize data workflows for scalability, reliability, and performance.\nApplication Integration:\nCollaborate with cross-functional teams to develop APIs using the .NET Framework for Azure Web Application integration.\nEnsure smooth data exchange between applications and downstream systems.\nData Warehousing and Analytics:\nBuild and manage data warehousing solutions using Synapse Analytics and Azure Data Factory (ADF).\nDevelop and maintain reusable and scalable data models to support business intelligence needs.\nAutomation and Orchestration:\nUtilize Azure Logic Apps, Function Apps, and Azure DevOps to automate workflows and streamline deployments.\nImplement CI/CD pipelines for efficient code deployment and testing.\nInfrastructure Management:\nOversee Azure infrastructure management and maintenance, ensuring a secure and optimized environment.\nProvide support for performance tuning and capacity planning.\nBusiness Alignment:\nGain a deep understanding of AMO data sources and their business implications.\nWork closely with stakeholders to provide customized solutions aligning with business needs.\nBAU Support:\nMonitor and support data engineering workflows and application functionality in BAU mode.\nTroubleshoot and resolve production issues promptly to ensure business continuity.\nTechnical Expertise:\nProficiency in Microsoft SQL for complex data queries and database management.\nAdvanced knowledge of Azure Databricks and PySpark for data engineering and ETL processes.\nExperience with Azure Data Factory (ADF) for orchestrating data workflows.\nExpertise in Azure Synapse Analytics for data integration and analytics.\nProficiency in .NET Framework for API development and integration.\nCloud and DevOps Skills:\nStrong experience in Azure Infrastructure Management and optimization.\nHands-on knowledge of Azure Logic Apps, Function Apps, and Azure DevOps for CI/CD automation.\n""We are an equal opportunity employer committed to fair and ethical hiring practices. We do not charge any fees or accept any form of payment from candidates at any stage of the recruitment process. If anyone claims to offer employment opportunities in our company in exchange for money or any other benefit, please treat it as fraudulent and report it immediately.""\n#LI-BS1",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'Automation', 'orchestration', 'Infrastructure management', 'Machine learning', 'Business intelligence', 'Business continuity', 'Analytics', 'Downstream', 'Capacity planning']",2025-06-12 14:03:46
Data Research Analyst (BPO Non-Voice) - Immediate Joiners,Trupp Global Technologies,0 - 4 years,2.5-4.5 Lacs P.A.,[],"Role & responsibilities\nWe're hiring a Data Research Analyst to join our Research & Data Services team. This role involves gathering and analyzing information about companies from the web including crafting short descriptions about companies, tracking investments and funding rounds, mergers & acquisitions, and other key corporate events.\nIf you have a knack for internet research, a love for data accuracy, and an interest in the world of startups, finance, and business, this could be a great fit.\n\nWhat You'll Do\nConduct internet research to collect accurate information about companies across sectors.\nTrack and record business events such as Venture funding(Seed, Series A, B, etc), Mergers and acquisitions, IPOs and executive changes.\nWrite clear and concise company descriptions based on publicly available data. Research online and create relevant content as per style, tone, and requirements.\nOrganize data in spreadsheets or internal databases with precision.\nVerify and validate data from multiple sources for consistency and reliability.\nCollaborate with the quality assurance team to ensure data integrity.\n\n\nPreferred candidate profile\n0 - 4 years of experience in a data research, web research, or business intelligence role.\nExcellent written English and ability to summarize complex information quickly.\nFamiliarity with business and financial terms.\nProficient in tools like Google Search, LinkedIn, Pitchbook, Company Websites, business information sites and Excel/Google Sheets.\nStrong attention to detail and ability to meet deadlines.\n\nNice to Have\nBackground in business, finance, Journalism and content writing\nExperience using tools like PitchBook, Owler, or similar research platforms.\nPrior experience in a BPO/KPO or analytics environment.",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Internet Research', 'Research Analysis', 'Data Mining', 'Content Writing', 'Written Communication', 'Bpo Non Voice']",2025-06-12 14:03:48
Data Analyst /Science executive,Hav2 Apparels,2 - 5 years,1.75-2.5 Lacs P.A.,"['Bengaluru( Kundalahalli, AECS Layout, Munnekollal, Whitefield )']","Build and run scripts to scrape emails, phone numbers, and business data, clean and organize it, analyze insights using Python/Excel, automate workflows, and support lead generation for import-export operations.",Industry Type: Import & Export,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['basic data analysis', 'Attention to Detail', 'Excel proficiency', 'regex knowledge', 'experience extracting emails/phones', 'Email Marketing', 'Numpy', 'and ability to automate and document tasks.', 'Beautiful Soup', 'CRM Management', 'Pandas', 'Data Scraping', 'Selenium', 'Python']",2025-06-12 14:03:50
Financial Data Analyst,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: ROC(ROC)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies:\nBasic knowledge of financial statements and basic understanding of how data fits into methodologies\nAbility to read, understand and interpret financial metrics reported by rated entities\nStrong organizational skills\nAttention to detail\nAbility to work effectively in a collaborative team environment\nIntermediate Microsoft Excel skills\nGood written and verbal communication skills\nGood interpersonal skills, interact with team members, direct managers and limited other stakeholders\nDevelop working knowledge of more than one simple project/deliverable with guidance\nRelevant experience of up to 2 years in credit/financial data analysis and interpretation; experience in structured finance will be an added advantage\n\nEducation\nBachelors/Masters in Finance, Business, Accounting or similar field\n\nResponsibilities\nPerform analysis to support ratings, research, and analytical outreach\nApply Moody s Ratings standards to existing data to produce valuable inputs into the rating and research process, including Moodys adjusted data, key indicators, ratios, charts, and graphs in line with Moody s Ratings methodologies\nPerform various data intake tasks, including scrubbing and validating data for further use in research and ratings\nReview and understand financial reports, official statements, and other documents related to issuers performance\nWork directly with ratings and support analysts to understand data capture requirements, adjustments, and other information needed by the rating team for ratings and research\nPerform simple calculations and apply judgment for other calculations of data\nGather data from various sources (sometimes unstructured), update relevant databases, escalate or resolve issues\nComplete simple deliverables such as newsletters, database maintenance, more complex or high-profile admin or other ad-hoc support with oversight\n\nAbout the team\nOur Data & Analytics team is responsible for performing a range of data, analytical and research services that contribute to the overall credit analysis function carried out by the structured finance rating groups. By joining our team, you will be part of exciting work in financial data analysis.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['remediation', 'Data analysis', 'Financial statements', 'Excel', 'Analytical', 'Finance', 'Structured finance', 'ROC', 'Credit analysis', 'Research']",2025-06-12 14:03:52
Data Analyst - Senior,FedEx,4 - 7 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Role & responsibilities :\n\nAct as a technical expert on complex and specialist subject(s).\nSupport management with the analysis, interpretation and application of complex information, contributing to the achievement of divisional and corporate goals. Supports or leads projects by applying area of expertise.\nLead and implement advanced analytical processes through data/text mining, model development, and prediction to enable informed business decisions.\nApply sound analytical expertise to examine structured and unstructured data from multiple disparate sources to provide insights and recommend high-quality solutions to leadership across levels.\nPlan initiatives from concept to execution with minimal supervision and communicate results to a broad range of audiences. Develops a superior understanding of pricing and revenue management through internal and external sources to creatively solve business problems and lead the team from concept to execution of projects.\nTypically uses data, statistical and quantitative analysis, modeling, and fact-based management to drive decision-making. Provides regular expert consultative advice to senior leadership.\nEffectively shares best practices and fosters knowledge sharing across teams. Provides crossteam and cross-org consultation and supports communities of practice excellence.\n\n\n\nPreferred candidate profile\n\nRelevant experience in analytics/consulting/informatics and statistics\nKey Skills - Data and Business Analytics, Advanced Statistics and Predictive Modelling,\nStakeholder Management, Project Management\nExperience in pricing and revenue management yield management, customer segmentation analytics, revenue impact analytics, etc. is a plus\nExposure to predictive analytics, ML/ AI techniques is an added advantage\nTools - Oracle, SQL Server, Teradata, SAS, Python, Tableau/PowerBI/Spotfire\nGood to have cloud computing, big data, Azure",Industry Type: Courier / Logistics (Logistics Tech),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Business Insights', 'Python', 'SQL', 'Power Bi', 'Business Acumen', 'Tableau']",2025-06-12 14:03:55
Senior Financial Data Analyst,Moodys Investors Service,1 - 2 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: RRS(RRS)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSolid accounting background with a strong focus on financial analysis\nDemonstrates knowledge of MS Excel, Word, and PowerPoint\nStrong organizational skills and attention to detail\nAbility to work effectively in a team environment with matrix reporting\nSolid verbal, written communication, and interpersonal skills\nAbility to adapt to a changing environment and prioritize tasks accordingly\nEducation:\nMinimum Experience: 1-2 years relevant in Credit Rating Analysis, Financial Statement Analysis\nPreferably a Postgraduate degree in Accounting, Finance, Economics, from a premium institution\nGood to have CFA/FRM certification\nJob Responsibilities:\nThe Senior Financial Data Analyst contributes to the success of the Research and Ratings Support team by providing a range of data and analytic services that support the overall credit analysis functions performed by the MIS analytic teams. This internal-facing role involves working directly with rating and research support analysts, preparing data, and performing various analytical tasks such as spreading, data gathering, and analysis for credit ratings, research, analytical market outreach, and presentations\nKey responsibilities include:\nPreparing a variety of discrete credit process inputs, performing preliminary analyses to identify trends in data, and applying reasoning to the completed work product\nPerforming financial statement analysis using accounting and finance principles to read and understand financial statements and other disclosures related to debt issuers performance\nApplying Moody s relevant methodology standards and requirements to financial data and making appropriate adjustments\nCreating a variety of standard initial work package items that serve as starting points for the ratings and research process, including data, spreadsheets, charts, and tables\nUpdating financial spreadsheets, charts, and tables\nIdentifying trends in data and applying reasoning to work being completed\nInitiating/escalating deeper reviews when necessary\nPreparing presentation materials for outreach activities\nProviding support for RRS and R&R in monitoring/surveillance of Moody s rated issuers\nSupporting monitoring of analyst credit portfolios through news and industry source tracking and highlighting key issues requiring further analysis\nUnderstanding the application of accounting concepts on a particular entity\nCreating documentation and providing guidance to support analysts and outsourcers\nReviewing, adjusting, and publishing data to external market participants\nSupporting the credit administration process and performing other routine administrative and ad hoc tasks as directed by RRS & R&R Teams\nAbout the Team:\nOur Research and Ratings Support (RRS) team is responsible for providing a range of data and analytic services that support the overall credit analysis functions performed by the MIS analytic teams\nBy joining our team, you will be part of exciting work in credit ratings, research, analytical market outreach, and presentations",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Administration', 'Financial statements', 'Publishing', 'Financial analysis', 'MIS', 'Analytical', 'Credit analysis', 'Financial statement analysis', 'Credit rating', 'Monitoring']",2025-06-12 14:03:57
Financial Data Analyst,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: ROC(ROC)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies\nStrong understanding of fundamental finance and financial statements\nBasic understanding of capital markets\nCurious problem solvers who enjoy learning new things, working with others, and continuously growing their interpersonal and technical skills.\nCandidates from diverse backgrounds and academic disciplines with a strong focus on Finance/Technology/Support & Management\nFluency in English with good written and verbal communication skills; good interpersonal skills\nCreate visual representations of data findings through charts, graphs, and dashboards to make the data understandable.\nFamiliarity with Alteryx, SQL and other data visualization tools such as Tableau, PowerBI etc.\nPreferred proficiency in Python for data analysis and scripting.\nRelevant experience of up to 2 years in credit/financial data analysis and interpretation is an added advantage\nEducation\nMasters in Finance, Business, Accounting or similar field. Any knowledge in SQL, Python, PowerBI, Alteryx, etc or any experience related to data science, data analytics will be an added advantage.\nResponsibilities\nPerform analysis to support ratings, research, analytical outreach. Examples of work include:\nPerform various data intake tasks, including scrubbing, validating the data for further use in research and ratings\nApply MIS standards to existing data in order to produce valuable inputs into the rating and research process, including Moodys adjusted data, key indicators, ratios, charts and graphs in line with MISs methodologies\nResponsible for reviewing and understanding financial reports, official statements and other documents related to issuers performance\nWork directly with ratings and support analysts to understand data capture requirements, adjustments and other information needed by the rating team for ratings and research\nTake initiative to participate in projects or process improvements\nComplete simple deliverables such as newsletters, database maintenance, more complex or high profile admin or other ad-hoc support with oversight\nBe able to perform data intake exercises such as resolution of data point or mapping issues\nOur Ratings & Operations Control (ROC) team is responsible for 1) analytic data capture and enrichment, inputs and outputs to support ratings & research, 2) ratings transaction setup and release and rating desk services, 3) regulatory processes and operational controls, 4) product management for regulatory website, 5) center of excellence for process improvement and 6) project management support.\nBy joining our team, you will be part of exciting work in supporting ratings accuracy and timely market impact by delivering high-quality, consistent work product, while driving process excellence.\n\n\n\n\nFor more information on the Securities Trading Program, please refer to the STP Quick Reference guide on ComplianceNet\n\nPlease note: STP categories are assigned by the hiring teams and are subject to change over the course of an employee s tenure with Moody s.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Financial statements', 'MIS', 'Project management', 'Process improvement', 'Analytical', 'Credit analysis', 'Operations', 'SQL']",2025-06-12 14:03:59
urgent requirement For Data Analyst / BI Developer,Quantzig,3 - 6 years,Not Disclosed,[],"Key Responsibilities:\nDevelop, design, and maintain dashboards and reports using Tableau and Power BI to support business decision-making.\nWrite and optimize complex SQL queries to extract, manipulate, and analyze data from multiple sources.\nCollaborate with cross-functional teams to understand business needs and translate them into effective data solutions.\nWork with AWS Redshift and Databricks for data extraction, transformation, and loading (ETL) processes.\nProactively identify and resolve data issues, acting as a solution finder to overcome challenges and drive improvements.\nWork independently, taking ownership of tasks and ensuring high-quality deliverables within deadlines.\nBe a strong team player, contributing to team knowledge sharing and fostering a collaborative environment.\nApply knowledge of US healthcare systems to help build relevant data solutions and insights.\n\nRequired Skills & Qualifications:\nMinimum 3 years of experience in data analysis, business intelligence, or related roles.\nStrong expertise in SQL for data querying and manipulation.\nExtensive experience creating dashboards and reports using Tableau and Power BI.\nHands-on experience working with AWS Redshift and Databricks.\nProven problem-solving skills with a focus on providing actionable data solutions.\nSelf-motivated and able to work independently, while being a proactive team player.\nExperience or strong understanding of US healthcare systems and data-related needs.\nExcellent communication skills with the ability to work across different teams and stakeholders.\nDesired Skills (Nice to Have):\nFamiliarity with other BI tools or cloud platforms.\nExperience in healthcare data analysis or healthcare analytics.",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Power Bi', 'Tableau', 'SQL', 'Redshift Aws', 'databricks']",2025-06-12 14:04:02
Sr. Data Analyst,Icims,4 - 9 years,Not Disclosed,['Hyderabad'],"Overview\nThe Senior Data Analyst is responsible for serving as a subject matter expert who can lead efforts to analyze data with the goal of delivering insights that will influence our products and customers. This position will report into the Data Analytics Manager, and will work closely with members of our product and marketing teams, data engineers, and members of our Customer Success organization supporting client outreach efforts. The chief functions of this role will be finding and sharing data-driven insights to deliver value to less technical audiences, and instilling best practices for analytics in the rest of the team.",,,,"['server', 'data', 'vlookup', 'market data', 'data mapping', 'dashboards', 'research', 'sql', 'analytics', 'tables', 'prep', 'pivot', 'data visualization', 'communication skills', 'python', 'data analytics', 'data analysis', 'insights', 'pivot table', 'data engineering', 'graph', 'excel', 'data quality', 'tableau', 'data governance', 'root cause']",2025-06-12 14:04:05
Optimal Data Analyst : Supply Chain : 12 LPA : Apply Now,Leading ITES Company,3 - 8 years,10-12 Lacs P.A.,"['Bangalore Rural', 'Bengaluru', 'Mumbai (All Areas)']","Hi,\n\nWe are hiring for the ITES Company for the Optimal Data Analyst Role.\nOverview\nThe Optimal Data Analyst is responsible for leveraging data to generate actionable insights that support strategic decision-making, particularly in supplier negotiations and cost forecasting. The role involves working with large data sets, using statistical methods, programming tools (e.g., SQL, R, Python), and business intelligence platforms like Tableau to identify patterns, trends, and financial opportunities. This position requires strong analytical thinking, problem-solving abilities, and collaboration across technical, operational, and supply chain teams. The analyst plays a key role in translating complex data into meaningful business insights, aligning analytical efforts with high-level business objectives, and driving value through data-informed negotiation support.\n\nKey Skills:\n\na) Bachelor's degree in discipline such as Supply Chain, Economic, Manufacturing, Technology, or Data Analytics\nb) Minimum 3 years of experience in data analysis with understanding of statistical methods and strong analytical skills\n\nTo Apply, WhatsApp 'Hi' @ 9151555419\n\nFollow the Steps Below:\n>Click on Start option to Apply and fill the details\n>Select the location as Other (to get multiple location option)\na)To Apply for above Job Role (Bangalore) Type : Job Code # 20\nb)To Apply for above Job Role (Mumbai) Type : Job Code # 21\n\nJob Description\n\nBachelor's degree in discipline such as Supply Chain, Economic, Manufacturing, Technology, or Data Analytics to bring diversity and different perspectives\nMinimum 3 years of experience in data analysis with understanding of statistical methods and strong analytical skills\nExperience with database management, programming, statistical modelling and/or business intelligence (SQL, R, Python, JMP, Tableau, etc.)\nExperienced with and proficient in Microsoft Office Suite\nLateral and logical thinking. The ability to think creatively and outside the box to solve unique and challenging problems\nMotivated self-starter\nStrong problem-solving tendencies\nWilling and able to push boundaries\nGoal-oriented, with a focus on utilizing data for insight\nAble to multi-task, prioritize and project manage independently in an environment with competing priorities\nExperience working in a technical, operational or manufacturing environment with the ability to translate that knowledge into financial opportunities\nDiverse functional experience, with a desire to use data in negotiations\nExcellent communication skills and a proven history of excelling in a collaborative environment as a key team player\nWorking closely with technical teams, and other organizations to understand the product and data\nFinding and interpreting large data sets to help predict costs\nLearning and understanding Boeing's data resources and knowing when, how, and which to use and which not to use.\nIdentifying, analyzing, and solve systematic problems, while maintaining focus on the bigger picture\nWorking together with the team to ensure data analysis and developed algorithms can be appropriately applied for negotiation support\nEnsuring data collected, analyzed and presented result in actionable insights for negotiation support\nEngaging and participating in negotiation support, to bolster the use of data analytics within supplier negotiations\nUnderstanding high-level business objectives and continually align those objectives to meet needs of the business.",Industry Type: BPM / BPO,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Genpact', 'Supply Chain', 'Sutherland', 'Statistical Modeling', 'Data Modeling', 'Wipro', 'Cognizant', 'Business Intelligence', 'Accenture', 'Data Mining', 'Data Extraction', 'Data Collection', 'HCL', 'Optimal Data Analyst', 'Database Management', 'Data Analysis', 'Data Visualization', 'Amazon', 'Hexaware', 'WNS']",2025-06-12 14:04:07
Senior Data Analyst,OnlineSales.ai,2 - 7 years,Not Disclosed,['Pune'],"About OnlineSales.ai\nBuilt by ex-Amazon ad-tech experts, OnlineSales.ai offers a future-proof Retail Media Operating System - boosting Retailer s profitability by 7% of Sales! We are an Enterprise B2B SaaS startup, based out of Pune India. With OnlineSales.ais platform, retailers activate and delight 10x more Brands by offering an omni-channel media buying experience, advanced targeting, analytics & 2x better ROAS. Tier 1 Retailers and Marketplaces globally are accelerating their Monetization strategy with OnlineSales.ai and are innovating ahead of the market by at least 2 years.\n\nAbout the Role\nWe are seeking a talented and motivated individual to join our team as a Senior Data Analyst who will be responsible for extracting insights from complex datasets to drive informed decision-making and enhance business performance. You will collaborate closely with cross-functional teams to identify key metrics, develop data-driven strategies, and provide actionable recommendations. Additional responsibilities may include managing daily regulatory reporting tasks and remediation activities, as well as process improvement.\n\nWhat will you do @OnlineSales?\nData Analysis: Utilize advanced analytical techniques to explore large datasets, identify trends, patterns, and anomalies, and extract actionable insights.\nData Visualization: Create visually compelling dashboards and reports to communicate findings effectively to stakeholders, enabling them to make informed decisions.\nData Extraction: regular extraction of relevant data from internal databases using SQL queries. Design and optimize SQL queries to retrieve specific datasets required for performance analysis and reporting\nIssue Identification: Proactively identify performance-related issues by monitoring key performance indicators (KPIs), analyzing trends, and investigating anomalies reported by internal stakeholders or external clients.\nAddressing Client Exceptions and Issues: Responsively address performance-related exceptions and issues raised by clients, ensuring timely resolution and effective communication throughout the process. Collaborate with client-facing teams to understand client requirements, prioritize tasks, and deliver solutions that meet or exceed client expectations.\nRoot Cause Analysis: Dive deep into data to understand the root causes of performance issues, considering factors such as system architecture, infrastructure, code efficiency, and user behavior.\nHypothesis Testing: Apply hypothesis testing techniques to validate assumptions and identify statistically significant factors impacting performance.\nDocumentation and SOP Creation: Create clear and detailed Standard Operating Procedures (SOPs) outlining the process for diagnosing, troubleshooting, and resolving performance issues. Ensure that documentation is organized, easily accessible, and regularly updated to reflect changes in systems, processes, or configurations.\nCross-Functional Collaboration: Collaborate with teams across the organization, including business development, marketing, product development and operations, to understand their data needs and provide analytical support\n\nYou will be a great fit, if you have :\n2-4 years of relevant experience.\nBachelors or Masters degree in Computer Science, Engineering, or a related technical field.\nProficiency in SQL for data extraction and manipulation from relational databases.\nFamiliarity with programming languages such as Python for Data Analysis and Data modeling is a plus.\nStrong analytical skills with the ability to interpret complex datasets and draw meaningful insights.\nStrong problem-solving abilities with a proactive approach to troubleshooting and issue resolution.\nAdvanced proficiency in Excel and adept data manipulation skills for efficient analysis and visualization of large datasets.\nEffective communication and interpersonal skills for collaboration with cross-functional teams and stakeholders.\nUnderstanding of E-Commerce as a domain.\nExcellent documentation skills with the ability to create clear and comprehensive reports and SOPs.\nAttention to detail and commitment to data accuracy and quality. Willingness to work for a startup.\n\nWhy Online Sales.ai?\nStartup-y . We believe Startup is a mindset. It s about being scrappy, being nimble, solving tough problems with constrained resources, and more. It s about working hard and playing hard\nEnterprise SaaS . Opportunity to work with an Enterprise Product SaaS firm with aspirations of growing 10x across the globe\nAI-led Retail Tech . We are working to digitize & democratize one of the most exciting and growing verticals - Retail Tech leveraging data, machine learning, and automation (culmination of ad-tech, mar-tech, and analytics for Retail vertical)\nMeaningful work . This is not just a job. You can find a job anywhere. This is a place for the bold to get paid who make a real impact on business\nNo red tape . Say goodbye to pointless meetings or political hoops to jump through. We re scrappy, believe in autonomy, and empower our teams to do whatever it takes to do the unthinkable\nProblem Solving . We ignite the best in you. We exist not only to deliver meaningful innovation but to ignite and inspire the creative problem-solver in you\nQuirky & fun . Enjoy new skills and hobbies like being a quiz master, playing board games, trying your hands on percussion, playing Djembe, and spreading love within the org!",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Data modeling', 'Process improvement', 'Online sales', 'Troubleshooting', 'Analytics', 'Monitoring', 'SQL', 'Data extraction']",2025-06-12 14:04:09
Senior Data Management Analyst,Wells Fargo,4 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst in Corporate and Investment Banking ('CIB') to join the Applications Controls Execution & Services team, a subunit of the CIB Data Management organization.\nThe Application Controls Execution & Services team partners and supports CIB's wide network of Application Business Owners (ABO's) with identification, interpretation and/or implementation of governance processes or controls used to mitigate various compliance, operational, or data related risks.",,,,"['Data Management', 'Project Management', 'financial services management', 'operational risk', 'Analytics', 'business support', 'Business Analysis']",2025-06-12 14:04:11
"Senior Manager- Middle and Back Office Data Analyst- ISS,",Fidelity International,10 - 15 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Title: Middle and Back Office Data Analyst - ISS Data (Senior Manager)\nDepartment: Technology\nLocation: Bangalore & Gurgaon (hybrid / flexible working permitted)\nReports To: Middle and Back Office Data Product Owner\nLevel: Senior Manager\nWe re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our [insert name of team/ business area] team and feel like you re part of something bigger.\nAbout your team\nThe Technology function provides IT services that are integral to running an efficient run-the business operating model and providing change-driven solutions to meet outcomes that deliver on our business strategy. These include the development and support of business applications that underpin our revenue, operational, compliance, finance, legal, marketing and customer service functions. The broader organisation incorporates Infrastructure services that the firm relies on to operate on a day-to-day basis including data centre, networks, proximity services, security, voice, incident management and remediation.\nThe ISS Technology group is responsible for providing Technology solutions to the Investment Solutions & Services (ISS) business (which covers Investment Management, Asset Management Operations & Distribution business units globally)\n\nThe ISS Technology team supports and enhances existing applications as well as designs, builds and procures new solutions to meet requirements and enable the evolving business strategy.\nAs part of this group, a dedicated ISS Data Programme team has been mobilised as a key foundational programme to support the execution of the overarching ISS strategy.\nAbout your role\nThe Middle and Back Office Data Analyst role is instrumental in the creation and execution of a future state design for Fund Servicing & Oversight data across Fidelity s key business areas. The successful candidate will have an in- depth knowledge of data domains that represent Middle and Back-office operations and technology.\nThe role will sit within the ISS Delivery Data Analysis chapter and fully aligned to deliver Fidelity s cross functional ISS Data Programme in Technology, and the candidate will leverage their extensive industry knowledge to build a future state platform in collaboration with Business Architecture, Data Architecture, and business stakeholders.\nThe role is to maintain strong relationships with the various business contacts to ensure a superior service to our clients.\nData Product - Requirements Definition and Delivery of Data Outcomes\nAnalysis of data product requirements to enable business outcomes, contributing to the data product roadmap\nCapture both functional and non-functional data requirements considering the data product and consumers perspectives.\nConduct workshops with both the business and tech stakeholders for requirements gathering, elicitation and walk throughs.\nResponsible for the definition of data requirements, epics and stories within the product backlog and providing analysis support throughout the SDLC.\nResponsible for supporting the UAT cycles, attaining business sign off on outcomes being delivered\nData Quality and Integrity:\nDefine data quality use cases for all the required data sets and contribute to the technical frameworks of data quality.\nAlign the functional solution with the best practice data architecture & engineering principles.\nCoordination and Communication:\nExcellent communication skills to influence technology and business stakeholders globally, attaining alignment and sign off on the requirements.\nCoordinate with internal and external stakeholders to communicate data product deliveries and the change impact to the operating model.\nAn advocate for the ISS Data Programme.\nCollaborate closely with Data Governance, Business Architecture, and Data owners etc.\nConduct workshops within the scrum teams and across business teams, effectively document the minutes and drive the actions.\nAbout you\nAt least 10 years of proven experience as a business/technical/data analyst within technology and/or business changes within the financial services /asset management industry.\nMinimum 5 years as a senior business/technical/data analyst adhering to agile methodology, delivering data solutions using industry leading data platforms such as Snowflake, State Street Alpha Data, Refinitiv Eikon, SimCorp Dimension, BlackRock Aladdin, FactSet etc.\nProven experience. of delivering data driven business outcomes using industry leading data platforms such as Snowflake.\nExcellent knowledge of data life cycle that drives Middle and Back Office capabilities such as trade execution, matching, confirmation, trade settlement, record keeping, accounting, fund & cash positions, custody, collaterals/margin movements, corporate actions , derivations and calculations such as holiday handling, portfolio turnover rates, funds of funds look through .\nIn Depth expertise in data and calculations across the investment industry covering the below.\nAsset-specific data: This includes data related to financial instruments reference data like asset specifications, maintenance records, usage history, and depreciation schedules.\nMarket data: This includes data like security prices, exchange rates, index constituents and licensing restrictions on them.\nABOR & IBOR data: This includes calculation engines covering input data sets, calculations and treatment of various instruments for ABOR and IBOR data leveraging platforms such as Simcorp, Neoxam, Invest1, Charles River, Aladdin etc. Knowledge of TPAs, how data can be structured in a unified way from heterogenous structures.\nShould possess Problem Solving, Attention to detail, Critical thinking.\nTechnical Skills: Excellent hands-on SQL, Advanced Excel, Python, ML (optional) and proven experience and knowledge of data solutions.\nKnowledge of data management, data governance, and data engineering practices\nHands on experience on data modelling techniques such as dimensional, data vault etc.\nWillingness to own and drive things, collaboration across business and tech stakeholders.\nFeel rewarded",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['IT services', 'Data analysis', 'Data management', 'Incident management', 'Scrum', 'Customer service', 'Asset management', 'SDLC', 'SQL', 'Python']",2025-06-12 14:04:13
Senior Financial Data Analyst,Simcorp,4 - 5 years,Not Disclosed,['Noida'],"Financial Analyst WHAT MAKES US, US Join some of the most innovative thinkers in FinTech as we lead the evolution of financial technology. If you are an innovative, curious, collaborative person who embraces challenges and wants to grow, learn and pursue outcomes with our prestigious financial clients, say Hello to SimCorp! At its foundation, SimCorp is guided by our values caring, customer success-driven, collaborative, curious, and courageous. Our people-centered organization focuses on skills development, relationship building, and client success. We take pride in cultivating an environment where all team members can grow, feel heard, valued, and empowered. If you like what we re saying, keep reading!\nWHY THIS ROLE IS IMPORTANT TO US\nThe Financial Data Operator is responsible to perform the collection, composition, control and distribution of market and master data for financial instruments (Equities, Funds, Fixed Income, ABTS/MBS, OTS Derivatives, etc.) for various SimCorp clients and in accordance of the effective SLA agreements.\nFurthermore, this role is responsible for answering client questions and conduct all necessary data analyses of financial instruments data to resolve service delivery incidents to continue service delivery. The role is also responsible to adhere to all relevant operational risk as well as data governance and quality frameworks.\nEventually, this role also requires demonstrating very client-focused mindset, substantial know- how of financial instruments (such as Equities, Fixed Income, ABS/MBS, etc.) and provide coaching to other members.\nWHAT YOU WILL BE RESPONSIBLE FOR\nPerforms all daily service deliverables in terms of collecting, composing, controlling, and distributing financial instrument data according to effective client SLAs\nExecution of all quality checks part of the service scope and strict adherence to existing runbook(s) as well as data quality and governance frameworks and conduct first data analysis in case of unexpected data behavior\nResolve all data questions, service requests and requested audit support raised by clients in a timely and professional manner to ensure customer satisfaction and SLA compliance\nPerform all necessary tasks to comply existing operational risk frameworks (e.g., Sarbanes- Oxley Act (SOX), Risk and Control Engine (RACE) etc.)\nEfficiently support and contribute to continuous improvement of operational processes (with predominant focus on manual processes, high-risk areas), data quality checks and system functionality\nWork with local/regional clients to identify specific requirements, special data treatment or any other client demands which need to be delivered as part of the service scope\nExperience working cross-organizationally with both Business and Technology groups.\nPerform continuous know-how exchange between the different Data Operations teams in terms of processes, incidents, documentation, or other open topics to avoid know-how silos/gaps and assure service level consistency\nMonitor and report any kind of issues along the data supply chain including but not limited to interface issues, missing data files or interrupted business processes and trigger the necessary resolution processes to ensure service delivery continuation\nMaintain documentation in terms of business processes, functional descriptions, operational runbooks, or other manuals to ensure information transparency and enable know-how transfers\nWHAT WE VALUE\nFor the Financial Analyst position, we value\nMUST HAVE:\nExperience with data vendor feeds (Bloomberg, IDC, Reuters, etc.) and display products, 4- 5 years\nDeep knowledge of traditional and non-traditional financial instruments and markets including structured securities, Swaps, especially complex instruments like ABS/MBS, index linked bonds, and syndicated loans.\nBachelor s degree or equivalent in finance or engineering\nSolving master and reference data issues based on exception handling, 4-5 years\nExperience of data integration on any EDM platform, 4-5 years\nApplying operational data management and data governance, 2-3 years\nProcess design and engineering experience, 2-3 years\nExperience with service request systems or any other similar ticketing tool, like HPALM, Service Now Salesforce, etc., 4-5 years\nGOOD TO HAVE:\nAbility to troubleshoot technical glitches in existing data process and coordinate with Technology team to resolve.\nExperience in developing process automation, improvements, and streamlining using tools like KNIME, Alteryx, Excel VBA with scripting on programming language such as Python, PowerShell including intermediate knowledge of SQL",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Loans', 'Data analysis', 'Ticketing', 'Data management', 'Operational risk', 'Bloomberg', 'Fixed income', 'SQL', 'Auditing']",2025-06-12 14:04:16
"Sr. Data Analyst – Tableau, SQL, Snowflake",Int9 Solutions,5 - 7 years,Not Disclosed,['Bengaluru'],"We are looking for a skilled Data Analyst with excellent communication skills and deep expertise in SQL, Tableau, and modern data warehousing technologies. This role involves designing data models, building insightful dashboards, ensuring data quality, and extracting meaningful insights from large datasets to support strategic business decisions.\n\nKey Responsibilities:\nWrite advanced SQL queries to retrieve and manipulate data from cloud data warehouses such as Snowflake, Redshift, or BigQuery.\nDesign and develop data models that support analytics and reporting needs.\nBuild dynamic, interactive dashboards and reports using tools like Tableau, Looker, or Domo.\nPerform advanced analytics techniques including cohort analysis, time series analysis, scenario analysis, and predictive analytics.\nValidate data accuracy and perform thorough data QA to ensure high-quality output.\nInvestigate and troubleshoot data issues; perform root cause analysis in collaboration with BI or data engineering teams.\nCommunicate analytical insights clearly and effectively to stakeholders.\n\nRequired Skills & Qualifications:\nExcellent communication skills are mandatory for this role.\n5+ years of experience in data analytics, BI analytics, or BI engineering roles.\nExpert-level skills in SQL, with experience writing complex queries and building views.\nProven experience using data visualization tools like Tableau, Looker, or Domo.\nStrong understanding of data modeling principles and best practices.\nHands-on experience working with cloud data warehouses such as Snowflake, Redshift, BigQuery, SQL Server, or Oracle.\nIntermediate-level proficiency with spreadsheet tools like Excel, Google Sheets, or Power BI, including functions, pivots, and lookups.\nBachelor's or advanced degree in a relevant field such as Data Science, Computer Science, Statistics, Mathematics, or Information Systems.\nAbility to collaborate with cross-functional teams, including BI engineers, to optimize reporting solutions.\nExperience in handling large-scale enterprise data environments.\nFamiliarity with data governance, data cataloging, and metadata management tools (a plus but not required).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Tableau', 'Data Warehousing', 'Data Analytics', 'SQL', 'Scenario Analysis', 'Cohort Analysis', 'Data Modeling', 'Predictive Analysis', 'Redshift']",2025-06-12 14:04:18
"Sr. Data Analyst – Tableau, SQL, Snowflake",Int9 Solutions,5 - 10 years,Not Disclosed,"['Mumbai', 'Delhi / NCR', 'Bengaluru']","We are looking for a skilled Data Analyst with excellent communication skills and deep expertise in SQL, Tableau, and modern data warehousing technologies. This role involves designing data models, building insightful dashboards, ensuring data quality, and extracting meaningful insights from large datasets to support strategic business decisions.\n\nKey Responsibilities:\nWrite advanced SQL queries to retrieve and manipulate data from cloud data warehouses such as Snowflake, Redshift, or BigQuery.\nDesign and develop data models that support analytics and reporting needs.\nBuild dynamic, interactive dashboards and reports using tools like Tableau, Looker, or Domo.\nPerform advanced analytics techniques including cohort analysis, time series analysis, scenario analysis, and predictive analytics.\nValidate data accuracy and perform thorough data QA to ensure high-quality output.\nInvestigate and troubleshoot data issues; perform root cause analysis in collaboration with BI or data engineering teams.\nCommunicate analytical insights clearly and effectively to stakeholders.\n\nRequired Skills & Qualifications:\nExcellent communication skills are mandatory for this role.\n5+ years of experience in data analytics, BI analytics, or BI engineering roles.\nExpert-level skills in SQL, with experience writing complex queries and building views.\nProven experience using data visualization tools like Tableau, Looker, or Domo.\nStrong understanding of data modeling principles and best practices.\nHands-on experience working with cloud data warehouses such as Snowflake, Redshift, BigQuery, SQL Server, or Oracle.\nIntermediate-level proficiency with spreadsheet tools like Excel, Google Sheets, or Power BI, including functions, pivots, and lookups.\nBachelor's or advanced degree in a relevant field such as Data Science, Computer Science, Statistics, Mathematics, or Information Systems.\nAbility to collaborate with cross-functional teams, including BI engineers, to optimize reporting solutions.\nExperience in handling large-scale enterprise data environments.\nFamiliarity with data governance, data cataloging, and metadata management tools (a plus but not required).\nLocation : - Mumbai, Delhi / NCR, Bengaluru , Kolkata, Chennai, Hyderabad, Ahmedabad, Pune, Remote",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Tableau', 'SQL', 'BI Tools', 'Scenario Analysis', 'Cohort Analysis', 'Data Warehousing', 'SQL Server', 'Data Modeling', 'Data Analytics', 'Predictive Analysis', 'Redshift']",2025-06-12 14:04:20
Sr Analyst I Data Engineering,DXC Technology,9 - 12 years,Not Disclosed,['Hyderabad'],"Job Description:\nEssential Job Functions:\nParticipate in data engineering tasks, including data processing and integration activities.\nAssist in the development and maintenance of data pipelines.\nCollaborate with team members to collect, process, and store data.\nContribute to data quality assurance efforts and adherence to data standards.\nUse data engineering tools and techniques to analyze and generate insights from data.\nCollaborate with data engineers and other analysts on data-related projects.\nSeek out opportunities to enhance data engineering skills and domain knowledge.\nStay informed about data engineering trends and best practices.\n\nBasic Qualifications:\nBachelors degree in a relevant field or equivalent combination of education and experience\nTypically, 5+ years of relevant work experience in industry, with a minimum of 2 years in a similar role\nProven experience in data engineering\nProficiencies in data engineering tools and technologies\nA continuous learner that stays abreast with industry knowledge and technology\n\nOther Qualifications:\nAdvanced degree in a relevant field a plus\nRelevant certifications, such as Oracle Certified Professional, MySQL Database Administrator a plus\nRecruitment fraud is a scheme in which fictitious job opportunities are offered to job seekers typically through online services, such as false websites, or through unsolicited emails claiming to be from the company. These emails may request recipients to provide personal information or to make payments as part of their illegitimate recruiting process. DXC does not make offers of employment via social media networks and DXC never asks for any money or payments from applicants at any point in the recruitment process, nor ask a job seeker to purchase IT or other equipment on our behalf. More information on employment scams is available here .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Usage', 'Manager Quality Assurance', 'Senior Analyst', 'Social media', 'Manager Technology', 'Data processing', 'Data quality', 'Oracle', 'mysql database administrator', 'Recruitment']",2025-06-12 14:04:23
Senior Data Engineering Analyst,Optum,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Description\n\nExperience 4 to 7 years.\nExperience in any ETL tools [e.g. DataStage] with implementation experience in large Data Warehouse\nProficiency in programming languages such as Python etc.\nExperience with data warehousing solutions (e.g., Snowflake, Redshift) and big data technologies (e.g., Hadoop, Spark).\nStrong knowledge of SQL and database management systems.\nFamiliarity with cloud platforms (e.g., AWS, Azure, GCP) and data pipeline orchestration tools (e.g. Airflow).\nProven ability to lead and develop high-performing teams, with excellent communication and interpersonal skills.\nStrong analytical and problem-solving abilities, with a focus on delivering actionable insights.\nResponsibilities\nDesign, develop, and maintain advanced data pipelines and ETL processes using niche technologies.\nCollaborate with cross-functional teams to understand complex data requirements and deliver tailored solutions.\nEnsure data quality and integrity by implementing robust data validation and monitoring processes.\nOptimize data systems for performance, scalability, and reliability.\nDevelop comprehensive documentation for data engineering processes and systems.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ETL', 'SQL', 'Python', 'Azure', 'Datastage', 'Snowflake', 'Ab Initio', 'Informatica', 'Teradata', 'AWS']",2025-06-12 14:04:25
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Bengaluru'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nChennai\nData Engineer with Neo4j\nData Science\nIndia\nGurugram\nBusiness Analyst\nData Science\nPoland\nRemote Poland\nBengaluru, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Bengaluru\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:04:27
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Gurugram'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nChennai\nData Engineer with Neo4j\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nGurugram, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:04:29
Senior Flexera Data Analyst,Luxoft,6 - 11 years,Not Disclosed,['Chennai'],"Internal Data Structures & Modeling\nDesign, maintain, and optimize internal data models and structures within the Flexera environment.\nMap business asset data to Flexeras normalized software models with precision and accuracy.\nEnsure accurate data classification, enrichment, and normalization to support software lifecycle tracking.\nPartner with infrastructure, operations, and IT teams to ingest and reconcile data from various internal systems.\nReporting & Analytics\nDesign and maintain reports and dashboards in Flexera or via external BI tools such as Power BI or Tableau.\nProvide analytical insights on software usage, compliance, licensing, optimization, and risk exposure.\nAutomate recurring reporting processes and ensure timely delivery to business stakeholders.\nWork closely with business users to gather requirements and translate them into meaningful reports and visualizations.\nAutomated Data Feeds & API Integrations\nDevelop and support automated data feeds using Flexera REST/SOAP APIs.\nIntegrate Flexera with enterprise tools (e.g., CMDB, SCCM, ServiceNow, ERP) to ensure reliable and consistent data flow.\nMonitor, troubleshoot, and resolve issues related to data extracts and API communication.\nImplement robust logging, alerting, and exception handling for integration pipelines.\nSkills\nMust have\nMinimum 6+ years of working with Flexera or similar software.\nFlexera Expertise: Strong hands-on experience with Flexera One, FlexNet Manager Suite, or similar tools.\nTechnical Skills:\nProficient in REST/SOAP API development and integration.\nStrong SQL skills and familiarity with data transformation/normalization concepts.\nExperience using reporting tools like Power BI, Tableau, or Excel for data visualization.\nFamiliarity with enterprise systems such as SCCM, ServiceNow, ERP, CMDBs, etc.\nProcess & Problem Solving:\nStrong analytical and troubleshooting skills for data inconsistencies and API failures.\nUnderstanding of license models, software contracts, and compliance requirements.\nNice to have\nSoft Skills: Excellent communication skills to translate technical data into business insights.\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nData Engineer with Neo4j\nData Science\nIndia\nGurugram\nData Engineer with Neo4j\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nChennai, India\nReq. VR-114544\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114544\nApply for Senior Flexera Data Analyst in Chennai\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ERP', 'neo4j', 'Analytical', 'Data structures', 'data visualization', 'SCCM', 'Licensing', 'Analytics', 'Reporting tools', 'SQL']",2025-06-12 14:04:31
Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures\nIdentify data quality metrics and execute data quality audits to benchmark the state of data quality",,,,"['Data Management', 'Project Management', 'Data Analytics', 'Data Governance', 'Business Analysis']",2025-06-12 14:04:34
Business Analyst - Data Warehouse,Vichara Technologies,6 - 11 years,30-35 Lacs P.A.,"['Coimbatore', 'Bengaluru', 'Delhi / NCR']","Collaborate with business stakeholders to gather and validate requirements\nCreate and manage Jira tickets\nSupport sprint planning, backlog grooming\nCreate clear, structured requirements documentation and user stories\n\nRequired Candidate profile\nExperience in analytics, business intelligence, or data warehouse projects (Snowflake, Power BI, Streamlit\nWorking knowledge of Jira\nknowledge in Alternative Asset Management or Investment Banking.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Investment Banking', 'Power Bi', 'User Stories', 'Business Analysis', 'Snowflake', 'python', 'streamlit', 'JIRA', 'SQL', 'Capital Market', 'Hedge Funds', 'Private Equity', 'Credit', 'Private Debt', 'MDM', 'Asset Management', 'Data Warehousing']",2025-06-12 14:04:36
Associate Data Analyst- Contractual,Windows Consultants Pvt Ltd,4 - 8 years,Not Disclosed,['Gurugram'],"Job Title: Data Analytics Associate Finance Team\nContractual Role- 1 year\nWe are seeking a Data Analytics Associate to join our Finance team. This role is ideal\nfor an analytical thinker with a passion for data-driven insights and business\nperformance analysis.\nKey Responsibilities:\n• Collect, clean, and maintain datasets from multiple sources (sales, operations,\ncustomer data).\n• Ensure data accuracy and integrity across various platforms.\n• Assist in developing dashboards and reports to support business decision-\nmaking.\n• Analyze sales trends, inventory levels, and operational performance to\nprovide actionable insights.\n• Support in monitoring the effectiveness of marketing campaigns,\npromotions, and pricing strategies.\n• Utilize tools like Excel, SQL, Tableau, and Power BI to interpret data.\n• Collaborate with cross-functional teams (Marketing, Operations, Finance) to\nalign analytics initiatives with business objectives.\n• Identify operational inefficiencies and suggest improvements based on data\nanalysis.\n• Assist in automating and optimizing reporting processes to improve efficiency.\nWhat Were Looking For:\n• 1+ year of experience in data analytics, business intelligence, or financial\nanalytics.\n• Proficiency in Excel, SQL, Power BI (knowledge of Python/R is a plus).\n• Strong analytical skills with the ability to interpret complex datasets and\ngenerate insights.\n• A proactive and detail-oriented mindset with a problem-solving approach.\n• Strong communication skills to present findings in a clear and concise manner.\n• Ability to work collaboratively across teams and contribute to data-driven\ndecision-making.",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'R', 'Power Bi', 'Tableau', 'Dashboards', 'Python']",2025-06-12 14:04:38
Data Analyst Rights Management Claims,Straive,1 - 3 years,Not Disclosed,[],"Overview\n\nAs a Conflicts Coordinator, you will oversee the resolution of rights conflicts for the client audio and video catalog on various platforms while adhering to strict project deadlines. You will also aid in the development of new projects and processes to proactively free up revenue for our clients and will be responsible for frequently communicating with stakeholders internally and externally, including label management, 3rd party rightsholders, and platform contacts.",,,,"['Google Sheets', 'Excel', 'Complex Data Management', 'Advanced Excel', 'SQL', 'Spreadsheets', 'Data Management']",2025-06-12 14:04:40
Lead Data Analyst Walk IN - Gurgaon,Mascot E Services,6 - 10 years,12-22 Lacs P.A.,['Gurugram'],"- Python & SQL, Statistical analysis\n- Tableau & Power BI\n- HYBRID - 3 - 4 days in Office\n\nF2F WALK IN DRIVE in Gurgaon - 14-June\n\nConnect with *ANUJ - 8249759636* for further details",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'SQL', 'Power Bi', 'Tableau']",2025-06-12 14:04:42
Client Reference Data Analyst,Quantum Leap Consulting,2 - 3 years,3.5-4.5 Lacs P.A.,['Mumbai'],"Job Title: Client Reference Data Analyst\nWork Location: Mumbai\nEmployment Type: 1-Year Contract\nShift Timing: 12:30 PM 9:30 PM IST\nExperience Required: 2+ years\nNotice Period: Immediate\nLaptop Provided: Yes, if needed\nCompensation: Up to 5 LPA\nAbout the Role:\nWe are hiring a Client Reference Data Analyst to join the operations team of a leading global financial services firm. This role involves managing client data, setting up new accounts, and ensuring documentation and reporting accuracy. The role is ideal for professionals who are organized, detail-oriented, and familiar with financial data operations or client onboarding processes.\nKey Responsibilities:\nOpen and link client accounts on financial platforms such as Prime Brokerage or Portfolio Accounting systems.\nSet up account-level reporting and entitlements for clients and third-party users.\nReview and validate documentation submitted for account and reporting setup.\nPerform quality checks for newly created or modified client accounts.\nRequest and manage secure login credentials (e.g., Secure IDs) for client systems access.\nTrack and resolve issues related to account setup, data integrity, and documentation.\nCoordinate with internal teams for issue escalation and workflow alignment.\nMonitor key metrics and Service Level Agreements (SLAs) to ensure timely and accurate delivery.\nIdentify areas for process improvement and assist in implementing solutions.\nSupport team leads with rollout of new tools, processes, or reporting templates.\nMust-Have Skills:\nMinimum 2 years of experience in client onboarding, client data management, or financial operations.\nStrong knowledge of account creation and entitlements setup in financial or investment platforms.\nExcellent skills in Microsoft Excel including Pivot Tables, VLOOKUP, and data reporting.\nExposure to client documentation handling, preferably in the capital markets or banking domain.\nStrong problem-solving skills and ability to escalate with context and ownership.\nExperience in managing high volumes with precision under tight timelines.\nGood verbal and written communication skills to liaise with internal stakeholders.\nGood-to-Have:\nExposure to prime brokerage, reference data, or investment banking operations.\nFamiliarity with global markets, client reporting, or capital market products.\nPrior experience in a client-facing or middle office support role in BFSI.\nSoft Skills Required:\nHigh attention to detail and accuracy\nAdaptability and willingness to learn\nAbility to prioritize tasks effectively\nCollaborative team player\nClient service orientation and ownership\nProfessional and proactive communication",Industry Type: IT Services & Consulting,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Client onboarding', 'Data Management', 'Stakeholder management', 'reference data', 'Account opening']",2025-06-12 14:04:44
AVP Data Management Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Agile Methodology', 'Funds Transfer Pricing', 'Financial Data Mapping', 'Big Data Query Techniques', 'Lineage Tracing', 'Data warehousing', 'Data Governance', 'Jira', 'Market Risks', 'SQL']",2025-06-12 14:04:47
"Senior Analyst, Data and Product Solution",NOVARTIS,1 - 3 years,Not Disclosed,['Hyderabad'],"Summary\nNovartis specialists within Data and Product Solutions are on a data and digital transformation journey, leveraging analytics to generate actionable insights for Novartis medicines impacting more than 799 million patients worldwide. The team is poised to enable easier, faster, and reliable decisions for Novartis divisions across the globe.\nAbout the Role\nLocation - Hyderabad #Hybrid\nAbout the role:",,,,"['Analytical', 'Pharma', 'Diversity and Inclusion', 'Market research', 'Project planning', 'healthcare analytics', 'Stakeholder management', 'digital transformation', 'SQL', 'Python']",2025-06-12 14:04:49
Business Analyst/ Data Scientist - SAS & SQL,Khushboo,3 - 8 years,10-20 Lacs P.A.,['Hyderabad'],"hands on SQL/ SAS programming experience & handling complex/large data\nMust have experience inTableau/Power BI\nExperience in campaign performance measurement, customer targeting framework\nProven ability to design and lead strategic projects\n\nRequired Candidate profile\nMust - SAS , SQL, Python\nGood in Statistical model , Predictive model, Logistic regression, Linear regression\nBFSI Mandatory - Credit risk, Credit Card, Retail Banking",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Decision Tree', 'sas', 'sql', 'Advanced Analytics', 'Strategy Building', 'Predictive Modeling', 'python', 'Logistic Regression', 'Segmentation', 'Random Forest', 'Linear Regression', 'Classification', 'Statistical Modeling', 'Credit Risk']",2025-06-12 14:04:52
"Medical Data Analyst (Pharmacovigilance, Medical Summarization)",Ardem Data Services,1 - 5 years,Not Disclosed,[],"Shift Timings: 10:00 PM to 7:00 AM\nNight Shift experience mandatory\n\nWe are seeking a Medical Data Entry professional with a minimum of 1 year of experience in medical data annotation and document review. The ideal candidate will have a background in medical or pharmaceutical sciences and possess key skills related to medical data management, regulatory guidelines (FDA, EMA, ICH, GCP), and patient report handling. This role requires mandatory night shift experience and is a permanent work-from-home position.\nKey Responsibilities:\nReview and annotate medical documents and patient records accurately.\nApply knowledge of FDA, EMA, ICH, and GCP guidelines to data management tasks.\nPerform clinical data management activities.\nHandle and process patient reports efficiently.\nEnsure data quality and integrity during the entry and annotation process.\nRequirements:\nQualification: B.Sc, M.Sc, B.Pharma, or M.Pharma.\nMinimum 1 year of experience in medical data annotation and medical document review.\nMandatory experience working night shifts (US shift: 10:00 pm to 7:00 am).\nExperience with FDA, EMA, ICH, and GCP guidelines.\nProficiency in Clinical Data Management and handling Patient Reports.\nOnly candidates with a medical background and medical data annotation experience will be considered.\nImmediate joiner preferred.\nTechnical Requirements:\nLaptop or Desktop: Windows (i5 or higher, 8GB RAM minimum)\nScreen: 14 inches, Full HD (19201080)\nInternet Speed: 100 Mbps or higher\nAbout ARDEM\nARDEM is a leading Business Process Outsourcing and Business Process Automation service provider. For over twenty years, ARDEM has successfully delivered business process outsourcing and business process automation services to our clients in the USA and Canada. We are growing rapidly. We are constantly innovating to become a better service provider for our customers. We continuously strive for excellence to become the Best Business Process Outsourcing and Business Process Automation company.\nNOTE!\nARDEM will never ask for any personal information or banking information during the hiring process for any data entry/processing type of work. If you are contacted by any party claiming to represent ARDEM Incorporated offering work from home jobs this is fraud. Please disregard and refer to ARDEMs Careers page for all open job positions. We apologize for any inconvenience caused by such acts.",Industry Type: Miscellaneous,Department: Research & Development,"Employment Type: Full Time, Permanent","['US Healthcare', 'Pharmacovigilance', 'Medical Terminology', 'Summarizing', 'Patient reports', 'Electronic Medical Record', 'CPT', 'Medical Records', 'Medical Scribe', 'Medical Data Analyst', 'ICD', 'Medical Summarization', 'Medical Transcription', 'Medical', 'Clinical Data Management', 'Data Annotation']",2025-06-12 14:04:54
Senior Data Management Analyst,Wells Fargo,4 - 8 years,Not Disclosed,['Hyderabad'],"In this role, you will:\nLead or participate in moderately complex programs and initiatives for data quality, governance, and metadata activities\nDesign and conduct moderately complex analysis to identify and remediate data quality, data integrity, process, and control gaps\nAnalyze, assess, and test data controls and data systems to ensure quality and risk compliance standards are met and adhere to data governance standards and procedures",,,,"['Data Management Analysis', 'Project Management', 'Data Management', 'data governance', 'Business Analysis']",2025-06-12 14:04:57
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst. We believe in the power of working together because great ideas can come from anyone. Through collaboration, any employee can have an impact and make a difference for the entire company. Explore opportunities with us for a career in a supportive environment where you can learn and grow. This role requires a blend of technical expertise, analytical thinking, and strategic decision making to drive impactful insights.\nAt Wells Fargo, we are looking for talented people who will put our customers at the center of everything we do. We are seeking candidates who embrace diversity, equity and inclusion in a workplace where everyone feels valued and inspired. Help us build a better Wells Fargo. It all begins with outstanding talent. It all begins with you.",,,,"['Data Management', 'Hive', 'Power BI', 'DB2', 'SQL Server', 'Tableau', 'Oracle', 'Teradata', 'Analytics', 'Python', 'Business Analysis']",2025-06-12 14:04:59
Lead Data Management Analyst,Wells Fargo,5 - 10 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Lead Data Management Analyst\n\nIn this role, you will:\nOrganize and lead complex companywide initiatives to ensure that data quality is maintained so that data can effectively support business processes\nOversee analysis and reporting in support of regulatory requirements",,,,"['Data Management', 'metadata', 'Project Management', 'Teradata', 'Analytics', 'Business Analysis', 'SQL']",2025-06-12 14:05:01
Marketing Data Analyst,Ajni Consulting,5 - 10 years,10-14 Lacs P.A.,['Hyderabad'],"5+ years of experience in data management, marketing operations, sales operations,\n• Familiarity with CRM systems (e.g., Salesforce) and data management tools like\nInterested candidates share on purnima.prometheus@gmail.com or whtsapp 9220927729",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Salesforce', 'tag management', 'Sales Operations', 'Marketing Operations', 'Marketing Analytics', 'Customer Support Operations', 'Adobe Analytics']",2025-06-12 14:05:03
Financial Data Analyst,IPS group,1 - 6 years,3.5-4.5 Lacs P.A.,['Kolkata'],"Qualification: B Com / M.Com /MBA Finance\n\nExperience: Minimum 1 year of experience as a Financial Data Analyst\n\nJob Requirement:\n* Domain / Accounting knowledge and skills\n* Basic understanding of accounting principles and Finance\n* Good verbal and written communication skills\n* Willingness to work in rotational and night shifts\n\nJob Description:-\n* Research, Review, Analyze and Interpret financial statements/Broker reports of large corporates from global markets.\n* Ensure compliance with global policies including US GAAP & IFRS.\n* Capture data points of interest from financial reports and tag the same from Income Statement, Balance Sheet & Cash flow through an application.\n* Transaction based activities, rule-based decision making, verifying for accuracy and completeness, formatting data, posting and preparing output (various types of reconciliations, system to system  reconciliations, balancing, open item management, reports etc)\n* Constant quality check on the finalization of statement.\n* Capture specific figures from Revenue, Net Income, EPS, Weighted Average Shares, Income before tax,\nIncome Tax & One-time charges & provide timely, relevant and accurate information for Earnings.\n* Capture the future estimated data as given in press release, earnings call & company presentation report for Guidance.\n* Number crunching on specific items of the Income Statement, Balance sheet & Cash Flow.\n* Understanding of financial processes and applications",Industry Type: BPM / BPO,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Finance Data Analyst', 'Financial Statements', 'Ifrs Reporting', 'Financial Reporting', 'US GAAP', 'Financial Accounting', 'IFRS']",2025-06-12 14:05:06
EMS Data Analyst (Manual Support),Growexx,3 - 8 years,Not Disclosed,['Ahmedabad'],"EMS Data Analyst (Manual Support) - GrowExx EMS Data Analyst (Manual Support)\nGrowexx is seeking an\nEMS Data Analyst (Manual Support)\nto join our team. The EMS Data Analyst will be responsible for ensuring the accurate and timely import of EMS data into the NEMSIS database. This role involves working with EMS data from various sources, including electronic Patient Care Reports ( ePCRs ) and other EMS data systems. The focus will be on maintaining data quality, troubleshooting issues, and performing manual data entry or manipulation as necessary to ensure data integrity and compliance with NEMSIS standards.\nKey Responsibilities\nMonitor data submissions from EMS agencies and identify any issues with data quality or formatting\nManually review ePCR data to ensure compliance with NEMSIS data standards and identify errors\nPerform data entry and data manipulation tasks as needed to correct errors or format data for import\nWork with EMS agencies to resolve data quality issues and improve data collection practices\nDocument all data entry and quality assurance activities\nImplement and maintain data quality checks and validation processes\nIdentify trends and patterns related to data errors or inconsistencies\nAssist in developing and implementing data quality improvement plans\nAssist in data analysis and generating reports to support quality improvement initiatives and operational decisions\nHelp develop and maintain data dashboards and visualizations\nRespond to data requests from internal and external stakeholders\nMaintain a strong understanding of the NEMSIS data standard and ensure ongoing compliance\nStay updated on NEMSIS changes, updates, and best practices\nAssist with training EMS staff on data collection and NEMSIS requirements\nWork closely with EMS agencies, data managers, and other stakeholders to ensure seamless data flow and data quality\nCommunicate data-related issues and findings effectively to both technical and non-technical audiences\nKey Skills Strong analytical and problem-solving skills Attention to detail and commitment to data accuracy\nProficiency in data manipulation and analysis tools (e.g., Excel, SQL)\nExcellent communication and interpersonal skills\nAbility to work independently and as part of a team\nKnowledge of EMS operations, patient care, and medical terminology is a plus\nEducation and Experience Certification In Healthcare Data Analytics Or Related Field\n3+ years experience With Data Visualization Tools (E.G., Tableau, Power BI)\nExperience In Database Management Analytical and Personal Skills Must have good logical reasoning and analytical skills Ability to break big goals to small incremental actions Excellent Communication and collaboration skills Demonstrate Ownership and Accountability of their work\nGreat attention to details\nDemonstrate ownership of tasks Positive and Cheerful outlook in life Work with the problem solver engineers team (Doc / PDF Only, Max file size 2 MB) By using this form you agree with the storage and handling of your data by this website. *\nYou cannot copy content of this page\nReconciliation Automation Data Sheet\nThis field is for validation purposes and should be left unchanged.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Analytical', 'Reconciliation', 'Data collection', 'Healthcare', 'Troubleshooting', 'Operations', 'Data entry', 'SQL']",2025-06-12 14:05:08
Master Data Analyst Reporting,RK Hr Management,3 - 7 years,8-14 Lacs P.A.,['Ahmedabad'],"3–5 yrs exp in data reconciliations (Catalyst/Keystone to GFIN, GFIN vs HFM), dashboard support (Power BI), audit support, and data governance (MDG). Proactive, Excel-savvy, system-fluent (SAP, HFM, Oracle), with strong analytical and comms skills.",Industry Type: FMCG,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Reconciliation', 'SAP', 'oracle', 'Power BI', 'Data Governance', 'Data Quality', 'Data Management', 'Data Visualization', 'Etl Process', 'Tableau', 'Communication']",2025-06-12 14:05:10
Master Data Analyst- Reporting,Client of RK Hr Management,3 - 8 years,20-30 Lacs P.A.,['Ahmedabad'],"Compare and match data between systems; investigate and fix mismatches.\n\nHelp build dashboards, support audits, and maintain clear documentation.\n\nManage new data entries, ensure accuracy, and oversee smooth data processes.\n\nRequired Candidate profile\n3 to 5 years experience\nExperience of Data Governance and systems related DG\nConfidence in using applications, some systems experience - SAP, HFM, Oracle, Snowflake,\nAutonomy to review and research",Industry Type: FMCG,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Mdg', 'Power BI', 'Master Data Management', 'Data Governance', 'Data Reporting', 'SAP', 'Snowflake', 'Data Cleansing', 'Master data reporting', 'Master Data', 'Oracle', 'HFM']",2025-06-12 14:05:13
Data Science Analyst (Senior),Infogain,6 - 8 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python.\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n- Strong storytelling and communication skills to convey complex analytical findings to both technical and non-technical audiences.\n- Demonstrates ownership and leadership, driving projects from idea to impact with minimal supervision.\nSKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-12 14:05:15
Senior Data Management Analyst,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Data Management Analyst.\n\nIn this role, you will:\nMust have strong experience (SME) in JIRA, Assets, Structure, Confluence, Groovy/Python scripting, Linux, Script Runner.\nIn-depth knowledge of Jira Software, JSM and Confluence administration, configuration, customizations and Automations.",,,,"['Data Management', 'Script Runner', 'Linux', 'Confluence', 'JSM', 'Python scripting', 'Groovy', 'Jira', 'REST APIs']",2025-06-12 14:05:17
Data Management Analyst,Wells Fargo,2 - 6 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Data Management Analyst\n\nIn this role, you will:\nParticipate in less complex analysis to identify and remediate data quality or integrity issues and to identify and remediate process or control gaps\nAdhere to data governance standards and procedures",,,,"['Data Management', 'Project Management', 'data Analysis', 'Data governance', 'Business Analysis']",2025-06-12 14:05:19
Data Scientist,Tesco,1 - 3 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Summary:\n\nEnable data driven decision making across the Tesco business globally by developing analytics solutions using a combination of math, tech and business knowledge\n\nRoles and Responsibilities:\n- Identifying operational improvements and finding solutions by applying CI tools and techniques\n- Responsible for completing tasks and transactions within agreed KPI's",,,,"['Data Science', 'Advanced Excel', 'Data Analytics', 'Python', 'SQL', 'Applied Mathematics', 'Machine Learning', 'Statistics']",2025-06-12 14:05:21
"Data & Analytics Analyst, VP",NatWest Markets,15 - 20 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Join us as a Data & Analytics Analyst\nTake on a new challenge in Data & Analytics and help us shape the future of our business\nYou ll take accountability for the analysis of complex data to identify business issues and opportunities, and supporting the delivery of high quality business solutions\nWere committed to mapping a career path that works for you, with a focus on helping you build new skills and engage with the latest ideas and technologies in data analytics\nWere offering this role at vice president level\nWhat youll do\nAs a Data & Analytics Analyst, you ll be driving the production of high quality analytical input to support the development and implementation of innovative processes and problem resolution. You ll be capturing, validating and documenting business and data requirements, making sure they are in line with key strategic principles.\nWe ll look to you to interrogate, interpret and visualise large volumes of data to identify, support and challenge business opportunities and identify solutions.\nYou ll also be:\nPerforming data extraction, storage, manipulation, processing and analysis\nConducting and supporting options analysis, identifying the most appropriate solution\nAccountable for the full traceability and linkage of business requirements of analytics outputs\nSeeking opportunities to challenge and improve current business processes, ensuring the best result for the customer\nCreating and executing quality assurance at various stages of the project in order to validate the analysis and to ensure data quality, identify data inconsistencies, and resolve as needed\nStrong sense of ownership with a focus on delivering high-quality outcomes\nExceptional attention to detail\nEmphasis on measurable outcomes and impact of work\nExpertise in data analytics and reporting\nThe skills youll need\nYou ll need a background in business analysis tools and techniques, along with the ability to influence through communications tailored to a specific audience. Additionally, you ll need the ability to use core technical skills.\nYou ll also demonstrate:\nClear and effective communication\nProficiency in SQL, and tools such as Excel and Power BI\nExperience in Informatica, Snowflake or others\nResponsible for performance metrics and data solutions across the entire data architecture team\nSkilled in data visualization, report generation and presentation to both technical and business audiences\nOver 15 years of professional experience\nHours\n45\nJob Posting Closing Date:\n23/06/2025",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Manager Quality Assurance', 'Business analysis', 'Analytical', 'Data quality', 'Data analytics', 'Informatica', 'Business solutions', 'SQL', 'Data extraction', 'Data architecture']",2025-06-12 14:05:24
MIS Analyst,Data Marshall,1 - 4 years,Not Disclosed,['Hyderabad'],"Job Description\nThe MIS Analyst plays a crucial role in managing and optimizing the organizations information management system. This position involves pulling up pre-identified reports, validating the content, interpreting and formatting the data into details that provide insight, and sharing it in a timely manner or agreed upon TAT.\nWhat You Will Do: MIS Analyst\nData Management: Pulling, interpreting, processing, reporting, and storing specified data.\nRequirements Translation: Convert business requirements into specifications for reports and dashboards, integrating multiple data sources.\nCollaboration: Work with specialists, leads, and managers to understand reporting needs and develop solutions accordingly.\nStatistical Reporting: Compile, prepare, and present statistical information for both internal and external stakeholders.\nWhat You Will Need:\n\nAdded Advantage\nReporting Tools: Experience with Power BI for reporting and analysis will be an added advantage.\nAutomation: Knowledge of VBA for developing automation scripts using Excel Macros.\nDatabase Development: Familiarity with MS Access for database and application development.\nClient Communication: Ability to communicate effectively with client business lines, leadership teams, and other stakeholders.\nFamiliarity with Python, Power Automate, and Power Apps is a plus. Role & responsibilities\n\n\nPreferred candidate profile\n\nEducation: Bachelors degree\nHealthcare Experience; Minimum 1 year of RCM experience or US Medical Coding Experience.\nMIS Experience: Minimum One year of experience in MIS execution\nTechnical Skills: Proficiency in MS Office applications (Excel, Word, PowerPoint), Proficiency in SQL will be an advantage.\nCommunication: Excellent verbal and written communication skills to facilitate collaboration with internal, external, and customer teams.\nAnalytical Skills: Strong analytical, conceptual, and problem-solving abilities.\nPrioritization: Ability to manage multiple priorities and adapt quickly to changing demands.\nFor more Details Kindly reach out\n\nName: Pagidoju Dhana Laxmi\nContact No: 7995682418\nEmai: dhanalaxmi.pagidoju@datamarshall.com",Industry Type: Analytics / KPO / Research,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent","['Word', 'Excel', 'Excel Powerpoint', 'Power Bi', 'SQL', 'Excel Macros']",2025-06-12 14:05:27
"Data Science Specialist - R/Python, Statistical Analysis, AI/Ml",Cisco,4 - 8 years,Not Disclosed,['Bengaluru'],"Responsibilities:\nAnalysis of cross-customer and customer specific data.\nAnalysis for diagnosis of product and customers specific problems and also to demonstrate value of our data to customers.\nSupport sales and product adoption for data related use-cases (occupancy, captive portal, behavioral metrics, BMS integrations etc)\nHelp design monitoring tools to detect product and customer relative issues around product\nCustomer demonstrations of more sophisticated data products like Firehose. Engineering/Product linkages\nCollaborate with specialist teams to help deliver solutions. (Webex, Meraki etc)\nLeverage on ML based approaches for fault detection tools, for trends and also customer/category analysis\n\nQualifications:\nAdvanced degree or equivalent experience in Engineering, Computer Science, Maths or a related technical field\nProficiency in programming and scripting languagesRand/orPython\nExperience using relational database -SQL\nBasic proficiency withMachine Learning methods and applications\n\nSkills:\nPassion for problem solving.\nHighly driven and customer oriented.\nExcellent communication.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'rest', 'python', 'data analysis', 'natural language processing', 'machine learning', 'relational databases', 'artificial intelligence', 'javascript', 'sql', 'spring', 'r', 'tableau', 'java', 'computer science', 'html', 'mysql', 'data structures', 'data visualization', 'ml', 'statistics']",2025-06-12 14:05:30
Data Management Analyst Mutual Fund & Investment Operations,International IT Companies,3 - 8 years,4.25-6 Lacs P.A.,['Bengaluru'],"Manage process reference data, pricing data, dividends, benchmarks, and fund classification for mutual funds and equity instruments.\nReview key fund-related documents\nFactsheets to extract, validate, and update critical data points.\n\nRequired Candidate profile\nInteract with multiple stakeholders including internal teams and external clients for data quality and operational updates.\nEnsure data accuracy and integrity in all deliverables\n\nPerks and benefits\nPerks and Benefits",Industry Type: BPM / BPO,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Financial Services', 'Mutual Funds', 'Data Management', 'ETFs', 'Investment Operations', 'Fund Documentation', 'Pricing Data', 'Reference Data', 'Investment Management Analyst.', 'Corporate Actions', 'Equity Operations', 'Annual Reports', 'KIIDs', 'Factsheet Review', 'Benchmark Data']",2025-06-12 14:05:32
Scientific Business Analyst (Associate) – ELN,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nThis role involves working closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements scientific software platforms such as Laboratory Information Management Systems (LIMS) that enable the capture of lab workflows & experimental data and Electronic Lab Notebooks (ELN) that act as Amgens System of Record ensuring data integrity and business continuity. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the technology ecosystem for in vivo study data management and ensure that the platform meets their requirements for data analysis and data integrity\nTranslate complex scientific and technological needs into clear, actionable requirements for development teams\nDevelop and maintain a product roadmap that clearly outlines the planned features and enhancements, timelines, and landmarks\nIdentify and manage risks associated with the systems, including technological risks, scientific validation, and user acceptance\nDevelop documentations, communication plans and training plans for end users\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\nCollaborate with geographically dispersed teams, including those in the US and other international locations.\nFoster a culture of collaboration, innovation, and continuous improvement.\n\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nBachelors degree with 0 - 3 years of experience in Life Sciences, Computer Science, IT, Computational Chemistry/Cheminformatics, Computational Biology/Bioinformatics or related field, OR\nDiploma with 4 - 7years of experience in Life Sciences, Computer Science, IT, Computational Chemistry/Cheminformatics, Computational Biology/Bioinformatics or related field, OR\nDemonstrated expertise in a scientific domain area and related technology needs\nExcellent problem-solving skills and a passion for tackling complex challenges in drug discovery with technology and data\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience with Benchling, Revvity, IDBS, or similar LIMS/ELN platforms\nPreferred Qualifications:\nExperience with Agile software development methodologies (Scrum)\nExperience performing or enabling data capture and analysis from instruments in a research laboratory or vivarium\nAbility to communicate technical or complex subject matters in business terms\nKnowledge of business analysis standard processes, DevOps, Continuous Integration, and Continuous Delivery methodology\nExperience with cloud (e.g. AWS) and on-premise infrastructure\nExperience supporting ELN/LIMS platforms in biopharma\n\n\n\nProfessional Certifications:\nSAFe for Teams certification (preferred)\n\n\n\nSoft\n\nSkills:\nAble to work under minimal supervision\nExcellent analytical and gap/fit assessment skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Business Analysis', 'LIMS platforms', 'ELN platforms']",2025-06-12 14:05:34
Analyst - Master Data Management,Danfoss,1 - 3 years,Not Disclosed,"['Oragadam', 'Chennai']","Job Description\nWe are seeking a motivated and detail-oriented Analyst to join our team. The successful candidate will be responsible for material creation/extension in Glasswing, executing mass changes in SAP, improving data quality in collaboration with data stewards, and implementing automation rules to streamline processes.\nJob Responsibilities\n    Material Creation/Extension in Glasswing: Create and extend material records in the Glasswing system, ensuring accuracy and compliance with company standards.\n•    Mass Changes in SAP: Perform mass updates and changes in the SAP system, maintaining data integrity and consistency.\n•    Data Quality Improvement: Collaborate with data stewards to identify and rectify data quality issues, ensuring high standards of data accuracy and reliability.\n•    Automation Rules Implementation: Develop and implement automation rules to enhance efficiency and reduce manual intervention in data management processes.",,,,"['SAP MM', 'MDM', 'Master Data Management', 'SAP MDM']",2025-06-12 14:05:37
Data Science Analyst (Standard),Infogain,3 - 5 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python with minimal supervision\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n  SKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-12 14:05:39
"Sr Business Analyst (Process Modeling, and Stakeholder Collaboration)",Synechron,7 - 12 years,Not Disclosed,"['Pune', 'Hinjewadi']","Job Summary\nSynechron is seeking a highly experienced and detail-oriented Senior Business Analyst to join our dynamic team. In this role, you will serve as a key contributor to our business analysis function, translating complex business needs into effective solutions that support organizational goals. Your expertise will enable our teams to deliver value-driven projects efficiently and effectively, ensuring alignment with strategic objectives and stakeholder expectations.\nSoftware Requirements\nRequired Skills:\nBusiness analysis tools (e.g., Microsoft Visio, (version 2016 or later))\nData analysis and visualization software (e.g., Microsoft Excel - advanced proficiency, tools like Tableau or Power BI)\nRequirement management tools (e.g., Jira, Confluence - recent versions)\nWorkflow and process modeling software (e.g., BPMN tools)\nPreferred Skills:\nBasic understanding of enterprise-level ERP/CRM systems (e.g., SAP, Salesforce)\nKnowledge of project management tools (e.g., Microsoft Project, MS Teams)\nOverall Responsibilities\nGather, analyze, and document business requirements by engaging with stakeholders, ensuring clarity, completeness, and alignment with organizational objectives.\nDevelop detailed functional specifications, use cases, process flows, and user stories to guide development teams and project execution.\nFacilitate communication between business units and technical teams to ensure a mutual understanding of project scope and deliverables.\nSupport project planning, monitoring progress, and ensuring deliverables meet quality standards and deadlines.\nContribute to process improvement initiatives by analyzing current workflows and recommending efficiencies.\nAssist in testing and validating solutions to verify they meet business needs and specifications.\nProvide ongoing support during implementation, including stakeholder training and documentation.\nStrategic Objectives:\nDeliver comprehensive requirements that enable timely and successful project deliveries.\nEnhance stakeholder engagement and satisfaction through clear communication and tailored solutions.\nPromote continuous improvement by identifying opportunities to optimize business processes.\nPerformance Outcomes & Expectations:\nAccurate and comprehensive requirement documentation.\nSuccessful facilitation of collaborative sessions and stakeholder buy-in.\nOn-time delivery of specifications and supporting documentation.\nPositive feedback from stakeholders regarding clarity and usability of deliverables.\nTechnical Skills (By Category)\nProgramming Languages:\nRequired: Basic understanding of scripting or programming concepts (e.g., SQL, Python) is preferred but not mandatory.\nPreferred: None specifically required.\nDatabases/Data Management:\nRequired: Experience with relational databases (e.g., SQL Server, Oracle) and data querying techniques.\nPreferred: Experience with big data tools or NoSQL databases.\nCloud Technologies:\nRequired: Familiarity with cloud platforms (e.g., AWS, Azure) focusing on cloud-based data storage and services.\nPreferred: Certification or practical experience in cloud services.\nFrameworks and Libraries:\nRequired: Understanding of business process frameworks (e.g., BPMN, UML modeling).\nPreferred: Knowledge of agile frameworks like Scrum or Kanban.\nDevelopment Tools & Methodologies:\nRequired: Experience with Agile, Scrum, or Waterfall project methodologies.\nPreferred: Exposure to DevOps practices.\nSecurity Protocols:\nOptional: Basic understanding of data security, compliance, and privacy protocols relevant to business analysis.\nExperience Requirements\nMinimum of 7+ years in business analysis roles within financial services or related industries.\nProven track record of managing complex projects from requirements gathering through implementation.\nExtensive experience in stakeholder engagement, documentation, and process modeling.\nExperience working in diverse regulatory environments and compliance standards is advantageous.\nCandidates with alternative pathways demonstrating equivalent skillssuch as extensive cross-functional project leadershipare encouraged to apply.\nDay-to-Day Activities\nConduct interviews and workshops with stakeholders to elicit detailed business requirements.\nAnalyze existing business processes and document workflows to identify improvement opportunities.\nPrepare functional specifications, use cases, user stories, and process diagrams for project teams.\nCollaborate closely with developers, testers, and project managers in an Agile or traditional setting.\nParticipate in sprint planning, review sessions, and status meetings.\nSupport user acceptance testing (UAT) and assist with issue resolution.\nMaintain clear and organized documentation of requirements, decisions, and project artifacts.\nProvide ongoing communication and updates to stakeholders on project progress.\nDecision-Making Authority & Responsibilities:\nValidate solution approaches against requirements.\nRecommend process improvements and inform implementation strategies.\nEscalate issues related to scope or requirements misalignment to project leadership.\nQualifications\nBachelors degree in Business Administration, Information Systems, Computer Science, or related field.\nRelevant certifications (preferred but not mandatory): CBAP, CCBA, PMI-PBA, or equivalents.\nParticipation in ongoing professional development, such as courses in business analysis, project management, or domain-specific training.\nDemonstrated commitment to continuous learning and adapting industry best practices.\nProfessional Competencies\nStrong analytical and critical thinking skills, with an ability to interpret complex data and business scenarios.\nEffective collaboration and stakeholder management skills across varying levels of the organization.\nExcellent written and verbal communication abilities, ensuring clarity and mutual understanding.\nResilience and adaptability in fast-paced environments, with a proactive approach to problem-solving.\nInnovative mindset, open to leveraging new tools and methods to enhance processes.\nSkilled in prioritizing tasks, managing time efficiently, and meeting deadlines.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Azure', 'Kanban', 'NoSQL', 'Scrum', 'SQL Server', 'Oracle', 'AWS']",2025-06-12 14:05:41
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,8 - 9 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n8 to 9+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-12 14:05:43
Devops AWS DATA Engineeer|| Technical Analyst || 12Lakhs CTC,Robotics Technologies,7 - 9 years,11-12 Lacs P.A.,['Hyderabad( Banjara hills )'],"We are seeking a highly skilled Devops Engineer to join our dynamic development team. In this role, you will be responsible for designing, developing, and maintaining both frontend and backend components of our applications using Devops and associated technologies.\nYou will collaborate with cross-functional teams to deliver robust, scalable, and high-performing software solutions that meet our business needs. The ideal candidate will have a strong background in devops, experience with modern frontend frameworks, and a passion for full-stack development.\n\nRequirements:\nBachelor's degree in Computer Science Engineering, or a related field.\n7 to 9+ years of experience in full-stack development, with a strong focus on DevOps.\n\nDevOps with AWS Data Engineer - Roles & Responsibilities:\nUse AWS services like EC2, VPC, S3, IAM, RDS, and Route 53.\nAutomate infrastructure using Infrastructure as Code (IaC) tools like Terraform or AWS CloudFormation.\nBuild and maintain CI/CD pipelines using tools AWS CodePipeline, Jenkins,GitLab CI/CD.\nCross-Functional Collaboration\nAutomate build, test, and deployment processes for Java applications.\nUse Ansible, Chef, or AWS Systems Manager for managing configurations across environments.\nContainerize Java apps using Docker.\nDeploy and manage containers using Amazon ECS, EKS (Kubernetes), or Fargate.\nMonitoring & Logging using Amazon CloudWatch,Prometheus + Grafana,E\nStack (Elasticsearch, Logstash, Kibana),AWS X-Ray for distributed tracing manage access with IAM roles/policies.\nUse AWS Secrets Manager / Parameter Store for managing credentials.\nEnforce security best practices, encryption, and audits.\nAutomate backups for databases and services using AWS Backup, RDS Snapshots, and S3 lifecycle rules.\nImplement Disaster Recovery (DR) strategies.\nWork closely with development teams to integrate DevOps practices.\nDocument pipelines, architecture, and troubleshooting runbooks.\nMonitor and optimize AWS resource usage.\nUse AWS Cost Explorer, Budgets, and Savings Plans.\n\nMust-Have Skills:\nExperience working on Linux-based infrastructure.\nExcellent understanding of Ruby, Python, Perl, and Java.\nConfiguration and managing databases such as MySQL, Mongo.\nExcellent troubleshooting.\nSelecting and deploying appropriate CI/CD tools\nWorking knowledge of various tools, open-source technologies, and cloud services.\nAwareness of critical concepts in DevOps and Agile principles.\nManaging stakeholders and external interfaces.\nSetting up tools and required infrastructure.\nDefining and setting development, testing, release, update, and support processes for DevOps operation.\nHave the technical skills to review, verify, and validate the software code developed in the project.\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Iac', 'Devops', 'Jenkins', 'AWS', 'Kubernetes', 'RDS', 'Aws Cloudformation', 'Amazon Cloudwatch', 'Prometheus', 'Ci/Cd', 'Grafana', 'DR', 'Cloud Trail', 'Docker', 'IAM', 'Ansible / Chef', 'fargate', 'Gitlab', 'Monitoring', 'Python']",2025-06-12 14:05:45
Data Science Analyst (Lead),Infogain,8 - 11 years,Not Disclosed,['Gurugram'],"- Strong understanding of ML algorithms (regression, classification, clustering) with the ability to independently develop and scale models using Python.\n- Experience in commercial analytics with a knack for translating business problems into analytical solutions and strategic recommendations.\n- Proficient in Power BI to build intuitive dashboards and deliver insights in a clear, actionable format.\n- Strong storytelling and communication skills to convey complex analytical findings to both technical and non-technical audiences.\n- Demonstrates ownership and leadership, driving projects from idea to impact with minimal supervision.\n  SKILLS\nPrimary Skill: Data Science\nSub Skill(s): Data Science\nAdditional Skill(s): Python, Data Science",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analyst', 'Translation', 'data science', 'Analytical', 'power bi', 'Analytics', 'Supervision', 'Python']",2025-06-12 14:05:48
Data Governance & Data Quality Sr Associate Analyst,Amgen Inc,2 - 5 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgen's data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leveragesstate-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. This role involves working closely with business stakeholder and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with Data Product Owners, Data Stewards and technology teams to increase the trust and reuse of data across Amgen.\nRoles & Responsibilities:\nResponsible for the execution of data governance framework for a given domain of expertise (Research, Development, Supply Chain, etc.).\nContribute to the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nContribute to the cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nPartner with business teams to identify compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e.g., MDM, Enterprise Data Fabric, etc.) delivers data foundations.\nBuild strong relationship with key business leads and partners to ensure their needs are met.\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills (Advanced SQL, Python etc) with knowledge of Pharma processes with specialization in a domain (e.g., Research, Clinical Trials, Commercial, etc.)\nExperience of working with or supporting systems used to data governance framework. E.g. Collibra, Alation\nGeneral knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nExperience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nExcellent problem-solving skills and a committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience with Agile software development methodologies (Scrum)\nSoft Skills:\nExcellent analytical skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAbility to build business relationships and understand end-to-end data use and needs.\nStrong verbal and written communication skills\nBasic Qualifications:\nExperience with 5 - 9 years of experience in Business, Engineering, IT or related field",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Governance', 'data quality', 'Collibra', 'data stewardship', 'metadata management', 'Agile software development methodologies', 'Alation', 'data protection', 'master data management', 'SQL', 'Python']",2025-06-12 14:05:50
HIH - Data Science Lead Analyst - Evernorth,ManipalCigna Health Insurance,5 - 8 years,Not Disclosed,['Hyderabad'],"Internal Title: Data Science Lead Analyst\nExternal Title: Data Science Lead Analyst\nRole Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\n\nThe role will support the development and maintenance of machine learning models, with a focus on ensuring that models meet Cigna s requirements for governance and legal compliance. The role will require collaboration with other data scientists and involve work across many lines of business.\nKey Responsibilities:\nAnalyze model performance of new models with specific regards to requirements for legal compliance and governance standards around accuracy and bias;\nPerform periodic analyses of performance of existing models to ensure continued compliance with internal and external standards for accuracy and bias;\nConduct research (i.e. literature review) to understand when bias may be biologically or medically justifiable, and to what degree, for example: finding evidence from literature that heart disease is more prevalent among older populations\nUsing machine learning development tools to mitigate model bias when this is determined to be necessary\nCollaborating with data scientists, business stakeholders, and governance/compliance teams to ensure models meet compliance and governance standards\nQualifications:\nBachelors or Masters/PhD (preferred) in statistics or computer science or equivalent field with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR)\nAbility to promote best coding practices, championing a culture of documentation/logging\nThorough understanding of ML lifecycle, including necessary tradeoffs and associated risks\nLeadership in Data Science\nCan own a project end-to-end e.g., scoping, business value estimation, ideation, dev, prod, timeline\nCollaborates and guides junior team members in completion of projects and career development\nWorks cross functionally with technical (e.g., Data Science, Data Engineering) and business (e.g., clinical, marketing, pricing, business analysts) to implement solutions with measurable value\nScope and Impact\nIndependently delivers clear and well-developed presentations for both technical and business audiences\nCreates data science specific project goals associated with project deliverables\nArticulates timeline changes, rationale, and goals to meet deadlines moving forward\nValues diversity, growth mindset, and improving health outcomes of our customers\n\nLevel of Influence\nCommunicate with stakeholders to identify opportunities and possible solutions based on business need\nDraft project charter, timeline, and features/stories\nInfluence matrix-partner leadership\nAbout Evernorth Health Services",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Version control', 'Claims', 'data science', 'Legal compliance', 'Coding', 'Pharmacy', 'Machine learning', 'SQL', 'Python']",2025-06-12 14:05:52
HIH - Data Science Lead Analyst - Evernorth,Cigna Medical Group,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\nThe role will support the development and maintenance of proprietary advanced neural network (AI) foundation models in support of Cigna business operations.\nKey Responsibilities:\nWrite code using PyTorch and/or Tensorflow to implement, test, and operationalize deep learning models\nCollaborate with data scientists and engineers to improve deep learning models and implement business-facing solutions built on top of those models\nTake responsibility for improving code performance and quality\nFollow developments in deep learning technology to identify opportunities to improve models\nQualifications:\nBachelors or Masters(preferred) in computer science or statistics or any other equivalent discipline with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR), with emphasis on Tensorflow and Pytorch\nKnows and follows best coding and software engineering practices\nSuccessfully completes technical project components with limited guidance\nFamiliarity with deploying machine learning and predictive models to production and cloud environments\nLeadership in Data Science\nUnderstands how assigned work is related to purpose of the overall project\nIndependently identifies project roadblocks, and solutions\nSeeks to understand the health insurance domain\nScope and Impact\nDocuments the business considerations, methodology, process, code, and results associated with their work\nCollaborates to deliver clear and well developed presentations for both technical and business audiences\nConsistently communicates decisions, considerations, and needs for support\nReceives and responds to feedback in a professional and appropriate manner\nLevel of Influence\nPresent technical topics and results to non-technical stakeholders\nCommunicate and gather domain knowledge from non-technical stakeholders",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Health insurance', 'Version control', 'GIT', 'Claims', 'Coding', 'Machine learning', 'SQL', 'Python', 'Business operations']",2025-06-12 14:05:54
HIH - Data Science Lead Analyst - Evernorth,ManipalCigna Health Insurance,5 - 8 years,Not Disclosed,['Hyderabad'],"Internal Title: Data Science Lead Analyst\nExternal Title: Data Science Lead Analyst\nRole Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\nThe role will support the development and maintenance of proprietary advanced neural network ( AI ) foundation models in support of Cigna s business operations.\nKey Responsibilities:\nWrite code using PyTorch and/or Tensorflow to implement, test, and operationalize deep learning models\nCollaborate with data scientists and engineers to improve deep learning models and implement business-facing solutions built on top of those models\nTake responsibility for improving code performance and quality\nFollow developments in deep learning technology to identify opportunities to improve models\nQualifications:\nBachelors or Masters(preferred) in computer science or statistics or any other equivalent discipline with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR), with emphasis on Tensorflow and Pytorch\nKnows and follows best coding and software engineering practices\nSuccessfully completes technical project components with limited guidance\nFamiliarity with deploying machine learning and predictive models to production and cloud environments\nLeadership in Data Science\nUnderstands how assigned work is related to purpose of the overall project\nIndependently identifies project roadblocks, and solutions\nSeeks to understand the health insurance domain\nScope and Impact\nDocuments the business considerations, methodology, process, code, and results associated with their work\nCollaborates to deliver clear and well developed presentations for both technical and business audiences\nConsistently communicates decisions, considerations, and needs for support\nReceives and responds to feedback in a professional and appropriate manner\nLevel of Influence\nPresent technical topics and results to non-technical stakeholders\nCommunicate and gather domain knowledge from non-technical stakeholders\nAbout Evernorth Health Services",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Version control', 'GIT', 'Claims', 'Coding', 'Machine learning', 'Lead Analyst', 'SQL', 'Python', 'Business operations']",2025-06-12 14:05:56
Data Quality Analyst,Yallas Technology Solutions Opc,5 - 10 years,Not Disclosed,[],"Title: Data Quality Analyst/Developer\nDuration: 6 months to 1 year contract\nLocation:  Remote\nNotice period - Immediate to 7 days\nUAN /EPFO Report Required\n\nWork Experience:\n5 + years of this experience - Experience doing Data Emendation\nDesign/Develop Rules, monitoring mechanisms, notification\nDesign/Develop UI, Workflows, security\nDesign/Develop analytics (overall DQ reporting, usage statistics, etc).\nDesign/Develop migration activities to migrate existing DQ assets between our existing DQ platform and new DQ platform.\nDesign integration with MDM & Catalog (as needed)\nMonitor system performance and suggest optimization strategies (as needed).\nWork with DT to maintain system - patches, backups, etc.\nWork with LYB's Data Stewards to support their governance activities.\nTesting\n\nThe DQ Analyst/Developer should have experience with IMDC (for the sake of our example) cloud DQ and observability, JSON (depending on tool) Deep SQL skills, Integration tools/methodologies - API as well as ETL, Data Analysis, Snowflake or Databricks knowledge (for lineage), Power BI (nice to have), SAP ECC knowledge (nice to have), experience with cloud platforms (Azure, AWS, Google).\nIf you are interested please share required details along with resume\nFull Name:\nCurrent or Previous organization:\nCurrent Location:\nTotal Experience:\nRelevant experience as Python Developer:\nhow many years of experience In Azure, AWS, Google\nHow many years of experience in UI, Workflows, security\nWorking as full time or contract:\nReason for job change:\nAny other offers inhand:\nCurrent CTC:\nexpected CTC:\nNotice Period:\nemail id:\ncontact Number :\nDomain name:\nare you ok to work Cotractual role?:\nshare your aadhar or pan card for the verification",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Data quality analyst', 'cloud data quality', 'Azure', 'data quality developer', 'JSON', 'google', 'Informatica', 'AWS']",2025-06-12 14:05:59
Data Governance Process Analyst,K-logix Partnering Solutions,5 - 9 years,Not Disclosed,[],"Key Responsibilities:\n\nAnalyze end-to-end business processes using Celonis Process Mining to identify inefficiencies, root causes, and data quality issues.\nCollaborate with Data Stewards, IT, and business units to ensure data governance policies are aligned with process insights.\nDevelop and maintain dashboards and reports in Celonis to track key performance indicators (KPIs), data lineage, and governance metrics.\nWork with cross-functional teams to define and implement data governance controls and remediation strategies based on process analytics.\nSupport the development of data dictionaries, metadata management, and data cataloging in alignment with enterprise data standards.\nAssist in the rollout of enterprise-wide data governance programs and compliance initiatives (e.g., GDPR, CCPA).\nContinuously monitor and assess data quality metrics and suggest corrective actions to improve data accuracy and reliability.\nProvide training and documentation on Celonis best practices and data governance processes to business stakeholders.\n\nRequired Qualifications:\n\nBachelors degree in Information Systems, Data Analytics, Business Administration, or a related field.\n5+ years of experience in data governance, business process analysis, or data analytics roles.\n2+ years of hands-on experience with Celonis EMS (Execution Management System) or comparable process mining tools.\nStrong understanding of data governance frameworks, data quality principles, and data lifecycle management.\nProficient in SQL and working knowledge of data visualization tools (e.g., Power BI, Tableau).\nExcellent analytical and problem-solving skills, with a keen attention to detail.\nStrong communication and stakeholder engagement skills across technical and non-technical teams.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Celonis', 'Business Process Analysis', 'Data Governance']",2025-06-12 14:06:01
HIH - Data Science Lead Analyst - Evernorth,Cigna Medical Group,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Summary\nAs a member of the Data Science Center of Expertise (DSCOE), the DS Lead Analyst is responsible for leading and enabling Data Science within Cigna Group with demonstrable aptitude in Data Science (i) Technical Skills (ii) Leadership (iii) Scope & Impact (iv) Influence. Please see Qualifications section below for more details.\n\nThe role will support the development and maintenance of machine learning models, with a focus on ensuring that models meet Cigna requirements for governance and legal compliance. The role will require collaboration with other data scientists and involve work across many lines of business.\nKey Responsibilities:\nAnalyze model performance of new models with specific regards to requirements for legal compliance and governance standards around accuracy and bias;\nPerform periodic analyses of performance of existing models to ensure continued compliance with internal and external standards for accuracy and bias;\nConduct research (i.e. literature review) to understand when bias may be biologically or medically justifiable, and to what degree, for example: finding evidence from literature that heart disease is more prevalent among older populations\nUsing machine learning development tools to mitigate model bias when this is determined to be necessary\nCollaborating with data scientists, business stakeholders, and governance/compliance teams to ensure models meet compliance and governance standards\nQualifications:\nBachelors or Masters/PhD (preferred) in statistics or computer science or equivalent field with 5-8 years of relevant experience\nStrong proficiency in ML, statistics, python or R, SQL, version control (e.g., Git), health care data (e.g., claims, EHR)\nAbility to promote best coding practices, championing a culture of documentation/logging\nThorough understanding of ML lifecycle, including necessary tradeoffs and associated risks\nLeadership in Data Science\nCan own a project end-to-end e.g., scoping, business value estimation, ideation, dev, prod, timeline\nCollaborates and guides junior team members in completion of projects and career development\nWorks cross functionally with technical (e.g., Data Science, Data Engineering) and business (e.g., clinical, marketing, pricing, business analysts) to implement solutions with measurable value\nScope and Impact\nIndependently delivers clear and well-developed presentations for both technical and business audiences\nCreates data science specific project goals associated with project deliverables\nArticulates timeline changes, rationale, and goals to meet deadlines moving forward\nValues diversity, growth mindset, and improving health outcomes of our customers\n\nLevel of Influence\nCommunicate with stakeholders to identify opportunities and possible solutions based on business need\nDraft project charter, timeline, and features/stories\nInfluence matrix-partner leadership",Industry Type: Medical Services / Hospital,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Version control', 'GIT', 'Claims', 'data science', 'Legal compliance', 'Coding', 'Machine learning', 'SQL', 'Python']",2025-06-12 14:06:03
Data Entry (Fresher),Rapid Care,0 years,1-1.5 Lacs P.A.,['Chennai'],"Greetings from rapid care!!!!!!\n\nHiring Freshers and Experienced !!!!!!!!!\n\nwalkin interview\n\n\nJob Title: Data Analyst (Data Entry)\n\nLocation: Chennai\n\nShift: General and Rotational Shift\n\nGraduation: ( 10th, 12th, OR Any Diploma Qualification)\n\nInterview mode : walkin\n\n\nOffice Address : VLV Complex, 2nd floor, 41, SH 48, Little Mount, Saidapet, Chennai, Tamil Nadu 600015\n\nshare your resume : tag@rapidcare.ai\ncall , whatsapp : 9500170691, 9500170663.",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Typing Speed', 'Data Entry', 'Typing', 'Data Entry Operation']",2025-06-12 14:06:05
Data Entry Operator / Mis Executive,Talentlink Solutions,0 - 4 years,1-4 Lacs P.A.,[],"We Are looking For Computer Operator, Who can Perform defined tasks per documented instructions/process\n\nMale And Female Both Can apply\n\nFresher And Experience Both Can Apply\n\nBasic computer knowledge must\n\nHardworking\n\nWork from Home",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Back Office Processing', 'Non Voice Process', 'Data Entry', 'Back Office', 'Back Office Operations', 'Typing Speed', 'Computer Operating', 'Backend Operations', 'Chat Support', 'Non Voice', 'MS Office', 'Email Process', 'Chat Process', 'Data Processing', 'Data Entry Operation']",2025-06-12 14:06:08
Financial Planning And Analysis Intern,Kinara Capital,6 months duration,"15,000/month",['Bengaluru( Indira Nagar )'],"Job Title: Financial Planning & Analysis Intern\nDepartment : Finance & Accounting\nPurpose of Job: Vendor Management\n\nJob Responsibilities:\n\nSection 1: Vendor Management\n• Formulation & maintenance of Procure to Pay process\n• To check the pricing as per market rate, to negotiate with the\nvendor, save cost and & to select the potential vendor\n• To assess the risk level of the vendors\n• Liaise with various stakeholders to sign off on the contract terms\n• Ensure smooth on boarding of the vendor\n• Liaise with the various stakeholders to ascertain the\nperformance of the vendor\n• To renew the contracts within the due date\n• Support sourcing strategy, negotiations, and performance\nmanagement\n• Researching vendors\n• Improve vendor relationships\n• Establishing vendor management tools & technologies\n• Troubleshooting vendor issues\n• Stakeholder Management\n• Budget Check and analysis\n• Provide Executive Level briefings to Lead & Finance Controller at\nregular intervals to help keep them current with changes and\nperformance against existing agreements with vendors\nSection 2: Data Management\n• Maintaining a central repository of reports\n• Preparation of a monthly data pack that contains all the\noperational & financial parameters\n• Ensuring control checks on the operational reports being\npublished on a monthly basis\n\nQualifications:\n\nEducation: Degree/CA/MBA\nWork Experience:  Fresher\nOther Requirements: • Excellent communication skills\n• An Excel test needs to be undertaken\n• A PowerPoint presentation to be prepared\n\n• Negotiation\n• Problem-solving\n• Knowledge of procurement processes\n• Metrics and data analysis\n• Engage in continuous learning\n• Risk Identification & mitigation\n\nSkills & Competencies\n\nSkills\nTechnical Skills\n• Microsoft Excel Advanced\n• Financial Modeling & Forecasting\n• Budgeting & Variance Analysis\n• Accounting Knowledge\nSoft Skills\n• Communication Skills\n• Analytical Thinking\n• Collaboration & Teamwork\n• Adaptability\nCompetencies\n• Presentation skills\n• Data-Driven Decision Making\n• Business Partnering\n\nPlace of work: Head office, Bangalore.\nJob Type: Full Time",Industry Type: Financial Services,Department: Finance & Accounting,"Employment Type: Full Time, Permanent",['Vendor Management'],2025-06-12 14:06:10
MIS & Trading Data Coordinator,Abans Finance,0 - 3 years,Not Disclosed,['Ahmedabad'],"Position Summary:\nWe are looking for a meticulous and proactive Data coordinator to manage trading book entries in our in-house software system. This role is critical for ensuring the accurate generation of Management Information System (MIS) outputs and supporting data analysis. The ideal candidate will have a strong eye for detail, an aptitude for software systems, and a basic understanding of trading and financial operations.\n\n\nRole & responsibilities\nAccurately input trading book data into the companys in-house software system.\nEnsure completeness and consistency in all entries, adhering to organizational standards.\nUnderstand the intricacies of the in-house software system and its functionality.\nMonitor system workflows to identify and resolve issues or anomalies.\nStay updated on software enhancements and implement changes as required.\nPerform validation checks to ensure data integrity and accuracy.\nIdentify discrepancies in trading records and rectify them in coordination with relevant teams.\nGenerate MIS reports and ensure timely and accurate delivery to stakeholders.\nMaintain proper documentation of processes, changes, and findings.\nSupport audits by providing accurate and timely records as needed.\n\nPreferred candidate profile\nDegree in finance, commerce, business administration or a related field with 0-3 years of work experience in trading ops domain.\nBasic understanding of trading operations and financial concepts.\nFamiliarity with financial software systems and MIS reporting.\nProficiency in Microsoft Excel and database management tools.\nAbility to quickly learn and navigate proprietary software systems.\n\nWork Location- Gift City, Ahmedabad\n\nFreshers with trading knowledge can also apply at astha.satam@abans.co.in",Industry Type: Financial Services,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Management Information System', 'MIS Reporting', 'Trade Finance Operations', 'Trade Operations', 'MIS', 'MIS Operations', 'Database Management', 'Trading', 'Trade Finance', 'Trade Finance Management', 'Financial Operations']",2025-06-12 14:06:12
Business Analyst II,Conduent,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Track Description \nRequires formal education and relevant expertise in a professional, sales, or technical area.\nPerforms technical-based activities.\nContributes to and manages projects.\nUses deductive reasoning to solve problems and make recommendations.\nInterfaces with and influences key stakeholders.\nLeverages previous knowledge and expertise to achieve results.\nAbility to complete work self-guided.\nCollege or university degree required.\n\n General Profile  \nRequires knowledge and experience in own field.\nWill acquire higher-level knowledge and skills.\nDevelops an understanding of the company, processes, and customers.\nUses existing procedures to solve routine or standard problems.\nReceives moderate guidance and direction from others.\n\n Functional Knowledge  \nRequires expanded conceptual understanding of theories, practices, and procedures.\n\n Business Expertise  \nUses an understanding of key business drivers to accomplish work.\n\n Impact  \nImpacts own team through the quality of the services or information provided.\nFollows standardized procedures and practices to achieve objectives and meet deadlines.\n\n Leadership  \nNo supervisory responsibilities.\nProvides informal guidance to new team members.\n\n Problem Solving  \nUses existing procedures and technical experience to solve problems.\n\n Interpersonal Skills  \nExchanges complex information and ideas effectively.\n\n Responsibility Statements  \nFacilitates working sessions between customers and IT teams to define business requirements.\nCollects data from customers relating to systems and reports issues impacting service delivery.\nWrites detailed business functional requirements documents.\nCompiles cost assessment data for projects for supplier and vendor integration.\nRecommends requirement changes or improvements.\nPrepares business operations reports and develops recommendations.\nDevelops well-rounded knowledge of operating processes, user-based systems, and governing regulations.\nPerforms other duties as assigned.\nComplies with all policies and standards.",Industry Type: BPM / BPO,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'business analysis', 'sales', 'brd', 'business operations', 'data analysis', 'gap analysis', 'us healthcare', 'power bi', 'user stories', 'business intelligence', 'sql', 'claims processing', 'tableau', 'scrum', 'requirement analysis', 'sdlc', 'jira', 'agile methodology']",2025-06-12 14:06:15
Data Input & Management Executive,D&B Italiano,0 - 2 years,1.5-1.75 Lacs P.A.,['Ahmedabad'],"Position Overview:\nWe are seeking a diligent and organized professional to join our operations team. The ideal candidate will be responsible for accurate data entry, system management, and reporting processes that support our project and business workflows.\n\nKey Responsibilities:\nInput and manage project-related and administrative data with precision and consistency\nMaintain internal data systems and ensure regular updates across relevant platforms\nGenerate basic analytical reports to assist in operational decision-making\nCollaborate with design and procurement teams to ensure data accuracy across departments\nAssist in documentation of vendor, inventory.\n\nQualifications & Skills:\nBachelors degree in Business Administration, Information Systems, Statistics, or a related field\nStrong proficiency in Microsoft Excel, Google Sheets, and basic data visualization tools\nExcellent attention to detail, organizational, and time management skills\nAbility to work independently and in a cross-functional team environment\nPrior experience in data handling or operations support is advantageous but not mandatory",Industry Type: Architecture / Interior Design,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data Management', 'Data Analysis', 'Data Maintenance', 'Data Collection', 'Advanced Excel', 'Google Sheets', 'Records Management', 'Excel Sheet', 'Data Reporting', 'Excel Report Preparation']",2025-06-12 14:06:17
"Business Analyst I, AOP - Perfectmile",Amazon,1 - 6 years,Not Disclosed,['Bengaluru'],"AOP FC Analytics team manages a suite of MIS reporting published at a various regular frequency, productivity tools to bridge the current software challenges and serve all analytical needs of leadership team with data & analysis.\n\nThe ideal candidate relishes working with large volumes of data, enjoys the challenge of highly complex business contexts, and, above all else, is passionate about data and analytics. The candidate is an expert with business intelligence tools and passionately partners with the business to identify strategic opportunities where data-backed insights drive value creation. An effective communicator, the candidate crisply translates analysis result into executive-facing business terms. The candidate works aptly with internal and external teams to push the projects across the finishing line. The candidate is a self-starter, comfortable with ambiguity, able to think big (while paying careful attention to detail), and enjoys working in a fast-paced and global team.\n\n\nInterfacing with business customers, gathering requirements and delivering complete BI solutions to drive insights and inform product, operations, and marketing decisions.\nInterfacing with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL (Redshift, Oracle) and ability to use a programming and/or scripting language to process data for modeling\nEvolve organization wide Self-Service platforms\nBuilding metrics to analyze key inputs to forecasting systems\nRecognizing and adopting best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation\n\nA day in the life\n1) Solve analyses with well-defined inputs and outputs; drive to the heart of the problem and identify root causes\n2) Have the capability to handle large data sets in analysis\n3) Derive recommendations from analysis\n4) Understand the basics of test and control comparison; may provide insights through basic statistical measures such as hypothesis testing\n5) Communicate analytical insights effectively\n\nAbout the team\nAOP (Analytics Operations and Programs) team is missioned to standardize BI and analytics capabilities, and reduce repeat analytics/reporting/BI workload for operations across IN, AU, BR, MX, SG, AE, EG, SA marketplace.\n\nAOP is responsible to provide visibility on operations performance and implement programs to improve network efficiency and defect reduction. The team has a diverse mix of strong engineers, Analysts and Scientists who champion customer obsession.\n\nWe enable operations to make data-driven decisions through developing near real-time dashboards, self-serve dive-deep capabilities and building advanced analytics capabilities.\n\nWe identify and implement data-driven metric improvement programs in collaboration (co-owning) with Operations teams. 1+ years of tax, finance or a related analytical field experience\n2+ years of complex Excel VBA macros writing experience\nBachelors degree or equivalent\nExperience defining requirements and using data and metrics to draw business insights\nExperience with SQL or ETL Experience working with Tableau\nExperience using very large datasets",,,,"['Data analysis', 'Analytical', 'Test design', 'Hypothesis Testing', 'data integrity', 'Oracle', 'Business intelligence', 'Forecasting', 'Macros', 'SQL']",2025-06-12 14:06:19
Associate Analyst,Overture Rede,0 - 1 years,Not Disclosed,['Hyderabad'],"Job Title: Associate Analyst DataLocation: HyderabadExperience:03 YearsQualification: B\nComOpen Position(s):18Job Role:Maintain and update CRM, billing, and project data while supporting content creation and ensuring SLA-based client account management\nMust-Have Skills:-Understanding of advertising sales processes- CRM data entry and account updates-\nContent creation for internal and client-facing use- Invoice processing and account closure- Attention to detail and SLA adherence- Basic financial record management and reporting"",""Work_Experience0-1 year",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Client account management', 'Basic', 'Associate Analyst', 'Sales', 'Invoice processing', 'Finance', 'Billing', 'Advertising', 'Data entry', 'CRM']",2025-06-12 14:06:21
Business Operations Analyst,Qualcomm,3 - 6 years,Not Disclosed,['Bengaluru'],"Job Area: Operations Group, Operations Group > Business Operations\n\nGeneral Summary:\n\nHiring TitleBusiness Operations Analyst, (Compute GTM)\n\nAbout the GBFS TeamThe Global Business and Finance Support (GBFS) team provide support to HQ and the global regional team on Finance & Business Operation activities. This job role is for business operations related activities- Partner Onboarding, Global Channel Incentive and Marketing Development fund claims, fund requests, fund allocation, invoicing support and ad-hoc reporting.\n\nGeneral Job SummaryThis role serves as a key point of contact for both external customers and internal teams, providing essential support to HQ and Sales Teams. Responsibilities include overseeing account onboarding, managing product SKUs, administering partner offerings, and process MDF/GCI claims. Additionally, the role plays a vital part in ensuring precise reporting, smooth payment integration and communication to internal stakeholders/partners. The ideal candidate will be driven by a passion for fostering outstanding internal collaboration across the organization. Responsibilities include, but are not limited to, the following activities:\n\nJob Overview:\nOversee Partner account onboarding, manage product SKUs, and administer partner offerings\nprocessing of Market Development Funds and Global Channel Incentive claims, ensuring compliance with program guidelines and financial accuracy\nHandle marketing budgets, fund allocations, fund requests with accuracy\nEnsure seamless financial tracking, reporting, and billing processes.\nServe as a key contact for external customers and internal HQ and Sales Teams.\nProvide world-class assistance for Qualcomms products and services while fostering strong internal partnerships.\nPerform additional ad hoc business operations activities from time to time.\n\n\n:\n3 to 6 years relevant industry experience in Sales operations activities\nPrior experience in semiconductor industry, OEMs and partner management is desired.\nExcellent Advanced Excel Skills, Salesforce, data analysis and reporting.\nStrong analytical, problem solving and conceptual skills.\nPositive attitude and willingness to learn skills/tools\nFlexible for evening calls (8PM- 11PM IST) for HQ reviews and transition calls on regular basis and/or working in shift (2.30pm to 11.30pm) as needed\nStrong written and verbal communication skills.\n\n\nEducation :\nBachelors in Science / B.Tech / Commerce / Economics and/or,\nDiploma or Masters in business Analytics\nBusiness Administration from a reputed B-school.\n\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Engineering, Finance, Marketing, or related field and 2+ years of business operations or related experience.\nOR\nHigh School Diploma or equivalent and 4+ years of business operations or related experience.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'salesforce', 'sales operations', 'advanced excel', 'business operations', 'channel sales', 'business analytics', 'business development', 'partner management', 'distribution', 'sales', 'oems', 'business administration', 'marketing', 'sales management', 'dealer network']",2025-06-12 14:06:23
Sr. Business Analyst,Merkle B2b,8 - 13 years,Not Disclosed,['Mumbai'],"As a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms\nJob Description:\nSr. Business Analyst\nJob Description:\nAs a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms.\nKey Responsibilities\nUnderstand and identify the business issues / requirements and create a detailed Functional Requirement Document\nDevelop a prototype / framework that meets requirements and addresses the business issue.\nBrief the technical team on the requirements. Address and resolve all doubts/queries of the developer / tester. As and when required, check with stakeholders and seek clarity.\nEnsure smooth deployment of the solution and conduct training for end users as and when required.\nPost project completion; seek for feedback from project stakeholders.\nConduct a thorough impact analysis on system for change requests.\nAssist with solution testing and user acceptance testing plans and execution.\nUpdate and maintain solution documentation including requirements documents, data flows, schema/layout documentation, etc.\nMaintain the solution in production, working with end users, and facilitating change requests with the broader team using a defined change management process.\nQualifications + Skills\nBachelor s Degree or equivalent\n8+ years of experience in gathering and documenting solution requirements for the purposes of scope management, design, development and testing enablement.\nGood problem solving and business acumen\nExperience writing and maintaining solution documentation (requirements documents, data flows, User stories, etc.).\nExperience working within common delivery methodologies (e.g. agile and/or waterfall).\nExperience with business intelligence reporting (e.g. Power BI, Tableau, and/or similar platforms).\nExperience with system and user acceptance testing.\nExperience writing SQL to perform data analysis.\nStrong customer service orientation and collaboration skills.\nEffective communication skills, ability to simplify and structure complex concepts to streamline interactions and highlight key points.\nLocation:\nMumbai\nBrand:\nDentsu\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'Change management', 'Manager Quality Assurance', 'Prototype', 'Schema', 'Agile', 'Scope management', 'User acceptance testing', 'SQL']",2025-06-12 14:06:26
Technical Business Analysis Engineer II,Conduent,2 - 6 years,Not Disclosed,['Noida'],"JOB TITLE Technical Business Analysis Engineer II\n\n\nRESPONSIBILITIES\n\n\n\nMay perform one or more of the following:\n\n\nRequirement/Analysis\nAbility to comprehend Business Requirement Documents (BRD)\nMaintain and Update Data/Vendor Interfaces BRD\nInterprets requirements to create systems specifications documents to build and execute system.\nPerform Data Analysis, Audit, and associated research and provide subsequent resolutions.\nUnderstanding of database/SQL Query Writing\nWork alongside with Sr. members or individually (as required) to assist in smooth integration/transition of processes and create/maintain documentations for the same.\nResponsible for solving the data and Vendor files related issues and preparation of annual calendar, as applicable.\nExecute & Manage the assigned tasks {Data Analysis, Vendor files, Requirement Analysis} specific to your Tower\nHW Domain knowledge is good to have.\n\n  \nProcess\nAbility to think and conceptualize and/or implement ideas of process automation.\nFollow the standard practices and procedures specific to your Tower.\n\n  \nAccountability/Communication\nWork independently on tasks assigned.\nShould be able to Coach & mentor team members.\nDemonstrate ownership on work assigned to self and immediate sub-ordinates.\nManage Offshore/Onshore interaction and stakeholder communication as per the business needs.\nUpdate all documentation with task details and provide regular updates to team.\n\n\nAll other tasks as assigned.",Industry Type: BPM / BPO,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'business analysis', 'sql', 'brd', 'requirement analysis', 'hipaa', 'documentation', 'us healthcare', 'claims adjudication', 'user stories', 'claims processing', 'ar calling', 'denial management', 'claims', 'medical billing', 'process automation', 'rcm', 'revenue cycle management']",2025-06-12 14:06:28
Hiring Business Analyst with MSTR or Dataiku - Bangalore/ Chennai !!!!,Tech Mahindra,8 - 13 years,Not Disclosed,"['Chennai', 'Bengaluru']","A Business Analyst in the Financial Crime Surveillance Operations (FCSO) Data & Reporting PO Team understands the core concepts, principles, processes or procedures of Data & MI.\nExperienced in using MSTR reports & Dataiku. The FCSO Business Analyst gathers requirements from various stakeholders and creates user stories for the squad to understand and take it for delivery. They must have strong analytical skills, understand the strategic framework & make sense of data.\n\n1.Core Business Analysis Skills\nRequirement Gathering\nDocumentation\nGap analysis\n\n2. Data & MI Expertise\nData Analysis\nData mapping & Metrics understanding\nFCSO Process knowledge (Good to have)\n\n3. Technical Skills\nQuery Databases\nFamiliarity with BI Tools like Dataiku, MSTR\n\n4. Agile & Delivery management\n\nUnderstanding of Scrum for collaborating with Squads\nUser Story Creation\nBacklog Management\nStakeholder Management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Microstrategy', 'Business Analytics', 'Dataiku', 'Business Analysis']",2025-06-12 14:06:31
Business Analyst II,Conduent,5 - 8 years,Not Disclosed,['Noida'],"Responsibilities:\nProvide support to plan, organize, and deliver moderate to complex projects prioritized in alignment with the client\\u2019s expectations and business needs.Projects may include multiple disciplines and/or significant business process re-engineering efforts.\nPlan, coordinate and directs schedules.\nOrganizes project activities that may require interdepartmental meetings and communication ensuring completion of the program/project on schedule and within budget constraints.\nAt times directs the activities of project support staff and sub-contractors and is responsible for ensuring appropriate resources are allocated and maintained to facilitate the successful completion of the project.\nAssigns and monitors work of subject matter expert personnel, providing support and interpretation of instructions/objectives.\nManages and coordinates projects priorities that requires critical thinking and complex problem solving.\nLeads and communicates project scope, goals and responsibilities to project team; establish clear stakeholder expectations, and requirements of varying degrees of complexity.\nDevelops and maintains reporting procedures and monitors performance in project control activities; prepares and distributes reports related to project activities, general project management, and financial issues.\n\n\n:\n5 - 8 years of overall experience\nProficient in data analysis and reporting using MS Excel/Power BI (mandatory)\nProficient in creating project status and other presentation using MS PowerPoint (mandatory)\nExperience in communicating with end client (highly desirable)\nPMP Certified (highly desirable)\nProficient in Business Analysis (would be a plus)",Industry Type: BPM / BPO,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'presentation skills', 'power bi', 'business analysis', 'head hunting', 'screening', 'hiring', 'salary negotiation', 'project scheduling', 'bi', 'hrsd', 'sourcing', 'business process re-engineering', 'talent acquisition', 'pmp', 'it recruitment', 'recruitment']",2025-06-12 14:06:33
Data Engineer,Luxoft,5 - 8 years,Not Disclosed,['Pune'],"Help Group Enterprise Architecture team to develop our suite of EA tools and workbenches\nWork in the development team to support the development of portfolio health insights\nBuild data applications from cloud infrastructure to visualization layer\nProduce clear and commented code\nProduce clear and comprehensive documentation\nPlay an active role with technology support teams and ensure deliverables are completed or escalated on time\nProvide support on any related presentations, communications, and trainings\nBe a team player, working across the organization with skills to indirectly manage and influence\nBe a self-starter willing to inform and educate others\nSkills\nMust have\nB.Sc./M.Sc. degree in computing or similar\n5-8+ years experience as a Data Engineer, ideally in a large corporate environment\nIn-depth knowledge of SQL and data modelling/data processing\nStrong experience working with Microsoft Azure\nExperience with visualisation tools like PowerBI (or Tableau, QlikView or similar)\nExperience working with Git, JIRA, GitLab\nStrong flair for data analytics\nStrong flair for IT architecture and IT architecture metrics\nExcellent stakeholder interaction and communication skills\nUnderstanding of performance implications when making design decisions to deliver performant and maintainable software.\nExcellent end-to-end SDLC process understanding.\nProven track record of delivering complex data apps on tight timelines\nFluent in English both written and spoken.\nPassionate about development with focus on data and cloud\nAnalytical and logical, with strong problem solving skills\nA team player, comfortable with taking the lead on complex tasks\nAn excellent communicator who is adept in, handling ambiguity and communicating with both technical and non-technical audiences\nComfortable with working in cross-functional global teams to effect change\nPassionate about learning and developing your hard and soft professional skills\nNice to have\nExperience working in the financial industry\nExperience in complex metrics design and reporting\nExperience in using artificial intelligence for data analytics\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Power BI Developer\nBI Engineering\nIndia\nBengaluru\nSenior Power BI Developer\nBI Engineering\nIndia\nChennai\nSenior Power BI Developer\nBI Engineering\nIndia\nGurugram\nPune, India\nReq. VR-114797\nBI Engineering\nBCM Industry\n02/06/2025\nReq. VR-114797\nApply for Data Engineer in Pune\n*",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['GIT', 'Enterprise architecture', 'Analytical', 'Artificial Intelligence', 'Data processing', 'Data analytics', 'QlikView', 'JIRA', 'SDLC', 'SQL']",2025-06-12 14:06:35
Business Analyst,Global Banking Organization,3 - 8 years,Not Disclosed,['Bengaluru'],"Key Skills: Marketing Analytics, Analytics, SQL, Python, Business Analysis, Predictive Analysis, Statistical Analysis.\nRoles and Responsibilities:\nGathers operational data from various cross-functional stakeholders to examine past business performance.\nIdentifies data patterns and trends, and provides insights to enhance business decision-making capability in business planning, process improvement, solution assessment, etc.\nRecommends actions for future developments and strategic business opportunities, as well as enhancements to operational policies.\nMay be involved in exploratory data analysis, confirmatory data analysis, and/or qualitative analysis.\nTranslates data into consumer or customer behavioral insights to drive targeting and segmentation strategies, and communicates clearly and effectively to business partners and senior leaders all findings.\nContinuously improves processes and strategies by exploring and evaluating new data sources, tools, and capabilities.\nWorks closely with internal and external business partners in building, implementing, tracking, and improving decision strategies.\nAppropriately assesses risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding its clients and assets, by driving compliance with applicable laws, rules and regulations, adhering to policy, applying sound ethical judgment regarding personal behavior, conduct and business practices, and escalating, managing, and reporting control issues with transparency.\nExperience Requirement:\n3-8 years of relevant experience in business analytics, data analysis, or business intelligence roles.\nProven experience in using analytical tools such as SQL, Excel, Python, or R to extract and analyze data.\nHands-on experience with data visualization tools such as Tableau, Power BI, or similar platforms.\nExperience working in cross-functional teams and supporting decision-making through data-driven insights.\nStrong track record of identifying business trends and providing actionable recommendations based on data analysis.\nDemonstrated ability to handle multiple projects simultaneously with a strong attention to detail.\nEducation: B.Tech M.Tech (Dual), MCA, B.Tech.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Marketing Analytics', 'Analytics', 'SQL', 'Python', 'Business Analysis', 'Statistical Analysis.', 'Predictive Analysis']",2025-06-12 14:06:38
"Business Research Analyst - II, RBS ACCX Program",Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Amazon.com strives to be Earths most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want low prices, vast selection, and convenience Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazons evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the companys DNA. The worlds brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.\n\nOverview of the role\nThe Business Research Analyst will be responsible for Data and Machine learning part of continuous improvement projects across the Discoverability space. This will require collaboration with local and global teams. The Research Analyst should be a self-starter who is passionate about discovering and solving complicated problems, learning complex systems, working with numbers, and organizing and communicating data and reports. The Research Analyst will perform Big data analysis to identify patterns, train model to generate product to product relationship and product to brand & model relationship. The Research Analyst is also expected to continuously improve the ML/LLM solutions in terms of precision & recall, efficiency and scalability. The Research Analyst should be able to write clear and detailed functional specifications based on business requirements.\n\n\nScoping, driving and delivering complex projects across multiple teams.\nPerforms root cause analysis by understanding the data need, get data / pull the data and analyze it to form the hypothesis and validate it using data.\nBuild programs to create a culture of continuous improvement within the business unit, and foster a customer-centric focus on the quality, productivity, and scalability of our services.\nFind the scalable solution for business problem by executing pilots and build Deterministic and ML/LLM models.\nManages meetings, business and technical discussions regarding their part of the projects.\nMakes recommendations and decisions that impact development schedules and the success for a product or project.\nDrives team(s)/partners to meet program and/or product goals.\nCoordinates design effort between internal team and External team to develop optimal solutions.\nPerforms supporting research, conduct analysis of the bigger part of the projects and effectively interpret reports to identify opportunities, optimize processes, and implement changes.\nAbility to convince and interact with stakeholders at all level either to gather data and information or to execute and implement according to the plan.\nAbility to deal with ambiguity and problem solver\nCommunicate ideas effectively and with influence (both verbally and in writing), within and outside the team.\n\nKey Performance Areas:\nSolve large and complex business problems by aligning multiple teams together.\nData analytics and Data Sciences\nMachine learning\nProject/Program Management\nAutomation initiative conceptualization and implementation\nBig Data analytics\nProduct development Scoping and Testing\nDefect Elimination\nAgile Continuous Improvement\n\nAbout the team\nThe RBS group in Chennai/Bangalore is an integral part of Amazon online product lifecycle and buying operations. The team is designed to ensure Amazon remains competitive in the online retail space with the best price, wide selection and good product information. The team s primary role is to create and enhance retail selection on the worldwide Amazon online catalog. The tasks handled by this group have a direct impact on customer buying decisions and online user experience. 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc. experience\nExperience with data visualization using Tableau, Quicksight, or similar tools\nExperience with data modeling, warehousing and building ETL pipelines\nExperience writing complex SQL queries\nExperience in Statistical Analysis packages such as R, SAS and Matlab\nExperience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift\nExperience in data mining, ETL, etc. and using databases in a business environment with large-scale, complex datasets",,,,"['Automation', 'Data analysis', 'SAS', 'Data modeling', 'Machine learning', 'Agile', 'Oracle', 'Data mining', 'MATLAB', 'Python']",2025-06-12 14:06:40
Sr. Business Analyst,Merkle Science,10 - 15 years,Not Disclosed,['Mumbai'],"As a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms\nJob Description:\nSr. Business Analyst\nJob Description:\nAs a Senior Business Analyst, you ll be a key member of the Business Platforms team responsible for the solutions delivered to our stakeholders. You ll act as a liaison between the Business Platforms team and stakeholders from DGS and regional business function/technology team members. You ll gather and document solution requirements, working closely with domain subject matter experts, business stakeholders, project leadership, developers, and quality assurance team members. You will also be responsible for getting these requirements understood and executed by the development team and then getting the solution implemented in a timely fashion for the users. These solutions will include custom development for business function needs, integration with Global and regional platforms team, maintaining and enhancements to existing platforms.\nKey Responsibilities\nUnderstand and identify the business issues / requirements and create a detailed Functional Requirement Document\nDevelop a prototype / framework that meets requirements and addresses the business issue.\nBrief the technical team on the requirements. Address and resolve all doubts/queries of the developer / tester. As and when required, check with stakeholders and seek clarity.\nEnsure smooth deployment of the solution and conduct training for end users as and when required.\nPost project completion; seek for feedback from project stakeholders.\nConduct a thorough impact analysis on system for change requests.\nAssist with solution testing and user acceptance testing plans and execution.\nUpdate and maintain solution documentation including requirements documents, data flows, schema/layout documentation, etc.\nMaintain the solution in production, working with end users, and facilitating change requests with the broader team using a defined change management process.\nQualifications + Skills\nBachelor s Degree or equivalent\n8+ years of experience in gathering and documenting solution requirements for the purposes of scope management, design, development and testing enablement.\nGood problem solving and business acumen\nExperience writing and maintaining solution documentation (requirements documents, data flows, User stories, etc.).\nExperience working within common delivery methodologies (e.g. agile and/or waterfall).\nExperience with business intelligence reporting (e.g. Power BI, Tableau, and/or similar platforms).\nExperience with system and user acceptance testing.\nExperience writing SQL to perform data analysis.\nStrong customer service orientation and collaboration skills.\nEffective communication skills, ability to simplify and structure complex concepts to streamline interactions and highlight key points.\nLocation:\nMumbai\nBrand:\nDentsu\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'Change management', 'Manager Quality Assurance', 'Prototype', 'Schema', 'Agile', 'Scope management', 'User acceptance testing', 'SQL']",2025-06-12 14:06:42
Data Scientist,"Sourced Group, an Amdocs Company",4 - 9 years,Not Disclosed,['Gurugram'],"0px> Who are we?\nIn one sentence\nThis is a hands-on position for a motivated and talented innovator. The Data Scientist performs data mining and develops algorithms that provide insight from data.\nWhat will your job look like?\nYou will be responsible for and perform end-top-end data-based research.\nYou will craft data mining solutions to be implemented and executed with alignment to the planned scope and design coverage and needs/uses, demonstrating knowledge and a broad understanding of E2E business processes and requirements.\nYou will define the data analytics research plan, scope and resources required to meet the objectives of his/her area of ownership.\nYou will identify and analyze new data analytic directions and their potential business impact to determine the accurate prioritization of data analytics activities based on business needs and analytics value.\nYou will identify data sources, supervises the data collection process and crafts the data structure in collaboration with data experts (BI or big-data) and subject matter and business experts. Ensures that data used in the data analysis activities are of the highest quality.\nYou will construct data models (algorithms and formulas) for required business needs and predictions.\nYou will present results, including the preparation of patents and white papers and facilitating presentations during conferences.\nAll you need is...\nPh.D. in Computer Science, Mathematics or Statistics\n4 years experience in tasks related to data analytics\nKnowledge of telecommunications and of the subject area being investigated - advantage\nKnowledge in the product (ACC or other) application knowledge and configuration knowledge\nKnowledge in BSS, billing, Telco and the business processes\nFamiliarity in the Telco Networking - mobile, landline, cable TV, Internet\nknowledge in Oracle SQL\nWhy you will love this job:\nYou will ensure timely resolution or critical issue within the agreed SLA. This includes creating a positive customer support experience and build strong relationships through problem understanding, presenting promptly on progress, and handling customers with a professional demeanour.\nYou will be able to demonstrates an understanding of key business drivers and ensures strategic directions are followed and the organization succeeds\nWe are a dynamic, multi-cultural organization that constantly innovates and empowers our employees to grow. Our people our passionate, daring, and phenomenal teammates that stand by each other with a dedication to creating a diverse, inclusive workplace!\nWe offer a wide range of stellar benefits including health, dental, vision, and life insurance as well as paid time off, sick time, and parental leave!\n",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Bss', 'Networking', 'Billing', 'Data collection', 'Customer handling', 'Customer support', 'Data mining', 'Amdocs']",2025-06-12 14:06:45
Data Engineer - Databricks,KPI Partners,3 - 6 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","About KPI Partners.\nKPI Partners is a leading provider of data analytics solutions, dedicated to helping organizations transform data into actionable insights. Our innovative approach combines advanced technology with expert consulting, allowing businesses to leverage their data for improved performance and decision-making.\n\nJob Description.\nWe are seeking a skilled and motivated Data Engineer with experience in Databricks to join our dynamic team. The ideal candidate will be responsible for designing, building, and maintaining scalable data pipelines and data processing solutions that support our analytics initiatives. You will collaborate closely with data scientists, analysts, and other engineers to ensure the consistent flow of high-quality data across our platforms.",,,,"['python', 'data analytics', 'analytical', 'scala', 'pyspark', 'microsoft azure', 'data warehousing', 'data pipeline', 'data architecture', 'data engineering', 'sql', 'data bricks', 'cloud', 'analytics', 'data quality', 'data modeling', 'gcp', 'teamwork', 'integration', 'aws', 'etl', 'programming', 'communication skills', 'etl scripts']",2025-06-12 14:06:47
Senior Business Analyst Healthcare (FHIR),Happiest Minds Technologies,10 - 15 years,Not Disclosed,['Bengaluru'],"Job Title: Senior Business Analyst Healthcare (FHIR)\nLocation: Bangalore, India\nExperience: 1015 years\nEmployment Type: Full-time\n\nAbout the Role:\nWe are seeking a skilled and experienced Senior Business Analyst Healthcare (FHIR) to drive the design and implementation of FHIR-based solutions that enable seamless interoperability across healthcare systems. This role requires close collaboration with stakeholders, technical teams, and healthcare domain experts to ensure robust, compliant, and scalable data exchange mechanisms.",,,,"['HL7', 'Business Analyst', 'FHIR']",2025-06-12 14:06:49
Data Annotation hiring For Fresher || Excellent communication skills,Multinational Company,0 - 4 years,1-3 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Lead data annotation and collection projects.\nDevelop and implement data annotation guidelines and processes.\nTrain and manage data annotation teams.\nCollaborate with data scientists and engineers to understand data requirements.\n\nHR - 63980 09438\n\nRequired Candidate profile\nQualification - Graduate\nSalary :-\nCTC\n25,000 / experience\n20,000 / fresher\nExperience - Data Annotation only\nTransport:- Both Side\n\n5 Day working / Rotation shift / 2 day Rotation week off",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Object Detection', 'Data Annotation', 'Business Intelligence', 'Digital Image Processing', 'Data Management', 'Image Recognition', 'Image Analysis', 'Annotation', 'Deep Learning', 'Pattern Recognition', 'Image Processing', 'Imaging', 'Content Moderation', 'Data Warehousing', 'Data Analytics']",2025-06-12 14:06:52
Associate Data Engineer,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role We are seeking a Associate Data Engineer to design, build, and maintain scalable data solutions that drive business insights. You will work with large datasets, cloud platforms (AWS preferred), and big data technologies to develop ETL pipelines, ensure data quality, and support data governance initiatives.\nDevelop and maintain data pipelines, ETL/ELT processes, and data integration solutions.\nDesign and implement data models, data dictionaries, and documentation for accuracy and consistency.\nEnsure data security, privacy, and governance standard processes.\nUse Databricks, Apache Spark (PySpark, SparkSQL), AWS, Redshift, for scalable data processing.\nCollaborate with cross-functional teams to understand data needs and deliver actionable insights.\nOptimize data pipeline performance and explore new tools for efficiency.\nFollow best practices in coding, testing, and infrastructure-as-code (CI/CD, version control, automated testing).\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. Strong problem-solving, critical thinking, and communication skills.\nAbility to collaborate effectively in a team setting.\nProficiency in SQL, data analysis tools, and data visualization.\nHands-on experience with big data technologies (Databricks, Apache Spark, AWS, Redshift ).\nExperience with ETL tools, workflow orchestration, and performance tuning for big data.\nBasic Qualifications:\nBachelors degree and 0 to 3 years of experience OR Diploma and 4 to 7 years of experience in Computer science, IT or related field.\nPreferred Qualifications:\nKnowledge of data modeling, warehousing, and graph databases\nExperience with Python, SageMaker, and cloud data platforms.\nAWS Certified Data Engineer or Databricks certification preferred.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'data analysis', 'data modeling', 'data warehousing', 'data visualization', 'Databricks', 'ETL', 'AWS', 'SQL', 'Apache Spark', 'Python']",2025-06-12 14:06:54
Data Annotation // Upto 3 LPA,Skill Seekers Consultants,0 - 5 years,2.25-3 Lacs P.A.,"['Noida', 'New Delhi', 'Gurugram', 'Greater Noida', 'Delhi / NCR']","- Job Profile : Data Annotation\n- Location : Gurugram Sector 18\n- Rotational Shifts and Offs\n- Both side Cabs as per International Process\n- Excellent English speaking candidates\n- Freshers and Experienced candidates\n- Data Annotation Assessment\n\nRequired Candidate profile\nYouTube Channel - Sonu Chaurasiya\n\nInterview Location Video --- https://youtu.be/1AmXOLMEPEw\nGaurav Tower near Bank of Baroda pvr, , Vikaspuri, New Delhi, Delhi, 110018\n4th Floor- Waiting area",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Fluent English', 'Back Office', 'Interpretation', 'Data Annotation', 'BPO', 'Communication Skills', 'Transcription', 'Data Analysis', 'Data Collection', 'English Typing', 'Annotation', 'Strong Communication Skills']",2025-06-12 14:06:56
Data Scientist,Xoom,2 - 4 years,Not Disclosed,['Bengaluru'],"Job Summary\nWhat you need to know about the role\n\nEach Data Scientist on this team has full ownership of a portfolio of a product and is responsible for end-to-end management of loss and decline rates. Day-to-day duties include data analysis, monitoring and forecasting, creating the logic for and implementing risk rules and strategies, providing requirements to data scientists and technology teams on attribute, model and platform requirements, and communicating with global stakeholders to ensure we deliver the best possible customer experience while meeting loss rate targets.\n\nMeet our team\n\nPayPals Global Fraud Protection team is responsible for partnering with global business units to manage a variety of risk of various types, including identity fraud, account takeover, stolen financial fraud, and credit issues. This is an exciting department that plays an important role in contributing PayPals bottom line financial savings, ensuring safe and secure global business growth, and delivering the best customer experience.\n\nThis open opportunity is within the Large Merchant and Markets Fraud Risk team. This portfolio is comprised of PayPal s newest leading-edge payments solutions, such as Risk-as-Service, Fastlane, PayPal Complete Payments, etc. as well as customized experiences developed for the company s highest-priority strategic Markets and Partnerships.\nJob Description\nYour way to impact\nYou will be the Data Scientist in the Fraud Risk team , where you will work on leading new projects to build and improve the Risk strategies to prevent fraud using the Risk tooled and custom data & AL/ML models. In this position, you will be partnering with the corresponding Business Units to align with and influence their strategic priorities, educate business partners about Risk management principles, and collaboratively optimize the Risk treatments and experiences for these unique products and partners.\nYour day to day\nIn your day to day role you will -\nIn this role you will have full ownership of a portfolio of merchants and is responsible for end-to-end management of loss and decline rates.\nCollaborate with different teams to develop strategies for fraud prevention, loss savings, and optimize transaction declines or improve customer friction.\nYou will work together with cross-functional teams to deliver solutions and providing Risk analytics on frustration trend/ KPIs monitoring or alerting for fraud events.\nThese solutions will adapt PayPal s advanced proprietary fraud prevention tools enabling business growth.\nWhat do you need to bring-\n2-4 years of relevant experience working with large-scale complex dataset.\nStrong analytical mindset, ability to decompose business requirements into an analytical plan, and execute the plan to answer those business questions\nExcellent communication skills, equally adept at working with engineers as well as business leaders\nWant to build new solutions and invent new approaches to big, ambiguous, critical problems\nStrong working knowledge of Excel, SQL and Python/R\nTechnical Proficiency Exploratory Data Analysis and expertise in preparing a clean and structured data for model development. Experience in applying AI/ML techniques for business decisioning including supervised and unsupervised learning (e.g., regression, classification, clustering, decision trees, anomaly detection, etc.). Knowledge of model evaluation techniques such as Precision, Recall, ROC-AUC Curve, etc. along with basic statistical concepts.\nPreferred Qualification\nSubsidiary\nPayPal\nTravel Percent\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https//www.paypalbenefits.com .\nWho We Are\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. .\nBelonging at PayPal\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: Internet,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Risk analytics', 'Analytical', 'Diversity and Inclusion', 'ROC', 'Wellness', 'Risk management', 'Forecasting', 'Monitoring', 'SQL']",2025-06-12 14:06:58
"Program Analyst, Senior",Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Operations Group, Operations Group > Program Analyst\n\nGeneral Summary:\n\nAssists with program development and implementation through managing processes, procedures, and tools that improve efficiencies. A Program Analyst coordinates across teams and monitors timelines, budgets, risks, and priorities to achieve program progress. Typically, a program needing a Program Analyst will be of significant size and will require expertise related to the development of project management mechanisms.\n\nMinimum Qualifications:\n\nBachelors degree in engineering, Computer Science, or related field.\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Management, Computer Science, Engineering, Computer Science, or related field.\nOR\nHigh School Diploma or equivalent and 2+ years of relevant work experience.\n\nPreferred Qualifications:\n\nBachelors degree in electrical, Electronics engineering, Computer Science, or related field.\n\n3+ years of experience creating, scheduling, and maintaining program plans or related experience.\n2+ years of experience with program management tools.\n\nPrincipal Duties and Responsibilities:\nRegularly coordinates with third parties and/or internal customers for large, complex programs to identify and meet needs, track and communicate program status updates, and ensure compliance with processes and guidelines.\nPrepares and discusses agenda for review board meetings under guidance of the Program Manager and documents key discussion points, project plan changes, and stakeholder needs.\nContributes to and updates project plans to support Program Managers or Leads on large programs that include priorities, timelines, critical tasks, stakeholder identification for each task, and forecasted resource allocation.\nCollects, compiles, monitors, and maintains budget data, identifies potential issues, and communicates to the Program Manager.\nTracks the progress and execution of complex deliverables to ensure deadlines are met, and identifies and escalates issues that may impact deadlines.\nCoordinates schedules and task assignments for complex projects by following proper project management practices with some guidance from the Program Manager.\nManages and communicates changes in program timelines, priorities, and deliverables to stakeholders.\nIdentifies risks and issues in limited capacity that occur throughout the program lifecycle, communicates issues to the Program Manager, and identifies team members needed to determine a solution.\nGathers, analyzes, and interprets data and program metrics using advanced tools (e.g., macros, pivot tables, charts, graphs) and resolves inconsistencies.\nMaintains and updates databases using advanced aspects of data management tools (e.g., Excel, agile).\nSynthesizes moderately complex data and metrics into a summary of key trends, risks, and changes, and presents results into a report that can be easily understood by key stakeholders.\nGathers feedback and implements improvements to assigned planning processes, tools, and methods.\n\nLevel of Responsibility:\nWorking under some supervision.\nProviding some supervision/guidance to others.\nMaking decisions that are moderate in impact; errors may have relatively minor financial impact or affect on projects, operations, or customer relationships; errors may require involvement beyond immediate work group to correct.\nUsing verbal and written communication skills to convey information that may be somewhat complex to others who may have limited knowledge of the subject in question. May require basic negotiation and influence, cooperation, tact, and diplomacy, etc.\nCompleting most tasks with multiple steps which can be performed in various orders; some planning and prioritization must occur to complete the tasks effectively; mistakes may result in some rework.\nExercising creativity to draft original documents, imagery, or work products within established guidelines.\nUsing deductive problem solving to solve moderately complex problems; most problems have defined processes of diagnosis/detection; some limited data analysis may be required.\n\nThe responsibilities of this role do not include\nBudgetary accountability.\nInfluence over key organizational decisions.\nRole in strategic planning.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['project management', 'macros', 'program management', 'computer science', 'agile', '3d modeling', 'rest', 'data management', 'production', 'assembly design', 'design engineering', 'autocad', 'catia', 'part modeling', 'sheet metal design', 'solid works', 'drafting', 'creo', 'manufacturing', 'part design']",2025-06-12 14:07:01
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an exceptional Data Scientist to join a team of experts in the field of machine learning, and work together to tackle challenging problems across diverse compliance domains. We leverage risk models (including boosted trees and graph neural networks) as well as vision and large-language-models (LLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for multi-modal classification, intent detection, information retrieval, anomaly and fraud detection, and generative AI.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of image, text and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nExplore and evaluate state-of-the-art algorithms and approaches in risk modeling and vision/language models\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\nEvaluate model performance in production and refresh/implement necessary updates to maintain optimal system performance.\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nContributing to team retrospectives for continuous improvements\nParticipating in science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists building AI/ML solutions to make Amazon Earth s most trusted shopping destination for safe and compliant products. 2+ years of data scientist experience\n3+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience\n3+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\nExperience applying theoretical models in an applied environment\nKnowledge of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Experience in Python, Perl, or another scripting language\nExperience in a ML or data scientist role with a large technology company",,,,"['Data analysis', 'SAS', 'Neural networks', 'risk modeling', 'Machine learning', 'Information retrieval', 'Perl', 'MATLAB', 'Auditing', 'Python']",2025-06-12 14:07:03
Business Analyst,CGI,6 - 11 years,Not Disclosed,['Hyderabad'],"Business Data Analyst - HealthCare\nPosition Description\nJob Summary\nWe are seeking an experienced and results-driven Business Data Analyst with 5+ years of hands-on experience in data analytics, visualization, and business insight generation. This role is ideal for someone who thrives at the intersection of business and datatranslating complex data sets into compelling insights, dashboards, and strategies that support decision-making across the organization.\nYou will collaborate closely with stakeholders across departments to identify business needs, design and build analytical solutions, and tell compelling data stories using advanced visualization tools.\nKey Responsibilities\nData Analytics & Insights Analyze large and complex data sets to identify trends, anomalies, and opportunities that help drive business strategy and operational efficiency.\n• Dashboard Development & Data Visualization Design, develop, and maintain interactive dashboards and visual reports using tools like Power BI, Tableau, or Looker to enable data-driven decisions.\n• Business Stakeholder Engagement Collaborate with cross-functional teams to understand business goals, define metrics, and convert ambiguous requirements into concrete analytical deliverables.\n• KPI Definition & Performance Monitoring Define, track, and report key performance indicators (KPIs), ensuring alignment with business objectives and consistent measurement across teams.\n• Data Modeling & Reporting Automation Work with data engineering and BI teams to create scalable, reusable data models and automate recurring reports and analysis processes.\n• Storytelling with Data Communicate findings through clear narratives supported by data visualizations and actionable recommendations to both technical and non-technical audiences.\n• Data Quality & Governance Ensure accuracy, consistency, and integrity of data through validation, testing, and documentation practices.\nRequired Qualifications\nBachelor’s or Master’s degree in Business, Economics, Statistics, Computer Science, Information Systems, or a related field.\n• 5+ years of professional experience in a data analyst or business analyst role with a focus on data visualization and analytics.\n• Proficiency in data visualization tools: Power BI, Tableau, Looker (at least one).\n• Strong experience in SQL and working with relational databases to extract, manipulate, and analyze data.\n• Deep understanding of business processes, KPIs, and analytical methods.\n• Excellent problem-solving skills with attention to detail and accuracy.\n• Strong communication and stakeholder management skills with the ability to explain technical concepts in a clear and business-friendly manner.\n• Experience working in Agile or fast-paced environments.\nPreferred Qualifications\nExperience working with cloud data platforms (e.g., Snowflake, BigQuery, Redshift).\n• Exposure to Python or R for data manipulation and statistical analysis.\n• Knowledge of data warehousing, dimensional modeling, or ELT/ETL processes.\n• Domain experience in Healthcare is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Healthcare Domain', 'Bigquery', 'Redshift Aws', 'Snowflake', 'Data Analytics', 'Data Visualization', 'Python']",2025-06-12 14:07:05
Financial Data Operator,International Communication Services India Private Limited,0 - 2 years,Not Disclosed,['Pune'],"*Job Description:\n-We are looking for a detail-oriented Financial Data Operator to join our team.\n-Your primary responsibility will be to update, maintain, and record financial information in both Japanese and English using computerized databases.\n-The accuracy of these records will directly support our clients' operations.\n*Responsibilities:\n-Accurately collect and enter data into financial databases.\n-Maintain precise records in Japanese and English.\n-Perform routine data checks to ensure accuracy and consistency.\n-Utilize spreadsheets and online tools efficiently.\n-Collaborate with the team to troubleshoot and solve challenges effectively.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer Proficiency', 'Team Coordination', 'Jlpt N4', 'Data Analysis', 'Typing Skills', 'Teamwork']",2025-06-12 14:07:07
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an exceptional Data Scientist to join a team of experts in the field of machine learning, and work together to tackle challenging problems across diverse compliance domains. We leverage multi-modal and large-language-models (LLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for multi-modal classification, intent detection, information retrieval, anomaly and fraud detection, and generative AI.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of image, text and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nExplore and evaluate state-of-the-art algorithms and approaches in multi-modal classification, large language models (LLMs), intent detection, information retrieval, anomaly and fraud detection, and generative AI\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nContributing to team retrospectives for continuous improvements\nParticipating in science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists building AI/ML solutions to make Amazon Earth s most trusted shopping destination for safe and compliant products. 2+ years of data scientist experience\n2+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience\n2+ years of machine learning/statistical modeling data analysis tools and techniques, and parameters that affect their performance experience\nExperience applying theoretical models in an applied environment\nKnowledge of relevant statistical measures such as confidence intervals, significance of error measurements, development and evaluation data sets, etc. Experience in Python, Perl, or another scripting language\nExperience in a ML or data scientist role with a large technology company",,,,"['Data analysis', 'Statistical modeling', 'SAS', 'Machine learning', 'Information retrieval', 'Perl', 'MATLAB', 'Fraud detection', 'Auditing', 'Python']",2025-06-12 14:07:10
Data Scientist,New Relic One,2 - 7 years,Not Disclosed,['Bengaluru'],"We are seeking an experienced and dynamic Senior Data Scientist to join our team. You will be primarily responsible for driving data-oriented projects and transforming ambiguous business problems into clear, actionable insights as well as productionalizing insights. The ideal candidate is adept at understanding the business needs that are often quantitatively ambiguous and using large complex data sets to find opportunities for product and process optimization.\nWhat youll do\nAnalyzing complex datasets, applying advanced statistical methods as necessary (e.g., time series forecasting, classification, linear/logistic regression).\nDesigning and deploying data-science and technology-based algorithmic solutions to address business needs.\nTranslating data findings into actionable business insights and plans.\nCollaborating effectively with internal stakeholders, understanding their needs and being able to communicate data-driven recommendations.\nPresenting information using data visualization techniques and clearly communicating complex findings and ideas to non-technical stakeholders.\nThis role requires\n2+ years of experience\nProven experience as a Data Scientist, or in a similar role.\nPhD or Masters degree in Statistics, Mathematics, Computer Science, or related quantitative field.\nStrong understanding and application of advanced statistical techniques and concepts, including but not limited to machine learning algorithms, classification, regression, and time series analysis.\nProficiency with data analysis tools and languages such as Python, SQL, etc.\nFamiliarity with data visualization tools (e.g., Looker, Tableau, PowerBI, etc.).\nStrong problem-solving abilities, business acumen, and excellent communication skills.\nAbility to work independently and with minimal supervision.Proven ability in managing and delivering on multiple, competing priorities.\nPrior experience with stakeholder management and ability to present complex data in a clear manner to non-technical audience.\nBonus points if you have\nExperience in Observability is a plus.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAN', 'Logistic regression', 'Data analysis', 'Process optimization', 'Machine learning', 'Stakeholder management', 'Forecasting', 'SQL', 'Python']",2025-06-12 14:07:12
Senior Business Analyst,Skillsoft Software Services,2 - 7 years,Not Disclosed,['Hyderabad'],"India-based candidates only. We’re primarily a NYC-based team, but have a growing international team. \n \nROLE OVERVIEW:  \nAs a Senior Data Analyst, you will be pivotal in driving strategic decision-making for the Codecademy consumer and enterprise business lines. Reporting to the senior manager, Strategy and business Operations, this role will work cross-functionally to tackle the business’ highest priorities. You will utilize your technical expertise in data analytics, financial modeling, and executive communication to create actionable business strategies that drive growth.",,,,"['snowflake', 'python', 'data analytics', 'data analysis', 'modeling', 'analytical', 'verbal communication', 'business analysis', 'sql', 'analytics', 'marketing analytics', 'data integration tools', 'looker', 'writing', 'financial modelling', 'data visualization', 'business operations', 'reporting', 'communication skills']",2025-06-12 14:07:15
MDM Associate Data Steward,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\n\nRole Description\n\nWe are seeking an MDM Associate Data Steward who will be responsible for ensuring the accuracy, completeness, and reliability of master data across critical business domains such as Customer, Product, Affiliations, and Payer. This role involves actively managing and curating master data through robust data stewardship processes, comprehensive data cataloging, and data governance frameworks utilizing Informatica or Reltio MDM platforms. Additionally, the incumbent will perform advanced data analysis, data validation, and data transformation tasks through SQL queries and Python scripts to enable informed, data-driven business decisions. The role emphasizes cross-functional collaboration with various teams, including Data Engineering, Commercial, Medical, Compliance, and IT, to align data management activities with organizational goals and compliance standards.\n\nRoles & Responsibilities\nResponsible for master data stewardship, ensuring data accuracy and integrity across key master data domains (e.g., Customer, Product, Affiliations).\nConduct advanced data profiling, cataloging, and reconciliation activities using Informatica or Reltio MDM platforms.\nManage the reconciliation of potential matches, ensuring accurate resolution of data discrepancies and preventing duplicate data entries.\nEffectively manage Data Change Request (DCR) processes, including reviewing, approving, and documenting data updates in compliance with established procedures and SLAs.\nExecute and optimize SQL queries for validation and analysis of master data.\nPerform basic Python for data transformation, quality checks, and automation.\nCollaborate effectively with cross-functional teams including Data Engineering, Commercial, Medical, Compliance, and IT to fulfill data requirements.\nSupport user acceptance testing (UAT) and system integration tests for MDM related system updates.\nImplement data governance processes ensuring compliance with enterprise standards, policies, and frameworks.\nDocument and maintain accurate SOPs, Data Catalogs, Playbooks, and SLAs.\nIdentify and implement process improvements to enhance data stewardship and analytic capabilities.\nPerform regular audits and monitoring to maintain high data quality and integrity.\nBasic Qualifications and Experience\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related fieldOR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related fieldOR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional\n\nSkills:\nMust-Have Skills:\nDirect experience in data stewardship, data profiling, and master data management.\nHands-on experience with Informatica or Reltio MDM platforms.\nProficiency in SQL for data analysis and querying.\nKnowledge of data cataloging techniques and tools.\nBasic proficiency in Python scripting for data processing.\nGood-to-Have\n\nSkills:\nExperience with PySpark and Databricks for large-scale data processing.\nBackground in the pharmaceutical, healthcare, or life sciences industries.\nFamiliarity with AWS or other cloud-based data solutions.\nStrong project management and agile workflow familiarity (e.g., using Jira, Confluence).\nUnderstanding of regulatory compliance related to data protection (GDPR, CCPA).\nProfessional Certifications\nAny ETL certification ( e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nSoft\n\nSkills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data management', 'python', 'project management', 'data analysis', 'data stewardship', 'agile database', 'data processing', 'sql', 'data profiling']",2025-06-12 14:07:17
Senior Functional Business Analyst,Luxoft,5 - 10 years,Not Disclosed,['Gurugram'],"Work closely with business stakeholders to understand, document, and prioritize requirements.\nConduct detailed analysis of current-state processes for client onboarding, credit scoring, lending workflows, and compliance.\nDefine and document user stories, functional specifications, process flows, and data mappings.\nSupport the product owner with backlog refinement, sprint planning, and prioritization.\nFacilitate workshops and walkthroughs with subject matter experts.\nEnsure alignment between business requirements and technical deliverables.\nAssist with UAT planning, test case development, and defect triaging.\nMaintain strong communication with project managers, developers, testers, and stakeholders throughout the SDLC.\nSkills\nMust have\n5+ years of experience as a Functional Business Analyst in the banking or financial services domain.\nProven domain expertise in at least three of the following:\nC&IB Client Onboarding\nCredit and Risk Scoring\nLending Processes\nAML (Anti-Money Laundering)\nKYC\nStrong verbal and written communication skills in English.\nAbility to create structured and well-documented artefacts (resumes will be reviewed for documentation quality).\nExperience working in Agile delivery models (Scrum, SAFe).\nFamiliarity with tools like JIRA, Confluence, and MS Office Suite.\nNice to have\nExposure to regulatory change or transformation programs.\nKnowledge of GRC platforms or tools (e.g., Archer, ServiceNow GRC).\nPrior experience in data analysis or data mapping activities.\nFamiliarity with integration patterns between front-office and back-office systems.\nAwareness of global banking regulations and compliance frameworks.\nOther\nLanguages\nEnglish: B2 Upper Intermediate\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nJunior Implementation Consultant\nOther Vendor specific (Quantum, Coremont etc.)\nSingapore\nSingapore\nFunctional BA (Orchestrade/Murex/Calypso)\nOther Vendor specific (Quantum, Coremont etc.)\nHong Kong\nHong Kong\nJunior Implementation Consultant\nOther Vendor specific (Quantum, Coremont etc.)\nSingapore\nSingapore\nGurugram, India\nReq. VR-114629\nOther Vendor specific (Quantum, Coremont etc.)\nBCM Industry\n27/05/2025\nReq. VR-114629\nApply for Senior Functional Business Analyst in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Front office', 'Agile', 'calypso', 'Back office', 'Scrum', 'JIRA', 'SDLC', 'Murex', 'Financial services']",2025-06-12 14:07:19
Manager-Business Analyst,Jubilant FoodWorks (JFL),8 - 12 years,Not Disclosed,['Noida'],"The IT Business Analyst is responsible for bridging business needs and IT capabilities, ensuring that technology solutions align with strategic objectives. This role involves analysing business processes including SAP, gathering requirements, and collaborating with IT teams to develop effective solutions. The ideal candidate has strong analytical skills, deep understanding of both business processes preferably Finance background along with IT systems including SAP, and experience in project management.\n\nKey Responsibilities:\n\nBusiness Requirements Gathering\nWork with business stakeholders to identify needs, pain points, and opportunities for process improvement.\nDocument business requirements in clear, detailed formats for technical teams.\n\nSolution Design and Analysis\nAnalyze and evaluate technology solutions that best align with business requirements.\nCreate functional specifications, use cases, and workflow diagrams to communicate solutions effectively.\n\nProject Support and Coordination\nCollaborate with project managers to ensure that projects meet business goals and timelines.\nTrack progress and provide updates on requirements, ensuring adherence to project scope and budget.\n\nTesting and Quality Assurance\nDevelop test cases and participate in system testing to validate that requirements are met.\nAssist in User Acceptance Testing (UAT) and ensure successful project delivery.\n\nContinuous Improvement and Documentation\nRecommend improvements to business processes based on data analysis.\nMaintain and update documentation for requirements, processes, and system changes.\n\nPreferred qualification & skills\n\nBachelors degree preferably in Finance Business, IT, or a related field.\n8+ years of experience in business analysis or a similar role. Experience of Finance & HR domain is preferred under QSR Industry.\nStrong analytical and problem-solving skills, with experience in requirements gathering and process improvement.\nExcellent communication skills, with the ability to work cross-functionally.\nFamiliarity with project management methodologies (Agile, Waterfall).\nKnowledge of data analysis and ERP preferably SAP, CRM, or other business applications.",Industry Type: Hotels & Restaurants,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['User Acceptance Testing', 'SAP', 'Digital Transformation', 'Business Transformation', 'Digitization', 'Process Improvement']",2025-06-12 14:07:21
Data Scientist,Neoware Technology Solutions,3 - 7 years,Not Disclosed,"['Chennai', 'Bengaluru']","Data Scientist - Neoware Technology Solutions Private Limited\nRequirements\nDevelop predictive and prescriptive models to optimize business outcomes and drive growth.\nDesign and build Generative AI solutions to enhance business capabilities.\nWork with leading cloud platforms such as AWS, Azure, or GCP.\nProcess and analyze unstructured data using NLP and Computer Vision techniques.\nLead data-driven initiatives and collaborating with stakeholders to understand business needs and develop strategic solutions.\nConduct exploratory data analysis (EDA) to identify patterns, trends and insights in large, complex datasets.\nMentor and coach junior team members, providing technical guidance and fostering a culture of continuous learning and innovation.\nResponsibilities\nB.E. / Masters in Computer Science, Statistics, Applied Mathematics, Economics or a related quantitative field.\n3-7years of experience in data science, with a proven track record of delivering impactful business solutions.\nStrong proficiency in Python/R and SQL; experience with cloud platforms (AWS, Azure or GCP) is a plus.\nSolid understanding of machine learning techniques (classification, regression, clustering) and statistical methods.\nExcellent communication skills, with the ability to convey complex concepts to diverse audiences.\nStrong problem-solving abilities and capability to work both independently and in a team environment\nChennai / Bangalore / Mumbai\nPrincipal Architect (Data and Cloud) Development",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'Data analysis', 'GCP', 'Machine learning', 'Cloud', 'Business solutions', 'AWS', 'SQL', 'Python']",2025-06-12 14:07:23
CPU Performance & Power Analyst/Sr Lead Engineer - 5 Open positions,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 5 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:25
"Senior Data Engineer ( T-SQL & SSIS,Data Warehousing & ETL Specialist)",Synechron,5 - 10 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Job Summary\nSynechron is seeking a highly skilled Senior Data Engineer specializing in T-SQL and SSIS to lead and advance our data integration and warehousing initiatives. In this role, you will design, develop, and optimize complex ETL processes and database solutions to support enterprise data needs. Your expertise will enable efficient data flow, ensure data integrity, and facilitate actionable insights, contributing to our organizations commitment to data-driven decision-making and operational excellence.\nSoftware Requirements\nRequired Skills:\nProficiency in SQL Server, advanced T-SQL querying, stored procedures, functions, and scripting\nExpertise in SQL Server Integration Services (SSIS), including design, deployment, and troubleshooting\nDeep understanding of data warehousing concepts, schema design, and ETL best practices\nExperience in performance tuning, query optimization, and troubleshooting SQL and SSIS packages\nHands-on experience with database security, compliance, and data masking standards\nFamiliarity with source system analysis and complex data migration\nPreferred Skills:\nExperience with cloud platforms (Azure Data Factory, AWS Glue)\nKnowledge of Azure SQL, Amazon RDS or other cloud-based data services\nExperience with scripting languages like PowerShell or Python for automation\nOverall Responsibilities\nDesign, develop, and maintain robust ETL workflows using SSIS to meet diverse data integration requirements\nWrite optimized, scalable T-SQL queries, stored procedures, and functions aligned with data quality standards\nDevelop and manage data warehouse schemas, tables, and relationships to support reporting and analytics\nEnsure data accuracy, security, and compliance across all data processes\nCollaborate closely with business analysts and other stakeholders to understand data requirements and translate them into technical solutions\nTroubleshoot and resolve performance issues in SQL Server and SSIS packages\nDocument data workflows, schemas, and data mappings to support ongoing maintenance and audits\nParticipate in code reviews, performance tuning, and implementing best practices for ETL and database management\nSupport data migration projects and facilitate seamless data transfers between systems\nTechnical Skills (By Category)\nProgramming Languages:\nEssential: T-SQL, SQL\nPreferred: PowerShell, Python, or similar scripting languages for automation and scripting\nDatabases & Data Management:\nEssential: SQL Server (2016 or higher), relational data modeling, ETL processes\nPreferred: Azure SQL, Amazon RDS, or other cloud-based databases\nFrameworks & Libraries:\nEssential: SSIS (SQL Server Integration Services) packages and components\nPreferred: Data analysis libraries (e.g., Pandas, Power BI integrations)\nDevelopment Tools & Methodologies:\nEssential: SQL Server Management Studio (SSMS), Visual Studio, SQL Server Data Tools (SSDT), version control (Git)\nPreferred: Azure Data Factory, DevOps pipelines, automated deployment tools\nDesign & Architecture:\nData warehouse schema design (star schema, snowflake)\nData flow and process automation best practices\nSecurity & Compliance:\nBasic understanding of database security, access control, and data masking standards\nExperience Requirements\nMinimum of 5+ years working in database development, data warehousing, or ETL processing\nProven experience designing and optimizing large-scale ETL workflows in enterprise environments\nDemonstrated proficiency in writing complex T-SQL queries, stored procedures, and functions\nExperience with SSIS, including package development, deployment, and troubleshooting\nBackground in data migration and data governance is preferred\nIndustry experience in financial services, banking, or large enterprise environments is advantageous\nAlternative pathways include extensive hands-on experience or relevant professional training in ETL and database management\nDay-to-Day Activities\nDevelop, test, and deploy robust ETL workflows using SSIS to meet business needs\nBuild and optimize T-SQL queries, stored procedures, and functions for performance and reliability\nAnalyze source system data structures, identify best-fit schemas, and design data warehouse models\nMonitor and troubleshoot ETL processes, resolving performance bottlenecks and errors\nCollaborate with stakeholders to gather requirements and translate them into technical designs\nReview and optimize database performance and security configurations\nDocument data models, mappings, and processes for operational clarity\nEngage in regular team meetings, code reviews, and process improvement initiatives\nQualifications\nBachelors degree or higher in Computer Science, Information Technology, or related field\nRelevant certifications such as Microsoft Certified: Data Engineer or SQL Server certifications (preferred)\nProven track record of designing and maintaining enterprise data warehouses and ETL processes\nProfessional Competencies\nCritical thinking and analytical skills to troubleshoot complex data issues\nStrong communication skills for effective stakeholder engagement and documentation\nAbility to work independently and collaboratively in a fast-paced environment\nAdaptability to evolving data technologies and requirements\nResults-oriented with excellent time and priority management\nCommitment to continuous improvement and learning new data management techniques.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'T-SQL', 'Azure Data Factory', 'query optimization', 'performance tuning', 'database security', 'AWS Glue', 'Data Warehousing', 'SSIS', 'ETL']",2025-06-12 14:07:28
CPU Performance & Power Analyst/Sr Staff Engineer - 3 Open positions,Qualcomm,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 5+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 12 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'uart', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:30
CPU Performance and Power Analyst/Sr Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 4+ years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:33
CPU Performance and Power Analyst/Sr Staff Engineer,Qualcomm,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 5+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 12 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:07:35
Market Intelligence Associate Analyst,Salesforce,3 - 4 years,Not Disclosed,['Bengaluru'],"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.\nJob Category\nData\nJob Details\nAbout Salesforce\nCustomer & Market Intel Overview:\nWe re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good - you ve come to the right place.\nDo you enjoy a blend of strategy and research? The Customer & Market Intel team partners directly with the Sales team as a trusted advisor, focused on providing strategic insights around our customers, prospects, industries, CXOs, and Competitors. You will collaborate with many cross-functional teams such as Strategy, Marketing Operations, Programs, Enablement, Sales Dev, and others. This is a high-velocity and high-impact role, with constantly evolving priorities and demands.\nImpact:\nAs a Market Intelligence Associate Analyst at Salesforce, you will play a critical role in gathering, analyzing, and synthesizing information to provide strategic insights and support to our business. Your primary responsibility will be to ensure that our company remains informed about key market trends, what s happening in our client s organizations as well as key competitor activities. You will work closely with various departments, including Strategy, Marketing Operations, Programs, Enablement, Sales Dev, to help shape our strategies and initiatives.\nKey Responsibilities:\nCustomer & Persona Insights:\nResearch about the company- Overview, numbers, trends, key leadership & stakeholders, value chain, recent initiatives, strategic & tech priorities, Current Tech landscape, Digital Audit, etc.\nLeveraging the above research to create detailed PoV on how Salesforce can help that customer succeed\nCreate detailed customer profiles for sales understanding - What s top of mind of a persona and how can we support that persona\nIndustry PoVs & Bashos:\nResearch about the industry - numbers, trends, key players, value chain, recent initiatives, strategic & tech priorities\nLeveraging the above research to create emails/Bashos as well as detailed PoV on how Salesforce can help customers of that industry\nCompetitor Insights:\nEvaluating a competitor s focus areas - products, verticals, geographies, etc.\nComparison of Competitor s strengths vs ours\nCreating Win Wires:\nOne-stop solution for sales reps on won deals\nHighlights customer challenges and use cases sold\nWin-loss analysis: Identify and call out the reason for winning a deal and how can we scale it\nRequirements:\nBachelors degree or equivalent experience in Business, Strategy, Marketing or related field. MBA preferred\nCompetence in market research and competitive analysis\nExcellent communication and presentation skills\nKnowledge of industry trends and market dynamics\nDemonstrated business acumen and understanding of sales and research processes.\nStrong analytical skills and proficiency in data analysis\nRelated experience 3-4 years+ in sales research or saas sales.\nAccommodations\nIf you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .\nPosting Statement",Industry Type: Internet,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Data analysis', 'Sales', 'Competitive analysis', 'Market intelligence', 'Market research', 'Marketing operations', 'Business strategy', 'Research', 'Salesforce', 'Auditing']",2025-06-12 14:07:38
Business Analyst - Configuration Management,Moodys Investors Service,3 - 8 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: Technology Services Group(TSG)\nJob Category:\nEngineering & Technology\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nPosition Overview\nWe are looking for a skilled Configuration Management Data Analyst with expertise in ServiceNow to manage, analyze, and optimize configuration data across our organization. The ideal candidate will play a critical role in maintaining the accuracy and integrity of our Configuration Management within ServiceNow, ensuring alignment with ITIL best practices and supporting business decision-making. This role requires a strong background in ServiceNow, analytical capabilities, and a collaborative approach to working with cross-functional teams.\nKey Responsibilities\n1. Configuration Management Administration and Maintenance\no Maintain and enhance the ServiceNow CMDB to ensure data accuracy, completeness, and compliance with organizational standards.\no Regularly audit configuration data to identify inconsistencies, address gaps, and enforce data governance policies.\no Design and implement automated workflows within ServiceNow to streamline data updates and ensure real-time accuracy.\n2. Data Analysis and Reporting\no Analyze configuration data stored in ServiceNow to identify trends, risks, and opportunities for optimization.\no Create and maintain dashboards, reports, and KPIs within ServiceNow to provide actionable insights to stakeholders.\no Provide data-driven recommendations to improve IT infrastructure and configuration management processes.\n3. Collaboration and Process Improvement\no Work closely with IT, operations, and engineering teams to ensure the proper integration of configuration management processes with business objectives.\no Act as a subject matter expert for CMDB best practices and ServiceNow capabilities, providing training and support to teams as needed.\n4. ServiceNow Development and Optimization\no Collaborate with ServiceNow developers to customize CMDB modules, workflows, and scripts based on organizational needs.\no Stay up-to-date with ServiceNow platform updates, features, and releases to identify opportunities for improved functionality.\no Troubleshoot and resolve technical issues related to ServiceNow CMDB operations.\nExperience and Qualification\n* 3+ years of experience in configuration management, data analysis, or CMDB administration, preferably in financial services.\n* Hands-on experience with ServiceNow, including CMDB module administration and customization.\n* Strong understanding of ITIL principles, particularly Configuration Management.\n* Proficiency in creating dashboards, reports, and workflows within ServiceNow.\n* Bachelor s degree in Information Technology, Computer Science, or a related field.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Configuration management', 'Analytical', 'Process improvement', 'data governance', 'IT operations', 'Information technology', 'Financial services', 'Auditing']",2025-06-12 14:07:40
"Finance Analyst, IN Amazon Now Finance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"Amazon seeks a Finance Analyst to be a key member of its Now (Quick Commerce) Finance team. The person would play a pivotal role in driving the business agenda and would work as a copilot in delivering business results while driving the P&L for the Now business. This includes responsibility for financial metrics, reporting, forecasting, and providing decision support through data analysis & business insights.\n\nThe Finance Analyst position is based in Bangalore.\n\n\nThe successful candidate will be strategic, analytical, and will need to demonstrate ability to effectively manage finances of a high-growth business including:Drive financial reporting and analysis for Now business, including daily/weekly business reviews, variance analysis, and real-time operational metrics tracking\nPartner with business teams to analyze and optimize key metrics like order density, delivery speed, catalog availability, and dark store economics\nDevelop and maintain P&L forecasting models, incorporating key business levers across dark stores and delivery network\nProvide controllership support and build scalable processes that enhance transparency and strengthen controls across high-velocity operations\nSupport business reviews with leadership team, focusing on unit economics and network efficiency\nPartner with operations teams to analyze and optimize dark store costs, delivery economics, and inventory holding costs\nWork closely with category teams to analyze and improve product margins and inventory turns\nDrive monthly, quarterly, and annual financial close process in partnership with accounting teams\nPerform ad-hoc analysis and financial modeling to support network expansion and strategic initiatives\nPresent data-driven recommendations to senior management on growth and profitability initiatives ideal candidate should possess good analytical skills, attention to detail, and the ability to work effectively in a dynamic, fast-paced environment while managing multiple stakeholders in real-time operations. 2+ years of finance experience\n2+ years of applying key financial performance indicators (KPIs) to analyses experience\nKnowledge of standard software including Excel, Access, Oracle, Essbase, SQL and VBA skills\nExperience using data to influence business decisions\nExperience in corporate finance including budgeting/planning, forecasting and reporting\nChartered Accountant or MBA (Finance) 2+ years of participating in continuous improvement projects in your team to scale and improve controllership with measurable results experience\nExperience of working in ecommerce/Quick commerce domain",,,,"['Data analysis', 'Financial reporting', 'Corporate finance', 'Budgeting', 'Oracle', 'Continuous improvement', 'Forecasting', 'Variance analysis', 'Operations', 'SQL']",2025-06-12 14:07:43
"Data Scientist II, Regulatory Intelligence, Safety, and Compliance",Amazon,2 - 7 years,Not Disclosed,['Bengaluru'],"About Amazon Regulatory Intelligence, Safety, and Compliance (RISC).\n\nAmazon RISC s vision is to make Amazon the Earth s most trusted shopping destination for safe and compliant products. Towards this mission, we take a science-first approach to building technology, products and services, that protect customers from unsafe, illegal, controversial, or policy-violating products while offering the optimal selling partner experience.\n\nJob Summary\n\nWe are seeking an exceptional Data Scientist to join a team of experts in the field of AI/ML, and work together to tackle challenging business problems across diverse compliance domains. We leverage and train state-of-the-art multi-modal, large-language-models (LLMs), and vision language models (VLMs) to detect illegal and unsafe products across the Amazon catalog. We work on machine learning problems for generative AI, agentic system, multi-modal classification, intent detection, information retrieval, anomaly and fraud detection.\n\nThis is an exciting and challenging position to deliver scientific innovations into production systems at Amazon-scale to make immediate, meaningful customer impacts while also pursuing ambitious, long-term research. You will work in a highly collaborative environment where you can analyze and process large amounts of images, texts, documents, and tabular data. You will work on hard science problems that have not been solved before, conduct rapid prototyping to validate your hypothesis, and deploy your algorithmic ideas at scale. There will be something new to learn every day as we work in an environment with rapidly evolving regulations and adversarial actors looking to outwit your best ideas.\n\n\nDesign and evaluate state-of-the-art algorithms and approaches in generative AI, agentic system, multi-modal classification, intent detection, information retrieval, anomaly and fraud detection.\nTranslate product and CX requirements into measurable science problems and metrics.\nCollaborate with product and tech partners and customers to validate hypothesis, drive adoption, and increase business impact\nKey author in writing high quality scientific papers in internal and external peer-reviewed conferences.\n\nA day in the life\nUnderstanding customer problems, project timelines, and team/project mechanisms\nProposing science formulations and brainstorming ideas with team to solve business problems\nWriting code, and running experiments with re-usable science libraries\nReviewing labels and audit results with investigators and operations associates\nSharing science results with science, product and tech partners and customers\nWriting science papers for submission to peer-review venues, and reviewing science papers from other scientists in the team.\nContributing to team retrospectives for continuous improvements\nDriving science research collaborations and attending study groups with scientists across Amazon\n\nAbout the team\nWe are a team of scientists and engineers building AI/ML solutions to make Amazon the Earth s most trusted shopping destination for safe and compliant products. PhD, or Masters degree with 2+ years of machine learning experience, or bachelor degree with 3+ years of machine learning experience\nExperience programming in Python, Java, C++, or related language\nExperience with neural deep learning methods, LLM, and natural language processing\nExperience with conducting research in a corporate setting Experience with large scale machine learning systems such as profiling and debugging and understanding of system performance and scalability",,,,"['deep learning', 'C++', 'Debugging', 'Machine learning', 'Information retrieval', 'Natural language processing', 'Scientist II', 'Fraud detection', 'Auditing', 'Python']",2025-06-12 14:07:45
AVP - Finance Analyst,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Finance Analyst\n\nIn this role, you will:\nParticipate in functions related to financial research and reporting\nForecast analysis of key metrics, as well as other financial consulting related to business performance, operating and strategic reviews",,,,"['financial research', 'Data analysis', 'Project management', 'documentation', 'Gap analysis', 'financial consulting', 'SQL']",2025-06-12 14:07:48
Data Scientist,H3 Technologies,3 - 8 years,Not Disclosed,['Thiruvananthapuram'],"Position: Data Scientist\nLocation: Trivandrum\nJob Description :\nWe are urgently looking for a motivated Data Scientist with a focus on Computer Vision and Machine Learning. The candidate will have a passion for solving complex problems using deep learning, image processing, and AI-driven techniques. He shall work closely with a team of data scientists, engineers, etc and to build, optimize, and deploy machine learning models for real-world applications\nKey Responsibilities :\nDevelop, train, and optimize deep learning models for image classification, object detection, segmentation, and other computer vision tasks.\nImplement and fine-tune machine learning algorithms for structured and unstructured data analysis.\nPreprocess and augment image/video datasets to improve model accuracy and robustness.\nWork with frameworks such as YOLO, TensorFlow, PyTorch, and OpenCV to build scalable models.\nAssist in deploying models to production environments, including cloud and edge computing platforms.\nCollaborate with cross-functional teams to integrate AI solutions into existing workflows and products.\nStay up-to-date with the latest research and trends in AI, computer vision, and machine learning.\nQualifications :\nBachelors or masters degree in computer science, Data Science, AI/ML, or a related field.\nMinimum of 3 year of professional experience in Python programming and AI/ML integrations\nSolid understanding of machine learning concepts, neural networks, and deep learning architectures.\nHands-on experience in training and optimizing computer vision models.\nFamiliarity with data preprocessing techniques, image annotation tools, and model evaluation metrics.\nStrong problem-solving skills and the ability to work in a fast-paced environment.\nJoining: Immediate to less than 30 days\nBudget: 13 - 14 LPA\n"",",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'deep learning', 'Data analysis', 'Image processing', 'data science', 'Neural networks', 'Machine learning', 'Budgeting', 'Python']",2025-06-12 14:07:50
Senior Analyst - Direct Display,Merkle B2b,2 - 8 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-12 14:07:52
Data Scientist For DMAI,Prodapt Solutions,2 - 5 years,Not Disclosed,['Chennai'],"Overview\n\nThe Senior Data Science Engineer will leverage advanced data science techniques to solve complex business problems, guide decision-making processes, and mentor junior team members. This role requires a combination of technical expertise in data analysis, machine learning, and project management skills.\n\nResponsibilities\n\n Data Analysis and Modeling Analyze large-scale telecom datasets to extract actionable insights and build predictive models for network optimization and customer retention.\n Conduct statistical analyses  to validate models and ensure their effectiveness.\n Machine Learning Development Design and implement machine learning algorithms for fraud detection, churn prediction, and network failure analysis.\n Telecom-Specific Analytics Apply domain knowledge to improve customer experience by analyzing usage patterns, optimizing services, and predicting customer lifetime value.\n ETL Processes Develop robust pipelines for extracting, transforming, and loading telecom data from diverse sources.\n Collaboration Work closely with data scientists, software engineers, and telecom experts to deploy solutions that enhance operational efficiency.\n Data Governance :  Ensure data integrity, privacy, security and compliance with industry standards\n\n\nAdvanced degree in Data Science, Statistics, Computer Science, or a related field.\nExtensive experience in data science roles with a strong focus on machine learning and statistical modeling.\nProficiency in programming languages such as Python or R and strong SQL skills.\nFamiliarity with big data technologies (e.g., Hadoop, Spark) is advantageous.\nExpertise in cloud platforms such as AWS or Azure.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'machine learning', 'sql', 'statistical modeling', 'algorithms', 'python', 'big data technologies', 'microsoft azure', 'cloud platforms', 'r', 'data science', 'spark', 'data governance', 'hadoop', 'aws', 'etl', 'machine learning algorithms', 'statistics']",2025-06-12 14:07:54
Project Analyst Senior,Qualcomm,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Area: Operations Group, Operations Group > Project Analyst\n\nGeneral Summary:\n\nJob OverviewQualcomm Customer Engineering team is seeking a highly organized, self-motivated problem solver with exceptional communication skills and expertise as a Salesforce Service Cloud Specialist. The ideal candidate will have\n\nSalesforce administrative experience with\n\na strong knowledge of standard (out-of-the-box) Salesforce administrative functions and features, including but not limited to\n\nreports/dashboards, case assignments, validations, and profiles/permissions sets. This individual will work closely with Operations, Administrators, Customer Engineering, and IT Development teams to\n\nsupport, organize, prioritize, manage and deliver\n\na large variety of support requests and issues by leveraging established processes, solutions, or features and escalating/driving improvements when necessary. This role requires the\n\nability to\n\nextract business needs,\n\nidentify and promote existing solutions/workarounds,\n\nconnect stakeholders, discover answers or data, assess impact,\n\ncollect requirements, write and define user stories, perform user acceptance testing, write/update user trainings,\n\nand promote user adoption of new solutions. Salesforce Admin, Business Analys, and/or Advanced Admin certification is preferred.\n\nResponsibilities include:\nUtilize\n\nbroad knowledge of Salesforce Service Cloud to support internal and external customers as well as the company's programs\n\nthough standard and available custom features.\nCollaborate with Data and Business Analysts, System Administrators, Development teams, and Customer Engineers to\n\ncollect, interpret, analyze, and document use, functional, and technical requirements for new projects and enhancements.\nMust\n\ntriage and share solutions/workarounds/status updates for known system issues, compile and prioritize new issues, and test/QA delivered solutions.\nEnsures\n\neffective\n\nprocessing of internal stakeholder support tickets submitted through JIRA by internal users for support on case team management, customer role/profile changes, attachment visibility, tools licensing, general tech support and use of the system(s), system downtime and case assignment corrections/redirections.\n\n\nBackup of administrative business operations around case support entitlement for contractually licensed customers, case assignment rule and queue, reports and dashboards, and other administratively controlled operational functions.\nEnabling users and supporting business needs through profile changes,\n\nreports type creation, validation analysis, sharing rules evaluation, and\n\nrecord/values configurations.\nExperience with Data Load, Import Wizard, and/or Workbench\n\nfor database management tasks, including defining, preparing, and executing data corrections and alignment tasks.\nCreate and execute user guides and process documentation for end users.\nWork with internal stakeholders (CE team, Finance, Engineering, Sales, etc.) to gather requirements, support, and\n\ndevelop functional work statements as needed.\nExcellent\n\norganizational, prioritization, and time management skills.\nDemonstrate a strong work ethic and ready to execute best practices for supporting the business.\nCustomer support experience maintaining, triaging, and troubleshooting existing programmatic integrations with internal and external systems.\n\nRequired if we take up Case API, otherwise not necessary\nStrong communication abilities and soft skills like organization are essential- Must be capable of addressing a diverse range of audiences.\n\n\nMinimum Qualifications:\n2+ years relevant work experience on Salesforce Lightning administration\nBachelor in one of the following or equivalent experience Business Administration, Business Operations, Data Analysis, Communication or Information Systems, or related field\nExpert level knowledge in MS Excel (current versions) and MS PowerPoint\n\n\nPreferred Qualifications:\nMaster's in Business Administration, Business Operations, Computer Science, Information Systems, or related field\nSalesforce\n\nCertified Administrator, Advanced Administrator, or Business Analyst\nExperience using, interacting and supporting established API or programmatic integrations\n\n\nMinimum Qualifications:\nAssociate's degree in Business Administration, Management, Computer Science, Engineering, Computer Science, or related field.\nOR\nHigh School Diploma or equivalent and 2+ years of relevant work experience.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['salesforce lightning', 'prioritization', 'salesforce', 'data loader', 'salesforce service cloud', 'visualforce', 'data analysis', 'import wizard', 'sfdc', 'business analysis', 'triggers', 'javascript', 'apex', 'sales force development', 'salesforce crm', 'project analysis']",2025-06-12 14:07:56
Treasury Analyst,Wells Fargo,2 - 4 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Treasury Analyst\n\nIn this role, you will:\nPlan and set policies and guidelines for managing global treasury activities including funding, liquidity risk management, asset and liability management, capital management, financial performance management, and related activities",,,,"['Treasury', 'capital management', 'liability management', 'Power BI', 'liquidity risk management', 'Alteryx', 'Data Analysis', 'Forecasting', 'Python']",2025-06-12 14:07:58
Analyst - Tax & Transfer Pricing,HARMAN,3 - 8 years,Not Disclosed,['Bengaluru'],"Introduction: Corporate\nWe re a global, multi-disciplinary team that s putting the innovative power of technology to work and transforming tomorrow. At HARMAN Corporate, you are integral to our company s award-winning success.\nEnrich your managerial and organizational talents - from finance, quality, and supply chain to human resources, IT, sales, and strategy",,,,"['Supply chain', 'Data analysis', 'Change management', 'SAP', 'Analytical', 'Transfer pricing', 'International taxation', 'Wellness', 'Corporate taxation', 'Automotive']",2025-06-12 14:08:01
Senior Analyst - Direct Display,Merkle Science,1 - 6 years,Not Disclosed,['Chennai'],"The purpose of this role is to assist with the planning, reviewing and optimisation of Display campaigns whilst supporting the team in reporting and managing client accounts.\nJob Description:\nKey responsibilities:\nFocuses on day-to-day execution\nProactively reviews and manages client data to ensure optimal performance on all campaigns\nTracks and reports on campaign results, gathers data analysis and participates in weekly calls\nGenerates campaign reports and is responsible for pacing, QA and trafficking\nDevelops and maintains accurate project plans for client status updates\nLocation:\nChennai\nBrand:\nParagon\nTime Type:\nFull time\nContract Type:\nPermanent",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['QA', 'Data analysis', 'Senior Analyst', 'Management']",2025-06-12 14:08:04
Business Analyst Capital Markets / Fund Accounting,Pro Integrate,10 - 12 years,Not Disclosed,['Bengaluru'],"Job Title: Business Analyst Capital Markets / Fund Accounting\n\nLocation: Bangalore (Hybrid Model)\n\nShift Timing: UK Shift Hours\n\nExperience: 10 12 Years\n\nNotice Period: Immediate to 15 Days Only\n\nIndustry: BFSI / Investment Banking / Capital Markets\n\nEducation: MBA (Finance) Premier Institutes Only\n\nJob Description\n\nWe are looking for a Business Analyst with a strong foundation in software development and deep domain expertise in Capital Markets, Fund Accounting, and Investment Banking. The ideal candidate will be a former developer who has transitioned into a Business Analyst role and brings a unique combination of technical and functional expertise.\n\nKey Responsibilities\n\nAct as a bridge between business and technology teams\nTranslate business requirements into functional specifications\nAnalyze data using SQL and prepare insights for financial reporting\nCollaborate with global stakeholders in Agile delivery environments\nEnsure high-quality documentation and deliverables\nManage multiple priorities with a strong focus on accuracy and detail\nMust-Have Skills\n\nCareer Path: Started as a software developer (Java, .NET, SQL, PL/SQL) and transitioned to Business Analyst\nDomain Expertise:\nCapital Markets (Mandatory)\nFund Accounting & Reporting (Mandatory)\nOTC Derivatives / Investment Banking (Preferred)\nPrivate Equity / Private Credit (Nice to have)\nTechnical Skills:\nSQL for data analysis\nAgile ALM tools: JIRA, Rally, Azure Boards\nExperience working in Agile, distributed teams\nSoft Skills:\nExcellent communication (verbal & written)\nStrong stakeholder management and client interaction\nDetail-oriented with a focus on financial reporting accuracy\nOther Details\n\nJob Type: Full-Time / Permanent\nWork Model: Hybrid (Bangalore-based)\nShift: UK Hours\nNotice Period: Immediate to 15 days only\nApply Now if you meet the above criteria and are ready to make an immediate impact!",Industry Type: Analytics / KPO / Research,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Capital Markets', 'Business Analysis', 'Java', 'Financial Reporting', 'Investment Banking', 'Business Analyst', 'Fund Accounting', 'JIRA', 'SDLC', 'SQL', 'Private Equity', 'Client Communication', 'Azure Boards', 'Otc Derivatives', 'Agile', 'Data Analysis', 'PLSQL', '.Net', 'Private Credit', 'Rally', 'STLC', 'Stakeholder Management']",2025-06-12 14:08:06
"Systems Analyst, Senior",Qualcomm,3 - 8 years,Not Disclosed,['Hyderabad'],"Job Area: Information Technology Group, Information Technology Group > Systems Analysis\n\nGeneral Summary:\n\nWe are seeking a Systems Analyst,Senior to join our growing organization with specialized skills in IBM Planning Analytics/TM1 and functional understanding of Finance budgeting and forecasting. This role involves advanced development, troubleshooting, and implementation of TM1 solutions to meet complex business requirements.The person will be part of Finance Planning and reporting team and will primarily work closely with his/her manager and will be helping in delivering TM1 planning and budgeting roadmap for the global stakeholders.Key Responsibilities:\nAble to design and develop IBM Planning Analytics(TM1) solutions as per standards. Able to write logical, complex, concise, efficient, and well-documented code for both TM1 rules and Turbo Integrator processes. Good to have knowledge of Python and TM1py libraries.\nAble to write business requirement specifications, define level of efforts for Projects/Enhancements and should design and coordinate system tests to ensure solutions meet business requirements\nSQL skills to be able to work with source data and understand source data structures. Good understanding of the SQL and ability to write complex queries.\nUnderstanding cloud technologies especially AWS and Databricks will be an added advantage.\nExperience in client reporting and dashboard tools like Tableau, PA Web,PAFE.\nUnderstanding of ETL processes and data manipulation\nWorking independently with little supervision\nTaking responsibility for own work and making decisions that are moderate in impact; errors may have financial impact or effect on projects, operations, or customer relationships; errors may require involvement beyond immediate work group to correct.\nShould provide ongoing system support, including troubleshooting and resolving issues to ensure optimal system performance and reliability\nUsing verbal and written communication skills to convey information that may be complex to others who may have limited knowledge of the subject in question\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or incomplete; intermediate data analysis/interpretation skills may be required.\nExercising substantial creativity to innovate new processes, procedures, or work products within guidelines or to achieve established objectives.\n\nMinimum Qualifications:\n3+ years of IT-relevant work experience with a Bachelor's degree.\nOR\n5+ years of IT-relevant work experience without a Bachelors degree.\nQualifications:The ideal candidate will have 8-10 years of experience in designing, modeling, and developing enterprise performance management (EPM) applications using IBM Planning Analytics (TM1).Able to design and develop IBM Planning Analytics(TM1) solutions as per standards. Able to write logical, complex, concise, efficient, and well-documented code for both TM1 rules and Turbo Integrator processes.Lead the design, modeling, and development of TM1 applications, including TI scripting, MDX, rules, feeders, and performance tuning.Should able to provide technical expertise in identifying, evaluating, and developing systems and procedures that are efficient, cost effective and meet user requirements.Plans and executes unit, integration and acceptance testingMust be a good team player who can work seamlessly with Global teams and Data teamsExcellent communication and collaboration skills to work with business stakeholdersHaving functional understanding of Finance budgeting and forecasting\n\nUnderstanding cloud technologies especially AWS and Databricks will be an added advantageExperience in Agile methodologies and JIRA user storiesAble to design and develop solutions using python as per standards\n\nwe are seeking a Systems Analyst,Senior to join our growing organization with specialized skills in IBM Planning Analytics/TM1 and functional understanding of Finance budgeting and forecasting.The person will be part of Finance Planning and reporting te\n\nRequired bachelors or masters degree in information science, computer science, business, or equivalent work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'sql', 'tableau', 'enterprise performance management', 'etl', 'rest', 'data analysis', 'performance tuning', 'cloud technologies', 'data bricks', 'system analysis', 'planning analytics', 'computer science', 'tm', 'troubleshooting', 'data structures', 'agile', 'aws', 'jira', 'agile methodology']",2025-06-12 14:08:10
"Sr. Functional App Analyst, FOAA",Amazon,10 - 15 years,Not Disclosed,['Pune'],"Amazons Finance Operations, Accounting & Analysis (FOAA) team is a fast-paced, team-focused, dynamic environment and delivering great experiences for our customers is top priority. FOAA is seeking a Functional App Analyst to support our Accounting Onboarding team.\n\nThe Functional App Analyst will partner with the Accounting Onboarding team (based in the US) to support various Amazon businesses to launch their products and services by automating their accounting use cases. This is an exciting opportunity to join fast-paced businesses at Amazon. The successful candidate will be strategic, analytical, and have a demonstrated ability to support financial systems and architecture. The successful candidate will be comfortable working in cross-functional teams, and demonstrate strong leadership skills.\n\nThe Functional App Analyst manager will independently manage a team of Functional Analysts, establish structures that enable their team to deliver on projects. Partner with customers, team members, and other teams on what projects move forward and in what priority order. A successful candidate will track team level activities in terms of customer engagement, adherence to SLAs, and execution of projects and programs, customer roadmaps and successfully deliver projects that executes that vision of the org.\n\nThe ideal candidate must have superior attention to detail and the ability to manage multiple competing priorities. The position represents an exciting opportunity to be a part of an extremely dynamic and high -paced environment, support a global organization and work with accounting and business teams. The role offers significant opportunities for rapid growth and is a great place to learn about various businesses at Amazon.\n\n\n-Build relationships with stakeholders, earn trust through transparency and alignment.\n-Dive deep into our customers business to understand pain points and future needs.\n-Lead an existing team of Functional App Analyst and System Analysts.\n-Partner with stakeholders to define strategy and roadmaps for the strategic areas your team owns.\n-Represent verbally and in writing complex decisions, tough trade-offs, and potential solutions clearly to leaders up to 2 levels above.\n-Understand system capabilities in order to deliver IT solutions to business users across Amazon.\n-Advise the customers on the financial integration architecture.\n-Acquire deep understanding of one or more lines of businesses and system integration and data flows.\n-Must have a strong knowledge of an application s functionality. They know what functionality is available in their system and how to configure it to work for business processes\n-Help customers author and release accounting configurations using home grown business configuration management solutions.\n-Troubleshoot integration issues by partnering with internal technical teams across the orgs.\n-Work very closely with the technical teams across Amazons lines of businesses to come up with innovative solutions that will accelerate the adoption of technology used for Financial Reporting and reconciliation.\n-Work independently to manage projects and support Amazons global businesses and development teams in the design and implementation of accounting systems.\n-Provide project management update within and across business units to transition new processes and/or permanent solutions to support the Amazon accounting team.\n-Coordinate with the global accounting teams to establish and maintain strong communication channels.\n-Identify, implement, and adhere to best practices across all new project launches -Offering and receiving coaching, support, and guidance to the team.\n-Supporting in User Acceptance Testing (UATs) in close co-ordination with business and accounting teams.\n-Provide inputs for monthly and quarterly business reviews in a timely manner.\n-Facilitate the business reviews with data analysis and follow through with business leaders on actionable items for improving business metrics over a period of time.\n-Measuring and monitoring of metrics for new business initiatives.\n-Present recommendations to senior management on strategic decisions, and planned future initiatives.\n-Demonstrate appropriate understanding / working knowledge of accounting principles and internal controls, and apply them.\n-Ensure appropriate financial policies, procedures, and internal controls are in place, documented, and operating as intended.\n-Drive process improvements required to enhance controls.\n-Actively participate in strategic initiatives and special projects when assigned or required.\n\nA day in the life\nPrioritization, Resource Planning and Stakeholder Management.\n\nGathering requirements from various Amazon businesses integrating with financial automation tools.\n\nCollaborate with engineering teams to come up with optimal solutions for accounting automation.\n\nWork on code review and config review process by following the guidelines.\n\nParticipate in UAT and guide internal customers with troubleshooting.\n\nWork on deployments to production after acquiring UAT sign-off from stakeholders.\n\nAbout the team\nAmazons Finance Operations, Accounting & Analysis (FOAA) team is a fast-paced, team-focused, dynamic environment and delivering great experiences for our customers is top priority. FOAA is seeking a Finance Analyst to support our Accounting Onboarding team. 10+ years of relevant experience in identifying, leading, and executing opportunities to improve, automate, standardize or simplify finance or business tools and processes experience\n5+ years of experience of working in Financial Services implementing solutions.\nHands on experience in ERP implementation along with understanding of modules like GL, AP, AR, CM, FA, Expenses, PPM etc.\nAct as liaison between customers and engineering teams.\nAbility to understand complex business flows and break them into use cases\nExperience using data to influence business decisions\nExcellent verbal and written communication. Good interpersonal skills\nStrong Project Management skills\n-Experience working with large-scale data reporting tools (examples: SQL, MS Access, Essbase, Cognos) and other financial systems (examples: Oracle, PeopleSoft, SAP, Lawson, JD Edwards)\nExperience in a technical consulting or techno-functional consulting role in a customer centric, fast-moving environment.\nProven ability to develop new ideas and creative solutions\nProven ability to work successfully in an ambiguous environment\nProven ability to meet tight deadlines and prioritize workload\nAbility to work in cross-functional teams\nCustomer focus and professional demeanor",,,,"['Data analysis', 'SAP', 'MS Access', 'Cognos', 'Configuration management', 'Consulting', 'PeopleSoft', 'JD Edwards', 'Oracle', 'SQL']",2025-06-12 14:08:12
Data Scientist,Swits Digital,5 - 12 years,Not Disclosed,['Chennai'],"Job Title: Data Scientist\nLocation: Chennai\nExperience: 5-12 Years\nJob Summary:\nWe are seeking a highly analytical and results-driven Data Scientist with a strong background in statistics , machine learning , and data science , combined with domain knowledge in mechanical engineering and cost analysis . The ideal candidate will have experience working with Google Cloud Platform (GCP) and will play a key role in transforming engineering and operational data into actionable insights to drive business decisions.\nRequired Skills & Experience:\nStrong knowledge of statistics , machine learning , and data science principles\nHands-on experience with Google Cloud Platform (GCP) , especially BigQuery , Vertex AI , and Cloud Functions\nProficiency in Python or R for data analysis and modeling\nSolid understanding of mechanical engineering concepts and their application in data analysis\nExperience with cost modeling , cost-benefit analysis , or operational performance analytics\nExcellent problem-solving , analytical thinking , and communication skills\nAbility to work with large datasets and create clear, actionable insights",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'data science', 'GCP', 'Analytical', 'Machine learning', 'Cost benefit analysis', 'Operations', 'Mechanical engineering', 'Analytics', 'Python']",2025-06-12 14:08:15
Senior Data Engineer - Azure,Blend360 India,3 - 6 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n3+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:08:17
Strategic Buying Services Analyst II,Conduent,3 - 6 years,Not Disclosed,['Bengaluru'],"Job Track Description \nRequires formal education and relevant expertise in a professional, sales, or technical area.\nPerforms technical-based activities.\nContributes to and manages projects.\nUses deductive reasoning to solve problems and make recommendations.\nInterfaces with and influences key stakeholders.\nLeverages previous knowledge and expertise to achieve results.\nAbility to complete work self-guided.\nCollege or university degree required.\n\n General Profile  \nRequires knowledge and experience in the field.\nWill acquire higher-level knowledge and skills.\nDevelops an understanding of the company, processes, and customers.\nUses existing procedures to solve routine or standard problems.\nReceives moderate guidance and direction from others.\n\n Functional Knowledge  \nRequires expanded conceptual understanding of theories, practices, and procedures.\n\n Business Expertise  \nUses an understanding of key business drivers to accomplish work.\n\n Impact  \nImpacts a team, by example, through the quality service and information provided.\nWorks within guidelines and policies.\n\n Leadership  \nNo supervisory responsibilities.\nProvides informal guidance to new team members.\n\n Problem Solving  \nUses existing procedures to solve standard problems.\nExamines information and standard practices to make judgments.\n\n Interpersonal Skills  \nClearly and effectively exchanges complex information and ideas.\n\n Responsibility Statements  \nTracks and reports out business-critical project metrics for the client operations.\nResponsible for managing quality cost savings and vendor relations.\nConducts RFQ and limited reverse auctions to verify supplier, pricing, and availability.\nManages supplier performance, identified risks, and developed strategic buying plans.\nPrepares customized reports and dashboards.\nKeeps data updated and readily available to be leveraged for presentations and reporting.\nPerforms other duties as assigned.\nComplies with all policies and standards.",Industry Type: BPM / BPO,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['pivot table', 'vlookup', 'sales', 'sql', 'advanced excel', 'data analysis', 'mis reporting', 'data dictionary', 'business analysis', 'dashboards', 'budgeting', 'plsql', 'salesforce', 'marketing', 'tableau', 'mis', 'smartforms', 'sap abap']",2025-06-12 14:08:19
CPU Performance & Power Analyst/Staff Engineer - 4 Open positions,Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 8 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'uart', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:08:22
CPU Performance and Power Analyst/Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\n\nWould be working on Qualcomm Snapdragon CPUSS Architecture and performance team.\n\nResponsible for analyzing the performance aspects of Snapdragon CPU subsystem and influence the same for performance uplifts in upcoming revisions.\n\nWill be guiding the execution team by projecting CPUSS performance in upcoming chips and correlating them with pre-silicon runs and post silicon measurements.\n\nResponsible for driving deep dive analysis on performance issues, bottleneck providing fixes or workarounds on CPU subsystem and related SOC Modules.\n\nThe ideal candidate to have a strong CPU architecture / analysis background along with overall SOC wide exposure and Embedded system concepts on modern chipsets-based\n\nARM/X86\n\n\n\n\nEssential Skills and Experience\n\nFamiliar with\n\nMicroprocessor and/or SoC Architecture and micro-Architecture, preferably ARM processors and ARM processor-based systems.\n\nExperience of ARM based System Designs, Knowledge of CPU\n\nand hierarchical memory system, cache configurations and coherency issues in multi-core systems .\n\nExperience with workload performance characterization,\n\nbottleneck analysis, and driving microarchitecture investigations on CPU /GPU/Systems with relevant performance matrix\n\nHands-on with Lauterbach debug environment, Emulation platforms and experience in working with\n\nbare-metal environment with knowledge of Linux boot.\n\nEngage with architects and design teams to investigate next-generation CPU microarchitecture performance features through workload-driven investigations, especially well-known CPU benchmarks like\n\nLmbench, Spec, Geekbench .\n\nDevelop, simulate workloads for pre-silicon performance analysis and performance projections on silicon.\n\n\nLead initiatives for performance technology alignment across product engineering teams\n\n\nGood to have\n\nMinimum 5 + years years of experience on relevant areas.\n\nStrong data analysis skills to identify performance trends from large data sets and the technical bent to investigate anomalies\n\nUnderstanding of Linux and Android internals from a performance point of view.\n\nStrong programming experience in at least one languageC/C++, Perl, Python\n\nFamiliarity with hardware/software level performance analysis of industry standard benchmarks & open source applications.\n\nExcellent debugging skills at SoC and System level\n\nExcellent communication skills and ability to collaborate with peers and senior architects/design engineers across the globe.\n\nFamiliar with pre-silicon environments such as Verification, Emulation and Virtual Bring-Up, etc.\n\nGood knowledge of high-performance microprocessor architecture and complex SoC\n\nPre-silicon performance experience is a huge plus\n\nPost Silicon Experience and debugging on the devices using relevant Debug tools and Bus profiling tools are added advantage.\n\n\nEducational qualification\n\nBachelor's degree in Electrical, Electronics or Computer Engineering and/or Computer Science, with 6+ years of experience in SOC/CPU post-silicon validation / performance analysis\n\nStrong knowledge of\n\nmodern OS kernel (Android, Linux)\n\n,\n\nenable Linux/Android during bring-up.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'kernel', 'computer architecture', 'arm processor', 'bus', 'data analysis', 'arm processors', 'soc', 'hardware engineering', 'cpu', 'performance engineering', 'spi', 'profiling', 'linux', 'debugging', 'perl', 'microprocessors', 'i2c', 'digital transformation', 'performance analysis']",2025-06-12 14:08:25
Senior BI Analyst - Tableau Expert,BMC Software,7 - 12 years,Not Disclosed,['Pune'],"BU Description:\nOur Analytics and Automation team is at the forefront of leveraging data-driven insights to enhance business performance across sales, marketing, product development, and VSE. We specialize in harnessing advanced analytics and automation techniques to provide actionable intelligence, drive efficiency, and foster innovation. Our commitment to excellence ensures that we deliver impactful solutions that propel our organization's strategic goals forward.\n\nAbout You:\n\nYou like to develop, design, and deliver data visualization solutions that deliver sustained business value from our and associated solutions\nYou enjoy working cross-functionally across Sales, Marketing, Operations, and IT organizations for supporting the customer success organization\nYou re a team player and believe in building synergies across BMC to create/continually evolve one integrated customer journey.\nYou like to innovate, and have a passion for solving business problems, to continuously improve our quality of service\nYou have a passion for development, and challenge yourself to learn new things\nYou know how to have fun and connect with people.\n\nKey Responsibility/Role Expectations:\n\nThe Senior BI Analyst supports senior leadership by providing data-driven insights and analytics, enabling informed decision-making, and driving strategic initiatives to enhance customer success and align with business objectives. You should be responsible to\n\nDesign, develop, and maintain advanced and interactive Tableau dashboards to provide actionable insights into customer success metrics.\nAnalyze customer behavior, trends, and performance metrics to identify actionable opportunities for improvement.\nMonitor key customer success indicators (e.g., retention, churn, satisfaction) and provide insights to drive enhanced customer engagement and satisfaction.\nCreate visually compelling and interactive reports tailored for senior leadership to support data-driven strategic decision-making.\nCollaborate with cross-functional teams, including Customer Success, Product, and Support, to gather requirements and deliver tailored BI solutions.\nIntegrate data from multiple sources (e.g., CRM systems like Salesforce, support tools, and internal databases) to create a unified view of performance.\nProvide data-driven recommendations to senior leadership to align customer success efforts with organizational objectives.\nIdentify and report on key trends and anomalies in customer success data, proactively addressing potential challenges.\nDevelop and implement automated workflows for reporting and analytics to enhance efficiency and reduce manual effort.\nStay updated on Tableau and broader BI trends, implementing best practices in data visualization and analysis.\n\nProfessional Experience:\n\nMinimum of 7+ years of experience in Business Intelligence and data analysis.\nExpert proficiency in Tableau, with demonstrated ability to build advanced visualizations.\nStrong understanding of relational databases with expertise in advanced SQL writing.\nProven ability to extract and analyze data from sources such as Snowflake, Excel, CSV, and text files.\nProficient knowledge of Salesforce.com, with experience in CRM data analysis and integration.\nAdvanced skills in Excel, PowerPoint, and Word for creating reports and presentations.\nStrong analytical skills to critically evaluate data, reconcile discrepancies, and ensure accuracy.\nAbility to translate user requirements into technical solutions and design effective BI implementations.\nExcellent organizational skills, with the ability to manage multiple complex projects in a fast-paced, dynamic environment.\nSelf-motivated, detail-oriented, and able to deliver quality outcomes under tight deadlines.\nStrong communication and presentation skills to effectively collaborate with stakeholders, including senior leaders such as Sr. Directors and VPs.\nDemonstrated ability to influence and build long-term relationships with cross-functional teams and business partners.\nExperience mentoring and training team members on technical skills and BI best practices.\nQuick learner, adaptable to changing tools, environments, and priorities.\nCustomer-oriented mindset, with a proven ability to partner with stakeholders to achieve shared business goals.\nFamiliarity with programming languages like Python or R, cloud-based platforms like AWS are a plus.\nBasic understanding of machine learning concepts and predictive analytics is a bonus.\n\nEducation\n\nBachelor s or master s degree in computer science, Information Systems, or a related field (Advanced degree preferred).",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Tableau', 'salesforce', 'python', 'data analysis', 'predictive analytics', 'presentation skills', 'relational databases', 'machine learning', 'business intelligence', 'sql']",2025-06-12 14:08:27
Sales Operations & Data Analytics- Sr. Associate,GEP,2 - 6 years,Not Disclosed,['Navi Mumbai'],"Overview\nGEP is a diverse, creative team of people passionate about procurement. We invest ourselves entirely in our client’s success, creating strong collaborative relationships that deliver extraordinary value year after year. Our clients include market global leaders with far-flung international operations, Fortune 500 and Global 2000 enterprises, leading government and public institutions. \n We deliver practical, effective services and software that enable procurement leaders to maximise their impact on business operations, strategy and financial performance. That’s just some of the things that we do in our quest to build a beautiful company, enjoy the journey and make a difference. GEP is a place where individuality is prized, and talent respected. We’re focused on what is real and effective. GEP is where good ideas and great people are recognized, results matter, and ability and hard work drive achievements. We’re a learning organization, actively looking for people to help shape, grow and continually improve us.",,,,"['crm systems', 'project management', 'data analytics', 'oracle', 'data analysis', 'bi', 'power bi', 'business analysis', 'dashboards', 'sql', 'plsql', 'power query', 'sales operations', 'salesforce', 'analytics', 'excel', 'advanced excel', 'collaboration', 'data governance', 'hubspot', 'powerpoint', 'communication skills', 'crm']",2025-06-12 14:08:29
"Associate Director, Data Science/Software Engineering",ATT Communication Services,10 - 15 years,Not Disclosed,['Bengaluru'],"Associate Director, Data Science/Software Engineering:\nAT&T is one of the leading service providers in the telecommunication sector and propelling it into the data and AI driven era is powered by CDO (Chief Data Office) . CDO is empowering AT&T, through execution, self-service, and as a data and AI center of excellence, to unlock transformative insights and actions that drive value for the company and its customers.\nEmployees in CDO imagine, innovate, and unlock data & AI driven insights and actions that create value for our customers and the enterprise. Part of the work, we govern data collection and use, mitigate for potential bias in machine learning models, and encourage an enterprise culture of responsible AI.\nAT&T s Chief Data Office (CDO) is harnessing data and making AT&T s data assets and ground-breaking AI functionality accessible to employees across the firm. In addition, our talented employees are a significant component that contributes to AT&T s place as the U.S. company with the sixth most AI-related patents. CDO also maintains academic and tech partnerships to cultivate the next generation of experts in statistics and machine learning, statistical computing, data visualization, text mining, time series modelling, data stream and database management, data quality and anomaly detection, data privacy, and more.\nWe are looking for an accomplished and visionary professional for the role of Associate Director, Data Science/Software Engineering to join our team and lead the development of cutting-edge software solutions. This is a hands-on leadership position that requires the fine balance of supervising and leading people while providing significant technical contributions to the projects you will be responsible for. As a key technical leader, you will leverage your expertise in full-stack development, DevOps best practices, Data analysis, AI/ML and Generative AI to lead your team in creating scalable, reliable, and efficient systems.\nThis role demands a strategic thinker and hands-on contributor who can work across multiple teams, drive innovation, and ensure technical excellence. You will be instrumental in shaping the technical roadmap, mentoring teams, and delivering transformative solutions that align with business objectives.\nKey Responsibilities:\nTechnical Leadership:\nDefine and drive the technical vision and architecture for scalable, resilient, and secure full-stack applications utilizing data powered insights.\nLead end-to-end software development projects from concept to deployment and maintenance.\nCollaborate with cross-functional teams to translate business requirements into technical solutions.\nServe as a mentor and technical advisor to engineering teams, fostering a culture of innovation and excellence.\nFull-Stack Development:\nDesign and implement scalable and high-performance web applications using modern front-end and back-end frameworks (e.g., React, Angular, Node.js, Python, Java).\nDevelop modular and reusable APIs (RESTful or GraphQL) with an emphasis on maintainability and performance.\nEnsure seamless integration of front-end and back-end systems while maintaining best practices for UI/UX design.\nOptimize database structures and queries for both relational (e.g., MySQL, PostgreSQL) and non-relational (e.g., MongoDB, DynamoDB) databases.\nDevOps and Automation:\nArchitect and implement CI/CD pipelines to streamline build, test, and deployment processes.\nEnsure seamless deployment and scalability of applications through containerization tools (e.g., Docker) and orchestration platforms (e.g., Kubernetes).\nLeverage infrastructure-as-code solutions (e.g., Terraform, Ansible) to automate infrastructure provisioning and management.\nMonitor application performance, troubleshoot issues, and ensure high availability through tools like Prometheus, Grafana, or New Relic.\nShell Scripting and Automation:\nDevelop and maintain shell scripts to automate routine tasks, system monitoring, and application deployments.\nDebug and troubleshoot production issues using scripting techniques to ensure minimal downtime.\nEnhance system efficiency by automating log analysis, error detection, and reporting.\nStrategic Contribution:\nCollaborate with stakeholders to align technical priorities with business goals.\nEvaluate emerging technologies and tools to recommend and implement solutions that advance the organization s technical capabilities.\nEstablish and enforce software engineering best practices, ensuring robust security, scalability, and maintainability.\nQualifications:\nEducation:\nBachelor s or Master s degree in Computer Science, Software Engineering, or a related field. A Ph.D. is a plus.\nExperience:\n13+ years of experience in software engineering, including hands-on experience with full-stack development and DevOps practices.\nProven track record of delivering large-scale, high-impact software solutions in a leadership capacity.\nTechnical Expertise:\nAdvanced proficiency in front-end frameworks (React, Angular, or Vue.js) and back-end technologies (Node.js, Python, Java, Go, etc.).\nStrong experience with DevOps tools (Jenkins, GitLab CI/CD, Docker, Kubernetes).\nDeep understanding of cloud platforms (AWS, Azure, GCP), including architecture and deployment strategies.\nSolid grasp of database technologies (SQL and NoSQL) and optimization techniques.\nProficiency in writing, debugging, and maintaining shell scripts for automation and system monitoring.\nStrong knowledge of microservices architecture, API gateways, and distributed systems.\nSoft Skills:\nExceptional problem-solving and critical-thinking abilities.\nStrong leadership and mentoring skills, with the ability to inspire and guide teams.\nExcellent communication skills, both written and verbal, to collaborate effectively with technical and non-technical stakeholders.\nStrategic mindset, capable of balancing technical depth with business impact.\nPreferred Qualifications:\nExperience with serverless computing frameworks (e.g., AWS Lambda).\nCertifications in cloud platforms (e.g., AWS Certified Solutions Architect, Azure DevOps Engineer Expert).\nKnowledge of security best practices in software development and DevOps.\n#DataEngineering\nLocation:\nIND:KA:Bengaluru / Innovator Building, Itpb, Whitefield Rd - Adm: Intl Tech Park, Innovator Bldg\nJob ID R-66889 Date posted 05/14/2025",Industry Type: Telecom / ISP,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Data analysis', 'Front end', 'Postgresql', 'MySQL', 'Shell scripting', 'Telecommunication', 'SQL', 'Python']",2025-06-12 14:08:31
Data Bricks,PwC India,7 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary:\n\nWe are seeking a talented Data Engineer with strong expertise in Databricks, specifically in Unity Catalog, PySpark, and SQL, to join our data team. Youll play a key role in building secure, scalable data pipelines and implementing robust data governance strategies using Unity Catalog.\n\nKey Responsibilities:",,,,"['DataBricks', 'Data Bricks', 'Pyspark', 'Delta Lake', 'Databricks Engineer', 'Unity Catalog', 'SQL']",2025-06-12 14:08:34
Consultant- Real-World Data (RWD),IQVIA,2 - 7 years,Not Disclosed,"['Pune', 'Gurugram', 'Bengaluru']","Project Role: Consultant- Real-World Data (RWD)\nWork Experience: 2 to 8 Years\nWork location: Bengaluru/Pune/Gurugram\nWork Mode: Hybrid\nMust Have Skills: Real-World Data (RWD), Healthcare, Data analytics, SQL/Python\nJob Overview:\nWe are seeking a highly motivated Associate Consultant to join our Real-World Data (RWD) team. The selected candidate will support data analysis activities using IQVIA Connected Intelligence RWD and clinical data assets across multiple R&D projects. This role involves close collaboration with Therapeutic Analytic Leads to ensure standardized, data-driven decision-making at the indication, program, and study levels.\n\nKey Responsibilities:\nLeverage IQVIA Connected Intelligence datasets to inform and enhance clinical trial strategies (pre- and post-award).\nCollaborate with internal stakeholders to align on data analytics requirements, capabilities, and deliverables.\nLead the development and implementation of analytics methodologies, including:\nCountry evaluation and ranking\nCompetitive landscape assessments\nHistorical recruitment analysis\nPatient density analytics\nGenerate patient insights using RWD to support site targeting strategies.\nCoordinate the collection and analysis of site outreach data to inform country/site strategy development.\n\nQualifications:\nBachelors degree in Life Sciences, Information Technology, Computer Science, Statistics, or a related field.\n2-7 years of experience in data analytics, clinical research, or consulting within the pharmaceutical or healthcare industry.\nExperience working with large-scale electronic data (e.g., medical claims, EMRs/EHRs, prescriptions, sales data).\nFamiliarity with the pharmaceutical and healthcare market and drug development lifecycle.\nPreferred experience working with global, cross-functional teams.\nProficiency in business intelligence tools (e.g., Power BI, Tableau) is a plus.\nHands-on experience with programming/scripting languages (Python, R, Spark, PySpark) and relational databases (SQL Server, Oracle, PostgreSQL) is advantageous.\n\nSkills & Competencies:\nStrong attention to detail and analytical thinking.\nEffective verbal and written communication skills.\nProficiency in MS Excel and PowerPoint.\nLogical problem-solving and task prioritization abilities.\nAdaptability and eagerness to learn new tools and systems.\nStrong presentation and stakeholder engagement skills.",Industry Type: Analytics / KPO / Research,Department: Consulting,"Employment Type: Full Time, Permanent","['Real World Evidence', 'Healthcare', 'Data Analytics', 'Healthcare Analytics', 'Pharma', 'Feasibility Analysis', 'Clinical']",2025-06-12 14:08:36
Graph Engineer- Data Science,HARMAN,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Description\nIntroduction: Digital Transformation Solutions (DTS)\n.\nExtensive experience in defining, developing, and implementing security software, ideally with a strong embedded firmware development background\nAbout the Role\nThis position offers an opportunity to work in a globally distributed team where you will get a unique opportunity of personal development in a multi-cultural environment. You will also get a challenging environment to develop expertise in the technologies useful in the industry.",,,,"['Computer science', 'Product quality', 'UML', 'XML', 'Relationship', 'Javascript', 'HTML', 'Oracle', 'Automotive', 'Python']",2025-06-12 14:08:38
Data Techology Senior Associate,MSCI Services,4 - 7 years,Not Disclosed,['Pune'],"Overview\nThe Data Technology team at MSCI is responsible for meeting the data requirements across various business areas, including Index, Analytics, and Sustainability. Our team collates data from multiple sources such as vendors (e.g., Bloomberg, Reuters), website acquisitions, and web scraping (e.g., financial news sites, company websites, exchange websites, filings). This data can be in structured or semi-structured formats. We normalize the data, perform quality checks, assign internal identifiers, and release it to downstream applications.\nResponsibilities\nAs data engineers, we build scalable systems to process data in various formats and volumes, ranging from megabytes to terabytes. Our systems perform quality checks, match data across various sources, and release it in multiple formats. We leverage the latest technologies, sources, and tools to process the data. Some of the exciting technologies we work with include Snowflake, Databricks, and Apache Spark.\nQualifications\nCore Java, Spring Boot, Apache Spark, Spring Batch, Python. Exposure to sql databases like Oracle, Mysql, Microsoft Sql is a must. Any experience/knowledge/certification on Cloud technology preferrably Microsoft Azure or Google cloud platform is good to have. Exposures to non sql databases like Neo4j or Document database is again good to have.\n What we offer you\nTransparent compensation schemes and comprehensive employee benefits, tailored to your location, ensuring your financial security, health, and overall wellbeing.\nFlexible working arrangements, advanced technology, and collaborative workspaces.\nA culture of high performance and innovation where we experiment with new ideas and take responsibility for achieving results.\nA global network of talented colleagues, who inspire, support, and share their expertise to innovate and deliver for our clients.\nGlobal Orientation program to kickstart your journey, followed by access to our Learning@MSCI platform, LinkedIn Learning Pro and tailored learning opportunities for ongoing skills development.\nMulti-directional career paths that offer professional growth and development through new challenges, internal mobility and expanded roles.\nWe actively nurture an environment that builds a sense of inclusion belonging and connection, including eight Employee Resource Groups. All Abilities, Asian Support Network, Black Leadership Network, Climate Action Network, Hola! MSCI, Pride & Allies, Women in Tech, and Women’s Leadership Forum.\nAt MSCI we are passionate about what we do, and we are inspired by our purpose – to power better investment decisions. You’ll be part of an industry-leading network of creative, curious, and entrepreneurial pioneers. This is a space where you can challenge yourself, set new standards and perform beyond expectations for yourself, our clients, and our industry.\nMSCI is a leading provider of critical decision support tools and services for the global investment community. With over 50 years of expertise in research, data, and technology, we power better investment decisions by enabling clients to understand and analyze key drivers of risk and return and confidently build more effective portfolios. We create industry-leading research-enhanced solutions that clients use to gain insight into and improve transparency across the investment process.\nMSCI Inc. is an equal opportunity employer. It is the policy of the firm to ensure equal employment opportunity without discrimination or harassment on the basis of race, color, religion, creed, age, sex, gender, gender identity, sexual orientation, national origin, citizenship, disability, marital and civil partnership/union status, pregnancy (including unlawful discrimination on the basis of a legally protected parental leave), veteran status, or any other characteristic protected by law. MSCI is also committed to working with and providing reasonable accommodations to individuals with disabilities. If you are an individual with a disability and would like to request a reasonable accommodation for any part of the application process, please email Disability.Assistance@msci.com and indicate the specifics of the assistance needed. Please note, this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation; it is not intended for other inquiries.\n To all recruitment agencies\nMSCI does not accept unsolicited CVs/Resumes. Please do not forward CVs/Resumes to any MSCI employee, location, or website. MSCI is not responsible for any fees related to unsolicited CVs/Resumes.\n Note on recruitment scams\nWe are aware of recruitment scams where fraudsters impersonating MSCI personnel may try and elicit personal information from job seekers. Read our full note on careers.msci.com",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['hive', 'access', 'scala', 'pyspark', 'data warehousing', 'hibernate', 'research', 'sql', 'analytics', 'spring', 'java', 'spring batch', 'spark', 'gcp', 'mysql', 'html', 'hadoop', 'big data', 'etl', 'snowflake', 'python', 'oracle', 'data analysis', 'microsoft azure', 'power bi', 'sql server', 'javascript', 'data bricks', 'spring boot', 'tableau', 'neo4j', 'aws', 'sql database']",2025-06-12 14:08:41
Data Engineer KL-BL,Puresoftware,5 - 12 years,Not Disclosed,['Bengaluru'],"Core Competences Required and Desired Attributes:\nBachelors degree in computer science, Information Technology, or a related field.\nProficiency in Azure Data Factory, Azure Databricks and Unity Catalog, Azure SQL Database, and other Azure data services.\nStrong programming skills in SQL, Python and PySpark languages.\nExperience in the Asset Management domain would be preferable.\nStrong proficiency in data analysis and data modelling, with the ability to extract insights from complex data sets.\nHands-on experience in Power BI, including creating custom visuals, DAX expressions, and data modelling.\nFamiliarity with Azure Analysis Services, data modelling techniques, and optimization.\nExperience with data quality and data governance frameworks with an ability to debug, fine tune and optimise large scale data processing jobs.\nStrong analytical and problem-solving skills, with a keen eye for detail.\nExcellent communication and interpersonal skills, with the ability to work collaboratively in a team environment.\nProactive and self-motivated, with the ability to manage multiple tasks and deliver high-quality results within deadlines.",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Interpersonal skills', 'Data modeling', 'Analytical', 'data governance', 'Data quality', 'Asset management', 'Information technology', 'SQL', 'Python']",2025-06-12 14:08:43
Data Engineer II,Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Amazon strives to be the worlds most customer-centric company, where customers can research and purchase anything they might want online\nWe set big goals and are looking for people who can help us reach and exceed them\nThe CPT Data Engineering & Analytics (DEA) team builds and maintains critical data infrastructure that enhances seller experience and protects the privacy of Amazon business partners throughout their lifecycle\nWe are looking for a strong Data Engineer to join our team\n\nThe Data Engineer I will work with well-defined requirements to develop and maintain data pipelines that help internal teams gather required insights for business decisions timely and accurately\nYou will collaborate with a team of Data Scientists, Business Analysts and other Engineers to build solutions that reduce investigation defects and assess the health of our Operations business while ensuring data quality and regulatory compliance\n\nThe ideal candidate must be passionate about building reliable data infrastructure, detail-oriented, and driven to help protect Amazons customers and business partners\nThey will be an individual contributor who works effectively with guidance from senior team members to successfully implement data solutions\nThe candidate must be proficient in SQL and at least one scripting language (e\ng\nPython, Perl, Scala), with strong understanding of data management fundamentals and distributed systems concepts\n\n\nBuild and optimize physical data models and data pipelines for simple datasets\nWrite secure, stable, testable, maintainable code with minimal defects\nTroubleshoot existing datasets and maintain data quality\nParticipate in team design, scoping, and prioritization discussions\nDocument solutions to ensure ease of use and maintainability\nHandle data in accordance with Amazon policies and security requirements Masters degree in computer science, engineering, analytics, mathematics, statistics, IT or equivalent\n3+ years of data engineering experience\nExperience with SQL\nExperience with data modeling, warehousing and building ETL pipelines\nKnowledge of distributed systems concepts from data storage and compute perspective\nAbility to work effectively in a team environment Experience with AWS technologies like Redshift, S3, AWS Glue, EMR, Kinesis, FireHose, Lambda, and IAM roles and permissions\nFamiliarity with big data technologies (Hadoop, Spark, etc\n)\nKnowledge of data security and privacy best practices\nStrong problem-solving and analytical skills\nExcellent written and verbal communication skills",Industry Type: Internet,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data management', 'Data modeling', 'data security', 'Perl', 'Data quality', 'Distribution system', 'Analytics', 'SQL', 'Python']",2025-06-12 14:08:45
Senior Data Scientist,Epsilon,6 - 9 years,Not Disclosed,['Bengaluru'],"Responsibilities: -\nContribute and build an internal product library that is focused on solving business problems related to prediction & recommendation.\nResearch unfamiliar methodologies, techniques to fine tune existing models in the product suite and, recommend better solutions and/or technologies.\nImprove features of the product to include newer machine learning algorithms in the likes of product recommendation, real time predictions, fraud detection, offer personalization etc\nCollaborate with client teams to on-board data, build models and score predictions.\nParticipate in building automations and standalone applications around machine learning algorithms to enable a One Click solution to getting predictions and recommendations.\nAnalyze large datasets, perform data wrangling operations, apply statistical treatments to filter and fine tune input data, engineer new features and eventually aid the process of building machine learning models.\nRun test cases to tune existing models for performance, check criteria and define thresholds for success by scaling the input data to multifold.\nDemonstrate a basic understanding of different machine learning concepts such as Regression, Classification, Matrix Factorization, K-fold Validations and different algorithms such as Decision Trees, Random Forrest, K-means clustering.\nDemonstrate working knowledge and contribute to building models using deep learning techniques, ensuring robust, scalable and high-performance solutions\nMinimum Qualifications:\nEducation: Master's or PhD in a quantitative discipline (Statistics, Economics, Mathematics, Computer Science) is highly preferred.\nDeep Learning Mastery: Extensive experience with deep learning frameworks (TensorFlow, PyTorch, or Keras) and advanced deep learning projects across various domains, with a focus on multimodal data applications.\nGenerative AI Expertise: Proven experience with generative AI models and techniques, such as RAG, VAEs, Transformers, and applications at scale in content creation or data augmentation.\nProgramming and Big Data: Expert-level proficiency in Python and big data/cloud technologies (Databricks and Spark) with a minimum of 4-5 years of experience.\nRecommender Systems and Real-time Predictions: Expertise in developing sophisticated recommender systems, including the application of real-time prediction frameworks.\nMachine Learning Algorithms: In-depth experience with complex algorithms such as logistic regression, random forest, XGBoost, advanced neural networks, and ensemble methods.\nExperienced with machine learning algorithms such as logistic regression, random forest, XG boost, KNN, SVM, neural network, linear regression, lasso regression and k-means.\nDesirable Qualifications:\nGenerative AI Tools Knowledge: Proficiency with tools and platforms for generative AI (such as OpenAI, Hugging Face Transformers).\nDatabricks and Unity Catalog: Experience leveraging Databricks and Unity Catalog for robust data management, model deployment, and tracking.\nWorking experience in CI/CD tools such as GIT & BitBucket",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Engineering', 'Pyspark', 'Azure Aws', 'Generative AI', 'Big Data', 'AWS', 'Data Bricks', 'Deep Learning', 'Python', 'SQL']",2025-06-12 14:08:47
Sr. Data Scientist-Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist\n\nLocation: Onsite Bangalore\nExperience: 8+ years\n\nRole Overview\n\nWe are seeking a Senior Data Scientist with a strong foundation in machine learning, deep learning, and statistical modeling, with the ability to translate complex operational problems into scalable AI/ML solutions. In addition to core data science responsibilities, the role involves building production-ready backends in Python and contributing to end-to-end model lifecycle management. Exposure to computer vision is a plus, especially for industrial use cases like identification, intrusion detection, and anomaly detection.\n\nKey Responsibilities\n\nDevelop, validate, and deploy machine learning and deep learning models for forecasting, classification, anomaly detection, and operational optimization\nBuild backend APIs using Python (FastAPI, Flask) to serve ML/DL models in production environments\nApply advanced computer vision models (e.g., YOLO, Faster R-CNN) to object detection, intrusion detection, and visual monitoring tasks\nTranslate business problems into analytical frameworks and data science solutions\nWork with data engineering and DevOps teams to operationalize and monitor models at scale\nCollaborate with product, domain experts, and engineering teams to iterate on solution design\nContribute to technical documentation, model explainability, and reproducibility practices\n\n\nRequired Skills\n\nStrong proficiency in Python for data science and backend development\nExperience with ML/DL libraries such as scikit-learn, TensorFlow, or PyTorch\nSolid knowledge of time-series modeling, forecasting techniques, and anomaly detection\nExperience building and deploying APIs for model serving (FastAPI, Flask)\nFamiliarity with real-time data pipelines using Kafka, Spark, or similar tools\nStrong understanding of model validation, feature engineering, and performance tuning\nAbility to work with SQL and NoSQL databases, and large-scale datasets\nGood communication skills and stakeholder engagement experience\n\n\nGood to Have\n\nExperience with ML model deployment tools (MLflow, Docker, Airflow)\nUnderstanding of MLOps and continuous model delivery practices\nBackground in aviation, logistics, manufacturing, or other industrial domains\nFamiliarity with edge deployment and optimization of vision models\n\n\nQualifications\n\nMasters or PhD in Data Science, Computer Science, Applied Mathematics, or related field\n7+ years of experience in machine learning and data science, including end-to-end deployment of models in production",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scikit-learn', 'time-series modeling', 'ML/DL libraries', 'data science', 'Python', 'Airflow', 'Kafka', 'MLflow', 'logistics', 'anomaly detection', 'aviation', 'SQL', 'PyTorch', 'NoSQL', 'MLOps', 'forecasting techniques', 'Docker', 'manufacturing', 'FastAPI', 'Spark', 'TensorFlow', 'Flask']",2025-06-12 14:08:50
Senior Engineer - Data Science,Sasken Technologies,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Summary\nPerson at this position has gained significant work experience to be able to apply their knowledge effectively and deliver results. Person at this position is also able to demonstrate the ability to analyse and interpret complex problems and improve change or adapt existing methods to solve the problem.\nPerson at this position regularly interacts with interfacing groups / customer on technical issue clarification and resolves the issues. Also participates actively in important project/ work related activities and contributes towards identifying important issues and risks. Reaches out for guidance and advice to ensure high quality of deliverables.\nPerson at this position consistently seek opportunities to enhance their existing skills, acquire more complex skills and work towards enhancing their proficiency level in their field of specialisation.\nWorks under limited supervision of Team Lead/ Project Manager.\n\n\nRoles & Responsibilities\nResponsible for design, coding, testing, bug fixing, documentation and technical support in the assigned area. Responsible for on time delivery while adhering to quality and productivity goals. Responsible for adhering to guidelines and checklists for all deliverable reviews, sending status report to team lead and following relevant organizational processes. Responsible for customer collaboration and interactions and support to customer queries. Expected to enhance technical capabilities by attending trainings, self-study and periodic technical assessments. Expected to participate in technical initiatives related to project and organization and deliver training as per plan and quality.\n\n\nEducation and Experience Required\nEngineering graduate, MCA, etc Experience: 2-5 years\n\nCompetencies Description\nData Science TCB is applicable to one who\n1) Analyses data to arrive at patterns/Insights/models\n2) Come up with models based on the data to provide recommendations, predictive analytics etc\n3) Provides implementation of the models in R, Matlab etc\n4) Can understand and apply machine learning/AI techniques\nPlatforms-\nUnix\nTechnology Standard-\nNA\nTools-\nR, Matlab, Spark Machine Learning, Python-ML, SPSS, SAS\nLanguages-\nR, Perl, Python, Scala\nSpecialization-\nCOGNITIVE ANALYTICS INCLUDING COMPUTER VISION, AI and ML, STATISTICS.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'R', 'SAS', 'Scala', 'Perl', 'SPSS', 'Spark', 'machine learning', 'Python']",2025-06-12 14:08:52
Senior Data Scientist,Toast,6 - 11 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist - S&A\nNow, more than ever, the Toast team is committed to our customers. We re taking steps to help restaurants navigate these unprecedented times with technology, resources, and community. We focus on building the restaurant platform that helps restaurants adapt, take control, and get back to what they do best: building the businesses they love. And because our technology is purpose-built for restaurants, by restaurant people, restaurants can trust that we ll deliver on their needs for today while investing in experiences that will power their restaurant of the future.\nBready*\nto make a change?\n\nAs the Senior Data Scientist in our Bangalore Data Science team, you will contribute to building machine learning algorithms using our huge reservoir of point of sale transaction data. You will work with architects, engineers and product managers to solve business and customer problems and turn machine learning models into business impact across product lines, including financial processing and fraud.\nAbout this\nRoll*\n:\nDesign, build, train and evaluate machine learning models to drive business value for Toast and our restaurant customers\nCollaborate closely with internal and external product stakeholders, both technical and non-technical and help translate deep machine learning knowledge to product applications\nBreak down larger ML initiatives into smaller problems that enables data science to deliver incremental business value and lead the team to execute on them\nWork closely with Production Engineering and Data Platform teams to deploy models to production and regularly monitor for efficiency, key KPIs and enhance them as needed\nWork with incident response and problem resolution teams to check and resolve any problems/challenges as and when identified in the model deployed in the production\nEffectively document all steps and manage code repositories for easy scalability and knowledge sharing with the the team\nIncorporate up-to-date ML technology and DS approach as best practice for the team\nHelp in continuing to build out and expand the Data Science and ML Engineering teams\nWork effectively in a dynamic, changing environment while focusing on key goals and objectives\nDo you have the right\ningredients*\n?\nAdvanced degree in Data Science, Statistics, Applied Math, Computer Science, Engineering or other equivalent quantitative disciplines\n6 + years of industry experience in the field of Data Science and Machine Learning\nExperience in time series modelling. Familiarity with ARIMA, SARIMA, ETS, VAR models. Familiarity with forecasting tools like Facebook Prophet, GluonTS, or NeuralProphet.\nStrong proficiency in Python and SQL; experience with some of the following languages, tools, and frameworks: R, Spark, Scala, scikit-learn, Tensorflow, PyTorch, etc.\nFamiliarity with standard software engineering practices and tools including object-oriented programming, test-driven development, CI/CD, git, shell scripting, task orchestration (Airflow, Luigi, etc.) and preferably AWS tooling (Sagemaker, DynamoDB, ECS, etc.)\nStrong knowledge of underlying mathematical foundations of statistics and machine learning\nPrior success deploying machine learning solutions in large-scale production environments\nExperience collaborating with cross-functional teams and stakeholders to evaluate new Machine Learning opportunities\nProblem solver who loves to dig into different kinds of data and can communicate their findings to cross-functional stakeholders\nBonus\ningredients*\n:\nPassion for research and curiosity that calls you to go beyond good enough to create something innovative and exciting\nDiversity, Equity, and Inclusion is Baked into our Recipe for Success\nAt Toast, our employees are our secret ingredient when they thrive, we thrive. The restaurant industry is one of the most diverse, and we embrace that diversity with authenticity, inclusivity, respect, and humility. By embedding these principles into our culture and design, we create equitable opportunities for all and raise the bar in delivering exceptional experiences.\nWe Thrive Together\nWe embrace a hybrid work model that fosters in-person collaboration while valuing individual needs. Our goal is to build a strong culture of connection as we work together to empower the restaurant community. To learn more about how we work globally and regionally, check out: https: / / careers.toasttab.com / locations-toast .\nApply today!\nToast is committed to creating an accessible and inclusive hiring process. As part of this commitment, we strive to provide reasonable accommodations for persons with disabilities to enable them to access the hiring process. If you need an accommodation to access the job application or interview process, please contact .\n------\nFor roles in the United States, It is unlawful in Massachusetts to require or administer a lie detector test as a condition of employment or continued employment. An employer who violates this law shall be subject to criminal penalties and civil liability.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'orchestration', 'data science', 'Production engineering', 'Machine learning', 'Shell scripting', 'test driven development', 'Forecasting', 'SQL', 'Python']",2025-06-12 14:08:54
Audit Manager Vice President Data Analytics,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"Wells Fargo is seeking a Data Analytics/Audit Manager, VP to lead audits within a dynamic environment. The person we seek will supervise audits and manage work within our CDO audit team, which is responsible for audit coverage of data management and data risk audit coverage strategy for Internal Audit. This is an individual contributor role.\nIn this role, you will:\nLead execution of the integrated audit process\nParticipate in audits in accordance with Wells Fargo Internal Audit policy",,,,"['Data Analytics', 'data management', 'Project management', 'data governance', 'data quality management', 'Risk management']",2025-06-12 14:08:56
Data Engineer III,Expedia Group,5 - 10 years,Not Disclosed,['Bengaluru'],"Why Join Us?\nTo shape the future of travel, people must come first. Guided by our Values and Leadership Agreements, we foster an open culture where everyone belongs, differences are celebrated and know that when one of us wins, we all win.\nWe provide a full benefits package, including exciting travel perks, generous time-off, parental leave, a flexible work model (with some pretty cool offices), and career development resources, all to fuel our employees passion for travel and ensure a rewarding career journey. We re building a more open world. Join us.\nData Engineer III\nIntroduction to the Team\nExpedia Technology teams partner with our Product teams to create innovative products, services, and tools to deliver high-quality experiences for travelers, partners, and our employees. A singular technology platform powered by data and machine learning provides secure, differentiated, and personalized experiences that drive loyalty and traveler satisfaction.\nExpedia Group is seeking a skilled and motivated Data Engineer III to join our Finance Business Intelligence team supporting the Product & Technology Finance organization. In this role, you will help drive data infrastructure and analytics solutions that support strategic financial planning, reporting, and operational decision-making across the Global Finance community. You ll work closely with Finance and Technology partners to ensure data accuracy, accessibility, and usability in support of Expedia s business objectives.\nAs a Data Engineer III, you have strong experience working with a variety of datasets, data environments, tools, and analytical techniques. You enjoy a fun, collaborative and stimulating team environment. Successful candidates should be able to own projects end-to-end, including identifying problems and solutions, building and maintain data pipelines and dashboards, distilling key insights and communicate to stakeholders.\nIn this role, you will:\nDevelop new and improve existing end to end Business Intelligence products (data pipelines, Tableau dashboards, and Machine Learning predictive forecasting models).\nDrive internal efficiencies through streamline code/documentation/Tableau development to maintain high data integrity.\nTroubleshoot and resolve production issues with the team products (automation opportunities, optimizations, back-end data issues, data reconciliations).\nProactively reach out to subject matter experts /stakeholders and collaborate to solve problems.\nRespond to ad hoc data requests and conduct analysis to provide valuable insights to stakeholders.\nCollaborate and coordinate with team members/stakeholders to translate complex data into meaningful insights, that improve the analytical capabilities of the business.\nApply knowledge of database design to support migration of data pipelines from on prem to cloud environment (including data extraction, ingestion, processing of large data sets)\nSupport dashboard development on cloud environment to enable self-service reporting.\nCommunicate clearly on current work status and design considerations\nThink broadly and comprehend the how, why, and what behind data architecture designs\nExperience & Qualifications:\nBachelor s in Computer Science, Mathematics, Statistics, Information Systems, or related field\n5+ years experience in a Data Analyst, Data Engineer or Business Analyst role\nProven expertise in SQL, with practical experience utilizing query engines including SQL Server, Starburst, Trino, Querybook and data science tools such as Python/R, SparkSQL.\nProficient visualization skills (Tableau, Looker, or similar) and excel modeling/report automation.\nExceptional understanding of relational and dimensional datasets, data warehouse and data mining and applies database design principles to solve data requirements\nExperience building robust data extract, load and transform (ELT) processes, that source data from multiple databases.\nDemonstrated record of defining and executing key analysis and solving problems with minimal supervision.\nDynamic individual contributor who consistently enhances operational playbooks to address business problems.\n3+ year working in a hybrid environment that uses both on-premise and cloud technologies is preferred.\nExperience working in an environment that manipulates large datasets on the cloud platform preferred.\nBackground in analytics, finance or a comparable reporting and analytics role preferred.\nAccommodation requests\nIf you need assistance with any part of the application or recruiting process due to a disability, or other physical or mental health conditions, please reach out to our Recruiting Accommodations Team through the Accommodation Request .\nWe are proud to be named as a Best Place to Work on Glassdoor in 2024 and be recognized for award-winning culture by organizations like Forbes, TIME, Disability:IN, and others.\nExpedia Groups family of brands includes: Brand Expedia , Hotels.com , Expedia Partner Solutions, Vrbo , trivago , Orbitz , Travelocity , Hotwire , Wotif , ebookers , CheapTickets , Expedia Group Media Solutions, Expedia Local Expert , CarRentals.com , and Expedia Cruises . 2024 Expedia, Inc. All rights reserved. Trademarks and logos are the property of their respective owners. . Never provide sensitive, personal information to someone unless you re confident who the recipient is. Expedia Group does not extend job offers via email or any other messaging tools to individuals with whom we have not made prior contact. Our email domain is @expediagroup.com. The official website to find and apply for job openings at Expedia Group is careers.expediagroup.com/jobs .\nExpedia is committed to creating an inclusive work environment with a diverse workforce. All qualified applicants will receive consideration for employment without regard to race, religion, gender, sexual orientation, national origin, disability or age.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Database design', 'Machine learning', 'Business intelligence', 'Data mining', 'Analytics', 'SQL', 'Python', 'Data architecture']",2025-06-12 14:08:58
Data Engineer _Technology Lead,Broadridge,6 - 10 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nAnalyzes and solve problems using technical experience, judgment and precedents\nProvides informal guidance to new team members\nExplains complex information to others in straightforward situations\n1. Data Engineering and Modelling:\nDesign & Develop Scalable Data Pipelines: Leverage AWS technologies to design, develop, and manage end-to-end data pipelines with services like .",,,,"['Star Schema', 'Snowflake', 'AWS', 'Apache Airflow']",2025-06-12 14:09:01
Senior Data Scientist - AI/ML,Inumellas Consultancy Services,9 - 14 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Role - Senior Data Scientist / Senior Gen AI Engineer\nExp Range - 8 to 18 yrs\nPosition - Permanent Fulltime\nCompany - Data Analytics & AIML MNC\nLocation - Hyderabad, Pune, Bangalore (Relocation accepted)\nAbout the Role:\n\nWe are seeking a Software Engineer with expertise in Generative AI and Microsoft technologies to design, develop, and deploy AI-powered solutions using the Microsoft ecosystem. You will work with cross-functional teams to build scalable applications leveraging generative AI models and Azure services.\n\nSkills Required:\n\nExperience with Large Language Models (LLMs) like GPT, LLaMA, Claude, etc.\nProficiency in Python for building and fine-tuning AI/ML models\nFamiliarity with LangChain, LLMOps, or RAG (Retrieval-Augmented Generation) pipelines\nExperience with Vector Databases (e.g. FAISS, Pinecone, Weaviate)\nKnowledge of Prompt Engineering and model evaluation techniques\nExposure to cloud platforms (Azure, AWS or GCP) for deploying GenAI solutions\n\nPreferred Skills:\n\nExperience with Azure OpenAI, Databricks or Microsoft Fabric\nHands-on with Hugging Face Transformers, OpenAI APIs or custom model training",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Deep Learning', 'Prompt Engineering', 'Large Language Model', 'Vector Database', 'Retrieval Augmented Generation', 'GenAI', 'Langchain', 'Artificial Intelligence', 'LLMOps', 'LLaMa', 'GPT', 'Azure OpenAI', 'Machine Learning', 'ML Models', 'Model Evaluation', 'Huggingface', 'Aiml', 'OpenAI', 'Azure Machine Learning', 'Python']",2025-06-12 14:09:03
Data Science,Global Banking Organization,5 - 10 years,Not Disclosed,['Bengaluru'],"Key Skills: Machine Learning, Data Science, Azure, Python, Hadoop.\nRoles and Responsibilities:\nStrong understanding of Math, Statistics, and the theoretical foundations of Statistical & Machine Learning, including Parametric and Non-parametric models.\nApply advanced data mining techniques to curate, process, and transform raw data into reliable datasets.\nUse various statistical techniques and ML methods to perform predictive modeling/classification for problems related to clients, distribution, sales, client profiles, and segmentation, and provide actionable insights for business decision-making.\nDemonstrate expertise in the full Machine Learning lifecycle--feature engineering, training, validation, scaling, deployment, scoring, monitoring, and feedback loops.\nProficiency in Python visualization libraries such as matplotlib and seaborn.\nExperience with cloud computing infrastructure like Azure, including Machine Learning Studio, Azure Data Factory, Synapse, Python, and PySpark.\nAbility to develop, test, and deploy models on cloud/web platforms.\nExcellent knowledge of Deep Learning Architectures, including Convolutional Neural Networks and Transformer/LLM Foundation Models.\nStrong expertise in supervised and adversarial learning techniques.\nRobust working knowledge of deep learning frameworks such as TensorFlow, Keras, and PyTorch.\nExcellent Python coding skills.\nExperience with version control tools (Git, GitHub/GitLab) and data version control.\nExperience in end-to-end model deployment and productionization.\nDemonstrated proficiency in deploying, scaling, and optimizing ML models in production environments with low latency, high availability, and cost efficiency.\nSkilled in model interpretability and CI/CD for ML using tools like MLflow and Kubeflow, with the ability to implement automated monitoring, logging, and retraining strategies.\nExperience Requirement:\n5-12 years of experience in designing and deploying deep learning and machine learning solutions.\nProven track record of delivering AI/ML solutions in real-world business applications at scale.\nHands-on experience working in cross-functional teams including data engineers, product managers, and business stakeholders.\nExperience mentoring junior data scientists and providing technical leadership within a data science team.\nExperience working with big data tools and environments such as Hadoop, Spark, or Databricks is a plus.\nPrior experience in managing model lifecycle in enterprise production environments including drift detection and retraining pipelines.\nEducation: B.Tech.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure', 'Hadoop.', 'Machine Learning', 'Python']",2025-06-12 14:09:05
Senior Data Scientist with GCP,TVS Next,5 - 7 years,Not Disclosed,['Bengaluru'],"What you’ll do:\nUtilize advanced mathematical, statistical, and analytical expertise to research, collect, analyze, and interpret large datasets from internal and external sources to provide insight and develop data driven solutions across the company\nBuild and test predictive models including but not limited to credit risk, fraud, response, and offer acceptance propensity\nResponsible for the development, testing, validation, tracking, and performance enhancement of statistical models and other BI reporting tools leading to new innovative origination strategies within marketing, sales, finance, and underwriting",,,,"['analytical', 'scikit-learn', 'searching', 'bi', 'pyspark', 'numpy', 'sql', 'analytics', 'apache', 'automation', 'data science', 'spark', 'gcp', 'bigquery', 'data visualization', 'xgboost', 'programming', 'reporting', 'ml', 'advanced analytics', 'python', 'data processing', 'predictive', 'jupyter notebook', 'bert', 'pandas', 'matplotlib', 'statistics']",2025-06-12 14:09:07
Senior Data Engineer - AWS,Blend360 India,5 - 10 years,Not Disclosed,['Hyderabad'],"Job Description\nWe are looking for an experienced Senior Data Engineer with a strong foundation in Python, SQL, and Spark , and hands-on expertise in AWS, Databricks . In this role, you will build and maintain scalable data pipelines and architecture to support analytics, data science, and business intelligence initiatives. You ll work closely with cross-functional teams to drive data reliability, quality, and performance.\nResponsibilities:\nDesign, develop, and optimize scalable data pipelines using Databricks in AWS such as Glue, S3, Lambda, EMR, Databricks notebooks, workflows and jobs.\nBuilding data lake in WS Databricks.\nBuild and maintain robust ETL/ELT workflows using Python and SQL to handle structured and semi-structured data.\nDevelop distributed data processing solutions using Apache Spark or PySpark .\nPartner with data scientists and analysts to provide high-quality, accessible, and well-structured data.\nEnsure data quality, governance, security, and compliance across pipelines and data stores.\nMonitor, troubleshoot, and improve the performance of data systems and pipelines.\nParticipate in code reviews and help establish engineering best practices.\nMentor junior data engineers and support their technical development.\n\n\nQualifications\nRequirements\nBachelors or masters degree in computer science, Engineering, or a related field.\n5+ years of hands-on experience in data",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Version control', 'GIT', 'Workflow', 'Data quality', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:09:10
BPEX (Business Process Excellence) - Malad,Motilal Oswal Financial Services (MOFSL),0 - 4 years,Not Disclosed,['Mumbai (All Areas)'],"Role & responsibilities\n1. Work full time on improvement projects\n2. Deliver BPEX trainings\n3. Support MBB/BB in projects\n4. Support Organization wide BPEX initiatives\n\nKey Work Relationships:\n\n1.Internal\n\nInvolving project team members including process owners, influencing people and driving process excellence across the organization\n2.External\n\nLimited\n\nPreferred candidate profile\n1.Experience - 0-2 years overall experience\n2.Other Skills - Good analytical and communication skills",Industry Type: Financial Services (Broking),Department: Quality Assurance,"Employment Type: Full Time, Permanent","['Lean Six Sigma', 'Process Excellence', 'Process Automation', 'Project Documentation', 'Six Sigma Certified', 'Process Documentation', 'Green Belt', 'Business Improvement', 'Yellow Belt', 'Data Analysis', 'Process Optimization', 'Business Excellence', 'BPEX']",2025-06-12 14:09:13
Lead Analyst,AMERICAN EXPRESS,5 - 10 years,Not Disclosed,['Gurugram'],"Global Merchant & Network Services (GMNS) brings together American Express merchant-and network-related businesses to enable a sharp focus on using the power of our network to provide unique value to all of our mutual customers. The organization manages the relationships with the millions of merchants around the world that accept American Express and runs the company s payment network and manages bank partnerships globally.\nIn support of GMNS s mission, Global, Strategy, Operations & Processes (GSOP) is focused on delivering a friction free, resilient, and efficient operational core for critical merchant experiences; strengthening monitoring and adherence to network and merchant policies; and leading key operational excellence functions. As part of GSOP, the Merchant Onboarding & Maintenance team prioritizes strengthening governance for merchant account setup, account management, and Know Your Customer (KYC) activities.",,,,"['Career development', 'Operational excellence', 'Data management', 'Account management', 'Information technology', 'Client management', 'Monitoring', 'SQL']",2025-06-12 14:09:15
Business Analyst,Abad Fisheries,3 - 5 years,4-7 Lacs P.A.,['Kochi( Thoppumpady )'],"Collaborate with department heads to define data needs and ensure consistent metric capture. Apply statistical tools to analyze data, identify trends & create clear visualizations using Power BI. Identify bottlenecks and improvement opportunities,\n\nRequired Candidate profile\nWe are looking for candidates from FMCG background with advanced Exel Knowledge and other data analysis tools like power BI, tableau etc..\n\nPerks and benefits\nBest in the industry",Industry Type: Food Processing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'VLOOKUP', 'Data Analysis', 'Advanced Excel', 'MIS Reporting', 'Data Visualizations', 'Excel', 'Dashboards']",2025-06-12 14:09:17
Business Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role we are seeking a Business Systems Analyst with a good background in data and analytics to define and manage product requirements for AI-driven applications.\nPartner with Data Scientists, ML Engineers, and Product Managers to define business processes, product needs, and AI solution requirements.\nCapture and document epics, user stories, acceptance criteria, and data process flows for AI-powered analytics applications.\nWork closely with partners to define scope, priorities, and impact of new AI and data initiatives.\nEnsure non-functional requirements, such as data security, model interpretability, and system performance, are included in product backlogs.\nFacilitate the breakdown of Epics into Features and Sprint-Sized User Stories and lead backlog grooming sessions.\nEnsure alignment of technical requirements and UX for AI-based applications and interactive dashboards.\nCollaborate with engineers to define data ingestion, transformation, and model deployment processes.\nDevelop and implement product demonstrations showcasing AI-driven insights and analytics.\nMaintain detailed documentation of data pipelines, model lifecycle management, and system integrations.\nStay engaged throughout software development, providing proactive feedback to ensure business needs are met\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. This role bridges the gap between business needs and technical execution, ensuring the development of high-quality, scalable AI solutions. You will collaborate with data scientists, engineers, and product managers to shape product roadmaps, refine requirements, and drive alignment between business objectives and technical capabilities.\nBasic Qualifications:\nMasters degree and 1 to 3 years expereince in Computer Science, Data Science, Information Systems, or related field OR\nBachelors degree and 3 to 5 years of in Computer Science, Data Science, Information Systems, or related field OR\nDiploma and 7 to 9 years of in Computer Science, Data Science, Information Systems, or related field\nPreferred Qualifications:\nExperience defining requirements for AI/ML models, data pipelines, or analytics dashboards.\nFamiliarity with cloud platforms (AWS, Azure, GCP) for AI and data applications.\nUnderstanding of data security, governance, and compliance in AI solutions.\nAbility to communicate complex AI concepts and technical constraints to non-technical partners.\nKnowledge of MLOps, model monitoring, and CI/CD for AI applications.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business analysis', 'continuous integration', 'data science', 'gcp', 'ci/cd', 'microsoft azure', 'information systems', 'aws', 'artificial intelligence']",2025-06-12 14:09:19
Data Engineer,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"Role Description:\nAs part of the cybersecurity organization, In this vital role you will be responsible for designing, building, and maintaining data infrastructure to support data-driven decision-making. This role involves working with large datasets, developing reports, executing data governance initiatives, and ensuring data is accessible, reliable, and efficiently managed. The role sits at the intersection of data infrastructure and business insight delivery, requiring the Data Engineer to design and build robust data pipelines while also translating data into meaningful visualizations for stakeholders across the organization. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture, ETL processes, and cybersecurity data frameworks.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in design and development of the data pipeline.\nBuild data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nDevelop and maintain interactive dashboards and reports using tools like Tableau, ensuring data accuracy and usability\nSchedule and manage workflows the ensure pipelines run on schedule and are monitored for failures.\nCollaborate with multi-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nCollaborate with data scientists to develop pipelines that meet dynamic business needs.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\n\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of experience of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience\nPreferred Qualifications:\nHands on experience with data practices, technologies, and platforms, such as Databricks, Python, GitLab, LucidChart, etc.\nHands-on experience with data visualization and dashboarding toolsTableau, Power BI, or similar is a plus\nProficiency in data analysis tools (e.g. SQL) and experience with data sourcing tools\nExcellent problem-solving skills and the ability to work with large, complex datasets\nUnderstanding of data governance frameworks, tools, and best practices\nKnowledge of and experience with data standards (FAIR) and protection regulations and compliance requirements (e.g., GDPR, CCPA)\n\nGood-to-Have Skills:\nExperience with ETL tools and various Python packages related to data processing, machine learning model development\nStrong understanding of data modeling, data warehousing, and data integration concepts\nKnowledge of Python/R, Databricks, cloud data platforms\nExperience working in Product team's environment\nExperience working in an Agile environment\n\nProfessional Certifications:\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\n\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to handle multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data engineering', 'data analysis', 'data modeling', 'analysis tools', 'data warehousing', 'troubleshooting', 'data architecture', 'data integration', 'etl process']",2025-06-12 14:09:21
Business Analyst,WP Translation And Testing Services,1 - 4 years,5-7 Lacs P.A.,['Navi Mumbai'],"Role - Business Analyst Software Testing Products\nExperience 1-3 Years\nLocation Ghansoli, Navi Mumbai\nNotice period – Immediate – 30 days\nJob Type – Contract (6-9 Months)\n\nWP is looking for a results-oriented Business Analyst with 1-2 years of experience in software product development, specializing in quality assurance (QA) and testing solutions. The candidate should have expertise in gathering and analyzing business requirements by coordinating with relevant stakeholders, act as an interface between stakeholders and development teams, and contribute to the development of scalable, user-friendly test management and testing automation products.\n\nResponsibilities:\n• Collaborate with development team, UI/UX engineering and QA, assist on continuous basis to shape product features aligned with product testing workflows.\n• Research and document requirements from stakeholders and product owners.\n• Document detailed functional specifications and write user stories. Prioritize tasks using internal task management tool.\n• Worked closely with developers to validate logic and alignment with product requirements & functionalities.\n• Perform UAT, validate test cases, and coordinate with QA for release signoffs.\n\nKey Skills:\n• Business analysis expertise with software testing experience will be an added advantage\n• Agile Software Development Lifecycle (SDLC) understanding\n• Exposure to various tools like TestRail, Jira, Bugzila, etc.\n• Workflow Design & User Story Creation (Agile/Scrum)\n• Background of API & Integration Requirement Analysis\n• SQL & Basic Data Analysi",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Agile', 'JIRA', 'SDLC Life Cycle', 'SQL', 'Testrail', 'Scrum', 'API', 'Bugzilla']",2025-06-12 14:09:23
Analytics and Modeling Senior Analyst,Overture Rede,2 - 5 years,Not Disclosed,['Bengaluru'],"Lead sales reporting, business analysis, and team development to enable data-driven decision-making and support sales enablement strategies.\n\nJob Summary\nWe are seeking an experienced Analytics and Modeling Senior Analyst to drive insights and reporting for sales enablement initiatives. The role involves managing analytics processes, mentoring teams, and supporting strategic decision-making through accurate data reporting and business intelligence.\n\nRequired Skills\n5+ years in sales operations and data analysis\nAdvanced Excel skills; Power Query, Power Pivot, Power BI preferred\nExperience in Software & Platforms and cloud/data infrastructure\nExcellent communication and stakeholder management\nProficiency in MS Office Suite (Excel, Word, PowerPoint, Outlook)\nExpertise in workflow management, process mapping, and training delivery\nStrong in RCA, collaboration, and team coaching",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MS Office suite', 'RCA', 'Data analysis', 'Sales operations', 'Business analysis', 'Senior Analyst', 'sales enablement', 'Business intelligence', 'Stakeholder management', 'Analytics']",2025-06-12 14:09:25
Hiring For MIS (Senior Analyst)-Chandigarh,Skyway Solution,1 - 4 years,1-4.25 Lacs P.A.,['Chandigarh'],"Hiring For MIS ( Senior Analyst)-Male\nLocation - Chandigarh\n\nGraduate\nExperience - 1year exp in MIS\n\nSalary - Up to 35,000/-\nRotational shift\n5 days working\nCandidate should must have knowledge of Advance Excel\n\nShare cv@9988352892\nHR -Sonali Rana",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Advanced Excel', 'MIS Operations', 'Formulas', 'Charts', 'MIS Reporting', 'Excel Reporting', 'HLOOKUP', 'Macros', 'Pivot Table', 'MIS', 'VLOOKUP', 'Data Analysis', 'Data Reporting']",2025-06-12 14:09:27
Scientific Business Analyst (Specialist) – Biological Studies (LIMS),Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements LIMS platforms that enable the capture, analysis, storage, and report of pre-clinical and clinical studies as well as those that manage biological sample banks. You will collaborate with Product Owners and developers to maintain an efficient and consistent process, ensuring quality work from the team. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\n\nRoles & Responsibilities:\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the technology ecosystem for in vivo study data management and ensure that the platform meets their requirements for data analysis and data integrity\nTranslate complex scientific and technological needs into clear, actionable requirements for development teams\nDevelop and maintain a product roadmap that clearly outlines the planned features and enhancements, timelines, and achievements\nIdentify and manage risks associated with the systems, including technological risks, scientific validation, and user acceptance\nDevelop documentations, communication plans and training plans for end users\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\nCollaborate with geographically dispersed teams, including those in the US and other international locations.\nFoster a culture of collaboration, innovation, and continuous improvement.\nWhat we expect of you\n\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nMasters degree and 4 to 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree and 6 to 8 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma and 10 to 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nMust-Have\n\nSkills:\nDemonstrated expertise in a scientific domain area and related technology needs\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience in configuration and administration of LIMS/ELN platforms such as Benchling, Revvity, IDBS, STARLIMS, Watson, LabVantage, etc.\nExperience using platforms such as Spotfire, Tableau, Power BI, etc., to build dashboards and reports\nPreferred Qualifications:\n5+ years of experience in designing and supporting biopharma scientific software platforms\nExperience leading the implementation of scientific software platforms, Electronic Lab Notebook (ELN), or Laboratory Information Management Systems (LIMS)\nExperience handling GxP data and system validation, and knowledge of regulatory requirements affecting laboratory data (e.g., FDA 21 CFR Part 11, GLP, GCP)\nKnowledge of bioanalytical workflows and/or biospecimen management\nExperience in AI and machine learning for drug discovery research and preclinical development\nExperience with cloud (e.g. AWS) and on-premise infrastructure\nIn-depth knowledge of Agile processes and principles for coordinated solutions and teams via SAFe\nExperience in establishing business partnerships and IS governance practices involving senior business collaborators\nKnowledge of business analysis standard methodologies, DevOps, Continuous Integration, and Continuous Delivery methodology\nProfessional Certifications:\nSAFe for Teams certification (preferred)\nSoft\n\nSkills:\nAble to work under minimal supervision\nExcellent analytical and gap/fit assessment skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills\nAs we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, well support your journey every step of the way.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Biological Studies', 'computational biology', 'FDA 21 CFR Part 11', 'biopharma', 'GCP', 'bioinformatics', 'system validation', 'GLP', 'computational chemistry', 'GxP data']",2025-06-12 14:09:30
Technical Business Analyst,Euclid Innovations,10 - 20 years,Not Disclosed,[],"Hi ,\nGreetings from Euclid Innovations !!!\n\nWe have openings for Technical Business Analyst with one of our Banking based Company as Remote work Mode.\n\nPosition : Technical Business Analyst\nExperience : 10+ Years\nLocation : Remote\nNotice Period: Immediate to 20 Days Max\n\nSkills set: FINANCIAL /CAPITAL MARKET and FIXED INCOME, EQUITY, CREDIT, Bond, Investment Banking any\n\nDuties and Responsibilities\nAssist in the Business Analysis phase including the capture and translation of business requirements turning these into functional requirements, and non-functional requirements (i.e. architectural, infrastructure, security, testing, migration, operational, DR). Ensuring appropriate documentation of requirements is captured and recorded (e.g. 'Requirement Story' in JIRA).\nAnalysing end to end business streams to establish data requirements in line with XML/XSD modelling, specifically FpML, of entities across multiple business areas across multiple geographical regions.\nLogical Data Modelling working closely with both business and IT teams.\nIdentification of common data requirements and helping to drive shared data platforms.\nCleaning, mapping, and extending data sets to improve business processes and tools.\nCoordination and delivery management of solutions across Enterprise Delivery teams in support of end to end testing and production delivery.\nAdherence to existing global, local and department project standards for documentation, security, testing and release management.\nQualifications, Skills and Experience\nBachelors Degree or equivalent.\nExcellent technical analysis and investigatory skills.\nAbility to work with both business and IT staff in a pressured environment.\nBusiness analysis within an Agile development project.\nStrong data analysis skills to ensure accurate system data extracts and reconciliations working with large datasets.\nProven track record of writing structured business requirements and functional specifications.\nWorking knowledge of financial instruments: government bonds, SAS bonds, credit bonds, exchange traded bond futures, interest rate swaps, repos, stock lending and equities.\nWell-structured and logical approach to working.\nGood knowledge of Compliance business processes.\nProven track record of supporting Back/Middle Office systems.\nProven experience of developing mutually beneficial relationships with business stake holders, users, software solution providers, and other IT teams.\nProven experience of full involvement in project life cycles within Investment Banking.\nProven experience performing system testing and guiding users with building their functional plans for user testing.\nAbility to handle multiple work streams and assignments simultaneously.\nProven experience of issue resolution through data mining and investigation\n\nif interested share profile to aruna.c@euclidinnovations.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Capital Market', 'Data Modelling', 'Investment Banking', 'Business Analyst', 'Technical Business Analyst', 'XML', 'XSD', 'Fixed Income', 'EQUITY']",2025-06-12 14:09:32
Budgeting Analyst Cloud & Enterprise ( Immediate Joiner),Hiring for Telecom Client,7 - 10 years,14-22.5 Lacs P.A.,['Hyderabad'],"Key Result Areas/Accountabilities\n\nBudgeting Strategy and forecasting\nFiscal budget forecasting for Core based on inputs from various stakeholders viz. Business, Marketing, COG, Radio Planning and Enterprise.\nLong Range Planning (LRP), annual and quarterly capex budgeting strategies for Core domain.\nCapex budget finalisation for the year, present annual budgets to CXOs.\nReview budget requests for approval. Prioritization and allocations based on criticality across sub domains and circles.\nFinalisation of capacity, coverage targets, KPIs, deliverables for Core.\nForecast future budget needs and quarter-wise refresh cycles. Interfacing with the finance team for available budget and further execution.\nBudget control and cost efficiency\nRegular monitoring of budget release v/s spend.\nPost budget approval, execution of budget - involvement in various stages of execution, resolving issues in the process, managing budget shortfalls.\nEstimate QoQ capex savings due to various cost-effective measures in coordination with cross functional teams.\nMonitoring reusability of inventory\nEnsure cost effective network solution\nCore Competencies, Knowledge, Experience\n\nTechnical Skills\nNetwork Understanding: A solid grasp of telecommunications networks, especially mobility network (2G/4G/5G) Core and cloud networks. A thorough understanding of cloud infrastructure and various enterprise solutions like CPaaS, U/CCaaS, IoT, SIP Trunking, SDWAN, Private 5G etc.\nData Analysis: Proficiency in data analysis tools (e.g., Excel, Python) to extract insights from large datasets.\nTechnical Writing: Ability to create clear and concise documentation, reports, and presentations.\nProblem-Solving: Strong analytical and problem-solving skills to identify and resolve technical issues.\nTechnical Tools: Extensive experience in leveraging MS Office Suite (Excel, PowerPoint, Word) and SAP for data analysis and reporting,\nSoft Skills\nCommunication Skills: Effective written and verbal communication skills to convey complex technical information to both technical and non-technical audiences.\nAttention to Detail: Meticulous attention to detail to ensure accuracy in data analysis and report generation.\nSchedule Management: Ability to prioritize tasks and meet deadlines efficiently.\nAdaptability: Flexibility to adapt to changing business requirements and technological advancements.\nMust have technical / professional qualifications\n\nEngineering Graduate.\nAny industry grade certifications in Telecom Network, SAP are good to have.\nYears of Experience\n\nMin 6 Years",Industry Type: Telecom / ISP,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Budget Analysis', 'Ucaas', 'SDWAN', 'SAP', 'QoQ capex', 'Cost Optimization', 'IoT', 'mobility network', 'Private 5G', 'CPaaS', 'Budgeting Strategy and forecasting', 'SIP Trunking', 'cloud infrastructure', 'Cost Planning', 'Revenue Planning']",2025-06-12 14:09:35
Business Analyst (Capital Markets),Eagle Technology Resources,5 - 10 years,Not Disclosed,[],"Job Title: Business Analyst Capital Markets\nLocation: Bhuvaneswar/Chennai/Remote Work\nSalary: Based on competency\nRequired Skills (Domain):\nCandidate must possess minimum of 5+ years of experience in Banking and Financial services domain with Investment Management experience.\nGood understanding of the systems, workflows and data related to front, middle, and back-office solutions in Asset Servicing/Asset Management.\nStrong grasp of Investment operational processes with respect to Accounting, Pricing, Nav Calculation, Trade Settlement, Reconciliation, Reference Data Management, Corporate Actions etc\nHands-on experience in Eagle suit of products (Accounting, RDC/SRM, Data Management or Performance) is a must.\nClient interfacing skills, Requirements gathering, Data Analysis skills and Test Execution skills are mandatory\nGood understanding of Market Data and operational workflow related to EQ, Fixed Income, Derivatives (Options, Futures, Swaps, etc) and/or Alternatives are a must\nStrong understanding of data integration, meta data management and ability to run SQL queries to perform data analysis are must to have.\nStrong communication and Documentation skills are mandatory Exposure to Third-party data providers such as Bloomberg, Reuters, MSCI, and other rating agencies is a plus.\nThis is what you will do:\nThis position requires a highly motivated individual with the ability to work independently and as part of a project team.\nYou will :\nBe working with the client team to gather requirements, demonstrate product capabilities, define/streamline Business Processes, train the client team on product modules, triage, debug, and fix quality issues through resolution.\nMust rationalize problems and use judgment and innovation to define clear and concise solutions.\nPerform gap analysis or conduct Proof of concepts where necessary\nPrepare Functional Requirements and to articulate them to Client Stakeholders to pursue approvals.\nHandle client expectations and manage the delivery of related interfaces by internally coordinating with teams across the globe.\nPrepare test bed for UAT executions\nBe writing test cases, test plans and preparing detailed test logs with suitable proof of validation.\nBe writing SQL queries to validate voluminous data across systems and performing reconciliation.\nCollaborate across regions (APAC, EMEA, and NA) to effectively and efficiently identify root cause of code/data issues and come up with a permanent solution.\nTeam Overview:\nThe dedicated team of highly skilled professionals at Eagle Technology Resources Pvt Ltd work on ensuring deployment of innovative solutions for the complex world of finance. Our extensive experience helps clients bring to life their business and technology operations, as well as gain the most value from their ongoing investments in technology.\nThis is what you will get:\nCompetitive compensation package.\nA close and informal relation with the client’s team (We are treated as the extension of the project team of our client).\nChallenging product development work with a team of professionals.\nDynamic environment with very low level of bureaucracy.\nFlexible working hours with the option to work from home under certain circumstances.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Data Management', 'Fixed Income Analysis', 'Capital Market', 'Market Data', 'Requirement Gathering', 'Reconciliation', 'Middle Office Operations', 'Derivatives', 'Consulting And Implementation', 'Trade Settlements', 'Investment Management', 'SQL']",2025-06-12 14:09:37
Scientific Business Analyst ( Specialist ) – Large Molecule Discovery,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that they technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role demonstrates scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams.\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the Large Molecule Discovery technology ecosystem and ensure that the platform meets the requirements for data analysis and data integrity\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\nBasic Qualifications:\nMasters degree with 4 - 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 6- 8years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 10 - 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nPreferred Qualifications:\n5+ years of experience in implementing and supporting biopharma scientific software platforms.\n\n\nFunctional Skills:\nMust-Have Skills:\nProven expertise in a scientific domain area and related technology needs\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience in configuration and administration of LIMS/ELN platforms (e.g. Benchling), Discovery software tools (e.g. Geneious, Genedata Screener) and Instrument Automation and Analysis platforms\nExperience using platforms such as Spotfire, Tableau, Power BI, etc., to build dashboards and reports and understanding of basic data querying using SQL, Databricks, etc.\n\n\nGood-to-Have Skills:\nExperience leading the implementation of scientific software platforms, Electronic Lab Notebook (ELN), or Laboratory Information Management Systems (LIMS)\nKnowledge of the antibody discovery design, make, test, and analyze cycle.\nExperience in AI and machine learning for drug discovery research and preclinical development\nExperience with leveraging LLM tools to accelerate software development processes.\nExperience with cloud (e.g. AWS) and on-premise infrastructure.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analysis', 'Spotfire', 'Power BI', 'Tableau', 'Databricks', 'JIRA', 'LLM', 'AWS', 'SQL']",2025-06-12 14:09:39
Data Scientist (Offshore),HTC Global Services,2 - 7 years,Not Disclosed,['Chennai'],"We are seeking a Data Scientist (Offshore) with minimum experience of 3 or more years. The ideal candidate should be familiar with relational or NoSQL databases such as Oracle, Teradata, SQL Server, Hadoop and ELK etc.\nRequirements:\nMinimum 3 or more years working with languages such as R, Python or Java\nAt least 3 or more years working with advanced statistical methods such as regressions, classifiers, recommenders, anomaly detection, optimization algorithms, tree methods and neural nets etc.",,,,"['tableau', 'NoSQL', 'Hadoop', 'Agile', 'Teradata SQL', 'data visualization', 'Oracle', 'Powerpoint', 'SDLC', 'Python']",2025-06-12 14:09:41
Supplier Quality Management Senior Analyst,Vertiv Group Corp,5 - 8 years,Not Disclosed,['Mumbai'],"Vertiv Group Corp is looking for Supplier Quality Management Senior Analyst to join our dynamic team and embark on a rewarding career journey.\nThe Senior Analyst plays a crucial role in driving data-driven decision-making processes within the organization\nThis position involves analyzing complex data sets, generating actionable insights, and providing strategic recommendations to support key business initiatives\nKey Responsibilities:Data Analysis:Conduct in-depth analysis of large and complex datasets to extract meaningful insights",,,,"['inprocess quality', 'sqa', 'data analysis', 'apqp', 'quality control', 'iso', 'control plan', 'spc', '7qc', 'pfmea', 'incoming quality', '8d', 'fmea', 'supplier quality assurance', 'quality assurance', 'qms', 'vendor quality', 'supplier quality', 'msa', 'supplier audit', 'ppap', 'customer quality']",2025-06-12 14:09:44
"Financial Analyst II - AR, FinOps",Amazon,5 - 10 years,Not Disclosed,['Hyderabad'],"Are you an experienced Program Manager interested in an opportunity to help drive Amazon s flywheel and develop your A to Z business understanding? Do you enjoy learning about different Amazon business types and new subsidiaries, and thinking creatively about brand new businesses that Amazon is inventing on behalf of customers? The Global Accounts Receivable (GAR) team is seeking a creative and passionate program manager to help achieve our vision to provide a world-class Order-to-Cash (O2C) onboarding experience to our global business partners in support of Amazon s journey to become earth s most customer-centric company. We love to offer our customers unique world-class experiences, and we invite you to help Amazon make history!\n\nThe Program Manager will have global oversight of the integration of new initiatives onto O2C platforms, driving effective people, processes, and technology to achieve organizational goals and deliver results. This individual will have ownership over new business integration programs while standardizing the global implementation processes and driving efficiency. This role will require engagement and alignment with global business teams, finance teams, operational teams, system developers and product managers. Responsibilities include supporting new business initiatives through designing transactional workflows in line with the business model, defining requirements and testing of the solutions to ensure delivery is as expected and delivering and improving the customer experience. Implementation of mechanisms to monitor and measure performance is essential.\n\nThe ability to thrive in a fast-paced, ambiguous and demanding work environment is critical to success in this role. The ideal candidate will be a self-starter with knowledge of program management, experience with accounts receivable operational processes, demonstrate faster learning and adoptability, demonstrate good relationship and strategic influencing skills, experienced in large scale change management across functions and geographies, and exhibit a relentless pursuit for improvement. This individual must have a proven record of delivering results through good program management skills, problem solving skills, financial process and system knowledge, and a passion for customer experience.\n\nCore Requirements:\n5+ years of Accounts Receivable experience, with at least 2 years in a leadership role( not mandate)\nBachelors degree in Finance, Accounting, Business Administration, or related field\nAdvanced Excel skills and experience with ERP systems\nData Analytics Requirements:\n3+ years experience with data analysis and reporting tools\nProficiency in SQL for data extraction and analysis\nExperience with visualization tools (e.g., Tableau, Power BI)\nDemonstrated ability to translate data insights into actionable recommendations\n\nProgram Management Skills:\n3+ years experience managing complex projects or programs\nTrack record of process improvement initiatives\nExperience leading cross-functional teams\nGood stakeholder management abilities\nTechnical Skills:\nExperience with AR automation tools and systems\nKnowledge of financial control frameworks\nProficiency in Microsoft Office Suite\nExperience with business intelligence platforms\n\nAdditional Desired Qualifications:\nMBA or relevant masters degree\nProfessional certifications (CPA, PMP, or similar)\nExperience with machine learning or predictive analytics\nKnowledge of Python or R for advanced data analysis\n\n\nOwnership and implementation of new businesses and subsidiaries onto AR platforms\nPartner with key counterparts across geographies to launch and support initiatives globally in a scalable manner\nDevelop a solid understanding of Amazon s Finance Operations systems and processes\nDefine and implement global standards for business integration program management\nDefine and describe various business scenarios that can be relevant to New Businesses and convert them into system and operational requirements.\nTranslate complex business requirements into functional designs\nOversee comprehensive testing of systems changes and development of standard operating procedures, process documentation and performance metrics\nManage process transitions/implementations across multiple functions and geographies\nMotivate and influence business, operational and technical teams to ensure that best practices are followed and implemented\nIdentify, assess, track and mitigate risks at multiple levels\nProactively monitor program performance to identify, address and prevent potential issues\nAddress barriers through problem solving, communication and active coordination with stakeholders\nDrive effective teamwork, communication collaboration and commitment across multiple disparate groups with competing priorities\nIdentify gaps and strive constantly for re-engineering of systems and processes\nAmazon is an Equal Opportunity-Affirmative Action Employer Minority / Female / Disability /\nVeteran / Gender Identity / Sexual Orientation\n5+ years of Accounts Receivable (AR) experience 4+ years of participating in continuous improvement projects in your team to scale and improve controllership with measurable results experience\nMBA, or CPA\nKnowledge of Tableau\nExperience working with large-scale data mining and reporting tools (examples: SQL, MS Access, Essbase, Cognos) and other financial systems (examples: Oracle, SAP, Lawson, JD Edwards)",,,,"['Data analysis', 'Change management', 'PMP', 'SAP', 'MS Access', 'Process improvement', 'Oracle', 'Data mining', 'Business intelligence', 'SQL']",2025-06-12 14:09:46
Senior Associate - Data Science,Axtria,3 - 8 years,Not Disclosed,['Noida'],"Job Summary-\nData Scientist with good hands-on experience of 3+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nJob Responsibilities-\n\n1. Hands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\n2. Proficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\n3. Experience of working in large teams and using collaboration tools like GIT, Jira and Confluence\n4. Good understanding of any of the cloud platform - AWS, Azure or GCP\n5. Understanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\n6. Should have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\n7. Should be able to mentor and guide mid to large sized teams under him/her\n\nJob -\n1. Strong experience on Spark with Scala/Python/Java\n2. Strong proficiency in building/training/evaluating state of the art machine learning models and its deployment\n3. Proficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\n4. Proficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'keras', 'spark mllib', 'jira', 'sentiment analysis', 'lingpipe', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-12 14:09:49
Senior Associate - Data Science,Axtria,2 - 5 years,Not Disclosed,['Noida'],"Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT\nSoftware development experience in python is needed as backend for UI based applications\nBe a part of large delivery teams working on advanced projects when expert assistance is required.\nDeliver advanced Data Science capabilities to businesses in a meaningful manner through successful proof-of-concept solutions, and later smoothly transition the proof-of-concept into production.\nCreate Technical documents, develop, test, and deploy data analytics processes using Python, SQL on Azure/AWS platforms\nCan interact with client on GenAI related capabilities and use cases\n\n\nMust have\n\nSkills:\n\n\nMinimum of 3-5years develop, test, and deploy Python based applications on Azure/AWS platforms\nMust have basic knowledge on concepts of Generative AI / LLMs / GPT\nDeep understanding of architecture and work experience on Web Technologies\nPython, SQL hands-on experience\nExpertise in any popular python web frameworks e.g. flask, Django etc.\nFamiliarity with frontend technologies like HTML, JavaScript, REACT",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'software testing', 'gpm', 'microsoft azure', 'python web framework', 'data analytics', 'neural networks', 'aws stack', 'machine learning', 'javascript', 'artificial intelligence', 'sql', 'react.js', 'deep learning', 'django', 'data science', 'html', 'flask', 'aws']",2025-06-12 14:09:51
Sr Tax Analyst,Illuminz,4 - 7 years,Not Disclosed,['Bengaluru'],"What if the work you did every day could impact the lives of people you know? Or all of humanity?\nAt Illumina, we are expanding access to genomic technology to realize health equity for billions of people around the world. Our efforts enable life-changing discoveries that are transforming human health through the early detection and diagnosis of diseases and new treatment options for patients.\nWorking at Illumina means being part of something bigger than yourself. Every person, in every role, has the opportunity to make a difference. Surrounded by extraordinary people, inspiring leaders, and world changing projects, you will do more and become more than you ever thought possible.\nJoin us and you can make a difference\nIllumina s mission is to improve human health by unlocking the power of the genome. If that inspires you, let s talk.\nAt Illumina, we push boundaries. We think beyond the conventional. We dream big. With the energy of so many bright and accomplished people, the opportunities are endless. You ll join a culture fueled by innovation, collaboration and openness. We change lives by driving advancements in life sciences, oncology, reproductive health, genetic disease and other emerging markets. We are all deeply passionate about what we do, knowing that our work has the power to improve lives.\nJob Summary\nIllumina is looking for Tax Analyst/Sr Tax Analyst to be part of newly created Tax Center of Excellence in India and reports to Tax Manager in India. This role will be APAC tax compliance focused and primarily responsible in all aspects of data analysis, tax calculation and reconciliation necessary to meet APAC tax filing, tax audit and statutory audit requirements in APAC region. You will support the Tax Manager in fostering seamless collaboration with global/regional Finance and Tax teams, and other business stakeholders to ensure the adherence of tax compliance governance and efficient tax process maintained in the region.\nTasks and Responsibilities:\nJob duties include but not limited to:\nPrepare monthly tax calculation for APAC entities, this includes extracting SAP reports, analyzing and reconciling financial data, and coordinating with finance teams.\nCollation and managing all aspects of information necessary for submission in tax audits, inquiries and notices raised by tax authorities.\nPerform financial data analysis/schedules/reports necessary for internal and external tax reporting for APAC entities\nInvolve in month-end/statutory audit activities, this includes preparing tax provision/deferred tax calculation and reconciliation relating to tax accounts for APAC entities\nIdentify and drive opportunities for process optimization within the tax reporting workflow, which includes collaborating with internal stakeholder to align processes and implementing into the working environment.\nResearch tax regulations to address daily inquiry on TDS/GST/withholding tax/SAC coding\nParticipate in cross-functional projects and tax projects as and when assigned by the Regional Tax Team/Tax Manager\nPreferred Educational Background:\nBachelor s degree or equivalent in Accounting/Finance/Taxation.\nMinimum 4-7 year in accounting with direct and indirect tax from Big 4 or Accounting with taxation experience. APAC region exposure is a plus\nProficiency in Microsoft Office applications especially Microsoft Excel;\nPrior experience in SAP (or equivalent ERP system) is preferred;\nGood organizational skills, highly detailed oriented and ability to work with minimal supervision and independently;\nAbility to work in a dynamic and fast paced environment and a multi-tasker;\nAbility to be flexible and work analytically in a problem-solving environment;\nExcellent communication (written and oral) and interpersonal skills.\n\nWe are a company deeply rooted in belonging, promoting an inclusive environment where employees feel valued and empowered to contribute to our mission. Built on a strong foundation, Illumina has always prioritized openness, collaboration, and seeking alternative perspectives to propel innovation in genomics. We are proud to confirm a zero-net gap in pay, regardless of gender, ethnicity, or race. We also have several Employee Resource Groups (ERG) that deliver career development experiences, increase cultural awareness, and offer opportunities to engage in social responsibility. We are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship status, and genetic information. Illumina conducts background checks on applicants for whom a conditional offer of employment has been made. Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable local, state, and federal laws. Background check results may potentially result in the withdrawal of a conditional offer of employment. The background check process and any decisions made as a result shall be made in accordance with all applicable local, state, and federal laws. Illumina prohibits the use of generative artificial intelligence (AI) in the application and interview process. If you require accommodation to complete the application or interview process, please contact accommodations@illumina.com. To learn more, visit: https: / / www.dol.gov / ofccp / regs / compliance / posters / pdf / eeopost.pdf. The position will be posted until a final candidate is selected or the requisition has a sufficient number of qualified applicants. This role is not eligible for visa sponsorship.",Industry Type: Pharmaceutical & Life Sciences,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['TDS', 'Data analysis', 'Process optimization', 'SAP', 'Excel', 'Coding', 'Tax reporting', 'Workflow', 'Taxation', 'Auditing']",2025-06-12 14:09:54
Senior Data Scientist,Straive,5 - 10 years,Not Disclosed,"['Hyderabad', 'Gurugram', 'Bengaluru']","Role & responsibilities\nRequires 5-8 years of proven experience in banking/payments/other domains\nStrong experience in developing Machine Learning models, Python & SQL\nExperience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases\nDetailed oriented with a proactive mindset towards problem-solving\nExcellent communication and presentation skills with the ability to convey complex information clearly and concisely",,,,"['Machine Learning', 'Python', 'SQL', 'Xgboost', 'Neural Networks', 'Random Forest']",2025-06-12 14:09:56
Analyst - Projects,Microland,4 - 6 years,Not Disclosed,['Bengaluru'],"Microland Limited is looking for Analyst - Projects to join our dynamic team and embark on a rewarding career journey.\n\nAs a Project Analyst, you will play a crucial role in supporting project planning, execution, and monitoring activities. Your responsibilities will include data analysis, reporting, and providing valuable insights to ensure the successful completion of projects. Strong analytical skills, attention to detail, and effective communication are essential for this role. Responsibilities : Project Planning Support : Assist in the development of project plans, including timelines, milestones, and resource requirements. Collaborate with project managers to ensure accurate and comprehensive project documentation. Data Analysis : Collect, analyze, and interpret data related to project performance and key metrics. Identify trends, patterns, and areas for improvement based on data analysis. Reporting : Prepare regular project status reports, highlighting key performance indicators and progress against goals. Communicate project updates to stakeholders in a clear and concise manner. Risk Management : Work with the project team to identify and assess risks. Contribute to the development of risk mitigation strategies. Resource Coordination : Collaborate with various teams and departments to ensure resources are allocated effectively. Assist in tracking resource utilization and availability. Quality Assurance : Support the implementation of quality assurance processes to ensure project deliverables meet established standards. Conduct periodic reviews to assess project compliance. Documentation : Maintain accurate and up - to - date project documentation, including meeting minutes, action items, and decision logs. Ensure documentation aligns with organizational standards.",,,,"['Data analysis', 'Master Analyst', 'Project management', 'Agile', 'Manager Technology', 'Scrum', 'Data analytics']",2025-06-12 14:09:58
"Associate Analyst, R Programmer-1",Mastercard,1 - 4 years,Not Disclosed,['Gurugram'],"We are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology.\nAn individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (eg Plotly, Highcharts, D3.js) or front-end frameworks (eg React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, we'll-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (eg roxygen2)\nfamiliar with version control concepts and tools (eg Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:00
Process Executive - B&L,Cognizant,0 - 2 years,Not Disclosed,['Coimbatore'],Job Summary\nThe Process Executive - B&L role is designed for individuals with 0 to 2 years of experience focusing on tasks related to consumer lending cards and payments. This position requires proficiency in MS Excel and offers a hybrid work model with day shifts. The role does not require travel allowing for a balanced work-life integration.,,,,"['cards', 'data analysis', 'analytical', 'workflow', 'lending', 'documentation', 'policies', 'business analysis', 'monitoring', 'process improvements', 'sql', 'plsql', 'excel', 'flexcube', 'operations', 'customer satisfaction', 'service delivery', 'compliance', 'onboarding', 'core banking', 'consumer lending', 'communication skills']",2025-06-12 14:10:03
Data & Analytics Specialist,Hoffmann La Roche,5 - 10 years,Not Disclosed,['Pune'],"At Roche you can show up as yourself, embraced for the unique qualities you bring. Our culture encourages personal expression, open dialogue, and genuine connections, where you are valued, accepted and respected for who you are, allowing you to thrive both personally and professionally. This is how we aim to prevent, stop and cure diseases and ensure everyone has access to healthcare today and for generations to come. Join Roche, where every voice matters.\nThe Position The Position\nWe are looking for a Data & Analytics Specialist/ Business Analyst who will join us in the newly setup Integrated Informatics for a journey to drive transformation with data and foster automated and efficient decision making throughout the organisation\nThe Data and Analytics Specialist must be the big-picture thinker who understands the value of data to the organisation, has a strong focus on delivering high value, connecting the dots, investing in right initiatives with reusability at the heart of it.\nIn this position you will be acting as squad lead, have end to end ownership of Product delivery with setting up teams from multiple teams/areas with focus on Lifecycle management of the product\nResponsibilities\nYou will work on various aspects of Analytics Solution Development, Data Management, Governance and Information Architecture including but not limited to:\nCollaborate with business stakeholders to understand their data and analytics needs and develop a product roadmap that aligns with business goals.\nDefine and prioritise product requirements, user stories, and acceptance criteria for data and analytics products and ensure what was agreed gets delivered.\nWork with data engineers and data scientists to develop data pipelines, analytical models, and visualisations that meet business requirements.\nCollaborate with Infrastructure Teams and software developers to ensure that data and analytics products are integrated into existing systems and platforms in a sustainable way that still meets the needs of business to generate the insights necessary to drive their decisions.\nMonitor data and analytics product performance and identify opportunities for improvement.\nStay up-to-date with industry trends and emerging technologies related to data and analytics in the pharmaceutical industry.\nAct as a subject matter expert for data and analytics products and provide guidance to business stakeholders on how to effectively use these products.\nAccountable to Develop and maintain documentation, training materials, and user guides for data and analytics products.\nThe ideal candidate\nBachelors or Masters degree in computer science, information systems, or a related field.\n5+ years of experience in roles such as Senior Data & Analytics Specialist, Data Solutions Lead, Data Architect, or Data Consultant, with a focus on solution design and implementation. Alternatively, 3-4 years of experience in data streams (e.g., Data Science, Data Engineering, Data Governance) combined with a couple of years in Strategic Data Consultancy / Data Product Ownership. Experience in the pharmaceutical or healthcare industry is highly desirable.\nHigh Level understanding of data engineering, data science, Data governance and analytics concepts and technologies.\nExperience working with cross-functional teams, including data engineers, data scientists, and software developers.\nExcellent communication and interpersonal skills.\nStrong analytical and problem-solving skills.\nExperience with agile development methodologies.\nKnowledge of regulatory requirements related to data and analytics in the pharmaceutical industry.\nKnowledge of working with vendor and customer master data for different divisions - Pharmaceuticals, Diagnostic, & Diabetes care.\nUnderstanding of the transparency reporting landscape.\nHands-on experience of working on applications such as Jira, SQL, Postman, SAP GUI, Monday.com, Trello\nProficient in the knowledge of different CRM/Master Data Management systems such as SFDC, Reltio MDM\nUnderstanding data protection laws and consent processes applicable to healthcare professionals and organizations before transparency disclosure.\nWho we are\n.\nBasel is the headquarters of the Roche Group and one of its most important centres of pharmaceutical research. Over 10,700 employees from over 100 countries come together at our Basel/Kaiseraugst site, which is one of Roche`s largest sites. Read more.\nBesides extensive development and training opportunities, we offer flexible working options, 18 weeks of maternity leave and 10 weeks of gender independent partnership leave. Our employees also benefit from multiple services on site such as child-care facilities, medical services, restaurants and cafeterias, as well as various employee events.\nWe believe in the power of diversity and inclusion, and strive to identify and create opportunities that enable all people to bring their unique selves to Roche.\nRoche is an Equal Opportunity Employer.\nWho we are\nA healthier future drives us to innovate. Together, more than 100 000 employees across the globe are dedicated to advance science, ensuring everyone has access to healthcare today and for generations to come. Our efforts result in more than 26 million people treated with our medicines and over 30 billion tests conducted using our Diagnostics products. We empower each other to explore new possibilities, foster creativity, and keep our ambitions high, so we can deliver life-changing healthcare solutions that make a global impact.\n\nLet s build a healthier future, together.\nRoche is an Equal Opportunity Employer.\n""",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAP', 'Diagnostics', 'HP data protector', 'Analytical', 'Healthcare', 'JIRA', 'Analytics', 'SQL', 'CRM']",2025-06-12 14:10:05
Data & Analytics Specialist,Roche Diagnostics,5 - 10 years,Not Disclosed,['Pune'],"At Roche you can show up as yourself, embraced for the unique qualities you bring. Our culture encourages personal expression, open dialogue, and genuine connections, where you are valued, accepted and respected for who you are, allowing you to thrive both personally and professionally. This is how we aim to prevent, stop and cure diseases and ensure everyone has access to healthcare today and for generations to come. Join Roche, where every voice matters.\nThe Position The Position\nWe are looking for a Data & Analytics Specialist/ Business Analyst who will join us in the newly setup Integrated Informatics for a journey to drive transformation with data and foster automated and efficient decision making throughout the organisation\nThe Data and Analytics Specialist must be the big-picture thinker who understands the value of data to the organisation, has a strong focus on delivering high value, connecting the dots, investing in right initiatives with reusability at the heart of it.\nIn this position you will be acting as squad lead, have end to end ownership of Product delivery with setting up teams from multiple teams/areas with focus on Lifecycle management of the product\nResponsibilities\nYou will work on various aspects of Analytics Solution Development, Data Management, Governance and Information Architecture including but not limited to:\nCollaborate with business stakeholders to understand their data and analytics needs and develop a product roadmap that aligns with business goals.\nDefine and prioritise product requirements, user stories, and acceptance criteria for data and analytics products and ensure what was agreed gets delivered.\nWork with data engineers and data scientists to develop data pipelines, analytical models, and visualisations that meet business requirements.\nCollaborate with Infrastructure Teams and software developers to ensure that data and analytics products are integrated into existing systems and platforms in a sustainable way that still meets the needs of business to generate the insights necessary to drive their decisions.\nMonitor data and analytics product performance and identify opportunities for improvement.\nStay up-to-date with industry trends and emerging technologies related to data and analytics in the pharmaceutical industry.\nAct as a subject matter expert for data and analytics products and provide guidance to business stakeholders on how to effectively use these products.\nAccountable to Develop and maintain documentation, training materials, and user guides for data and analytics products.\nThe ideal candidate\nBachelors or Masters degree in computer science, information systems, or a related field.\n5+ years of experience in roles such as Senior Data & Analytics Specialist, Data Solutions Lead, Data Architect, or Data Consultant, with a focus on solution design and implementation. Alternatively, 3-4 years of experience in data streams (e.g., Data Science, Data Engineering, Data Governance) combined with a couple of years in Strategic Data Consultancy / Data Product Ownership. Experience in the pharmaceutical or healthcare industry is highly desirable.\nHigh Level understanding of data engineering, data science, Data governance and analytics concepts and technologies.\nExperience working with cross-functional teams, including data engineers, data scientists, and software developers.\nExcellent communication and interpersonal skills.\nStrong analytical and problem-solving skills.\nExperience with agile development methodologies.\nKnowledge of regulatory requirements related to data and analytics in the pharmaceutical industry.\nKnowledge of working with vendor and customer master data for different divisions - Pharmaceuticals, Diagnostic, & Diabetes care.\nUnderstanding of the transparency reporting landscape.\nHands-on experience of working on applications such as Jira, SQL, Postman, SAP GUI, Monday.com, Trello\nProficient in the knowledge of different CRM/Master Data Management systems such as SFDC, Reltio MDM\nUnderstanding data protection laws and consent processes applicable to healthcare professionals and organizations before transparency disclosure.\nWho we are\nAt Roche, more than 100,000 people across 100 countries are pushing back the frontiers of healthcare. Working together, we ve become one of the world s leading research-focused healthcare groups. Our success is built on innovation, curiosity and diversity.\nBasel is the headquarters of the Roche Group and one of its most important centres of pharmaceutical research. Over 10,700 employees from over 100 countries come together at our Basel/Kaiseraugst site, which is one of Roche`s largest sites. Read more.\nBesides extensive development and training opportunities, we offer flexible working options, 18 weeks of maternity leave and 10 weeks of gender independent partnership leave. Our employees also benefit from multiple services on site such as child-care facilities, medical services, restaurants and cafeterias, as well as various employee events.\nWe believe in the power of diversity and inclusion, and strive to identify and create opportunities that enable all people to bring their unique selves to Roche.\nRoche is an Equal Opportunity Employer.\nWho we are\n.\n\nLet s build a healthier future, together.\nRoche is an Equal Opportunity Employer.\n""",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'SAP', 'Diagnostics', 'HP data protector', 'Analytical', 'Healthcare', 'JIRA', 'Analytics', 'SQL', 'CRM']",2025-06-12 14:10:07
"Associate Analyst, R Programmer-2",Mastercard,3 - 6 years,Not Disclosed,['Gurugram'],"The Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (eg Plotly, Highcharts, D3.js) or front-end frameworks (eg React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, we'll-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (eg roxygen2)\nfamiliar with version control concepts and tools (eg Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:10
Senior Associate Data Scientist,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will identify trends, root causes, and potential improvements in our products and processes, ensuring that patient voices are heard and addressed with utmost precision.\nAs the Sr Associate Data Scientist at Amgen, you will be responsible for developing and deploying basic machine learning, operational research, semantic analysis, and statistical methods to uncover structure in large data sets. This role involves creating analytics solutions to address customer needs and opportunities.\nCollect, clean, and manage large datasets related to product performance and patient complaints.\nEnsure data integrity, accuracy, and accessibility for further analysis.\nDevelop and maintain databases and data systems for storing patient complaints and product feedback.\nAnalyze data to identify patterns, trends, and correlations in patient complaints and product issues.\nUse advanced statistical methods and machine learning techniques to uncover insights and root causes.\nDevelop analytics or predictive models to foresee potential product issues and patient concerns to address customer needs and opportunities.\nPrepare comprehensive reports and visualizations to communicate findings to key collaborators.\nPresent insights and recommendations to cross-functional teams, including product development, quality assurance, and customer service.\nCollaborate with regulatory and compliance teams to ensure adherence to healthcare standards and regulations.\nFind opportunities for product enhancements and process improvements based on data analysis.\nWork with product complaint teams to implement changes and monitor their impact.\nStay abreast of industry trends, emerging technologies, and standard methodologies in data science and healthcare analytics.\nEvaluate data to support product complaints.\nWork alongside software developers and software engineers to translate algorithms into commercially viable products and services.\nWork in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\nPerform exploratory and targeted data analyses using descriptive statistics and other methods.\nWork with data engineers on data quality assessment, data cleansing and data analytics\nGenerate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience OR\nBachelors degree and 3 to 5 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience OR\nDiploma and 7 to 9 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience\nPreferred Qualifications:\nDemonstrated skill in the use of applied analytics, descriptive statistics, feature extraction and predictive analytics on industrial datasets.\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification.\nExperience in analyzing time-series data for forecasting and trend analysis.\nExperience with Data Bricks platform for data analytics.\nExperience working with healthcare data, including patient complaints, product feedback, and regulatory requirements.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'data bricks', 'hypothesis testing', 'predictive analytics', 'data visualization', 'machine learning', 'statistics']",2025-06-12 14:10:12
"Associate Analyst, R Programmer-3",Mastercard,4 - 7 years,Not Disclosed,['Gurugram'],"The Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology.\n  An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (eg Plotly, Highcharts, D3.js) or front-end frameworks (eg React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, we'll-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (eg roxygen2)\nfamiliar with version control concepts and tools (eg Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:14
Data Engineer,AMERICAN EXPRESS,2 - 4 years,13-17 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Role & responsibilities\nUnderstanding business use cases and be able to convert to technical design\nPart of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners.\nYou will be designing scalable, testable and maintainable data pipelines\nIdentify areas for data governance improvements and help to resolve data quality problems through the appropriate choice of error detection and correction, process control and improvement, or process design changes",,,,"['Spark', 'SQL', 'Python', 'Hadoop', 'Big Data']",2025-06-12 14:10:16
Data Engineer,Luxoft,5 - 10 years,Not Disclosed,['Pune'],"Are you passionate about data and analytics? Are you keen to be part of the journey to modernize a data warehouse/ analytics suite of application(s). Do you take pride in the quality of software delivered for each development iteration?\nWere looking for someone like that to join us and\nbe a part of a high-performing team on a high-profile project.\nsolve challenging problems in an elegant way\nmaster state-of-the-art technologies\nbuild a highly responsive and fast updating application in an Agile & Lean environment\napply best development practices and effectively utilize technologies\nwork across the full delivery cycle to ensure high-quality delivery\nwrite high-quality code and adhere to coding standards\nwork collaboratively with diverse team(s) of technologists\nYou are:\nCurious and collaborative, comfortable working independently, as well as in a team\nFocused on delivery to the business\nStrong in analytical skills. For example, the candidate must understand the key dependencies among existing systems in terms of the flow of data among them. It is essential that the candidate learns to understand the big picture of how IB industry/business functions.\nAble to quickly absorb new terminology and business requirements\nAlready strong in analytical tools, technologies, platforms, etc. The candidate must also demonstrate a strong desire for learning and self-improvement.\nOpen to learning home-grown technologies, support current state infrastructure and help drive future state migrations. imaginative and creative with newer technologies\nAble to accurately and pragmatically estimate the development effort required for specific objectives\nYou will have the opportunity to work under minimal supervision to understand local and global system requirements, design and implement the required functionality/bug fixes/enhancements. You will be responsible for components that are developed across the whole team and deployed globally.\nYou will also have the opportunity to provide third-line support to the applications global user community, which will include assisting dedicated support staff and liaising with the members of other development teams directly, some of which will be local and some remote.\nSkills\nMust have\nA bachelors or masters degree, preferably in Information Technology or a related field (computer science, mathematics, etc.), focusing on data engineering.\n5+ years of relevant experience as a data engineer in Big Data is required.\nStrong Knowledge of programming languages (Python / Scala) and Big Data technologies (Spark, Databricks or equivalent) is required.\nStrong experience in executing complex data analysis and running complex SQL/Spark queries.\nStrong experience in building complex data transformations in SQL/Spark.\nStrong knowledge of Database technologies is required.\nStrong knowledge of Azure Cloud is advantageous.\nGood understanding and experience with Agile methodologies and delivery.\nStrong communication skills with the ability to build partnerships with stakeholders.\nStrong analytical, data management and problem-solving skills.\nNice to have\nExperience working on the QlikView tool\nUnderstanding of QlikView scripting and data model\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nBig Data Engineer (Scala/Java/Python)\nBigData Development\nUnited States of America\nStamford, US\nBig Data Engineer (Scala/Java/Python)\nBigData Development\nUnited States of America\nWeehawken\nData Engineer - PostgreSQL\nBigData Development\nPoland\nRemote Poland\nPune, India\nReq. VR-114879\nBigData Development\nBCM Industry\n05/06/2025\nReq. VR-114879\nApply for Data Engineer in Pune\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data management', 'Coding', 'Postgresql', 'Agile', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-12 14:10:19
Data Science Manager,ZS,10 - 15 years,Not Disclosed,"['Pune', 'Bengaluru']","A key enabler of our services is leveraging data in delivering client solutions. The data available about customers is getting richer and the problems that our customers are trying to answer continue to evolve. In our endeavor to stay ahead in providing solutions to these evolving complex problems, ZS has set up an Advanced Data Science which has three major focus areas:\nResearch the evolving datasets and advanced analytical techniques to develop new offerings/solutions\nDeliver client impact by collaboratively implementing these solutions",,,,"['Team management', 'data science', 'Pharma', 'Analytical', 'Management consulting', 'Financial planning', 'Healthcare', 'Project planning', 'Predictive modeling', 'Financial services']",2025-06-12 14:10:21
"Associate Analyst, R Programmer-3",Dynamic Yield,4 - 7 years,Not Disclosed,['Gurugram'],"Our Purpose\nTitle and Summary\nAssociate Analyst, R Programmer-3\nOverview\nThe Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (e.g. Plotly, Highcharts, D3.js) or front-end frameworks (e.g. React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, well-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (e.g. roxygen2)\nfamiliar with version control concepts and tools (e.g. Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:10:23
Enterprise Data Operations Manager,Pepsico,12 - 17 years,Not Disclosed,['Hyderabad'],"Overview\n\nDeputy Director - Data Engineering\n\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCos global business scale to enable business insights, advanced analytics, and new product development. PepsiCos Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nIncrease awareness about available data and democratize access to it across the company.\nAs a data engineering lead, you will be the key technical expert overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be empowered to create & lead a strong team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premises data sources as well as cloud and remote systems.\nResponsibilities\n\nData engineering lead role for D&Ai data modernization (MDIP)\n\nIdeally Candidate must be flexible to work an alternative schedule either on tradition work week from Monday to Friday; or Tuesday to Saturday or Sunday to Thursday depending upon coverage requirements of the job. The candidate can work with immediate supervisor to change the work schedule on rotational basis depending on the product and project requirements.\nResponsibilities\nManage a team of data engineers and data analysts by delegating project responsibilities and managing their flow of work as well as empowering them to realize their full potential.\nDesign, structure and store data into unified data models and link them together to make the data reusable for downstream products.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nCreate reusable accelerators and solutions to migrate data from legacy data warehouse platforms such as Teradata to Azure Databricks and Azure SQL.\nEnable and accelerate standards-based development prioritizing reuse of code, adopt test-driven development, unit testing and test automation with end-to-end observability of data\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality, performance and cost.\nCollaborate with internal clients (product teams, sector leads, data science teams) and external partners (SI partners/data providers) to drive solutioning and clarify solution requirements.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects to build and support the right domain architecture for each application following well-architected design standards.\nDefine and manage SLAs for data products and processes running in production.\nCreate documentation for learnings and knowledge transfer to internal associates.\nQualifications\n\n12+ years of engineering and data management experience\n\nQualifications\n12+ years of overall technology experience that includes at least 5+ years of hands-on software development, data engineering, and systems architecture.\n8+ years of experience with Data Lakehouse, Data Warehousing, and Data Analytics tools.\n6+ years of experience in SQL optimization and performance tuning on MS SQL Server, Azure SQL or any other popular RDBMS\n6+ years of experience in Python/Pyspark/Scala programming on big data platforms like Databricks\n4+ years in cloud data engineering experience in Azure or AWS.\nFluent with Azure cloud services. Azure Data Engineering certification is a plus.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modelling, data warehousing, and building high-volume ETL/ELT pipelines.\nExperience with data profiling and data quality tools like Great Expectations.\nExperience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one business intelligence tool such as Power BI or Tableau\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like ADO, Github and CI/CD tools for DevOps automation and deployments.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus.\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nBA/BS in Computer Science, Math, Physics, or other technical fields.\nCandidate must be flexible to work an alternative work schedule either on tradition work week from Monday to Friday; or Tuesday to Saturday or Sunday to Thursday depending upon product and project coverage requirements of the job.\nCandidates are expected to be in the office at the assigned location at least 3 days a week and the days at work needs to be coordinated with immediate supervisor\nSkills, Abilities, Knowledge:\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain/exceed individual and team goals.\nAbility to lead others without direct authority in a matrixed environment.\nComfortable working in a hybrid environment with teams consisting of contractors as well as FTEs spread across multiple PepsiCo locations.\nDomain Knowledge in CPG industry with Supply chain/GTM background is preferred.",Industry Type: Beverage,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Pyspark', 'Azure', 'Power BI', 'Github', 'Azure Databricks', 'Tableau', 'ADO', 'Scala programming', 'SQL', 'Azure Data Factory', 'Azure Machine learning', 'Data Lakehouse', 'Azure Data Engineering', 'CI/CD', 'Data Warehousing', 'Data Analytics', 'AWS', 'Python']",2025-06-12 14:10:26
Manager Data Science,Optum,12 - 17 years,Not Disclosed,['Noida'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together. \n\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.\n\n Primary Responsibilities \nDevelop and implement AI and machine learning strategies for several healthcare domains\nCollaborate with cross-functional teams to identify and prioritize AI and machine learning initiatives\nManage the development and deployment of AI and machine learning solutions\nDevelop and run pipelines for data ingress and model output egress\nDevelop and run scripts for ML model inference\nDesign, implement, and maintain CI/CD pipelines for MLOps and DevOps functions\nIdentify technical problems and develop software updates and fixes\nDevelop scripts or tools to automate repetitive tasks\nAutomate the provisioning and configuration of infrastructure resources\nProvide guidance on the best use of specific tools or technologies to achieve desired results\nCreate documentation for infrastructure design and deployment procedures\nUtilize AI/ML frameworks and tools such as MLFlow, TensorFlow, PyTorch, Keras, Scikit-learn, etc.\nLead and manage AI/ML teams and projects from ideation to delivery and evaluation\nApply expertise in various AI/ML techniques, including deep learning, NLP, computer vision, recommender systems, reinforcement learning, and large language models\nCommunicate complex AI/ML concepts and results to technical and non-technical audiences effectively\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\n Required Qualifications: \nBachelors/master degree in computer science, engineering, mathematics, statistics, or a related discipline\n12+ years of experience in Software Engineering, Data Science, or Analytics with 8+ years of experience in AI/ML engineering or related fields\nExperience with cloud platforms and services, such as AWS, Azure, GCP, etc.\nExperience in developing solutions in the NLP space and relevant projects\nHands on Experience in AI and drive the development of innovative AI and machine learning solutions\nDemonstrated experience in leading and managing AI/ML teams and projects, from ideation to delivery and evaluation\nExperience with Azure development environments\nKnowledge of NLP literature, thrust areas, conference venues, and code repositories\nFamiliarity with both open-source and OpenAI LLMs and RAG architecture\nFamiliarity with UI tools like Streamlit, Flask, FAST APIs, Rest APIs, Docker containers\nUnderstanding of common NLP tasks such as text classification, entity recognition, entity extraction, and question answering\nProficient in Python and one of PySpark or Scala. Familiarity with python tools for data processing\nProficiency in multiple machine learning and AI techniques such as supervised, unsupervised, reinforcement learning, deep learning, and NLP\nProficiency in Python, R, or other programming languages for data analysis and AI/ML development\nProficiency in libraries such as Hugging Face and OpenAI API\nProven ability to develop and deploy data pipelines, machine learning models, or applications on cloud platforms (Azure, Databricks, AzureML)\nProven excellent communication, presentation, and interpersonal skills, with the ability to explain complex AI/ML concepts and results to technical and non-technical audiences\nProven solid analytical, problem-solving, and decision-making skills, with the ability to balance innovation and pragmatism\nProeven passion for learning and staying updated with the latest AI/ML trends and research",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'machine learning', 'artificial intelligence', 'r', 'continuous integration', 'data analysis', 'scala', 'scikit-learn', 'presentation skills', 'ci/cd', 'microsoft azure', 'docker', 'tensorflow', 'data science', 'ai techniques', 'devops', 'pytorch', 'keras', 'software engineering', 'aws']",2025-06-12 14:10:28
Sr Data Engineer,Lowes Services India Private limited,5 - 10 years,Not Disclosed,['Bengaluru'],"We are seeking a seasoned Senior Data Engineer to join our Marketing Data Platform team. This role is pivotal in designing, building, and optimizing scalable data pipelines and infrastructure that support our marketing analytics and customer engagement strategies. The ideal candidate will have extensive experience with big data technologies, cloud platforms, and a strong understanding of marketing data dynamics.\n\nData Pipeline Development & Optimization\nDesign, develop, and maintain robust ETL/ELT pipelines using Apache PySpark on GCP services like Dataproc and Cloud Composer.\nEnsure data pipelines are scalable, efficient, and reliable to handle large volumes of marketing data.\nData Warehousing & Modeling\nImplement and manage data warehousing solutions using BigQuery, ensuring optimal performance and cost-efficiency.\nDevelop and maintain data models that support marketing analytics and reporting needs.\nCollaboration & Stakeholder Engagement\nWork closely with marketing analysts, data scientists, and cross-functional teams to understand data requirements and deliver solutions that drive business insights.\nTranslate complex business requirements into technical specifications and data architecture.\nData Quality & Governance\nImplement data quality checks and monitoring to ensure the accuracy and integrity of marketing data.\nAdhere to data governance policies and ensure compliance with data privacy regulations.\nContinuous Improvement & Innovation\nStay abreast of emerging technologies and industry trends in data engineering and marketing analytics.\nPropose and implement improvements to existing data processes and infrastructure\n  Years of Experience\n5 Years in Data Engineer space\n  Education Qualification & Certifications\nB.Tech or MCA\n  Experience\nProven experience with Apache PySpark, GCP (including Dataproc, BigQuery, Cloud Composer), and data pipeline orchestration.\nTechnical Skills\nProficiency in SQL and Python.\nExperience with data modeling, ETL/ELT processes, and data warehousing concepts.",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['orchestration', 'Data modeling', 'data governance', 'Data quality', 'Apache', 'Continuous improvement', 'Monitoring', 'SQL', 'Python', 'Data architecture']",2025-06-12 14:10:30
Azure Cloud Data Engineering Consultant,Optum,7 - 10 years,17-27.5 Lacs P.A.,['Gurugram'],"Primary Responsibilities:\nDesign and develop applications and services running on Azure, with a strong emphasis on Azure Databricks, ensuring optimal performance, scalability, and security.\nBuild and maintain data pipelines using Azure Databricks and other Azure data integration tools.\nWrite, read, and debug Spark, Scala, and Python code to process and analyze large datasets.\nWrite extensive query in SQL and Snowflake\nImplement security and access control measures and regularly audit Azure platform and infrastructure to ensure compliance.\nCreate, understand, and validate design and estimated effort for given module/task, and be able to justify it.\nPossess solid troubleshooting skills and perform troubleshooting of issues in different technologies and environments.\nImplement and adhere to best engineering practices like design, unit testing, functional testing automation, continuous integration, and delivery.\nMaintain code quality by writing clean, maintainable, and testable code.\nMonitor performance and optimize resources to ensure cost-effectiveness and high availability.\nDefine and document best practices and strategies regarding application deployment and infrastructure maintenance.\nProvide technical support and consultation for infrastructure questions.\nHelp develop, manage, and monitor continuous integration and delivery systems.\nTake accountability and ownership of features and teamwork.\nComply with the terms and conditions of the employment contract, company policies and procedures, and any directives.\nRequired Qualifications:\nB.Tech/MCA (Minimum 16 years of formal education)\nOverall 7+ years of experience.\nMinimum of 3 years of experience in Azure (ADF), Databricks and DevOps.\n5 years of experience in writing advanced level SQL.\n2-3 years of experience in writing, reading, and debugging Spark, Scala, and Python code.\n3 or more years of experience in architecting, designing, developing, and implementing cloud solutions on Azure.\nProficiency in programming languages and scripting tools.\nUnderstanding of cloud data storage and database technologies such as SQL and NoSQL.\nProven ability to collaborate with multidisciplinary teams of business analysts, developers, data scientists, and subject-matter experts.\nFamiliarity with DevOps practices and tools, such as continuous integration and continuous deployment (CI/CD) and Teraform.\nProven proactive approach to spotting problems, areas for improvement, and performance bottlenecks.\nProven excellent communication, writing, and presentation skills.\nExperience in interacting with international customers to gather requirements and convert them into solutions using relevant skills.\nPreferred Qualifications:\nKnowledge of AI/ML or LLM (GenAI).\nKnowledge of US Healthcare domain and experience with healthcare data.\nExperience and skills with Snowflake.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Azure Databricks', 'ETL', 'SQL', 'Python', 'Airflow', 'Pyspark', 'Snowflake', 'SCALA', 'Spark', 'Data Bricks']",2025-06-12 14:10:32
R&D Technologist - Clinical Data Management,ZS,5 - 10 years,Not Disclosed,"['Pune', 'Bengaluru']","Our team has deep understanding of EDC tools like Rave, Veeva, InForm, openClinica, clinical data repositories like SAS LSAF, Oracle LSH, eCS elluminate, Metadata Repositories like Nurocor, Sycamore, Formedix, statistical computing environments like Sycamore, Domino, Sas Viya systems, Clinical data review systems, RBQM systems, and more. With experience as solution architects, business analysts, or techno-functional SMEs in GXP compliant validated environments, they guide the creation of solution, data flows and strategies for building clinical development and data management systems. Their offerings encompass technical advisory, consultancy, developing of clinical data platforms and products, system integration, and intelligent automation. Additionally, the team has created innovative tools through advanced technology and data science, aiding numerous clients in expediting the drug development process.",,,,"['Automation', 'SAS', 'Business analysis', 'Pharma', 'Consulting', 'Financial planning', 'Oracle', 'Risk management', 'Analytics', 'Clinical data management']",2025-06-12 14:10:35
Senior Data Engineer,Talentien Global Solutions,4 - 8 years,12-18 Lacs P.A.,"['Hyderabad', 'Chennai', 'Coimbatore']","We are seeking a skilled and motivated Data Engineer to join our dynamic team. The ideal candidate will have experience in designing, developing, and maintaining scalable data pipelines and architectures using Hadoop, PySpark, ETL processes, and Cloud technologies.\n\nResponsibilities:\nDesign, develop, and maintain data pipelines for processing large-scale datasets.\nBuild efficient ETL workflows to transform and integrate data from multiple sources.\nDevelop and optimize Hadoop and PySpark applications for data processing.\nEnsure data quality, governance, and security standards are met across systems.\nImplement and manage Cloud-based data solutions (AWS, Azure, or GCP).\nCollaborate with data scientists and analysts to support business intelligence initiatives.\nTroubleshoot performance issues and optimize query executions in big data environments.\nStay updated with industry trends and advancements in big data and cloud technologies.\nRequired Skills:\nStrong programming skills in Python, Scala, or Java.\nHands-on experience with Hadoop ecosystem (HDFS, Hive, Spark, etc.).\nExpertise in PySpark for distributed data processing.\nProficiency in ETL tools and workflows (SSIS, Apache Nifi, or custom pipelines).\nExperience with Cloud platforms (AWS, Azure, GCP) and their data-related services.\nKnowledge of SQL and NoSQL databases.\nFamiliarity with data warehousing concepts and data modeling techniques.\nStrong analytical and problem-solving skills.\n\nInterested can reach us at +91 7305206696/ saranyadevib@talentien.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Engineering', 'Hadoop', 'Spark', 'ETL', 'Airflow', 'Etl Pipelines', 'Big Data', 'EMR', 'Gcp Cloud', 'Data Bricks', 'Azure Cloud', 'Data Pipeline', 'SCALA', 'Snowflake', 'Data Lake', 'Data Warehousing', 'Data Modeling', 'AWS', 'Python']",2025-06-12 14:10:37
Lead Data Engineer - Azure,Blend360 India,7 - 12 years,Not Disclosed,['Hyderabad'],"Job Description\nAs a Sr Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\nQualifications\n7+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar fiel",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:10:39
Senior GCP Data Engineer,Swits Digital,6 - 9 years,Not Disclosed,['Bengaluru'],"Job Title: Senior GCP Data Engineer\nLocation: Chennai, Bangalore, Hyderabad\nExperience: 6-9 Years\nJob Summary:\nWe are seeking a GCP Data & Cloud Engineer with strong expertise in Google Cloud Platform services, including BigQuery, Cloud Run, Cloud Storage , and Pub/Sub . The ideal candidate will have deep experience in SQL coding , data pipeline development, and deploying cloud-native solutions.\nKey Responsibilities:\nDesign, implement, and optimize scalable data pipelines and services using GCP\nBuild and manage cloud-native applications deployed via Cloud Run\nDevelop complex and performance-optimized SQL queries for analytics and data transformation\nManage and automate data storage, retrieval, and archival using Cloud Storage\nImplement event-driven architectures using Google Pub/Sub\nWork with large datasets in BigQuery , including ETL/ELT design and query optimization\nEnsure security, monitoring, and compliance of cloud-based systems\nCollaborate with data analysts, engineers, and product teams to deliver end-to-end cloud solutions\nRequired Skills & Experience:\n3+ years of experience working with Google Cloud Platform (GCP)\nStrong proficiency in SQL coding , query tuning, and handling complex data transformations\nHands-on experience with:\nBigQuery\nCloud Run\nCloud Storage\nPub/Sub\nUnderstanding of data pipeline and ETL/ELT workflows in cloud environments\nFamiliarity with containerized services and CI/CD pipelines\nExperience in scripting languages (e.g., Python, Shell) is a plus\nStrong analytical and problem-solving skills",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SUB', 'query optimization', 'GCP', 'Analytical', 'Cloud', 'query', 'cloud storage', 'Security monitoring', 'SQL coding', 'Python']",2025-06-12 14:10:42
"Associate Scientist, Data Sourcing & Solutions",XL India Business Services Pvt. Ltd,1 - 5 years,Not Disclosed,"['Hyderabad', 'Ahmedabad', 'Bengaluru']","Associate Scientist - Data Sourcing & Solutions Gurgaon/Bangalore, India AXA XL recognises data and information as critical business assets, both in terms of managing risk and enabling new business opportunities\n\nThis data should not only be high quality, but also actionable - enabling AXA XLs executive leadership team to maximise benefits and facilitate sustained enterprise advantage\n\nOur Innovation, Data, and Analytics Office (IDA) is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market\n\nAs we develop an enterprise-wide data and digital strategy that moves us toward a greater focus on the use of data and data-driven insights, we are seeking an Associate Scientist for our Data Sourcing & Solutions team\n\nThe role sits across the IDA Department to make sure customer requirements are properly captured and transformed into actionable data specifications\n\nSuccess in the role will require a focus on proactive management of the sourcing and management of data from source through usage\n\nWhat you ll be DOING What will your essential responsibilities include? Accountable for documenting data requirements (Business and Function Requirements) and assessing the reusability of Axiom assets\n\nBuild processes to simplify and expedite data sourcing to focus on delivering data to AXA XL business stakeholders frequently\n\nDevelops and operationalizes strategic data products, and answers and proactively manages the sourcing and management of data from source through usage (reusable Policy and Claim Domain data assets)\n\nData Validation Testing of the data products in partnership with the AXA XL business to ensure the accuracy of the data and validation of the requirements\n\nAssesses all data required as part of the Data Ecosystem to make sure data has a single version of the truth\n\nRespond to ad-hoc data requests to support AXA XLs business\n\nInstill a customer-first attitude, prioritizing service for our business stakeholders above all else\n\nInternalize and execute IDA and company-wide goals to become a data-driven organization\n\nContribute to best practices and standards to make sure there is a consistent and efficient approach to capturing business requirements and translating them into functional, non-functional, and semantic specifications\n\nDevelop a comprehensive understanding of the data and our customers\n\nDrive root cause analysis for identified data deficiencies within reusable data assets delivered via IDA\n\nIdentify solution options to improve the consistency, accuracy, and quality of data when captured at its source\n\nYou will report to the Team Lead - Data Sourcing & Solutions\n\nWhat you will BRING We re looking for someone who has these abilities and skills: Required Skills and Abilities: Experience in a data role (business analyst, data analyst, analytics) preferably in the Insurance industry and within a data division\n\nA minimum of a bachelor s or masters degree (preferred) in a relevant discipline\n\nRobust SQL knowledge and technical ability to query AXA XL data sources to understand our data\n\nExcellent presentation, communication (oral & written), and relationship-building skills, across all levels of management and customer interaction\n\nInsurance experience in data, underwriting, claims, and/or operations, including influencing, collaborating, and leading efforts in complex, disparate, and interrelated teams with competing priorities\n\nPassion for data and experience working within a data-driven organization\n\nWork together internal data with external industry data to deliver holistic answers\n\nWork with unstructured data to unlock information needed by the business to create unique products for the insurance industry\n\nPossesses robust exploratory analysis skills and high intellectual curiosity\n\nDisplays exceptional organizational skills and is detail-oriented\n\nThe robust conceptual thinker who connects dots, and has critical thinking, and analytical skills\n\nDesired Skills and Abilities: Ability to work with team members across the globe and departments\n\nAbility to take ownership, work under pressure, and meet deadlines\n\nBuilds trust and rapport within and across groups\n\nApplies in-depth knowledge of business and specialized areas to solve business problems and understand integration challenges and long-term impact creatively and strategically\n\nAbility to manage data needs of an individual project(s) while being able to understand the broader enterprise data perspective\n\nExpected to recommend innovation and improvement to policies, and procedures, deploying resources, and performing core activities\n\nExperience with SQL Server, Azure Databricks Notebook, Qlikview, PowerBI, and Jira/Confluence a plus",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data validation', 'Claims', 'Underwriting', 'Agile', 'QlikView', 'Business strategy', 'JIRA', 'Analytics', 'SQL', 'Customer interaction']",2025-06-12 14:10:44
Data Scientist,Ltimindtree,8 - 13 years,Not Disclosed,"['Chennai', 'Bengaluru', 'Mumbai (All Areas)']",We are looking for an experienced AI ML Developers experience in data science specializing in machine learning python statistical modelling and big data technologies pyspark sql.\n\nThe ideal candidate will have a strong background in developing and deploying machine learning models optimizing ML pipelines and handling largescale structured and unstructured data to drive business impact.\n\nDeep understanding of supervised and unsupervised learning including regression classification Multiclass classification clustering and NLP Proficiency in statistical analysis AB testing and causal inference techniques Experience with model deployment and MLOps in cloud environments AWS GCP \n\nKey Responsibilities\n\nDevelop and deploy machine learning models and predictive analytics solutions for business impact\nWork with largescale structured and unstructured data to extract insights and build scalable models\nDesign implement and optimize ML pipelines for realtime and batch processing\nCollaborate with engineering product and business stakeholders to translate business problems into data science solutions\nApply statistical modeling AB testing and causal inference techniques to evaluate business performance\nApply machine learning and statistical techniques for audience segmentation helping to identify patterns and optimise business strategies\nDrive research and innovation by staying updated with cuttingedge MLAI advancements and incorporating them into our solutions\nOptimize data science models for performance scalability and interpretability in production environments\nMentor junior data scientists and contribute to best practices in data science and engineering,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Aiml', 'Ab Testing']",2025-06-12 14:10:47
Data Scientist,Devon Software Services,3 - 7 years,12-19 Lacs P.A.,['Bengaluru'],"What you will do\nBuild end-to-end machine learning models to solve business problems in Marketing\nPerform feature engineering and support data engineering to build robust data pipelines on large marketing datasets from different sources\nCollaborate with ML Engineering to build ML Pipelines to Train, Test, Deploy, Serve and Monitor models, Tune Hyperparameters, detect model and data drift and resolve issues\nPresent machine learning models outcomes, and help interpret model predictions to various stakeholders using standard data visualization tools",,,,"['Tensorflow', 'Ai Algorithms', 'Ml Algorithms', 'Machine Learning', 'Python', 'Pytorch', 'Model Development']",2025-06-12 14:10:49
Data Scientist,Ltimindtree,8 - 13 years,19-34 Lacs P.A.,"['Pune', 'Bengaluru', 'Mumbai (All Areas)']",10 years of experience in Data ScienceML domain\nShould have experience in Python and libraries like pandas numpy scikitlearn etc\nHave worked on building ML models and integrating it with application end to end\nHave knowledge on Recommender engines and the ML models running behind it like ALS and LightFM\nHave experience in Azure Machine Learning and Azure Services\nHave experience in deploying models in cloud environment and exposing it as an API\nGood communication and presentation skill\nAbility to deliver ML projects as an individual contributor,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'Ml']",2025-06-12 14:10:51
ML Engineer/Data Scientist,Altimetrik,6 - 8 years,15-30 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Role & responsibilities\nData Scientist /ML engineers : ML Engineer with Python, SQL, Machine Learning, Azure skills(Good to have)",Industry Type: IT Services & Consulting,,,"['Machine Learning', 'Python', 'SQL', 'Data Science', 'Ml', 'azure']",2025-06-12 14:10:54
It Recruiter,IonIdea,0 - 3 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nTalent Sourcing: Utilize various channels such as job boards, social media, LinkedIn, networking events, and internal databases to source and attract high-quality candidates for a variety of technical positions (software developers, systems engineers, data scientists, etc.).\nCandidate Screening: Review resumes, conduct initial phone screenings, and assess candidates technical skills, experience, and cultural fit.\nInterview Coordination: Schedule and facilitate interviews with hiring managers, ensuring a smooth and efficient process for all parties involved.\nCandidate Engagement: Build relationships with both active and passive candidates to maintain a strong pipeline of qualified talent. Keep candidates informed throughout the hiring process.\nOffer Management: Work with HR and hiring managers to present offers, negotiate terms, and ensure a positive candidate experience during the offer process.\n\nQualifications:\nExperience: Fresher-3years\n\nTechnical Knowledge: A solid understanding of IT roles, including knowledge of programming languages, software development frameworks, network infrastructure, cloud technologies, and emerging IT trends.\nRecruitment Tools: Proficient in using Applicant Tracking Systems (ATS), job boards (e.g., LinkedIn, Indeed), and social media platforms for sourcing candidates.\nCommunication Skills: Excellent written and verbal communication skills with the ability to engage with both technical and non-technical stakeholders.",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['IT Recruitment', 'C2H', 'Contract Hiring']",2025-06-12 14:10:56
"Senior Analyst I, BI Solution Design & Transformation",XL India Business Services Pvt. Ltd,4 - 9 years,Not Disclosed,['Gurugram'],"Senior Analyst, BI Solution Design & Transformation Gurgaon/ Bangalore, India AXA XL recognizes data and information as critical business assets, both in terms of managing risk and enabling new business opportunities\n\nThis data should not only be high quality, but also actionable - enabling AXA XL s executive leadership team to maximize benefits and facilitate sustained advantage\n\nOur Chief Data Office also known as our Innovation, Data Intelligence & Analytics team (IDA) is focused on driving innovation through optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market\n\nAs we develop an enterprise-wide data and digital strategy that moves us toward greater focus on the use of data and data-driven insights, we are seeking an Assistant Manager for our Business Intelligence team\n\nThe role will support the team s efforts towards reporting transformation project (especially for Ceded Re business) and handling customer requests/enhancements\n\nThis role requires a person that is a team player, can work well with team members from other disciplines to deliver data in an efficient and strategic manner\n\nWhat you ll be DOING What will your essential responsibilities include: Business Intelligence Management: Oversee and manage Business Intelligence (BI) and Reporting activities, ensuring smooth operations and effective stakeholder engagement\n\nProduct Support and Management: Support and enhance BI and Reporting products, driving improvements that align with organizational goals and stakeholder needs\n\nModel Integration and Optimization: Energize and synergize various Business Intelligence models and reporting frameworks to enhance data insights and reporting effectiveness\n\nStrategic Initiative Support: Collaborate with the IDA team on various strategic initiatives, facilitating the development of BI and Reporting functions and related capabilities as they arise\n\nTalent Development: Foster the growth of BI and Reporting talent across AXA XL by promoting an inclusive and diverse environment that enhances the utilization and value creation of our digital, data, and analytics assets\n\nCustomer-Centric Culture: Instill a customer-first mentality within the team, prioritizing exceptional service and responsiveness to the needs of business stakeholders\n\nTeam Development and Culture Building: Contribute to the enhancement of the Business Intelligence team s tools, skills, and culture, driving positive impacts on team performance and outcomes\n\nYou will report to the Senior Manager, Business Intelligence & Reporting\n\nWhat you will BRING At AXA XL, we view individuals holistically through their People, Business, and Technical Skills\n\nWe re interested in what you bring, how you think, and your potential for growth\n\nWe value diverse backgrounds and perspectives, recognizing that each person contributes uniquely to our teams success\n\nWe value relevant education and experience in a related field\n\nAdditionally, we encourage candidates with diverse educational backgrounds or equivalent experience to apply\n\nHere are some of the key skills important for the role: PEOPLE Skills Customer Centricity: Brings a collaborative spirit, a can-do attitude, and a Customer First mindset, ensuring that stakeholder needs are prioritized\n\nAgility: Ability to communicate effectively within teams, peers, and across global teams, adapting to changing circumstances and stakeholder needs\n\nGrowth Mindset: Passion for digital, data, and AI, demonstrating a commitment to continuous learning and development in a digital and data-driven organization\n\nResilience: Ability to help and guide team members on technical issues, fostering their development so that the team can Self-directedly manage challenges\n\nPerformance Excellence: Relevant years of experience in a data role (analytics or engineering) supporting multiple specialty areas of Data and Analytics, showcasing a excellent track record of high performance\n\nCross-Functional Collaboration: Ability to effectively manage stakeholders and collaborate across various teams to achieve common goals\n\nBUSINESS Skills Ethical Judgment: Understanding of ethical considerations in data management and business practices, ensuring integrity in decision-making\n\nDigital Literacy: Relevant years of end-user experience with BI tools like Power BI, including the Report Builder tool, demonstrating proficiency in utilizing digital tools for data analysis\n\nBusiness & Insurance Acumen: A foundational understanding of general business concepts and principles, with an openness to learning about the insurance or financial services industry, providing a basis for growth in the role\n\nTECHNICAL Skills Data Analytics: Intermediate proficiency in SQL, Advanced Excel, MS Access, and VBA, enabling effective data manipulation and analysis\n\nReporting Tools: Extensive experience in building and managing data models in Power BI, contributing to effective reporting and insights generation\n\nData Visualization: Proficiency in utilizing BI tools to create meaningful visualizations that drive insights and support decision-making",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence reporting', 'Data analysis', 'MS Access', 'Agile', 'Business strategy', 'data visualization', 'Product support', 'Financial services', 'Reporting tools', 'SQL']",2025-06-12 14:10:58
"Associate Analyst, R Programmer-1",Dynamic Yield,1 - 4 years,Not Disclosed,['Gurugram'],"Our Purpose\nTitle and Summary\nAssociate Analyst, R Programmer-1\nOverview\nThe Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (e.g. Plotly, Highcharts, D3.js) or front-end frameworks (e.g. React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, well-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (e.g. roxygen2)\nfamiliar with version control concepts and tools (e.g. Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Software Product,Department: Other,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:11:00
"Associate Analyst, R Programmer-2",Dynamic Yield,3 - 6 years,Not Disclosed,['Gurugram'],"Our Purpose\nTitle and Summary\nAssociate Analyst, R Programmer-2\nOverview\nThe Mastercard Economics Institute (MEI) is an economics lab powering scale at Mastercard by owning economic thought leadership in support of Mastercard s efforts to build a more inclusive and sustainable digital economy\nThe Economics Institute was launched in 2020 to analyze economic trends through the lens of the consumer to deliver tailored and actionable insights on economic issues for customers, partners and policymakers\nThe Institute is composed of a team of economists and data scientists that utilize & synthesize the anonymized and aggregated data from the Mastercard network together with public data to bring powerful insights to life, in the form of 1:1 presentation, global thought leadership, media participation, and commercial work through the company s product suites\nAbout the Role\nWe are looking for an R programmer to join Mastercard s Economics Institute, reporting to the team lead for Economics Technology. An individual who will:\ncreate clear, compelling data visualisations that communicate economic insights to diverse audiences\ndevelop reusable R functions and packages to support analysis and automation\ncreate and format analytical content using R Markdown and/or Quarto\ndesign and build scalable Shiny apps\ndevelop interactive visualisations using JavaScript charting libraries (e.g. Plotly, Highcharts, D3.js) or front-end frameworks (e.g. React, Angular, Vue.js)work with databases and data platforms (eg. SQL, Hadoop)\nwrite clear, well-documented code that others can understand and maintain\ncollaborate using Git for version control\nAll About You\n\nproficient in R and the RStudio IDE\nproficient in R packages like dplyr for data cleaning, transformation, and aggregation\nfamiliarity with dependency management and documentation in R (e.g. roxygen2)\nfamiliar with version control concepts and tools (e.g. Git, GitHub, Bitbucket) for collaborative development\nexperience writing SQL and working with relational databases\ncreative and passionate about data, coding, and technology\nstrong collaborator who can also work independently organized and able to prioritise work across multiple projects comfortable working with engineers, product owners, data scientists, economists",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Front end', 'Associate Analyst', 'Version control', 'Coding', 'Information security', 'Analytical', 'Manager Technology', 'Corporate security', 'SQL']",2025-06-12 14:11:02
Data Scientist,Acesoft,6 - 9 years,18-20 Lacs P.A.,['Bengaluru'],"Hi all,\nWe are hiring for the role Data Scientist AI ML\nExperience: 6 -9 Years\nLocation: Bangalore\nNotice Period: Immediate - 15 Days\nSkills:\nWe are looking for a Data Scientist to lead data-driven solutions across our business, from exploratory analysis, incremental hypothesis validation, model development, deployment and monitoring.\nSkills Needed:\nStrong knowledge of Applied AI ML & Deep Learning Data Science techniques, Hardcore in ANN /Deep Learning /Machine Learning/NLP\nDeep knowledge about machine learning algorithms such as tree-based methods, clustering, regression and classification, dimension reduction techniques, linear regression, Logistic regression, k-means, time series forecasting, Hypothesis testing (ANOVA, t-test, etc.), random forest, SVMs, Naive Bayes, gradient boosting, kNN, Deep learning algorithms like CNN, ANN and Reinforcement learning, Anomaly detection.\nIn-depth understanding of Statistical concepts e.g. Probability distributions, statistical tests, correlation analysis, descriptive statistics, kernels, ROC, F1-Score etc.\nAdvanced coding experience in at least one programming language (Python, Pyspark) & Strong experience in object-oriented concepts.\nGood to have advanced experience in one or more of the following: Spark, Databricks, Azure technical stack\nGood to have experience in model deployment to cloud/on-prem.\nGood Communication & presentation skills.\n\nIf you are interested drop your resume at mojesh.p@acesoftlabs.com\nCall: 9701971793",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Temporary/Contractual","['AI ML', 'Data Scientist', 'Machine Learning', 'Deep Learning', 'ANN', 'EDA', 'ANOVA', 'Hypothesis Testing', 'Model Building']",2025-06-12 14:11:04
Senior Research Analyst,Demandbase,8 - 10 years,Not Disclosed,['Hyderabad'],"Introduction to Demandbase:\nDemandbase is the Smarter GTM company for B2B brands. We help marketing and sales teams overcome the disruptive data and technology fragmentation that inhibits insight and forces them to spam their prospects. We do this by injecting Account Intelligence into every step of the buyer journey, wherever our clients interact with customers, and by helping them orchestrate every action across systems and channels - through advertising, account-based experience, and sales motions. The result? You spot opportunities earlier, engage with them more intelligently, and close deals faster.\nAs a company, we re as committed to growing careers as we are to building world-class technology. We invest heavily in people, our culture, and the community around us. We have offices in the San Francisco Bay Area, New York, Seattle, and teams in the UK and India . We have also been continuously recognized as one of the best places to work in the San Francisco Bay Area.\nWere committed to attracting, developing, retaining, and promoting a diverse workforce. By ensuring that every Demandbase employee is able to bring a diversity of talents to work, were increasingly capable of living out our mission to transform how B2B goes to market. We encourage people from historically underrepresented backgrounds and all walks of life to apply. Come grow with us at Demandbase!\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented Senior Research Analyst to join our dynamic team. This role is crucial for driving informed business decisions through data gathering, analysis, and insightful reporting. The ideal candidate will possess a strong understanding of business research methodologies, data analysis techniques, and a passion for data accuracy and problem-solving.\nKey Responsibilities:\nLead Comprehensive Data Research and Analysis: Source, collect, research, and analyze data from a variety of business information sources and specialized databases to generate actionable insights.\nDrive Data-Driven Decision-Making: Conduct in-depth strategic analysis to identify trends, anomalies, and root causes, translating complex findings into clear, impactful recommendations for product and business growth.\nEnsure Data Quality and Integrity: Apply strong problem-solving skills to resolve data queries, perform rigorous quality checks, and proactively identify and address data coverage gaps.\nProvide Training and Knowledge Transfer: Mentor and train new team members on industry best practices and advanced data analysis techniques.\nLeverage Domain and Product Expertise: Work closely with data engineers, product teams, and business stakeholders to define and deliver technical roadmaps, ensuring sound solutions and maximizing customer value.\nRequired Skills & Experience:\nBachelor s or Master s degree in Business or Commerce\n8-10 years of relevant work experience\nExpertise in sourcing and extracting data from diverse business information sources\nAdvanced proficiency in Microsoft Excel (e.g., pivot tables, VLOOKUP, complex formulas, data validation, charting) for data manipulation, analysis, and reporting\nSkill in translating complex data into visually compelling narratives for various audiences\nAbility to design and create clear, insightful, and actionable dashboards and reports\nExcellent communication and interpersonal skills\nSelf-organized and self-driven, with strong personal integrity\nStrong understanding and application of data quality principles and best practices\nAbility to perform root cause analysis on large datasets and identify underlying business drivers\nProven ability to train and mentor new team members, sharing best practices and advanced techniques and strong knowledge transfer skills.\nA strong passion for data, continuous learning, and staying updated with industry best practices and emerging analytical techniques.\nStrong organizational and time management skills\nAbility to work independently, manage multiple priorities, and meet deadlines in a fast-paced environment.\nOur Commitment to Diversity, Equity, and Inclusion at Demandbase\nAt Demandbase, we believe in creating a workplace culture that values and celebrates diversity in all its forms. We recognize that everyone brings unique experiences, perspectives, and identities to the table, and we are committed to building a community where everyone feels valued, respected, and supported. Discrimination of any kind is not tolerated, and we strive to ensure that every individual has an equal opportunity to succeed and grow, regardless of their gender identity, sexual orientation, disability, race, ethnicity, background, marital status, genetic information, education level, veteran status, national origin, or any other protected status. We do not automatically disqualify applicants with criminal records and will consider each applicant on a case-by-case basis.\nWe recognize that not all candidates will have every skill or qualification listed in this job description. If you feel you have the level of experience to be successful in the role, we encourage you to apply!\nWe acknowledge that true diversity and inclusion require ongoing effort, and we are committed to doing the work required to make our workplace a safe and equitable space for all. Join us in building a community where we can learn from each other, celebrate our differences, and work together.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAN', 'Data analysis', 'Data validation', 'Excel', 'Data research', 'Business research', 'VLOOKUP', 'Analytical', 'Data quality', 'Senior Research Analyst']",2025-06-12 14:11:06
Data Scientist,Ltimindtree,6 - 11 years,Not Disclosed,['Bengaluru'],"F2F Weekend Drive - Bangalore- 14th June - DS Gen AI\n\nJob description\n\nWe are having a F2F weekend drive for the requirement of a Data Scientist + Gen AI at our LTIM Bangalore Whitefield office.\nDate - 14th June 2025\nExperience - 6+ Years\nMandatory Skills - Data Science, Gen AI, Python, RAG and Azure/AWS, AI/ML, NLPt\n\nLocation - LTIMindtree Bangalore Whitefield Office\n\nSecondary - (Any) Machine Learning, Deep Learning, ChatGPT, Langchain, Prompt, vector stores, RAG, llama, Computer vision, Deep learning, Machine learning, OCR, Transformer, regression, forecasting, classification, hyper parameter tunning, MLOps, Inference, Model training, Model Deployment\nGeneric JD-\nMore than 6 years of experience in Data Engineering, Data Science and AI / ML domain\nExcellent understanding of machine learning techniques and algorithms, such as GPTs, CNN, RNN, k-NN, Naive Bayes, SVM, Decision Forests, etc.\nExperience using business intelligence tools (e.g. Tableau, PowerBI) and data frameworks (e.g. Hadoop)\nExperience in Cloud native skills.\nKnowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset\nAnalytical mind and business acumen and Strong math skills (e.g. statistics, algebra)\nExperience with common data science toolkits, such as TensorFlow, KERAs, PyTorch, PANDAs, Microsoft CNTK, NumPy etc. Deep expertise in at least one of these is highly desirable.\nExperience with NLP, NLG and Large Language Models like BERT, LLaMa, LaMDA, GPT, BLOOM, PaLM, DALL-E, etc.\nGreat communication and presentation skills. Should have experience in working in a fast-paced team culture.\nExperience with AIML and Big Data technologies like AWS SageMaker, Azure Cognitive Services, Google Colab, Jupyter Notebook, Hadoop, PySpark, HIVE, AWS EMR etc.\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase, Vector databases\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression, etc.\nShould be a data-oriented person with analytical mind and business acumen.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-12 14:11:08
Data Scientist,Puresoftware Technology,8 - 13 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Title: Data Scientist(5 Positions)/ Lead OR Manager -Data Scientist (3 positions)\n\nExperience: Data scientist (8-10 years) / Lead Data scientist(14+ years)\n\nJob Location: Whitefield, Bangalore\nMode of working: Hybrid\n\nInterview Process: First Round: L1-Internal interview\nSecond Round: Assessment shared by us needs to be completed in 48 hours\nThird Round: Client discussion over the submitted assessment.\nFinal Round: HR Discussion\n\nPreferred Domain: Healthcare Insurance/ Insurance agencies / Health Insurance / Any Insurance\n\nWe are looking for a talented Data Scientist to join our growing team. In this role, you will lead efforts to develop, enhance, and optimize advanced AI and machine learning models with a particular focus on Generative AI, Large Language Models (LLMs), Langchain, and Prompt Engineering. You will oversee the application of statistical modeling techniques to derive insights, build models, and lead research initiatives that push the boundaries of AI technologies.\n\nKey Responsibilities:\nLeadership & Collaboration: Lead a team of data scientists, researchers, and engineers working on high-impact projects related to generative models, NLP, and statistical modeling. Collaborate with cross-functional teams, including engineering, product management, and research, to deliver AI-powered products and solutions.\nGenerative AI Development: Spearhead the development and deployment of Generative AI models and algorithms to address complex problems in areas like content generation, conversational AI, and creative automation.\nLLM Implementation & Optimization: Develop, fine-tune, and optimize large language models (LLMs) for diverse applications, ensuring they are robust, scalable, and accurate in real-world scenarios.\nLangchain Integration: Design and integrate Langchain for managing and deploying sophisticated language models with a focus on complex workflows, multi-agent systems, and real-time applications.\nPrompt Engineering: Lead prompt engineering efforts to optimize AI models' output quality, improve interactions, and enable more effective natural language understanding across a variety of use cases.\nStatistical Modeling: Utilize advanced statistical techniques to analyze and interpret data, build predictive models, and solve business-critical challenges through data-driven insights.\nResearch & Innovation: Stay ahead of trends in AI and ML, particularly in the fields of NLP, LLMs, and generative models. Drive innovation by exploring cutting-edge techniques and methodologies in the AI space.\nMentorship & Knowledge Sharing: Mentor junior team members and promote a collaborative, learning-oriented environment. Share knowledge and foster an atmosphere of continuous improvement within the data science team.\nPerformance Optimization: Ensure model performance meets or exceeds company and client expectations by identifying areas of improvement, testing new methods, and scaling the systems accordingly.\nEthical AI Development: Advocate for and implement ethical considerations in the development and deployment of AI models, including fairness, transparency, and privacy.\n\nQualifications:\nRequired:\nEducation: Ph.D. or Masters degree in Computer Science, Data Science, Mathematics, Statistics, or related field, or equivalent practical experience.\nExperience:\n8+ years of experience in data science, with at least 2-3 years in a leadership role.\nProven expertise in Generative AI, particularly in areas like content generation, deep learning, and language modeling.\nStrong background in Large Language Models (LLMs) such as GPT, T5, BERT, or similar architectures.\nHands-on experience with Langchain for building NLP workflows, pipelines, and integrating external systems with LLMs.\nHands-on experience of Prompt Engineering, including techniques to refine and optimize outputs for various NLP tasks.\nExpertise in statistical modeling and quantitative analysis, with the ability to apply techniques to solve real-world problems.\n\nPreferred:\nExperience working with transformer models and fine-tuning LLMs for specific tasks.\nExpertise in AI model evaluation and metrics (e.g., BLEU, ROUGE, perplexity).\nBackground in developing AI-driven products from concept to deployment.\nStrong publication record in AI research, particularly in NLP and machine learning.\n\nUsed cases( Any of them)\nAutomated Underwriting.\nCustomer experience enhancement.\nFraud detection.\nPredictive analytics.\nAccelerated claims processing.\nRisk assessment and premium calculation.\nCustomer profiling.\ncustomer segmentation.\nCredit Risk Assessment.\nPersonalised marketing .\nAnti-Money Laundering (AML).\nPersonalized patient care.\nMedical training and simulations.\nMedical Data Analysis.\n\nPlease share your updated resume at renuka.rathi@puresoftware.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'data scientist', 'statistical modelling', 'Predictive Modeling', 'Customer profiling', 'Healthcare Insurance', 'Customer Segmentation', 'Automated Underwriting', 'Insurance Domain', 'Credit Risk Assessment', 'insurance agency', 'Fraud detection', 'Healthcare Domain']",2025-06-12 14:11:11
Data Scientist - Immediate Joiners Only,Reyika,5 - 10 years,Not Disclosed,"['Pune', 'Gurugram', 'Bengaluru']","Role: Data Scientist\nExperience: 5+ years\nLocation: Any - Hybrid (Bangalore, Hyderabad, Pune, Chennai and Gurgaon)\nJob Summary:\nWe're seeking a highly skilled NLP Engineer with expertise in Large Language Models (LLMs) and text summarization to join our team. The ideal candidate will have hands-on experience with Amazon Bedrock, OpenAI, or Hugging Face transformers and a strong background in Python programming. This role involves working with unstructured audio-to-text data, such as call transcripts, and developing innovative solutions using LLMs.\n\nRequirements:\nStrong expertise in NLP, text summarization, semantic search, and LLM APIs.\nPractical experience with Amazon Bedrock, OpenAI, or Hugging Face transformers.\nFamiliar with prompt tuning and few-shot learning.\nPython (pandas, langchain, boto3, NumPy, etc.)\nExperience working with unstructured audio-to-text data (e.g., call transcripts).\n\nKey Responsibilities:\nDesign and Development: Design, develop, and deploy LLM-based solutions for text summarization, semantic search, and other NLP tasks\nLLM APIs: Integrate LLM APIs from Amazon Bedrock, OpenAI, or Hugging Face transformers into existing applications\nPrompt Tuning and Few-Shot Learning: Implement prompt tuning and few-shot learning techniques to improve LLM performance\nUnstructured Audio-to-Text Data: Work with unstructured audio-to-text data, such as call transcripts, to develop accurate and efficient NLP models\nPython Programming: Utilize Python libraries like pandas, LangChain, boto3, and NumPy for data processing and model development.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Large Language Model', 'Natural Language Processing', 'Python']",2025-06-12 14:11:13
Senior Programmer Analyst,Tira Consulting,3 - 5 years,12-15 Lacs P.A.,['Gurugram'],"Role & responsibilities\n• Proficiency in designing and constructing SQL procedures.\n• Advanced knowledge of SQL queries and scripts for data validation.\n• Experience working with Scrum and agile methodologies.\n• Ability to collaborate effectively in a team with members from various backgrounds.\n• Hands-on experience in deploying code frequently across multiple environments.\n• Expertise in developing cloud-native applications using serverless and/or containerized technologies.\n• Capability to work independently with minimal supervision in a fast-paced environment with shifting priorities and tight deadlines. Additionally, the candidate should be able to lead small-scale projects with a team of 3-4 developers.\n• Strong communication skills to interact with stakeholders at different levels in application delivery, QA, and business departments.\n• Proficiency in creating new tables, views, and accessing stored procedures in SQL Server.\n• Continuous awareness of key business systems and upcoming developments.\n• Ability to quickly analyze issues, identify bug trends, log defects accurately, escalate issues, and provide precise management reports.\n• Deliver tasks according to agreed schedules and quality standards.\n• Collaboration with Business Analysts to grasp requirements and implement solutions accordingly.\n• Working closely with the development team, architects, and leads.\n• Willingness to experiment, evaluate, and adopt new technologies.\n• Hands-on experience in unit testing and data analysis.\n• Good understanding of multiple software development methodologies such as Waterfall and Agile.\n\nEssential Skills\nExcellent experience in MS SQL Server and ETL tools.\nUnderstanding of Snaplogic will be preferable.\nMust understand Cloud development (AWS/Azure).\nGood exposure on PowerShell\nExperience in CI/CD, TDD, DevOps, CI/CD tools - Jenkins/SonarQube\nGood Understanding of RDBMS and Data Warehousing concepts.\nProficiency in SQL and SQL programming using Oracle & MSSQL Server\nMust have SQL Tuning experience.\nExperience of Source Control Tools like Subversion/SVN\nWilling to learn and adapt to new opportunities and challenges",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Database Warehouse', 'Azure Cloud', 'Oracle Database', 'Ci/Cd', 'ETL Tool', 'Jenkins', 'Aws Cloud', 'Snaplogic', 'SQL Database', 'SVN', 'Sonarqube', 'Devops']",2025-06-12 14:11:15
Senior Analyst - IO - Investment Reporting Services,M&G plc,2 - 5 years,Not Disclosed,['Mumbai'],"We are M&G Global Services Private Limited (formerly known as 10FA India Private Limited, and prior to that Prudential Global Services Private Limited) . We are a fully owned subsidiary of the M&G plc group of companies, operating as a Global Capability Centre providing a range of value adding services to the Group since 2003. At M&G our purpose is to give everyone real confidence to put their money to work. As an international savings and investments business with roots stretching back more than 170 years, we offer a range of financial products and services through Asset Management, Life and Wealth. All three operating segments work together to deliver attractive financial outcomes for our clients, and superior shareholder returns.\nSupport Sales channels in providing accurate and efficient fund data to clients\nCarrying out appropriate levels of data quality assurance / validation\nEnsuring Daily, Weekly, Monthly and Quarterly reports are distributed to the Client and Custodians.\nExtracting and producing Performance reports using Power BI\nPreparation for distribution of client data files under direction of UK Institutional Client Service team\nInvestigation into issues identified with accuracy of externally presented data\nProvision of data to the relevant team for database maintenance\nSupport Investment Teams with data analysis and data report production\nEnsure own work is completed to a high level of accuracy within service level agreements, to achieve regulatory targets\nMaintain and implement personal development plan in partnership with immediate manager\nIdentify, facilitate and implement process improvement ideas to improve efficiency\nKeep own knowledge up to date in relation to client servicing and data management\nTo demonstrate a positive risk, compliance and control culture through the identification, assessment, monitoring and management of risks and issues within the business area, alongside ensuring timely and appropriate resolution of control weaknesses, actions and failures that arise\nTo achieve and maintain required level of competency as per the training and competency framework.\nWe have a diverse workforce and an inclusive culture at M&G Global Services, regardless of gender, ethnicity, age, sexual orientation, nationality, disability or long term condition, we are looking to attract, promote and retain exceptional people. We also welcome those who take part in military service and those returning from career breaks.",Industry Type: Banking,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Data analysis', 'Manager Quality Assurance', 'Business transformation', 'Data management', 'Process improvement', 'Actuarial', 'Customer service', 'Asset management', 'Monitoring', 'Auditing']",2025-06-12 14:11:18
Senior Analyst - Survey Programming (Healthcare),Omnicom Media Group,3 - 6 years,Not Disclosed,['Gurugram'],"Overview\nShift time - 06:30 PM - 03:30 AM (IST)\nLocation - Gurugram / Mumbai\nHybrid Mode - 3 Days work from office / week\nSkills - Survey programming + Confirmit (survey scripting tools ) + healthcare domain\n About Role - \nThis role requires you to be an active team player for multiple clients and OMC agencies, being responsible for quality delivery of research templates, objectives, and overall solutions. You will get an opportunity to demonstrate your skills and inspire various stakeholders to realize the goals and visions of the Market Research function at Annalect India. \nAbout Us - \nOmnicom Global Solutions is an integral part of Omnicom Group, a leading global marketing and corporate communications company. Omnicom’s branded networks and numerous specialty firms provide advertising, strategic media planning and buying, digital and interactive marketing, direct and promotional marketing, public relations, and other specialty communications services to over 5,000 clients in more than 70 countries.\n Omnicom Global Solutions India plays a key role for our group companies and global agencies by providing stellar products, solutions, and services in the areas of Creative Services, Technology, Marketing Science (Data & Analytics), Advanced Analytics, Market Research, Business Support Services, Media Services, and Project Management.\n We currently have 4000+ awesome colleagues in Omnicom Global Solutions India who are committed to solving our clients’ pressing business issues. We are growing rapidly and looking for talented professionals like you to be part of this journey.\n Let us build this, together!\nResponsibilities\nUnderstand the requirements of projects, design and formulate the questionnaire programming, sampling, and data layouts\nWork with Data Ops teams and project managers to understand and align on post survey analysis objectives\nRecommend a solution design and template suite of survey programming\nCoordinate with field teams\nIntegrate graphics, logos and relevant creatives, banners, or other multimedia assets with the survey\n User testing, quality assurance of functionalities, click through options, radio buttons and other UI features of survey landing pages\nSupport the team in various tasks like ongoing development, Proof of Concept, and troubleshooting the issues faced with maintenance projects \n You will be working closely with\nGlobal clients with a strong presence in Market Research space\nQualifications\n4-6 years’ experience in Market Research Operations in healthcare domain\nExpertise in one or more prominent survey scripting tools like, Confirmit, Qualtrics, Dimensions, Decipher, Askia, CMix\nExperience of working with international clients in multi-cultural environment\nDrive and flexibility to adapt to new platforms\nAbility to exhibit reliable independent decision making\nAbility to receive and act on constructive feedback provided by supervisors\nAbility to work in and adapt to a high-paced environment",Industry Type: Film / Music / Entertainment,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['providing', 'css', 'spss', 'manual testing', 'healthcare domain', 'market research', 'tools', 'research', 'jquery', 'healthcare', 'radio', 'sql', 'scripting', 'operations', 'java', 'survey design', 'html', 'advanced analytics', 'python', 'data analysis', 'software testing', 'javascript', 'excel', 'marketing', 'tableau', 'survey', 'confirmit', 'decipher']",2025-06-12 14:11:20
Big Data Developer/Data Engineer,Grid Dynamics,5 - 10 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\nExperience: 5 - 8 years\nEmployment Type: Full-Time\n\nJob Summary:\nWe are looking for a highly skilled Scala and Spark Developer to join our data engineering team. The ideal candidate will have strong experience in building scalable data processing solutions using Apache Spark and writing robust, high-performance applications in Scala. You will work closely with data scientists, data analysts, and product teams to design, develop, and optimize large-scale data pipelines and ETL workflows.\n\nKey Responsibilities:\nDevelop and maintain scalable data processing pipelines using Apache Spark and Scala.\nWork on batch and real-time data processing using Spark (RDD/DataFrame/Dataset).\nWrite efficient and maintainable code following best practices and coding standards.\nCollaborate with cross-functional teams to understand data requirements and implement solutions.\nOptimize performance of Spark jobs and troubleshoot data-related issues.\nIntegrate data from multiple sources and ensure data quality and consistency.\nParticipate in design reviews, code reviews, and provide technical leadership when needed.\nContribute to data modeling, schema design, and architecture discussions.\nRequired Skills:\nStrong programming skills in Scala.\nExpertise in Apache Spark (Core, SQL, Streaming).\nHands-on experience with distributed computing and large-scale data processing.\nExperience with data formats like Parquet, Avro, ORC, and JSON.\nGood understanding of functional programming concepts.\nFamiliarity with data ingestion tools (Kafka, Flume, Sqoop, etc.).\nExperience working with Hadoop ecosystem (HDFS, Hive, YARN, etc.) is a plus.\nStrong SQL skills and experience working with relational and NoSQL databases.\nExperience with version control tools like Git.\nPreferred Qualifications:\nBachelor's or Masters degree in Computer Science, Engineering, or related field.\nExperience with cloud platforms like AWS, Azure, or GCP (especially EMR, Databricks, etc.).\nKnowledge of containerization (Docker, Kubernetes) is a plus.\nFamiliarity with CI/CD tools and DevOps practices.ndidate profile",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Scala', 'Pyspark', 'Spark']",2025-06-12 14:11:22
Senior Analyst - SAP QM,Solenis,3 - 6 years,Not Disclosed,['Hyderabad'],"Solenis is a leading global provider of water and hygiene solutions. The company s product portfolio includes a broad array of water treatment chemistries, process aids, functional additives, cleaners, disinfectants, and state-of-the-art monitoring, control and delivery systems. These technologies are used by customers to improve operational efficiencies, enhance product quality, protect plant assets, minimize environmental impact, and create cleaner and safer environments. Headquartered in Wilmington, Delaware, the company has 70 manufacturing facilities strategically located around the globe and employs a team of over 16, 500 professionals in 130 countries across six continents. Solenis is a 2025 Best Managed Company Gold Standard honoree. For more information about Solenis, please visit www. solenis. com .",,,,"['Data analysis', 'Analytical', 'Biochemistry', 'Project planning', 'Maintenance Manager', 'Customer service', 'Operations', 'Analytics', 'Monitoring', 'Business operations']",2025-06-12 14:11:25
Data Scientist,Grid Dynamics,10 - 20 years,Not Disclosed,['Hyderabad'],"Role & responsibilitiMes\n\nCandiate needs to be 8+ Years of Experience\n\nDetails on tech stack\nPython\nPrompt engineering\nBest practices for prompt engineering\nHow LLM can be used in applications for a variety of tasks\nNLP\nUnderstanding of typical NLP problems: classification, NER, summarization, question answering, sentiment analysis, etc.\nTheoretical intuitive understanding of how Transformers work (tokenization, attention, etc).\nWord and sentence embeddings\nVector search\nVector databases, performance tuning\nDocument chunking techniques\nLLM applications development\nLangChain, LlamaIndex\nChain of Thoughts, DSP, and other techniques\nAgents and tools\nGoogle cloud (GCP)\nNice to have requirements to the candidate\nPreferable, the engineers are expected to have IT services/consulting experience.\nProficient in developing LLM-powered systems using advanced prompt engineering techniques, RAG and agentic design patterns. Experienced with frameworks like LangChain, LlamaIndex, and DSPy.\nFamiliar with evaluation approaches and metrics for different types of LLM-based systems.\nExperienced with keyword and vector search methods, including understanding of their underlying algorithms. Familiar with popular vector search engines.\nCompetent in various document understanding models and techniques to parse complex documents and implement effective chunking strategies for RAG systems.\nFamiliar with LLM and embedding models fine-tuning techniques.\nCompetent in using joint vision-language and generative models to solve various problems related to image generation, visual question answering, and multi-modal search. Familiar with diffusion models and associated techniques like LoRA, Dreambooth, and ControlNet.\nUnderstanding of the challenges and risks associated with the development of Generative AI systems and how to mitigate them.\nFamiliar with various architecture design patterns for different types of LLM-based applications such as chatbots, text2sql, document understanding, etc. Familiar with various approaches to scalability and cost reduction in Generative AI systems.\nAbility to stay updated with the latest advancements in Generative AI and integrate emerging technologies to drive innovation and improve the performance of AI systems.\nFamiliar with Responsible AI principles and Human-AI interaction design best practices.\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Lora', 'Natural Language Processing', 'Deep Learning', 'Python']",2025-06-12 14:11:26
Hiring Fresher - Back office - MS Excel - Night shift -Mumbai,Trigent Software,0 years,1-2 Lacs P.A.,['Mumbai'],"Hi,\n\nGreetings from Trigent!!!\n\nHiring for fresher with good excel knowledge.\nJob Summary:\nWe are seeking a detail-oriented and analytical professional with strong communication skills and expertise in Microsoft Excel. The ideal candidate will be responsible for handling data analysis, generating reports, and effectively communicating insights.\nKey Responsibilities:\nWork with large data sets to clean, analyze, and present insights.\nPrepare and maintain reports using Excel (pivot tables, VLOOKUP, charts, etc.).\nCommunicate findings effectively with stakeholders.\nCollaborate with teams to optimize processes and improve efficiency.\nAdhere to rotational evening shift schedules as required.\nRequired Skills & Qualifications:\nProficiency in Microsoft Excel (advanced formulas, pivot tables, data visualization).\nStrong verbal and written communication skills.\nAnalytical mindset with attention to detail.\nAbility to work independently and as part of a team.\n\nWork location: Airoli\nOnly Immediate joiners are preferred.\nBoth pick & drop cab facility is provided.\nOnly graduates can apply (Bcom/ BBA/ BBI, BMS, BA).",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['ms excel', 'VLOOKUP', 'MIS Reporting']",2025-06-12 14:11:28
Document Controller,Larsen & Toubro (L&T),0 - 2 years,3.5-4 Lacs P.A.,['Vadodara'],"Technical Expertise\nProficient in Document Management Systems and Engineering Data Warehouses.\nKnowledge of Document Numbering, Receipt Formatting, Filing Structure, and Registration.\nUnderstanding of Tagging Specification and Philosophy.\nExpertise in Document Distribution, including distribution matrices, electronic/hard copies, and transmittals.\nSkilled in Revision Management, Comment Handling, and Status Reporting.\nExperience in Correspondence, Technical Queries, Action Tracking, and Data Management.\nEngineering & Data Interpretation\nAbility to interpret engineering drawings such as P&IDs, PEFS, and PFDs.\nProficient in technical data extraction from:\nMachine drawings\nPEFS (Process Engineering Flow Scheme)\nSeal gas, lube oil, and instrument P&IDs\nVibration & temperature P&IDs\nAlarm/trip matrices, performance curves, and data sheets.\nExperience in Building Asset Registers and Equipment Record Cards.\nComprehensive knowledge of plant equipment and systems.\nIndustry Experience & Technical Tools\nExtensive experience in the Oil & Gas (O&G) industry.\nStrong interpersonal skills for effective communication and collaboration.\nProficient in MS Access and Advanced Excel for data analysis and reporting.",Industry Type: Engineering & Construction,Department: Project & Program Management,"Employment Type: Full Time, Temporary/Contractual","['Document Control', 'Document controller', 'Document Management System', 'Data Control', 'EDMS', 'Aconex', 'Dms', 'Document Management']",2025-06-12 14:11:30
Analyst Programmer,Fidelity International,2 - 4 years,Not Disclosed,"['Gurugram', 'Bengaluru']","We re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our Non-Financial Risk Policy team and feel like you re part of something bigger.\nDepartment Description:\nAMO (ISS) production support consists of applications like Global Fund Data Repository (GFDR), Product hub, Performance Hub, Product (FRD), Reference Data Service, Transaction Service, Position Service, Frontier, Fund Distribution Service etc. architecture and engineering services that comprises of various Fidelity s Business Units in the UK and other parts of Europe, Asia and is a strategic area targeted for growth over the coming years. Various key systems have been acting as the key enablers for the business in achieving their goals. The Enterprise portfolio of projects will include a large collection of strategic initiatives as well as tactical ones to support day-to-day operations and strengthen the environment. The support team aims at supporting & maintaining global data warehouse acting as the single source of data for various line of business s to help them in the MI reporting requirements and data analysis. This source of data is considered as the golden source for distribution data and helps various business groups across organization to take knowledge based decisions.\nPurpose of the Role:\nThe position is for an Application Programmer in AMO production Support team. The role involves supporting key AMO - Enterprise applications and data marts involving strong PL/SQL and stored procedure knowledge on Oracle database platform. The candidate should have high expertise and core skills of Informatica and UNIX shell script. In addition, hands-on experience with Control-M technologies would be a plus. The successful candidate will be responsible to support for consumption of downstream feeds and applications in varied technologies. This would also involve intensive interaction with the business and other systems groups, so good communications skills and the ability to work under pressure are absolute must.\nKey Responsibilities:\nThe candidate is expected to display professional ethics in his/her approach to work and exhibit a high level ownership within a demanding working environment.\nProviding first line of technical support for business critical applications (Principal technologies / applications used include Oracle, UNIX , PaaS, Python, Java and Control-M).\nWork in the support team alongside data analysts, business analysts, database administrators and business project teams in enhancing and supporting the production services.\nHelp maintain Control-M schedules.\nConduct analysis and do bug fixes for production incidents. Carry out technical enhancements as desired.\nCarry out daily health-check activities involving application checks, system checks, and database checks and related on production systems / servers.\nThe scope of responsibility also covers monitoring business critical batch workloads, real-time / interactive processing, data transfer services, application on-boarding and upgrades, and recovery procedures.\nReport root cause of the incidents and present ideas on how to prevent the incidents from occurring in future.\nEnsure adherence to incident and change management processes. Regular engagement with Business & Systems Teams looking to adopt and apply the best practice of Service Support.\nPrepares and maintains documentation related application support like SOM, Service Card, Support Rota, Knowledge base, etc.\nDemonstrates continuous effort to improve operations, decrease turnaround times, streamline work processes, and work cooperatively and jointly to provide quality seamless customer service.\nResponsible for servicing 24x7 support as per support rosters.\nFlexibility to work in shifts ( on-demand & short-term basis), and/or on weekends.\nExperience and Qualifications Required:\nAround 2 - 4 years of technical experience in Software / IT industry in Development and Support functions\nMinimum 2 - 4 years of support experience in Production Support roles\nEssential Technical skills:\nAt least 2-4 years of Oracle experience with strong focus on SQL. PL/SQL knowledge is good to have.\nBasic understanding of PaaS technology, Python, Core Java and web services/ REST API.\nShould have core skills of UNIX shell script.\nEssential behavioural/operational skills:\nAbility to apply new skills / additional information acquired in relation to role.\nAbility to interact with end users/business users.\nAbility to work closely with cross functional teams including Infrastructure teams/Architects/Business Analysts.\nAbility to prioritise own activities, work under hard deadlines.\nTeam player with commitment to achieve team goals.\nMotivated, flexible and with a can do approach.\nKeen to learn and develop proficiency\nGood communication skills both verbal and written.\nDelivery and results focused.\nGood to have technical skills:\nHands-on experience with scheduling tools - Control-M would be a definite plus.\nExperience in informatica is good to have.\nExperience of any source control tool - SVN would be a plus.\nGood Operating Systems knowledge and associated commands (UNIX [Linux/AIX], MS Windows).\nFamiliarity in Data Warehouse, Datamart and ODS concepts.\nKnowledge of essential Software Engineering principles.\nKnowledge of ITIL practices.\nFeel rewarded",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Unix', 'Aix', 'Core Java', 'Linux', 'Production support', 'PLSQL', 'Informatica', 'Oracle', 'Technical support', 'Python']",2025-06-12 14:11:33
Hiring MBA/PGDM graduates For Retail Operations,MALABAR GOLD & DIAMONDS,0 - 5 years,3.75-4.75 Lacs P.A.,"['Ernakulam', 'Kannur', 'Malappuram']","Contact HR:- Anjitha CM\nSenior HR Executive\n8714506916\nMALABAR GROUP HEAD QUARTERS\n\nJob Description\nTo effectively manage the sales, operations, marketing & administration of the Showroom &",,,,"['Communication Skills', 'Presentation Skills', 'Management Skills', 'Interpersonal Skills', 'Team Skills', 'Convincing Power', 'Leadership Skills']",2025-06-12 14:11:35
MIS Executive-Enrollment Department,Medi Assist,0 - 2 years,3.5-5 Lacs P.A.,['Mumbai (All Areas)( Marol )'],"JOB DESCRIPTION\n\nAbility to speak, write and read both English\nGood numerical ability\nDemonstrated proficiency in computer skills.\nMust have expertise in MS Excel, Pivot Table, Vlookup, tabulation, formatting etc.\nKnowledge of Insurance Industry or TPA Background will be a plus.\n\nADMINISTRATIVE\n\nTo ensure TAT is met from receipt of policies till card dispatch through TAT report.\nTo ensure smooth Vendor co-ordination & stock movement to vendor.\nSending required reports to HO\nTo ensure storing of policy documents/data in retrievable manner .\nE-card generation\n\nInterested candidates can share resumes on varsha.kumari@mediassist.in",Industry Type: Insurance,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['advance Excel', 'Pivot Table', 'MIS reporting', 'SUMIF', 'Tabulation', 'VLOOKUP', 'MIS', 'Conditional Formatting', 'Formulas', 'Enrollment', 'HLOOKUP', 'Management Information System']",2025-06-12 14:11:37
Data Scientist,Jsg. Consulting. Pvt.Ltd.,3 - 5 years,9.6-10.8 Lacs P.A.,['Jaipur'],"Familiarity with MDM (Meter Data Management), HES, and utility billing systems.\nExposure to AMI events analysis, load curves, and customer behavior analytics.\nKnowledge of regulatory requirements, data retention, and data .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['billing exceptions', 'load profiling', 'Machine Learning', 'Meter Data Management', 'Smart Metering', 'Hes']",2025-06-12 14:11:39
Senior Data Manager/ Lead,Codeforce 360,6 - 8 years,Not Disclosed,['Hyderabad'],"Job Description:\nWe are looking for a highly experienced and dynamic Senior Data Manager / Lead to oversee a team of Data Engineers and Data Scientists. This role demands a strong background in data platforms such as Snowflake and proficiency in Python, combined with excellent people management and project leadership skills. While hands-on experience in the technologies is beneficial, the primary focus of this role is on team leadership, strategic planning, and project delivery .\n\nJob Title : Senior Data Manager / Lead\nLocation: Hyderabad (Work From Office)\nShift Timing: 10AM-7PM\nKey Responsibilities:\nLead, mentor, and manage a team of Data Engineers and Data Scientists.\nOversee the design and implementation of data pipelines and analytics solutions using Snowflake and Python.\nCollaborate with cross-functional teams (product, business, engineering) to align data solutions with business goals.\nEnsure timely delivery of projects, with high quality and performance.\nConduct performance reviews, training plans, and support career development for the team.\nSet priorities, allocate resources, and manage workloads within the data team.\nDrive adoption of best practices in data management, governance, and documentation.\nEvaluate new tools and technologies relevant to data engineering and data science.\n\nRequired Skills & Qualifications:\n6+ years of experience in data-related roles, with at least 23 years in a leadership or management position.\nStrong understanding of Snowflake architecture, performance tuning, data sharing, security, etc.\nSolid knowledge of Python for data engineering or data science tasks.\nExperience in leading data migration, ETL/ELT, and analytics projects.\nAbility to translate business requirements into technical solutions.\nExcellent leadership, communication, and stakeholder management skills.\nExposure to tools like Databricks, Dataiku, Airflow, or similar platforms is a plus.\nBachelors or Master’s degree in Computer Science, Engineering, Mathematics, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Data Bricks', 'Python', 'Airflow', 'Data Migration', 'Dataiku', 'Data Warehousing', 'ETL', 'ELT', 'SQL']",2025-06-12 14:11:42
"Principal Analyst, Insights",Zeta Global,3 - 4 years,Not Disclosed,['Bengaluru'],"Description: Principal Data Analyst will be responsible for analyzing complex datasets, identifying opportunities for process improvements, and implementing automation solutions to streamline workflows. This role requires a deep understanding of data analytics, process automation tools, and excellent problem-solving skills. The ideal candidate will be proactive, detail-oriented, and able to work collaboratively with cross-functional teams to drive data-driven initiatives.\nWhat you ll do:\nAnalyze large and complex datasets to identify trends, patterns, and insights that drive business decisions.\nDevelop, implement, and maintain automated processes to improve data accuracy, efficiency,and reporting capabilities.\nCollaborate with stakeholders to understand business requirements and translate them into technical solutions.\nDesign and build automated dashboards and reports to provide real-time insights to various departments.\nUtilize data visualization tools to present findings in a clear and actionable manner.\nContinuously monitor and refine automated processes to ensure optimal performance and scalability.\nStay updated with industry trends and best practices in data analytics and process automation.\nMentor and provide guidance to junior data analysts on best practices and technical skills.\nWho you are:\nA great communicator who can convey complex technical features in simple terms.\nAble to multitask and prioritize among several high-profile clients.\nHave a high degree of creativity, self-motivation, and drive.\nEagerness to work in a startup team environment that will be rapidly changing.\nEnthusiastic team player with a penchant for collaboration and knowledge sharing.\nWillingness to do whatever it takes to get the job done.\nNerdy but loveable.\nData driven, technical, self-starting and curious.\nWhat you need:\nBachelor s or Master s degree in data science, Computer Science, Statistics, or a related field.\nMinimum of 3-4 years of experience in data analysis, with a focus on process automation.\nA minimum of 2 years of work experience in analytics (minimum of 1 year with a Ph.D.)\nExperience with data querying languages (e.g. SQL), scripting languages (e.g. Python), and/or statistical/mathematical software (e.g. R) Experience with combining and consolidating disparate datasets in apps such as Big Query, Data Bricks\nProficiency in programming languages such as Python, R, or SQL.\nExtensive experience with data visualization tools such as Tableau, Power BI or similar.\nStrong knowledge of process automation tools and platforms (e.g., Alteryx, UiPath, Microsoft Power Automate).\nExperience with database management systems (e.g., SQL Server, MySQL, PostgreSQL).\nExcellent analytical and problem-solving skills.\nAbility to work effectively in a fast-paced, collaborative environment.\nStrong communication skills, with the ability to convey complex data insights to non-technical stakeholders.\nExperience with machine learning and predictive analytics is a plus.\nBonus if you have:\nMaster s or Ph.D. Degree in a quantitative field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL', 'UiPath', 'R', 'Power BI', 'PostgreSQL', 'MySQL', 'Alteryx', 'Tableau', 'Python']",2025-06-12 14:11:44
Procurement Analyst,Verizon Media Group,2 - 5 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","We are seeking a motivated Procurement Analyst to analyze procurement processes, ensure policy compliance, and drive cost efficiencies. This role requires strong analytical and problem-solving skills, a process improvement mindset, and the ability to collaborate effectively across various teams.\nRelationship Management: Actively build and maintain strong, collaborative relationships with various internal departments (such as Finance, Legal, and Business units) and external suppliers. This includes effective communication, actively listening to stakeholder needs, and proactively resolving issues to ensure smooth collaboration and positive partnerships.\nData Analysis: Analyze detailed procurement data, including spending patterns, supplier performance metrics, and contract terms, to identify trends, anomalies, and cost-saving opportunities. Utilize tools like Excel, data analysis software, and Oracle applications to generate insightful reports and drive data-driven decisions that optimize procurement activities.\nProcess Development and Improvement: Create, review, and continuously improve procurement processes to enhance efficiency, accuracy, and compliance. Document procedures, identify potential bottlenecks or areas for improvement, and implement changes to streamline operations, reduce errors, and ensure best practices are followe'd.\nReporting: Prepare regular and ad-hoc reports on key procurement metrics, such as spending, supplier performance, and key performance indicators (KPIs). Provide clear and concise insights to stakeholders, track progress towards procurement goals, and highlight areas requiring attention or further action.\nCross-Functional Collaboration: Work closely and effectively with cross-functional teams, including Finance, Legal, and Business teams, to align procurement activities with broader organizational objectives. Coordinate efforts, communicate updates, and ensure successful collaboration to achieve shared goals.\nCompliance: Ensure that all procurement activities adhere strictly to company policies, procedures, and relevant regulations. Stay updated on any changes to policies or regulations and implement necessary adjustments to ensure ongoing compliance.\nPurchase Order Management: Manage the creation, modification, and tracking of purchase orders to ensure the timely and accurate procurement of goods and services. This includes monitoring order fulfillment, addressing any discrepancies, and maintaining accurate records.\nIssue Resolution: Handle and resolve any escalations, disputes, or discrepancies that arise within the procurement process. Utilize strong problem-solving skills, attention to detail, and effective communication to find solutions and prevent future issues.\nProject Assistance: Assist with other finance-related projects as needed, providing support, contributing to project tasks, and helping to achieve overall organizational goals and objectives.\nRequired Qualifications:\nbachelors degree in Business Administration, Supply Chain Management, or Finance.\n2+ years of experience in procurement or a related role.\nStrong analytical and problem-solving skills with proficiency in Excel and data analysis tools.\nFamiliarity with procurement software and ERP systems (eg, Oracle).\nExcellent communication and interpersonal skills.\nStrong organizational skills and attention to detail.\nAbility to manage multiple priorities in a fast-paced environment.\nPreferred Qualifications:\nProfessional certifications (CPP, CSCP).\nExperience with supplier performance evaluation and contract management.\nAbility to work various shifts, including early morning and late evening/night shifts.",Industry Type: Internet,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Order management', 'ERP', 'Data analysis', 'General accounting', 'Contract management', 'Process improvement', 'Analytical', 'Oracle', 'Monitoring', 'Auditing']",2025-06-12 14:11:47
Associate- Referral - Decision Science / Data Science,Axtria,3 - 5 years,Not Disclosed,['Gurugram'],"Position Summary \n\nThis Requisition is for the Employee Referral Campaign.\n\nWe are seeking high-energy, driven, and innovative Data Scientists to join our Data Science Practice to develop new, specialized capabilities for Axtria, and to accelerate the company’s growth by supporting our clients’ commercial & clinical strategies.\n\n Job Responsibilities \n\nBe an Individual Contributor tothe Data Science team and solve real-world problems using cutting-edge capabilities and emerging technologies.\n\nHelp clients translate the business use cases they are trying to crack into data science solutions. Provide genuine assistance to users by advising them on how to leverage Dataiku DSS to implement data science projects, from design to production.\n\nData Source Configuration, Maintenance, Document and maintain work-instructions.\n\nDeep working onmachine learning frameworks such as TensorFlow, Caffe, Keras, SparkML\n\nExpert knowledge in Statistical and Probabilistic methods such as SVM, Decision-Trees, Clustering\n\nExpert knowledge of python data-science and math packages such as NumPy , Pandas, Sklearn\n\nProficiency in object-oriented languages (Java and/or Kotlin),Python and common machine learning frameworks(TensorFlow, NLTK, Stanford NLP, Ling Pipe etc\n\n\n Education \n\nBachelor Equivalent - Engineering\nMaster's Equivalent - Engineering\n\n Work Experience \n\nData Scientist 3-5 years of relevant experience in advanced statistical and mathematical models and predictive modeling using Python. Experience in the data science space prior relevant experience in Artificial intelligence and machine Learning algorithms for developing scalable models supervised and unsupervised techniques likeNLP and deep Learning Algorithms. Ability to build scalable models using Python, R-Studio, R Shiny, PySpark, Keras, and TensorFlow. Experience in delivering data science projects leveraging cloud infrastructure. Familiarity with cloud technology such as AWS / Azure and knowledge of AWS tools such as S3, EMR, EC2, Redshift, and Glue; viz tools like Tableau and Power BI. Relevant experience in Feature Engineering, Feature Selection, and Model Validation on Big Data. Knowledge of self-service analytics platforms such as Dataiku/ KNIME/ Alteryx will be an added advantage.\n\nML Ops Engineering 3-5 years of experience with MLOps Frameworks like Kubeflow, MLFlow, Data Robot, Airflow, etc., experience with Docker and Kubernetes, OpenShift. Prior experience in end-to-end automated ecosystems including, but not limited to, building data pipelines, developing & deploying scalable models, orchestration, scheduling, automation, and ML operations. Ability to design and implement cloud solutions and ability to build MLOps pipelines on cloud solutions (AWS, MS Azure, or GCP). Programming languages like Python, Go, Ruby, or Bash, a good understanding of Linux, knowledge of frameworks such as Keras, PyTorch, TensorFlow, etc. Ability to understand tools used by data scientists and experience with software development and test automation. Good understanding of advanced AI/ML algorithms & their applications.\n\nGen AI :Minimum of 4-6 years develop, test, and deploy Python based applications on Azure/AWS platforms.Must have basic knowledge on concepts of Generative AI / LLMs / GPT.Deep understanding of architecture and work experience on Web Technologies.Python, SQL hands-on experience.Expertise in any popular python web frameworks e.g. flask, Django etc. Familiarity with frontend technologies like HTML, JavaScript, REACT.Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT.Can interact with client on GenAI related capabilities and use cases.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'gpm', 'machine learning', 'python data', 'statistics', 'kubernetes', 'microsoft azure', 'numpy', 'javascript', 'sql', 'docker', 'pandas', 'tensorflow', 'java', 'django', 'predictive modeling', 'python web framework', 'mathematical modeling', 'pytorch', 'keras', 'aws', 'flask', 'advanced statistical']",2025-06-12 14:11:49
Manager - Data Science,Axtria,6 - 11 years,Not Disclosed,['Noida'],"Job Summary-\n\nData Scientist with good hands-on experience of 6+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nJob Responsibilities-\n\nHands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\nProficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\nExperience of working in large teams and using collaboration tools like GIT, Jira and Confluence\nGood understanding of any of the cloud platform – AWS, Azure or GCP\nUnderstanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\nShould have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\nShould be able to mentor and guide mid to large sized teams under him/her\n\n\nJob -\nStrong experience on Spark with Scala/Python/Java\nStrong proficiency in building/training/evaluating state of the art machine learning models and its deployment\nProficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\nProficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'keras', 'spark mllib', 'jira', 'sentiment analysis', 'lingpipe', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-12 14:11:52
"Sr. Data Engineer, R&D Data Catalyst Team",Amgen Inc,7 - 9 years,Not Disclosed,['Hyderabad'],"The R&D Data Catalyst Team is responsible for buildingData Searching, Cohort Building, and Knowledge Management tools that provide the Amgen scientific community with visibility to Amgens wealth of human datasets, projects and study histories, and knowledge over various scientific findings. These solutions are pivotal tools in Amgens goal to accelerate the speed of discovery, and speed to market of advanced precision medications.\nThe Data Engineer will be responsible for the end-to-end development of an enterprise analytics and data mastering solution leveraging Databricks and Power BI. This role requiresexpertise in both data architecture and analytics, with the ability to create scalable, reliable, and high-performing enterprise solutions that research cohort-building and advanced research pipeline.The ideal candidate will have experience creating and surfacing large unifiedrepositories of human data, based on integrations from multiple repositories and solutions, and be exceptionally skilled with data analysis and profiling.\nYou will collaborate closely with stakeholders, product team members, and related IT teams, to design and implement data models, integrate data from various sources, and ensure best practices for data governance and security. The ideal candidate will have a strong background in data warehousing, ETL, Databricks, Power BI, and enterprise data mastering.\nRoles & Responsibilities:\nDesign and build scalable enterprise analytics solutions using Databricks, Power BI, and other modern data tools.\nLeverage data virtualization, ETL, and semantic layers to balance need for unification, performance, and data transformation with goal to reduce data proliferation\nBreak down features into work that aligns with the architectural direction runway\nParticipate hands-on in pilots and proofs-of-concept for new patterns\nCreate robust documentation from data analysis and profiling, and proposed designs and data logic\nDevelop advanced sql queries to profile, and unify data\nDevelop data processing code in sql, along with semantic views to prepare data for reporting\nDevelop PowerBI Models and reporting packages\nDesign robust data models, and processing layers, that support both analytical processing and operational reporting needs.\nDesign and develop solutions based on best practices for data governance, security, and compliance within Databricks and Power BI environments.\nEnsure the integration of data systems with other enterprise applications, creating seamless data flows across platforms.\nDevelop and maintain Power BI solutions, ensuring data models and reports are optimized for performance and scalability.\nCollaborate with stakeholders to define data requirements, functional specifications, and project goals.\nContinuously evaluate and adopt new technologies and methodologies to enhance the architecture and performance of data solutions.\nBasic Qualifications and Experience:\nMasters degree with 1 to 3years of experience in Data Engineering OR\nBachelors degree with 4 to 5 years of experience in Data Engineering\nDiploma and 7 to 9 years of experience in Data Engineering.\nFunctional Skills:\nMust-Have Skills:\nMinimum of 3 years of hands-on experience with BI solutions (Preferrable Power BI or Business Objects) including report development, dashboard creation, and optimization.\nMinimum of 3years of hands-on experience building Change-data-capture (CDC) ETL pipelines, data warehouse design and build, and enterprise-level data management.\nHands-on experience with Databricks, including data engineering, optimization, and analytics workloads.\nDeep understanding of Power BI, including model design, DAX, and Power Query.\nProven experience designing and implementing data mastering solutions and data governance frameworks.\nExpertise in cloud platforms (AWS), data lakes, and data warehouses.\nStrong knowledge of ETL processes, data pipelines, and integration technologies.\nStrong communication and collaboration skills to work with cross-functional teams and senior leadership.\nAbility to assess business needs and design solutions that align with organizational goals.\nExceptional hands-on capabilities with data profiling, data transformation, data mastering\nSuccess in mentoring and training team members\nGood-to-Have Skills:\nExperience in developing differentiated and deliverable solutions\nExperience with human data, ideally human healthcare data\nFamiliarity with laboratory testing, patient data from clinical care, HL7, FHIR, and/or clinical trial data management\nProfessional Certifications (please mention if the certification is preferred or mandatory for the role):\nITIL Foundation or other relevant certifications (preferred)\nSAFe Agile Practitioner (6.0)\nMicrosoft Certified: Data Analyst Associate (Power BI) or related certification.\nDatabricks Certified Professional or similar certification.\nSoft Skills:\nExcellent analytical and troubleshooting skills\nDeep intellectual curiosity\nHighest degree of initiative and self-motivation\nStrong verbal and written communication skills, including presentation to varied audiences of complex technical/business topics\nConfidence technical leader\nAbility to work effectively with global, virtual teams, specifically including leveraging of tools and artifacts to assure clear and efficient collaboration across time zones\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong problem solving, analytical skills;\nAbility to learn quickly and retain and synthesize complex information from diverse sources",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'data analysis', 'ETL processes', 'DAX', 'Business Objects', 'data warehouse design', 'ETL', 'PowerBI Models', 'AWS', 'Power Query']",2025-06-12 14:11:54
"Senior data engineer - Python, Pyspark, AWS - 5+ years Gurgaon",One of the largest insurance providers.,5 - 10 years,Not Disclosed,['Gurugram'],"Senior data engineer - Python, Pyspark, AWS - 5+ years Gurgaon\n\nSummary: An excellent opportunity for someone having a minimum of five years of experience with expertise in building data pipelines. A person must have experience in Python, Pyspark and AWS.\n\nLocation- Gurgaon (Hybrid)\n\nYour Future Employer- One of the largest insurance providers.\n\nResponsibilities-\nTo design, develop, and maintain large-scale data pipelines that can handle large datasets from multiple sources.\nReal-time data replication and batch processing of data using distributed computing platforms like Spark, Kafka, etc.\nTo optimize the performance of data processing jobs and ensure system scalability and reliability.\nTo collaborate with DevOps teams to manage infrastructure, including cloud environments like AWS.\nTo collaborate with data scientists, analysts, and business stakeholders to develop tools and platforms that enable advanced analytics and reporting.\n\nRequirements-\nHands-on experience with AWS services such as S3, DMS, Lambda, EMR, Glue, Redshift, RDS (Postgres) Athena, Kinesics, etc.\nExpertise in data modeling and knowledge of modern file and table formats.\nProficiency in programming languages such as Python, PySpark, and SQL/PLSQL for implementing data pipelines and ETL processes.\nExperience data architecting or deploying Cloud/Virtualization solutions (Like Data Lake, EDW, Mart ) in the enterprise.\nCloud/hybrid cloud (preferably AWS) solution for data strategy for Data lake, BI and Analytics.\nWhat is in for you-\nA stimulating working environment with equal employment opportunities.\nGrowing of skills while working with industry leaders and top brands.\nA meritocratic culture with great career progression.\n\nReach us- If you feel that you are the right fit for the role please share your updated CV at randhawa.harmeen@crescendogroup.in\n\nDisclaimer- Crescendo Global specializes in Senior to C-level niche recruitment. We are passionate about empowering job seekers and employers with an engaging memorable job search and leadership hiring experience. Crescendo Global does not discriminate on the basis of race, religion, color, origin, gender, sexual orientation, age, marital status, veteran status, or disability status.",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Pipeline', 'AWS', 'Data Ingestion', 'Data Engineering', 'Data Processing']",2025-06-12 14:11:57
Director - Data Science,Axtria,12 - 17 years,Not Disclosed,['Noida'],"Minimum 12+ years of relevant experience in building software applications in data and analytics field\nEnhance the go-to-market strategy by designing new and relevant solution frameworks to accelerate our clients’ journeys for impacting patient outcomes. Pitch for these opportunities and craft winning proposals to grow the Data Science Practice.\nBuild and lead a team of data scientists and analysts, fostering a collaborative and innovative environment.\nOversee the design and delivery of the models, ensuring projects are completed on time and meet business objectives.\nEngaging in consultative selling with clients to grow/deliver business.\nDevelop and operationalize scalable processes to deliver on large & complex client engagements.\nExtensive hands-on experience with Python, R, or Julia, focusing on data science and generative AI frameworks.\nExpertise in working with generative models such as GPT, DALL-E, Stable Diffusion, Codex, and MidJourney for various applications.\nProficiency in fine-tuning and deploying generative models using libraries like Hugging Face Transformers, Diffusers, or PyTorch Lightning.\nStrong understanding of generative techniques, including GANs, VAEs, diffusion models, and autoregressive models.\nExperience in prompt engineering, zero-shot, and few-shot learning for optimizing generative AI outputs across different use cases.\nExpertise in managing generative AI data pipelines, including preprocessing large-scale multimodal datasets for text, image, or code generation.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['application software', 'python', 'artificial intelligence', 'r', 'julia', 'hive', 'natural language processing', 'neural networks', 'predictive analytics', 'machine learning', 'sql', 'deep learning', 'java', 'data science', 'spark', 'predictive modeling', 'pytorch', 'hadoop', 'statistics']",2025-06-12 14:11:59
Tax Analyst,Illuminz,4 - 7 years,Not Disclosed,['Bengaluru'],"Job Summary\nIllumina is looking for Tax Analyst/Sr Tax Analyst to be part of newly created Tax Center of Excellence in India and reports to Tax Manager in India. This role will be APAC tax compliance focused and primarily responsible in all aspects of data analysis, tax calculation and reconciliation necessary to meet APAC tax filing, tax audit and statutory audit requirements in APAC region. You will support the Tax Manager in fostering seamless collaboration with global/regional Finance and Tax teams, and other business stakeholders to ensure the adherence of tax compliance governance and efficient tax process maintained in the region.\nTasks and Responsibilities:\nJob duties include but not limited to:\nPrepare monthly tax calculation for APAC entities, this includes extracting SAP reports, analyzing and reconciling financial data, and coordinating with finance teams.\nCollation and managing all aspects of information necessary for submission in tax audits, inquiries and notices raised by tax authorities.\nPerform financial data analysis/schedules/reports necessary for internal and external tax reporting for APAC entities\nInvolve in month-end/statutory audit activities, this includes preparing tax provision/deferred tax calculation and reconciliation relating to tax accounts for APAC entities\nIdentify and drive opportunities for process optimization within the tax reporting workflow, which includes collaborating with internal stakeholder to align processes and implementing into the working environment.\nResearch tax regulations to address daily inquiry on TDS/GST/withholding tax/SAC coding\nParticipate in cross-functional projects and tax projects as and when assigned by the Regional Tax Team/Tax Manager\nPreferred Educational Background:\nBachelor s degree or equivalent in Accounting/Finance/Taxation.\nMinimum 4-7 year in accounting with direct and indirect tax from Big 4 or Accounting with taxation experience. APAC region exposure is a plus\nProficiency in Microsoft Office applications especially Microsoft Excel;\nPrior experience in SAP (or equivalent ERP system) is preferred;\nGood organizational skills, highly detailed oriented and ability to work with minimal supervision and independently;\nAbility to work in a dynamic and fast paced environment and a multi-tasker;\nAbility to be flexible and work analytically in a problem-solving environment;\nExcellent communication (written and oral) and interpersonal skills.\n",Industry Type: Pharmaceutical & Life Sciences,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['TDS', 'Data analysis', 'Process optimization', 'SAP', 'Excel', 'Coding', 'Tax reporting', 'Workflow', 'Taxation', 'Auditing']",2025-06-12 14:12:02
Decarbonisation Data Manager,ISS India,8 - 13 years,Not Disclosed,['Chennai'],"Select with space bar to view the full contents of the job information. Decarbonisation Data Manager Job Details | ISS\nWe use cookies to offer you the best possible website experience. Your cookie preferences will be stored in your browser s local storage. This includes cookies necessary for the websites operation. Additionally, you can freely decide and change any time whether you accept cookies or choose to opt out of cookies to improve websites performance, as well as cookies used to display content tailored to your interests. Your experience of the site and the services we are able to offer may be impacted if you do not accept all cookies.\nModify Cookie Preferences\nAccept All Cookies\nSearch by Keyword Search by location (e.g. ZIP code, city) Full Time/ Part Time Select how often (in days) to receive an alert: Select how often (in days) to receive an alert: Decarbonisation Data Manager Published 1 day ago\nAs a global leader in facilities services we connect people and places to make the world work better. Whether directly or indirectly, you ll play a vital role in supporting our placemakers in delivering exceptional workplace experiences for our customers. Together, we make space for people and businesses to thrive.\nLocation: Chennai, India\nLanguage: English\nMain purpose of the position :\nThe Supply Chain Decarbonization Manager will play a key role in shaping and executing ISS s global supply chain sustainability agenda. With ISS committed to reaching net-zero carbon emissions by 2040, this role will be pivotal in translating procurement spend into carbon intelligence. You will lead the design and implementation of carbon transparency strategies, develop a data-driven emissions tracking framework, and engage internal and external stakeholders to drive measurable Scope 3 emission reductions.\nWhat you ll do:\nLead a team of two competent Supply Chain & Procurement decarbonisation data analysts\nLead the global emissions data strategy for Supply Chain & Procurement, including methodology and governance\nManage the mapping and enhancement of carbon emission factors across supplier categories\nOversee data improvement initiatives in procurement systems (e.g. Sievo)\nLead supplier sustainability engagement programme\nSupport ISS s Science-Based Target roadmap by tracking progress and advising on supplier impact\nDrive global decarbonisation agenda across Supply Chain & Procurement in the countries\nWho you ll work with:\nGroup Digital Procurement Your core team, responsible for global procurement transformation and analytics. You ll work closely with them to embed CO tracking into procurement systems and processes.\nGroup Sustainability Teams Lead collaborators on ISS s overarching climate strategy. You ll align carbon tracking initiatives with enterprise-level ESG targets and disclosures (e.g., CSRD, SBTi).\nGroup & Country Procurement Teams Key internal clients whom you will support in localising decarbonisation strategies, identifying high-impact categories, and operationalising carbon insights in supplier decisions.\nExternal Suppliers & Data Providers You will manage regular engagement with suppliers and data sources to ensure accurate emissions data, compliance with ISS sustainability criteria, and continuous improvement.\nTechnology Partners & Platform Owners (e.g. Sievo) You ll collaborate with system stakeholders to design, test, and calibrate platforms for effective CO data capture, analysis, and reporting at scale.\nKey qualifications:\nMaster s degree in Business, IT, Supply Chain Management, Environmental Management or a related field.\n8+ years of experience in supply chain, sustainability, or carbon data management\nStrong knowledge of GHG Protocol, SBTi, CDP, DEFRA, or other reporting standards\nSolid understanding of procurement systems and spend analysis platforms\nProven expertise in Scope 3 emissions tracking\nNice to have: sustainability data modelling, experience with data visualization tools (e.g., Power BI), programming (e.g. Python) and application-building tools (e.g. PowerApps, PowerAutomate)\nPersonal skills you excel:\nStrong problem-solving and analytical thinking to identify actionable carbon insights\nExcellent communication and stakeholder engagement skills\nA strong change management mindset enabling you to show resilience and adapt and change priorities and approach based on market conditions and organizational needs\nAbility to manage complexity and drive clarity in global, cross-functional settings\nAttention to detail and a high level of ownership for data quality and reporting integrity\nAbility to prioritise and drive own and team activities\nWhy ISS\nAt ISS, we are more than just a service provider of cleaning, food, workplace and technical services, we are a partner in our customers success. By creating exceptional service moments and transforming workplaces into spaces where employees feel valued, engaged and productive, we enhance productivity and help our customers to attract talent and grow their businesses. This begins with our own people through training, career development, and a supportive culture empowering them to deliver outstanding service. We know that when our people thrive, they create spaces where our customers employees and businesses thrive too.\nISS is a Place to Be You.\nBe who you are. Become what you want. Be part of something bigger.\nBecome more. Become ISS.\nHow you ll apply\nApply directly via the link on this page by submitting a cover letter, CV and other relevant documents for the position you are applying for.\nWe look forward to receiving your application as soon as possible.\nISS seeks to BE a place of belonging and CREATE places where every person is welcomed, embraced, and valued for exactly who they are. Places where people feel safe, respected, represented, and supported as their authentic selves.\n#LI-Hybrid\nThe Recruitment Process 1. Job search 4. Interview(s) 5. Job offer Browse the ISS Career Site and find your next job Click ""Apply now"" and follow the steps to complete your application Our Recruiting team reviews your application We get to know you better and answer any questions you may have Congratulations! We are excited to offer you a job and look forward to onboarding you soon The Recruitment Process\n1. Job search\nBrowse the ISS Career Site and find your next job\nOur Recruiting team reviews your application\n4. Interview(s)\nWe get to know you better and answer any questions you may have\n5. Job offer\nCongratulations! We are excited to offer you a job and look forward to onboarding you soon\nWhy ISS\nSince our founding in 1901, ISS has been a people-first company. We recognise the power of diversity, inclusion and belonging and celebrate the differences that make us unique. When everyone is free to be themselves, everyone benefits.\nOur people feel safe, respected, represented, and supported as their authentic selves, allowing them to seize opportunities and reach their full potential. We take seriously our obligation to improve lives, make a difference in our communities, and protect our planet - because when we get things right, the world works better. And that is what drives us.\nISS is a Place to Be You.\nBe who you are. Become what you want. Be part of something bigger.\nWhen you visit any website, it may store or retrieve information on your browser, mostly in the form of cookies. Because we respect your right to privacy, you can choose not to allow some types of cookies. However, blocking some types of cookies may impact your experience of the site and the services we are able to offer.\nThese cookies are required to use this website and cant be turned off.\nProvider Description Enabled SAP as service provider\nWe use the following session cookies, which are all required to enable the website to function:\n""route"" is used for session stickiness\n""careerSiteCompanyId"" is used to send the request to the correct data center\n""JSESSIONID"" is placed on the visitors device during the session so the server can identify the visitor\n""Load balancer cookie"" (actual cookie name may vary) prevents a visitor from bouncing from one instance to another\nAdvertising Cookies\nThese cookies serve ads that are relevant to your interests. You may freely choose to accept or decline these cookies at any time. Note that certain functionality that these third parties make available may be impacted if you do not accept these cookies.",Industry Type: Facility Management Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Procurement', 'Change management', 'Supply chain management', 'SAP', 'Data management', 'Web analytics', 'Analytical', 'Continuous improvement', 'Analytics']",2025-06-12 14:12:04
Senior Azure Data Engineer,Cloud Angles Digital Transformation,8 - 12 years,Not Disclosed,['Hyderabad'],"Job Summary:\nWe are seeking a highly skilled Data Engineer with expertise in leveraging Data Lake architecture and the Azure cloud platform to develop, deploy, and optimise data-driven solutions. . You will play a pivotal role in transforming raw data into actionable insights, supporting strategic decision-making across the organisation.\nResponsibilities\nDesign and implement scalable data science solutions using Azure Data Lake, Azure Data Bricks, Azure Data Factory and related Azure services.\nDevelop, train, and deploy machine learning models to address business challenges.\nCollaborate with data engineering teams to optimise data pipelines and ensure seamless data integration within Azure cloud infrastructure.\nConduct exploratory data analysis (EDA) to identify trends, patterns, and insights.\nBuild predictive and prescriptive models to support decision-making processes.\nExpertise in developing end-to-end Machine learning lifecycle utilizing crisp-DM which includes of data collection, cleansing, visualization, preprocessing, model development, model validation and model retraining\nProficient in building and implementing RAG systems that enhance the accuracy and relevance of model outputs by integrating retrieval mechanisms with generative models.\nEnsure data security, compliance, and governance within the Azure cloud ecosystem.\nMonitor and optimise model performance and scalability in production environments.\nPrepare clear and concise documentation for developed models and workflows.\nSkills Required:\nGood experience in using Pyspark, Python, MLops (Optional), ML flow (Optional), Azure Data Lake Storage. Unity Catalog\nWorked and utilized data from various RDBMS like MYSQL, SQL Server, Postgres and NoSQL databases like MongoDB, Cassandra, Redis and graph DB like Neo4j, Grakn.\nProven experience as a Data Engineer with a strong focus on Azure cloud platform and Data Lake architecture.\nProficiency in Python, Pyspark,\nHands-on experience with Azure services such as Azure Data Lake, Azure Synapse Analytics, Azure Machine Learning, Azure Databricks, and Azure Functions.\nStrong knowledge of SQL and experience in querying large datasets from Data Lakes.\nFamiliarity with data engineering tools and frameworks for data ingestion and transformation in Azure.\nExperience with version control systems (e.g., Git) and CI/CD pipelines for machine learning projects.\nExcellent problem-solving skills and the ability to work collaboratively in a team environment.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Azure Data Engineering', 'Azure Databricks', 'Pyspark', 'Azure Data Lake', 'Python']",2025-06-12 14:12:07
Senior Data Engineer - Azure,Blend360 India,6 - 11 years,Not Disclosed,['Hyderabad'],"As a Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\n3+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar field\nMust have experience e",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:12:09
Senior Data Engineer,Amgen Inc,3 - 7 years,Not Disclosed,['Hyderabad'],"What you will do\nRole Description:\nWe are seeking a Senior Data Engineer with expertise in Graph Data technologies to join our data engineering team and contribute to the development of scalable, high-performance data pipelines and advanced data models that power next-generation applications and analytics. This role combines core data engineering skills with specialized knowledge in graph data structures, graph databases, and relationship-centric data modeling, enabling the organization to leverage connected data for deep insights, pattern detection, and advanced analytics use cases. The ideal candidate will have a strong background in data architecture, big data processing, and Graph technologies and will work closely with data scientists, analysts, architects, and business stakeholders to design and deliver graph-based data engineering solutions.\nRoles & Responsibilities:\nDesign, build, and maintain robust data pipelines using Databricks (Spark, Delta Lake, PySpark) for complex graph data processing workflows.\nOwn the implementation of graph-based data models, capturing complex relationships and hierarchies across domains.\nBuild and optimize Graph Databases such as Stardog, Neo4j, Marklogic or similar to support query performance, scalability, and reliability.\nImplement graph query logic using SPARQL, Cypher, Gremlin, or GSQL, depending on platform requirements.\nCollaborate with data architects to integrate graph data with existing data lakes, warehouses, and lakehouse architectures.\nWork closely with data scientists and analysts to enable graph analytics, link analysis, recommendation systems, and fraud detection use cases.\nDevelop metadata-driven pipelines and lineage tracking for graph and relational data processing.\nEnsure data quality, governance, and security standards are met across all graph data initiatives.\nMentor junior engineers and contribute to data engineering best practices, especially around graph-centric patterns and technologies.\nStay up to date with the latest developments in graph technology, graph ML, and network analytics.\nWhat we expect of you\nMust-Have Skills:\nHands-on experience in Databricks, including PySpark, Delta Lake, and notebook-based development.\nHands-on experience with graph database platforms such as Stardog, Neo4j, Marklogic etc.\nStrong understanding of graph theory, graph modeling, and traversal algorithms\nProficiency in workflow orchestration, performance tuning on big data processing\nStrong understanding of AWS services\nAbility to quickly learn, adapt and apply new technologies with strong problem-solving and analytical skills\nExcellent collaboration and communication skills, with experience working with Scaled Agile Framework (SAFe), Agile delivery practices, and DevOps practices.\nGood-to-Have Skills:\nGood to have deep expertise in Biotech & Pharma industries\nExperience in writing APIs to make the data available to the consumers\nExperienced with SQL/NOSQL database, vector database for large language models\nExperienced with data modeling and performance tuning for both OLAP and OLTP databases\nExperienced with software engineering best-practices, including but not limited to version control (Git, Subversion, etc.), CI/CD (Jenkins, Maven etc.), automated unit testing, and Dev Ops\nEducation and Professional Certifications\nMasters degree and 3 to 4 + years of Computer Science, IT or related field experience\nBachelors degree and 5 to 8 + years of Computer Science, IT or related field experience\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\nScaled Agile SAFe certification preferred\nSoft Skills:\nExcellent analytical and troubleshooting skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals.\nAbility to learn quickly, be organized and detail oriented.\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'SPARQL', 'Maven', 'PySpark', 'GSQL', 'Subversion', 'AWS services', 'Stardog', 'Cypher', 'SAFe', 'Jenkins', 'DevOps', 'Git', 'Neo4j', 'Delta Lake', 'Graph Databases', 'Spark', 'Marklogic', 'Gremlin']",2025-06-12 14:12:11
Senior Data Engineer - AWS,Blend360 India,6 - 10 years,Not Disclosed,['Hyderabad'],"We are looking for an experienced Senior Data Engineer with a strong foundation in Python, SQL, and Spark , and hands-on expertise in AWS, Databricks . In this role, you will build and maintain scalable data pipelines and architecture to support analytics, data science, and business intelligence initiatives. You ll work closely with cross-functional teams to drive data reliability, quality, and performance.\nResponsibilities:\nDesign, develop, and optimize scalable data pipelines using Databricks in AWS such as Glue, S3, Lambda, EMR, Databricks notebooks, workflows and jobs.\nBuilding data lake in WS Databricks.\nBuild and maintain robust ETL/ELT workflows using Python and SQL to handle structured and semi-structured data.\nDevelop distributed data processing solutions using Apache Spark or PySpark .\nPartner with data scientists and analysts to provide high-quality, accessible, and well-structured data.\nEnsure data quality, governance, security, and compliance across pipelines and data stores.\nMonitor, troubleshoot, and improve the performance of data systems and pipelines.\nParticipate in code reviews and help establish engineering best practices.\nMentor junior data engineers and support their technical development.\n\n\nRequirements\nBachelors or masters degree in computer science, Engineering, or a related field.\n5+ years of hands-on experience in data engineering , with at lea",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Version control', 'GIT', 'Workflow', 'Data quality', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:12:13
Associate - Founder's Office,Healthkart,0 - 2 years,4-6.5 Lacs P.A.,['Gurugram'],"Get an opportunity to work directly with leadership on high-impact business strategy, financial modeling & data-driven decision-making in the Founder's Office team.\n\nKey Responsibilities:\nData Analysis and Reporting: Gather, consolidate, and analyze financial data from various sources to generate reports, dashboards, and presentations that provide actionable insights to the leadership team. Present findings in a clear and concise manner.\nFinancial Modeling: Develop and maintain financial models to evaluate business performance, scenario planning, and investment opportunities. Ensure accuracy and integrity of the models by incorporating relevant data and updating assumptions as needed.\nForecasting and Budgeting: Collaborate with key stakeholders to develop annual budgets and periodic forecasting processes. Track actual performance against budget and provide insightful analysis on variances.\nCommunication and Collaboration: Communicate financial insights, forecasts, and recommendations effectively to the leadership team, influencing strategic discussions and supporting key business initiatives. Collaborate with cross-functional teams to align financial goals with operational objectives.\n\nRequirements:\nBachelor's degree in Eco (Hons), B.Com (Hons) and Math (Hons) or related fields is preferred\nStrong analytical and problem-solving skills, with a high attention to detail\nAdvanced proficiency in Microsoft Excel and financial modeling\nSolid understanding of financial statements, key financial metrics, and financial analysis techniques\nExcellent written and verbal communication skills, with the ability to present complex data in a clear and concise manner\nProactive and self-motivated individuals who can work both independently and collaboratively.\nAbility to manage multiple priorities and meet deadlines in a fast-paced environment\nPrior experience in financial analysis, forecasting, or strategic planning is preferred\nKnowledge of the sports nutrition or consumer goods industry is a plus.",Industry Type: Internet (E-Commerce),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Financial Analysis', 'Financial Modelling', 'Financial Reporting', 'Financial Strategy', 'Budgeting', 'Forecasting', 'Stakeholder Management']",2025-06-12 14:12:16
Data Scientist,Ltimindtree,7 - 12 years,Not Disclosed,['Hyderabad'],Data Scientist\n\nJob Description\n\nResponsibilities\n\nWork with team members across multiple disciplines to understand the data behind product features user behaviors the security landscape and our goals\nAnalyze data from several large sources then automate solutions using scheduled processes models and alerts\nWork with partners to design and improve metrics that guide our decisions for the product\nDetect patterns associated with fraudulent accounts and anomalous behavior\nSolve scientific problems and create new methods independently\nTranslate requirements and security questions into data insights\nSet up alerting mechanisms so our leadership is always aware of the security posture\n\nQualifications\n\nPostgraduate degree with specialization in machine learning artificial intelligence statistics or related fields or 2 years of equivalent work experience in applied machine learning and analytics\nExperience with SQL Snowflake and NoSQL databases\nProficiency in Python programming\nFamiliarity with statistics modeling and data visualization\n\nExperience\n\nExperience building statistical and machine learning models applying techniques such as regression classification clustering and anomaly detection Time series and Classical ML modeling\nFamiliarity with Snowflake SQL\nFamiliarity with cloud platforms such as AWS\nSome experience to software development or data engineering\nAnalyze business problems or research questions identify relevant data points and extract meaningful insights,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Snowflake Sql', 'AWS']",2025-06-12 14:12:18
MIS Analyst,Credgenics,3 - 5 years,3-4 Lacs P.A.,['New Delhi'],"Requirement:\n1. Ability to work with Data Management & BI platforms.\n2. Good data analytical & problem-solving skills.\n3. Understand and analyze Business requirements\n4. Demonstrate ability to work in a team environment.\n\nMust have skills:\n5. Advance Excel, python,SQL (All Three are mandatory)",,,,['Advanced Excel'],2025-06-12 14:12:20
Full Stack Data Scientist,Vimo Getinsured,2 - 7 years,Not Disclosed,['Gurugram( Sector 61 Gurgaon )'],"About the Role\nAs a Data Science Engineer, you will need strong technical skills in data modeling, machine learning, data engineering, and software development. You will have the ability to conduct literature reviews and critically evaluate research papers to identify applicable techniques. Additionally, you should be able to design and implement efficient and scalable data processing pipelines, perform exploratory data analysis, and collaborate with other teams to integrate data science models into production systems. Passion for conversational AI and a desire to solve some of the most complex problems in the Natural Language Processing space are essential. You will work on highly scalable, stable, and automated deployments, aiming for high performance. Taking on the challenge of building and scaling a truly remarkable AI platform to impact the lives of millions of customers will be part of your responsibilities. Working in a challenging yet enjoyable environment, where learning new things is the norm, you should think of solutions beyond boundaries. You should also drive outcomes with full ownership, deeply believe in customer obsession, and thrive in a fast-paced environment of learning and innovation.\nYou will work in a challenging, consumer-facing problem space, where you can make an immediate impact. You will get to work with the latest technologies, learn to use new tools and get the opportunity to have your say in the final product. Youll work alongside a great team in an open, collaborative environment. We are part of Vimo, a well-funded, stable mid-size company with excellent salaries, medical/dental/vision coverage, and perks. Vimo is an Equal Opportunity Employer.",,,,"['python', 'Langchain', 'Neural Networks', 'LLM', 'Linux', 'Data Structures', 'Natural Language Processing', 'Jupyter Notebook', 'Machine Learning', 'Deep Learning', 'Numpy', 'Data Science', 'pandas', 'Nltk', 'Langgraph', 'Transformers', 'BERT', 'langsmith']",2025-06-12 14:12:22
Technical Specialist - Data Scientist,Fidelity International,8 - 9 years,Not Disclosed,['Gurugram'],"Application Deadline: 21 June 2025\nTitle Senior Analyst- Data Scientist\nDepartment Data Value\nLocation Gurgaon\nReports To Suman Kaur\nLevel 3\nWe re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved this? By working together - and supporting each other - all over the world. So, join our Data Value team and feel like you re part of something bigger.\nAbout your team\nData Value team drives the renewed focus of extracting value from Fidelity s data for business and client insights and working as one voice with the business, technology, and data teams. The team s vision is to create measurable business impact by leveraging technology and utilising the skills to generate valuable insights and streamline engagements. The Data Science function within Data Value supports Fidelity International s Sales, Marketing, Propositions, Risk, Finance, Customer Service and HR teams across the globe. The key objectives of the function are:\nTo develop deep customer insights for our businesses helping them segment and target customers more effectively\nTo develop a fact-based understanding of sales trends and identify actionable sales growth opportunities for each of our sales channels\nTo understand customer preferences in terms of products, service attributes and marketing activity to help refine each of these\nTo help develop new services lines e.g. develop customer analytics for key IFAs, DC Clients, Individual clients etc.\nTo develop market and competitive intelligence in our key markets to help shape our business planning in those markets\nThe function works directly with business heads and other senior stakeholder s stakeholders to identify areas of analytics, define problem statements and develop key insights.\nAbout your role\nYou will be expected to take a leading role in developing the Data Science and Advanced Analytics solutions for our business. This will involve:\nEngaging with the key stakeholders to understand Fidelity s sales, marketing, client services and propositions context\nImplement advanced analytics solutions on On-Premises/Cloud platforms, develop proof-of-concepts and engage with internal and external ecosystem to progress the proof of concepts to production.\nEngaging and collaborating with different other internal teams like Data engineering, DevOps, technology team etc for development of new tools, capabilities, and solutions.\nMaximize Adoption of Cloud Based advanced analytics solutions: Build out sandbox analytics environments using Snowflake, AWS, Adobe, Salesforce.\nAbout you\nKey Responsibilities\nDeveloping and Delivering Data Science solutions for business (40%)\nPartner with internal (FIL teams) & external ecosystem to design and deliver advanced analytics enabled Data Science solutions\nCreate advanced analytics solution on quantitative and text data using Artificial Intelligence, Machine Learning and NLP techniques.\nCreate compelling visualisations that enable the smooth consumption of predictions and insights for customer benefit\n. Stakeholder Management (30%)\nWorks with channel heads/stakeholders and other sponsors understand the business problem and translate it into appropriate analytics solution.\nEngages with key stakeholders for smooth execution, delivery, and implementation of solutions\nAdoption of Cloud enabled Data Science solutions: (20%)\nMaximize Adoption of Cloud Based advanced analytics solution\nBuild out sandbox analytics environments using Snowflake, AWS, Adobe, Salesforce\nDeploy solutions in productions while adhering to best practices involving Model Explainability, MLOps, Feature Stores, Model Management, Responsible AI etc\nCollaboration and Ownership (10%)\nSharing of knowledge, best practices with the team including coaching or training in some of deep learning/machine learning methodologies. Provides mentoring, coaching, and consulting advice and guidance to staff, e.g. analytic methodologies, data recommendations\nTakes complete independent ownership of the projects and the initiatives in the team with the minimal support\nExperience and Qualifications Required\nQualifications:\nEngineer from IIT/Master s in field related to Data Science/Economics/Mathematics (Tie1 Institutions like ISI, Delhi School of Economics)/M.B.A from tier 1 institutions\nMust have Skills & Experience Required:\nOverall, 8+ years of experience in Data Science and Analytics\n5+ years of hands-on experience in - Statistical Modelling /Machine Learning Techniques/Natural Language Processing/Deep Learning\n5+ years of experience in Python/Machine Learning/Deep Learning\nExcellent problem-solving skills\nShould be able to run analytics applications such as Python, SAS and interpret statistical results\nImplementation of models with clear measurable outcomes\nGood to have Skills & Experience Required:\nAbility to engage in discussion with senior stakeholders on defining business problems, designing analyses projects, and articulating analytical insights to stakeholders.\nExperience on SPARK/Hadoop/Big Data Platforms is a plus\nExperience with unstructured data and big data\nExperience with secondary data and knowledge of primary market research is a plus.\nAbility to independently own and manage the projects with minimal support.\nExcellent analytical skills and a strong sense for structure and logic\nAbility to develop, test and validate hypotheses.\nFeel rewarded",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAS', 'Senior Analyst', 'Consulting', 'Machine learning', 'Business planning', 'Competitive intelligence', 'Customer service', 'Adobe', 'Stakeholder management', 'Salesforce']",2025-06-12 14:12:24
Data Scientist,Callaway Digital Technologies,6 - 9 years,Not Disclosed,['Hyderabad'],"JOB OVERVIEW\nThe ideal candidate will be responsible for analyzing and interpreting large data sets related to finance, sales and supply chain operations to optimize business processes, identify opportunities for improvement, and provide strategic insights to support decision-making. The Data Scientist will work closely with cross-functional teams to identify key business questions, design and implement statistical models, and develop innovative data-driven solutions.\nKey Responsibilities:",,,,"['Statistical Modeling', 'Machine Learning', 'Python', 'Data Visualization', 'Azzure', 'R Program', 'SQL']",2025-06-12 14:12:26
Data Scientist,Celebal Technologies,4 - 9 years,20-35 Lacs P.A.,"['Mumbai', 'Navi Mumbai', 'Pune']","Job Summary: We are looking for a highly skilled Data Scientist with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus. Key Responsibilities • Develop, deploy, and maintain time series forecasting models (Prophet, ARIMA, etc.) for demand forecasting and customer behavior modeling. • Design and implement Customer Lifetime Value (CLV) models to drive customer retention and engagement strategies. • Process and analyze large datasets using PySpark or Python (Pandas). • Partner with cross-functional teams to identify business needs and translate them into data science solutions. • Leverage classic ML techniques (classification, regression) and boosting algorithms (e.g., XGBoost, LightGBM) to support broader analytics use cases. • Use Databricks for collaborative development, data pipelines, and model orchestration. • Apply optimization techniques where relevant to improve forecast accuracy and business decision-making. • Present actionable insights and communicate model results effectively to technical and non-technical stakeholders. Required Qualifications • Strong experience in Time Series Forecasting, with hands-on knowledge of Prophet, ARIMA, or equivalent Mandatory. • Proven track record in Demand Forecasting Highly Preferred. • Experience in modeling Customer Lifecycle Value (CLV) or similar customer analytics use cases – Highly Preferred. • Proficiency in Python (Pandas) or PySpark – Mandatory. • Experience with Databricks – Mandatory. • Solid foundation in statistics, predictive modeling, and machine learning",,,,"['Machine Learning', 'Data Bricks', 'Optimization', 'Pricing', 'Time Series', 'Pyspark', 'Arima', 'Classic ML', 'Artificial Intelligence', 'Regression', 'Customer Lifecycle', 'Manufacturing Industry', 'Regression Modeling', 'Forecasting', 'Data Science', 'Xgboost', 'Time Series Analysis', 'Pandas', 'Classical', 'Python', 'Prophet']",2025-06-12 14:12:29
Data Scientist,Apcfss,2 - 6 years,Not Disclosed,"['Vijayawada', 'Guntur', 'Mangalagiri']","Location: Vijayawada, Andhra Pradesh\nExperience: 2 to 6 years\nEmployment Type: Full-Time\n\nJob Opening: Data Scientist\nWe are seeking a data-driven problem solver to join our team as a Data Scientist. You will play a key role in transforming data into actionable insights and building models that support strategic decisions across the organization. Collaborating with cross-functional teams, youll help turn complex data into clear value.\nKey Responsibilities\nAnalyze large and complex datasets to uncover trends, patterns, and insights\nBuild, validate, and deploy predictive and statistical models\nWork closely with engineering and product teams to integrate models into production systems\nCommunicate analytical findings and insights clearly to both technical and non-technical stakeholders\nRequirements\nProficiency in Python or R, and strong command of SQL\nHands-on experience with machine learning and statistical modeling\nStrong analytical and problem-solving skills\nExperience with cloud platforms such as AWS, GCP, or Azure\nNice to Have\nExperience in Natural Language Processing (NLP), deep learning, or time-series forecasting\nPrior work in [industry-specific domain, e.g., fintech, healthcare, e-commerce]",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'GCP', 'Machine Learning', 'AWS', 'Deep Learning', 'SQL']",2025-06-12 14:12:31
Data Scientist,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nThe Data Scientist is responsible for developing and implementing AI-driven solutions to enhance cybersecurity measures within the organization. This role involves leveraging data science techniques to analyze security data, detect threats, and automate security processes. The Data Scientist will work closely with cybersecurity teams to identify data-driven automation opportunities, strengthening the organizations security posture.\nRoles & Responsibilities:\nDevelop analytics to address security concerns, enhancements, and capabilities to improve the organization's security posture.\nCollaborate with Data Engineers to translate security-focused algorithms into effective solutions.\nWork in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\nPerform exploratory and targeted data analyses using descriptive statistics and other methods to identify security patterns and anomalies.\nDesign and implement security-focused analytics pipelines leveraging MLOps practices.\nCollaborate with data engineers on data quality assessment, data cleansing, and the development of security-related data pipelines.\nContribute to data engineering efforts to refine data infrastructure and ensure scalable, efficient security analytics.\nGenerate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\nFunctional Skills:\nBasic Qualifications:\nMasters degree and 1 to 3 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python) OR\nBachelors degree and 3 to 5 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python) OR\nDiploma and 7 to 9 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python)\nPreferred Qualifications:\nExperience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python)\nDemonstrated skill in the use of applied analytics, descriptive statistics, feature extraction and predictive analytics on industrial datasets\nStrong foundation in machine learning algorithms and techniques\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification\nGood-to-Have Skills:\nProficiency in Python and relevant ML libraries (e.g., TensorFlow, PyTorch, Scikit-learn)\nOutstanding analytical and problem-solving skills; Ability to learn quickly; Excellent communication and interpersonal skills\nExperience with data engineering and pipeline development\nExperience in analyzing time-series data for forecasting and trend analysis\nExperience with AWS, Azure, or Google Cloud\nExperience with Databricks platform for data analytics and MLOps\nExperience with Generative AI models (e.g., GPT, DALLE, Stable Diffusion) and their applications in cybersecurity and data analysis\nExperience working in Product team's environment\nExperience working in an Agile environment\nProfessional Certifications:\nAny AWS Developer certification (preferred)\nAny Python and ML certification (preferred)\nAny SAFe Agile certification (preferred)\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'R', 'PyTorch', 'SAS', 'predictive analytics', 'Scikit-learn', 'SPSS', 'machine learning', 'data engineering', 'Python', 'TensorFlow']",2025-06-12 14:12:33
Data Scientist,Celebal Technologies,3 - 6 years,Not Disclosed,"['Navi Mumbai', 'Mumbai (All Areas)']","Job Title: Data Scientists\nLocation: Navi Mumbai\nDuration: Fulltime\nPositions: Multiple\n\nWe are looking for a highly skilled Data Scientists with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus.",,,,"['Demand Forecasting', 'Data Bricks', 'Time Series', 'Pyspark', 'Arima', 'Customer Lifecycle', 'Forecasting', 'Machine Learning', 'Optimization', 'Data Science', 'Xgboost', 'Time Series Analysis', 'Prophet', 'Python']",2025-06-12 14:12:35
Data Scientist,An Indian NBFC,3 - 8 years,Not Disclosed,['Chennai'],"Responsibilities:\nCollect, clean, and analyze large sets of structured and unstructured data to extract meaningful insights and trends\nDevelop and implement advanced machine learning algorithms to solve complex business problems\nSupport moving models to production, by creating high quality code modules that can be seamlessly integrated into existing systems (both on-prem and cloud)\nCommunicate complex findings to both technical and non-technical audiences through effective data visualization and storytelling.\nCollaborate with cross-functional teams to identify data-driven opportunities and translate business requirements into actionable data solutions.\nSupport the development and maintenance of data pipelines and infrastructure\nStay up-to-date with industry trends and advancements in Data Science and Machine Learning technologies.\n\nSkills Required:\nStrong foundation in statistics, and machine learning algorithms\nStrong proficiency in programming languages like Python and SQL.\nExcellent problem-solving and analytical skills.\nAbility to work independently and as part of a team.\nShould have built production models using at least 2 of the ML techniques: Clustering, Regression, Classification\nExperience in Banking & Financial Services is preferred.\nExperience working on cloud platforms (e.g., AWS, GCP) is preferred.\nA passion for data and a curiosity to explore new trends and technologies",Industry Type: NBFC,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Pipeline', 'Data Extraction', 'Model Building', 'Artificial Intelligence', 'Cloud', 'Machine Learning']",2025-06-12 14:12:37
Data Scientist,Celebal Technologies,3 - 6 years,Not Disclosed,"['Mumbai', 'Navi Mumbai']","About Us: Celebal Technologies is a leading Solution Service company that provide Services the field of Data Science, Big Data, Enterprise Cloud & Automation. We are at the forefront of leveraging cuttingedge technologies to drive innovation and enhance our business processes. As part of our commitment to staying ahead in the industry, we are seeking a talented and experienced Data & AI Engineer with strong Azure cloud competencies to join our dynamic team.\n\nJob Summary: We are looking for a highly skilled Data Scientist with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus.\n\nKey Responsibilities\n• Develop, deploy, and maintain time series forecasting models (Prophet, ARIMA, etc.) for demand forecasting and customer behavior modeling.\n• Design and implement Customer Lifetime Value (CLV) models to drive customer retention and engagement strategies.\n• Process and analyze large datasets using PySpark or Python (Pandas).\n• Partner with cross-functional teams to identify business needs and translate them into data science solutions.\n• Leverage classic ML techniques (classification, regression) and boosting algorithms (e.g., XGBoost, LightGBM) to support broader analytics use cases.\n• Use Databricks for collaborative development, data pipelines, and model orchestration.\n• Apply optimization techniques where relevant to improve forecast accuracy and business decision-making.\n• Present actionable insights and communicate model results effectively to technical and non-technical stakeholders.\n\nRequired Qualifications\n• Strong experience in Time Series Forecasting, with hands-on knowledge of Prophet, ARIMA, or equivalent Mandatory.\n• Proven track record in Demand Forecasting Highly Preferred.\n• Experience in modeling Customer Lifecycle Value (CLV) or similar customer analytics use cases Highly Preferred.\n• Proficiency in Python (Pandas) or PySpark Mandatory.\n• Experience with Databricks Mandatory.\n• Solid foundation in statistics, predictive modeling, and machine learning",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning Operations', 'Demand Forecasting', 'Data Bricks', 'Pyspark', 'Large Language Model', 'Time Series', 'Spark', 'Machine Learning', 'Python']",2025-06-12 14:12:39
Data Scientist,Mindpro Technologies,4 - 9 years,5-12 Lacs P.A.,"['Karur', 'Dharwad']","Greetings From Mind Pro Technologies Pvt ltd (www.mindprotech.com)\n\nJob Title : Data Scientist\nWork Location : Karur (Tamil Nadu) or Dharwad (Karnataka )\nNp : 15days or Less\n\n\nJOB DESCRIPTION:\n Must have At least 4+ Years of experience in Python with Data Science.\n Must have worked on at least one Live project.\nExperience in relevant field such as Statistics, Computer Science or Applied Math or Operational Research.\nMust have Masters in (Maths/Statistics or Applied Mathematics/Machine Learning etc.)\nHistory of successfully performing customer implementations\nStrong customer facing skills, and previous consulting experience.\nExperience of handling high frequency streaming data for real time analysis and reporting.\nFamiliarity with - Natural Language Processing, Statistical Analysis (distribution analysis, correlation, variance, deep learning.\nExperience in tools like AWS, IBM Watson is a plus.\nExperience with open source technologies is a must.\nExcellent communication\nAbility to lead & build strong teams\nAbility to work in an ambiguous environment\n\nDesired Skills and Experience\nLanguages/Tools: Python/R.\nApproaches: Machine Learning\nConcepts: Supervised ANN, Bayesian, Gaussian, Vector Quantization, Logistic Model, Statistical, Predictive Modeling, Minimum Message Length, SVM, Random Forest, Ensembles, ANOVA, Decision Trees, Hidden Markov Models\nUnsupervised ANN, ARL, Clustering Hierarchical, Cluster Analysis\nReinforcement\nGen AI, LLM, LSTM, RNN, CNN, KNN\nBig Data (Good to have): Hadoop /Kafka / Storm / Spark streaming\nOS: Linux, Windows 32/64 bits.\n\nNote:  should know supervised and unsupervised learning,   semi-supervised learning, neural networks concepts, and how ML algorithms works with training and testing data. Experience on particular data set to train, test and roll-out for production use\n\nTool sets : Python, R, MATLAB or  any AI frame work, Neural network, Gen AI, LLM\nContact Details:\n\nRecruitment Team\nMindpro Technologies Pvt Ltd (www.mindprotech.com)\n+91-04324-240904 / +91-9600672304",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Gen AI', 'Statistical Modeling', 'LLM', 'Predictive Modeling', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Machine Learning', 'Deep Learning', 'Python']",2025-06-12 14:12:41
Data Scientist,Big Oh Tech,4 - 6 years,Not Disclosed,['Noida'],"Key Responsibilities:\n\nDesign, build, and maintain robust and scalable data pipelines to support analytics and reporting needs.\nManage and optimize data lake architectures, with a focus on Apache Atlas for metadata management, data lineage, and governance.\nIntegrate and curate data from multiple structured and unstructured sources to enable advanced analytics.\nCollaborate with data scientists and business analysts to ensure availability of clean, well-structured data.\nImplement data quality, validation, and monitoring processes across data pipelines.\nDevelop and manage Power BI datasets and data models, supporting dashboard and report creation.\nSupport data cataloging and classification using Apache Atlas for enterprise-wide discoverability and compliance.\nEnsure adherence to data security, privacy, and compliance policies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['advanced analytics', 'metadata', 'Compliance', 'Business Analyst', 'data security', 'power bi', 'Data quality', 'Management', 'Apache', 'Monitoring']",2025-06-12 14:12:43
Senior BUSINESS INTELLIGENCE CONSULTANT II,Lumen Technologies,8 - 12 years,Not Disclosed,['Bengaluru'],"The Senior Business Intelligence Consultant will be a member of the Enterprise Operations Team at Lumen and will be responsible for designing, developing, and deploying interactive and automated reports and dashboards using Power BI, analyzing data to identify trends, and translating business needs into effective data visualizations. He or she will be leading data analysis, developing BI solutions, mentoring junior analysts, and ensuring data quality, ultimately driving data-driven decision-making and business insights.\nRequired skills:\n8 to 12+ years of hands-on experience in PowerBI, writing SQL queries and MSOffice tools like Excel and PowerPoint\nShould have worked closely with stakeholders to understand their business problems and translate them into actionable data requirements\nPossess a strong understanding of data warehousing, data modeling, and BI technologies.\nDevelop and maintain SQL queries and ETL processes to extract, transform, and load data\nProficient in Data Collection from various sources and cleaning and repairing them for accurate and relevant analysis.\nShould be very good at applying statistical methods and data analysis techniques to identify trends, patterns and helpful insights, providing data-driven insights to support business decisions.\nCreating clear, concise and actionable reports and presenting findings and recommendations to stakeholders in a clear and concise manner.\nVery proficient in the usage of PowerBI to create reports and dashboards that effectively communicate findings, identify potential issues and opportunities.\nStrong communication skills and customer focus\nSelf-motivated, detail orientated, highly organized and able to handle a variety of tasks and responsibilities in an efficient manner with a high level of quality\nExperience of working in a Managed Services organization\n\n""We are an equal opportunity employer committed to fair and ethical hiring practices. We do not charge any fees or accept any form of payment from candidates at any stage of the recruitment process. If anyone claims to offer employment opportunities in our company in exchange for money or any other benefit, please treat it as fraudulent and report it immediately.""",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL queries', 'Usage', 'Claims', 'Managed services', 'Data modeling', 'Data collection', 'power bi', 'Data quality', 'Business intelligence', 'Recruitment']",2025-06-12 14:12:46
MDM Data Scientist,Amgen Inc,4 - 9 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nWe are seeking an accomplished and visionary Data Scientist/ GenAIdeveloper to join Amgens Enterprise Data Management team. As part of MDM team, you will be responsible for designing, developing, and deploying Generative AI and ML models to power data-driven decisions across business domains. This role is ideal for an AI practitioner who thrives in a collaborative environment and brings a strategic mindset to applying advanced AI techniques to solve real-world problems.\nTo succeed in this role, the candidate must have strong AI/ML, Data Science, GenAI experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have AI/ML, data science and GenAI experience on technologies like (PySpark/PyTorch, TensorFlow, LLM, Autogen, Hugging FaceVectorDB,Embeddings, RAGsetc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nDevelop enterprise-level GenAI applications using LLM frameworks such as Langchain, Autogen, and Hugging Face.\nDesign and develop intelligent pipelines using PySpark, TensorFlow, and PyTorch within Databricks and AWS environments.\nImplement embedding models andmanage VectorStores for retrieval-augmented generation (RAG) solutions.\nIntegrate and leverage MDM platforms like Informatica and Reltio to supply high-quality structured data to ML systems.\nUtilize SQL and Python for data engineering, data wrangling, and pipeline automation.\nBuild scalable APIs and services to serve GenAI models in production.\nLead cross-functional collaboration with data scientists, engineers, and product teams to scope, design, and deploy AI-powered systems.\nEnsure model governance, version control, and auditability aligned with regulatory and compliance expectations.\nBasic Qualifications and Experience:\nMasters degree with 4 - 6 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 6 - 9 years of experience in Business, Engineering, IT or related field OR\nDiploma with 10 - 12 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n6+ years of experience working in AI/ML or Data Science roles, including designing and implementing GenAI solutions.\nExtensive hands-on experience with LLM frameworks and tools such as Langchain, Autogen, Hugging Face, OpenAI APIs, and embedding models.\nStrong programming background with Python, PySpark, and experience in building scalable solutions using TensorFlow, PyTorch, and SK-Learn.\nProven track record of building and deploying AI/ML applications in cloud environments such as AWS.\nExpertise in developing APIs, automation pipelines, and serving GenAI models using frameworks like Django, FastAPI, and DataBricks.\nSolid experience integrating and managing MDM tools (Informatica/Reltio) and applying data governance best practices.\nGuide the team on development activities and lead the solution discussions\nMust have core technical capabilities in GenAI, Data Science space\nGood-to-Have Skills:\nPrior experience in Data Modeling, ETL development, and data profiling to support AI/ML workflows.\nWorking knowledge of Life Sciences or Pharma industry standards and regulatory considerations.\nProficiency in tools like JIRA and Confluence for Agile delivery and project collaboration.\nFamiliarity with MongoDB, VectorStores, and modern architecture principles for scalable GenAI applications.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nData Science and ML Certification\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'GenAI', 'Langchain', 'PySpark', 'Hugging Face', 'OpenAI API', 'Autogen', 'PyTorch', 'Django', 'MDM', 'FastAPI', 'Data Modeling', 'ETL', 'TensorFlow', 'Python']",2025-06-12 14:12:48
MDM Data Scientist,Amgen Inc,3 - 8 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nWe are seeking an accomplished and visionary Data Scientist/ GenAIdeveloper to join Amgens Enterprise Data Management team. As part of MDM team, you will be responsible for designing, developing, and deploying Generative AI and ML models to power data-driven decisions across business domains. This role is ideal for an AI practitioner who thrives in a collaborative environment and brings a strategic mindset to applying advanced AI techniques to solve real-world problems.To succeed in this role, the candidate must have strong AI/ML, Data Science, GenAI experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have AI/ML, data science and GenAI experience on technologies like (PySpark/PyTorch, TensorFlow, LLM, Autogen, Hugging FaceVectorDB,Embeddings, RAGsetc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nDevelop enterprise-level GenAI applications using LLM frameworks such as Langchain, Autogen, and Hugging Face.\nDesign and develop intelligent pipelines using PySpark, TensorFlow, and PyTorch within Databricks and AWS environments.\nImplement embedding models andmanage VectorStores for retrieval-augmented generation (RAG) solutions.\nIntegrate and leverage MDM platforms like Informatica and Reltio to supply high-quality structured data to ML systems.\nUtilize SQL and Python for data engineering, data wrangling, and pipeline automation.\nBuild scalable APIs and services to serve GenAI models in production.\nLead cross-functional collaboration with data scientists, engineers, and product teams to scope, design, and deploy AI-powered systems.\nEnsure model governance, version control, and auditability aligned with regulatory and compliance expectations.\nBasic Qualifications and Experience:\nMasters degree with 4 - 6 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 6 - 9 years of experience in Business, Engineering, IT or related field OR\nDiploma with 10 - 12 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n6+ years of experience working in AI/ML or Data Science roles, including designing and implementing GenAI solutions.\nExtensive hands-on experience with LLM frameworks and tools such as Langchain, Autogen, Hugging Face, OpenAI APIs, and embedding models.\nStrong programming background with Python, PySpark, and experience in building scalable solutions using TensorFlow, PyTorch, and SK-Learn.\nProven track record of building and deploying AI/ML applications in cloud environments such as AWS.\nExpertise in developing APIs, automation pipelines, and serving GenAI models using frameworks like Django, FastAPI, and DataBricks.\nSolid experience integrating and managing MDM tools (Informatica/Reltio) and applying data governance best practices.\nGuide the team on development activities and lead the solution discussions\nMust have core technical capabilities in GenAI, Data Science space\nGood-to-Have Skills:\nPrior experience in Data Modeling, ETL development, and data profiling to support AI/ML workflows.\nWorking knowledge of Life Sciences or Pharma industry standards and regulatory considerations.\nProficiency in tools like JIRA and Confluence for Agile delivery and project collaboration.\nFamiliarity with MongoDB, VectorStores, and modern architecture principles for scalable GenAI applications.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nData Science and ML Certification\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams\nWe will ensure that individuals with disabilities are provided with reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['MDM', 'GenAI', 'Langchain', 'PySpark', 'VectorStores', 'Hugging Face', 'LLM', 'Data Science', 'DataBricks', 'SK-Learn', 'AI/ML', 'Autogen', 'PyTorch', 'Django', 'OpenAI APIs', 'FastAPI', 'MongoDB', 'Data Modeling', 'PySpark/PyTorch', 'TensorFlow', 'Python']",2025-06-12 14:12:50
Senior Data Engineer : 7+ Years,Jayam Solutions Pvt Ltd - CMMI Level III Company,5 - 9 years,Not Disclosed,['Hyderabad( Madhapur )'],"Job Description:\nPosition: Sr.Data Engineer\nExperience: Minimum 7 years\nLocation: Hyderabad\nJob Summary:\n\nWhat Youll Do\n\nDesign and build efficient, reusable, and reliable data architecture leveraging technologies like Apache Flink, Spark, Beam and Redis to support large-scale, real-time, and batch data processing.\nParticipate in architecture and system design discussions, ensuring alignment with business objectives and technology strategy, and advocating for best practices in distributed data systems.\nIndependently perform hands-on development and coding of data applications and pipelines using Java, Scala, and Python, including unit testing and code reviews.\nMonitor key product and data pipeline metrics, identify root causes of anomalies, and provide actionable insights to senior management on data and business health.\nMaintain and optimize existing datalake infrastructure, lead migrations to lakehouse architectures, and automate deployment of data pipelines and machine learning feature engineering requests.\nAcquire and integrate data from primary and secondary sources, maintaining robust databases and data systems to support operational and exploratory analytics.\nEngage with internal stakeholders (business teams, product owners, data scientists) to define priorities, refine processes, and act as a point of contact for resolving stakeholder issues.\nDrive continuous improvement by establishing and promoting technical standards, enhancing productivity, monitoring, tooling, and adopting industry best practices.\n\nWhat Youll Bring\n\nBachelors degree or higher in Computer Science, Engineering, or a quantitative discipline, or equivalent professional experience demonstrating exceptional ability.\n7+ years of work experience in data engineering and platform engineering, with a proven track record in designing and building scalable data architectures.\nExtensive hands-on experience with modern data stacks, including datalake, lakehouse, streaming data (Flink, Spark), and AWS or equivalent cloud platforms.\nCloud - AWS\nApache Flink/Spark , Redis\nDatabase platform- Databricks.\nProficiency in programming languages such as Java, Scala, and Python(Good to have) for data engineering and pipeline development.\nExpertise in distributed data processing and caching technologies, including Apache Flink, Spark, and Redis.\nExperience with workflow orchestration, automation, and DevOps tools (Kubernetes,git,Terraform, CI/CD).\nAbility to perform under pressure, managing competing demands and tight deadlines while maintaining high-quality deliverables.\nStrong passion and curiosity for data, with a commitment to data-driven decision making and continuous learning.\nExceptional attention to detail and professionalism in report and dashboard creation.\nExcellent team player, able to collaborate across diverse functional groups and communicate complex technical concepts clearly.\nOutstanding verbal and written communication skills to effectively manage and articulate the health and integrity of data and systems to stakeholders.\n\nPlease feel free to contact us: 9440806850\nEmail ID : careers@jayamsolutions.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Apache Flink', 'Redis', 'Spark', 'Python', 'SCALA', 'Ci/Cd', 'Devops', 'AWS']",2025-06-12 14:12:52
Data Scientist IV - Python / LLM,Sadup Soft,6 - 8 years,Not Disclosed,['Hyderabad'],"Must have skills :\n\n- 6+ Years of Experience.\n\n- Statics, SQL, Big query, LLM, AI, Python\n\n- Work experience in the payments, ecommerce, or financial services industry is a plus .\n\nResponsibilities :\n\n- At least 6 years of experience analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions\n\n- Bachelor's/Master's degree in a quantitative field (such as Analytics, Statistics, Mathematics, Economics or Engineering) or equivalent field experience\n\n- Advanced SQL experience, preferable with Big Query analytics (Google Cloud) on Jupyter Notebooks and experience analyzing very large, complex, multi-dimensional data sets.\n\n- Understanding of statistics (e.g hypothesis testing, statistical inference, regression) and experience designing and evaluating complex experiments-\n\n- Ability to solve problems analytically and create actionable recommendations\n\n- Advanced ability to use reporting tools like Tableau and/or Excel to share analysis\n\n- Strong written and verbal communication skills with the ability to translate complex problems into simpler terms, expertise in stitching together findings to convey coherent insights and effectively influence both peers and senior leadership\n\n- Prior work experience in a product analytics space would be highly valued\n\n- A passion for problem-solving and comfort with ambiguity\n\n- Work experience in the payments, ecommerce, or financial services industry is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Data Science', 'BigQuery', 'Data Management', 'Jupyter', 'LLM', 'Statistics']",2025-06-12 14:12:54
Specialist Data Scientist,Atlasrtx,3 - 7 years,Not Disclosed,['Pune'],"So, what s the role all about\n\nNICE provides state-of-the-art enterprise level AI and analytics for all forms of business communications between speech and digital. We are a world class research team developing new algorithms and approaches to help companies with solving critical issues such as identifying their best performing agents, preventing fraud, categorizing customer issues, and determining overall customer satisfaction. If you have interacted with a major contact center in the last decade, it is very likely we have processed your call.\n\nThe research group partners with all areas of NICE s business to scale out the delivery of new technology and AI models to customers around the world that are tailored to their company, industry, and language needs.\n\n\nHow will you make an impact\n\nConduct cutting-edge research and develop advanced NLP algorithms and models.\n\nBuild and fine-tune deep learning and machine learning models, with a focus on large language models.\n\nWork closely with internal stakeholders to define model requirements and ensure alignment with business objectives.\n\nDevelop AI predictive models and perform data and model accuracy analyses.\n\nProduce and present findings, technical concepts, and model recommendations to both technical and non-technical stakeholders.\n\nDevelop and maintain scripts/tools to automate both new model production and updates to existing model packages.\n\nStay abreast of the latest advancements in data science research and contribute to the development of our knowledge base.\n\nCollaborate with developers to design automation and tool improvements for model building.\n\nMaintain documentation of processes and projects across all supported languages and environments.\n\n\nHave you got what it takes\n\nMasters degree in the field of Computer Science, Technology, Engineering, Math, or equivalent practical experience\n\nMinimum of 8 years of data science work experience, including implementing machine learning and NLP models using real-life data.\n\nExperience with Retrieval-Augmented Generation (RAG) pipelines or LLMOps.\n\nAdvanced knowledge of statistics and machine learning algorithms.\n\nProficiency in Python programming and familiarity with R.\n\nExperience with deep learning models and libraries such as PyTorch, TensorFlow, and JAX.\n\nFamiliarity with relational databases and query languages (e. g. , MSSQL) and basic SQL knowledge.\n\nHands-on experience with transformer models (BERT, FlanT5, Llama, etc. ) and GenAI frameworks (HuggingFace, LangChain, Ollama, etc. ).\n\nExperience deploying NLP models in production environments, ensuring scalability and performance using AWS/GCP/Azure\n\nStrong verbal and written communication skills, including effective presentation abilities.\n\nAbility to work independently and as part of a team, demonstrating analytical thinking and problem-solving skills.\n\n\n\nYou will have an advantage if you also have:\n\nExpertise with Big Data technologies (e. g. , PySpark).\n\nBackground in knowledge graphs, graph databases, or GraphRAG architectures.\n\nUnderstanding of multimodal models (text, audio, vision).\n\nExperience in Customer Experience domains.\n\nExperience with package development and technical writing.\n\nFamiliarity with tools like Jira, Confluence, and source control packages and methodology.\n\nKnowledge and interest in foreign languages and linguistics.\n\nExperience working on international, globe-spanning teams and with AWS.\n\nPast participation in a formal research setting.\n\nExperience as part of a software organization.\n\n\n\nWhat s in it for you\n\n\n\nEnjoy NICE-FLEX!\n\n\n\nRequisition ID : 7481\nReporting into : Tech Manager\nRole Type : Individual Contributor\n\nAbout NICE",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Automation', 'Technical writing', 'GCP', 'Analytical', 'Machine learning', 'Flex', 'Analytics', 'SQL', 'Python']",2025-06-12 14:12:57
Financial Data Specialist,Moodys Investors Service,2 - 7 years,Not Disclosed,['Bengaluru'],"Location(s):\nQuay Building 8th Floor, Bagmane Tech Park, Bengaluru, IN\nLine Of Business: RRS(RRS)\nJob Category:\nCredit Analysis & Research\nExperience Level: Experienced Hire\nAt Moodys, we unite the brightest minds to turn today s risks into tomorrow s opportunities. We do this by striving to create an inclusive environment where everyone feels welcome to be who they are-with the freedom to exchange ideas, think innovatively, and listen to each other and customers in meaningful ways.\nIf you are excited about this opportunity but do not meet every single requirement, please apply! You still may be a great fit for this role or other open roles. We are seeking candidates who model our values: invest in every relationship, lead with curiosity, champion diverse perspectives, turn inputs into actions, and uphold trust through integrity.\nSkills and Competencies:\nStrong understanding of fundamental finance and financial statements.\nGood understanding of capital markets.\nStrong organizational skills and attention to detail.\nAbility to work effectively in a collaborative team environment.\nProficient in technical and operational aspects of assigned deliverables.\nExcellent Microsoft Office skills, particularly advanced Microsoft Excel skills.\nFluency in English with advanced written and verbal communication skills; advanced interpersonal skills.\nEducation:\nBachelors/masters in engineering, Finance, Economics, or Business/Accounting.\nExperience Required:\nRelevant experience of 2+ years in credit/financial data analysis and interpretation\nExperience in fundamental finance or accounting or previous experience analyzing financial statements is an advantage\nResponsibilities:\nPerform analysis to support ratings, research, and analytical outreach.\nWork independently on complex deliverables such as loss given default, speculative grade liquidity information, or basic credit estimates.\nApply Moodys Investors Service standards to complex deliverables to produce valuable inputs into the rating and research process, including adjusted data, key indicators, ratios, charts, and graphs.\nPerform complex data intake tasks, including scrubbing and validating data for further use in research and ratings.\nReview and understand financial reports, official statements, and other documents related to issuers performance.\nLiaise with analysts and accounting specialists to understand the application of accounting concepts on a particular entity.\nWork directly with ratings and support analysts to understand data capture requirements, adjustments, and other information needed by the rating team for ratings and research.\nTake initiative to lead projects or process improvements.\nUndertake review of more junior team members work for straightforward tasks.\nAbout the team: Our Fundamental Rating Group team is responsible for performing a range of data, analytical, and research services that contribute to the overall credit analysis function. By joining our team, you will be part of exciting work in enhancing Moodys digital presence and improving customer engagement.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['remediation', 'Data analysis', 'Excel', 'Financial reporting', 'Accounting', 'Analytical', 'Credit analysis', 'Financial statement analysis', 'Customer engagement', 'Operations']",2025-06-12 14:12:59
Provider Data Management (US Healthcare),Careerguideline,1 - 5 years,1-5 Lacs P.A.,['Bengaluru'],Currently we are looking for *Provider Data Management* to join our team!\nBangalore\n\n*Provider Data Management*\n* 2 - 4 years of experience\n* Package is up to 5LPA\n* Work from office\n* US shift timing\n* 2 way cab provided\n* Immediate joiners (15days notice period considerable)\n\n**Requirements for SPE:**\n* 2 to 4 years of Provider Data Management.\n* Any Graduate.\n* Must have all respective documents.\n\n\nInterested candidates Contact HR Nikkitha @ 8655884774/ nikkitha@careeerguideline.com and also refer to the people who are seeking for job,Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Provider Data Management', 'provider data analyst', 'provider data asscociate', 'provider', 'PDM', 'US Healthcare']",2025-06-12 14:13:01
Data Visualization Expert - Manager,_VOIS,7 - 12 years,Not Disclosed,"['Pune', 'Bengaluru']","Data Visualization & UI/UX Designer (PowerBI & Power Solutions)\n\nAbout VOIS\n\nVOIS (Vodafone Intelligent Solutions) is a strategic arm of Vodafone Group Plc, creating value and enhancing quality and efficiency across 28 countries, and operating from 7 locations: Albania, Egypt, Hungary, India, Romania, Spain and the UK.\nOver 29,000 highly skilled individuals are dedicated to being Vodafone Groups partner of choice for talent, technology, and transformation. We deliver the best services across IT, Business Intelligence Services, Customer Operations, Business Operations, HR, Finance, Supply Chain, HR Operations, and many more.\nEstablished in 2006, _VOIS has evolved into a global, multi-functional organisation, a Centre of Excellence for Intelligent Solutions focused on adding value and delivering business outcomes for Vodafone.\n\nVOIS India\nIn 2009, VOIS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 14,500 employees, _VOIS India supports global markets and group functions of Vodafone and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Business), Intelligent Operations, Finance Operations, Supply Chain Operations and HR Operations and more.\n\nLocation: Pune / Bangalore\nWorking Persona: Hybrid\n\nRole Purpose:\nTalented and experienced Data Visualization and UI/UX Expert to join our dynamic team. In this role, you will play a pivotal role in creating compelling, user-friendly data visualizations and ensuring an exceptional user experience across our digital platforms. As a key member of our team, you will collaborate with various stakeholders to translate complex data into visually engaging and informative designs.\n\nKey Responsibilities:\nData Visualization:\no Create interactive and visually appealing data visualizations using tools such as PowerBI,\nPower BI, Power Solutions, or other relevant platforms.o Transform complex data sets into\neasy-to-understand charts, graphs, and dashboards.\no Ensure data accuracy, consistency, and integrity in visualizations.\nUI/UX Design:\no Design and implement user interfaces for web and mobile applications that prioritize user\nexperience and usability.\no Conduct user research, usability testing, and gather feedback to iterate on designs.\no Collaborate with front-end developers to ensure seamless integration of UI/UX designs.\nCollaboration:\no Work closely with cross-functional teams, including data analysts, developers, and product managers, to understand project requirements and objectives.\no Communicate design concepts and rationale effectively to both technical and non-technical stakeholders.\nContinuous Improvement:\no Stay updated with industry trends and best practices in data visualization and UI/UX design.\no Propose and implement improvements to existing visualizations and designs.\n\nQualifications:\nBachelor's degree in Graphic Design, HCI, Computer Science, or related field (Master's\ndegree preferred).\nProven experience in data visualization and UI/UX design, with a strong portfolio\nshowcasing your work.\nProficiency in data visualization tools (e.g., Power BI) and design tools (e.g., Adobe Creative\nSuite, Sketch, Figma).\nStrong understanding of usability principles, user-centered design, and information\narchitecture.\nFamiliarity with HTML, CSS, and JavaScript for UI implementation.\nExcellent communication and collaboration skills.\n\nVOIS Equal Opportunity Employer Commitment\nVOIS is proud to be an Equal Employment Opportunity Employer. We celebrate differences and we welcome and value diverse people and insights. We believe that being authentically human and inclusive powers our employees growth and enables them to create a positive impact on themselves and society. We do not discriminate based on age, colour, gender (including pregnancy, childbirth, or related medical conditions), gender identity, gender expression, national origin, race, religion, sexual orientation, status as an individual with a disability, or other applicable legally protected characteristics.\nAs a result of living and breathing our commitment, our employees have helped us get certified as a Great Place to Work in India for four years running. We have been also highlighted among the Top 5 Best Workplaces for Diversity, Equity, and Inclusion, Top 10 Best Workplaces for Women, Top 25 Best Workplaces in IT & IT-BPM and 14th Overall Best Workplaces in India by the Great Place to Work Institute in 2023. These achievements position us among a select group of trustworthy and high-performing companies which put their employees at the heart of everything they do.\n\nBy joining us, you are part of our commitment. We look forward to welcoming you into our family which represents a variety of cultures, backgrounds, perspectives, and skills!\n\nApply now, and well be in touch!",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Visualization', 'SQL', 'Figma', 'Tableau', 'Qlik', 'Dashboard Development', 'Adobe Creative Suite']",2025-06-12 14:13:04
Snowflake Data Engineer,Tredence,3 - 8 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\n\nDesign, build, and maintain scalable data pipelines using DBT and Airflow.\nDevelop and optimize SQL queries and data models in Snowflake.\nImplement ETL/ELT workflows, ensuring data quality, performance, and reliability.\nWork with Python for data processing, automation, and integration tasks.\nHandle JSON data structures for data ingestion, transformation, and APIs.\nLeverage AWS services (e.g., S3, Lambda, Glue, Redshift) for cloud-based data solutions. Collaborate with data analysts, engineers, and business teams to deliver high-quality data products.",,,,"['Snowflake', 'DBT', 'SQL']",2025-06-12 14:13:07
Immediate Opening For Data Science,Happiest Minds Technologies,8 - 13 years,Not Disclosed,['Bengaluru( Madiwala )'],"Machine Learning, Deep Learning models, Data Science. (Important);-R / python programming (mandatory) ;- Fast API development ;- deployment of models experience ; - any cloud Azure (good to have - for this requirement); - basics of Generative AI , NLP (optional - Good to have)\n\nGIS data, Geospatial data, Google Maps, ArcGIS, Demand pattern analysis\n\n5 to 15 Yrs",,,,"['Data Science', 'Machine Learning', 'Deep Learning', 'Python', 'GenAi', 'Natural Language Processing']",2025-06-12 14:13:09
Data Science Lead,Protiviti India,9 - 14 years,25-40 Lacs P.A.,['Mumbai (All Areas)'],"Role & responsibilities\n8+ year bachelors or master’s degree from reputed University with concentration on finance, economics or other quantitative field such as statistics or engineering.\nManage multiple client engagements in Financial Services locally in India\nActively drive pre-sales, sales activities primarily for FS clients locally in Data Science Domain\nUnderstand client requirements in detail and create technical & commercial proposal\nDrive client conversations specifically for business development activities",,,,"['Data Science', 'Natural Language Processing', 'Presales', 'Machine Learning', 'AWS', 'GCP', 'Cloud Platform', 'Python']",2025-06-12 14:13:11
Data Engineer II - Marketplace (Experimentation Track),Booking Holdings,5 - 10 years,Not Disclosed,['Bengaluru'],"We are looking for a Data Engineer to join our team and help us to improve the platform that supports one of the best experimentation tools in the world.\nYou will work side by side with other data engineers and site reliability engineers to improve the reliability, scalability, maintenance and operations of all the data products that are part of the experimentation tool at Booking.com.\nYour day to day work includes but is not limited to: maintenance and operations of data pipelines and products that handles data at big scale; the development of capabilities for monitoring, alerting, testing and troubleshooting of the data ecosystem of the experiment platform; and the delivery of data products that produce metrics for experimentation at scale. You will collaborate with colleagues in Amsterdam to achieve results the right way. This will include engineering managers, product managers, engineers and data scientists.\nKey Responsibilities and Duties\nTake ownership of multiple data pipelines and products and provide innovative solutions to reduce the operational workload required to maintain them\nRapidly developing next-generation scalable, flexible, and high-performance data pipelines.\nContribute to the development of data platform capabilities such as testing, monitoring, debugging and alerting to improve the development environment of data products\nSolve issues with data and data pipelines, prioritizing based on customer impact.\nEnd-to-end ownership of data quality in complex datasets and data pipelines.\nExperiment with new tools and technologies, driving innovative engineering solutions to meet business requirements regarding performance, scaling, and data quality.\nProvide self-organizing tools that help the analytics community discover data, assess quality, explore usage, and find peers with relevant expertise.\nServe as the main point of contact for technical and business stakeholders regarding data engineering issues, such as pipeline failures and data quality concerns\nRole requirements\nMinimum 5 years of hands-on experience in data engineering as a Data Engineer or as a Software Engineer developing data pipelines and products.\nBachelors degree in Computer Science, Computer or Electrical Engineering, Mathematics, or a related field or 5 years of progressively responsible experience in the specialty as equivalent\nSolid experience in at least one programming language. We use Java and Python\nExperience building production data pipelines in the cloud, setting up data-lakes and server-less solutions\nHands-on experience with schema design and data modeling\nExperience designing systems E2E and knowledge of basic concepts (lb, db, caching, NoSQL, etc)\nKnowledge of Flink, CDC, Kafka, Airflow, Snowflake, DBT or equivalent tools\nPractical experience building data platform capabilities like testing, alerting, monitoring, debugging, security\nExperience working with big data.\nExperience working with teams located in different timezones is a plus\nExperience with experimentation, statistics and A/B testing is a plus",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Airflow', 'Java', 'CDC', 'NoSQL', 'Snowflake', 'DBT', 'Kafka', 'Python']",2025-06-12 14:13:13
Tech. PM - Data Engineering-Data Analytics@ Gurgaon/Blore_Urgent,A global leader in delivering innovative...,5 - 10 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Job Title - Technical Project Manager\n\nLocation - Gurgaon/ Bangalore\n\nNature of Job - Permanent\n\nDepartment - data analytics\n\nWhat you will be doing\n\n\nDemonstrated client servicing and business analytics skills with at least 5 - 9 years of experience as data engineer, BI developer, data analyst, technical project manager, program manager etc.\nTechnical project management- drive BRD, project scope, resource allocation, team\ncoordination, stakeholder communication, UAT, Prod fix, change requests, project governance\nSound knowledge of banking industry (payments, retail operations, fraud etc.)\nStrong ETL experience or experienced Teradata developer\nManaging team of business analysts, BI developers, ETL developers to ensure that projects are completed on time\nResponsible for providing thought leadership and technical advice on business issues\nDesign methodological frameworks and solutions.\n\n\nWhat were looking for\n\n\nBachelors/masters degree in computer science/data science/AI/statistics, Certification in Gen AI. Masters degree Preferred.\nManage multiple projects, at a time, from inception to delivery\nSuperior problem-solving, analytical, and quantitative skills\nEntrepreneurial mindset, coupled with a “can do” attitude\nDemonstrated ability to collaborate with cross-functional, cross-border teams and coach / mentor colleagues.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Technical Project Manager', 'Data Engineering', 'multiple projects', 'Technical project management', 'Data Analytics', 'project scope', 'ETL Pipeline', 'team coordination', 'resource allocation', 'Prod fix', 'drive BRD', 'program manager', 'Big data']",2025-06-12 14:13:16
Anonymized Patient Level Data (APLD),Product & Service,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Description\nFunctional Responsibilities\nDevelop and execute approaches to analyze variety of Healthcare and Life sciences datasets, primarily creating reports on exploratory data analysis and statistical reports\nStrong proficiency with manipulating data with PL-SQL ( ORACLE 11g)\nA high comfort level with data manipulation and extraction of meaningful insights from large data and prior experience of working with IMS Health data assets or Patient level data (APLD) data is a plus.\nExperience with SQL/SAS/WPS is acceptable.\nMinimum 3 to 5 years of experience of working with pharmaceutical databases, including patient level transactional data, Claim analytics is preferred.\nBeing creative in identifying new techniques and processes to streamline and increase efficiency and effectiveness of current work-streams is a plus.\nHigh level of attention to detail and problem solving\nExposure on various Healthcare data sources like SHS, IQVIA, DRG , Labcorp, Flatiron Experion etc\nHave strong experience claims data and worked on various patient level data analytics like Adherence Studites, Line of therapy and Treatment Path analysis.\nExperienced on HEOR studies.\nPreference will be given to applicants with a demonstrated ability to work independently, take initiative, and manage responsibilities on multiple projects simultaneously.\nProfessional requirement\nPost graduate degree in Economics, MBA, Statistics, Mathematics, Operations Research, Quantitative Analysis, or related field\nWell-organized, capable of handling several projects at a time while meeting deadlines\n3-5 years of consolidated work experience in Analytic Industry.\nStrong statistical and quantitative analysis skills. Knowledge of Statistical Analysis for\nAdvanced knowledge of PL/SQL and experience with statistical packages such as R/SAS Strong problem solving skills\nExcellent data interpretation skills. Experience in using charting/reporting\nSkilled in MS-Office, specifically Excel and Powerpoint\nShould have strong knowledge of Healthcare domain OR any specific knowledge on Retail and FMCG/CPG industry will be an added advantage.\nKnowledge on Pharmaceutical Rx claims/ Medical claims will be an added advantage\nIntermediate to advanced proficiency in Excel and VBA\nAutomate data analysis in support of the client offices principals and consultants\nUtilize SAS/WPS/R to create and automate analytical and modeling processes\nPreference will be given to applicants with a demonstrated ability to work independently, take initiative, and manage responsibilities on multiple projects simultaneously",Industry Type: Software Product,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['SAS', 'Apld', 'SQL', 'Python', 'R']",2025-06-12 14:13:18
Data Engineer-Having Stratup-Mid-Size company Exp.@ Bangalore_Urgent,"As a leader in this space, we deliver wo...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Engineer\n\nLocation: Bangalore - Onsite\nExperience: 8 - 15 years\nType: Full-time\n\nRole Overview\n\nWe are seeking an experienced Data Engineer to build and maintain scalable, high-performance data pipelines and infrastructure for our next-generation data platform. The platform ingests and processes real-time and historical data from diverse industrial sources such as airport systems, sensors, cameras, and APIs. You will work closely with AI/ML engineers, data scientists, and DevOps to enable reliable analytics, forecasting, and anomaly detection use cases.\nKey Responsibilities\nDesign and implement real-time (Kafka, Spark/Flink) and batch (Airflow, Spark) pipelines for high-throughput data ingestion, processing, and transformation.\nDevelop data models and manage data lakes and warehouses (Delta Lake, Iceberg, etc) to support both analytical and ML workloads.\nIntegrate data from diverse sources: IoT sensors, databases (SQL/NoSQL), REST APIs, and flat files.\nEnsure pipeline scalability, observability, and data quality through monitoring, alerting, validation, and lineage tracking.\nCollaborate with AI/ML teams to provision clean and ML-ready datasets for training and inference.\nDeploy, optimize, and manage pipelines and data infrastructure across on-premise and hybrid environments.\nParticipate in architectural decisions to ensure resilient, cost-effective, and secure data flows.\nContribute to infrastructure-as-code and automation for data deployment using Terraform, Ansible, or similar tools.\n\n\nQualifications & Required Skills\n\nBachelors or Master’s in Computer Science, Engineering, or related field.\n6+ years in data engineering roles, with at least 2 years handling real-time or streaming pipelines.\nStrong programming skills in Python/Java and SQL.\nExperience with Apache Kafka, Apache Spark, or Apache Flink for real-time and batch processing.\nHands-on with Airflow, dbt, or other orchestration tools.\nFamiliarity with data modeling (OLAP/OLTP), schema evolution, and format handling (Parquet, Avro, ORC).\nExperience with hybrid/on-prem and cloud platforms (AWS/GCP/Azure) deployments.\nProficient in working with data lakes/warehouses like Snowflake, BigQuery, Redshift, or Delta Lake.\nKnowledge of DevOps practices, Docker/Kubernetes, Terraform or Ansible.\nExposure to data observability, data cataloging, and quality tools (e.g., Great Expectations, OpenMetadata).\nGood-to-Have\nExperience with time-series databases (e.g., InfluxDB, TimescaleDB) and sensor data.\nPrior experience in domains such as aviation, manufacturing, or logistics is a plus.\n\nRole & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['aviation', 'Data Modeling', 'Python', 'OLAP', 'Cloud', 'ORC', 'logistics', 'Avro', 'Terraform', 'Snowflake', 'manufacturing', 'AWS', 'Parquet', 'Java', 'Azure', 'BigQuery', 'Data', 'Redshift', 'SQL', 'TimescaleDB', 'GCP', 'InfluxDB', 'dbt', 'Ansible', 'OLTP', 'Kubernetes']",2025-06-12 14:13:20
Data Engineer,Talent Aspire,2 - 7 years,Not Disclosed,"['Chandigarh', 'Bengaluru']","As the Data Engineer, you will play a pivotal role in shaping our data infrastructure and\nexecuting against our strategy. You will ideate alongside engineering, data and our clients to\ndeploy data products with an innovative and meaningful impact to clients. You will design, build, and maintain scalable data pipelines and workflows on AWS. Additionally, your expertise in AI and machine learning will enhance our ability to deliver smarter, more predictive solutions.\n\nKey Responsibilities\nCollaborate with other engineers, customers to brainstorm and develop impactful data\nproducts tailored to our clients.\nLeverage AI and machine learning techniques to integrate intelligent features into our\nofferings.\nDevelop, and optimize end-to-end data pipelines on AWS\nFollow best practices in software architecture and development.\nImplement effective cost management and performance optimization strategies.\nDevelop and maintain systems using Python, SQL, PySpark, and Django for front-end\ndevelopment.\nWork directly with clients and end-users and address their data needs\nUtilize databases and tools including and not limited to, Postgres, Redshift, Airflow, and\nMongoDB to support our data ecosystem.\nLeverage AI frameworks and libraries to integrate advanced analytics into our solutions.\nQualifications\n\nExperience:\nMinimum of 3 years of experience in data engineering, software development, or\nrelated roles.\nProven track record in designing and deploying AWS cloud infrastructure\nsolutions\nAt least 2 years in data analysis and mining techniques to aid in descriptive and\ndiagnostic insights\nExtensive hands-on experience with Postgres, Redshift, Airflow, MongoDB, and\nreal-time data workflows.\n\nTechnical Skills:\nExpertise in Python, SQL, and PySpark\nStrong background in software architecture and scalable development practices.\nTableau, Metabase or similar viz tools experience\nWorking knowledge of AI frameworks and libraries is a plus.\nLeadership & Communication:\nDemonstrates ownership and accountability for delivery with a strong\ncommitment to quality.\nExcellent communication skills with a history of effective client and end-user\nengagement.\nStartup & Fintech Mindset:\nAdaptability and agility to thrive in a fast-paced, early-stage startup environment.\nPassion for fintech innovation and a strong desire to make a meaningful impact\non the future of finance.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'performance optimization strategies', 'PySpark', 'Django', 'cost management', 'AWS', 'AI frameworks', 'Python', 'SQL']",2025-06-12 14:13:22
Data Engineering Manager,NOVARTIS,6 - 8 years,Not Disclosed,['Hyderabad'],"Summary\nWe are seeking a highly skilled and motivated GCP Data Engineering Manager to join our dynamic team. As a Data Engineering manager specializing in Google Cloud Platform (GCP), you will play a crucial role in designing, implementing, and maintaining scalable data pipelines and\nsystems. You will leverage your expertise in Google Big Query, SQL, Python, and analytical skills to drive data-driven decision-making processes and support various business functions.\nAbout the Role\nKey Responsibilities:\nData Pipeline Development: Design, develop, and maintain robust data pipelines using GCP services like Dataflow, Dataproc, ensuring high performance and scalability.\nGoogle Big Query Expertise: Utilize your hands-on experience with Google Big Query to manage and optimize data storage, retrieval, and processing.\nSQL Proficiency: Write and optimize complex SQL queries to transform and analyze large datasets, ensuring data accuracy and integrity.\nPython Programming: Develop and maintain Python scripts for data processing, automation, and integration with other systems and tools.\nData Integration: Collaborate with data analysts, and other stakeholders to integrate data from various sources, ensuring seamless data flow and consistency.\nData Quality and Governance: Implement data quality checks, validation processes, and governance frameworks to maintain high data standards.\nPerformance Tuning: Monitor and optimize the performance of data pipelines, queries, and storage solutions to ensure efficient data processing.\nDocumentation: Create comprehensive documentation for data pipelines, processes, and best practices to facilitate knowledge sharing and team collaboration.\nMinimum Qualifications:\nProven experience (minimum 6 - 8 yrs) in Data Engineer, with significant hands-on experience in Google Cloud Platform (GCP) and Google Big Query.\nProficiency in SQL for data transformation, analysis and performance optimization.\nStrong programming skills in Python, with experience in developing data processing scripts and automation.\nProven analytical skills with the ability to interpret complex data and provide actionable insights.\nExcellent problem-solving abilities and attention to detail.\nStrong communication and collaboration skills, with the ability to work effectively in a team enviro\nDesired Skills :\nExperience with Google Analytics data and understanding of digital marketing data.\nFamiliarity with other GCP services such as Cloud Storage, Dataflow, Pub/Sub, and Dataproc.\nKnowledge of data visualization tools such as Looker, Tableau, or Data Studio.\nExperience with machine learning frameworks and libraries.\nWhy Novartis: Helping people with disease and their families takes more than innovative science. It takes a community of smart, passionate people like you. Collaborating, supporting and inspiring each other. Combining to achieve breakthroughs that change patients lives. Ready to create a brighter future together? https://www. novartis. com / about / strategy / people-and-culture\nJoin our Novartis Network: Not the right Novartis role for you? Sign up to our talent community to stay connected and learn about suitable career opportunities as soon as they come up: https://talentnetwork. novartis. com/network\nBenefits and Rewards: Read our handbook to learn about all the ways we ll help you thrive personally and professionally:",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Performance tuning', 'Automation', 'Google Analytics', 'Machine learning', 'Data processing', 'Data quality', 'data visualization', 'Digital marketing', 'SQL', 'Python']",2025-06-12 14:13:24
Data Engineer - Databricks,Inorg,2 - 5 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']",InOrg Global is looking for Data Engineer - Databricks to join our dynamic team and embark on a rewarding career journey.\n\nLiaising with coworkers and clients to elucidate the requirements for each task.\nConceptualizing and generating infrastructure that allows big data to be accessed and analyzed.\nReformulating existing frameworks to optimize their functioning.\nTesting such structures to ensure that they are fit for use.\nPreparing raw data for manipulation by data scientists.\nDetecting and correcting errors in your work.\nEnsuring that your work remains backed up and readily accessible to relevant coworkers.\nRemaining up - to - date with industry standards and technological advancements that will improve the quality of your outputs.,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent",['Data Engineer - Databricks'],2025-06-12 14:13:26
Senior Data Engineer,Conviction HR,8 - 10 years,Not Disclosed,"['Kolkata', 'Hyderabad', 'Pune( Malad )']","Must have -Azure Data Factory (Mandatory). Azure Databricks, Pyspark and Python and advance SQL Azure eco-system. 1) Advanced SQL Skills. 2)Data Analysis. 3) Data Models. 4) Python (Desired). 5) Automation - Experience required : 8 to 10 years.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Data Engineering', 'Python', 'Azure Databricks', 'Data Modeling', 'Data Bricks', 'SQL']",2025-06-12 14:13:28
GCP Data Engineer,Swits Digital,4 - 6 years,Not Disclosed,['Bengaluru'],"Job Title: GCP Data Engineer\nLocation: Chennai, Bangalore, Hyderabad\nExperience: 4-6 Years\nJob Summary:\nWe are seeking a GCP Data & Cloud Engineer with strong expertise in Google Cloud Platform services, including BigQuery, Cloud Run, Cloud Storage , and Pub/Sub . The ideal candidate will have deep experience in SQL coding , data pipeline development, and deploying cloud-native solutions.\nKey Responsibilities:\nDesign, implement, and optimize scalable data pipelines and services using GCP\nBuild and manage cloud-native applications deployed via Cloud Run\nDevelop complex and performance-optimized SQL queries for analytics and data transformation\nManage and automate data storage, retrieval, and archival using Cloud Storage\nImplement event-driven architectures using Google Pub/Sub\nWork with large datasets in BigQuery , including ETL/ELT design and query optimization\nEnsure security, monitoring, and compliance of cloud-based systems\nCollaborate with data analysts, engineers, and product teams to deliver end-to-end cloud solutions\nRequired Skills & Experience:\n4 years of experience working with Google Cloud Platform (GCP)\nStrong proficiency in SQL coding , query tuning, and handling complex data transformations\nHands-on experience with:\nBigQuery\nCloud Run\nCloud Storage\nPub/Sub\nUnderstanding of data pipeline and ETL/ELT workflows in cloud environments\nFamiliarity with containerized services and CI/CD pipelines\nExperience in scripting languages (e.g., Python, Shell) is a plus\nStrong analytical and problem-solving skills",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SUB', 'query optimization', 'GCP', 'Analytical', 'Cloud', 'query', 'cloud storage', 'Analytics', 'SQL coding', 'Python']",2025-06-12 14:13:31
Gcp Data Engineer,Saama Technologies,3 - 8 years,Not Disclosed,"['Pune', 'Chennai', 'Coimbatore']","We are looking for immediate joiners only.\nPosition: GCP Data Engineer\nWe are seeking a skilled and experienced GCP Data Engineer to join our dynamic team. The ideal candidate will have a strong background in Google Cloud Platform (GCP), BigQuery, Dataform, and data warehouse concepts. Experience with Airflow/Cloud Composer and cloud computing knowledge will be a significant advantage.\nResponsibilities:\n- Designing, developing, and maintaining data pipelines and workflows on the Google Cloud Platform.",,,,"['Pyspark', 'GCP', 'Python', 'SQL', 'Google Cloud Platforms']",2025-06-12 14:13:33
Azure Data Engineer ( Azure Databricks),Apex One,4 - 8 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Job Summary\nWe are seeking a skilled Azure Data Engineer with 4 years of overall experience, including at least 2 years of hands-on experience with Azure Databricks (Must). The ideal candidate will have strong expertise in building and maintaining scalable data pipelines and working across cloud-based data platforms.\nKey Responsibilities\nDesign, develop, and optimize large-scale data pipelines using Azure Data Factory, Azure Databricks, and Azure Synapse.\nImplement data lake solutions and work with structured and unstructured datasets in Azure Data Lake Storage (ADLS).\nCollaborate with data scientists, analysts, and engineering teams to design and deliver end-to-end data solutions.\nDevelop ETL/ELT processes and integrate data from multiple sources.\nMonitor, debug, and optimize workflows for performance and cost-efficiency.\nEnsure data governance, quality, and security best practices are maintained.\nMust-Have Skills\n4+ years of total experience in data engineering.\n2+ years of experience with Azure Databricks (PySpark, Notebooks, Delta Lake).\nStrong experience with Azure Data Factory, Azure SQL, and ADLS.\nProficient in writing SQL queries and Python/Scala scripting.\nUnderstanding of CI/CD pipelines and version control systems (e.g., Git).\nSolid grasp of data modeling and warehousing concepts.",Industry Type: Management Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure', 'Azure Data Factory', 'SQL queries', 'PySpark', 'Delta Lake', 'Azure Databricks', 'Notebooks', 'Azure SQL']",2025-06-12 14:13:36
Data Engineer with Neo4j,Luxoft,3 - 5 years,Not Disclosed,['Gurugram'],"Graph Data Modeling & Implementation.\nDesign and implement complex graph data models using Cypher and Neo4j best practices.\nLeverage APOC procedures, custom plugins, and advanced graph algorithms to solve domain-specific problems.\nOversee integration of Neo4j with other enterprise systems, microservices, and data platforms.\nDevelop and maintain APIs and services in Java, Python, or JavaScript to interact with the graph database.\nMentor junior developers and review code to maintain high-quality standards.\nEstablish guidelines for performance tuning, scalability, security, and disaster recovery in Neo4j environments.\nWork with data scientists, analysts, and business stakeholders to translate complex requirements into graph-based solutions.\nSkills\nMust have\n12+ years in software/data engineering, with at least 3-5 years hands-on experience with Neo4j.\nLead the technical strategy, architecture, and delivery of Neo4j-based solutions.\nDesign, model, and implement complex graph data structures using Cypher and Neo4j best practices.\nGuide the integration of Neo4j with other data platforms and microservices.\nCollaborate with cross-functional teams to understand business needs and translate them into graph-based models.\nMentor junior developers and ensure code quality through reviews and best practices.\nDefine and enforce performance tuning, security standards, and disaster recovery strategies for Neo4j.\nStay up-to-date with emerging technologies in the graph database and data engineering space.\nStrong proficiency in Cypher query language, graph modeling, and data visualization tools (e.g., Bloom, Neo4j Browser).\nSolid background in Java, Python, or JavaScript and experience integrating Neo4j with these languages.\nExperience with APOC procedures, Neo4j plugins, and query optimization.\nFamiliarity with cloud platforms (AWS) and containerization tools (Docker, Kubernetes).\nProven experience leading engineering teams or projects.\nExcellent problem-solving and communication skills.\nNice to have\nN/A\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Flexera Data Analyst\nData Science\nIndia\nBengaluru\nSenior Flexera Data Analyst\nData Science\nIndia\nChennai\nData Scientist\nData Science\nIndia\nBengaluru\nGurugram, India\nReq. VR-114556\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114556\nApply for Data Engineer with Neo4j in Gurugram\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'query optimization', 'neo4j', 'data science', 'Data modeling', 'Disaster recovery', 'Javascript', 'Data structures', 'data visualization', 'Python']",2025-06-12 14:13:38
Data Engineer with Neo4j,Luxoft,3 - 5 years,Not Disclosed,['Bengaluru'],"Graph Data Modeling & Implementation.\nDesign and implement complex graph data models using Cypher and Neo4j best practices.\nLeverage APOC procedures, custom plugins, and advanced graph algorithms to solve domain-specific problems.\nOversee integration of Neo4j with other enterprise systems, microservices, and data platforms.\nDevelop and maintain APIs and services in Java, Python, or JavaScript to interact with the graph database.\nMentor junior developers and review code to maintain high-quality standards.\nEstablish guidelines for performance tuning, scalability, security, and disaster recovery in Neo4j environments.\nWork with data scientists, analysts, and business stakeholders to translate complex requirements into graph-based solutions.\nSkills\nMust have\n12+ years in software/data engineering, with at least 3-5 years hands-on experience with Neo4j.\nLead the technical strategy, architecture, and delivery of Neo4j-based solutions.\nDesign, model, and implement complex graph data structures using Cypher and Neo4j best practices.\nGuide the integration of Neo4j with other data platforms and microservices.\nCollaborate with cross-functional teams to understand business needs and translate them into graph-based models.\nMentor junior developers and ensure code quality through reviews and best practices.\nDefine and enforce performance tuning, security standards, and disaster recovery strategies for Neo4j.\nStay up-to-date with emerging technologies in the graph database and data engineering space.\nStrong proficiency in Cypher query language, graph modeling, and data visualization tools (e.g., Bloom, Neo4j Browser).\nSolid background in Java, Python, or JavaScript and experience integrating Neo4j with these languages.\nExperience with APOC procedures, Neo4j plugins, and query optimization.\nFamiliarity with cloud platforms (AWS) and containerization tools (Docker, Kubernetes).\nProven experience leading engineering teams or projects.\nExcellent problem-solving and communication skills.\nNice to have\nN/A\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Flexera Data Analyst\nData Science\nIndia\nGurugram\nSenior Flexera Data Analyst\nData Science\nIndia\nChennai\nBusiness Analyst\nData Science\nPoland\nRemote Poland\nBengaluru, India\nReq. VR-114556\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114556\nApply for Data Engineer with Neo4j in Bengaluru\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'query optimization', 'neo4j', 'data science', 'Data modeling', 'Disaster recovery', 'Javascript', 'Data structures', 'data visualization', 'Python']",2025-06-12 14:13:40
Data Engineer with Neo4j,Luxoft,3 - 5 years,Not Disclosed,['Chennai'],"Graph Data Modeling & Implementation.\nDesign and implement complex graph data models using Cypher and Neo4j best practices.\nLeverage APOC procedures, custom plugins, and advanced graph algorithms to solve domain-specific problems.\nOversee integration of Neo4j with other enterprise systems, microservices, and data platforms.\nDevelop and maintain APIs and services in Java, Python, or JavaScript to interact with the graph database.\nMentor junior developers and review code to maintain high-quality standards.\nEstablish guidelines for performance tuning, scalability, security, and disaster recovery in Neo4j environments.\nWork with data scientists, analysts, and business stakeholders to translate complex requirements into graph-based solutions.\nSkills\nMust have\n12+ years in software/data engineering, with at least 3-5 years hands-on experience with Neo4j.\nLead the technical strategy, architecture, and delivery of Neo4j-based solutions.\nDesign, model, and implement complex graph data structures using Cypher and Neo4j best practices.\nGuide the integration of Neo4j with other data platforms and microservices.\nCollaborate with cross-functional teams to understand business needs and translate them into graph-based models.\nMentor junior developers and ensure code quality through reviews and best practices.\nDefine and enforce performance tuning, security standards, and disaster recovery strategies for Neo4j.\nStay up-to-date with emerging technologies in the graph database and data engineering space.\nStrong proficiency in Cypher query language, graph modeling, and data visualization tools (e.g., Bloom, Neo4j Browser).\nSolid background in Java, Python, or JavaScript and experience integrating Neo4j with these languages.\nExperience with APOC procedures, Neo4j plugins, and query optimization.\nFamiliarity with cloud platforms (AWS) and containerization tools (Docker, Kubernetes).\nProven experience leading engineering teams or projects.\nExcellent problem-solving and communication skills.\nNice to have\nN/A\nOther\nLanguages\nEnglish: C1 Advanced\nSeniority\nSenior\nRefer a Friend\nPositive work environments and stellar reputations attract and retain top talent. Find out why Luxoft stands apart from the rest.\nRecommend a friend\nRelated jobs View all vacancies\nSenior Flexera Data Analyst\nData Science\nIndia\nGurugram\nSenior Flexera Data Analyst\nData Science\nIndia\nBengaluru\nData Scientist\nData Science\nIndia\nBengaluru\nChennai, India\nReq. VR-114556\nData Science\nBCM Industry\n23/05/2025\nReq. VR-114556\nApply for Data Engineer with Neo4j in Chennai\n*",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'query optimization', 'neo4j', 'data science', 'Data modeling', 'Disaster recovery', 'Javascript', 'Data structures', 'data visualization', 'Python']",2025-06-12 14:13:42
Mis Executive (Goregaon - Mumbai) Fresher Also Can apply,Rigved Technologies,0 - 4 years,1.25-3 Lacs P.A.,['Mumbai (All Areas)'],"Dear Candidates,\n\nWe are hiring for the position of  ""MIS Executive"", Kindly find below details.\n\nPayroll Company Name                   : Rigved Technologies  (https://www.rigvedtech.com/)\n\nClient                                                   : Bank  \n\nJob Location                                      : Goregaon, Mumbai \n\nExperience Required                         : 0 - 2Years \n\nDesignation                                       : MIS Executive\n\nRequired Skills:\nAdvanced proficiency in Microsoft Excel (Pivot Tables, VLOOKUP/XLOOKUP, INDEX-MATCH, Charts, Conditional Formatting, etc.)\nExperience with data visualization and dashboard creation\nGood understanding of data analysis techniques\nStrong attention to detail and accuracy\nAbility to handle confidential data responsibly\nBasic knowledge of Excel.\nKnowledge of Power Query and Power BI is an added advantage\n\n\nINTEERSTED CANDIDATE CAN SHARE RESUME ON anshu.baranwal@rigvedtech.com",Industry Type: Recruitment / Staffing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Excel', 'MIS', 'VLOOKUP']",2025-06-12 14:13:44
E-Commerce Analyst,Exotic Mile,1 - 5 years,Not Disclosed,['Gurugram'],"Role & responsibilities\n\nMonitor and analyze daily, weekly, and monthly performance of e-commerce platforms (e.g., website, marketplaces).\nProvide insights into customer behavior, conversion rates, and key funnel metrics.\nTrack and report KPIs such as sales performance, traffic sources, bounce rates, cart abandonment, AOV, etc.\nIdentify trends, gaps, and opportunities to optimize performance and user experience.\nSupport marketing teams with campaign analysis, ROI tracking, and audience segmentation.\nCollaborate with product and UX teams to test hypotheses and recommend data-backed improvements.\nDevelop and maintain dashboards and automated reports using tools like Excel, Google Analytics,\nEnsure data accuracy and integrity across various platforms",Industry Type: Internet (E-Commerce),"Department: Merchandising, Retail & eCommerce","Employment Type: Full Time, Permanent","['Ecommerce', 'Analyst', 'Pricing Analysis', 'forecasting', 'Trend analysis', 'p&l', 'Data Analysis', 'Advanced Excel']",2025-06-12 14:13:46
Research Analyst - Writer,Panacorp Software Solutions,1 - 3 years,Not Disclosed,['Nagercoil'],"The Research Analyst in PhD Assistance supports academic research by gathering and analyzing data, conducting literature reviews, and preparing reports. This role helps PhD candidates and faculty members by ensuring high-quality, evidence-based research work.\n\nRoles & Responsibilities:\n\nLiterature Reviews & Data Collection:\nConduct thorough literature reviews to gather relevant academic resources.\nCollect and organize research data from various sources.\n\nData Analysis:\nAnalyze quantitative and qualitative data using research tools and software.\nSummarize findings to support research projects.\n\nReport Preparation:\nCreate detailed research reports, summaries, and presentations.\nAssist in preparing materials for academic publications and grant proposals.\n\nResearch Support:\nCollaborate with PhD candidates and faculty to refine research methodologies.\nProvide technical assistance and guidance in research best practices.\n\nDatabase & Documentation Management:\nMaintain organized records and databases of research materials.\nEnsure all research processes meet academic standards and documentation practices.",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['research analysis', 'research writing', 'Research Support', 'Documentation Management', 'research reports']",2025-06-12 14:13:48
Commercial Business Systems Manager,Wells Fargo,2 - 7 years,Not Disclosed,['Bengaluru'],"In this role, you will:\nEvaluate moderately complex business problems and provide technical assistance in identifying automated systems and related procedures that are cost effective and meet business requirements\nReview and evaluate moderately complex technical business problems that can be resolved through internet or intranet based solutions\nPresent recommendations for resolving business problems",,,,"['Business Systems Data', 'system analysis', 'project management', 'data analysis', 'business system', 'business analysis']",2025-06-12 14:13:51
Analyst Programmer,Fidelity International,2 - 4 years,Not Disclosed,['Gurugram'],"Title Analyst Programmer\nDepartment AMO (ISS) Production Support\nLocation Gurugram\nLevel 2\nAbout Fidelity International:\nFidelity International offers investment solutions and services and retirement expertise to more than 2.56 million customers globally. As a privately-held, purpose-driven company with a 50-year heritage, we think generationally and invest for the long term. Operating in more than 25 locations and with $783.6 billion in total assets, our clients range from central banks, sovereign wealth funds, large corporates, financial institutions, insurers and wealth managers, to private individuals.\nOur Workplace & Personal Financial Health business provides individuals, advisers and employers with access to world-class investment choices, third-party solutions, administration services and pension guidance. Together with our Investment Solutions & Services business, we invest $567 billion on behalf of our clients. By combining our asset management expertise with our solutions for workplace and personal investing, we work together to build better financial futures.\nOur clients come from all walks of life and so do we. We are proud of our inclusive culture and encourage applications from the widest mix of talent, whatever your age, gender, ethnicity, sexual orientation, gender identity, social background and more. We are a disability-friendly company and would welcome a conversation with you if you feel you might benefit from any reasonable adjustments to perform to the best of your ability during the recruitment process and beyond.\nWe are committed to being a truly flexible employer, encouraging and trusting our people to perform their role in the way that works best for them, our business, our colleagues and our clients. We offer the maximum possible flexibility over where and when you work for all, considering your role and any local regulations. We call this new approach dynamic working .\nDepartment Description:\nAMO (ISS) production support consists of applications like Global Fund Data Repository (GFDR), Product hub, Performance Hub, Product (FRD), Reference Data Service, Transaction Service, Position Service, Frontier, Fund Distribution Service etc. architecture and engineering services that comprises of various Fidelity s Business Units in the UK and other parts of Europe, Asia and is a strategic area targeted for growth over the coming years. Various key systems have been acting as the key enablers for the business in achieving their goals. The Enterprise portfolio of projects will include a large collection of strategic initiatives as well as tactical ones to support day-to-day operations and strengthen the environment. The support team aims at supporting & maintaining global data warehouse acting as the single source of data for various line of business s to help them in the MI reporting requirements and data analysis. This source of data is considered as the golden source for distribution data and helps various business groups across organization to take knowledge based decisions.\nPurpose of the Role:\nThe position is for an Application Programmer in AMO production Support team. The role involves supporting key AMO - Enterprise applications and data marts involving strong PL/SQL and stored procedure knowledge on Oracle database platform. The candidate should have high expertise and core skills of Informatica and UNIX shell script. In addition, hands-on experience with Control-M technologies would be a plus. The successful candidate will be responsible to support for consumption of downstream feeds and applications in varied technologies. This would also involve intensive interaction with the business and other systems groups, so good communications skills and the ability to work under pressure are absolute must.\nKey Responsibilities:\nThe candidate is expected to display professional ethics in his/her approach to work and exhibit a high level ownership within a demanding working environment.\nProviding first line of technical support for business critical applications (Principal technologies / applications used include Oracle, UNIX , PaaS, Python, Java and Control-M).\nWork in the support team alongside data analysts, business analysts, database administrators and business project teams in enhancing and supporting the production services.\nHelp maintain Control-M schedules.\nConduct analysis and do bug fixes for production incidents. Carry out technical enhancements as desired.\nCarry out daily health-check activities involving application checks, system checks, and database checks and related on production systems / servers.\nThe scope of responsibility also covers monitoring business critical batch workloads, real-time / interactive processing, data transfer services, application on-boarding and upgrades, and recovery procedures.\nReport root cause of the incidents and present ideas on how to prevent the incidents from occurring in future.\nEnsure adherence to incident and change management processes. Regular engagement with Business & Systems Teams looking to adopt and apply the best practice of Service Support.\nPrepares and maintains documentation related application support like SOM, Service Card, Support Rota, Knowledge base, etc.\nDemonstrates continuous effort to improve operations, decrease turnaround times, streamline work processes, and work cooperatively and jointly to provide quality seamless customer service.\nResponsible for servicing 24x7 support as per support rosters.\nFlexibility to work in shifts ( on-demand & short-term basis), and/or on weekends.\nExperience and Qualifications Required:\nAround 2 - 4 years of technical experience in Software / IT industry in Development and Support functions\nMinimum 2 - 4 years of support experience in Production Support roles\nEssential Technical skills:\nAt least 2-4 years of Oracle experience with strong focus on SQL. PL/SQL knowledge is good to have.\nBasic understanding of PaaS technology, Python, Core Java and web services/ REST API.\nShould have core skills of UNIX shell script.\nEssential behavioural/operational skills:\nAbility to apply new skills / additional information acquired in relation to role.\nAbility to interact with end users/business users.\nAbility to work closely with cross functional teams including Infrastructure teams/Architects/Business Analysts.\nAbility to prioritise own activities, work under hard deadlines.\nTeam player with commitment to achieve team goals.\nMotivated, flexible and with a can do approach.\nKeen to learn and develop proficiency\nGood communication skills both verbal and written.\nDelivery and results focused.\nGood to have technical skills:\nHands-on experience with scheduling tools - Control-M would be a definite plus.\nExperience in informatica is good to have.\nExperience of any source control tool - SVN would be a plus.\nGood Operating Systems knowledge and associated commands (UNIX [Linux/AIX], MS Windows).\nFamiliarity in Data Warehouse, Datamart and ODS concepts.\nKnowledge of essential Software Engineering principles.\nKnowledge of ITIL practices.",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Unix', 'Aix', 'Core Java', 'Linux', 'Production support', 'PLSQL', 'Informatica', 'Oracle', 'Technical support', 'Python']",2025-06-12 14:13:53
Research Analyst 2,Demandbase,4 - 7 years,Not Disclosed,['Hyderabad'],"Introduction to Demandbase:\nDemandbase is the Smarter GTM company for B2B brands. We help marketing and sales teams overcome the disruptive data and technology fragmentation that inhibits insight and forces them to spam their prospects. We do this by injecting Account Intelligence into every step of the buyer journey, wherever our clients interact with customers, and by helping them orchestrate every action across systems and channels - through advertising, account-based experience, and sales motions. The result? You spot opportunities earlier, engage with them more intelligently, and close deals faster.\nAs a company, we re as committed to growing careers as we are to building world-class technology. We invest heavily in people, our culture, and the community around us. We have offices in the San Francisco Bay Area, New York, Seattle, and teams in the UK and India . We have also been continuously recognized as one of the best places to work in the San Francisco Bay Area.\nWere committed to attracting, developing, retaining, and promoting a diverse workforce. By ensuring that every Demandbase employee is able to bring a diversity of talents to work, were increasingly capable of living out our mission to transform how B2B goes to market. We encourage people from historically underrepresented backgrounds and all walks of life to apply. Come grow with us at Demandbase!\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented Research Analyst 2 to join our dynamic team. This role is crucial for driving informed business decisions through data gathering, analysis, and insightful reporting. The ideal candidate will possess a strong understanding of business research methodologies, data analysis techniques, and a passion for data accuracy and problem-solving.\nKey Responsibilities:\nConduct Comprehensive Data Research and Analysis: Source, collate, research, and analyze data from diverse business information sources and specialized databases to generate actionable insights.\nDrive Data-Driven Decision Making: Experienced in performing in-depth analysis to identify trends, anomalies, and root causes. Translate findings into recommendations that enhance product value and business growth.\nEnsure Data Quality and Integrity: Apply problem-solving skills to resolve data queries, conduct rigorous quality checks, and identify and address data coverage gaps.\nDocument and Strategically Analyze: Understand and document business requirements and KPIs, create functional specifications, and conduct competitor and vendor analysis for strategic insights.Convert complex data and findings into easily understandable tables, graphs, and well-structured written reports.\nRequired Skills & Experience:\nBachelor s or Master s degree in Business or Commerce\n4-7 years of relevant work experience\nProven experience in business/secondary research\nProficiency in MS Office, particularly Excel\nExperience in using data visualization tools and generating insightful reports.\nExcellent reporting writing skills\nExcellent communication skills, both written and verbal, with the ability to articulate thoughts clearly and understand others effectively (a portion of this job may be customer-facing)\nSelf-organized and self-driven, with strong personal integrity\nDetail-oriented and highly analytical approach to problem-solving\nGreat interpersonal skills\nPassion for content accuracy and data integrity\nAbility to work in a fast-paced, high-scale data environment.\nOur Commitment to Diversity, Equity, and Inclusion at Demandbase\nAt Demandbase, we believe in creating a workplace culture that values and celebrates diversity in all its forms. We recognize that everyone brings unique experiences, perspectives, and identities to the table, and we are committed to building a community where everyone feels valued, respected, and supported. Discrimination of any kind is not tolerated, and we strive to ensure that every individual has an equal opportunity to succeed and grow, regardless of their gender identity, sexual orientation, disability, race, ethnicity, background, marital status, genetic information, education level, veteran status, national origin, or any other protected status. We do not automatically disqualify applicants with criminal records and will consider each applicant on a case-by-case basis.\nWe recognize that not all candidates will have every skill or qualification listed in this job description. If you feel you have the level of experience to be successful in the role, we encourage you to apply!\nWe acknowledge that true diversity and inclusion require ongoing effort, and we are committed to doing the work required to make our workplace a safe and equitable space for all. Join us in building a community where we can learn from each other, celebrate our differences, and work together.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.\nPersonal information that you submit will be used by Demandbase for recruiting and other business purposes. Our Privacy Policy explains how we collect and use personal information.",Industry Type: Advertising & Marketing,Department: Research & Development,"Employment Type: Full Time, Permanent","['SAN', 'Data analysis', 'Business research', 'Analytical', 'Diversity and Inclusion', 'Data quality', 'MS Office', 'Research Analyst', 'Analyst 2', 'Secondary research']",2025-06-12 14:13:55
"Analyst - Metrics, Analytics & Reporting",Oliver Wyman,3 - 6 years,Not Disclosed,['Noida'],"1: The main responsibility is to track and co-ordinate Client employee benefits insurance policy renewals and broking implementations across the different client locations\nManage the timeliness and quality of Client deliverables - before, during and after renewal or implementation Work with the consultants to develop reporting and presentations for Client meetings based on client requirements Perform quality checks (by more experienced colleagues) Lead Implementation and Onboarding processes\nData entry and high level analysis - assist the Consulting team in gathering, organizing, validating, entering and analyzing data using GBM Analytics (Mercer proprietary software) for the various clients\nProvide high level data analysis including sanity check for employee headcount movement, related premium change by line of coverage, etc. Liaise with local brokers on renewal strategy if needed, to ensure the Rules of the Road are followed Manage ad-hoc client requests including problem-solving on administrative and operations issues - source the details from System Admin Team and local brokers, when needed Route enquiries to the correct point of contact and provide timely follow up and responses for the Clients Liaising with local brokers to gather information not captured by GBM Analytics including the nature of local discussions impacting the insurance placement or plan design strategy Provide reporting from GBM Analytics or excel for clients as required.\nMaintain relationship with MCG team and ensure client expectations are met.\n*Note that this role will work with the GBM/Consulting team, System Admin Team, local brokers and in some cases regional (RBM) teams and might have direct Client contact in the future.\n70%\n2 : GBMA and Mercer Gold+ Platform Management Support for System Admin Team.\nComplete assigned tasks in GBM Analytics and data entry as required into that tool. This includes initiating renewals in the application and following up with local brokers to ensure they complete their GBM Analytics tasks in an accurate and timely manner Update relevant Insurance financial and plan design data on MG+ based on policy documents and reports supplied by local broking teams. Clarify information with local brokers when necessary and ensure broker peer review is obtained.\n20%\n3 : Assistance with overall GBM intellectual capital (projects).\nTo include assistance building a qualitative assessment of insurers, hot topics by country, and other items as needed.\n10%",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Administration', 'analytics reporting', 'Data analysis', 'Finance', 'Consulting', 'Management', 'Analytics', 'System Administrator', 'Data entry', 'Investment']",2025-06-12 14:13:58
Research Analyst - Writer,Panacorp Software Solutions,1 - 3 years,2-3 Lacs P.A.,['Kanyakumari'],"The Research Analyst in PhD Assistance supports academic research by gathering and analyzing data, conducting literature reviews, and preparing reports. This role helps PhD candidates and faculty members by ensuring high-quality, evidence-based research work.\n\nRoles & Responsibilities:\n\nLiterature Reviews & Data Collection:\nConduct thorough literature reviews to gather relevant academic resources.\nCollect and organize research data from various sources.\n\nData Analysis:\nAnalyze quantitative and qualitative data using research tools and software.\nSummarize findings to support research projects.\n\nReport Preparation:\nCreate detailed research reports, summaries, and presentations.\nAssist in preparing materials for academic publications and grant proposals.\n\nResearch Support:\nCollaborate with PhD candidates and faculty to refine research methodologies.\nProvide technical assistance and guidance in research best practices.\n\nDatabase & Documentation Management:\nMaintain organized records and databases of research materials.\nEnsure all research processes meet academic standards and documentation practices.",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['Research Analysis', 'creative writing', 'blog writing', 'content development', 'technical writing', 'research writing', 'article writing', 'academic writing', 'content writing', 'content editing', 'proofreading', 'copy editing']",2025-06-12 14:14:00
Analytics and Modeling Analyst,Overture Rede,1 - 3 years,Not Disclosed,['Hyderabad'],"Job Role ( 20 Words)Enable data-driven sales operations by creating reports, supporting communication, and tracking opportunities to drive sales performance.\n\nKey Responsibilities\nGenerate actionable sales insights and dashboardsSupport communication between teams and track sales KPIsWork cross-functionally to improve data accuracy and reporting workflowsRespond to queries and assist in driving sales enablement strategies\n\nRequired Skills\n3+ years in data analysis and sales operations\nProficient in Excel (functions, Power Query, Power Pivot); Power BI preferred\nStrong communication and client support skills\nExperience in Software & Platforms industry a plus\nUnderstanding of data/cloud infrastructure products\nFlexible with working hours, strong stakeholder management\nStrong in collaboration, problem-solving, and process orientation\n",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Sales operations', 'Process orientation', 'Senior Analyst', 'sales enablement', 'Client support', 'Infrastructure', 'power bi', 'Stakeholder management', 'Analytics']",2025-06-12 14:14:02
Analytics and Modeling Analyst,Overture Rede,1 - 3 years,Not Disclosed,['New Delhi'],"\nWere hiring an Analytics and Modeling Analyst to support B2B sales enablement with actionable insights, custom reporting, and data-driven recommendations that fuel revenue growth.Key ResponsibilitiesGenerate insightful sales reports and analyticsCustomize dashboards for strategic decision-makingTrack sales opportunities and highlight risksSupport sales meetings and document insightsAddress data queries and recommend improvements\n\nRequired Skills\n3+ years in data analysis or sales operations\nStrong in Excel, Power Query, Power Pivot, Power BI\nUnderstanding of Software & Platforms, cloud/data products\nExcellent communication and stakeholder management",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Excel', 'Sales operations', 'Senior Analyst', 'sales enablement', 'query', 'power bi', 'B2B Sales', 'Stakeholder management', 'Analytics']",2025-06-12 14:14:05
Senior Officer,Max Life Insurance,0 - 5 years,Not Disclosed,['Hyderabad'],"Max Life Insurance Company Limited is looking for Senior Officer to join our dynamic team and embark on a rewarding career journey\nLeadershipProvide leadership and guidance to team members, fostering a positive work environment\nLead by example, demonstrating professionalism, integrity, and dedication to the organization's goals and values\nProject ManagementManage and coordinate projects from initiation to completion, ensuring adherence to timelines and budget constraints\nDevelop project plans, allocate resources, and monitor progress to achieve project objectives\nIdentify and mitigate risks to project success, implementing appropriate solutions as needed\nOperational EfficiencyStreamline processes and procedures to improve operational efficiency and effectiveness\nIdentify opportunities for automation or technological enhancements to optimize workflow and productivity\nCollaborate with cross-functional teams to implement process improvements and best practices\nData Analysis and ReportingAnalyze data to identify trends, patterns, and insights relevant to the organization's objectives\nGenerate reports and presentations to communicate findings and recommendations to key stakeholders\nUtilize data-driven insights to inform decision-making and drive continuous improvement initiatives\nStakeholder EngagementBuild and maintain relationships with internal and external stakeholders, including clients, partners, and vendors\nCollaborate with stakeholders to understand their needs and requirements, ensuring alignment with organizational objectives\nEffectively communicate project updates, issues, and resolutions to stakeholders, fostering transparency and trust\nCompliance and Risk ManagementEnsure compliance with relevant laws, regulations, and internal policies and procedures\nProactively identify and address potential risks and compliance issues, implementing appropriate controls and safeguards\nKeep abreast of industry developments and best practices to inform risk management strategies",Industry Type: Insurance,Department: Other,"Employment Type: Full Time, Permanent","['insurance', 'vendor management', 'visualforce', 'project management', 'sap', 'sfdc', 'purchase', 'triggers', 'javascript', 'apex', 'kaizen', 'salesforce', 'salesforce crm', 'sales force development', 'data loader', 'operations', 'compliance', 'procurement', 'quality assurance', 'html']",2025-06-12 14:14:07
Senior Officer,Max Life Insurance,0 - 5 years,Not Disclosed,['Chennai'],"Max Life Insurance Company Limited is looking for Senior Officer to join our dynamic team and embark on a rewarding career journey\nLeadershipProvide leadership and guidance to team members, fostering a positive work environment\nLead by example, demonstrating professionalism, integrity, and dedication to the organization's goals and values\nProject ManagementManage and coordinate projects from initiation to completion, ensuring adherence to timelines and budget constraints\nDevelop project plans, allocate resources, and monitor progress to achieve project objectives\nIdentify and mitigate risks to project success, implementing appropriate solutions as needed\nOperational EfficiencyStreamline processes and procedures to improve operational efficiency and effectiveness\nIdentify opportunities for automation or technological enhancements to optimize workflow and productivity\nCollaborate with cross-functional teams to implement process improvements and best practices\nData Analysis and ReportingAnalyze data to identify trends, patterns, and insights relevant to the organization's objectives\nGenerate reports and presentations to communicate findings and recommendations to key stakeholders\nUtilize data-driven insights to inform decision-making and drive continuous improvement initiatives\nStakeholder EngagementBuild and maintain relationships with internal and external stakeholders, including clients, partners, and vendors\nCollaborate with stakeholders to understand their needs and requirements, ensuring alignment with organizational objectives\nEffectively communicate project updates, issues, and resolutions to stakeholders, fostering transparency and trust\nCompliance and Risk ManagementEnsure compliance with relevant laws, regulations, and internal policies and procedures\nProactively identify and address potential risks and compliance issues, implementing appropriate controls and safeguards\nKeep abreast of industry developments and best practices to inform risk management strategies",Industry Type: Insurance,Department: Other,"Employment Type: Full Time, Permanent","['insurance', 'vendor management', 'visualforce', 'project management', 'sap', 'sfdc', 'purchase', 'triggers', 'javascript', 'apex', 'kaizen', 'salesforce', 'salesforce crm', 'sales force development', 'data loader', 'operations', 'compliance', 'procurement', 'quality assurance', 'html']",2025-06-12 14:14:10
Data Visualization Expert - Deputy Manager,_VOIS,5 - 9 years,Not Disclosed,"['Pune', 'Bengaluru']","Data Visualization & UI/UX Designer (PowerBI & Power Solutions)\n\nAbout VOIS\n\nVOIS (Vodafone Intelligent Solutions) is a strategic arm of Vodafone Group Plc, creating value and enhancing quality and efficiency across 28 countries, and operating from 7 locations: Albania, Egypt, Hungary, India, Romania, Spain and the UK.\nOver 29,000 highly skilled individuals are dedicated to being Vodafone Groups partner of choice for talent, technology, and transformation. We deliver the best services across IT, Business Intelligence Services, Customer Operations, Business Operations, HR, Finance, Supply Chain, HR Operations, and many more.\nEstablished in 2006, _VOIS has evolved into a global, multi-functional organisation, a Centre of Excellence for Intelligent Solutions focused on adding value and delivering business outcomes for Vodafone.\n\nVOIS India\nIn 2009, VOIS started operating in India and now has established global delivery centres in Pune, Bangalore and Ahmedabad. With more than 14,500 employees, _VOIS India supports global markets and group functions of Vodafone and delivers best-in-class customer experience through multi-functional services in the areas of Information Technology, Networks, Business Intelligence and Analytics, Digital Business Solutions (Robotics & AI), Commercial Operations (Consumer & Business), Intelligent Operations, Finance Operations, Supply Chain Operations and HR Operations and more.\n\nLocation: Pune / Bangalore\nWorking Persona: Hybrid\n\nRole Purpose:\nTalented and experienced Data Visualization and UI/UX Expert to join our dynamic team. In this role, you will play a pivotal role in creating compelling, user-friendly data visualizations and ensuring an exceptional user experience across our digital platforms. As a key member of our team, you will collaborate with various stakeholders to translate complex data into visually engaging and informative designs.\n\nKey Responsibilities:\nData Visualization:\no Create interactive and visually appealing data visualizations using tools such as PowerBI,\nPower BI, Power Solutions, or other relevant platforms.o Transform complex data sets into\neasy-to-understand charts, graphs, and dashboards.\no Ensure data accuracy, consistency, and integrity in visualizations.\nUI/UX Design:\no Design and implement user interfaces for web and mobile applications that prioritize user\nexperience and usability.\no Conduct user research, usability testing, and gather feedback to iterate on designs.\no Collaborate with front-end developers to ensure seamless integration of UI/UX designs.\nCollaboration:\no Work closely with cross-functional teams, including data analysts, developers, and product managers, to understand project requirements and objectives.\no Communicate design concepts and rationale effectively to both technical and non-technical stakeholders.\nContinuous Improvement:\no Stay updated with industry trends and best practices in data visualization and UI/UX design.\no Propose and implement improvements to existing visualizations and designs.\n\nQualifications:\nBachelor's degree in Graphic Design, HCI, Computer Science, or related field (Master's\ndegree preferred).\nProven experience in data visualization and UI/UX design, with a strong portfolio\nshowcasing your work.\nProficiency in data visualization tools (e.g., Power BI) and design tools (e.g., Adobe Creative\nSuite, Sketch, Figma).\nStrong understanding of usability principles, user-centered design, and information\narchitecture.\nFamiliarity with HTML, CSS, and JavaScript for UI implementation.\nExcellent communication and collaboration skills.\n\nVOIS Equal Opportunity Employer Commitment\nVOIS is proud to be an Equal Employment Opportunity Employer. We celebrate differences and we welcome and value diverse people and insights. We believe that being authentically human and inclusive powers our employees growth and enables them to create a positive impact on themselves and society. We do not discriminate based on age, colour, gender (including pregnancy, childbirth, or related medical conditions), gender identity, gender expression, national origin, race, religion, sexual orientation, status as an individual with a disability, or other applicable legally protected characteristics.\nAs a result of living and breathing our commitment, our employees have helped us get certified as a Great Place to Work in India for four years running. We have been also highlighted among the Top 5 Best Workplaces for Diversity, Equity, and Inclusion, Top 10 Best Workplaces for Women, Top 25 Best Workplaces in IT & IT-BPM and 14th Overall Best Workplaces in India by the Great Place to Work Institute in 2023. These achievements position us among a select group of trustworthy and high-performing companies which put their employees at the heart of everything they do.\n\nBy joining us, you are part of our commitment. We look forward to welcoming you into our family which represents a variety of cultures, backgrounds, perspectives, and skills!\n\nApply now, and well be in touch!",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Visualization', 'SQL', 'Figma', 'Tableau', 'Qlik', 'Dashboard Development', 'Adobe Creative Suite']",2025-06-12 14:14:12
MDM Associate Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\n\nRole Description\n\nWe are seeking an MDM Associate Analyst with 2 5 years of development experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability. The ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.\n\nTo succeed in this role, the candidate must have strong experience on MDM (Master Data Management) on configuration (L3 Configuration, Assets creati on, Data modeling etc ) , ETL and data mappings (CAI, CDI ) , data mastering (Match/Merge and Survivorship rules) , source and target integrations ( RestAPI , Batch integration, Integration with Databricks tables etc )\n\nRoles & Responsibilities\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark , and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional\n\nSkills:\nMust-Have Skills:\nStrong experience with Informatica or Reltio MDM platforms in building configurations from scratch (Like L3 configuration or Data modeling, Assets creations, Setting up API integrations, Orchestration)\nStrong experience in building data mappings, data profiling, creating and implementation business rules for data quality and data transformation\nStrong experience in implementing match and merge rules and survivorship of golden records\nExpertise in integrating master data records with downstream systems\nVery good understanding of DWH basics and good knowledge on data modeling\nExperience with IDQ, data modeling and approval workflow/DCR.\nAdvanced SQL expertise and data wrangling.\nExposure to Python and PySpark for data transformation workflows.\nKnowledge of MDM, data governance, stewardship, and profiling practices.\nGood-to-Have\n\nSkills:\nFamiliarity with Databricks and AWS architecture.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nBasics of data engineering concepts.\nProfessional Certifications\nAny ETL certification ( e.g. Informatica)\nAny Data Analysis certification (SQL , Python, Databricks )\nAny cloud certification (AWS or AZURE)\nSoft\n\nSkills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM', 'advance sql', 'master data', 'reltio', 'data mapping', 'informatica', 'sql', 'data profiling']",2025-06-12 14:14:14
MDM Associate Analyst,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"Role Description:\nWe are seeking an MDM Associate Analystwith 25 years of development experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability. The ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.To succeed in this role, the candidate must have strong experience on MDM (Master Data Management) on configuration (L3 Configuration, Assets creation, Data modeling etc), ETL and data mappings (CAI, CDI) , data mastering (Match/Merge and Survivorship rules), source and target integrations (RestAPI, Batch integration, Integration with Databricks tables etc)\nRoles & Responsibilities:\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark, and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\nStrong experience with Informatica or Reltio MDM platforms in building configurations from scratch (Like L3 configuration or Data modeling, Assets creations, Setting up API integrations, Orchestration)\nStrong experience in building data mappings, data profiling, creating and implementation business rules for data quality and data transformation\nStrong experience in implementing match and merge rules and survivorship of golden records\nExpertise in integrating master data records with downstream systems\nVery good understanding of DWH basics and good knowledge on data modeling\nExperience with IDQ, data modeling and approval workflow/DCR.\nAdvanced SQL expertise and data wrangling.\nExposure to Python and PySpark for data transformation workflows.\nKnowledge of MDM, data governance, stewardship, and profiling practices.\nGood-to-Have Skills:\nFamiliarity with Databricks and AWS architecture.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nBasics of data engineering concepts.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL, Python, Databricks)\nAny cloud certification (AWS or AZURE)\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM', 'configuration', 'Data modeling', 'data governance', 'API integrations', 'Databricks', 'data mappings']",2025-06-12 14:14:16
Lead Data Scientist,Trion Consultancy Services,10 - 18 years,20-35 Lacs P.A.,['Chennai'],"LD Scientist with 12 yrs of industry exp, including at least 5 yrs of hands-on exp in data science & a proven track record of delivering impactful data science solutions.\nData Analysis &Exploration\nTime Series Analysis\nModel Deployment & Integration\n\nRequired Candidate profile\n12+ yrs/including 5+ yrs in data science\nExp in Python and SQL for data extraction, manipulation & analysis\nDS & Model Development: Demonstrated exp in performing exploratory data analysis (EDA)",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Lead Data science', 'Machine Learning', 'Python']",2025-06-12 14:14:19
Lead Data Scientist,Bizopp Management Consultants,11 - 18 years,25-35 Lacs P.A.,['Chennai'],"• Proficiency in Python and SQL for data extraction, manipulation, and analysis\n\n• Exploratory data analysis (EDA), developing, and deploying machine learning models\n\n• Expertise in deploying ML models on cloud platforms such as AWS or Azure",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['EDA', 'Data Scientist', 'Python', 'SQL', 'Azure', 'Exploratory data analysis', 'Machine Learning', 'AWS', 'ML']",2025-06-12 14:14:21
Financial Analyst,Icreon Communications,4 - 5 years,Not Disclosed,['Noida'],"Looking for a well-rounded Financial Analyst who can provide critical business partner support to our IT / ITes Services Business units. The candidate will be responsible for supporting Executive and Finance team members with data insights, budgets, and forecasts and other ad-hoc analyses.\nWhat you ll do:\nProvide finance support to the business teams regarding productivity, demand planning, reporting, and financial metrics\nAssist in the preparation of annual budgets and forecasts, variance analyses, long--range financial plans, risk/opportunity assessments, and periodic/ad hoc reporting",,,,"['Data analysis', 'Excel', 'Demand planning', 'Finance', 'ITES', 'data visualization', 'Continuous improvement', 'Operations', 'Analytics', 'SQL']",2025-06-12 14:14:23
MDM Testing - Associate Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"Role Description:\nWe are looking for a skilled MDM Testing Associate Analyst who will responsible for ensuring the quality and integrity of Master Data Management (MDM) applications through rigorous testing processes. This role involves collaborating with cross-functional teams to define testing objectives, scope, and deliverables, and to ensure that master data is accurate, consistent, and reliable. and comply with Amgens standard operating procedures, policies, and guidelines. Your expertise will be instrumental in ensuring quality and adherence to required standards so that the engineering teams can build and deploy products that are compliant.\nRoles & Responsibilities:\nTest Planning: Develop and implement comprehensive testing strategies for MDM applications, including defining test objectives, scope, and deliverables. This includes creating detailed test plans, test cases, and test scripts.\nTest Execution: Execute test cases, report defects, and ensure that all issues are resolved before deployment. This involves performing functional, integration, regression, and performance testing.\nData Analysis: Analyze data to identify trends, patterns, and insights that can be used to improve business processes and decision-making. This includes validating data accuracy, completeness, and consistency.\nCollaboration: Work closely with the MDM, RefData and DQDG team and other departments to ensure that the organizations data needs are met. This includes coordinating with data stewards, data architects, and business analysts.\nDocumentation: Maintain detailed documentation of test cases, test results, and any issues encountered during testing. This includes creating test summary reports and defect logs.\nQuality Assurance: Develop and implement data quality metrics to ensure the accuracy and consistency of master data. This includes conducting regular data audits and implementing data cleansing processes.\nCompliance: Ensure that all master data is compliant with data privacy and protection regulations. This includes adhering to industry standards and best practices for data management.\nTraining and Support: Provide training and support to end-users to ensure proper use of MDM systems. This includes creating user manuals and conducting training sessions\nStay current on new technologies, validation trends, and industry best practices to improve validation efficiencies.\nCollaborate and communicate effectively with the product teams.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n2+ years of experience in MDM implementations, primarily with testing (pharmaceutical, biotech, medical devices, etc.)\nExtensive experience on ETL/ELT and MDM testing (Creating test plan, test scripts and execution of test scripts and bugs tracking/reporting in JIRA)\nInformatica MDM: Proficiency in Informatica MDM Hub console, configuration, IDD (Informatica Data Director), IDQ, and data modeling\nor\nReltio MDM: Experience with Reltio components, including data modeling, integration, validation, cleansing, and unification.\nAdvanced SQL: Ability to write and optimize complex SQL queries, including subqueries, joins, and window functions.\nData Manipulation: Skills in data transformation techniques like pivoting and unpivoting.\nStored Procedures and Triggers: Proficiency in creating and managing stored procedures and triggers for automation.\nPython: Strong skills in using Python for data analysis, including libraries like Pandas and NumPy etc.\nAutomation: Experience in automating tasks using Python scripts.\nMachine Learning: Basic understanding of machine learning concepts and libraries like scikit-learn.\nStrong problem-solving and analytical skills\nExcellent communication and teamwork skills\nGood-to-Have Skills:\nETL Processes: Knowledge of ETL processes for extracting, transforming, and loading data from various sources.\nData Quality Management: Skills in data profiling and cleansing using tools like Informatica.\nData Governance: Understanding of data governance frameworks and implementation.\nData Stewardship: Ability to work with data stewards to enforce data policies and standards.\nSelenium: Experience with Selenium for automated testing of web applications.\nJIRA: Familiarity with JIRA for issue tracking and test case management.\nPostman: Skills in using Postman for API testing.\nUnderstanding of compliance and regulatory considerations in master data.\nIn depth knowledge of GDPR and HIPPA guidelines.\nProfessional Certifications:\nMDM certification (Informatica or Reltio)\nSQL Certified\nAgile or SAFe certified\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM Testing', 'ETL Processes', 'Data Stewardship', 'MDM', 'Agile', 'Data Quality Management', 'Data Governance', 'SQL']",2025-06-12 14:14:26
MDM Associate Analyst,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nWe are seeking an MDM Associate Analystwith 25 years of development experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability.\nThe ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.To succeed in this role, the candidate must have strong experience on MDM (Master Data Management) on configuration (L3 Configuration, Assets creation, Data modeling etc), ETL and data mappings (CAI, CDI) , data mastering (Match/Merge and Survivorship rules), source and target integrations (RestAPI, Batch integration, Integration with Databricks tables etc)\nRoles & Responsibilities:\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark, and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\nStrong experience with Informatica or Reltio MDM platforms in building configurations from scratch (Like L3 configuration or Data modeling, Assets creations, Setting up API integrations, Orchestration)\nStrong experience in building data mappings, data profiling, creating and implementation business rules for data quality and data transformation\nStrong experience in implementing match and merge rules and survivorship of golden records\nExpertise in integrating master data records with downstream systems\nVery good understanding of DWH basics and good knowledge on data modeling\nExperience with IDQ, data modeling and approval workflow/DCR.\nAdvanced SQL expertise and data wrangling.\nExposure to Python and PySpark for data transformation workflows.\nKnowledge of MDM, data governance, stewardship, and profiling practices.\nGood-to-Have Skills:\nFamiliarity with Databricks and AWS architecture.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nBasics of data engineering concepts.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL, Python, Databricks)\nAny cloud certification (AWS or AZURE)\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Reltio MDM', 'Data modeling', 'PySpark', 'data governance', 'Informatica', 'API integration', 'AWS', 'data profiling', 'SQL', 'Python']",2025-06-12 14:14:28
Technical Intern,Siemens Healthcare,3 months duration,Unpaid,['Bengaluru'],"Siemens Healthcare is looking for Technical Intern to join our dynamic team and embark on a rewarding career journey Learning and Shadowing: You'll spend a significant portion of your time observing and learning from experienced professionals in your field\n\nThis might involve shadowing software engineers, data analysts, network administrators, or other technical specialists to understand their workflows and best practices\n\nAssisting with Projects: You may have the opportunity to assist with ongoing projects or initiatives within your organization\n\nThis could include tasks such as coding, testing software applications, analyzing data, configuring systems, or troubleshooting technical issues\n\nTraining and Development: Many internships offer formal training sessions or workshops to help you develop your technical skills\n\nTake advantage of these opportunities to deepen your understanding of relevant programming languages, software tools, or methodologies\n\nProblem-Solving: Technical internships often provide opportunities to tackle real-world problems and challenges\n\nYou'll learn how to apply your technical knowledge to solve practical problems and improve processes within the organization\n\nCommunication Skills: Effective communication is crucial in any technical role\n\nAs an intern, you'll have opportunities to communicate with colleagues, present your work, and ask questions\n\nPractice conveying technical information clearly and concisely, both orally and in writing\n\nNetworking: Take advantage of networking opportunities during your internship to connect with professionals in your field\n\nAttend company events, join professional organizations, and reach out to colleagues for informational interviews or mentorship",Industry Type: Medical Services / Hospital,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Technical Intern', 'Internship']",2025-06-12 14:14:30
Supply Chain Analyst,Rhythm Placement,5 - 6 years,5.5-8 Lacs P.A.,['Pune'],"• Communicate with Planners/Buyers on Po creation requirements.\n• Monitor and collect data on Supplier KPI (Extra)\n• Purchase order creation, Amendment and follow ups on weekly basis\n• Quantitative analysis expertise\n• Critical thinking skills",Industry Type: Electronics Manufacturing (Electronic Manufacturing Services (EMS)),Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Management', 'MIS Reporting', 'Data Analysis', 'Dashboards', 'Data Interpretation', 'Advanced Excel', 'Data Collection', 'Dashboarding', 'Powerpoint', 'Business Reporting', 'Excel', 'VLOOKUP', 'Data Visualization', 'Data Reporting']",2025-06-12 14:14:32
MIS Executive (Fresher / Exp) B.SC Statistics / Math,Sarika Consultant Services,0 - 2 years,1.8-2.4 Lacs P.A.,['Kolkata( Gariahat )'],B.Sc Math or Stat must be needed\nFresher & experienced both can apply\nResponsibilities:\n* Analyze data using advanced Excel & Google Sheets skills.\n* Prepare monthly reports with statistical insights.\nCALL - 8697666885 or WhatsApp any queries\n\n\nHealth insurance\nProvident fund\nAnnual bonus,Industry Type: Industrial Equipment / Machinery,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Google Sheets', 'MIS', 'Advanced Excel', 'Mathematics', 'Statistics']",2025-06-12 14:14:34
E-commerce Executive,Wishkey Retail,0 - 5 years,1-3 Lacs P.A.,['Kolkata( Burrabazar )'],"Roles and Responsibilities\nManage and update product listings with accurate information and pricing.\nDevelop and adjust pricing strategies to stay competitive.\nPerform bulk uploads and data corrections using Excel/Google Sheets.\nEnsure listings comply with platform guidelines and maintain quality.\nUse AI tools to improve catalog and pricing processes.\nCollaborate with teams to support business growth via AI solutions.\nPrepare regular reports on sales and listing performance.\nCoordinate with teams for timely updates and issue resolution.\n\n\nDesired Candidate Profile\n0-5 years experience in e-commerce (freshers welcome).\nSkilled in product listing on Amazon, Flipkart, Blinkit, etc.\nDetail-oriented with knowledge of pricing strategies.\nComfortable using AI tools and basic Excel/Google Sheets.\nGood communication and teamwork skills.\nComfortable working on the 4th floor (no lift) in a busy commercial area (Burrabazar, Kolkata)",Industry Type: Internet (E-Commerce),"Department: Merchandising, Retail & eCommerce","Employment Type: Full Time, Permanent","['Data Analysis', 'E-commerce', 'Online Sales', 'Excel Sheet', 'Product Listing', 'Communication Skills', 'Ai Solutions', 'Adaptability', 'Catalog Management', 'Ecommerce Operations', 'Pricing Strategy', 'Content Optimization']",2025-06-12 14:14:36
Analytics and Modeling Associate,Overture Rede,0 - 1 years,Not Disclosed,['Bengaluru'],"Job Title: Analytics and Modeling AssociateLocation: Bengaluru Experience: 02 Years Education: 15 Years Full-TimeJob SummaryWe are seeking a motivated Analytics and Modeling Associate to support data-driven decision-making through insightful analysis, statistical modeling, and reporting\nIdeal for early-career professionals with a passion for data and problem-solving\nKey ResponsibilitiesCollect, clean, and analyze data to support business goalsBuild and maintain statistical models and dashboards\nCollaborate with stakeholders to define analytical needsPresent findings and provide actionable insightsSupport continuous improvement through data innovationMust-Have Skills Strong\nknowledge of Excel, SQL, and Python/R Understanding of statistical modeling and data visualization Familiarity with tools like Power BI / Tableau Excellent analytical and communication skills",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Statistical modeling', 'tableau', 'Excel', 'Analytical', 'power bi', 'data visualization', 'Continuous improvement', 'Analytics', 'SQL', 'Python']",2025-06-12 14:14:38
Mis Executive Bhubneswar,Talentpull And Infrastructure,0 - 3 years,"50,000-1.25 Lacs P.A.",['Bhubaneswar'],Role: MIS Infra\nLocation: Bhubneswar\nLocal candidates are preferred\nSalary: 18000 CTC\nQualification: 12th/Graduate\nSkills required:\n1. Expert in Advanced Excel\n2. Data Management\n3. Good communication skills\nInterested candidates can apply 7743003736,Industry Type: Telecom / ISP,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Pivot Table', 'VLOOKUP', 'Advanced Excel']",2025-06-12 14:14:40
Management Trainee - Hindi Speaking,Zebronics,0 - 5 years,Not Disclosed,['Chennai'],"Key Responsibilities:\n\nAssist in business planning, operations, and market analysis.\nSupport the team in day-to-day functions across departments.\nParticipate in negotiations and vendor/client meetings.\nDevelop insights based on data analysis and industry trends.\nCreate and deliver impactful presentations and reports.\nEngage in strategic decision-making and contribute ideas.\nCoordinate with internal teams to ensure smooth workflow.\nRepresent the brand with professionalism and presentability.\nRequired Skills:\n\nStrong communication and interpersonal abilities\nExcellent presentation and negotiation skills\nBusiness-oriented mindset with a problem-solving attitude\nAnalytical thinking and decision-making capabilities\nConvincing power and stakeholder handling",Industry Type: Consumer Electronics & Appliances,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Strategic Thinking', 'Hindi', 'Business Development', 'Communication Skills', 'Presentation Skills', 'Management Skills']",2025-06-12 14:14:42
Junior Accountant Executive,Singhi Chugh & Kumar,0 - 3 years,Not Disclosed,"['New Delhi', 'Gurugram', 'Greater Noida']","Role & responsibilities\nAssist in the preparation and filing of GST returns (GSTR-1, GSTR-3B) and ensure timely TDS deductions and filings.\nSupport in preparing monthly and quarterly financial reports, balance sheets, and profit & loss statements.\nUtilize Excel for data analysis, reporting, and maintaining financial records.\nMaintain accurate financial records using Tally ERP, recording daily transactions, and reconciling bank statements.\n\nPreferred candidate profile\n\nBachelor's degree in Commerce (B.Com) or equivalent.\nProficiency in Tally ERP and Microsoft Excel.\nBasic understanding of GST, TDS, and accounting principles.\nStrong attention to detail, analytical skills, and good communication abilities.",Industry Type: Accounting / Auditing,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Gst Reconciliation', 'Bank Reconciliation', 'Communication Skills', 'Excel', 'Tally ERP', 'Book Keeping']",2025-06-12 14:14:44
Executive Risk Advisory Services ( Internal Audit),Dpnc Global,0 - 3 years,Not Disclosed,"['Noida', 'New Delhi']","DPNC Global is looking for Executive Risk Advisory Services ( Internal Audit) to join our dynamic team and embark on a rewarding career journey.\n\nInternal Auditing : Conducting internal audits to evaluate the effectiveness of internal controls, risk management, and governance processes. Reviewing financial statements, operations, and various business processes. Risk Advisory : Providing advisory services related to risk management, helping the organization identify and mitigate potential risks. Developing strategies for risk avoidance, acceptance, reduction, or transfer. Compliance Assessment : Assessing and ensuring compliance with relevant laws, regulations, and internal policies. Identifying areas of non - compliance and recommending corrective actions. Audit Planning : Participating in the planning of audit projects, including defining the scope, objectives, and methodologies. Developing risk - based audit plans. Audit Execution : Performing audit procedures, including testing controls, reviewing documentation, and conducting interviews. Analyzing and interpreting data to draw meaningful conclusions. Report Generation : Preparing detailed and insightful audit reports outlining findings, recommendations, and action plans. Presenting audit reports to management and stakeholders. Continuous Monitoring : Implementing continuous monitoring processes to stay abreast of changes in risk factors and internal control environments. Recommending adjustments to audit plans as needed. Process Improvement : Identifying opportunities for process improvements and operational efficiencies based on audit findings. Collaborating with relevant departments to implement recommended changes. Training and Awareness : Conducting training sessions and awareness programs on risk management and internal controls for employees. Promoting a culture of risk awareness and compliance within the organization. Stakeholder Communication : Communicating with key stakeholders, including senior management and the audit committee. Providing updates on audit progress, findings, and recommendations. Technology Utilization : Leveraging technology tools for data analysis, audit automation, and risk assessment. Keeping up to date with advancements in audit technologies. Fraud Detection : Participating in fraud risk assessments and implementing measures to detect and prevent fraudulent activities.",Industry Type: Management Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Risk advisory', 'Manager Internal Audit', 'Senior Executive', 'Internal Audit Executive']",2025-06-12 14:14:46
Mis Executive,Harjai Computers,0 - 4 years,"50,000-2.75 Lacs P.A.","['Mumbai Suburban', 'Navi Mumbai', 'Mumbai (All Areas)']","Opening for MIS Executive Role.\nSkills - Excel, Advance Excel, Vlookup,Hlookup\nThane GB\nNotice Period - Immedite to 7 Days\nInterested candidate can share their updated resume at sangita@harjai.com",Industry Type: Banking,"Department: BFSI, Investments & Trading","Employment Type: Full Time, Permanent","['Advanced Excel', 'Pivot Table', 'SUMIF', 'Countif', 'VLOOKUP', 'Formulas', 'Lookup', 'Pivot', 'HLOOKUP']",2025-06-12 14:14:48
Mis Executive,Cafyo Management Solution,0 - 5 years,1.75-2.5 Lacs P.A.,['Delhi / NCR( Sector-16 Dwarka )'],"We are seeking a detail-oriented and technically proficient MIS Executive to manage and streamline the organization’s data reporting systems. The candidate will be responsible for designing, maintaining, and analyzing data reports andsupport business",Industry Type: Furniture & Furnishing,Department: Other,"Employment Type: Full Time, Permanent","['Advanced Excel', 'MIS Reporting', 'SQL', 'ERP', 'Power Bi', 'MIS']",2025-06-12 14:14:50
Research Analyst,Super Scholar,3 - 10 years,Not Disclosed,['Mumbai'],"Role Responsibilities:\n\nConduct thorough market research and data analysis to support company objectives.\n\nCollect and evaluate data from primary and secondary sources.\n\nDevelop and manage research projects, ensuring timelines and budget compliance.\n\nProvide actionable insights that inform strategic decision-making.\n\nPrepare detailed reports and presentations to communicate findings.\n\nCollaborate with cross-functional teams to identify research needs.\n\nAssist in the formulation of research methodologies and strategies.\n\nMonitor industry trends and competitive landscape.\n\nPresent research outcomes to stakeholders clearly and concisely.\n\nSupport the analysis of data sets using statistical software.\n\nIdentify opportunities for process improvements in research methodologies.\n\nEnsure data integrity and accuracy throughout research processes.\n\nFacilitate workshops and discussions to gather qualitative data.\n\nEngage with external vendors and partners for specialized research activities.\n\nMaintain a comprehensive research database and archives.\n\nContribute to brainstorming sessions to shape future research initiatives.\n\n\nQualifications:\n\nBachelors degree in Business, Economics, Statistics, or related field.\n\nProven experience as a Research Analyst or in a similar role.\n\nStrong knowledge of statistical tools and software.\n\nExcellent analytical and critical thinking skills.\n\nHands-on experience with quantitative and qualitative research methods.\n\nAbility to work independently and manage multiple projects simultaneously.\n\nExceptional communication skills, both oral and written.\n\nProficiency in Microsoft Office Suite, particularly Excel and PowerPoint.\n\nDetail-oriented with a strong focus on accuracy.\n\nAbility to synthesize complex information and present it in an understandable format.\n\nFamiliarity with market research techniques and methodologies.\n\nProactive, creative, and solution-focused mindset.\n\nStrong organizational and time management abilities.\n\nExperience working in a team-oriented, collaborative environment.\n\nWillingness to adapt and learn in a fast-paced setting.",Industry Type: E-Learning / EdTech,Department: Research & Development,"Employment Type: Full Time, Permanent","['Qualitative research', 'Data analysis', 'Time management', 'Analytical', 'Formulation', 'Market research', 'data integrity', 'Management', 'Research Analyst', 'MS Office']",2025-06-12 14:14:53
Quality Systems Analyst,PNG Air,3 - 5 years,Not Disclosed,['Papua New Guinea'],"Role & responsibilities\nMonitoring, analyzing and reporting of the performance and effectiveness of the Safety Management System (SMS)\nUsing analytical skills, to identify key issues and trends impacting on the risk level of the organization and escalate to the General Manager Safety, Aviation Security & Risk directly of any adverse trend involving high risk\nProviding quality reports to management on a weekly and monthly basis as specified in the QMS and as otherwise directed by the General Manager Safety, Aviation Security & Risk\nProducing data for inclusion in SQAG and SQRB reports with appropriate commentary on trends, including analysis of flight data management reports.\nBefore the end of each year, conducting an evaluation of investigation findings, assessment outcomes and audit findings to assist in validating the future risk based audit schedule.\nDeveloping and maintaining customized reports in the Quality Database against identified needs.\nProviding trend advice to various management forums as requested by the General Manager Safety, Aviation Security & Risk, including a quarterly analysis of Logged for Stats data.\nMonitor the audit schedule, ensuring that the requirements specified in the risk-based audit program are achieved.\nConducting Audits as a Lead Auditor as allocated in the audit schedule.\nEscalating to the General Manager Safety, Aviation Security & Risk directly of any deficiencies in the QMS which affect, or may affect, the safety of aircraft, clients or staff, or the achievement of corporate objective\nPreferred candidate profile\nLead Auditor Certificate\nSafety Investigator Certificate*\nFormal qualification in analytics*\nManagement System Training Level 3*\n5 years of experience in an aviation in an organizational role\n3 Years of experience within an SMS or QMS\nRelevant tertiary qualification of a Diploma or above\nAnalytical Skills in Analyzing data\nIT competency in using and developing customize reports through databases and quality software platforms\nProficiency in data analysis tools and techniques relevant to Quality and Safety reporting (Excel, Databases, Specialize software)",Industry Type: Aviation,Department: Aviation & Aerospace,"Employment Type: Full Time, Permanent","['Safety Management Systems', 'Analyzing Data', 'analytical skills', 'report writing', 'Auditing']",2025-06-12 14:14:55
Inventory/Product Listing Executive,Just Wines,0 - 5 years,Not Disclosed,['Faridabad'],"Job Title: Inventory/Product Listing Executive\nLocation: Faridabad\nJob Type: Full-Time\nReports To: Manager Inventory\nAbout Just Wines:\nJust Wines is a leading eCommerce company specializing in wines. We are committed to delivering high-quality products and seamless shopping experiences to our customers. As we continue to grow, we are looking for a detail-oriented Inventory Executive to optimize stock management, enhance product listings, and ensure smooth inventory operations.\nJob Summary:\nThe Inventory Executive will be responsible for managing stock levels, product listings, and\ndemand forecasting across our eCommerce platforms. The ideal candidate should have strong\nexpertise in Microsoft Excel, Shopify, and inventory forecasting techniques, ensuring optimal stock availability and operational efficiency.\nKey Responsibilities:\nInventory Management & Forecasting:\nMonitor and manage inventory levels across warehouses and eCommerce sales channels.\nUtilize advanced Excel skills (Pivot Tables, VLOOKUP, Macros, etc.) to track stock\nmovement, analyze data, and generate inventory reports.\nForecast demand trends using historical sales data and seasonal trends to optimize stock\nreplenishment.\nImplement and maintain inventory control procedures to minimize stock discrepancies.\nProduct Listing & Shopify Management:\nManage and update product listings on Shopify and other platforms to ensure accuracy in\ndescriptions, pricing, and stock availability.\n\nReporting & Data Analysis:\nGenerate detailed inventory reports, stock movement analysis, and sales trend insights.\nIdentify slow-moving or excess stock and propose strategies for liquidation or promotions.\nInvestigate stock discrepancies\nWork closely with finance and warehouse teams to ensure accurate stock valuation and\nreporting.\n\nRequired Skills & Qualifications:\nBachelors degree in Business Administration, Supply Chain, or a related field.\nProficiency in Microsoft Excel (Advanced Formulas, Pivot Tables, Macros, VLOOKUP,\netc.).\nGood Communications Skills",Industry Type: Internet (E-Commerce),"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Good Communication In English', 'Advanced Excel', 'Data Entry']",2025-06-12 14:14:57
Quality Analyst (Field Audit),Navi Technologies,2 - 6 years,3-6 Lacs P.A.,"['Thane', 'Mumbai (All Areas)( Borivali, Borivali East, Borivali West, Andheri, Andheri East, Andheri West, Thane East, Thane West )']","About Navi\nNavi is one of the fastest-growing financial services companies in India providing Personal & Home Loans, UPI, Insurance, Mutual Funds, and Gold. Navi's mission is to deliver digital-first financial products that are simple, accessible, and affordable. Drawing on our in-house AI/ML capabilities, technology, and product expertise, Navi is dedicated to building delightful customer experiences.\nFounders: Sachin Bansal & Ankit Agarwal\n\nKnow what makes you a Navi_ite :",,,,"['field sale', 'Credit Card Sales', 'Field Work', 'Field Collections', 'Interpersonal Skills', 'Communication Skills', 'B2C Sales', 'Microfinance', 'Credit Cards']",2025-06-12 14:14:59
Data Engineer,Xenonstack,2 - 5 years,Not Disclosed,['Mohali( Phase 8B Mohali )'],"At XenonStack, We committed to become the Most Value Driven Cloud Native, Platform Engineering and Decision Driven Analytics Company. Our Consulting Services and Solutions towards the Neural Company and its Key Drivers.\nXenonStacks DataOps team is looking for a Data Engineer who will be responsible for employing techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field.\nYou should demonstrate flexibility, creativity, and the capacity to receive and utilize constructive criticism. The ideal candidate should be highly skilled in all aspects of Python, Java/Scala, SQL and analytical skills.\nJob Responsibilities:\nDevelop, construct, test and maintain Data Platform Architectures\nAlign Data Architecture with business requirements\nLiaising with co-workers and clients to elucidate the requirements for each task.\nScalable and High Performant Data Platform Infrastructure that allows big data to be accessed and analysed quickly by BI & AI Teams.\nReformulating existing frameworks to optimize their functioning.\nTransforming Raw Data into InSights for manipulation by Data Scientists.\nEnsuring that your work remains backed up and readily accessible to relevant co-workers.\nRemaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.\nRequirements:\nTechnical Requirements\nExperience of Python, Java/Scala\nGreat Statistical / SQL based Analytical Skills\nExperience of Data Analytics Architectural Design Patterns for Batch, Event Driven and Real-Time Analytics Use Cases\nUnderstanding of Data warehousing, ETL tools, machine learning, Data EPIs\nExcellent in Algorithms and Data Systems\nUnderstanding of Distributed System for Data Processing and Analytics\nFamiliarity with Popular Data Analytics Framework like Hadoop , Spark , Delta Lake , Time Series / Analytical Stores Stores.\nProfessional Attributes:\nExcellent communication skills & Attention to detail.\nAnalytical mind and problem-solving Aptitude with Strong Organizational skills & Visual Thinking.\nBenefits:\nDiscover the benefits of joining our team:\nDynamic and purposeful work culture in a people-oriented organization contributing to multi-million-dollar projects with guaranteed job security.\nOpen, authentic, and transparent communication fostering a warm work environment.\nRegular constructive feedback and exposure to diverse technologies.\nRecognition and rewards for exceptional performance achievements.\nAccess to certification courses & Skill Sessions to develop continually and refine your skills.\nAdditional allowances for team members assigned to specific projects.\nSpecial skill allowances to acknowledge and compensate for unique expertise.\nComprehensive medical insurance policy for your health and well-being.\nTo Learn more about the company -\nWebsite - http://www.xenonstack.com/",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Hadoop', 'Spark', 'ETL', 'Python', 'SQL', 'Java', 'Data Processing', 'Machine Learning']",2025-06-12 14:15:01
Marketing Intern,Streamoid,No fixed duration,"40,000/month",['Bengaluru'],"About Us\nWere revolutionizing fashion photography by making professional-quality shoots accessible to every budget-conscious fashion business and content creator. Our AI-powered platform transforms basic product photos into stunning fashion campaigns with AI models and backgrounds - no photoshoot required.\nIf youre excited about AI technology, passionate about photography and fashion, and great at marketing we would like to meet you!\n\nThe Role\nThe Role\nWere looking for a creative marketing intern to help us spread the word about our game-changing AI photo studio. Youll work to create content, engage with fashion and photography communities, and help build our brand as the go-to solution for budget-smart visual content creation.\nThis is perfect for someone who wants hands-on experience in AI/tech marketing, content creation, and community building while supporting innovative small businesses.\n\nWhat Youll Do\nContent Creation & Storytelling\nCreate engaging social media content showcasing product transformations\nWrite blog posts about fashion photography trends, small business tips, and AI innovation\nDevelop case studies highlighting customer success stories\nScript and create short-form video content (Instagram Reels, YouTube Shorts)\nDesign simple graphics and visual content using Canva or similar tools\n\nCommunity Engagement\nEngage with fashion entrepreneurs and other potential customers on social media platforms\nMonitor and respond to comments, messages, and community discussions\nIdentify and connect with potential brand ambassadors and user-generated content creators\nParticipate in relevant online communities (Reddit, Facebook groups, industry forums)\nHelp manage our social media presence across Instagram, TikTok, LinkedIn, and Twitter\n\nMarket Research & Analysis\nResearch fashion industry trends and competitor activities\nIdentify potential partnership opportunities with fashion influencers and small business communities\nAnalyze social media performance and engagement metrics\nSurvey customers for feedback and testimonials\nResearch new platforms and marketing channels for our target audience\n\nCampaign Support\nAssist with email marketing campaigns\nHelp coordinate influencer partnerships and collaborations\nSupport product launch campaigns and promotional activities\nContribute to marketing materials and presentation development\nIdeal Profile\nWhat Were Looking For\nMust-Haves\nCurrently pursuing or recently completed degree in Marketing, Communications, Business, Fashion, or related field\nStrong written communication skills with a knack for engaging, conversational content\nSocial media native with understanding of platform-specific content strategies\nBasic design skills (Canva, Adobe Creative Suite, or similar)\nBasic video editing skills\nGenuine interest in fashion, small business, and/or AI technology\nSelf-motivated with ability to work independently and meet deadlines\nComfortable with data analysis and using analytics tools\n\nNice-to-Haves\nExperience with content creation (blogging, social media, video)\nFamiliarity with marketing tools (Mailchimp, Hootsuite, Google Analytics)\nUnderstanding of e-commerce and online fashion retail\nExperience with AI tools or tech startups\nPhotography or visual content creation background\n\nWhat Youll Gain\nProfessional Experience\nHands-on experience with AI/tech product marketing\nPortfolio of content creation and campaign work\nUnderstanding of startup marketing from strategy to execution\nExperience with multiple marketing channels and platforms\nData analysis and performance measurement skills\n\nCompensation & Benefits\n1. Internship fee will be Rs 30,000 to 40,000 per month.\n2. Lunch and snacks will be provided at office.\nWhats on Offer?\nOpportunity within a company with a solid track record of performance\nWork alongside & learn from best in class talent\nFlexible working options",Industry Type: Internet,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Graphics', 'Data analysis', 'Google Analytics', 'Email marketing', 'adobe creative suite', 'Social media', 'Market research', 'Video editing', 'Internship', 'Product marketing']",2025-06-12 14:15:04
Hiring MBA For Telesales Executive || CTC Up To 4.75 LPA ||,Multiple Clients,0 - 2 years,2.25-4.75 Lacs P.A.,['Gurugram'],"Applicants can call or WhatsApp to Ms.Zoya Shamsi-+91-7251000195 (11am-5pm) Only\n\nClient Overview:\nWe are a leading Recruitment company serving multiple prestigious clients across various industries, including Policy bazaar, Paisa Bazaar, Lenskart, Niva Bupa, Indiabulls, Globiva, Tech Mahindra, Research & Ranking,Fynocrat,Ebixcash, Hike Education, Indialends,Frankfinn,Teleperformance and more.\n\nAs an MBA Sales Associate or Customer Support Associate, you will have the opportunity to kickstart your career with these esteemed clients and contribute to their business growth.\nJob Profile:\nWe are seeking ambitious MBA freshers to join our team as Sales Associates and Customer Support Associates. Your primary responsibilities will include handling outbound/inbound/regional/e-mail/chat processes based on the assigned client and process. You will engage with customers, promote products/services, and provide exceptional customer support, applying the business acumen developed during your MBA studies.\nKey Responsibilities:\nHandle outbound/inbound/regional/e-mail/chat processes as assigned by the client.\nFor Sales Associates: Utilize MBA-level strategic thinking to contact potential customers, present products/services, and explain their features and benefits.\nApply advanced sales techniques and business strategies to follow scripts, engage with customers, and overcome objections.\nMeet or exceed sales/customer satisfaction targets, contributing to the growth of the client's business through data-driven decision-making.\nBuild and maintain customer relationships by providing exceptional service, leveraging your understanding of customer relationship management.\nMaintain accurate records of customer interactions, sales, and support tickets in the CRM system, applying data analysis skills.\n\nKey Skills and Requirements:\nMBA degree (freshers)\nExcellent verbal and written communication skills in English; additional regional languages are a plus.\nStrong analytical and problem-solving skills developed through MBA coursework.\nAbility to understand customer needs and effectively present solutions using business strategy principles.\nProficiency in data analysis and interpretation, with familiarity in using CRM systems.\nCapability to work in a target-driven environment and achieve sales/customer satisfaction goals.\nProactive and self-motivated with a positive attitude and entrepreneurial spirit.\nStrong leadership potential and ability to work effectively in team settings.\nFlexibility to adapt to changing processes and client requirements, demonstrating business agility.\nUnderstanding of market research, consumer behavior, and customer service principles.\n\nLocation: Delhi/Noida/Gurugram\nCTC: The salary range for MBA fresher Sales Associates and Customer Support Associates is 3.00 LPA to 5.00 LPA, depending on academic performance, interview results, and the assigned client.\nShift Type: The shift type may vary based on the client and process. We offer day shifts, night shifts, and rotational shifts to accommodate the preferences of our employees.",Industry Type: BPM / BPO,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['B2C Sales', 'Telesales', 'Sales', 'Inbound Sales', 'Insurance Sales', 'Inside Sales', 'Banking Sales', 'International Sales', 'Sales Process', 'Outbound Sales', 'Telecalling', 'Domestic BPO', 'Cold Calling', 'Domestic Calling', 'Bpo Sales', 'Domestic Sales', 'International Calling', 'International BPO']",2025-06-12 14:15:06
Data Engineer,Konrad Group,3 - 7 years,15-30 Lacs P.A.,['Gurugram( Sector 42 Gurgaon )'],"Who We Are\n\nKonrad is a next generation digital consultancy. We are dedicated to solving complex business problems for our global clients with creative and forward-thinking solutions. Our employees enjoy a culture built on innovation and a commitment to creating best-in-class digital products in use by hundreds of millions of consumers around the world. We hire exceptionally smart, analytical, and hard working people who are lifelong learners.\nAbout The Role\nAs a Data Engineer youll be tasked with designing, building, and maintaining scalable data platforms and pipelines. Your deep knowledge of data platforms such as Azure Fabric, Databricks, and Snowflake will be essential as you collaborate closely with data analysts, scientists, and other engineers to ensure reliable, secure, and efficient data solutions.\n\nWhat Youll Do\n\nDesign, build, and manage robust data pipelines and data architectures.\nImplement solutions leveraging platforms such as Azure Fabric, Databricks, and Snowflake.\nOptimize data workflows, ensuring reliability, scalability, and performance.\nCollaborate with internal stakeholders to understand data needs and deliver tailored solutions.\nEnsure data security and compliance with industry standards and best practices.\nPerform data modelling, data extraction, transformation, and loading (ETL/ELT).\nIdentify and recommend innovative solutions to enhance data quality and analytics capabilities.\n\nQualifications\n\nBachelors degree or higher in Computer Science, Data Engineering, Information Technology, or a related field.\nAt least 3 years of professional experience as a Data Engineer or similar role.\nProficiency in data platforms such as Azure Fabric, Databricks, and Snowflake.\nHands-on experience with data pipeline tools, cloud services, and storage solutions.\nStrong programming skills in SQL, Python, or related languages.\nExperience with big data technologies and concepts (Spark, Hadoop, Kafka).\nExcellent analytical, troubleshooting, and problem-solving skills.\nAbility to effectively communicate technical concepts clearly to non-technical stakeholders.\nAdvanced English\n\nNice to have\n\nCertifications related to Azure Data Engineering, Databricks, or Snowflake.\nFamiliarity with DevOps practices and CI/CD pipelines.\n\nPerks and Benefits\n\nComprehensive Health & Wellness Benefits Package \nSocials, Outings & Retreats\nCulture of Learning & Development\nFlexible Working Hours\nWork from Home Flexibility\nService Recognition Programs\n\nKonrad is committed to maintaining a diverse work environment and is proud to be an equal opportunity employer. All qualified applicants, regardless of race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status will receive consideration for employment. If you have any accessibility requirements or concerns regarding the hiring process or employment with us, please notify us so we can provide suitable accommodation.\nWhile we sincerely appreciate all applications, only those candidates selected for an interview will be contacted.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Hadoop', 'Azure Data Factory', 'Azure Databricks', 'Spark', 'Fabric', 'Python']",2025-06-12 14:15:09
Azure Data Engineer,Arges Global,2 - 5 years,8-18 Lacs P.A.,['Pune( Baner )'],"Scope of Work:\nCollaborate with the lead Business / Data Analyst to gather and analyse business requirements for data processing and reporting solutions.\nMaintain and run existing Python code, ensuring smooth execution and troubleshooting any issues that arise.\nDevelop new features and enhancements for data processing, ingestion, transformation, and report building.\nImplement best coding practices to improve code quality, maintainability, and efficiency.\nWork within Microsoft Fabric to manage data integration, warehousing, and analytics, ensuring optimal performance and reliability.\nSupport and maintain CI/CD workflows using Git-based deployments or other automated deployment tools, preferably in Fabric.\nDevelop complex business rules and logic in Python to meet functional specifications and reporting needs.\nParticipate in an agile development environment, providing feedback, iterating on improvements, and supporting continuous integration and delivery processes.\nRequirements:\nThis person will be an individual contributor responsible for programming, maintenance support, and troubleshooting tasks related to data movement, processing, ingestion, transformation, and report building.\nAdvanced-level Python developer.\nModerate-level experience in working in Microsoft Fabric environment (at least one and preferably two or more client projects in Fabric).\nWell-versed with understanding of modelling, databases, data warehousing, data integration, and technical elements of business intelligence technologies.\nAbility to understand business requirements and translate them into functional specifications for reporting applications.\nExperience in GIT-based deployments or other CI/CD workflow options, preferably in Fabric.\nStrong verbal and written communication skills.\nAbility to perform in an agile environment where continual development is prioritized.\nWorking experience in the financial industry domain and familiarity with financial accounting terms and statements like general ledger, balance sheet, and profit & loss statements would be a plus.\nAbility to create Power BI dashboards, KPI scorecards, and visual reports would be a plus.\nDegree in Computer Science or Information Systems, along with a good understanding of financial terms or working experience in banking/financial institutions, is preferred.",Industry Type: Financial Services (Asset Management),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Microsoft Azure', 'Python', 'Azure Data Factory', 'Microsoft Fabric', 'Azure Databricks', 'Azure Data Lake']",2025-06-12 14:15:11
"Associate Specialist, Data Delivery & Operations",XL India Business Services Pvt. Ltd,2 - 6 years,Not Disclosed,['Gurugram'],"Associate Specialist - Data Delivery & Operations Gurgaon/Bangalore, India AXA XL recognizes data and information as critical business assets, both in terms of managing risk and enabling new business opportunities\n\nThis data should not only be high quality, but also actionable - enabling AXA XLs executive leadership team to maximize benefits and facilitate sustained enterprise advantage\n\nOur Innovation, Data, and Analytics Office (IDA) is focused on driving innovation by optimizing how we leverage data to drive strategy and create a new business model - disrupting the insurance market\n\nAs we develop an enterprise-wide data and digital strategy that moves us toward a greater focus on the use of data and data-driven insights, we are seeking an Associate Scientist for our Data Sourcing & Solutions team\n\nThe role sits across the IDA Department to make sure customer requirements are properly captured and transformed into actionable data specifications\n\nSuccess in the role will require a focus on proactive management of the sourcing and management of data from source through usage\n\nWhat you ll be DOING What will your essential responsibilities include? Accountable for documenting data requirements (Business and Function Requirements) and assessing the reusability of Axiom assets\n\nBuild processes to simplify and expedite data sourcing to focus on delivering data to AXA XL business stakeholders frequently\n\nDevelops and operationalizes strategic data products and answers and proactively manages the sourcing and management of data from source through usage (reusable Policy and Claim Domain data assets)\n\nData Validation Testing of the data products in partnership with the AXA XL business to ensure the accuracy of the data and validation of the requirements\n\nAssesses all data required as part of the Data Ecosystem to make sure data has a single version of the truth\n\nRespond to ad-hoc data requests to support AXA XLs business\n\nInstill a customer-first attitude, prioritizing service for our business stakeholders above all else\n\nInternalize and execute IDA and company-wide goals to become a data-driven organization\n\nContribute to best practices and standards to make sure there is a consistent and efficient approach to capturing business requirements and translating them into functional, non-functional, and semantic specifications\n\nDevelop a comprehensive understanding of the data and our customers\n\nDrive root cause analysis for identified data deficiencies within reusable data assets delivered via IDA\n\nIdentify solution options to improve the consistency, accuracy, and quality of data when captured at its source\n\nYou will report to the Senior Scientist- Data Sourcing & Delivery & Operations\n\nWhat you will BRING We re looking for someone who has these abilities and skills: Required Skills and Abilities: A minimum of a bachelor s or masters degree (preferred) in a relevant discipline\n\nExperience in a data role (business analyst, data analyst, analytics) preferably in the Insurance industry and within a data division\n\nRobust SQL knowledge and technical ability to query AXA XL data sources to understand our data\n\nExcellent presentation, communication (oral & written), and relationship-building skills, across all levels of management and customer interaction\n\nInsurance experience in data, underwriting, claims, and/or operations, including influencing, collaborating, and leading efforts in complex, disparate, and interrelated teams with competing priorities\n\nPassion for data and experience working within a data-driven organization\n\nWork together internal data with external industry data to deliver holistic answers\n\nWork with unstructured data to unlock information needed by the business to create unique products for the insurance industry\n\nPossesses robust exploratory analysis skills and high intellectual curiosity\n\nDisplays exceptional organizational skills and is detail oriented\n\nThe robust conceptual thinker who connects dots, and has critical thinking, and analytical skills\n\nDesired Skills and Abilities: Ability to work with team members across the globe and departments\n\nAbility to take ownership, work under pressure, and meet deadlines\n\nBuilds trust and rapport within and across groups\n\nApplies in-depth knowledge of business and specialized areas to solve business problems and understand integration challenges and long-term impact creatively and strategically\n\nAbility to manage data needs of an individual project(s) while being able to understand the broader enterprise data perspective\n\nExpected to recommend innovation and improvement to policies, and procedures, deploying resources, and performing core activities\n\nExperience with SQL Server, Azure Databricks Notebook, QlikView, Power BI, and Jira/Confluence a plus",Industry Type: Insurance,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data validation', 'Claims', 'Underwriting', 'Agile', 'QlikView', 'Business strategy', 'JIRA', 'Analytics', 'SQL', 'Customer interaction']",2025-06-12 14:15:13
Senior Executive,Flipkart,1 - 3 years,Not Disclosed,['Bengaluru'],"Skills Required :\nAnticorruption Policy , Critical and logical Thinking , Risk taking & Innovation\nRole :\nLaw Graduate, Commerce Graduate, MBA, Certified Fraud Investigator with 1 - 3 years of relevant experience working on vendor due diligence, reviewing due diligence reports, identifying red flags in due diligence and resolving red flags through logical conclusion.\nA strong commitment to integrity and professionalism, and passion for excellence.\nStrong interpersonal skills with ability to interface with cross -functional teams and front-line associates.\nDemonstrable computer literacy with specific ability to use Microsoft Word, PowerPoint, Excel, internet and internet-based applications.\nEducation/Qualification :\nLaw Graduate, Commerce Graduate, MBA, Certified Fraud Investigator.",Industry Type: Courier / Logistics,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Vendor Due Diligence', 'Critical Thinking', 'Fraud Investigation', 'anticorruption policy', 'team collaboration']",2025-06-12 14:15:15
Data Engineer,Infoobjects Inc.,3 - 6 years,Not Disclosed,['Jaipur'],"Role & responsibilities:\nDesign, develop, and maintain robust ETL/ELT pipelines to ingest and process data from multiple sources.\nBuild and maintain scalable and reliable data warehouses, data lakes, and data marts.\nCollaborate with data scientists, analysts, and business stakeholders to understand data needs and deliver solutions.\nEnsure data quality, integrity, and security across all data systems.\nOptimize data pipeline performance and troubleshoot issues in a timely manner.\nImplement data governance and best practices in data management.\nAutomate data validation, monitoring, and reporting processes.\n\n\n\nPreferred candidate profile:\nBachelor's or Masters degree in Computer Science, Engineering, Information Systems, or related field.\nProven experience (X+ years) as a Data Engineer or similar role.\nStrong programming skills in Python, Java, or Scala.\nProficiency with SQL and working knowledge of relational databases (e.g., PostgreSQL, MySQL).\nHands-on experience with big data technologies (e.g., Spark, Hadoop).\nFamiliarity with cloud platforms such as AWS, GCP, or Azure (e.g., S3, Redshift, BigQuery, Data Factory).\nExperience with orchestration tools like Airflow or Prefect.\nKnowledge of data modeling, warehousing, and architecture design principles.\nStrong problem-solving skills and attention to detail.\n\nPerks and benefits\nFree Meals\nPF and Gratuity\nMedical and Term Insurance",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SCALA', 'Kafka', 'AWS', 'Python', 'Pyspark', 'Java', 'Postgresql', 'Hadoop', 'Spark', 'ETL', 'SQL']",2025-06-12 14:15:17
DBA DATA Engineer || 12 Lakhs CTC,Robotics Technologies,6 - 10 years,12 Lacs P.A.,['Hyderabad( Banjara hills )'],"Dear Candidate,\nWe are seeking a skilled and experienced DBA Data Engineer to join our growing data team. The ideal candidate will play a key role in designing, implementing, and maintaining our databases and data pipeline architecture. You will collaborate with software engineers, data analysts, and DevOps teams to ensure efficient data flow, data integrity, and optimal database performance across all systems. This role requires a strong foundation in database administration, SQL performance tuning, data modeling, and experience with both on-prem and cloud-based environments.\n\nRequirements:\nBachelors degree in Computer Science, Information Systems, or a related field.\n6+ years of experience in database administration and data engineering.\nProven expertise in RDBMS (Oracle, MySQL, and PostgreSQL) and NoSQL systems (MongoDB, Cassandra).\nExperience managing databases in cloud environments (AWS, Azure, or GCP).\nProficiency in ETL processes and tools (e.g., Apache NiFi, Talend, Informatica, AWS Glue).\nStrong experience with scripting languages such as Python, Bash, or PowerShell.\n\nDBA Data Engineer Roles & Responsibilities:\nDesign and maintain scalable and high-performance database architectures.\nMonitor and optimize database performance using tools like CloudWatch, Oracle Enterprise Manager, pgAdmin, Mongo Compass, or Dynatrace.\nDevelop and manage ETL/ELT pipelines to support business intelligence and analytics.\nEnsure data integrity and security through best practices in backup, recovery, and encryption.\nAutomate regular database maintenance tasks using scripting and scheduled jobs.\nImplement high availability, failover, and disaster recovery strategies.\nConduct performance tuning of queries, stored procedures, indexes, and table structures.\nCollaborate with DevOps to automate database deployments using CI/CD and IaC tools (e.g., Terraform, AWS CloudFormation).\nDesign and implement data models, including star/snowflake schemas for data warehousing.\nDocument data flows, data dictionaries, and database configurations.\nManage user access and security policies using IAM roles or database-native permissions.\nAnalyze existing data systems and propose modernization or migration plans (on-prem to cloud, SQL to NoSQL, etc.).\nUse AWS RDS, Amazon Redshift, Azure SQL Database, or Google BigQuery as needed.\nStay up-to-date with emerging database technologies and make recommendations.\n\nMust-Have Skills:\nDeep knowledge of SQL and database performance tuning.\nHands-on experience with database migrations and replication strategies.\nFamiliarity with data governance, data quality, and compliance frameworks (GDPR, HIPAA, etc.).\nStrong problem-solving and troubleshooting skills.\nExperience with data streaming platforms such as Apache Kafka, AWS Kinesis, or Apache Flink is a plus.\nExperience with data lake and data warehouse architectures.\nExcellent communication and documentation skills.\n\nSoft Skills:\nProblem-Solving: Ability to analyze complex problems and develop effective solutions.\nCommunication Skills: Strong verbal and written communication skills to effectively collaborate with cross-functional teams.\nAnalytical Thinking: Ability to think critically and analytically to solve technical challenges.\nTime Management: Capable of managing multiple tasks and deadlines in a fast-paced environment.\nAdaptability: Ability to quickly learn and adapt to new technologies and methodologies.\n\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Database Administration', 'Database Migration', 'Dba Skills', 'High Availability', 'Db Administration', 'Hadr', 'Database Security', 'Disaster Recovery', 'Dr Testing', 'DR', 'Luw', 'Db Upgrade', 'Brtools', 'UDDI', 'Os Migration', 'Dbase', 'DBMS', 'IBM DB2', 'Db Migration', 'Disaster Recovery Planning', 'Db Dba', 'Backup And Recovery']",2025-06-12 14:15:20
Data Analytics Mgr,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will report to the Organizational Planning Analytics & Insights Procurement & Sourcing Lead, you will support Amgens Tech & Workforce Strategy by applying business analytics and change leadership skills to drive insights that impact resource allocation and sourcing strategy.\n\nYour responsibilities include dashboard development, ad-hoc reporting, business partnering & engagement, and financial baselining. This role supports organizational change and enables the development of an integrated approach to global sourcing and financial planning.\n\nReporting to the Organizational Planning Analytics & Insights Procurement & Sourcing Lead, you will support Amgens Tech & Workforce Strategy by applying business analytics and change management skills to drive insights that impact resource allocation and sourcing strategy.\n\nYour responsibilities include dashboard development, ad-hoc reporting, business partnering & engagement, and financial baselining. This role supports change management and enables the development of an integrated approach to global sourcing and financial planning.\n\nRoles & Responsibilities:\nAddressing business challenges through process evaluation and insight generation.\nDevelop insights with a strong focus on Tableau and Power BI dashboard creation, as well as PowerPoint presentations.\nGuide data analysts and data engineers on standard methodologies for building data pipelines to support dashboards and other business objectives.\nConduct ad hoc analyses of FP&A and sourcing/procurement data.\nAddressing business challenges through process evaluation and insight generation.\nDevelop insights with a strong focus on Tableau and Power BI dashboard creation, as well as PowerPoint presentations.\nGuide data analysts and data engineers on standard methodologies for building data pipelines to support dashboards and other business objectives.\nConduct ad hoc analyses of FP&A and sourcing/procurement data.\nWhat we expect of you\n\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nMasters degree and 4 to 6 years of applicable experience in business analysis (finance analysis, data analysis, sourcing analysis, or similar experience OR\nBachelors degree and 6 to 8 years of applicable experience in business analysis (finance analysis, data analysis, sourcing analysis, or similar experience OR\nDiploma and 10 to 12 years of applicable experience in business analysis (finance analysis, data analysis, sourcing analysis, or similar experience\nPreferred Qualifications:\nMasters degree in data science, business, statistics, data mining, applied mathematics, business analytics, engineering, computer science, or a related field\n4 years of relevant experience in data science, data analytics, consulting, and/or financial planning & analysis.\nA keen eye for design, with the ability to craft engaging PowerPoint decks and develop compelling Power BI and Tableau dashboards.\nProven expertise in statistical/mathematical modeling and working with structured/unstructured data.\nExperience with procurement, sourcing, and/or financial planning data.\nSkilled in automating data workflows using tools like Tableau, Python, R, Alteryx, and PowerApps.\nKnowledge of global finance systems, Procurement, and sourcing operations.\nExperience with data analysis, budgeting, forecasting, and strategic planning in the Bio-Pharmaceutical or biotech industry.\nGrowing in a start-up environment, building a data-driven transformation capability.\nUnderstanding of the Bio-Pharmaceutical and biotech industry trends and operations.\nProven ability to engage with cross-functional business leaders to align data strategies with corporate objectives, redefining complex data insights into actionable strategies.\nFlexible work models, including remote work arrangements, where possible\n\nAs we work to develop treatments that deal with others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, well support your journey every step of the way.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'data analytics', 'data science', 'mathematical modeling', 'financial planning', 'financial planning and analysis', 'statistics']",2025-06-12 14:15:22
"Data Engineer, AVP",NatWest Markets,16 - 18 years,Not Disclosed,['Gurugram'],"Join us as a Data Engineer\nWe re looking for someone to build effortless, digital first customer experiences to help simplify our organisation and keep our data safe and secure\nDay-to-day, you ll develop innovative, data-driven solutions through data pipelines, modelling and ETL design while inspiring to be commercially successful through insights\nIf you re ready for a new challenge, and want to bring a competitive edge to your career profile by delivering streaming data ingestions, this could be the role for you\nWere offering this role at assistant vice president level\nWhat you ll do\nYour daily responsibilities will include you developing a comprehensive knowledge of our data structures and metrics, advocating for change when needed for product development. You ll also provide transformation solutions and carry out complex data extractions.\nWe ll expect you to develop a clear understanding of data platform cost levels to build cost-effective and strategic solutions. You ll also source new data by using the most appropriate tooling before integrating it into the overall solution to deliver it to our customers.\nYou ll also be responsible for:\nDriving customer value by understanding complex business problems and requirements to correctly apply the most appropriate and reusable tools to build data solutions\nParticipating in the data engineering community to deliver opportunities to support our strategic direction\nCarrying out complex data engineering tasks to build a scalable data architecture and the transformation of data to make it usable to analysts and data scientists\nBuilding advanced automation of data engineering pipelines through the removal of manual stages\nLeading on the planning and design of complex products and providing guidance to colleagues and the wider team when required\nThe skills you ll need\nTo be successful in this role, you ll have an understanding of data usage and dependencies with wider teams and the end customer. You ll also have experience of extracting value and features from large scale data.\nWe ll expect you to have experience of ETL technical design, data quality testing, cleansing and monitoring, data sourcing, exploration and analysis, and data warehousing and data modelling capabilities.\nYou ll also need:\nExperience of using programming languages alongside knowledge of data and software engineering fundamentals\nGood knowledge of modern code development practices\nGreat communication skills with the ability to proactively engage with a range of stakeholders\nHours\n45\nJob Posting Closing Date:\n16/06/2025",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Usage', 'Technical design', 'Programming', 'Data structures', 'Data quality', 'Assistant Vice President', 'Data warehousing', 'Monitoring', 'Data architecture']",2025-06-12 14:15:25
Data Engineer - R&D Data Catalyst Team,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role, you will be responsible for the end-to-end development of an enterprise analytics and data mastering solution using Databricks and Power BI. This role requires expertise in both data architecture and analytics, with the ability to create scalable, reliable, and impactful enterprise solutions that research cohort-building and advanced research pipeline. The ideal candidate will have experience creating and surfacing large unified repositories of human data, based on integrations from multiple repositories and solutions, and be extraordinarily skilled with data analysis and profiling.\nYou will collaborate closely with key customers, product team members, and related IT teams, to design and implement data models, integrate data from various sources, and ensure best practices for data governance and security. The ideal candidate will have a good background in data warehousing, ETL, Databricks, Power BI, and enterprise data mastering.\nDesign and build scalable enterprise analytics solutions using Databricks, Power BI, and other modern data tools.\nLeverage data virtualization, ETL, and semantic layers to balance need for unification, performance, and data transformation with goal to reduce data proliferation\nBreak down features into work that aligns with the architectural direction runway\nParticipate hands-on in pilots and proofs-of-concept for new patterns\nCreate robust documentation from data analysis and profiling, and proposed designs and data logic\nDevelop advanced sql queries to profile, and unify data\nDevelop data processing code in sql, along with semantic views to prepare data for reporting\nDevelop PowerBI Models and reporting packages\nDesign robust data models, and processing layers, that support both analytical processing and operational reporting needs.\nDesign and develop solutions based on best practices for data governance, security, and compliance within Databricks and Power BI environments.\nEnsure the integration of data systems with other enterprise applications, creating seamless data flows across platforms.\nDevelop and maintain Power BI solutions, ensuring data models and reports are optimized for performance and scalability.\nCollaborate with key customers to define data requirements, functional specifications, and project goals.\nContinuously evaluate and adopt new technologies and methodologies to enhance the architecture and performance of data solutions.\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The R&D Data Catalyst Team is responsible for building Data Searching, Cohort Building, and Knowledge Management tools that provide the Amgen scientific community with visibility to Amgens wealth of human datasets, projects and study histories, and knowledge over various scientific findings. These solutions are pivotal tools in Amgens goal to accelerate the speed of discovery, and speed to market of advanced precision medications.\nBasic Qualifications:\nMasters degree and 1 to 3 years of Data Engineering experience OR\nBachelors degree and 3 to 5 years of Data Engineering experience OR\nDiploma and 7 to 9 years of Data Engineering experience\nMust Have Skills:\nMinimum of 3 years of hands-on experience with BI solutions (Preferable Power BI or Business Objects) including report development, dashboard creation, and optimization.\nMinimum of 3 years of hands-on experience building Change-data-capture (CDC) ETL pipelines, data warehouse design and build, and enterprise-level data management.\nHands-on experience with Databricks, including data engineering, optimization, and analytics workloads.\nDeep understanding of Power BI, including model design, DAX, and Power Query.\nProven experience designing and implementing data mastering solutions and data governance frameworks.\nExpertise in cloud platforms (AWS), data lakes, and data warehouses.\nStrong knowledge of ETL processes, data pipelines, and integration technologies.\nGood communication and collaboration skills to work with cross-functional teams and senior leadership.\nAbility to assess business needs and design solutions that align with organizational goals.\nExceptional hands-on capabilities with data profiling, data transformation, data mastering\nSuccess in mentoring and training team members\nGood to Have Skills:\nITIL Foundation or other relevant certifications (preferred)\nSAFe Agile Practitioner (6.0)\nMicrosoft Certified: Data Analyst Associate (Power BI) or related certification.\nDatabricks Certified Professional or similar certification.\nSoft Skills:\nExcellent analytical and troubleshooting skills\nDeep intellectual curiosity\nThe highest degree of initiative and self-motivation\nStrong verbal and written communication skills, including presentation to varied audiences of complex technical/business topics\nConfidence technical leader\nAbility to work effectively with global, remote teams, specifically including using of tools and artifacts to assure clear and efficient collaboration across time zones\nAbility to handle multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong problem solving, analytical skills;\nAbility to learn quickly and retain and synthesize complex information from diverse sources.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'data management', 'Power BI', 'data governance', 'data warehousing', 'Databricks', 'ETL', 'AWS']",2025-06-12 14:15:27
Data Engineer,Atyeti,2 - 4 years,Not Disclosed,['Pune'],"Role & responsibilities\n\nDevelop and Maintain Data Pipelines: Design, develop, and manage scalable ETL pipelines to process large datasets using PySpark, Databricks, and other big data technologies.\nData Integration and Transformation: Work with various structured and unstructured data sources to build efficient data workflows and integrate them into a central data warehouse.\nCollaborate with Data Scientists & Analysts: Work closely with the data science and business intelligence teams to ensure the right data is available for advanced analytics, machine learning, and reporting.",,,,"['Azure Synapse', 'Pyspark', 'ETL', 'Python']",2025-06-12 14:15:30
Data Science Lead,Algoleap Technologies,10 - 15 years,Not Disclosed,['Hyderabad'],"As we build our Data Science Center of Excellence (CoE), we are looking for an entrepreneurial and technically strong Data Science Lead who can lay the foundation for a high-performing team. You will work directly with stakeholders across multiple business units to define use cases, lead model development, and ensure successful deployment and value realization.\n\nKey Responsibilities:\nServe as the technical and strategic lead for the Data Science CoE.",,,,"['customer analytics', 'Usage', 'data science', 'GCP', 'Machine learning', 'model development', 'Deployment', 'Stakeholder management', 'SQL', 'Python']",2025-06-12 14:15:32
Assoc. Data Engineer - R&D Precision Medicine Team,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nThe R&D Precision Medicine team is responsible for Data Standardization, Data Searching, Cohort Building, and Knowledge Management tools that provide the Amgen scientific community with access to Amgens wealth of human datasets, projects and study histories, and knowledge over various scientific findings. These data include clinical data, omics, and images. These solutions are pivotal tools in Amgens goal to accelerate the speed of discovery, and speed to market of advanced precision medications.\n\nThe Data Engineer will be responsible for full stack development of enterprise analytics and data mastering solutions leveraging Databricks and Power BI. This role requires expertise in both data architecture and analytics, with the ability to create scalable, reliable, and high-performing enterprise solutions that support research cohort-building and advanced AI pipelines. The ideal candidate will have experience creating and surfacing large unified repositories of human data, based on integrations from multiple repositories and solutions, and be exceptionally skilled with data analysis and profiling.\n\nYou will collaborate closely with partners, product team members, and related IT teams, to design and implement data models, integrate data from various sources, and ensure best practices for data governance and security. The ideal candidate will have a solid background in data warehousing, ETL, Databricks, Power BI, and enterprise data mastering.\n\nRoles & Responsibilities\nDesign and build scalable enterprise analytics solutions using Databricks, Power BI, and other modern data management tools.\nLeverage data virtualization, ETL, and semantic layers to balance need for unification, performance, and data transformation with goal to reduce data proliferation\nBreak down features into work that aligns with the architectural direction runway\nParticipate hands-on in pilots and proofs-of-concept for new patterns\nCreate robust documentation from data analysis and profiling, and proposed designs and data logic\nDevelop advanced sql queries to profile, and unify data\nDevelop data processing code in sql, along with semantic views to prepare data for reporting\nDevelop PowerBI Models and reporting packages\nDesign robust data models, and processing layers, that support both analytical processing and operational reporting needs.\nDesign and develop solutions based on best practices for data governance, security, and compliance within Databricks and Power BI environments.\nEnsure the integration of data systems with other enterprise applications, creating seamless data flows across platforms.\nDevelop and maintain Power BI solutions, ensuring data models and reports are optimized for performance and scalability.\nCollaborate with partners to define data requirements, functional specifications, and project goals.\nContinuously evaluate and adopt new technologies and methodologies to enhance the architecture and performance of data solutions.\n\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The professional we seek is someone with these qualifications.\n\nBasic Qualifications:\nMasters degree with 1 to 3 years of experience in Data Engineering OR\nBachelors degree with 1 to 3 years of experience in Data Engineering\nMust-Have\n\nSkills:\nMinimum of 1 year of hands-on experience with BI solutions (Preferrable Power BI or Business Objects) including report development, dashboard creation, and optimization.\nMinimum of 1 year of hands-on experience building Change-data-capture (CDC) ETL pipelines, data warehouse design and build, and enterprise-level data management.\nHands-on experience with Databricks, including data engineering, optimization, and analytics workloads.\nExperience using cloud platforms (AWS), data lakes, and data warehouses.\nWorking knowledge of ETL processes, data pipelines, and integration technologies.\nGood communication and collaboration skills to work with cross-functional teams and senior leadership.\nAbility to assess business needs and design solutions that align with organizational goals.\nExceptional hands-on capabilities with data profiling and data anlysis\nGood-to-Have\n\nSkills:\nExperience with human data, ideally human healthcare data\nFamiliarity with laboratory testing, patient data from clinical care, HL7, FHIR, and/or clinical trial data management\nProfessional Certifications:\nITIL Foundation or other relevant certifications (preferred)\nSAFe Agile Practitioner (6.0)\nMicrosoft CertifiedData Analyst Associate (Power BI) or related certification.\nDatabricks Certified Professional or similar certification.\nSoft\n\nSkills:\nExcellent analytical and troubleshooting skills\nDeep intellectual curiosity\nHighest degree of initiative and self-motivation\nStrong verbal and written communication skills, including presentation to varied audiences of complex technical/business topics\nConfidence technical leader\nAbility to work effectively with global, virtual teams, specifically including using of tools and artifacts to assure clear and efficient collaboration across time zones\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong problem solving, analytical skills;\nAbility to learn quickly and retain and synthesize complex information from diverse sources",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'data lakes', 'data pipelines', 'ETL processes', 'AWS', 'data warehouses', 'BI solutions']",2025-06-12 14:15:34
Data Engineer,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nAs part of the cybersecurity organization, the Data Engineer is responsible for designing, building, and maintaining data infrastructure to support data-driven decision-making. This role involves working with large datasets, developing reports, executing data governance initiatives, and ensuring data is accessible, reliable, and efficiently managed. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture, ETL processes, and cybersecurity data frameworks.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in design and development of the data pipeline.\nCreate data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nSchedule and manage workflows the ensure pipelines run on schedule and are monitored for failures.\nCollaborate with cross-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nCollaborate with data scientists to develop pipelines that meet dynamic business needs.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\nFunctional Skills:\nBasic Qualifications:\nMasters degree and 1 to 3 years of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience\nPreferred Qualifications:\nHands on experience with data practices, technologies, and platforms, such as Databricks, Python, Gitlab, LucidChart,etc.\nProficiency in data analysis tools (e.g. SQL) and experience with data sourcing tools\nExcellent problem-solving skills and the ability to work with large, complex datasets\nUnderstanding of data governance frameworks, tools, and best practices\nKnowledge of and experience with data standards (FAIR) and protection regulations and compliance requirements (e.g., GDPR, CCPA)\nGood-to-Have Skills:\nExperience with ETL tools and various Python packages related to data processing, machine learning model development\nStrong understanding of data modeling, data warehousing, and data integration concepts\nKnowledge of Python/R, Databricks, cloud data platforms\nExperience working in Product team's environment\nExperience working in an Agile environment\nProfessional Certifications:\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data engineering', 'data security', 'Agile', 'cloud data platforms', 'Databricks', 'data governance frameworks', 'ETL', 'AWS', 'SQL', 'Python']",2025-06-12 14:15:36
"Quant Data Specialist, Aladdin Financial Engineering - Associate",Primetrace Technologies,3 - 6 years,Not Disclosed,['Gurugram'],"About this role\nAbout Aladdin Financial Engineering (AFE):\nJoin a diverse and collaborative team of over 3 00 modelers and technologists in Aladdin Financial Engineering (AFE) within BlackRock Solutions, the business responsible for the research and development of Aladdin s financial models. This group is also accountable for analytics production, enhancing the infrastructure platform and delivering analytics content to portfolio and risk management professionals (both within BlackRock and across the Aladdin client community). The models developed and supported by AFE span a wide array of financial products covering equities, fixed income, commodities, derivatives, and private markets. AFE provides investment insights that range from an analysis of cash flows on a single bond, to the overall financial risk associated with an entire portfolio, balance sheet, or enterprise.\nRole Description:\nWe are looking for a person to join the Advanced Data Analytics team with AFE Single Security . Advanced Data Analytics is a team of Quantitative Data and Product Specialists, focused on delivering Single Security Data Content, Governance and Product Solutions and Research Platform. The team leverages data, cloud, and emerging technologies in building an innovative data platform, with the focus on business and research use cases in the S ingle S ecurity space. The team uses various statistical/mathematical methodologies to derive insights and generate content to help develop predictive models, clustering, and classification solutions and enable Governance . The team works on Mortgage, Structured & Credit Products.\nWe are looking for a person to help build and expand Data & Analytics Content in the Credit space . The person will be responsible for building, enhancing, and maintaining the Credit Content Suite . The person will work on the below -\nCredit Derived Data Content\nModel & Data Governance\nCredit Model & Analytics\nExperience\nExperience on Scala\nKnowledge of ETL, data curation and analytical jobs using distributed computing framework with Spark\nKnowledge and Experience of working with large enterprise databases like Snowflake, Cassandra & Cloud manged services like Dataproc , Databricks\nKnowledge of financial instruments like Corporate Bonds, Derivatives etc.\nKnowledge of regression methodologies\nAptitude for design and building tools for D ata Governance\nPython knowledge is a plus\nQualifications\nBachelors / masters in computer science with a major in Math, Econ, or related field\n3 - 6 years of relevant experience\nOur benefits\n\n.\nOur hybrid work model\n.\nAbout BlackRock\n.\nThis mission would not be possible without our smartest investment - the one we make in our employees. It s why we re dedicated to creating an environment where our colleagues feel welcomed, valued and supported with networks, benefits and development opportunities to help them thrive.\nFor additional information on BlackRock, please visit @blackrock | Twitter: @blackrock | LinkedIn: www.linkedin.com / company / blackrock\nBlackRock is proud to be an Equal Opportunity Employer. We evaluate qualified applicants without regard to age, disability, family status, gender identity, race, religion, sex, sexual orientation and other protected attributes at law.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Analytical', 'Fixed income', 'Financial risk', 'Finance', 'Healthcare', 'Data analytics', 'Risk management', 'Analytics', 'Balance Sheet', 'Financial engineering']",2025-06-12 14:15:39
Manager Data Engineer – Research Data and Analytics,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will create and develop data lake solutions for scientific data that drive business decisions for Research. You will build scalable and high-performance data engineering solutions for large scientific datasets and collaborate with Research collaborators. You will also provide technical leadership to junior team members. The ideal candidate possesses experience in the pharmaceutical or biotech industry, demonstrates deep technical skills, is proficient with big data technologies, and has a deep understanding of data architecture and ETL processes.\nRoles & Responsibilities:\nLead, manage, and mentor a high-performing team of data engineers\nDesign, develop, and implement data pipelines, ETL processes, and data integration solutions\nTake ownership of data pipeline projects from inception to deployment, manage scope, timelines, and risks\nDevelop and maintain data models for biopharma scientific data, data dictionaries, and other documentation to ensure data accuracy and consistency\nOptimize large datasets for query performance\nCollaborate with global multi-functional teams including research scientists to understand data requirements and design solutions that meet business needs\nImplement data security and privacy measures to protect sensitive data\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions\nCollaborate with Data Architects, Business SMEs, Software Engineers and Data Scientists to design and develop end-to-end data pipelines to meet fast paced business needs across geographic regions\nIdentify and resolve data-related challenges\nAdhere to best practices for coding, testing, and designing reusable code/component\nExplore new tools and technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The [vital attribute] professional we seek is a [type of person] with these qualifications.\nBasic Qualifications:\nDoctorate Degree OR\nMasters degree with 4 - 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 6 - 8 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 10 - 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nPreferred Qualifications:\n3+ years of experience in implementing and supporting biopharma scientific research data analytics (software platforms)\n\n\nFunctional Skills:\nMust-Have Skills:\nProficiency in SQL and Python for data engineering, test automation frameworks (pytest), and scripting tasks\nHands on experience with big data technologies and platforms, such as Databricks, Apache Spark (PySpark, SparkSQL), workflow orchestration, performance tuning on big data processing\nExcellent problem-solving skills and the ability to work with large, complex datasets\nAble to engage with business collaborators and mentor team to develop data pipelines and data models\n\n\nGood-to-Have Skills:\nA passion for tackling complex challenges in drug discovery with technology and data\nGood understanding of data modeling, data warehousing, and data integration concepts\nGood experience using RDBMS (e.g. Oracle, MySQL, SQL server, PostgreSQL)\nKnowledge of cloud data platforms (AWS preferred)\nExperience with data visualization tools (e.g. Dash, Plotly, Spotfire)\nExperience with diagramming and collaboration tools such as Miro, Lucidchart or similar tools for process mapping and brainstorming\nExperience writing and maintaining technical documentation in Confluence\nUnderstanding of data governance frameworks, tools, and best practices\n\n\nProfessional Certifications:\nDatabricks Certified Data Engineer Professional preferred\n\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nDemonstrated presentation skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Spotfire', 'PySpark', 'PostgreSQL', 'Plotly', 'SparkSQL', 'SQL server', 'SQL', 'process mapping', 'Dash', 'MySQL', 'ETL', 'Oracle', 'data governance frameworks', 'Python']",2025-06-12 14:15:41
Data Science Professional,Algoleap Technologies,6 - 11 years,Not Disclosed,['Hyderabad'],"Job_Description"":""\nJob Title: Data Science CoE\nLocation: Hyderabad, India (Hybrid)\nExperience: 6+ years\nRole Type: Full-time\nStart Date : Immediate\nAbout the Role:\nAs we build our Data Science Center of Excellence (CoE), we are looking for an entrepreneurial and technically strong Data Science Lead who can lay the foundation for a high-performing team. You will work directly with stakeholders across multiple business units to define use cases, lead model development, and ensure successful deployment and value realization.",,,,"['customer analytics', 'Usage', 'data science', 'GCP', 'Machine learning', 'model development', 'Deployment', 'Stakeholder management', 'SQL', 'Python']",2025-06-12 14:15:44
Big Data Developer,Techstar Group,7 - 10 years,Not Disclosed,['Hyderabad'],"Responsibilities of the Candidate :\n\n- Be responsible for the design and development of big data solutions. Partner with domain experts, product managers, analysts, and data scientists to develop Big Data pipelines in Hadoop\n\n- Be responsible for moving all legacy workloads to a cloud platform\n\n- Work with data scientists to build Client pipelines using heterogeneous sources and provide engineering services for data PySpark science applications\n\n- Ensure automation through CI/CD across platforms both in cloud and on-premises\n\n- Define needs around maintainability, testability, performance, security, quality, and usability for the data platform\n\n- Drive implementation, consistent patterns, reusable components, and coding standards for data engineering processes\n\n- Convert SAS-based pipelines into languages like PySpark, and Scala to execute on Hadoop and non-Hadoop ecosystems\n\n- Tune Big data applications on Hadoop and non-Hadoop platforms for optimal performance\n\n- Apply an in-depth understanding of how data analytics collectively integrate within the sub-function as well as coordinate and contribute to the objectives of the entire function.\n\n- Produce a detailed analysis of issues where the best course of action is not evident from the information available, but actions must be recommended/taken.\n\n- Assess risk when business decisions are made, demonstrating particular consideration for the firm's reputation and safeguarding Citigroup, its clients, and assets, by driving compliance with applicable laws, rules, and regulations, adhering to Policy, applying sound ethical judgment regarding personal behavior, conduct, and business practices, and escalating, managing and reporting control issues with transparency\n\nRequirements :\n\n- 6+ years of total IT experience\n\n- 3+ years of experience with Hadoop (Cloudera)/big data technologies\n\n- Knowledge of the Hadoop ecosystem and Big Data technologies Hands-on experience with the Hadoop eco-system (HDFS, MapReduce, Hive, Pig, Impala, Spark, Kafka, Kudu, Solr)\n\n- Experience in designing and developing Data Pipelines for Data Ingestion or Transformation using Java Scala or Python.\n\n- Experience with Spark programming (Pyspark, Scala, or Java)\n\n- Hands-on experience with Python/Pyspark/Scala and basic libraries for machine learning is required.\n\n- Proficient in programming in Java or Python with prior Apache Beam/Spark experience a plus.\n\n- Hand on experience in CI/CD, Scheduling and Scripting\n\n- Ensure automation through CI/CD across platforms both in cloud and on-premises\n\n- System level understanding - Data structures, algorithms, distributed storage & compute\n\n- Can-do attitude on solving complex business problems, good interpersonal and teamwork skills",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Big Data', 'Hive', 'Data Engineering', 'Data Pipeline', 'PySpark', 'Hadoop', 'Kafka', 'HDFS', 'Spark', 'Python']",2025-06-12 14:15:46
Data Engineer,Databeat,3 - 7 years,Not Disclosed,['Hyderabad( Rai Durg )'],"Experience Required: 3+ years\n\nTechnical knowledge: AWS, Python, SQL, S3, EC2, Glue, Athena, Lambda, DynamoDB, RedShift, Step Functions, Cloud Formation, CI/CD Pipelines, Github, EMR, RDS,AWS Lake Formation, GitLab, Jenkins and AWS CodePipeline.\n\n\n\nRole Summary: As a Senior Data Engineer,with over 3 years of expertise in Python, PySpark, SQL to design, develop and optimize complex data pipelines, support data modeling, and contribute to the architecture that supports big data processing and analytics to cutting-edge cloud solutions that drive business growth. You will lead the design and implementation of scalable, high-performance data solutions on AWS and mentor junior team members.This role demands a deep understanding of AWS services, big data tools, and complex architectures to support large-scale data processing and advanced analytics.\nKey Responsibilities:\nDesign and develop robust, scalable data pipelines using AWS services, Python, PySpark, and SQL that integrate seamlessly with the broader data and product ecosystem.\nLead the migration of legacy data warehouses and data marts to AWS cloud-based data lake and data warehouse solutions.\nOptimize data processing and storage for performance and cost.\nImplement data security and compliance best practices, in collaboration with the IT security team.\nBuild flexible and scalable systems to handle the growing demands of real-time analytics and big data processing.\nWork closely with data scientists and analysts to support their data needs and assist in building complex queries and data analysis pipelines.\nCollaborate with cross-functional teams to understand their data needs and translate them into technical requirements.\nContinuously evaluate new technologies and AWS services to enhance data capabilities and performance.\nCreate and maintain comprehensive documentation of data pipelines, architectures, and workflows.\nParticipate in code reviews and ensure that all solutions are aligned to pre-defined architectural specifications.\nPresent findings to executive leadership and recommend data-driven strategies for business growth.\nCommunicate effectively with different levels of management to gather use cases/requirements and provide designs that cater to those stakeholders.\nHandle clients in multiple industries at the same time, balancing their unique needs.\nProvide mentoring and guidance to junior data engineers and team members.\n\n\n\nRequirements:\n3+ years of experience in a data engineering role with a strong focus on AWS, Python, PySpark, Hive, and SQL.\nProven experience in designing and delivering large-scale data warehousing and data processing solutions.\nLead the design and implementation of complex, scalable data pipelines using AWS services such as S3, EC2, EMR, RDS, Redshift, Glue, Lambda, Athena, and AWS Lake Formation.\nBachelor's or Masters degree in Computer Science, Engineering, or a related technical field.\nDeep knowledge of big data technologies and ETL tools, such as Apache Spark, PySpark, Hadoop, Kafka, and Spark Streaming.\nImplement data architecture patterns, including event-driven pipelines, Lambda architectures, and data lakes.\nIncorporate modern tools like Databricks, Airflow, and Terraform for orchestration and infrastructure as code.\nImplement CI/CD using GitLab, Jenkins, and AWS CodePipeline.\nEnsure data security, governance, and compliance by leveraging tools such as IAM, KMS, and AWS CloudTrail.\nMentor junior engineers, fostering a culture of continuous learning and improvement.\nExcellent problem-solving and analytical skills, with a strategic mindset.\nStrong communication and leadership skills, with the ability to influence stakeholders at all levels.\nAbility to work independently as well as part of a team in a fast-paced environment.\nAdvanced data visualization skills and the ability to present complex data in a clear and concise manner.\nExcellent communication skills, both written and verbal, to collaborate effectively across teams and levels.\n\nPreferred Skills:\nExperience with Databricks, Snowflake, and machine learning pipelines.\nExposure to real-time data streaming technologies and architectures.\nFamiliarity with containerization and serverless computing (Docker, Kubernetes, AWS Lambda).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Aws Glue', 'SQL', 'Data Pipeline', 'Python', 'Amazon Ec2', 'Data Engineering', 'Data Bricks', 'Aws Lambda', 'Amazon Redshift', 'Azure Cloud', 'Data Lake', 'Data Modeling', 'Athena']",2025-06-12 14:15:48
Job opening For Data Warehouse + ADF + ETL,bct,3 - 6 years,Not Disclosed,['Pune'],"Greetings of the Day !!!\n\nWe have job opening for Data Warehouse + ADF + ETL with one of our Client .If you are interested for this role , kindly share update resume along with below details in this email id : shaswati.m@bct-consulting.com\n\nJob Description:\nSenior Data Engineer\nAs a Senior Data Engineer, you will support the European World Area using the Windows & Azure suite of Analytics & Data platforms. The focus of the role is on the technical aspects and implementation of data gathering, integration and database design.\nWe look forward to seeing your application!\nIn This Role, Your Responsibilities Will Be:\nData Ingestion and Integration: Collaborate with Product Owners and analysts to understand data requirements & design, develop, and maintain data pipelines for ingesting, transforming, and integrating data from various sources into Azure Data Services.\nMigration of existing ETL packages: Migrate existing SSIS packages to Synapse pipelines\nData Modelling: Assist in designing and implementing data models, data warehouses, and databases in Azure Synapse Analytics, Azure Data Lake Storage, and other Azure services.\nData Transformation: Develop ETL (Extract, Transform, Load) processes using SQL Server Integration Services (SSIS), Azure Synapse Pipelines, or other relevant tools to prepare data for analysis and reporting.\nData Quality and Governance: Implement data quality checks and data governance practices to ensure the accuracy, consistency, and security of data assets.\nMonitoring and Optimization: Monitor and optimize data pipelines and workflows for performance, scalability, and cost efficiency.\nDocumentation: Maintain comprehensive documentation of processes, including data lineage, data dictionaries, and pipeline schedules.\nCollaboration: Work closely with cross-functional teams, including data analysts, data scientists, and business stakeholders, to understand their data needs and deliver solutions accordingly.\nAzure Services: Stay updated on Azure data services and best practices to recommend and implement improvements in our data architecture and processes\nFor This Role, You Will Need:\n3-5 years of experience in Data Warehousing with On-Premises or Cloud technologies\nStrong practical experience of Synapse pipelines / ADF.\nStrong practical experience of developing ETL packages using SSIS.\nStrong practical experience with T-SQL or any variant from other RDBMS.\nGraduate degree educated in computer science or a relevant subject.\nStrong analytical and problem-solving skills.\nStrong communication skills in dealing with internal customers from a range of functional areas.\nWillingness to work flexible working hours according to project requirements.\nTechnical documentation skills.\nFluent in English.\nPreferred Qualifications that Set You Apart:\nOracle PL/SQL.\nExperience in working on Azure Services like Azure Synapse Analytics, Azure Data Lake.\nWorking experience with Azure DevOps paired with knowledge of Agile and/or Scrum methods of delivery.\nLanguages: French, Italian, or Spanish would be an advantage.\nAgile certification.\nThanks,\nShaswati",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['ADF', 'ETL', 'SSIS', 'Data ware house']",2025-06-12 14:15:51
MDM Associate Data Engineer,Amgen Inc,1 - 4 years,Not Disclosed,['Hyderabad'],"We are seeking an MDM Associate Data Engineerwith 25 years of experience to support and enhance our enterprise MDM (Master Data Management) platforms using Informatica/Reltio. This role is critical in delivering high-quality master data solutions across the organization, utilizing modern tools like Databricks and AWS to drive insights and ensure data reliability. The ideal candidate will have strong SQL, data profiling, and experience working with cross-functional teams in a pharma environment.To succeed in this role, the candidate must have strong data engineering experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have data engineering experience on technologies like (SQL, Python, PySpark, Databricks, AWS etc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nAnalyze and manage customer master data using Reltio or Informatica MDM solutions.\nPerform advanced SQL queries and data analysis to validate and ensure master data integrity.\nLeverage Python, PySpark, and Databricks for scalable data processing and automation.\nCollaborate with business and data engineering teams for continuous improvement in MDM solutions.\nImplement data stewardship processes and workflows, including approval and DCR mechanisms.\nUtilize AWS cloud services for data storage and compute processes related to MDM.\nContribute to metadata and data modeling activities.\nTrack and manage data issues using tools such as JIRA and document processes in Confluence.\nApply Life Sciences/Pharma industry context to ensure data standards and compliance.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\nAdvanced SQL expertise and data wrangling.\nStrong experience in Python and PySpark for data transformation workflows.\nStrong experience with Databricks and AWS architecture.\nMust have knowledge of MDM, data governance, stewardship, and profiling practices.\nIn addition to above, candidates having experience with Informatica or Reltio MDM platforms will be preferred.\nGood-to-Have Skills:\nExperience with IDQ, data modeling and approval workflow/DCR.\nBackground in Life Sciences/Pharma industries.\nFamiliarity with project tools like JIRA and Confluence.\nStrong grip on data engineering concepts.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL, Python, Databricks)\nAny cloud certification (AWS or AZURE)\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM', 'PySpark', 'AWS architecture', 'Jira', 'Reltio', 'SQL', 'Informatica MDM', 'data modeling', 'Confluence', 'IDQ', 'Databricks', 'data stewardship processes', 'Python']",2025-06-12 14:15:53
Lead Data Engineer - Azure,Blend360 India,7 - 12 years,Not Disclosed,['Hyderabad'],"As a Sr Data Engineer, your role is to spearhead the data engineering teams and elevate the team to the next level! You will be responsible for laying out the architecture of the new project as well as selecting the tech stack associated with it. You will plan out the development cycles deploying AGILE if possible and create the foundations for good data stewardship with our new data products!\nYou will also set up a solid code framework that needs to be built to purpose yet have enough flexibility to adapt to new business use cases tough but rewarding challenge!\n\nResponsibilities\nCollaborate with several stakeholders to deeply understand the needs of data practitioners to deliver at scale\nLead Data Engineers to define, build and maintain Data Platform\nWork on building Data Lake in Azure Fabric processing data from multiple sources\nMigrating existing data store from Azure Synapse to Azure Fabric\nImplement data governance and access control\nDrive development effort End-to-End for on-time delivery of high-quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards.\nPresent technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner.\nFurther develop critical initiatives, such as Data Discovery, Data Lineage and Data Quality\nLeading team and Mentor junior resources\nHelp your team members grow in their role and achieve their career aspirations\nBuild data systems, pipelines, analytical tools and programs\nConduct complex data analysis and report on results\n\n\n7+ Years of Experience as a data engineer or similar role in Azure Synapses, ADF or\nrelevant exp in Azure Fabric\nDegree in Computer Science, Data Science, Mathematics, IT, or similar field\nMust have experience e",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Data modeling', 'Analytical', 'Agile', 'data governance', 'Data quality', 'Data mining', 'SQL', 'Python']",2025-06-12 14:15:55
Data Engineer IV - Big Data / Spark,Sadup Soft,5 - 7 years,Not Disclosed,['Chennai'],"Must have skills :\n\n- Minimum of 5-7 years of experience in software development, with a focus on Java and infrastructure tools.\n\n- Min 6+ years of experience as a Data Engineer.\n\n- Good Experience in handling Big Data Spark, Hive SQL, BigQuery, SQL.\n\n- Candidate worked on cloud platforms and GCP would be an added advantage.\n\n- Good understanding of Hadoop based ecosystem including hard sequel, HDFS would be very essential.\n\n- Very good professional knowledge of PySpark or using Scala\n\nResponsibilities :\n\n- Collaborate with cross-functional teams such as Data Scientists, Product Partners and Partner Team Developers to identify opportunities for Big Data, Query ( Spark, Hive SQL, BigQuery, SQL ) tuning opportunities that can be solved using machine learning and generative AI.\n\n- Write clean, high-performance, high-quality, maintainable code.\n\n- Design and develop Big Data Engineering Solutions Applications for above ensuring scalability, efficiency, and maintainability of such solutions.\n\nRequirements :\n\n- A Bachelor or Master's degree in Computer Science or a related field.\n\n- Proven experience working as a Big Data & MLOps Engineer, with a focus on Spark, Scala Spark or PySpark, Spark SQL, BigQuery, Python, Google Cloud,.\n\n- Deep understanding and experience in tuning Dataproc, BigQuery, Spark Applications.\n\n- Solid knowledge of software engineering best practices, including version control systems (e.g Git), code reviews, and testing methodologies.\n\n- Strong communication skills to effectively collaborate and present findings to both technical and non-technical stakeholders.\n\n- Proven ability to adapt and learn new technologies and frameworks quickly.\n\n- A proactive mindset with a passion for continuous learning and research.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Big Data', 'Data Engineering', 'BigQuery', 'GCP', 'Spark', 'Machine Learning', 'Python', 'SQL']",2025-06-12 14:15:58
Trainee Risk Advisory Services (Internal Audit),Dpnc Global,0 - 1 years,Not Disclosed,['Noida'],"DPNC Global is looking for Trainee Risk Advisory Services (Internal Audit) to join our dynamic team and embark on a rewarding career journey.\n\nInternal Auditing : Conducting internal audits to evaluate the effectiveness of internal controls, risk management, and governance processes. Reviewing financial statements, operations, and various business processes. Risk Advisory : Providing advisory services related to risk management, helping the organization identify and mitigate potential risks. Developing strategies for risk avoidance, acceptance, reduction, or transfer. Compliance Assessment : Assessing and ensuring compliance with relevant laws, regulations, and internal policies. Identifying areas of non - compliance and recommending corrective actions. Audit Planning : Participating in the planning of audit projects, including defining the scope, objectives, and methodologies. Developing risk - based audit plans. Audit Execution : Performing audit procedures, including testing controls, reviewing documentation, and conducting interviews. Analyzing and interpreting data to draw meaningful conclusions. Report Generation : Preparing detailed and insightful audit reports outlining findings, recommendations, and action plans. Presenting audit reports to management and stakeholders. Continuous Monitoring : Implementing continuous monitoring processes to stay abreast of changes in risk factors and internal control environments. Recommending adjustments to audit plans as needed. Process Improvement : Identifying opportunities for process improvements and operational efficiencies based on audit findings. Collaborating with relevant departments to implement recommended changes. Training and Awareness : Conducting training sessions and awareness programs on risk management and internal controls for employees. Promoting a culture of risk awareness and compliance within the organization. Stakeholder Communication : Communicating with key stakeholders, including senior management and the audit committee. Providing updates on audit progress, findings, and recommendations. Technology Utilization : Leveraging technology tools for data analysis, audit automation, and risk assessment. Keeping up to date with advancements in audit technologies. Fraud Detection : Participating in fraud risk assessments and implementing measures to detect and prevent fraudulent activities.",Industry Type: Management Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Risk advisory', 'Manager Internal Audit', 'IPCC']",2025-06-12 14:16:00
CMA fresher,JTEKT India,0 - 3 years,Not Disclosed,['Gurugram'],"Role & responsibilities\nEnsuring accuracy and timeliness in financial reporting\nSupporting compliance with Ind AS, Companies Act, and other regulations\nAssisting in internal control processes and audit preparedness\nPreparing financial statements and conducting data analysis\nEnsure timely and correct data for Audit\nAssisting and doing internal and Statutory audits\n\n\nPreferred candidate profile\nCMA qualified (mandatory)\nBasic knowledge of Ind AS and regulatory compliance\nProficiency in Oracle ERP\nStrong Excel and analytical skills\nGood communication and attention to detail",Industry Type: Auto Components,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Auditing', 'Statutory Audit', 'Internal Audit', 'Communication Skills', 'Compliance', 'Reporting']",2025-06-12 14:16:02
Research Assistant,Panacorp Software Solutions,0 - 1 years,Not Disclosed,"['Nagercoil', 'Kanyakumari']","Key Responsibilities:\nAssist with the design and execution of research projects\nCollect, organize, and analyze data using various research methodologies\nPrepare and review research documents, reports, and presentations\nConduct literature reviews and summarize relevant research articles\nCollaborate with other team members and researchers to facilitate research activities\nEnsure the quality and accuracy of research data and findings\nSupport researchers in experimental tasks and lab work (if applicable)\nQualifications:\nEducation: BE/B.Tech (Recent Graduates) or relevant degree\nExperience: 0-1+ year(s) of experience in research projects\nSkills:\nStrong analytical and problem-solving skills\nFamiliarity with data analysis software (e.g., MS Excel, MATLAB, Python, or R)\nExcellent communication skills (both verbal and written)\nAbility to work independently as well as part of a collaborative team\nAttention to detail and ability to manage time effectively",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['Python', 'MS Excel', 'R Programming', 'Data Analysis', 'MATLAB', 'research projects']",2025-06-12 14:16:04
Growth Intern,The Peak View Stories,0 - 3 years,Not Disclosed,[],"Assist in developing and implementing growth strategies for the organization.\nConduct market research and analyze data to identify growth opportunities.\nSupport marketing and sales efforts to acquire new customers.\nCollaborate with cross-functional teams to execute growth initiatives.\nMonitor and report on the performance of growth strategies.\nProvide administrative support for growth projects and campaigns.\nStay updated on industry trends and best practices in growth marketing.\n\n\nAnalytics, headlines, SEOif these make your eyes light up, we need you.",Industry Type: Miscellaneous,Department: Research & Development,"Employment Type: Full Time, Permanent","['data analysis', 'business analysis', 'business development', 'teaching', 'market research', 'analysis', 'research', 'sales', 'market analysis', 'brand management', 'marketing', 'secondary research', 'key account management', 'research and development', 'communication skills']",2025-06-12 14:16:06
"Business Intelligence Engineer, RBS ARTS",Amazon,5 - 10 years,Not Disclosed,['Chennai'],"An candidate will be a self-starter who is passionate about discovering and solving complicated problems, learning complex systems, working with numbers, and organizing and communicating data and reports. You will be detail-oriented and organized, capable of handling multiple projects at once, and capable of dealing with ambiguity and rapidly changing priorities. You will have expertise in process optimizations and systems thinking and will be required to engage directly with multiple internal teams to drive business projects/automation for the RBS team. Candidates must be successful both as individual contributors and in a team environment, and must be customer-centric. Our environment is fast-paced and requires someone who is flexible, detail-oriented, and comfortable working in a deadline-driven work environment. Responsibilities Include Works across team(s) and Ops organization at country, regional and/or cross regional level to drive improvements and enables to implement solutions for customer, cost savings in process workflow, systems configuration and performance metrics.\n\nBasic Qualifications\nBachelors degree in Computer Science, Information Technology, or a related field\nProficiency in automation using Python\nExcellent oral and written communication skills\nExperience with SQL, ETL processes, or data transformation\n\nPreferred Qualifications\nExperience with scripting and automation tools\nFamiliarity with Infrastructure as Code (IaC) tools such as AWS CDK\nKnowledge of AWS services such as SQS, SNS, CloudWatch and DynamoDB\nUnderstanding of DevOps practices, including CI/CD pipelines and monitoring solutions\nUnderstanding of cloud services, serverless architecture, and systems integration\n\n\nAs a Business Intelligence Engineer in the team, you will collaborate closely with business partners, architect, design, implement, and BI projects & Automations.\n\nResponsibilities:\n\nDesign, development and ongoing operations of scalable, performant data warehouse (Redshift) tables, data pipelines, reports and dashboards.\nDevelopment of moderately to highly complex data processing jobs using appropriate technologies (eg SQL, Python, Spark, AWS Lambda, etc)\nDevelopment of dashboards and reports.\nCollaborating with stakeholders to understand business domains, requirements, and expectations. Additionally, working with owners of data source systems to understand capabilities and limitations.\nDeliver minimally to moderately complex data analysis; collaborating as needed with Data Science as complexity increases.\nActively manage the timeline and deliverables of projects, anticipate risks and resolve issues.\nAdopt best practices in reporting and analysis: data integrity, test design, analysis, validation, and documentation.\nInternal job description\n\nRetail Business Service, ARTS is a growing team that supports the Retail Efficiency and Paid Services business and tech teams. There is ample growth opportunity in this role for someone who exhibits Ownership and Insist on the Highest Standards, and has strong engineering and operational best practices experience.\n\nBasic qualifications:\n\n5+ years of relevant professional experience in business intelligence, analytics, statistics, data engineering, data science or related field.\nExperience with Data modeling, SQL, ETL, Data Warehousing and Data Lakes.\nStrong experience with engineering and operations best practices (version control, data quality/testing, monitoring, etc)\nExpert-level SQL.\nProficiency with one or more general purpose programming languages (eg Python, Java, Scala, etc)\nKnowledge of AWS products such as Redshift, Quicksight, and Lambda.\nExcellent verbal/written communication & data presentation skills, including ability to succinctly summarize key findings and effectively communicate with both business and technical teams.\n\nPreferred qualifications:\n\nExperience with data-specific programming languages/packages such as R or Python Pandas.\nExperience with AWS solutions such as EC2, DynamoDB, S3, and EMR.\nKnowledge of machine learning techniques and concepts. 3+ years of analyzing and interpreting data with Redshift, Oracle, NoSQL etc experience\nExperience with data visualization using Tableau, Quicksight, or similar tools\nExperience with data modeling, warehousing and building ETL pipelines\nExperience in Statistical Analysis packages such as R, SAS and Matlab\nExperience using SQL to pull data from a database or data warehouse and scripting experience (Python) to process data for modeling Experience with AWS solutions such as EC2, DynamoDB, S3, and Redshift\nExperience in data mining, ETL, etc and using databases in a business environment with large-scale, complex datasets",,,,"['SAS', 'Data modeling', 'Oracle', 'Business intelligence', 'MATLAB', 'Information technology', 'Analytics', 'SQL', 'Python']",2025-06-12 14:16:09
Senior Mis Executive,Thyrocare,2 - 6 years,2.5-5 Lacs P.A.,['Mumbai (All Areas)'],"Roles and Responsibilities\nAnalyse, extract, and review relevant data from various client and proprietary systems to create spreadsheet reports for use of management, efficiency, quality, and productivity analysis, employee stack-ranking, cost analysis, billing/invoicing\nAnalyse data and publish daily, weekly and monthly reports as per the pre-defined timelines\nBuild and manage the tools to collect raw data that is not available from current software and systems.\nCreate multi-level reports from the same data to serve multiple stakeholders with minimum manual re-work\nSuch other activities as may be assigned by your manager\nParticipate in cross-functional meetings to resolve recurring customer issues.\nAnalyze current business processes and make recommendations for improvements\nMaintain thorough understanding of data and information resources\nMaintain a status on all projects and proactively communicate with management\n\nDesired Candidate Profile\nCandidates with 3+ Years of experience in creating and maintaining MIS reports for Banking, Financial Services, BPO/KPO/LPO, or Back-office Operations.\nAdvanced Excel Knowledge including but not limited to: Creating Impressive Dashboards, working with large excel data running into lakhs of rows and several hundred columns, use of excel tools and formulas: pivot, xlookup, vlookup, index, sumifs, countifs, maxifs, sumproduct, offset, string and date related formulas, multiple layer nested if loops, rank, use of array formulas such as unique, filter, sort, sortby.\nAnd Knowledge of Big Data analysis tools such as SQL, Python etc\nKnowledge of Power Suite: Power Query, Power Automate and Power BI would be an added advantage\nProficiency with macros and VBA coding would be an added advantage\nHigh attention to detail\nMust have an analytical bent of mind\nShould be able to build tools with high scalability and agility\nQualifications/ Requirements:\nUG- Any Graduate\nHigh producer with attention to quality\nStrong PC skills, with demonstrated proficiency with Microsoft Office\nWilling to work in shifts as per business requirements\nWillingness to learn and invest time and effort for career development.",Industry Type: Pharmaceutical & Life Sciences,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Purchase', 'MIS', 'Advanced Excel', 'MIS Preparation', 'MIS Operations', 'Supply Chain Management', 'MIS Reporting', 'Management Information System', 'Inventory', 'Excel Report Preparation']",2025-06-12 14:16:11
Data Specialist - Research,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Research domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Research domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Agile', 'Data quality', 'SQL']",2025-06-12 14:16:13
DBA DATA Engineer || 12 Lakhs CTC,Robotics Technologies,8 - 9 years,12 Lacs P.A.,['Hyderabad( Banjara hills )'],"Dear Candidate,\nWe are seeking a skilled and experienced DBA Data Engineer to join our growing data team. The ideal candidate will play a key role in designing, implementing, and maintaining our databases and data pipeline architecture. You will collaborate with software engineers, data analysts, and DevOps teams to ensure efficient data flow, data integrity, and optimal database performance across all systems. This role requires a strong foundation in database administration, SQL performance tuning, data modeling, and experience with both on-prem and cloud-based environments.\n\nRequirements:\nBachelors degree in Computer Science, Information Systems, or a related field.\n8+ years of experience in database administration and data engineering.\nProven expertise in RDBMS (Oracle, MySQL, and PostgreSQL) and NoSQL systems (MongoDB, Cassandra).\nExperience managing databases in cloud environments (AWS, Azure, or GCP).\nProficiency in ETL processes and tools (e.g., Apache NiFi, Talend, Informatica, AWS Glue).\nStrong experience with scripting languages such as Python, Bash, or PowerShell.\n\nDBA Data Engineer Roles & Responsibilities:\nDesign and maintain scalable and high-performance database architectures.\nMonitor and optimize database performance using tools like CloudWatch, Oracle Enterprise Manager, pgAdmin, Mongo Compass, or Dynatrace.\nDevelop and manage ETL/ELT pipelines to support business intelligence and analytics.\nEnsure data integrity and security through best practices in backup, recovery, and encryption.\nAutomate regular database maintenance tasks using scripting and scheduled jobs.\nImplement high availability, failover, and disaster recovery strategies.\nConduct performance tuning of queries, stored procedures, indexes, and table structures.\nCollaborate with DevOps to automate database deployments using CI/CD and IaC tools (e.g., Terraform, AWS CloudFormation).\nDesign and implement data models, including star/snowflake schemas for data warehousing.\nDocument data flows, data dictionaries, and database configurations.\nManage user access and security policies using IAM roles or database-native permissions.\nAnalyze existing data systems and propose modernization or migration plans (on-prem to cloud, SQL to NoSQL, etc.).\nUse AWS RDS, Amazon Redshift, Azure SQL Database, or Google BigQuery as needed.\nStay up-to-date with emerging database technologies and make recommendations.\n\nMust-Have Skills:\nDeep knowledge of SQL and database performance tuning.\nHands-on experience with database migrations and replication strategies.\nFamiliarity with data governance, data quality, and compliance frameworks (GDPR, HIPAA, etc.).\nStrong problem-solving and troubleshooting skills.\nExperience with data streaming platforms such as Apache Kafka, AWS Kinesis, or Apache Flink is a plus.\nExperience with data lake and data warehouse architectures.\nExcellent communication and documentation skills.\n\nSoft Skills:\nProblem-Solving: Ability to analyze complex problems and develop effective solutions.\nCommunication Skills: Strong verbal and written communication skills to effectively collaborate with cross-functional teams.\nAnalytical Thinking: Ability to think critically and analytically to solve technical challenges.\nTime Management: Capable of managing multiple tasks and deadlines in a fast-paced environment.\nAdaptability: Ability to quickly learn and adapt to new technologies and methodologies.\n\nInterview Mode : F2F for who are residing in Hyderabad / Zoom for other states\nLocation : 43/A, MLA Colony,Road no 12, Banjara Hills, 500034\nTime : 2 - 4pm",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Database Administration', 'Database Migration', 'Dba Skills', 'High Availability', 'Db Administration', 'Hadr', 'Database Security', 'Disaster Recovery', 'Dr Testing', 'DR', 'Luw', 'Db Upgrade', 'Brtools', 'UDDI', 'Os Migration', 'Dbase', 'DBMS', 'IBM DB2', 'Db Migration', 'Disaster Recovery Planning', 'Db Dba', 'Backup And Recovery']",2025-06-12 14:16:16
"Delivery Head - Infrastructure Engineering, Data Center",Bajaj Allianz General Insurance Company Limited,15 - 20 years,Not Disclosed,['Pune'],"The role requires strong leadership, strategic thinking, and the ability to drive innovation and efficiency within the technology department. It demands extensive experience in leading complex data center infrastructures, focusing on servers, SAN storage, high availability, disaster recovery, and hybrid environments, including data center operations and physical servers (blade and rack). Responsibilities include designing and testing backup strategies, maintaining documentation, ensuring compliance with regulations, and conducting product and vendor evaluations. Collaboration with various IT teams, the security team, and business stakeholders is essential\n",,,,"['process setting', 'document management', 'vmware', 'center', 'microsoft azure', 'itil service management', 'storage', 'shuttering', 'analysis', 'problem management', 'change management', 'cloud', 'data center', 'operations', 'service delivery', 'incident management', 'leadership', 'it infrastructure management', 'itil']",2025-06-12 14:16:18
Data Science Lead,Algoleap Technologies,10 - 15 years,Not Disclosed,['Hyderabad'],"As we build our Data Science Center of Excellence (CoE), we are looking for an entrepreneurial and technically strong Data Science Lead who can lay the foundation for a high-performing team. You will work directly with stakeholders across multiple business units to define use cases, lead model development, and ensure successful deployment and value realization.\n\nKey Responsibilities:\nServe as the technical and strategic lead for the Data Science CoE.",,,,"['customer analytics', 'Usage', 'data science', 'GCP', 'Machine learning', 'model development', 'Deployment', 'Stakeholder management', 'SQL', 'Python']",2025-06-12 14:16:21
Data Specialist - G&A,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the General and Administrative operations (GA) domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the General and Administrative operations (GA) domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 Years of Experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Administration', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Data quality', 'SQL']",2025-06-12 14:16:23
Data Specialist - Supply Chain,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Supply Chain domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Supply Chain domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Data quality', 'SQL']",2025-06-12 14:16:25
Data Specialist - Development,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Development domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Development domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Agile', 'Data quality', 'SQL']",2025-06-12 14:16:27
Data Specialist - Commercial,Horizon Therapeutics,9 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for the Commercialization domain of the biopharma lifecycle.\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in the Commercialization domain of the biopharma lifecycle.\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business process', 'Data analysis', 'Change management', 'operational support', 'SAS', 'Pharma', 'Analytical', 'Agile', 'Data quality', 'SQL']",2025-06-12 14:16:30
Data Quality Lead by Domain,Horizon Therapeutics,3 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for a given domain of expertise (Research, Development, Supply Chain, etc. ).\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles. Develop and implement data quality frameworks. Design and enforce standards for data quality and governance to ensure consistent, accurate, and reliable data.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. data quality best practices and tools for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains. Collaborate with stakeholders and work closely with data stewards, analysts, IT, and business units to understand data requirements and address quality concerns.\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leaders and partners to ensure their needs are being met. Lead data quality initiatives aimed at improving data quality, including data cleansing, enrichment, and validation processes.\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in a domain (e. g. , Research, Clinical Trials, Commercial, etc. ).\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions. Proficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\n3-5 years of experience in data quality management, data governance, or related roles.\nSoft Skills:\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business process', 'Data analysis', 'Change management', 'SAS', 'Pharma', 'Analytical', 'Clinical trials', 'Data quality', 'SQL']",2025-06-12 14:16:32
Data Privacy Specialist,Horizon Therapeutics,3 - 13 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgens data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leverages state-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. You will leverage domain, technical and business process expertise to provide exceptional support of Amgen s data governance framework. This role involves working closely with business stakeholders and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with the Product Owner and other Business Analysts to ensure operational support and excellence from the team.\nRoles Responsibilities:\nResponsible for the data governance and data management framework implementation for a given domain of expertise (Research, Development, Supply Chain, etc. ).\nResponsible for the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nDrives cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles. Create and maintain privacy policies and procedures to protect sensitive data and ensure compliance.\nConduct regular privacy risk assessments and audits to identify and mitigate potential risks as required\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nEnsure compliance requirements with data privacy, security, and regulatory policies for the assigned domains including GDPR, CCPA, and other relevant legislations.\nJointly with Technology teams, business functions, and enterprise teams (e. g. , MDM, Enterprise Data Fabric, etc. ) define the specifications shaping the development and implementation of data foundations .\nBuild strong relationships with key business leads and partners to ensure their needs are being met\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills with knowledge of Pharma processes with specialization in a domain (e. g. , Research, Clinical Trials, Commercial, etc. )\nIn depth knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc. Strong understanding of data protection laws and regulations, including GDPR, CCPA, and other relevant legislations.\nIn depth experience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer-focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nIn depth experience of working with or supporting systems used to data governance framework. E. g. Collibra, Alation\nExcellent problem-solving skills and committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience of working with data governance councils or forums\nExperience with Agile software development methodologies (Scrum)\nProficiency in data analysis and quality tools (e. g. , SQL, Excel, Python, or SAS)\n3-5 years of experience in data privacy, compliance, or a related field.\nSoft Skills:\nIntegrity: Commitment to maintaining the highest ethical standards and protecting confidential information.\nAdaptability: Ability to adapt to changing regulations and emerging privacy challenges.\nProactivity: Self-motivated with a proactive approach to identifying and addressing privacy issues.\nLeadership: Strong leadership skills and the ability to influence and drive change within the organization.\nHighly organized and able to work under minimal supervision\nExcellent analytical and assessment skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAmbitious to further develop their skills and career\nAbility to build business relationships and understand end-to-end data use and needs.\nExcellent interpersonal skills (team player). People management skills either in matrix or direct line function.\nStrong verbal and written communication skills\nHigh degree of initiative and self-motivation.\nGood presentation and public speaking skills.\nStrong attention to detail, quality, time management and customer focus.\nBasic Qualifications:\nAny Degree and 9-13 years of experience\n.",Industry Type: Biotechnology,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Business process', 'Data analysis', 'Change management', 'SAS', 'Pharma', 'Analytical', 'Clinical trials', 'Data quality', 'SQL']",2025-06-12 14:16:34
Senior Applied AI Scientist,ZS,4 - 9 years,Not Disclosed,['Bengaluru'],"Write complex SQL queries for data extraction, perform exploratory data analysis (EDA) to uncover insights.\nStrong proficiency in Python and Py Spark for scalable data processing and analytics.\nCreate, transform, and optimize features to enhance model performance.\nTrain, evaluate, and maintain machine learning models in production.\nWrite efficient, maintainable, and version-controlled code that handles large datasets.\nRegularly update internal teams and clients on project progress, results, and insights.\nConduct hypothesis testing and experiment analysis to drive data-driven decisions using AB testing.",,,,"['Data analysis', 'data security', 'Financial planning', 'Management consulting', 'Machine learning', 'Data processing', 'Analytics', 'Data extraction', 'Python']",2025-06-12 14:16:37
Data Stage Developer,Anblicks Solutions,6 - 11 years,Not Disclosed,['Chennai'],"Job Summary:\nWe are looking for a seasoned ETL Engineer with hands-on experience in Talend or IBM DataStage, preferably both, to lead data integration efforts in the mortgage domain. The ideal candidate will play a key role in designing, developing, and managing scalable ETL solutions that support critical mortgage data processing and analytics workloads.\n\nKey Responsibilities:\nEnd-to-end ETL solution development using Talend or DataStage.Design and implement robust data pipelines for mortgage origination, servicing, and compliance data.Collaborate with business stakeholders and data analysts to gather requirements and deliver optimized solutions.Perform code reviews, mentor junior team members, and ensure adherence to data quality and performance standards.Manage job orchestration, scheduling, and error handling mechanisms.Document ETL workflows, data dictionaries, and system processes.Ensure data privacy and compliance requirements are embedded in all solutions.\n\nRequired Skills:\nStrong experience in ETL tools Talend (preferred) or IBM DataStage.Solid understanding of mortgage lifecycle and related data domains.Proficiency in SQL and experience with relational databases (e.g., Oracle, SQL Server, Snowflake).Familiarity with job scheduling tools, version control, and CI/CD pipelines.Excellent problem-solving, leadership, and communication skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Datastage', 'Ibm Datastage', 'Etl Datastage']",2025-06-12 14:16:39
Intern - Influencer Marketing,Team Pumpkin,No fixed duration,Unpaid,['Gurugram'],"We are seeking a motivated and detail-oriented Intern - Influencer Marketing to join our dynamic team. In this role, you will support the influencer marketing process by assisting with influencer outreach, campaign coordination, and reporting.\nKey Responsibilities:\n\nInfluencer Database Management:\nCompile and maintain an up-to-date list of influencers, categorizing them by type (Mega, Micro, Macro) to ensure effective outreach.\n\nInfluencer Outreach:\nReach out to identified influencers for potential collaboration opportunities on brand campaigns.\n\nCampaign Coordination:\nAssist in coordinating with influencers throughout the execution of campaigns, ensuring clear communication and adherence to timelines.\n\nCampaign Reporting:\nPrepare and present reports on campaign performance, capturing key metrics and insights for further analysis.\n\nMarket Research:\nConduct research on influencers and social media platforms to identify trends and opportunities for future collaborations.\n\nRelationship Management:\nBuild and maintain positive relationships with influencers and vendors to facilitate smooth campaign execution.\n\nCompetitive Analysis:\nGather and analyze competitive commercial offers from influencers to inform negotiation strategies.\n\nQualifications:\nBachelors degree in Marketing, Communications, or a related field.\nStrong understanding of social media platforms and influencer dynamics.\nExcellent communication and interpersonal skills.\nProficiency in data analysis and report generation.\nAbility to manage multiple tasks and work efficiently in a fast-paced environment.",Industry Type: Advertising & Marketing,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Relationship management', 'Report generation', 'Marketing Manager', 'Data analysis', 'Interpersonal skills', 'Intern', 'Competitive analysis', 'Social media', 'Market research', 'Marketing communication']",2025-06-12 14:16:41
Azure Data Engineer (Azure Databricks must),Fortune India 500 IT Services Firm,5 - 8 years,Not Disclosed,['Hyderabad'],"We are looking for an experienced Azure Data Engineer with strong expertise in Azure Databricks to join our data engineering team.\n\nMandatory skill- Azure Databricks\nExperience- 5 to 8 years\nLocation- Hyderabad\nKey Responsibilities:\nDesign and build data pipelines and ETL/ELT workflows using Azure Databricks and Azure Data Factory\nIngest, clean, transform, and process large datasets from diverse sources (structured and unstructured)\nImplement Delta Lake solutions and optimize Spark jobs for performance and reliability\nIntegrate Azure Databricks with other Azure services including Data Lake Storage, Synapse Analytics, and Event Hubs\n\n\n\nInterested candidates share your CV at himani.girnar@alikethoughts.com with below details\n\nCandidate's name-\nEmail and Alternate Email ID-\nContact and Alternate Contact no-\nTotal exp-\nRelevant experience-\nCurrent Org-\nNotice period-\nCCTC-\nECTC-\nCurrent Location-\nPreferred Location-\nPancard No-",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure Databricks', 'Azure Data Factory', 'Pyspark', 'Azure Data Lake', 'SQL']",2025-06-12 14:16:43
Artificial Intelligence Intern,Kumaran Systems,0 - 1 years,4.5-5 Lacs P.A.,['Chennai( Siruseri Sipcot IT Park )'],"We are looking for a passionate and motivated AI Developer Fresher to join our growing AI team. This role will focus on Generative AI (GenAI) technologies such as large language models (LLMs), diffusion models, and other cutting-edge machine learning techniques.\n\nAs a fresher, youll work closely with senior AI engineers and data scientists to build and fine-tune generative models, contribute to prompt engineering, and support model integration into real-world applications.",,,,"['Data Science', 'Mechine Learning', 'Artificial Intelligence', 'GEN AI', 'Python']",2025-06-12 14:16:46
Supply Chain Intern,Azelis India,6 months duration,"20,000/month",['Navi Mumbai'],Job Description: -\nWork from Office:\nLocation: Airoli Navi Mumbai\ncontact person: tushar.shete@azelis.com\nQualifications: - Graduate from any stream\nBasic knowledge of purchase to pay.\nknowledge of Incoterm,,,,"['Communication Skills', 'MS Office']",2025-06-12 14:16:48
Research Assistant,Panacorp Software Solutions,0 - 1 years,Not Disclosed,"['Nagercoil', 'Kanyakumari']","Key Responsibilities:\nAssist with the design and execution of research projects\nCollect, organize, and analyze data using various research methodologies\nPrepare and review research documents, reports, and presentations\nConduct literature reviews and summarize relevant research articles\nCollaborate with other team members and researchers to facilitate research activities\nEnsure the quality and accuracy of research data and findings\nSupport researchers in experimental tasks and lab work (if applicable)\nQualifications:\nEducation: BE/B.Tech (Recent Graduates) or relevant degree\nExperience: 0-1+ year(s) of experience in research projects\nSkills:\nStrong analytical and problem-solving skills\nFamiliarity with data analysis software (e.g., MS Excel, MATLAB, Python, or R)\nExcellent communication skills (both verbal and written)\nAbility to work independently as well as part of a collaborative team\nAttention to detail and ability to manage time effectively",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['Research Development', 'R', 'data analysis', 'MATLAB', 'Python']",2025-06-12 14:16:50
B-Tech Internship Trainee,ADA Tech Solutions,3 months duration,"15,000/month",['Pune'],"Roles & Responsibilities:\nAssist in project execution under the guidance of senior team members.\nSupport in research, development, testing, documentation, or data analysis based on the assigned domain.\nCollaborate with cross-functional teams to understand business and technical requirements.\nParticipate in team meetings and contribute to idea generation and problem-solving.\nMaintain project documentation, reports, and presentations.\nComplete assigned tasks within deadlines while maintaining quality and accuracy.\nLearn and use tools, platforms, or frameworks relevant to the tteam'seams work.\nEligibility Criteria:\nCurrently pursuing B.Tech / B.E. in [Computer Science, IT, ECE, Mechanical, Civil, etc.].\nStrong academic background and willingness to learn.\nGood communication and teamwork skills.\nBasic knowledge in domain-related tools or technologies is a plus (e.g., Python, Java, CAD, SQL, AutoCAD, etc.)\nSkills Required (customize as needed):\nAnalytical and problem-solving abilities\nBasic technical or engineering knowledge\nMS Office / Google Workspace proficiency\nEagerness to learn and adapt in a fast-paced environment\nTime management and accountability",Industry Type: BPM / BPO,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['IT Support', 'LAN Troubleshooting', 'Desktop Support', 'Laptop Support', 'Network Support', 'Hardware Support', 'System Support', 'LAN Support', 'Hardware Installation']",2025-06-12 14:16:52
Office Assistant & Accountant,Swami Associates,0 - 5 years,"72,000-1.8 Lacs P.A.",['Ahmedabad( Naroda Road )'],Responsibilities:\n* Maintain financial records using accounting software\n* Manage office supplies inventory\n* Prepare monthly reports with data analysis\n* Coordinate meetings and travel arrangements\n* Prepare Documents and Scan and Upload download\n\n\nAnnual bonus\nAccessible workspace,Industry Type: Accounting / Auditing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Computer Knowledge of MS Office', 'Communication Skills', 'Multitasking', 'workaholic', 'English', 'Gujarati', 'Clerical work', 'Hindi']",2025-06-12 14:16:54
Accounts and Audit Assistant,MAG Finserv Company Ltd,0 - 3 years,2.4-4.2 Lacs P.A.,['Pune'],"Bachelors/Master’s degree in Commerce, Finance, Accounting,and a CA Inter who has completed articleship of 3 years preferred).\n\nAccounting and finance\nAudit & Compliance\nData Analysis & Reporting\nTaxation & Regulatory Reporting",Industry Type: NBFC,Department: Finance & Accounting,"Employment Type: Full Time, Permanent",['Analytical'],2025-06-12 14:16:56
Trainee Solution Engineer,Qualitykiosk Technologies,0 - 1 years,Not Disclosed,"['Mumbai', 'Navi Mumbai']","Key ResponsibilitiesLearning and Development: Engage in training sessions and workshops to enhance your skills and knowledge relevant to your role\nAssisting Senior Staff: Support senior team members in their tasks, which may include research, data analysis, and project management\nProject Participation: Contribute to team projects, providing fresh perspectives and innovative ideas to foster collaboration and creativity\nProblem-Solving: Participate in problem-solving activities, making decisions based on available information and seeking guidance when necessary\nCollaboration: Work with cross-functional teams to gain a holistic understanding of the company s operations and contribute to multidisciplinary projects",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['project management', 'python', 'data analysis', 'data analytics', 'data management', 'c', 'mis reporting', 'business analysis', 'pivot table', 'vlookup', 'machine learning', 'presales', 'javascript', 'sql', 'excel', 'react.js', 'tableau', 'node.js', 'advanced excel', 'data visualization', 'pega', 'powerpoint']",2025-06-12 14:16:58
Machine Learning Engineer,Panacorp Software Solutions,0 - 5 years,Not Disclosed,"['Nagercoil', 'Kanyakumari']","Research Programmer (Python/ MATLAB) Fresher & Experienced\nAbout Panacorp Software Solutions\nPanacorp Software Solutions is a research-driven organization specializing in providing technical assistance for PhD research projects. Our focus is on supporting research scholars with programming, simulations, and computational analysis in various domains, including AI, Machine Learning, and numerical computing.\n\nJob Role & Responsibilities\nAssist in research-based projects related to PhD studies.\nPerform simulations, numerical computing, and data analysis using Python, MATLAB, and Simulink.\nSupport research scholars in implementing Machine Learning (ML) and Deep Learning (DL) models.\nAutomate processes and optimize research workflows through scripting.\nDocument research methodologies, findings, and technical reports.\nWork closely with scholars to analyze and interpret computational results.\nEligibility Criteria\nQualification: BE/B.Tech/MCA\nExperience: 0 5+ years (Freshers with strong academic knowledge can apply).\nStrong understanding of research methodologies and computational tools.\nPreferred Skills\nProficiency in Python, MATLAB, and Simulink.\nKnowledge of data analysis, AI/ML techniques, and numerical simulations.\nAbility to interpret and validate research outcomes.\nStrong analytical and problem-solving skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Machine Learning', 'matlab', 'simulink', 'python', 'data analysis', 'research methodology', 'artificial intelligence']",2025-06-12 14:17:00
Python Senior Developer,Infosys,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title\nPython Senior Developer\n\nResponsibilities\nSolid development experience in Data Science Arch.\nExperience in Application Architecture & Design of Java Based Applications\nGood Knowledge of Architecture and related technologies\nExperience in Integration Technologies and Architecture\nWorking knowledge of frontend and database technologies\nExcellent Analytical and Debugging Skills\nFamiliarity with Agile & DevSecOps, Log Analytics, APM\nExperience in leading the teams technically\nExperience in requirements gathering, analysis & design and estimation\nGood communication and articulation skills Technical and Professional :\nWe are seeking a skilled Python and SQL Developer to join our dynamic team. The ideal candidate will have a strong background in Python programming and SQL database management.\nDevelop and maintain Python-based applications and scripts.\nWrite efficient SQL queries for data extraction and manipulation.\nCollaborate with cross-functional teams to gather requirements and deliver solutions.\nFamiliarity with Linux operating systems.\nBasic understanding of cloud platforms (e.g., AWS, Azure, Google Cloud).\nKnowledge of Model Quantization and Pruning\nExperience playing a Data Scientist role Preferred Skills:\nPython Technology-Open System-Open System- ALL-Python Technology-Full stack-Java Full stack-Frontend(Vue.js)+Enterprise layer(Python)+DB Additional Responsibilities:\nIn-depth knowledge of design issues and best practices\nSolid understanding of object-oriented programming\nFamiliar with various design, architectural patterns and software development process.\nExperience with both external and embedded databases\nCreating database schemas that represent and support business processes\nImplementing automated testing platforms and unit tests\nGood verbal and written communication skills\nAbility to communicate with remote teams in effective manner\nHigh flexibility to travelSoft Skills\nGood verbal & written communication skills articulate value of AI to business, project managers & other team members\nAbility to break complex problem into smaller problems and create hypothesis\nInnovation and experimentation Educational Master of Computer Science,Master Of Science,Master Of Technology,MCA,Bachelor Of Comp. Applications,Bachelor Of Computer Science,Bachelor of Engineering,Bachelor Of Technology Service LineApplication Development and Maintenance* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Enterprise layer', 'software development', 'report generation', 'MIS', 'CI/CD', 'Java Full stack-Frontend', 'SDLC']",2025-06-12 14:17:02
Medical Coder Trainee,Resolve Medicode,0 - 2 years,1.25-3 Lacs P.A.,"['Pollachi', 'Mettupalayam', 'Coimbatore']","Medical coders translate detailed patient information from clinical records into standardized numerical and alphabetical codes. These codes are essential for billing, data analysis, research, and other healthcare functions.\n\nRegards,\nDeepika\n9880650498",Industry Type: Pharmaceutical & Life Sciences,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent",['Medical Coding'],2025-06-12 14:17:04
Assistant Manager - FP&A,Mahansaria Group,0 - 2 years,5-6.5 Lacs P.A.,['Mumbai (All Areas)'],"Job description\nSupport and assists in the budgeting process. This involves collaborating with different departments to create detailed budgets that align with the company's overall financial strategy.\nProduces monthly Key Performance Indicator (KPI) analysis. These KPIs offer valuable insights into the company's financial performance and help identify areas for improvement. Develop, Maintain, and enhance MIS reports to support decision making.\nSupports the creation and distribution of monthly board packs. These packs typically contain key financial and operational information that is presented to the company's board of directors.\nResponsible for preparing regular and insightful reports on revenue and client-related metrics. These reports assist in tracking performance, identifying trends, and highlighting areas for improvement.\nCollaborates with various departments within the organization to provide valuable insights and data-driven analysis. They use financial data to help stakeholders make informed decisions that align with the company's goals and objectives.\nFinancial Review and Analysis of Group companies.\nBenchmarking, Ratio analysis, Trend analysis, Variance Analysis etc.\nPerforming ad-hoc analysis where required to assist in management decision making.\nPreparation of comparison of P&L and Balance Sheet with respect to budget/MIS along with variance.\nBuilding/developing and maintaining of data analysis, data visualization and presenting business insight thru BI Tools.\nOther work to be assigned time to time.",Industry Type: Auto Components (Tyre),Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Budgeting And Forecasting', 'Financial Planning And Analysis', 'Margin Analysis', 'ERP', 'Financial Reporting', 'Revenue Analysis', 'Bi Tools', 'Variance Analysis', 'MIS Reporting', 'Balance Sheet Analysis', 'Material Management', 'KPI Analysis', 'Ad Hoc Reporting', 'Trend Analysis', 'Ratio Analysis']",2025-06-12 14:17:06
Senior Engineer,A Large Global Organization,5 - 10 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Key Skills: Data Analysis, Project Management, PMP\nRoles and Responsibilities:\nLead and manage projects involving analytics, reporting, and process improvements across departments\nConduct data analysis to identify performance trends, root causes, and actionable insights\nAutomate routine business processes and reporting tasks to drive operational efficiency\nPrepare clear, impactful presentations and documentation for stakeholders at all levels\nMonitor project timelines, deliverables, and risks while ensuring alignment with business goals\nCollaborate cross-functionally to gather requirements, develop project plans, and drive execution\nSupport strategic initiatives by providing analytical input and business insights\nServe as a liaison between technical and business teams to ensure effective solution delivery\nContinuously identify and implement improvements in workflow, reporting, and stakeholder engagement\nSkills Required:\nStrong verbal and written communication skills\nAbility to simplify and present complex data and concepts to varied audiences, including senior leadership\nDetail-oriented with excellent organizational skills to manage multiple projects concurrently\nHands-on experience in project management and data analytics\nTechnological proficiency to automate tasks and streamline documentation (e.g., scripting, dashboards, data querying tools)\nCreative problem-solving abilities, with a proven track record of developing innovative solutions\nComfortable working with senior professionals and stakeholders on complex or sensitive topics\nAbility to analyze similar but varied issues, requiring data gathering and applying defined procedures or best practices to resolve\nEducation: Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field",Industry Type: Medical Services / Hospital,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['PMP', 'Project Management', 'Data Analysis']",2025-06-12 14:17:08
"Sr Software Eng: Generative AI, Go/Python, AWS, Kubernetes 7-12 Yrs",Cisco,7 - 12 years,Not Disclosed,['Bengaluru'],"Meet The Team\nThe Cisco AI Software & Platform Group drives the development of groundbreaking generative AI applications. We empower Cisco's diverse product portfolio, spanning networking and security, with intelligent assistants and agents. We work on pioneering technologies that proactively defend against threats, safeguard critical business assets, and simplify security operations. Fueled by a passion for AI/ML, we strive to create a secure future for businesses. Our collaborative and passionate team thrives with tackling sophisticated challenges and delivering innovative solutions.",,,,"['Golang', 'Generative Ai', 'AWS', 'Python', 'Kubernetes', 'Java']",2025-06-12 14:17:11
Senior Murex Front Office & Risk Support Engineer,Synechron,5 - 10 years,Not Disclosed,"['Pune', 'Bengaluru', 'Hinjewadi']","Job Summary\nSynechron is seeking an experienced Murex FO & Risk Support Specialist to join our dynamic team. This role is central to maintaining and supporting Murex platform functionalities related to front-office operations and risk management, with a focus on production support.\nThe individual will collaborate closely with business users and IT teams to resolve complex issues, optimize configurations, and ensure the stability of critical trading and risk systems. By providing expert-level support, this role contributes directly to the organizations ability to manage market and credit risks effectively, deliver timely business insights, and uphold operational resilience.\nSoftware Requirements\nRequired Software Proficiency:\nMurex platform (version 3.1 or later) extensive experience in FO & Risk modules from a production support perspective\nSQL and Database querying tools (Oracle, SQL Server) strong experience in data analysis and troubleshooting\nMarket data management tools and configurations within Murex\nIssue tracking and collaboration tools (e.g., JIRA, ServiceNow)\nPreferred Software Skills:\nFamiliarity with scripting languages (Python, Shell scripting) for automation\nVersion control systems (e.g., Git)\nCloud platforms (if applicable to client environment)\nOverall Responsibilities\nProvide second-line support for Murex front-office and risk modules, ensuring operational stability and performance\nAnalyze and troubleshoot issues related to P&L, market risk, credit risk, pricing, simulations, and market data, collaborating with business users to identify root causes\nManage Murex configurations, including GOM (Global Object Model) setups, static data configurations, and cross-asset class risk settings\nLiaise with business stakeholders and IT teams to resolve complex incidents, queries, and configuration challenges\nCollaborate on incident resolution, change management, and service improvement initiatives\nDocument technical procedures, resolutions, and configuration changes for knowledge sharing and audit compliance\nContinuously monitor platform health, performance, and data integrity, proposing proactive solutions for operational risks\nTechnical Skills (By Category)\nProgramming Languages:\nEssential: Murex editing languages, SQL\nPreferred: Python, Shell scripting for automation tasks\nDatabases / Data Management:\nEssential: Oracle, SQL Server experience with schema design, data queries, and performance tuning\nPreferred: Understand market data integration and static data management in Murex\nCloud Technologies:\nOptional/Preferred: Basic understanding of cloud integrations related to trading platforms, if applicable\nFrameworks and Libraries:\nNot applicable, focus on Murex platform and related tools\nDevelopment Tools and Methodologies:\nFamiliarity with ITSM processes, incident & problem management, Agile/Scrum methodologies\nSecurity Protocols:\nUnderstanding of access controls, data confidentiality, and system compliance relevant to financial platforms\nExperience Requirements\nMinimum of 5+ years experience supporting Murex FO & Risk modules in a production environment\nProven experience in analyzing issues related to P&L, market risk, credit risk, and pricing in a trading systems context\nStrong understanding of GOM configurations, static data setups, and cross-asset risk configurations\nExperience working directly with business lines, traders, risk managers, and IT teams\nIndustry background within banking, financial services, or capital markets preferred but not mandatory\nDay-to-Day Activities\nMonitor and support Murex FO & Risk modules, identifying and resolving operational issues\nPerform root-cause analysis on incidents related to market data, P&L, and risk calculations\nFine-tune GOM and static data configurations to optimize system performance and accuracy\nEngage in daily stand-ups, incident reviews, and change implementation meetings\nCollaborate with business users and technical teams to clarify issues and implement fixes\nConduct system audits and maintain detailed logs of support activities and configuration changes\nContribute to continuous improvement initiatives for system stability and efficiency\nQualifications\nBachelors degree or higher in Computer Science, Finance, Information Technology, or related field\nCertifications in Murex support, risk management, or related disciplines are a plus\nPrior experience with Murex platform support in financial markets, trading, or risk management environments\nKnowledge of market practices, instruments, and risk concepts across multiple asset classes\nWillingness to engage in ongoing professional development and staying current with Murex updates and industry trends\nProfessional Competencies\nStrong analytical and problem-solving skills, with a focus on root cause identification\nEffective communication skills to interact clearly with technical and business stakeholders\nAbility to work collaboratively within cross-functional teams and under pressure\nAdaptability to evolving systems, processes, and technology landscapes\nCustomer-centric approach, ensuring timely and quality support delivery\nDemonstrated organizational skills for managing multiple issues and priorities efficiently.",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['Murex support', 'risk management', 'Risk Support', 'credit risk', 'market risk', 'pricing']",2025-06-12 14:17:13
CPU Full Stack Python Developer (Staff/Sr. Staff),Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nWe are seeking a highly skilled Full Stack Python Developer to join our dynamic team. The ideal candidate should have a strong background in tool development, data science, and automation of complex tasks. You will be responsible for developing high volume regression dashboard, parametric and power tools and contributing to both front-end and back-end development.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\n\nTechnical\n\nSkills:\n\n\n\nPythonProficiency in Python programming, including libraries like Pandas, NumPy, and SciPy for data science.\n\n\nFull Stack DevelopmentExperience with both front-end (HTML, CSS, JavaScript, React, Vue.js) and back-end (Django, Flask) technologies.\n\n\nTool DevelopmentAbility to develop parametric and power tools, possibly using frameworks like Vue.js , PyQt or Tkinter for GUI development.\n\n\nData ScienceStrong understanding of data analysis, machine learning (using libraries like scikit-learn, TensorFlow), and data visualization (using Matplotlib, Seaborn).\n\n\nAutomationExperience in automating complex tasks using scripting and tools like Selenium, Airflow, or custom automation scripts.\n\n\nSoft\n\nSkills:\n\n\n\nProblem-SolvingAbility to tackle complex problems and develop innovative solutions.\n\n\nCommunicationStrong communication skills to effectively collaborate with team members and stakeholders.\n\n\nAdaptabilityFlexibility to adapt to new technologies and methodologies.\n\n\nExperience:\n\n\nProjectsPrevious experience in developing tools and automation solutions.\n\n\nIndustry KnowledgeFamiliarity with the specific industry or domain you're working in can be a plus.\n\n\nKey Responsibilities:\n\nDevelop and maintain parametric and power tools using Python.\n\nDesign and implement automation solutions for complex tasks.\n\nCollaborate with data scientists to analyze and visualize data.\n\nBuild and maintain web applications using Django or Flask.\n\nDevelop front-end components using HTML, CSS, JavaScript, and React.\n\nIntegrate third-party APIs and services.\n\nOptimize applications for maximum speed and scalability.\n\nWrite clean, maintainable, and efficient code.\n\nTroubleshoot and debug applications.\n\nStay updated with the latest industry trends and technologies.\n\n\nPreferred Qualifications:\n\nBachelor's degree in Computer Science, Engineering, or related field.\n\nPrevious experience in tool development and automation.\n\nFamiliarity with industry-specific tools and technologies.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['tool development', 'data science', 'python', 'data analysis', 'machine learning', 'css', 'hiring', 'scikit-learn', 'vue.js', 'numpy', 'staffing', 'react.js', 'tensorflow', 'seaborn', 'selenium', 'pyqt', 'html', 'data visualization', 'scipy', 'hardware engineering', 'javascript', 'pandas', 'django', 'matplotlib', 'flask']",2025-06-12 14:17:15
"Wireless Technology Hardware Program Manager, Senior",Qualcomm,5 - 10 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Services Group, Engineering Services Group > Program Management\n\nGeneral Summary:\n\nDevelops, defines, and executes plans of record, includingschedules, budgets, resources, deliverables, and risks. Monitors and drives the program from initiation through delivery, interfacing with internal and external stakeholders across functions on technical matters, as needed. Monitors budget/spending, on-time delivery, and achievement of program milestones. Represents the program and drives alignment across stakeholders.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Computer Science, or related field.\n5+ years of Program Management or related work experience.\n\nPreferred Qualifications:\n\nMaster's degree in Engineering, Computer Science, or related field.\n\nPMP Certification.\n\n10+ years of Program Management or related work experience.\n\n5+ years of work experience in a role requiring interaction with senior leadership (e.g., Director level and above).\n\n3+ years of experience working in a large matrixed organization.\n\n2+ years of experience with program management tools such as dashboards, Gantt charts, etc.\n\nPrincipal Duties and Responsibilities:\nCollaborates with key stakeholders and program sponsors to develop program goals, set the prioritization of deliverables, discuss involvement of business processes (e.g., program change management, communication) and drives decisions necessary for on time delivery.\nManages and takes responsibility for multiple medium sized programs/technology with moderate complexity by applying up-to-date program management knowledge to meet deadlines.\nDevelops and manages the execution of the program Plan of Record (e.g., on time, on budget, within scope) for multiple medium sized programs which include schedule and resource forecasting, stakeholders identification, method and frequency of communication, scope, and prioritization.\nEstablishes key program metrics and manages team to take action outside their comfort zone to ensure program success when metrics deviate from Plan of Record.\nIdentifies and secures resources to ensure alignment of team with program/technology demand for multiple medium sized programs with moderate complexity.\nDrives teams to identify program issues/risks, and create a risk mitigation plan for multiple medium sized or a single complex program(s). Maintains and updates the risk tracker.\nPromotes program vision and objectives within the team, ensures program objectives are met or exceeded, presents program vision to management, and gains buy-in from stakeholders.\nPromotes adoption of processes by applying best practices and identifying and executing process improvement initiatives across the Program Management team.\n\nLevel of Responsibility:\nWorking independently with little supervision.\nMaking decisions that are significant in impact; errors are not readily apparent due to the complexity of work process/product or time between decisions and results; errors typically result in significant expenditure of time, resources, and funds to correct.\nUsing verbal and written communication skills to convey complex and/or detailed information to multiple individuals/audiences with differing knowledge levels. May require strong negotiation and influence, communication to large groups or high-level constituents.\nHaving a moderate amount of influence over key organizational decisions (e.g., is consulted by senior leadership to provide input on key decisions).\nCompleting tasks that require multiple steps that can be performed in various orders; tasks require simultaneously executing multiple cognitive abilities and maintaining information in short- or long-term memory.\nExercising exceptional creativity to innovate new ideas and develop innovative products/processes without established objectives or known parameters.\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or conflicting; advanced data analysis and interpretation skills are required.\nOccasionally participates in strategic planning within own area affecting immediate operations.\n\nThe responsibilities of this role do not include:\nFinancial accountability (e.g., does not involve budgeting responsibility).",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['data analysis', 'program management', 'pmi', 'pmp', 'computer science', 'project management', 'project scheduling', 'ms project', 'business analysis', 'pmo', 'delivery management', 'scrum', 'project execution', 'agile', 'pmbok', 'csm', 'project coordination', 'project planning', 'agile methodology']",2025-06-12 14:17:17
Senior System Software Engineer,Nvidia,4 - 12 years,Not Disclosed,['Bengaluru'],"NVIDIAs Deep Learning GPUs have ignited modern AI the next era of computing with the GPU acting as the brain of computers, robots, and self-driving cars that can perceive and understand the world. Today, we are increasingly known as the AI computing company . We are growing our company and the team with the smartest people in the world.\nWe are looking for extraordinary Software Engineers to develop and productize NVIDIAs DRIVE OS software. As a member of NVIDIAs Solution Engineering team, you will adapt DRIVE OS solutions to various car platforms equipped with different sensors. We are looking for a Senior System Software Engineer with strong experience in Linux/QNX/Android operating system, Device Drivers development, virtualization, and ARM architecture\nWhat you will be doing:\nArchitecture, development, and enhancement of native/para-virtualized Linux/QNX device drivers\nSolve complex system issues on Linux/Android/QNX OS\nLead the architecture discussions for SW components and interface with customers to support DRIVE software solutions.\nContinuously evolve and support requirements gathering process and traceability flow.\nActively coordinate with cross-functional engineering teams to meet customers requirements and to drive complex issues to closure.\nParticipate in architectural explorations which include feasibility studies, safety evaluations and data analysis.\nPerformance tuning of customer use-cases and functions on Drive OS software\nWhat we need to see:\nBS/MS or equivalent experience.\n5+ years of overall experience and preferably with 2+ years of automotive industry experience.\nStrong understanding of QNX/Linux/Android operating system and hands-on experience with QNX/Linux device driver development\nStrong C/C++ programming and debugging skills\nIn-depth understanding of ARM processor architecture fundamentals\nBackground in embedded software development and deep knowledge of product development lifecycle.\nExposure to functional safety architecture to meet ISO26262 standard would be a plus\nEffective written and verbal communication regardless of audience or issue complexity.\nWays to stand out from the crowd:\nIn-depth device driver development experience on Linux and/or QNX OS\nStrong kernel/OS debugging skills\nNVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression , sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance tuning', 'Data analysis', 'Linux', 'Architecture', 'Debugging', 'QNX', 'System software', 'Virtualization', 'Automotive', 'Android']",2025-06-12 14:17:20
Senior Murex Front Office & Risk Support Engineer,Synechron,5 - 10 years,Not Disclosed,"['Pune', 'Bengaluru']","Software Requirements\nRequired Skills:\nProficiency with Murex (version 3.1 or higher) focusing on Front Office and Risk modules\nExperience in analyzing issues related to P&L, market risk, credit risk, pricing, simulations, and market data\nKnowledge of GOM configurations and static data (e.g., instruments, reference data)\nHands-on experience in troubleshooting and resolving system issues in a production environment\nGood understanding of cross-asset class configurations and risk management concepts\nStrong communication skills for engaging with business users, IT teams, and Murex vendors\nPreferred Skills:\nFamiliarity with other risk management and trading systems\nKnowledge of automation tools or scripting (e.g., Python, VBA) is advantageous\nOverall Responsibilities\nSupport daily operations of Murex Front Office and Risk modules, ensuring system stability\nInvestigate and resolve issues related to P&L calculations, risk metrics, pricing models, and data discrepancies\nCollaborate with business stakeholders to address queries and resolve configuration or data issues\nAssist in managing GOM configurations, static data, and cross-asset class setup\nParticipate in system upgrades, change management, and testing activities\nDocument issues, solutions, process changes, and configuration details for team knowledge\nMonitor system performance, identify risks, and recommend improvements\nMaintain effective communication with stakeholders regarding incident status, risk issues, and ongoing support requirements\nContribute to continuous improvement initiatives in procedures and configurations\nStrategic objectives:\nEnhance system stability and accuracy of risk calculations\nReduce incident resolution time and improve user satisfaction\nSupport effective risk and trading operations aligned with compliance\nPerformance outcomes:\nMinimal system downtime and accurate risk results\nTimely resolution of user queries and configuration issues\nClear, comprehensive documentation supporting ongoing support and audits\nTechnical Skills (By Category)\nProgramming Languages (Essential):\nBasic scripting (e.g., VBA, Python) for automation and data analysis (preferred)\nApplications & Modules (Essential):\nMurex Front Office and Risk modules (version 3.1 or above)\nExperience in P&L analysis, risk metrics, and market data management\nDatabases & Data Management (Essential):\nSQL for data retrieval, validation, and troubleshooting\nConfiguration & Static Data (Essential):\nManaging GOM templates, instrument data, and reference data configurations\nTrade & Risk Management Concepts (Essential):\nCross-asset class risk concepts, valuation techniques, and pricing methodologies\nTools & Integration (Preferred):\nFamiliarity with risk and trading system integrations\nMonitoring and troubleshooting tools specific to Murex environment\nExperience Requirements\nMinimum 5+ years supporting Murex Front Office and Risk modules from a production support perspective\nHands-on experience resolving issues related to P&L, market risk, credit risk, and pricing\nPrior experience in a support organization within financial institutionstrading desks, risk teams, or similarpreferred\nSupporting support in 24x5 or 24x7 environments, handling urgent incident escalations\nIndustry experience in banking, trading, or risk management sectors is advantageous\nAlternative experience pathways:\nCandidates with extensive support experience in related trading/risk systems demonstrating deep understanding of Murex modules may be considered\nDay-to-Day Activities\nMonitor daily Murex Front Office and Risk modules for issues or alerts\nInvestigate and troubleshoot discrepancies in P&L, risk metrics, and data quality\nCollaborate with traders, risk managers, IT team, and vendors to resolve incidents and support requests\nAssist in static data management, GOM configurations, and risk setup for multiple asset classes\nSupport system upgrades, configuration adjustments, and testing activities\nDocument incidents, solutions, and best practices for team knowledge base\nParticipate in change management, incident reviews, and process improvements\nProvide timely updates and communicate issues clearly to stakeholders\nQualifications\nBachelors degree in Finance, Computer Science, Information Technology, or related field\nStrong understanding of risk management, trading workflows, and modelling\nExperience with GOM configuration and static data setup\nGood SQL and scripting skills for troubleshooting and data analysis\nProven ability to work effectively under pressure and manage multiple priorities\nWillingness to support shifts, including non-core hours, as needed\nProfessional Competencies\nCritical thinking and strong problem-solving skills for complex issues\nEffective communication with technical teams, business users, and vendors\nStakeholder management and customer service orientation\nAbility to work autonomously, prioritize tasks, and manage incidents efficiently\nFlexible and adaptable to changing business and technological needs\nCommitment to continuous learning and process enhancement",Industry Type: IT Services & Consulting,Department: Risk Management & Compliance,"Employment Type: Full Time, Permanent","['Risk management', 'GOM configurations', 'VBA', 'configurations', 'troubleshooting', 'pricing', 'Python', 'SQL']",2025-06-12 14:17:22
Senior Staff Engineer - AI-IOT Product,Infineon,6 - 8 years,Not Disclosed,['Bengaluru'],"We are seeking an experienced AI-IOT Product Engineer to design and develop AI and IoT products, with a focus on technical product management and product design. This role requires a strong technical background, excellent problem-solving skills, and the ability to collaborate with cross-functional teams to deliver innovative solutions.\n\nJob Description\nProduct Design: Design and develop AI and IoT product concepts, including hardware, firmware, and software components. This includes:\nDeveloping product requirements and technical specifications.\nCollaborating with engineering teams to design and develop product architectures.\nEnsuring product designs meet technical and business requirements.\nTechnical Product Management: Manage the technical aspects of AI and IoT products, including:\nDefining and prioritizing product features and requirements.\nCollaborating with engineering teams to develop and deploy products.\nEnsuring products meet quality and reliability standards.\nSensor Algorithm Development: Collaborate with engineering teams to develop and implement sensor algorithms that enable accurate and efficient data collection and processing. This includes:\nProviding technical guidance on sensor fusion algorithms and machine learning models.\nCollaborating with engineering teams to integrate sensor algorithms with IoT devices and platforms.\nLLM RAG Systems: Collaborate with engineering teams to design and develop Large Language Model (LLM) Retrieval-Augmented Generation (RAG) systems that enable efficient and effective natural language processing. This includes:\nProviding technical guidance on LLM models and RAG systems.\nCollaborating with engineering teams to integrate LLM RAG systems with IoT devices and platforms.\nApplied Deep Learning: Collaborate with engineering teams to develop and implement deep learning models that enable accurate and efficient data analysis and processing. This includes:\nProviding technical guidance on deep learning models and architectures.\nCollaborating with engineering teams to integrate deep learning models with IoT devices and platforms.\nTechnical Road mapping: Develop and maintain technical roadmaps for AI and IoT products, including:\nIdentifying and prioritizing technical requirements and features.\nCollaborating with engineering teams to develop and deploy products.\nYou are best equipped for this task if you have:\n6-8 years of experience in AI, IoT, or related fields.\nBachelors or Masters degree in Computer Science, Electrical/Electronics Engineering, or a related field.\nExcellent problem-solving skills and attention to detail.\nExperience with AI and IoT technologies, such as AWS or Azure.\nStrong technical knowledge of sensor algorithms, LLM RAG systems, and applied deep learning.\nExperience with technical product management and product design.\nExperience with agile development methodologies.\nKnowledge of IoT protocols and technologies (eg, MQTT, CoAP, BLE, Zigbee, LoRa, NB-IoT).\nExperience with data analytics and machine learning.\nCertifications in AI or IoT technologies (eg, AWS Certified IoT Architect, Microsoft Certified Azure AI Engineer).\nExperience with DevOps tools and practices.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Semiconductor', 'Data analysis', 'Machine learning', 'Data collection', 'Product design', 'Natural language processing', 'Firmware', 'microsoft']",2025-06-12 14:17:24
Senior Staff - Embedded Linux,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nJob Overview:\n\nDevelops, creates, and modifies general computer applications software or specialized utility programs. Analyzes user needs and develops software solutions. Designs software or customizes software for client use with the aim of optimizing operational efficiency. Modifies existing software to correct errors, allow it to adapt to new hardware, or to improve its performance. Analyzes user needs and software requirements to determine feasibility of design within time and cost constraints. Confers with systems analysts, engineers, programmers and others to design system and to obtain information on project limitations and capabilities, performance requirements and interfaces. Stores, retrieves, and manipulates data for analysis of system capabilities and requirements. Designs, develops, and modifies software systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design.\n\nThe responsibilities of this role include\nWorking independently with no supervision.\nMaking decisions that are significant in impact, influencing overall program or project success, finances, and/or the ability to meet objectives; errors are not readily apparent due to the complexity of work process/product or time between decisions and results; errors typically result in significant expenditure of time, resources, and funds to correct.\nUsing verbal and written communication skills to convey complex and/or detailed information to multiple individuals/audiences with differing knowledge levels. May require strong negotiation and influence, communication to large groups or high-level constituents.\nHaving a great degree of influence over key organizational decisions (e.g., is making or directly making key decisions that have substantial impact on the organization).\nCompleting tasks that require multiple steps that can be performed in various orders; tasks require simultaneously executing multiple cognitive abilities and maintaining information in short or long-term memory.\nRegularly determines what needs to be done and is involved with sharing innovative solutions to achieve broad policies and objectives.\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or conflicting; advanced data analysis and interpretation skills are required.\nOccasionally participates in strategic planning within own area affecting immediate operations.\nPRINCIPAL DUTIES AND RESPONSIBILITIES\nSeeks information within and outside of team to identify and manage overarching technical issues and wide-ranging solutions.\nResolves design and technical issues related to technical area of expertise.\nServes as a technical expert for technology related to an overall large system.\nDetermines best strategies to solve current and future technical challenges associated with area of expertise.\nCollaborates with others inside and outside of project team to accomplish project objectives.\nSolves highly complex technical problems that affect multiple software layers or teams.\nMakes significant decisions as it pertains to the approach in coding large features or modules.\nActs as a tech lead and on major projects to ensure they are driven to completion.\nConsults with other large project team leaders to determine how best to address a new or unique problem.\nAnalyzes project requirements to determine time and resources required.\nReviews and advises on coding efforts to ensure that projects are completed to specification.\nWorks with high-level representatives from other functions (e.g., testing group, product group, customers) to integrate plan for software design of large initiative.\nNetworks with customers and colleagues within and outside of Qualcomm to gain insight, ideas, and connections.\n\nDiscusses state of software solution, approach, or other information with customers and others outside of Qualcomm.\n\nREQUIRED COMPETENCIES\n\n(All competencies are required upon entry)\nAnalyzing Complex Information - The ability to collect information from a variety of different sources (e.g., platform level performance, resource constraints, performance dashboards, etc.), and identify fundamental patterns/trends across sets of highly complex data. This includes the ability to gather, integrate, and interpret high level information from multiple sources.\nBuilding Trusting Relationships - The ability to build trusting, collaborative relationships and rapport with different types of people and businesses. This includes delivering on commitments and maintaining confidential information, as well as being approachable, showing interest in the other person, and relating well to people regardless of personality or background.\nCommunicating Effectively - The ability to compellingly communicate one's perspectives and ideas to all levels of the organization. This includes the ability to convey complex information in an engaging way, adapt the message, delivery, and point-of-view based on the audience's real-time or anticipated reactions. This also includes active listening, and eliciting questions, participation, and buy-in from the audience.\nCommunication - The ability to convey information clearly and accurately, as well as choosing the most effective method of delivery (e.g., email, phone, face-to-face). This includes using a technically sound communication style both verbally and in writing.\nCreating the New and Different - The ability to be creative. This includes the ability to produce breakthrough ideas, being a visionary, managing innovation, seeing multiple futures, having broad interests and knowledge, and gaining support in order to translate new ideas into solutions. This also includes the ability to plan and implement unconventional ideas and speculate about alternative futures without all of the data.\nDealing with Conflict - The ability to quickly and directly address problems, find common ground, and persevere on tough assignments. This includes having the willingness to be centrally involved in debates and facilitating conflict discussion and resolution.\nDecision Making - The ability to make quick, accurate decisions. This includes the ability to weigh alternatives and take into account the impact of the decisions on people, equipment, or other resources.\nDemonstrating Personal Flexibility - The ability to demonstrate resourcefulness and resilience in the face of change, obstacles, and adversity. This includes adapting to competing demands and shifting priorities. This also includes improving adaptability, pursuing new skills and knowledge, and regularly seeking feedback from others.\nGetting Organized - The ability to be organized, resourceful, and planful. This includes the ability to leverage multiple resources to get things done and lay out tasks in sufficient detail. This also includes the ability to get things done with fewer resources and in less time, work on multiple tasks at once without losing track, and foresee and plan around obstacles.\nMentoring and Coaching - The ability to develop, coach, and mentor associates. This includes the ability to provide development experiences and network opportunities, advise, and teach to prepare associates for effective job performance.\nSoftware Engineering - Knowledge of the overall process for developing new software. This includes knowledge of the roles and responsibilities of software engineering and other functions, major phases, checkpoints and deliverables. This also includes the ability to identify common issues and considerations for bringing a new product to the marketplace.\nSoftware Optimization - Knowledge of techniques and approaches to optimize software for specific hardware platforms. This includes basic practices in software optimization and the interaction between software and the hardware platform.\nTaking Initiative - The ability to attack work activities with drive and energy, understanding the impact of work on key metrics, and making decisions that are in the company's best interest. This includes not being afraid to initiate action before all the facts are known, and driving value-added work tasks to completion.\nTechnical Troubleshooting - Knowledge of systematic approaches to solving common technical problems (e.g., hardware, software, application, operational). This includes the ability to identify problems and report and escalate problems according to established procedures. This also includes the ability to identify available resources for troubleshooting.\nTime Management - The ability to quickly prioritize mission-critical from less important or trivial work activities. This includes sensing what the next most useful thing is to work on, and focusing on the critical few tasks that add value while putting aside or delaying the rest.\nMinimum Qualifications\nBachelor's degree in Engineering, Electronics and Communication Engineering, Information Systems, Computer Science/Engineering or related field.\n8+ years Software Engineering or related work experience.\n4+ years experience with Programming Language such as C, C++, Java, Python, etc.\nPreferred Qualifications\nStrong knowledge and hands-on experience with the OS concepts, Linux Device Driver, and other RTOS, Hypervisors, Containers etc\nExperience with the wireless Modem technologies such as 4G/5G, DSDA, DSRC/CV2X, Antenna & Compensator SW design and Validation.\nExperience with the Telematics Modules architecture, SW Design and Development and commercialization.\nKnowledge on the Automotive systems and experience with the SW development according to ASPICE and other agile methodologies.\n4+ years experience with Programming Language such as C, C++, Java, Python, etc.\n15+ years Software Engineering or related work experience.\n5+ years experience working in a large matrixed organization.\n3+ years of work experience in a role requiring interaction with executive leadership (e.g., Director/ Sr Director or Vice President level and above).\nMaster's Degree in Engineering, Electronics and Communication Engineering, Information Systems, Computer Science/Engineering or related field.\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 8+ years of Software Engineering or related work experience.\nORMaster's degree in Engineering, Information Systems, Computer Science, or related field and 7+ years of Software Engineering or related work experience.\nORPhD in Engineering, Information Systems, Computer Science, or related field and 6+ years of Software Engineering or related work experience.\n4+ years of work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['container', 'mac', 'rtos', 'hypervisor', 'linux device drivers', 'c++', 'hiring', 'networking', 'staffing', 'apex', 'salesforce', 'java', 'data loader', 'recruitment', 'linux', 'software engineering', 'visualforce', 'python', 'c', 'data analysis', 'sfdc', 'vmware', 'microsoft azure', 'triggers', 'salesforce crm', 'aws']",2025-06-12 14:17:27
Computer Operator,Sai Space Engg.,0 - 5 years,"36,000-1.2 Lacs P.A.",['Jamshedpur( Telco Colony )'],Responsibilities:\n* Enter data into computer systems accurately using MS Office software\n* Manage email correspondence and calendar scheduling\n* Maintain database integrity through regular backups and updates\n\n\nFlexi working\nOver time allowance\nAnnual bonus\nReferral bonus,Industry Type: Electronics Manufacturing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Computer Operating', 'Word Processing', 'Typing', 'Excel Powerpoint', 'Computer', 'English Typing', 'Internet', 'Data Entry', 'MS Office', 'MS Office Word', 'Data Entry Operation']",2025-06-12 14:17:29
"Software Developer , Software Testing Fresher &Experience- 0 To 4 yrs",Prime Time Solutions Pune,0 - 4 years,3-8 Lacs P.A.,"['Navi Mumbai', 'Pune']","Urgent Job Opening - Multiple\n\n1) Designation - Software Developer ,Java, . Net , Python, PHP, SQL, Data science ,Data Analyst\n\n2) Designation - Manual Testing & Automation Testing\n\nExperience- 0 to 4 yrs\n\nSalary - 4 to 9 Lakh\n\nJob Location - Pune",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Java', 'Manual Testing', 'SQL', 'Software Developer', 'Python', 'C++', 'Data science', 'Data Analyst', 'Linux', 'Automation Testing', 'PHP', '. Net', 'Python Development', 'AWS']",2025-06-12 14:17:31
In-Business Control - Operations,Crisil,1 - 2 years,Not Disclosed,['Pune'],"Role Overview:\nThe IBCOO Group is seeking a Retainer to provide operational support for the Ratings line of Business within the In-Business Control Group. This role focuses on access control activities, including conducting periodic and non-periodic access reviews, managing access control certifications and overseeing governance for transfers and leavers.\nKey Responsibilities:\nFunctional Responsibilities:\nExecute access control, ensuring timely reviews of user access and effective resolution of discrepancies.\nAnalyze system data to identify trends and share insights with stakeholders, developing targeted action plans based on findings.\nConduct independent research to enhance data understanding and inform decision-making.\nApply troubleshooting skills, including Root Cause Analysis, to identify issues and implement corrective actions.\nAdhere to strict deadlines, maintaining accurate records in compliance with internal procedures.\nRespond promptly to access-related inquiries via email or calls.\nBalance effective operational execution with a commitment to continuous improvement. - Support process stakeholders (e. g., requestors, approvers, IT application teams, compliance) through training, expertise, and clear communication.\nClient and Stakeholder Management:\nTake ownership of all deliverables, ensuring timely and high-quality execution of tasks.\nBuild and maintain strong relationships with client counterparts.\nCommunicate effectively with clients regarding task guidance, progress updates, and any challenges encountered during execution.\nCandidate Profile:\nGood communication (written and oral), interpersonal, and organizational skills.\nBasic understanding of data analysis principles.\nProficiency in Basic Excel is required; familiarity with Power BI and Python is preferred but not mandatory.\nProfessional demeanor with a collaborative mindset, capable of interfacing effectively with internal and external stakeholders.\nDiligent, intellectually curious self-starter with a strong work ethic and a drive for success.\nEssential Qualifications:\nBachelor s degree with 1-2 years of experience in operational processes, preferably in Risk & Control processes.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Access control', 'Root cause analysis', 'Basic', 'Data analysis', 'Risk control', 'power bi', 'Stakeholder management', 'Troubleshooting', 'Operations', 'Python']",2025-06-12 14:17:33
"Applied Scientist, Amazon Autos",Amazon,3 - 8 years,Not Disclosed,['Gurugram'],"Interested in building something new? Join the Amazon Autos team on an exhilarating journey to redefine the vehicle shopping experience.\nThis is an opportunity to be part of the Amazons new business ventures. Our goal is to create innovative automotive discovery and shopping experiences on Amazon, providing customers with greater convenience and a wider selection.\nYoull work in a creative, fast-paced, and entrepreneurial environment at the center of Amazons innovation. As a key member, youll play a pivotal role in helping us achieve our mission. We are looking for a highly accomplished Applied Science professional drive our science strategy, foster a culture of data-driven decision-making, and drive impactful business outcomes through advanced state-of-the-art science methodologies.\nIf youre enthusiastic about innovating and delivering exceptional shopping experiences to customers, thrive on new challenges, and excel at solving complex problems using top-notch ML models, LLM and GenAI techniques, then youre the perfect candidate for this role. Strong business acumen and interpersonal skills are a must, as youll work closely with business owners to understand customer needs and design scalable solutions.\nJoin us on this exhilarating journey and be part of redefining the vehicle shopping experience.\n\n\nAs an Applied Scientist in Amazon Autos, you will:\n\nShape the roadmap and strategy for applying science to solve customer problems in the Amazon AutoStore domain.\nDrive big picture innovations with clear roadmaps for intermediate delivery.\nApply your skills in areas such as deep learning and reinforcement learning while building scalable solutions for business problems.\nProduce and deliver models that help build best-in-class customer experiences and build systems that allow us to deploy these models to production with low latency and high throughput.\nUtilize your Generative AI, time series and predictive modeling skills, and creative problem-solving skills to drive new projects from ideation to implementation.\nInterface with business customers, gathering requirements and delivering science solutions.\nCollaborate with cross-functional teams, including software engineers, data scientists, and product managers, to define project requirements, establish success metrics, and deliver high-quality solutions.\nEffectively communicate complicated machine learning concepts to multiple partners.\nResearch new and innovative machine learning approaches.\n\nA day in the life\nIn this role, you will be part of a multidisciplinary team working on one of Amazons newest business ventures. As a key member, you will collaborate closely with engineering, product, design, operations, and business development to bring innovative solutions to our customers.\nYour science expertise will be leveraged to research and deliver novel solutions to existing problems, explore emerging problem spaces, and create new knowledge. You will invent and apply state-of-the-art technologies, such as large language models, machine learning, natural language processing, and computer vision, to build next-generation solutions for Amazon.\nYoull publish papers, file patents, and work closely with engineers to bring your ideas to production.\n\nAbout the team\nThis is a critical role for Amazon Autos team with a vision to create innovative automotive discovery and shopping experiences on Amazon, providing customers better convenience and more selection. We re collaborating with other experienced teams at Amazon to define the future of how customers research and shop for cars online. 3+ years of building models for business application experience\nPhD, or Masters degree and 4+ years of CS, CE, ML or related field experience\nExperience in patents or publications at top-tier peer-reviewed conferences or journals\nExperience programming in Java, C++, Python or related language\nExperience in any of the following areas: algorithms and data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing Experience using Unix/Linux\nExperience in professional software development\nExperience building complex software systems, especially involving deep learning, machine learning and computer vision, that have been successfully delivered to customers",,,,"['Unix', 'Computer vision', 'C++', 'Linux', 'Machine learning', 'Data structures', 'Product design', 'Data mining', 'Automotive', 'Python']",2025-06-12 14:17:35
Mis Executive,Export Company,3 - 5 years,2.5-3.5 Lacs P.A.,['Mumbai (All Areas)( Bhiwandi )'],"Perform in-depth data analysis using Excel formulas (e.g., VLOOKUP, HLOOKUP, SUMIFS, INDEX/MATCH), Pivot Tables, & other analytical tools to identify trends, patterns, anomalies, & opportunities for improvement.will be responsible for managing, analy\n\nRequired Candidate profile\nTranslate complex data into clear, concise, and visually appealing presentations and charts within Excel.Provide actionable insights and recommendations based on data analysis to support business",Industry Type: Textile & Apparel (Fashion),"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Mis Excel', 'Google Sheets', 'MIS Preparation', 'Textile', 'MIS Operations', 'Formulas', 'Advanced Excel', 'Excel Sheet', 'Data Entry', 'HLOOKUP', 'MIS Reporting', 'Excel Reporting', 'Computer Skills', 'Excel Report Preparation', 'Pivot Table', 'SUMIF', 'Google Drive', 'VLOOKUP', 'Mis', 'Mis Analysis', 'Data Analysis', 'Lookup', 'Pivot']",2025-06-12 14:17:38
Senior Analytics Consultant,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Analytics Consultant with a proven track record of success preferably in the banking industry.\n\nIn this role, you will:\nConsult, review and research moderately complex business, operational, and technical challenges that require an in-depth evaluation of variable data factors",,,,"['data manipulation', 'Data Engineering', 'data analysis', 'data management', 'SQL']",2025-06-12 14:17:40
Mis Executive,apply for more details,2 - 5 years,2.5-3.5 Lacs P.A.,"['Mumbai', 'Mumbai Suburban', 'Mumbai (All Areas)']","Mini 2 yrs of exp in MIS or data reporting roles; background in insurance domain is preferred,Advanced Excel skills-VLOOKUP, HLOOKUP, SUMIF, COUNTIF, Pivot Tables,Power Pivot.\nHandle large data sets with accuracy and ensure timely report delivery.\n\nRequired Candidate profile\nResponsible for creating,maintaining MIS reports, dashboards,data analysis to support business decisions.\nStrong analytical mindset with attention to detail,ability to troubleshoot data-related issues\n\nPerks and benefits\nTo be disclosed post interview",Industry Type: Financial Services,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['MS Excel', 'MIS Operations', 'Insurance Domain', 'MIS Reporting', 'MIS Executive', 'data analysis', 'Conditional Formatting', 'Advanced Excel', 'Troubleshooting', 'dashboards', 'HLOOKUP', 'COUNTIF', 'Pivot Table', 'SUMIF', 'report delivery', 'MIS', 'VLOOKUP', 'Power Pivot', 'MIS reports', 'Management Information System']",2025-06-12 14:17:42
Senior Manager- Hub Operations - Rajpura Chandigarh,Delhivery,4 - 9 years,12-15 Lacs P.A.,"['Chandigarh', 'Rajpura']","Hi,\n\nPFB the key responsibilities:\n\nPlanning, Organizing & Monitoring end to end line haul operations which includes all modes of transportation (Air, Road, and Rail)\nManage the weekly creation and daily management of the linehaul schedule and associated systems\nProper implementation of the policies and is a part of audit team to find gaps and provide time to time solutions\nMonitoring commercial connections, vehicles availability and daily follow up for the held back shipments\nMaintain the shipment records for each client\nMaintain the SLA for each shipment to be received at customer premises within scheduled time.\nWork with forecasting team to drive improvement of the base forecast\nManage and perform ongoing analysis to work with appropriate teams to develop and improve scheduling methodologies and systems\nManage and improve scheduling metrics to identify trends and shortcomings and drive scheduling accuracy\nFacilitate communication and coordination with different teams and coordinate for the creation of a schedule that meets all stakeholders expectations and concerns.\n*Candidate should be flexible to work in shifts* *6 days working*",Industry Type: Courier / Logistics (Logistics Tech),Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Supply Chain Operations', 'Reverse Logistics', 'Inbound Logistics', 'Outbound Logistics', 'Data Analysis', 'Hub Operations', 'Logistics Operations', 'People Management', 'Transport Operations', 'Warehouse Operations', '3Pl']",2025-06-12 14:17:44
Data Science Consultant,Techf Solutions,8 - 13 years,22.5-30 Lacs P.A.,['Indore'],"As a Senior AI Developer/ AI Architect in the AI team, you will work and mentor a team of developers, working on the Fusion AI Team and its AI engine AI Talos alongside research in the space, such as large language models, simulations, & agentic AI.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['RAG architecture', 'Python', 'full-stack developer', 'GitHub', 'Hugging Face', 'Jira', 'Pytorch', 'Gen AI', 'Llama2', 'Docker', 'Pandas', 'Pydantic', 'Pyarrow', 'Scikit', 'Mistral AI']",2025-06-12 14:17:47
Business Development Manager,MakeMyTrip,3 - 8 years,Not Disclosed,['Ludhiana'],"About the Opportunity:\nRole: Business Development Manager\nReporting To: Zonal Manager\nLocation: Ludhiana\nLevel: Senior Executive/Assistant Manager\n\nAbout the Function The Independent Hotels team is part of the Domestic Hotel Supply Function and this team manages supply from Independent hotels based across India and has about 70,000+ Hotels contracted on our platforms.\n\nAbout the Role The incumbent will be tasked with establishing and fostering connections with independent hotels. Oversee comprehensive key account management from start to finish, ensuring the sustainable performance of the region. This role necessitates travel to various hotels within the portfolio, delivering expert guidance, metrics analysis and recommendations based on industry best practices to our hotel partners.\n\nWhat will you be doing\n1. Relationship and Account Management :\nResponsible for connecting and engaging with independent hotels.\nEnd to end account management and driving sustainable performance of the region.\nSourcing & onboarding new hotels.\nThe role involves traveling to different hotels in the portfolio and providing expertise, metrics analysis and recommendations based on the industry's best practices to the hotel partners.\n2. Portfolio Management and Driving Growth :\nGrowing net revenue in the market by developing business plans to achieve revenue goals, ensuring inventory levels exceed demand throughout the market, and maintaining rate competitiveness across multiple available platforms.\n3. Data Analysis and Reporting:\nEstablishing and maintaining supplier relationships, training partner hotels on our extranet and wholesale business, reviewing monthly production reports, providing feedback to top-producing hotels, and planning and executing market site visits.\nBuilding MIS & market intelligence reports, preparing geography wise and service wise sales plans and achieving them. Sharing insights on market and industry with the clients and internal stake holders.\n4. Negotiating:\nNetworking, Deal initiating, negotiation & closing deal with the clients.\nStrategizing in order to market the hotel in a better way. It helps hotel partners to serve the needs of their customers and at the same time grow their businesses.\n\nQualification & Experience\nMasters degree from a reputed institute with 2- 6 years of experience in sales/Travel\nTrade/ Key Account Management/ Contracting/B2B Sales\nExperience in handling multiple accounts as a partner is preferred.\nProficiency in MS Excel and MS Power-point\n\nKey Success Factors for the Role\nStrong communication skills, Influencing skills, great interpersonal & stakeholder management skills.\nHigh on energy, team player coupled with a great attitude.\nProficiency in MS Excel and MS PowerPoint is essential.",Industry Type: Internet,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Business Development', 'Client Onboarding', 'Client Acquisition', 'New Business Development', 'Revenue Generation']",2025-06-12 14:17:50
Sr. Technology Auditor,AMERICAN EXPRESS,2 - 4 years,13-18 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Role & responsibilities\n•       Translate business risks, controls and supporting data into analytic requirements and partners with colleagues to build effective analytics and insights\n•       Responsible for multiple simultaneous audit projects of all sizes and complexity across multiple business areas within and outside of local region, in unfamiliar areas, and for different audit leaders\n•       Link analytics and insights to ongoing strategic initiatives\n•       Apply proven/ advanced data algorithms, advanced analytic and modeling techniques to draw insights essential to driving improvement initiatives",,,,"['Natural Language Processing', 'Tableau', 'Machine Learning', 'SQL', 'Python']",2025-06-12 14:17:52
Mis Executive,Hire Best Recruitment Company,3 - 5 years,3-4 Lacs P.A.,['Panaji'],"1. Practical experience with a variety of software applications like Excel/Advanced Excel/MS Access VBA/ Macros are an additional advantage.\n2. Attention to details.\n3. Proficiency in Microsoft Office and writing emails,\n\nRequired Candidate profile\nManage students related information including absenteeism, fee submission and processing, timetable/teacher’s updates etc\n.\nJob Location - Panaji Goa\nWeek Off - Rotational\n\nPlease call on\n9560477391",Industry Type: E-Learning / EdTech,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['MIS', 'Data Validation', 'Countif', 'MIS Operations', 'Formulas', 'Conditional Formatting', 'Charts', 'Advanced Excel', 'HLOOKUP', 'Macros', 'MIS Reporting', 'Pivot Table', 'SUMIF', 'Filters', 'Pivots', 'Excel', 'VBA', 'MS Access', 'VLOOKUP', 'Data Analysis', 'Lookup', 'Pivot', 'Dashboards', 'Management Information System']",2025-06-12 14:17:54
BD MIS Executive,Nuvoco Vistas Corporation (Nuvoco),2 - 5 years,3-6 Lacs P.A.,['Kolkata'],"Role & responsibilities Preferred candidate profile\nInteract with State BD Team to drive below mentioned key objective:\nBudgeting, Provisioning & Monitoring of sales Vs cost / MT as a monitoring tools at State level.\nTeam KPI Vs Actual compliance analysis, publishing State Performance Dash Board\nBudget control & collaboration with state BD team, raising PR in accordance with HO requirement.\nPerformance Monitoring, Checking, Circulation, Ranking, Review with State BD Team\nGift Stock reconciliation, BD MIS, IC, MRM data preparation at State Level.\nMonitoring State BD Team productivity increase by 10% Month on Month\nReporting and monitoring BD Dashboard data of State BD team.\nFlash report on Shubharambh, Utkarsh,Baat-Cheet & MayDay programs at State level.\nDetailed reporting and analysis on sales promotional activities. Reconciliation of BD Gifts and Stock.\nAnalysis of contractor lifting through Vriddhi Loyalty program\nAnalysis on enrollments of influencers & activation\nTracking of Enrollment in Nuvo Nirman App & Usage.\nSharing lead generated report by Nuvo Nirman App.\nClose coordination with State Sales data to achieve BD specific goals.\nFlash quality complaints report weekly basis.\nRaising PR at State level for BD Activity and follow up with Vendor\nTimely clearance of payment and bills follow up with accounts & finance team.\nImplementation of innovative ideas to increase maximum utilization of State BD Dashboard.\nCost optimization on services and State BD activities expenditure.\nBudget planning, analysis and execution (Cost/MT)\nPreparing of Special reports & Presentation for Sales & BD review.\n\n\nPreferred candidate profile\n\n2-3 years of experience in a similar organisation",Industry Type: Miscellaneous,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['MIS', 'Sales Mis', 'Advanced Excel']",2025-06-12 14:17:56
Senior AI Camera Systems Engineer,Qualcomm,2 - 4 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n2-4 years of experiences in image processing/computer vision/camera domain.\nWorking experience with machine learning framework/packages (e.g, PyTorch, TensorFlow, Keras etc.)\nStrong hands on experience on developing object detection, tracking or face detection algorithms.\nStrong background in image and signal processing, statistics, and data analysis.\nDeveloping machine learning algorithms for advanced imaging features\nStrong programming skills and working experience in C/C++\\ assembly programming skills, multithreading and RTOS/OS concepts\\fundamentals and Python.\nStrong debugging skills to debug complex system level issues.\nCollaborate with cross-functional teams to design, implement and debug camera\\multimedia features for mobiles.\nGood analytical and problem-solving skills.\n\n\nResponsibilities:\nDevelopment and productize camera essential features on Qualcomm chipsets for mobile\nInfluence camera HW architecture in Qualcomm chipsets\nCollaborate with systems, software, hardware teams at various stages of chipset life in design/validation/commercialization.\nCustomer interaction to commercialize Qualcomm camera solutions.\nIndividual contributions and working with cross functional teams on camera essential features design/planning/execution/commercialization for future Snapdragon chipsets\n\n\nEducation requirements:\nRequiredBachelor's/Masters/PHd Computer Engineering and/or Electrical / Electronic Engineering\nPreferred Masters\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['algorithms', 'data analysis', 'signal processing', 'debugging', 'statistics', 'image processing', 'python', 'c++', 'c', 'object detection', 'machine learning', 'imaging', 'mac', 'hw', 'tensorflow', 'rtos', 'computer science', 'computer vision', 'pytorch', 'keras', 'multithreading', 'system engineering']",2025-06-12 14:17:59
Senior Business Project Manager,Thryve Digital,9 - 14 years,Not Disclosed,"['Hyderabad', 'Chennai']","Job Summary:\n\nThis role collaborates across client teams to uncover, synthesize, analyze, and present critical information, supporting the team to identify insights and shape recommendations. The consultant will translate data analysis into a cohesive narrative, presenting findings clearly to both the team and clients. This position provides analytical support to the Enterprise Effectiveness team and requires excellent customer service and a proactive, problem-solving approach. The ideal candidate possesses a strong analytical mindset with the intuition to ask clarifying questions to uncover deeper insights.\nEssential Responsibilities:\n\nManage the entire analysis process from inception to completion, including advising on data nuances, providing suggestions on methodology, and preserving data security and integrity.\nDefine the design and layout of each analysis, working with clients to ensure data accuracy and quality. This includes conducting market research and performing rigorous data analysis. Develop compelling visualizations within PowerPoint and Excel.\nConduct research, data analysis, and benchmarking to inform decision-making. Support the development of strategic recommendations for internal business challenges. Assist in preparing executive-level presentations and reports.\nAnalyze workflows, identify inefficiencies, and propose process enhancements. Support implementation of leading practices to improve business performance.\nAssist in financial/business modeling, business case development, and cost-benefit analysis. Use data analytics to generate insights and support internal projects. Monitor trends and provide actionable insights to leadership.\nSupport client and customer immersion activities, including stakeholder interviews and market research.\nDevelop compelling presentations with a clear point of view, using formats such as PowerPoint. Clearly articulate findings and recommendations in a concise and impactful manner.\nWork effectively with teams across multiple departments to execute strategic initiatives. Assist in project management, including tracking deliverables and coordinating stakeholders. Support project teams in driving change management.\nEducation:\nBachelors degree in business, Engineering, or a related field (or equivalent experience).\n\nExperience:\nOverall Experience looking for 10 -15 Years with project management role.\nRequired: 2 years in strategy, operations, M&A, organizational development, general management, or a related field within a consulting firm or other professional environment.\n\nPreferred: Experience working in complex, matrixed environments or in the US Healthcare, Insurance industry.\n\nSkills:\n\nAbility to synthesize analysis, recommend actions, and prioritize next steps.\nDemonstrated ability to exercise initiative, independent judgment, and be a self-starter.\nAdvanced knowledge of Excel and PowerPoint, including data visualization techniques.\nStrong written and oral communication skills.\nSolid organizational skills and meticulous attention to detail.\nDemonstrated ability to use complex and interrelated data to generate insights.\nStrong analytical and problem-solving skills; intuition to ask clarifying questions where ambiguity exists.\nAbility to translate data analysis into a cohesive story via presentations.\nAbility to work independently while collaborating with global teams.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Project management', 'data analytics', 'data analysis', 'business modeling', 'customer service', 'business case development', 'business analysis', 'business analytics', 'data visualization', 'market research', 'organizational development']",2025-06-12 14:18:02
Senior Operational Risk Specialist,Wells Fargo,4 - 9 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a Senior Operational Risk Specialist\n\nIn this role, you will:\nManage the development, implementation, and monitoring of a risk-based program for a business or large functional area with moderate to high risk to identify, assess and mitigate operational risk that arises from inadequate or failed internal processes, people, systems, or external events",,,,"['Operational Risk', 'data analysis', 'SAS', 'Risk & Control', 'SQL']",2025-06-12 14:18:04
Senior Consultanr - AI Cloud Engineer,AstraZeneca India Pvt. Ltd,5 - 10 years,Not Disclosed,['Chennai'],"Job Title: Senior Consultant - AI Cloud Engineer Career Level: D2 Introduction to role:\nAre you ready to tackle some of the most exciting machine-learning challenges in drug discovery? We are seeking a Senior AI Platform Engineer to join our innovative AI platform team, IGNITE. With your expertise in AWS cloud environments, youll design and deploy large-scale production infrastructure that will redefine healthcare and improve the lives of millions worldwide. As part of a close-knit team of technical specialists, youll create tools that support major AI initiatives, from clinical trial data analysis to imaging and Omics. Your role will be pivotal in providing frameworks for data scientists to develop scalable machine learning models safely and robustly. Are you prepared to bridge the gap between science and engineering with your deep expertise?\nAccountabilities:\nDesign, implement, and manage cloud infrastructure on AWS using Infrastructure as Code (IaC) tools such as Terraform or AWS CloudFormation.\nMaintain and enhance CI/CD pipelines using tools like GitHub Actions, AWS CodePipeline, Jenkins, or ArgoCD.\nEnsure platform reliability, scalability, and high availability across development, staging, and production environments.\nAutomate operational tasks, environment provisioning, and deployments using scripting languages such as Python, Bash, or PowerShell.\nEnable and maintain Amazon SageMaker environments for scalable ML model training, hosting, and pipelines.\nIntegrate AWS Bedrock to provide foundation model access for generative AI applications, ensuring security and cost control.\nLead and publish curated infrastructure templates through AWS Service Catalogue to enable consistent and compliant provisioning.\nCollaborate with security and compliance teams to implement best practices around IAM, encryption, logging, monitoring, and cost optimization.\nImplement and manage observability tools like Amazon CloudWatch, Prometheus/Grafana, or ELK for monitoring and alerting.\nSupport container orchestration environments using EKS (Kubernetes), ECS, or Fargate.\nContribute to incident response, post-mortems, and continuous improvement of the platform s operational excellence.\nEssential Skills/Experience:\nBachelor s degree in Computer Science, Engineering, or related field (or equivalent experience).\n5+ years of hands-on experience with AWS cloud services.\nStrong experience with Terraform, AWS CDK, or CloudFormation.\nProficiency in Linux system administration and networking fundamentals.\nSolid understanding of IAM policies, VPC design, security groups, and encryption.\nExperience with Docker and container orchestration using Kubernetes (EKS preferred).\nHands-on experience with CI/CD tools and version control (Git).\nExperience with monitoring, logging, and alerting systems.\nStrong solving skills and ability to work independently or in a team.\nDesirable Skills/Experience:\nAWS Certification (e.g., AWS Certified DevOps Engineer, Solutions Architect - Associate/Professional).\nExperience with serverless technologies like AWS Lambda, Step Functions, and EventBridge.\nExperience supporting machine learning or big data workloads on AWS.\nExperience with SAFe agile principles and practices.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Data analysis', 'Version control', 'Networking', 'Machine learning', 'Agile', 'Healthcare', 'Monitoring', 'Python', 'Recruitment']",2025-06-12 14:18:06
Senior Software Engineer - Adobe Experience Platform ( AEP ),Wells Fargo,4 - 7 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a senior Software Engineer - Adobe Experience Platform (AEP)\nIn this role, you will:\nLead moderately complex initiatives and deliverables within technical domain environments\nContribute to large scale planning of strategies\nDesign, code, test, debug, and document for projects and programs associated with technology domain, including upgrades and deployments",,,,"['Software Engineering', 'Data Science', 'data model', 'data analysis', 'data modeling', 'configuration', 'APIs', 'AEP', 'CDP']",2025-06-12 14:18:08
Senior .Net Full stack Developer,Conduent,4 - 9 years,Not Disclosed,['Noida'],Job Track Description: \n\n Responsibilities \nDesign and develop highly scalable web based applications based on business needs.\nAnalyze user needs and develop software solutions using agile methodology.\nPerform data analysis using SQL Server.\nDevelop and maintain a thorough understanding of business needs from both technical and business perspectives\nAssist and mentor junior team members to enforce development guidelines.\nEffectively prioritize and execute tasks in a high-pressure environment\n\n\n Qualifications / Experience \nBachelor\\u2019s/Master\\u2019s degree in Computer Science / Computer Engineering\nMinimum of 4+ years\\u2019 experience in building enterprise scale N-tier web application using Microsoft .NET technologies.\n3+ years of experience in ASP.NET MVC\n2+ years\\u2019 experience on WCF Services or Microsoft Web API\n1+ years of experience in Angular 2 or higher is mandatory\nExperience with Agile application development.\nStrong knowledge of HTML5 and CSS3\nSQL server performance tuning (SQL Server 2008/2012/2014)\nWorking knowledge of SSRS and SSIS is plus\nAbility to work with a sense of urgency and attention to detail\nExcellent oral and written communication skills.,Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['css', 'html', 'web api', 'angular', 'asp', 'web application', 'devexpress', 'jquery', 'sql', 'ssrs', 'asp.net', 'mvc', 'wcf', 'api', 'microsoft net', 'agile methodology', 'c#', 'asp.net mvc', 'net mvc', 'sql server', 'wcf services', 'application development', 'asp.net core mvc', 'winforms', 'full stack', '.net', 'agile', 'ssis']",2025-06-12 14:18:10
Senior SailPoint Developer,Synechron,7 - 10 years,Not Disclosed,['Gurugram'],"Required Skills:\nExtensive hands-on experience with SailPoint IdentityIQ (IIQ) including onboarding, rule creation, object configuration, and application integration\nProficiency in core Java development for customization and extension of SailPoint functionalities\nStrong understanding of IAM concepts, including RBAC, SODs, role mining, and access provisioning\nExperience with API integrations via SCIM, web services, and REST APIs\nKnowledge of scripting languages to develop or customize workflows (e.g., Java, Groovy, or similar)\nFamiliarity with version control tools such as Git\nBasic understanding of enterprise ticketing platforms like Remedy or JIRA for provisioning and workflow integration\nPreferred Skills:\nUnderstanding of cloud IAM solutions or cloud migration considerations\nKnowledge of LDAP, Active Directory, or other directory services\nExperience with SailPoint out-of-the-box connectors and customizing them\nOverall Responsibilities\nLead design, implementation, and support of SailPoint IdentityIQ solutions, including onboarding applications, roles, certifications, reports, and workflows\nSupport the full SDLC (requirements, design, development, testing, deployment, and support) in line with organizational standards and Agile practices\nTroubleshoot, debug, and resolve IAM issues to minimize orphan accounts and access anomalies\nDevelop and deploy automation utilities and enhancements to improve operational efficiency of IAM processes\nCollaborate with vendors and internal teams to incorporate new features, perform upgrades, and resolve platform issues\nConduct regular performance reviews of IAM processes post-change deployment to ensure stability and security compliance\nDocument technical solutions, process workflows, and support artifacts for knowledge sharing and audits\nDrive continuous improvement initiatives and assist in feasibility analysis for cloud migrations and emerging IAM technologies\nTechnical Skills (By Category)\nProgramming Languages:\nEssential: Java, Groovy (for customization and workflow development)\nPreferred: Python, JavaScript for automation scripting\nDatabases & Data Management:\nBasic understanding of relational databases (e.g., Oracle, SQL Server) for audit reports and data analysis\nCloud Technologies:\nPreferred: Knowledge of cloud platforms (AWS, Azure) with focus on IAM aspects\nFrameworks & Libraries:\nFamiliarity with API standards (SCIM, REST) and integration protocols\nDevelopment Tools & Methodologies:\nEssential: Git, Agile/Scrum practices, version control, DevOps methodologies\nPreferred: CI/CD pipelines (Jenkins, Bitbucket pipelines)\nSecurity Protocols:\nUnderstanding of SAML, OAuth, LDAP, and other security standards\nExperience Requirements\n7 to 10 years of professional experience in IAM, with deep focus on SailPoint IdentityIQ implementations\nProven success managing complex identity management projects, including onboarding, provisioning, and role management\nDemonstrated ability to analyze and translate business requirements into technical IAM solutions\nExperience supporting identity security policies, SOD, and role mining workflows\nPrior experience with enterprise IT environments and vendor support collaborations preferred\nDay-to-Day Activities\nImplement and customize SailPoint IdentityIQ applications and components to meet project requirements\nConduct system configuration, testing, and deployment activities, ensuring compliance with organizational standards\nTroubleshoot identity and access issues, providing timely resolutions and root cause analysis\nDevelop scripts and utilities to automate manual processes, enhancing operational efficiency\nLiaise with vendors (like Cloudera or other platform providers) for platform support and feature enhancements\nPerform regular system performance reviews and capacity planning exercises\nProvide technical guidance and knowledge transfer to team members and stakeholders\nMaintain documentation of configurations, workflows, and system changes\nQualifications\nEducational Requirements:\nBachelors degree in Computer Science, Information Technology, or related field\nEquivalent professional experience in IAM or identity management\nCertifications (Preferred):\nSailPoint Certified IdentityIQ Engineer or similar IAM certifications\nTraining & Professional Development:\nCommitment to ongoing learning related to identity security, cloud IAM solutions, and emerging technologies\nProfessional Competencies\nCritical thinker with strong problem-solving skills\nEffective communicator with clarity in technical and non-technical language\nCollaborative team player able to work across geographically dispersed teams\nAbility to prioritize, manage time effectively, and adapt to changing project scopes\nProactive with a focus on continuous process improvement and innovation\nAnalytical mindset for identifying risks and implementing mitigation strategies",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SailPoint', 'Git', 'IAM', 'LDAP', 'CI/CD', 'Agile', 'Scrum', 'cloud IAM', 'SAML', 'OAuth']",2025-06-12 14:18:13
MIS Executive,Wipro,1 - 3 years,Not Disclosed,['Kolkata'],"Role Purpose\n\nThe purpose of the role is to provide timely, accurate and quality MIS reports, dashboards to the external & internal stakeholders of account(s) as per the defined process and standards of security and compliance\n\n\n\nDo\nPrepare timely and accurate MIS reports and dashboards as required by the stakeholders\nInteract and work closely with management, internal stakeholders & clients to understand the business information needs\nEnsuring all reports & dashboards are prepared as per stakeholder requirements as per the desired frequency (weekly/ monthly/ quarterly)\nEnsure regular review with the MIS Team Lead for 100% accuracy before populating any customized dashboard or generating any customized report\nTrack and follow up with relevant stakeholder for timely updation and data management of parameters (key SLA metrics such as run-rate etc.)\nGenerate account level reports (billable and non-billable) on forecasting, scheduling (both onshore and offshore) and performance against SLAs, CSAT, Quality etc.\nEnsure zero non-compliances on process audit on data security and compliance\nSupport and adopt tools and systems for efficient MIS generation and reporting system\nContinuous support to the manager in rolling out new techniques and initiatives to increase productivity\nProviding update to the manager on the progress of any new MIS initiatives\nPerform periodic maintenance and servicing of MIS system to improve operational efficiency\nAdopt new tools, technology solutions and develop capability through training to improve own productivity.\nDevelop analytical skills and understanding of statistical analysis to suggest improvement in the quality of analysis\nDeliver\nNo.Performance ParameterMeasure\n1. MIS Management and Reporting Quality of Analysis\nZero errors in reports\nZero non-conformance on timelines with respect to the client/ stakeholder requirements\n2.Stakeholder Management Customised dashboards as per client and functional requirements\nZero escalations on data reporting\nZero non-conformance on security or compliance requirements\n3.Team Management Team attrition %, Employee satisfaction score\nMandatory Skills: MIS.",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['MIS', 'data management', 'data reporting', 'advanced excel', 'dashboards']",2025-06-12 14:18:15
Adobe Analytics Specialist,Ltimindtree,5 - 7 years,Not Disclosed,['Bengaluru'],Reporting Dashboarding Data Analysis Insights\nStrong handson experience of Adobe Analytics Workspace in generating differentall types of CustomStandard Reports like Funnel Performance Path Analysis Fallout and End to End Customer Journey Analysis\nMust have working knowledge of AA dashboards designing and ad hoc reports to showcase trends progressspikefall rate across business KPIs and goals which provide stakeholders a clear understanding of digital performance\nSound functional knowledge on building segmentscrosssegmentation and calculated metrics to better understand user experience conversion based on data factors like source channel visitor frequency CLV and Demography etc\nAbility connect data from different data sources Media Campaign Web Analytics CRM First Party and Third Party etc Performance to design selfexplanatory dashboards\nGood understanding of AA OOB AddonsPlugins APIs to derive Automation Anomaly Detection and ReportingTagging Process Optimization\nMust have ability of story telling out of the data analysis for key business decision making for marketing leaders\nWell versed in conducting indepth analysis to identify improvement opportunities and provide actionable recommendations for data monetization and marketing strategies\nAbility to stich data across customer touch points within 1st Party website and later if user navigates to 3rd Party Partner Site and make it meaningful to leverage customer targeting as well as for personalization\nWeb Campaign TaggingData Collection\nGood experience in developing designing measurement frameworks across CLEs to stitch customer journeys\nCross Collaborate with DevelopmentIT Teams to ensure proper data collection and implementation of the required tags\nHands on experience in implementation of Thirdparty media pixels Creation of Campaign Tags and Custom Tracking codes as well as first party tags on site\nShould have sharp IQ for Data Validation Verification of website and campaign tagging which required QA across all stages of tagpixel implementation\nIdentify issues proactively and work closely with cross functional teams to recommend resolutions and enhancements\nOthers\nStay updated on industry trends and best practices in Web Analytics space recommending and implementing updates and optimizations\nShould have understanding of personalized customer targeting out of web and campaign performance analytics to derive the better ROI\nTraining and Support Provide training and support to internal teams on Adobe Analytics tools and methodologies\nTechnoFunctional Skills\nAdobe Analytics and Adobe Launch\nCampaign and Web Tagging Media Pixel Implementation\nCrossDevice Analytics Predictive Analytics Attribution Modeling RealTime Reporting Advance Segmentation MultiChannel Data Collection\nWorkspace Data Warehouse Reporting\nBasic understanding of htmljavascript,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Automation', 'Data validation', 'Process optimization', 'adobe analytics', 'Web analytics', 'Javascript', 'Data collection', 'HTML', 'CRM']",2025-06-12 14:18:18
Mis Executive / Edp Officer,Aakash Educational Services (AESL),1 - 6 years,3-5 Lacs P.A.,['Mumbai (All Areas)( Shanti Nagar Borivali )'],"Job Title: EDP Officer / MIS\nDepartment: Branch Operations\nReporting To: ABM Operations\nLocation: Borivali\n\nWhy Join AESL?\nPan-India Presence: Over 300 branches, offering vast growth opportunities.\nStudent-Centric Culture: Join 10,000+ professionals working with expert faculty to mentor and guide students.\nInnovative Environment: Work with cutting-edge digital learning tools in a fully digitized and hybrid classroom setup.\nProven Track Record: Join a team that helped produce 1,15,000+ NEET & JEE qualifiers in a single year, including 8 NEET AIR 1 ranks and 50+ top JEE ranks.\nJob Responsibilities:\nProcess admission forms, test results, and other academic documents.\nMaintain accurate student data (both historical and current) at the branch level.\nAnalyze student data and generate reports as needed.\nEnsure timely and accurate information delivery to relevant stakeholders.\nQualifications & Skills:\nGraduate in any discipline with relevant experience in desktop publishing.\nProficiency in Advanced Excel (Pivot Tables, VLOOKUP, HLOOKUP, Filters, Logical Formulas, VBA Macros).\nBasic working knowledge of MS Word and PowerPoint.\nWorking experience with the following tools is preferred:\nAdobe PageMaker\nCorelDRAW\nAdobe Photoshop\nMathType / Equation Editor\nMicrosoft Access\nKey Competencies:\nStrong attention to detail and organizational skills\nEffective planning and prioritization abilities\nAccuracy in data handling and reporting\n\nIndustry: Education / Training / Teaching\nFunctional Area: Branch Operations / EDP\nRole Type: Full-Time, Permanent",Industry Type: Education / Training,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Advanced Excel', 'Pivot Table', 'MIS Operations', 'VLOOKUP', 'Macros', 'HLOOKUP']",2025-06-12 14:18:20
Applied Research Center (ARC),Infosys,5 - 10 years,Not Disclosed,['Bengaluru'],"Responsibilities\n1. Emerging Tech Trends Research - Research on emerging tech trends, ecosystem of players, use cases and their applicability and impact to client businesses. Scan & curate startups, universities and tech partnerships needed and create innovation ecosystem. Rapidly design and develop PoCs in Emerging tech areas. Share design specifications with other team members, get the components developed, integrate and test. Build reusable components and develop PoCs using relevant startups and Open-source solutions.\n2. Thought Leadership - Develop showcases that demonstrate how emerging technologies can be applied in a business context, demo scenarios for the IP. Contribute towards patents, tier-1 publications, whitepapers, blogs in the relevant emerging tech area Get certified on the emerging technology, frameworks\n3. Applied Research Center Activities - Contribute to high level design development, testing and implementation of new proof of concepts in emerging tech areas.\n4. Problem Definition, Requirements - Understand technical requirements and define detailed design. Analyze the reusable components to map the given requirement to existing implementation and identify needs for enhancements\n5. IP Development - Develop program level design, modular components to implement the proposed design. Design and develop reusable components. Ensure compliance with coding standards, secure coding, KM guidelines while developing the IP\n6. Innovation Consulting - Understand client requirements and implement first of kind solutions using emerging tech expertise. Customize and extend IP for client specific features\n7. Talent Management - Mentor the team and help them acquire the identified emerging tech skill. Participate in demo sessions, hackathons8. Emerging Tech Startup Ecosystem Work with startups in providing innovative solutions to client problems and augmenting Infosys offerings\nTechnical and Professional Requirements:\nApplied Research Center [Emerging Areas]Advanced AI [SLM, Inference Scaling, Synthetic Data, Distributed Learning, Agentic AI, ANI]New Interaction Models [Spatial computing, Mixed Reality, 3D visualizations, New Experiences]Platforms and Protocols [Architecting and engineering for Performance, Uptime, Low-latency, Scalability, Efficiency, Data, Interoperability and Low cost, Beckn, CDPI]Cybersecurity [Ethical hacking, Threat Mgmt, Supply chain security & risk, Cyber Resilience]Quantum [Quantum AI, Stack, Simulation & Optimization, Cryptography, Valued use cases]Autonomous Machines [Humanoids, Industrial Robots, Drones, Smart Products]Emerging Research [Brain, AGI, Space, Semicon ]\nPreferred Skills:\nDomain->User Experience Design->Usability Principles->HCI\nFoundational->Learning Experience Design->Learning design Management->IP Management\nTechnology->X Reality (XR)->Augmented Reality\nTechnology->X Reality (XR)->Virtual Reality\nTechnology->Blockchain->Blockchain as a Service (BaaS)->AWS Blockchain\nTechnology->Robotic Process Automation->Intelligent Process Automation\nFoundational->Cybersecurity Competency Management->Cyber Competency Strategy Planning\nFoundational ->Data privacy->Privacy by design\nTechnology->Machine Learning->Generative AI\nAdditional Responsibilities:\nTechnical Competencies\nAdvanced theoretical knowledge in specific domain\nExperimental design and methodology expertise\nData analysis and interpretation skills\nPrototype development capabilities\nResearch tool proficiency relevant to domainSoft Skills and Attributes\nCollaborative mindset for cross-disciplinary research\nCommunication skills for knowledge dissemination\nCreative problem-solving approach\nIntellectual curiosity and innovation focus\nCommercial awareness for translational research\nEducational Requirements\nPhD of Computer Science,Bachelor of Engineering\nService Line\nGlobal Delivery\n* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['User Experience Design', 'Agentic AI', '3D visualizations', 'SLM', 'Distributed Learning', 'Inference Scaling', 'Spatial computing', 'ANI', 'Mixed Reality', 'Synthetic Data', 'New Experiences']",2025-06-12 14:18:22
MIS Executive,2coms,1 - 6 years,Not Disclosed,['Kolkata'],"SUMMARY\nWe are seeking a detail-oriented and skilled MIS Executive to join our team in New Alipore, Kolkata. The ideal candidate must be proficient in MS Excel, possess solid knowledge of accounting processes, and be experienced in generating accurate and insightful MIS reports. You will play a key role in managing data, tracking operational metrics, and supporting financial functions including TDS deductions, vendor payouts, and attendance reports.\n\nJob Title: MIS Executive\nLocation: New Alipore, Kolkata\nJob Type: Full-Time Work from Office\nIndustry:  Recruitment & Staffing\nKey Responsibilities:\nCreate, update, and manage daily/weekly/monthly MIS reports using MS Excel.\nMaintain and analyze data related to finance, operations, and HR (attendance, payroll, etc.).\nAssist in preparation of accounting statements including TDS deductions and vendor payments.\nCoordinate with finance and HR departments for timely collection and validation of data.\nHandle large data sets with accuracy and present it in a user-friendly format.\nEnsure timely and error-free report submissions to management and relevant stakeholders.\nCreate dashboards, pivot tables, VLOOKUPs, and other Excel tools for automation and reporting.\nMonitor and track key business performance indicators and operational KPIs.\nMaintain confidentiality and integrity of all financial and operational data.\n\n\nRequirementsRequired Qualifications:\nGraduate in B.Com / MBA (Finance preferred).\n1 3 years of experience in MIS reporting, accounting, or finance operations.\nStrong knowledge of MS Excel (Pivot Tables, VLOOKUP, Charts, Formulas, etc.).\nGood understanding of TDS, vendor payouts, and other accounting principles.\nAbility to analyze data and provide actionable insights.\nExcellent attention to detail, organizational skills, and time management.\nGood communication skills in English and Hindi/Bengali.\n\nBenefits\nCompetitive salary + performance incentives\n PF + ESIC\nWork Timings: 9:30 AM to 6:30 PM\nWeekly Offs: 2nd & 4th Saturdays\nInterested? Apply Now!\nInterested candidate kindly share your CV on 843684365",Industry Type: Recruitment / Staffing,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['charts', 'tds', 'formulas', 'vlookup', 'accounting', 'dashboards', 'tables', 'operations', 'recruitment', 'mis', 'vendor', 'english', 'bengali', 'pivot', 'reporting', 'communication skills', 'process', 'mis reporting', 'time management', 'pivot table', 'monitoring', 'vendor payments', 'excel', 'financial operations', 'hindi', 'payroll']",2025-06-12 14:18:25
Manufacturing Engineering,Exide,8 - 13 years,Not Disclosed,['Bengaluru'],"Manufacturing Engineering Roles at Exide Energy Bengaluru\nExide Energy Solutions Ltd is actively recruiting for Manager, Deputy Manager, and Assistant Manager positions within its Manufacturing Engineering team at the Bengaluru Gigafactory. These roles are integral to the development, ramp-up, and optimization of lithium-ion cell manufacturing processes, encompassing areas such as electrode making, cell assembly, formation, and automated material handling systems\n\nKey Responsibilities:\nEquipment Specification & Vendor Management: Collaborate with technology providers to define equipment specifications, ensuring alignment with critical process control requirements. Lead interactions with project facilities teams to finalize plant design and equipment layout.\nProcurement & Installation Oversight: Create Request for Proposals (RFPs) for equipment, conduct technical evaluations, and provide recommendations. Manage the procurement process, ensuring timely release of Purchase Orders (POs) and adherence to project timelines.\nCommissioning & Stabilization: Oversee installation and commissioning activities, ensuring equipment meets specifications. Participate in Factory Acceptance Testing (FAT) and Site Acceptance Testing (SAT), validating equipment performance post-installation.\nProcess Optimization & Performance Monitoring: Analyze production data to identify bottlenecks and implement corrective actions. Utilize Manufacturing Execution System (MES) reports to track tool performance and improve metrics such as Overall Equipment Efficiency (OEE), yield, and cycle time.\nTraining & Documentation: Develop and deliver training programs for operations and maintenance teams. Maintain comprehensive documentation, including machine specifications, drawings, Bills of Materials (BOM), spare parts lists, and process flow charts.\nQualifications & Experience:\nEducational Background: Bachelor’s degree in Mechanical, Electrical, or Manufacturing Engineering.\nProfessional Experience: 5–8 years of experience in manufacturing engineering, with a focus on high-volume production environments.\nTechnical Skills: Proficiency in process optimization, equipment troubleshooting, and data analysis. Familiarity with Lean Six Sigma principles is advantageous.\nSoft Skills: Strong analytical abilities, attention to detail, and effective communication skills. Ability to work collaboratively in a cross-functional team setting.",Industry Type: Auto Components,"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['Installation And Commissioning', 'Manufacturing Engineering', 'Equipment Installation', 'Line Balancing', 'Assembly Line']",2025-06-12 14:18:27
Software Engineer Lab Test Automation,Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nRoleThe BDC Post Silicon Engineering group has an opening for a RF and Mixed-Signal Bench Characterization Engineer. This group develops Test solutions for design verification of highly integrated Receivers/Transmitters/Transceivers, Power management, Analog and Mixed signal ASICs designed by QCT. Job responsibilities for this position include New Test methodology implementation, Device Verification and Characterization, Design and debug of Test interface hardware, Test automation, and Data analysis.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 1+ year of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field.\nRoleThe BDC Post Silicon Engineering group has an opening for a Lab Test Automation Framework Developer. This group develops Test solutions for design verification of highly integrated Receivers/Transmitters/Transceivers, Power management, Analog and Mixed signal ASICs designed by QCT. Job responsibilities for this position include developing robust, reliable automation framework and Software solutions to interface with RF Hardware and Instruments, ensuring seamless integration and functionality.\n\nSkills/Experience:\n\nSolid software skills for writing and debugging Test Automation code. Competency in automation development using at least 1 automation tool (C# / Python).\n\nDevelop software solutions using OOPs principles to interface with RF hardware, instruments, ensuring seamless integration and functionality.\n\nConduct rigorous testing and validation of automation framework to ensure compliance with industry standards and performance requirements.\n\nWork closely with cross-functional teams, to ensure cohesive system design and implementation.\n\nFamiliarity with AI/ML algorithms, understanding of deep learning concepts is a plus.\n\nKnowledge of RF fundamentals and System level knowledge is a plus.\n\nAble to work independently with initiative through challenges, Technical or otherwise.\n\nAble to communicate clearly, organize effectively and document work thoroughly while working with local and global teams.\n\nEducation :\n\nB.E, M.E or equivalent.\n\n4 years plus experience.\n\nKey Terms to Find on Resumes:\n\nC#, Framework, Object Oriented Programming(OOPs), Python, Test Automation, Software, AI, ML, Deep Learning, RF",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c#', 'hardware engineering', 'oops', 'debugging', 'object oriented programming', 'python', 'software test automation', 'bdd', 'software testing', 'automation testing', 'cucumber', 'manual testing', 'rest assured', 'deep learning', 'java', 'rf', 'selenium', 'test automation framework', 'testng']",2025-06-12 14:18:29
"Software Development Engineer II, International Emerging Stores",Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"Shaping the Future of Global E-commerce!!\n\nAt Amazons International Emerging Stores (IES), were reinventing how millions of customers discover and shop online. Our team is architecting foundational platforms and mechanisms that will power Amazons next generation of shopping experiences globally. Were tackling intrinsically hard problems at the intersection of AI, personalization, and scalable systems challenges that require innovative solutions while maintaining our commitment to operational excellence. Our charter extends beyond traditional e-commerce boundaries, focusing on creating competitive advantages through technical innovation. Were building solutions that not only serve immediate business needs but establish new patterns and practices that can be adopted across Amazon. Our work demands deep technical judgment, cross-organizational collaboration, and the ability to influence at the highest levels of the organization.\n\nThe Opportunity: Software Development Engineer\n\nAt IES, were building the future of retail, and were looking for a talented Software Development Engineer to join our innovative team. As an SDE, youll be instrumental in revolutionizing how customers make purchase decisions across our retail platform by developing next-generation shopping experiences powered by artificial intelligence and adaptive technologies.\n\nIn this role, youll design and implement intelligent systems that deliver personalized shopping experiences, working with cutting-edge generative AI and ML models to create innovative visual experiences. Youll develop sophisticated algorithms for adaptive layout optimization, product visualization features, theme-based recommendation systems, and customer behavior analysis. Your work will span multiple customer touchpoints, requiring you to write high-quality, scalable code while collaborating with product managers, designers, and data scientists to drive technical solutions.\n\nWere seeking someone with strong programming skills and software design expertise, particularly in distributed systems and scalable architectures. Knowledge of AI/ML technologies and their practical applications is essential, as is the ability to translate complex business requirements into technical solutions. Youll participate in architecture discussions, technical design reviews, and contribute to the continuous improvement of customer experience metrics while debugging complex production issues and optimizing system performance.\n\nThis position offers an exciting opportunity to work on cutting-edge technologies while solving complex engineering challenges that impact millions of customers globally. Youll be part of a team that values technical excellence and innovation, with the chance to shape the future of e-commerce through technological advancement.\n\n3+ years of non-internship professional software development experience\n2+ years of non-internship design or architecture (design patterns, reliability and scaling) of new and existing systems experience\nExperience programming with at least one software programming language 3+ years of full software development life cycle, including coding standards, code reviews, source control management, build processes, testing, and operations experience\nBachelors degree in computer science or equivalent",,,,"['Computer science', 'Software design', 'Operational excellence', 'Software Development Engineer II', 'Coding', 'Artificial Intelligence', 'Debugging', 'Continuous improvement', 'Internship', 'Distribution system']",2025-06-12 14:18:31
AI/ML framework Staff Engineer,Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nLooking for ""ML framework and AI compiler Engineer"" responsible for\nDesigning, implementing, and deploying machine learning models using PyTorch\nFocusing on backend infrastructure and system architecture.\nResponsibilities often include developing framework, integrating with other AI tools, and ensuring scalability and reliability.\n\nHere's a more detailed breakdown of what you might see in such a job description:\n\nKey Responsibilities:\n\n\nModel Development and DeploymentDesigning, building, and deploying AI models, particularly those leveraging PyTorch for deep learning.\n\n\nBackend InfrastructureDeveloping and maintaining the backend systems that power AI applications, including data ingestion, processing, and storage.\n\n\nSystem ArchitectureDesigning scalable and high-performance backend architectures to handle AI workloads.\n\n\nModel OptimizationOptimizing model performance for speed, accuracy, and resource efficiency.\n\n\nIntegrationIntegrating AI models with other systems and applications.\n\n\nAPI DevelopmentCreating and maintaining APIs for communication between frontend and backend components.\n\n\nData HandlingManaging data ingestion, preprocessing, and storage for AI training and inference.\n\n\nCollaborationWorking with data scientists, product managers, and other engineers to bring AI solutions to life.\n\nTools, Technologies, Skills and Programming:\n\n\nC, C++: Strong programming capability using advanced techniques to design and develop AI compilers and backends.\n\n\nScripting: Strong expertise in Python with design, develop, release and maintain projects.\n\n\nAI Frameworks: Familiarity with other AI frameworks like PyTorch, TensorFlow, Hugging Face, etc.\n\n\nMachine Learning Knowledge: Understanding of machine learning principles and algorithms starting Computer vision to large language models and continuously update to new trends.\nExpertise to deep learning accelerator programming (GPU, NPU). Any parallel programming experience (Like CUDA, OpenCL, MKLDNN ..etc) is a plus.\nExperience with deep leaning compilers like Glow, TVM ""etc is a plus.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'system engineering', 'c#', 'cuda', 'algorithms', 'c++', 'parallel programming', 'artificial intelligence', 'opencl', 'deep learning', 'java', 'product management', 'computer vision', 'asp.net', 'multithreading', 'mvc', 'ml']",2025-06-12 14:18:33
"Manager, Vendor Consultant, AVS-NOP",Amazon,6 - 11 years,Not Disclosed,['Bengaluru'],"About Amazon.com\nAmazon.com strives to be Earths most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want low prices, vast selection, and convenience Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazons evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the companys DNA. The worlds brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.\n\n\nAbout the Role\nTeam Manager, Vendor Consultants Team RBS AVS\nAs a Vendor Consultants Manager in Retail Business Services (RBS), you will have the exciting opportunity to help shape and deliver on the strategy for managing Amazon vendors.\nRBS team is looking for a customer centric, driven, and creative people leader to join our team. The role leads a team of Vendor Consultants responsible for managing business growth for some of the most influential Selling Partners (vendors) on Amazon, ensuring Selling Partner satisfaction with the program through a high level of service and operational standards. In this role, you will manage strategic joint business plans for Selling Partners across your team by collaborating with them to explore innovative ways to identify and execute new operational improvement opportunities. You will interface internally with leaders from our Retail and Vendor Services teams and will be responsible for all operational aspects of the vendor s business with Amazon. Your team will engage directly with multiple internal teams to optimize the product line for key manufacturers (vendors) on Amazon. The candidate thrives in an ambiguous environment where they must develop, implement and iterate data, processes, mechanisms and guardrails to improve the customer experience. Further, the candidate is a business owner who understands the key levers to drive business growth and can operationalize those levers across their team. They have a passion for people leadership and are at their best when they re building, developing and managing high-performing teams. Your team will utilize a wide range of skills and work across major functional areas such as site merchandising, buying, inventory management, finance, operations and online marketing, to drive the performance of strategic vendor partners at Amazon. In this role you will be focused on the strategic and operational aspects of managing the customer relationships.\nYou will lead the team that looks into strategic and operational aspects of vendors business with Amazon, root cause analysis of issues and opportunities affecting the vendor s business.\n\nA day in the life\nResponsibilities Include:\nLead a team of Vendor Consultants, prioritizing strategic initiatives and provide escalation support as needed.\nSuccess will be measured by the performance of your internal teams on input metrics and impact of vendors on creating a great customer experience.\nIdentify, action and/or provide advice on how to improve business input metrics that drive growth and improve end customer experience, in collaboration with other Amazon programs and teams.\nManage end to end goal setting for team to align with organizational goals.\nBuild relationships with stakeholders across the portfolio; proactively build joint business plan action items and act as a point of escalation for issues, questions, and concerns.\nAct as a thought leader in defining success criteria and understand business needs of Selling Partners in an ever-changing business environment. Contributes to and leads strategic plans and documents for the organization.\nLeads recruiting and hiring efforts across direct team and broader organization.\nManage stakeholders needs and monitor complexity through efficient resource allocation of Vendor Consultants.\nMonitor stakeholders satisfaction survey results to analyze both positive and negative feedback trends. Establish improvement plans and mange expectations with Vendor Consultants as appropriate. 6+ years of digital advertising and client facing roles with a focus on data analysis experience\nBachelors degree\nExperience analyzing data and best practices to assess performance drivers\nExperience influencing internal and external stakeholders\nExperience with sales CRM tools such as Salesforce or similar software 2+ years of mentoring, leading and coaching experience",,,,"['Business services', 'Root cause analysis', 'Data analysis', 'Operations improvement', 'Online marketing', 'Resource allocation', 'Inventory management', 'Merchandising', 'CRM', 'Salesforce']",2025-06-12 14:18:36
Senior/Lead MLops Engineer,Tiger Analytics,7 - 10 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","JOB DESCRIPTION\n\nSenior MLE / Architect MLE (ML Ops) Chennai / Bangalore / Hyderabad (Hybrid)\n\nWho we are Tiger Analytics is a global leader in AI and analytics, helping Fortune 1000 companies solve their toughest challenges. We offer fullstack AI and analytics services & solutions to empower businesses to achieve real outcomes and value at scale. We are on a mission to push the boundaries of what AI and analytics can do to help enterprises navigate uncertainty and move forward decisively. Our purpose is to provide certainty to shape a better tomorrow. Our team of 4000+ technologists and consultants are based in the US, Canada, the UK, India, Singapore and Australia, working closely with clients across CPG, Retail, Insurance, BFS, Manufacturing, Life Sciences, and Healthcare. Many of our team leaders rank in Top 10 and 40 Under 40 lists, exemplifying our dedication to innovation and excellence. We are a Great Place to Work-Certified (2022-24), recognized by analyst firms such as Forrester, Gartner, HFS, Everest, ISG and others. We have been ranked among the Best and Fastest Growing analytics firms lists by Inc., Financial Times, Economic Times and Analytics India Magazine.",,,,"['MLops', 'Azure', 'Snowflake', 'Deployment', 'Ci/Cd', 'Machine Learning']",2025-06-12 14:18:38
HW Program Manager - Staff,Qualcomm,5 - 10 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Services Group, Engineering Services Group > Program Management\n\nGeneral Summary:\n\nDevelops, defines, and executes plans of record, includingschedules, budgets, resources, deliverables, and risks. Monitors and drives the program from initiation through delivery, interfacing with internal and external stakeholders across functions on technical matters, as needed. Monitors budget/spending, on-time delivery, and achievement of program milestones. Represents the program and drives alignment across stakeholders.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Computer Science, or related field.\n5+ years of Program Management or related work experience.\n\nPreferred Qualifications:\n\nMaster's degree in Engineering, Computer Science, or related field.\n\nPMP Certification.\n\n10+ years of Program Management or related work experience.\n\n5+ years of work experience in a role requiring interaction with senior leadership (e.g., Director level and above).\n\n3+ years of experience working in a large matrixed organization.\n\n2+ years of experience with program management tools such as dashboards, Gantt charts, etc.\n\nPrincipal Duties and Responsibilities:\nCollaborates with key stakeholders and program sponsors to develop program goals, set the prioritization of deliverables, discuss involvement of business processes (e.g., program change management, communication) and drives decisions necessary for on time delivery.\nManages and takes responsibility for multiple medium sized programs/technology with moderate complexity by applying up-to-date program management knowledge to meet deadlines.\nDevelops and manages the execution of the program Plan of Record (e.g., on time, on budget, within scope) for multiple medium sized programs which include schedule and resource forecasting, stakeholders identification, method and frequency of communication, scope, and prioritization.\nEstablishes key program metrics and manages team to take action outside their comfort zone to ensure program success when metrics deviate from Plan of Record.\nIdentifies and secures resources to ensure alignment of team with program/technology demand for multiple medium sized programs with moderate complexity.\nDrives teams to identify program issues/risks, and create a risk mitigation plan for multiple medium sized or a single complex program(s). Maintains and updates the risk tracker.\nPromotes program vision and objectives within the team, ensures program objectives are met or exceeded, presents program vision to management, and gains buy-in from stakeholders.\nPromotes adoption of processes by applying best practices and identifying and executing process improvement initiatives across the Program Management team.\n\nLevel of Responsibility:\nWorking independently with little supervision.\nMaking decisions that are significant in impact; errors are not readily apparent due to the complexity of work process/product or time between decisions and results; errors typically result in significant expenditure of time, resources, and funds to correct.\nUsing verbal and written communication skills to convey complex and/or detailed information to multiple individuals/audiences with differing knowledge levels. May require strong negotiation and influence, communication to large groups or high-level constituents.\nHaving a moderate amount of influence over key organizational decisions (e.g., is consulted by senior leadership to provide input on key decisions).\nCompleting tasks that require multiple steps that can be performed in various orders; tasks require simultaneously executing multiple cognitive abilities and maintaining information in short- or long-term memory.\nExercising exceptional creativity to innovate new ideas and develop innovative products/processes without established objectives or known parameters.\nUsing deductive and inductive problem solving; multiple approaches may be taken/necessary to solve the problem; often information is missing or conflicting; advanced data analysis and interpretation skills are required.\nOccasionally participates in strategic planning within own area affecting immediate operations.\n\nThe responsibilities of this role do not include:\nFinancial accountability (e.g., does not involve budgeting responsibility).",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['data analysis', 'training and development', 'staff management', 'program management', 'training', 'employee relations', 'customer service', 'presentation skills', 'human resource management', 'employee engagement', 'recruitment', 'compensation', 'payroll', 'performance management']",2025-06-12 14:18:40
Engineer-Command Centre,ANZ,3 - 5 years,Not Disclosed,['Bengaluru'],"About Us\n\nAt ANZ, were applying new ways technology and data can be harnessed as we work towards a common goal: to improve the financial wellbeing and sustainability of our millions of customers.\nOur community of over 5,000 engineers is key to making this happen, because technology underpins every part of our business - from delivering tools, apps and services for our customers, to building a bank for the future.\nAbout the Role\nAs an Engineer in our Command Centre - Global Shift Operations, you ll play a key role in helping to monitor all the applications system, tasks and supervise the shift assigned to the operator through tools and provide first level support in case of any issues and proactively monitor the applications and systems to avoid critical impacts to the production.\nBanking is changing and we re changing with it, giving our people great opportunities to try new things, learn and grow. Whatever your role at ANZ, you ll be building your future, while helping to build ours.\nRole Type:Permanent\nRole Location:Bengaluru\nWork Hours:24*7\nWhat will your day look like?\nOversee and manage Tandem/Mainframe shift operations to ensure smooth and efficient functioning of the mainframe systems.\nLead a team of mainframe operators/Tandem, providing guidance, support, and direction to ensure tasks are completed effectively and efficiently.\nMonitor system performance, identify issues or anomalies, and take corrective actions to maintain system stability and availability.\nManage the allocated responsibilities as defined in the Incident Management Process for its effective and efficient operation.\nHandle and escalate incidents or problems that arise during the shift, coordinating with technical teams to resolve issues in a timely manner.\nOperate assigned platform(s) to provide reliable, secure and effective first level support to users/ customers.\nUndertake remedial action independently under limited guidance and keep internal users/ customers informed of progress.\nControl, monitor and maintain service availability according to defined standards and procedures.\nAnalyse, evaluate and prioritise incidents, changes and work requests and actions to resolve conflict or escalate to next level of support to ensure agreed service levels of performance are met.\nMaintain accurate records, logs, and documentation of operations activities, incidents, and changes for reference and audit purposes.\nTroubleshoot mainframe hardware, software, and network issues, working with technical teams to resolve complex problems and implement solutions.\nWhat will you bring?\n\nTo grow and be successful in this role, you will ideally bring the following:\nSignificant experience in computer operations, with approximately 6 years in multi-vendor system environments (IBM Mainframe and/ or Tandem and/ or systems management).\nComprehensive knowledge of Job Control Language (JCL) and /or systems operation and/or systems management, and on-line transaction processing systems (such as IMS, CICS, BASE24).\nHands-on experience working in Control-M GUI (IBM tool) for batch job monitoring.\nA proven track record in an operational environment with approximately 5 years experience in at least two of the following platforms - competent in one and adequate in another. Platforms include -\nMainframe - Control M, ISPF, $avers, Console, Netview.\nControl-M\nTandem (NonStop/Authentic)\nUnderstand infrastructure and application issues to a level that allows escalate or fix decisions.\nWell-developed data analysis skills with the ability to work independently or as part of a team. 3-5 years experience in a first level support type role with technical knowledge to train others.\nUnderstanding of operational/technical people management in a multi-platform environment.\nUnderstand support team functions and structures to allow correct second-level escalation decisions to occur.\nExcellent written and oral communication skills, and, demonstrated ability to liaise with all levels of management and external parties.",Industry Type: Banking,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Data analysis', 'JCL', 'ISPF', 'Cics', 'Control-M', 'Incident management', 'Operations', 'Financial services', 'IMS', 'Auditing']",2025-06-12 14:18:43
Wealth Management-Bengaluru-Associate-Software Engineering,Goldman Sachs,3 - 5 years,Not Disclosed,['Bengaluru'],"Associate GenAI Developer\nWe are seeking a highly skilled GenAI Developer to join our dynamic, global team. The ideal candidate will have a strong background in applied generative AI. This role will involve developing and implementing AI solutions, working with various technologies, and collaborating with cross-functional teams to drive innovation. The GenAI Developer will play a crucial role in advancing our GenAI capabilities and contributing to the success of our Wealth Management division.\nKey Responsibilities:\nWork with stakeholders to understand requirements and deliver AI solutions across several domains in Wealth Management.\nStay updated with the latest advancements in AI and machine learning technologies.\nConduct research and experiments to improve AI capabilities within the division.\nRequired Competencies:\nRetrieval-Augmented Generation (RAG): Experience in developing and implementing RAG models to enhance information retrieval and generation tasks.\nVector Stores: Knowledge of Vector Stores for efficient data storage and retrieval.\nPrompt Engineering: Skills in designing and optimizing prompts for AI models to improve accuracy and relevance.\nLarge Language Model APIs (LLM APIs): Understanding of different LLMs, both commercial and open source, and their capabilities (e.g., OpenAI, Gemini, Llama, Claude).\nProgramming Languages: Proficiency in Python, Java, or other relevant programming languages.\nData Analysis: Strong analytical skills and experience with data analysis tools.\nProblem-Solving: Excellent problem-solving abilities and attention to detail.\nCommunication: Strong verbal and written communication skills.\nPreferred Competencies:\nGraph RAG: Proficiency in using Graph RAG for complex data relationships and insights.\nKnowledge Graphs: Expertise in building and managing Knowledge Graphs to represent and query complex data structures.\nMachine Learning Frameworks: Experience with TensorFlow, PyTorch, or similar frameworks.\nExperience with cloud platforms such as AWS, Google Cloud, or Azure.\nFamiliarity with natural language processing (NLP) and computer vision technologies.\nPrevious experience in a similar role or industry.\nMaster s or Ph.D. in Computer Science, Data Science, or a related field.\nYears of experience: 3-5",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Computer vision', 'Data analysis', 'Wealth management', 'Machine learning', 'Data structures', 'HTML', 'Investment banking', 'Open source', 'Python']",2025-06-12 14:18:45
Associate/ Senior Associate - Retail Sales,Delhivery,3 - 8 years,Not Disclosed,"['Pune', 'Tiruppur']","Roles and Responsibilities\n\nAbility to identify customers LTL/PTL requirements and clearly communicate the product\nofferings to match their needs.\nService a geographical area/client segment to generate leads & sign new customers. Responsible for negotiation & pricing closure.\nManage a portfolio of customers and potential customers via personal sales visits, using face to face contact to provide a personal service.\nBuild a strong client relationship to ensure that the account performs and grows to its maximum potential, reducing attrition rate and minimizing opportunities for competitors to gain business.\nConversion of qualified leads into customers (First Time Buyers) across Major, Small and Medium Business Accounts and develop and penetrate existing accounts (Retention and Development).\nAct as the customers main point of contact, by liaising closely with the relevant departments\nwithin Delhivery to ensure that their queries, problems or issues are dealt with appropriately.\nMonitor the health of accounts, service levels and enhace SOW growth. Prepare and present\nweekly/monthly reports detailing sales achieved and those predicted against targets.\nTo continually develop knowledge of Deliverys products/services and general commercial\nawareness to provide the best possible solutions to the customers.\n\nDesired Skills and Experience\n\nCandidate should have 2-7 yrs. experience in Logistics / SCM BD Role\nCandidate should have excellent communication skills, good negotiation & co-ordination, market intelligence, generate business inquiries, expanding sales & ensure the profitability of the\ncompany\nNew acquisition skills required\nAnalytical bent of mind and good data analysis skills\nWilling to travel and are ready to visit as per the company ask\nA positive attitude and a desire to promptly resolve potential customer issues or complaints to\nsupport business growth.\nGo getter and responsibility taker who will ensure that we hit monthly targets with given margins",Industry Type: Courier / Logistics (Logistics Tech),Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Retail Sales', 'Channel Sales', 'Sales', 'B2C Sales', 'Direct Sales', 'Field Sales', 'Business Development', 'B2B Sales', 'Corporate Sales']",2025-06-12 14:18:48
Wealth Management - Vice President-Software Engineering,Goldman Sachs,6 - 10 years,Not Disclosed,['Bengaluru'],"We are seeking a highly skilled GenAI Developer to join our dynamic, global team. The ideal candidate will have a strong background in applied generative AI. This role will involve developing and implementing AI solutions, working with various technologies, and collaborating with cross-functional teams to drive innovation. The GenAI Developer will play a crucial role in advancing our GenAI capabilities and contributing to the success of our Wealth Management division.\n  Key Responsibilities:\nWork with stakeholders to understand requirements and deliver AI solutions across several domains in Wealth Management.\nStay updated with the latest advancements in AI and machine learning technologies.\nConduct research and experiments to improve AI capabilities within the division.\nRequired Competencies:\nRetrieval-Augmented Generation (RAG): Experience in developing and implementing RAG models to enhance information retrieval and generation tasks.\nVector Stores: Knowledge of Vector Stores for efficient data storage and retrieval.\nPrompt Engineering: Skills in designing and optimizing prompts for AI models to improve accuracy and relevance.\nLarge Language Model APIs (LLM APIs): Understanding of different LLMs, both commercial and open source, and their capabilities (eg, OpenAI, Gemini, Llama, Claude).\nProgramming Languages: Proficiency in Python, Java, or other relevant programming languages.\nData Analysis: Strong analytical skills and experience with data analysis tools.\nProblem-Solving: Excellent problem-solving abilities and attention to detail.\nCommunication: Strong verbal and written communication skills.\nPreferred Competencies:\nGraph RAG: Proficiency in using Graph RAG for complex data relationships and insights.\nKnowledge Graphs: Expertise in building and managing Knowledge Graphs to represent and query complex data structures.\nMachine Learning Frameworks: Experience with TensorFlow, PyTorch, or similar frameworks.\nExperience with cloud platforms such as AWS, Google Cloud, or Azure.\nFamiliarity with natural language processing (NLP) and computer vision technologies.\nPrevious experience in a similar role or industry.\nmasters or Ph.D. in Computer Science, Data Science, or a related field.",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer vision', 'Data analysis', 'Wealth management', 'Machine learning', 'Data structures', 'HTML', 'Investment banking', 'Open source', 'Python']",2025-06-12 14:18:50
AutoIT Solutioning Engineer-Staff,Qualcomm,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n \n\nQualcomm Overview: \nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.\n\nGeneral Summary:\n\nAs a Site Reliability Engineer (SRE), youll be part of a highly collaborative team focused on provisioning and maintaining infrastructure and services with stability, sustainability, and security always on your mind. You will work in a self-guided, cross-functional team responsible for everything from modernizing traditional services and applications to deploying new technology. You'll collaborate closely with software engineers, data scientists, and product managers to maintain and optimize our systems. If you're passionate about automotive technology, software reliability, and continuous improvement, this role is perfect for you.\n\nYour Guiding Principles:\n\n\nAutomationYou understand the power of automation and ""infrastructure as code"" concepts. Automation is your primary consideration in problem-solving.\n\n\nCollaboration: You share a common language with fellow engineers, understand their needs, and thrive working in a high trust collaborate culture in which people are rewarded for taking risks.\n\n\nData-drivenYou understand why decisions are supported by facts and not opinions. You have experience applying logical approach to decision making. Skilled at metric collection and using that data to drive change.\n\n\nDebuggingYou understand debugging principles and are adept at applying them routinely and successfully.\n\n\nDevSecOps: You understand that DevSecOps is a culture which needs to be cultivated and you can help nurture those philosophies.\n\n\nSecurityYou know how to layer appropriate security within solutions across the lifecycle. You understand the security implications and consequences of any deployment.\n\n\nSelf-Driven: You understand how to prioritize work and time allocation at a personal and team level.\n\n\nStability: You know what it means to deliver a service with a high degree of reliability and are intimately familiar with how disruptions impact consumers.\n\n\nSustainability: You avoid one off solutions which are challenging to support. Instead, your solutions are aligned with team goals and strategic vision. You routinely dedicate cycles to reducing technical debt.\n\n\nWhat you have:\nExtensive Linux experience with servers and workstations. You can easily navigate the CLI, knowledgeable with typical Linux troubleshooting tools, and have a broad understanding of Ubuntu and RedHat.\nThe ability to automate through scripting languages such as Python, Bash, Go, etc.\nThe skill to provide sufficient automated test coverage of various implementations.\nYou have familiarity with Jenkins, Puppet, Splunk, JIRA, Vault, Docker, AWS, Cloud services, etc.\nAbility to respond rapidly to changing landscapes while providing stable, reliable, and secure services to customers.\nYou have a passion for continuous learning and leverage the scientific method to ensure nothing is taken for granted.\n\n\nResponsibilities:\nSystem Monitoring and Incident Response:\nMonitor system health, detect anomalies, and respond promptly to incidents.\nInvestigate and troubleshoot issues related to services.\nImplement proactive measures to prevent service disruptions.\nInfrastructure Automation:\nDevelop and maintain infrastructure-as-code (IaC) scripts for deployment and scaling.\nAutomate routine tasks to improve efficiency and reduce manual intervention.\nPerformance Optimization:\nCollaborate with development teams to optimize software performance.\nIdentify bottlenecks and implement solutions to enhance system speed and reliability.\nCapacity Planning:\nForecast resource requirements based on traffic patterns and business growth.\nScale infrastructure to accommodate increasing demand.\nSecurity and Compliance:\nEnsure compliance with industry standards and best practices.\nImplement security controls and participate in security audits.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['docker', 'linux', 'python', 'puppet', 'aws', 'kubernetes', 'owasp', 'golang', 'redhat linux', 'vulnerability assessment', 'ansible', 'microservices', 'java', 'devops', 'jenkins', 'debugging', 'penetration testing', 'vault', 'jira', 'cloud services', 'ubuntu', 'microsoft azure', 'splunk', 'bash', 'devsecops', 'terraform']",2025-06-12 14:18:52
RAG Architect,Qualcomm,13 - 18 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Test Engineering\n\nGeneral Summary:\n\nJob description\n\nWe are seeking an experienced AI Architect to design, develop, and deploy Retrieval-Augmented Generation (RAG) solutions for Qualcomm Cloud AI Platforms.\n\nRoles and Responsibilities\nLead the design and development of applications for RAG AI models and provide APIs for frontend consumption. Manage the interaction between retrieval-augmented techniques and generative models.\nBuild services that connect AI models (e.g., transformers, embeddings, and vector search) to handle tasks such as query retrieval, model inference, and generating responses. Leverage frameworks like Flask, FastAPI, or Django for API development.\nDesign pipelines to preprocess, clean, and prepare data for AI model training, as well as for serving the models in production environments. Optimize these pipelines to support both batch and real-time data processing. Implement RESTful APIs or GraphQL endpoints for seamless frontend-backend interaction.\nImplement cloud solutions to host Python-based services, ensuring that AI models are scalable and that the infrastructure can handle high traffic. Leverage containerization (Docker) and orchestration (Kubernetes) for model deployment and management.\nSet up monitoring, logging, and alerting for Python backend services, ensuring smooth operation of AI features. Use tools like Prometheus, Grafana, and ELK stack for real-time performance tracking.\nContinuously optimize model performance by fine-tuning and adapting Python-based AI models for real-time use cases. Manage trade-offs between computation load, response time, and quality of generated content.\nPartner with data scientists, machine learning engineers, and mobile/web developers to ensure tight integration between AI models, mobile/web front-end, and backend infrastructure.\n\n- Experience:\n13+ years of overall SW development experience\n10+ years Strong experience in working with technologies (e.g., React, React Native, Flutter, Django, Flask, FastAPI).\n5+ years of experience in building AI applications with a focus on NLP, machine learning, generative models, and retrieval-augmented systems.\nProven experience in designing and deploying AI systems that integrate retrieval-based techniques (e.g., FAISS, Weaviate) and generative models (e.g., GPT, BERT). - Expertise in cloud platforms (e.g., AWS, GCP, Azure) and deployment of Python-based microservices.\nBuilding RESTful APIs or GraphQL services (using frameworks like Flask, FastAPI, or Django).\nHandling AI model inference and data processing (using libraries like NumPy, Pandas, TensorFlow, PyTorch, and Hugging Face Transformers).\nIntegrating vector search solutions (e.g., FAISS, Pinecone, Weaviate) with the AI models for efficient retrieval-augmented generation. - Experience with containerization (Docker) and Kubernetes for deploying scalable Python-based services.\nProficient in cloud infrastructure management, with a focus on managing Python services in the cloud.\nExperience in End-to-End product development and Software Lifecycle\n\n\nKey\n\nSkills:\n\nAdvanced proficiency in Python for building backend services and data processing pipelines. Familiarity with frameworks like Flask, Django, and FastAPI. Experience with AI libraries and frameworks (TensorFlow, PyTorch, Hugging Face Transformers).\nFamiliarity with vector databases (e.g., Pinecone, FAISS, Weaviate) and integration with retrieval-augmented systems.\nStrong knowledge of RESTful API design, GraphQL, and API security best practices (e.g., OAuth, JWT).\nExcellent problem-solving abilities and a strong focus on creating highly scalable and performant solutions.\nStrong communication skills, with the ability to collaborate across different teams and geography\nAbility to mentor junior team members and lead technical discussions.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Software Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Software Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Test Engineering or related work experience.\n\n2+ year of work experience with Software Test or System Test, developing and automating test plans, and/or tools (e.g., Source Code Control Systems, Continuous Integration Tools, and Bug Tracking Tools).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data processing', 'cloud platforms', 'api', 'graphql', 'natural language processing', 's w development', 'rest api design', 'system testing', 'react native', 'machine learning', 'pipeline', 'react.js', 'flutter', 'test engineering', 'django', 'cloud infrastructure management', 'flask']",2025-06-12 14:18:55
AI Technical Architect,Care Allianz,7 - 11 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","Care Allianz is looking for AI Technical Architect_ to join our dynamic team and embark on a rewarding career journey\n\nDesigns AI-based system architectures for scalable solutions\n\nCollaborates with data scientists and engineers for model integration\n\nEnsures performance, scalability, and security of AI platforms\n\nGuides development teams in implementing AI strategies",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Technical Architect', 'Manager Technology']",2025-06-12 14:18:57
Staff System Test Engineer,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Test Engineering\n\nGeneral Summary:\n\n\n\nWe are seeking a Senior Staff AI System-Level Test Engineer to lead end-to-end testing of Retrieval-Augmented Generation (RAG) AI systems for Hybrid, Edge-AI Inference solutions. This role will focus on designing, developing, and executing comprehensive test strategies for evaluating the reliability, accuracy, usability and scalability of large-scale AI models integrated with external knowledge retrieval systems.\n\nThe ideal candidate needs to have deep expertise in AI testing methodologies, experience with large language models (LLMs), expertise in building test solutions for AI Inference stacks, RAG, search/retrieval architecture, and a strong background in automation frameworks, performance validation, and building E2E automation architecture.\n\nExperience testing large-scale generative AI applications, familiarity with LangChain, LlamaIndex, or other RAG-specific frameworks, and knowledge of adversarial testing techniques for AI robustness are preferred qualifications\n\nKey Responsibilities:\n\nTest Strategy & Planning\nDefine end-to-end test strategies for RAG, retrieval, generation, response coherence, and knowledge correctness\nDevelop test plans & automation frameworks to validate system performance across real-world scenarios.\nHands-on experience in benchmarking and optimizing Deep Learning Models on AI Accelerators/GPUs\nImplement E2E solutions to integrate Inference systems with customer software workflows\nIdentify and implement metrics to measure retrieval accuracy, LLM response quality\n\n\nTest Automation\nBuild automated pipelines for regression, integration, and adversarial testing of RAG workflows.\nValidate search relevance, document ranking, and context injection into LLMs using rigorous test cases.\nCollaborate with ML engineers and data scientists to debug model failures and identify areas for improvement.\nConduct scalability and latency tests for retrieval-heavy applications. Analyze failure patterns, drift detection, and robustness against hallucinations and misinformation.\n\n\nCollaboration\nWork closely with AI research, engineering teams & customer teams to align testing with business requirements.\nGenerate test reports, dashboards, and insights to drive model improvements.\nStay up to date with the latest AI testing frameworks, LLM evaluation benchmarks, and retrieval models.\n\n\nRequired Qualifications:\n8+ years of experience in AI/ML system testing, software quality engineering, or related fields.\nBachelors or masters degree in computer science engineering/ data science / AI/ML\nHands-on experience with test automation frameworks (e.g., PyTest, Robot Framework, JMeter).\nProficiency in Python, SQL, API testing, vector databases (e.g., FAISS, Weaviate, Pinecone) and retrieval pipelines.\nExperience with ML model validation metrics (e.g., BLEU, ROUGE, MRR, NDCG).\nExpertise in CI/CD pipelines, cloud platforms (AWS/GCP/Azure), and containerization (Docker, Kubernetes).\n\n\nWhy Join Us\nWork on cutting-edge AI retrieval-augmented generation technologies\nCollaborate with world-class AI researchers and engineers.\n\nIf you are passionate about AI system testing and ensuring the reliability of next-generation generative models, apply now!\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Systems Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Systems Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Test Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['automation framework', 'continuous integration', 'python', 'sql', 'ci cd pipeline', 'kubernetes', 'ci/cd', 'cloud platforms', 'software quality', 'artificial intelligence', 'docker', 'test engineering', 'quality engineering', 'e2e', 'testing methodologies', 'vector', 'aws', 'api testing']",2025-06-12 14:19:00
6 months Contract- HR Operations/Generalist/HR background,EY,1 - 5 years,Not Disclosed,"['Kochi', 'Bengaluru']","The opportunity\nProvide operation support for various administrative projects including but not limited mailbox management, managing databases, creation and release of periodic reports, work MS-excel reporting, Content Management, web based publication support, working on dashboard creations and data analysis.\nYour key responsibilities\nThe role requires someone who can manage a number of concurrent activities, with strong multi-tasking, prioritization, organizational and time management skills.\nVery good understanding of business functions and operations\nAbility to prioritize and co-ordinate with multiple people on various variables\nAbility to liaise with POC's in different regions/offices and work as a team\nDemonstrated proficiency and experience in MS Office Suite especially in Excel\nFlexible with working hours\nObservant with an eye for detail\nAbility to make sound decisions fast\nMethodical and systematic approach\nAnalytical and problem solving ability\nHigh energy level, confident and assertive\nSolid research and analytical skills\nThe ability to simplify complex analytical issues and communicate them to a variety of audiences.\nStrong interpersonal skills\nSkills and attributes for success\nExcellent written and oral communication skills in English language\nExcellent critical thinking skills to decipher the complex business requirements\nStrong presentational skills; ability to clearly communicate complex messages to a variety of audiences\nPossess high standard of integrity\nThe ability to work and team effectively with clients and other management personnel.\nTo qualify for the role, you must have\n2 to 4 Years in / BPO services/Project Co-Ordination.\nExperience in multiple systems and applications\nPrior work experience in a large professional services or financial services company\nExperience working with clients from different countries (Desirable)\nExperience working in an business where the primary spoken language is English",Industry Type: Management Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['HR Operations', 'Hr Ops', 'HR Generalist Activities', 'HR Coordination', 'HR Administration']",2025-06-12 14:19:02
Bill,Robert Bosch Engineering and Business Solutions Private Limited,2 - 5 years,Not Disclosed,['Bengaluru'],"Roles Responsibilities :\nActing as a billing and eInvoicing expert in the Bosch Digital Backbone Project, implementing S/4 HANA on the horizontal layer\nDriving Billing forms and templates for different countries and ensure standardization as much as possible\nDefine / align / facilitate requirements on functional process level\nSupport in definition of scenarios and template process design\nContribute to definition of IT requirements and acceptance criteria\nContribute to create user documentation for template processes\nSupport process documentation in Signavio and testing results in SolMan system\nSupport in definition of test cases\nConduct functional and component testing for template billing processes and eInvoicing\nBring in best practices / solutions from your area of expertise (e. g. from shared services) into the Order-to-Cash table work\nTake part in backlog creation and refinement, prioritization and sprint planning\nCoordinate with cross-functional departments (BD, C/FI, Tax)",Industry Type: Automobile,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Process design', 'O2C', 'Data analysis', 'Project management', 'Billing', 'Agile', 'Scrum', 'Test cases', 'Stakeholder management', 'Information technology']",2025-06-12 14:19:04
OMNI Channel Manager,Titan Company,7 - 10 years,17-20 Lacs P.A.,['Bengaluru'],"OMNI Channel Manager\nBusiness IBD Job Description: We are seeking a highly skilled and dynamic Omni-Channel Manager to join our growing international business division. This individual will be responsible for overseeing, optimizing the customer journey across all online, and offline touchpoints. The role will focus on integrating e-commerce platforms, brick-and-mortar stores, and other sales channels to deliver a seamless, efficient, and personalized experience for our global customer base.\nKey Responsibilities:\n1. Omni-Channel Strategy Development & Execution:\nDevelop and implement a comprehensive Omni-channel strategy for IBD, ensuring an integrated and consistent customer journey across all touchpoints (online, offline, social media, customer service) etc. Drive the seamless integration of the brand’s e-commerce platform with retail stores, improving both online and in-store customer experience",,,,"['Channel Growth', 'E-Com & OMNI sales', 'Omni-Channel Strategy Development & Execution', 'Lead Management', 'Sales Optimization', 'Business Strategy']",2025-06-12 14:19:06
Team Leader - Key Accounts Manager,Startek,3 - 6 years,5-7 Lacs P.A.,['Bengaluru'],"Location: Bangalore\nProcess: Key Account Management (E-commerce)\nExperience: 4+ years (including 1+ year in team handling)\nEducation: Any Graduate (10+2+3)\n\nJob Overview\nWe are looking for a dynamic and experienced Team Leader Operations to manage a team of Key Account Managers. The role requires driving seller performance on an ecommerce platform through strategic relationship management, sales enablement, and data-driven insights.\n\nKey Responsibilities\nLead and manage a team of Key Account Managers (KAMs) handling e-commerce sellers\nMonitor and drive team performance to achieve sales, revenue, and growth targets\nAnalyze seller performance and provide strategic inputs to enhance business outcomes\nCoordinate with internal stakeholders to ensure seamless seller support and resolution\nConduct regular reviews, coaching, and training sessions for the team\nMaintain team motivation and discipline while ensuring performance benchmarks are met\nManage dashboards, track KPIs, and generate performance reports using Excel\n\nDesired Candidate Profile\n• Graduate in any discipline (10+2+3)\n• Minimum 4 years of experience in KAM/RE (Relationship Executive) processes\n• Minimum 1 year of team handling experience\n• Proficient in MS Excel and comfortable with data analysis\n• Strong communication skills in Hindi and English\n• Proven leadership skills with ability to drive results through team\n• E-commerce domain experience preferred",Industry Type: Analytics / KPO / Research,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['key account manager', 'team leader', 'Ecommerce Marketing', 'Seller Onboarding', 'E-commerce']",2025-06-12 14:19:08
Assistant Manager,Genpact,3 - 8 years,Not Disclosed,['Bengaluru'],"Genpact (NYSE: G) is a global professional services and solutions firm delivering outcomes that shape the future. Our 125,000+ people across 30+ countries are driven by our innate curiosity, entrepreneurial agility, and desire to create lasting value for clients. Powered by our purpose the relentless pursuit of a world that works better for people – we serve and transform leading enterprises, including the Fortune Global 500, with our deep business and industry knowledge, digital operations services, and expertise in data, technology, and AI.\nInviting applications for the role of Data Analyst!\nWe are seeking a detail-oriented and analytical Data Analyst to join our team. The ideal candidate will be responsible for collecting, processing, and analyzing large datasets to provide insights that will help drive business decisions. You will collaborate with cross-functional teams to translate data into actionable recommendations, improving operational efficiency and enhancing strategic decision-making.",,,,"['Aviation', 'Aerospace', 'Data Analysis']",2025-06-12 14:19:11
Associate - Accounts Receivable,upGrad,1 - 6 years,5-6 Lacs P.A.,"['Bengaluru', 'Mumbai (All Areas)']","Job description - Associate - Accounts Receivable\n\nDaily Receipt Bookings: Accurately record and process all receipts, ensuring timely and correct\nupdates in the system.\nReconciliation: Perform daily and monthly reconciliation of accounts to ensure all discrepancies are\nidentified and resolved promptly.\nData Entry & Maintenance (Excel): Maintain and update accurate AR records, ensuring consistency",,,,"['Reconciliation', 'Accounts Receivable', 'AR']",2025-06-12 14:19:13
Cognizant hiring For Veeva CRM developer,Cognizant,4 - 9 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Location - Bangalore & Hyderabad\nExperience - 4 to 12 Years\nJob Summary\nExperience working in IT projects for Healthcare, Life sciences or Biopharma industry .\nExpertise in system administration, configurations, maintenance or Support of Salesforce CRM, VEEVA CRM projects\nDomain Admin and Configuration specialization on different Veeva OOB modules. Well-versed in all aspects of the and applications, including the application functions, system and business administration settings",,,,"['Veeva Crm', 'controller', 'Triggers', 'Apex']",2025-06-12 14:19:16
Senior Software Engineer,Dynamic Yield,5 - 10 years,Not Disclosed,"['Pune', 'Gurugram']","Our Purpose\nTitle and Summary\nSenior Software Engineer\nWhat is Mastercard?\n\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOur Team:\n\nThe AI & DPE team is responsible for product decisioning management and innovative product development under services business unit to address the evolving risk and security needs of all of Mastercard s various customer segments. AI & DPE team focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services to drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on driving actionable insights and build innovative solutions out of multiple data sources using analytics, machine learning and reporting capabilities.\n\nThe Role:\n\nWe are seeking a Senior Software Engineer who will:\nPartner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on requirement gathering in order to deliver analytics solutions that generate business value\n\nPerform data preparation by ingestion, aggregation, processing to drive and enable relevant insights from available data sets\n\nIdentify and code the best suited data algorithm model for the relevant insights\n\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions\n\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements\n\nAll about You\n\nStrong SQL knowledge for data preparation and mining\nStrong knowledge of writing data/machine learning algorithm in Python or R\nExperience in doing data analysis and extraction on Hadoop\nExperience of working on at least one reporting tool - Tableau and PowerBI is a plus\nExperience in data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies\nStrong understanding of the application of analytical methods and data visualization to support business decisions\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Data modeling', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:19:18
Project Support Officer / Engineer - Planisware,Quest Global,4 - 9 years,10-20 Lacs P.A.,['Bengaluru'],"Work Experience\n            Hands-on experience with various tools such as Planisware, Qlik Sense, Windchill, data spreadsheets, word processing software, PowerPoint, and Power BI\n            Proficient in data analysis, creating dashboards, summarizing information, and using pivot tables with spreadsheets\n            Strong analytical skills, with the ability to interpret complex project data.\n            Experience in project management or project support roles, ideally with a focus on cost planning, budgeting, or time tracking.\n            Proficiency in MS Excel (including advanced functions) and other data analysis tools.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Planisware', 'Power Bi', 'Powerpoint']",2025-06-12 14:19:20
Snowflake - Senior Technical Lead,Sopra Steria,2 - 11 years,Not Disclosed,['Noida'],"Position: Snowflake - Senior Technical Lead\nExperience: 8-11 years\nLocation: Noida/ Bangalore\nEducation: B.E./ B.Tech./ MCA\nPrimary Skills: Snowflake, Snowpipe, SQL, Data Modelling, DV 2.0, Data Quality, AWS, Snowflake Security\nGood to have Skills: Snowpark, Data Build Tool, Finance Domain\nPreferred Skills",,,,"['Performance tuning', 'Schema', 'HIPAA', 'Javascript', 'Data quality', 'Informatica', 'Analytics', 'SQL', 'Python', 'Auditing']",2025-06-12 14:19:22
Lead Digital Product Manager - Lending,Wells Fargo,5 - 7 years,Not Disclosed,['Bengaluru'],"About this role:\nThe CB CIB Digital team is looking for a dynamic individual to focus on building and evolving new digital lending experiences for ""Wells Fargo Vantage"", while partnering with multiple product teams across the organization. This individual will support the strategic roadmap, product vision and end-to-end execution in creating and delivering transformational experiences for specific product(s) within the individual journeys on Vantage such as Lending on the Digital Channels Team. The successful candidate will be able to build new experiences, leverage their well-rounded analytical, business, and communication skills, leadership capabilities, and must be a team player.",,,,"['digital product management', 'data analysis', 'business transformation', 'Agile', 'digital strategy', 'Tableau', 'product development lifecycle']",2025-06-12 14:19:24
"Manager, Account Management, AVS EU",Amazon,6 - 11 years,Not Disclosed,['Bengaluru'],"About Amazon.com\nAmazon.com strives to be Earths most customer-centric company where people can find and discover virtually anything they want to buy online. By giving customers more of what they want low prices, vast selection, and convenience Amazon.com continues to grow and evolve as a world-class e-commerce platform. Amazons evolution from Web site to e-commerce partner to development platform is driven by the spirit of innovation that is part of the companys DNA. The worlds brightest technology minds come to Amazon.com to research and develop technology that improves the lives of shoppers and sellers around the world.\nAbout the Role\nTeam Manager, Account Management\nAs a Manager, Account Management as part of Amazon Vendor Services (AVS) Team of Retail Business Services, you will have the exciting opportunity to help shape and deliver on a strategy for managing Amazon AVS vendors.\nAVS team is looking for a bright, customer centric, driven, and creative people leader to join our team. The role leads a team of Account Managers responsible for managing business growth for some of the most influential Selling Partners (vendors) on Amazon, ensuring Selling Partner satisfaction with the program through a high level of service and operational standards. In this role, you will manage strategic joint business plans for Selling Partners across your team by collaborating with them to explore innovative ways to identify and execute new selection, merchandising, and operational improvement opportunities. You will interface internally with leaders from our Retail and Vendor Services teams and will be responsible for all aspects of the vendor s business with Amazon. Your team will engage directly with multiple internal teams to optimize the product line for key manufacturers (vendors) on Amazon. The candidate thrives in an ambiguous environment where they must develop, implement and iterate data, processes, mechanisms and guardrails to improve the customer experience. Further, the candidate is a business owner who understands the key levers to drive business growth and can operationalize those levers across their team. They have a passion for people leadership and are at their best when they re building, developing and managing high-performing teams. Your team will utilize a wide range of skills and work across major functional areas such as site merchandising, buying, inventory management, finance, operations and online marketing, to drive the performance of strategic vendor partners at Amazon. In this role you will be focused on the strategic and operational aspects of managing the customer relationships with our vendors.\nYou will lead the team to conceive, create and analyze a wide range of marketing and site merchandising efforts, to include marketing campaigns to grow the vendor s traffic, brand awareness, customer conversion, and revenue on Amazon. Also you will look into strategic and operational aspects of their business with Amazon, root cause analysis of issues and opportunities affecting the vendor s business.\nResponsibilities Include\nLead a team of Account Managers, prioritizing strategic initiatives and provide escalation support as needed.\nSuccess will be measured by the performance of your internal teams on input metrics and impact of vendors on creating a great customer experience for buying consumers\nIdentify, action and/or provide advice on how to improve business input metrics that drive growth and improve end customer experience, in collaboration with other Amazon programs and teams.\nManage end to end goal setting for team to align with organizational goals.\nBuild relationships with Selling Partners across the portfolio; proactively build joint business plan action items and act as a point of escalation for outstanding issues, questions, and concerns.\nAct as a thought leader in defining success criteria and understand business needs of Selling Partners in an ever-changing business environment. Contributes to and leads strategic plans and documents for the organization.\nLeads recruiting and hiring efforts across direct team and broader organization.\nManage Selling Partner needs and monitor complexity through efficient resource allocation of Account Managers.\nMonitor Selling Partner satisfaction survey results to analyze both positive and negative feedback trends. Establish improvement plans and mange expectations with Account Managers as appropriate.\n\n\nLead a team of Account Managers, prioritizing strategic initiatives and provide escalation support as needed.\nManage end to end goal setting for team to align with organizational goals.\n\nBuild relationships with Selling Partners across the portfolio; proactively build joint business plan action items and act as a point of escalation for outstanding issues, questions, and concerns.\n\nAct as a thought leader in defining success criteria and understand business needs of Selling Partners in an ever-changing business environment. Contributes to and leads strategic plans and documents for the organization.\n\nLeads recruiting and hiring efforts across direct team and broader organization.\n\nManage Selling Partner needs and monitor complexity through efficient resource allocation of Account Managers.\n\nMonitor Selling Partner satisfaction survey results to analyze both positive and negative feedback trends. Establish improvement plans and mange expectations with Account Managers as appropriate.\n\nothers 6+ years of digital advertising and client facing roles with a focus on data analysis experience\nBachelors degree\nExperience analyzing data and best practices to assess performance drivers\nExperience influencing internal and external stakeholders 3+ years of mentoring, leading and coaching experience",Industry Type: Internet,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Business services', 'Root cause analysis', 'Data analysis', 'Operations improvement', 'Online marketing', 'Resource allocation', 'Inventory management', 'Brand awareness', 'Account management', 'Merchandising']",2025-06-12 14:19:27
Senior Software Engineer,Mastercard,10 - 15 years,Not Disclosed,"['Pune', 'Gurugram']","The AI & DPE team is responsible for product decisioning management and innovative product development under services business unit to address the evolving risk and security needs of all of Mastercard s various customer segments. AI & DPE team focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services to drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on driving actionable insights and build innovative solutions out of multiple data sources using analytics, machine learning and reporting capabilities.\n\nThe Role:\n\nWe are seeking a Senior Software Engineer who will:\nPartner with various teams (ie, Product Manager, Data Science, Platform Strategy, Technology) on requirement gathering in order to deliver analytics solutions that generate business value\n\nPerform data preparation by ingestion, aggregation, processing to drive and enable relevant insights from available data sets\n\nIdentify and code the best suited data algorithm model for the relevant insights\n\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\n\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions\n\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements\n\nAll about You\n\nStrong SQL knowledge for data preparation and mining\nStrong knowledge of writing data/machine learning algorithm in Python or R\nExperience in doing data analysis and extraction on Hadoop\nExperience of working on at least one reporting tool - Tableau and PowerBI is a plus\nExperience in data modeling, programming, querying, data mining and report development using large volumes of granular data to deliver business intelligence and custom reporting solutions\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies\nStrong understanding of the application of analytical methods and data visualization to support business decisions\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group\n",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data analysis', 'Data modeling', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Analytics', 'SQL', 'Python']",2025-06-12 14:19:29
Supply Chain Specialist Staff,Juniper Networks,10 - 15 years,Not Disclosed,['Bengaluru'],".\nPosition : Supply Planner\nLocation: Bangalore\nExperience: 10+ years\nJob description\nIn this role, We are looking for a proactive and analytical Supply & Inventory Planner with a strong foundation in data analysis and exposure to AI/ML . This hybrid role ensures supply continuity, optimal inventory levels, and improved forecast accuracy through a mix of traditional planning and next-gen analytics. The ideal candidate brings a blend of operational planning expertise, a data-savvy mindset, and a passion for using emerging technologies to transform supply chain performance.\nKey Responsibilities:\nSupply Planning:\nCreate and maintain short- and long-term supply plans based on demand forecasts, capacity, and lead time constraints.\nEnsure product availability by managing supply across multiple nodes (e.g., suppliers, factories, distribution centers).\nCollaborate cross-functionally with Demand Planning, Procurement, Manufacturing, Logistics , and commercial teams.\nMonitor supplier performance and track on-time delivery, lead times, and shortages to inform planning decisions.\nUse scenario modeling and simulations to assess plan sensitivity and enable rapid decision-making.\nParticipate in S&OP and IBP processes , contributing insights and aligning operational plans with business strategy.\nInventory Planning:\nOptimize inventory levels, Safety Stock targets and mix across the network to meet service targets while minimizing excess and obsolescence.\nPerform inventory health reviews , flag aging or slow-moving stock, and collaborate with stakeholders to reduce working capital.\nLead E&O forecasting and contribute to proactive mitigation plans.\nPartner with finance, operations, and commercial teams to align inventory with business goals and budget constraints.\nBuild inventory projection models to assess future inventory trends based on current supply/demand dynamics.\nAnalytics & AI/ML Enablement:\nUse tools such as Excel, SQL, Python, Power BI, Tableau for reporting, diagnostics, and automation.\nLeverage AI/ML models for demand sensing, inventory optimization, and supply risk prediction .\nCollaborate with data science and engineering teams to translate business needs into modeling requirements.\nChampion digital transformation by identifying manual processes that can be automated or enhanced using intelligent solutions.\nRequirements\nBachelor s degree in Supply Chain, Engineering, Business, or related discipline (Master s a plus).\n10 years of experience in supply planning, demand planning, or end-to-end supply chain roles.\nStrong expertise in planning systems (e.g., SAP, Kinaxis, Oracle, O9) and advanced Excel or data analysis tools.\nProven ability to lead cross-functional projects and influence without authority.\nDetail oriented, Strategic thinker with a hands-on mindset, comfortable navigating ambiguity and fast-changing environments.\nStrong communication skills, with the ability to tailor messaging to technical teams and senior leaders.\nExperience in inventory optimization, scenario planning, and supplier collaboration is a strong plus.",Industry Type: IT Services & Consulting,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Procurement', 'Supply chain', 'Automation', 'Data analysis', 'SAP', 'Networking', 'Oracle', 'Analytics', 'SQL', 'Python']",2025-06-12 14:19:31
Senior Software Engineer,Mastercard,5 - 8 years,Not Disclosed,['Pune'],"Senior Software Engineer\n?\n\n\n\n\nThe AI & DPE team is responsible for product management and innovative product development of products and services to address the evolving risk and security needs of all of Mastercard s various customer segments. Platform Services team in AI & DPE focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services across AI & DPE and drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven cyber products, services and actionable insights.\n\nThe Role:\nWe are seeking a Senior Software Engineer who will:\n\nPerform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\nPartner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\nIdentify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\nIntegrate & Unify new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\nAnalyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nMinimum 5-8 years of relevant experience.\nGood understanding of programming language preferably PySpark and Big Data technologies.\nExperience with Enterprise Business Intelligence Platform/Data platform.\nStrong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\nExperience with data integration tools - ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Databricks)\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\nStrong understanding of the application of analytical methods and data visualization to support business decisions.\nAbility to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Operations', 'Analytics', 'SQL']",2025-06-12 14:19:33
Lead Quantitative Analytics Specialist ALM Modeling,Wells Fargo,5 - 10 years,Not Disclosed,['Bengaluru'],"Lead Quantitative Analytics Specialist ALM Modeling Balance sheet modeling IRRBB EVE FTP Deposit models Liquidity Risk models-\nCorporate Risk helps Wells Fargo businesses identify and manage risk. The team focuses on three key risk areas: credit risk, operational risk and market risk. As the company's second line of defense, Corporate Risk or Independent Risk Management provides independent oversight of risk-taking activities. Independent Risk Management establishes and maintains Wells Fargo's risk management program and provides oversight, including challenges to and independent assessment of the frontline's execution of its risk management responsibilities. Corporate Risk roles depend on a variety of skills, viz. data analysis and synthesis, root cause analysis, change management, process management & execution, risk governance, risk strategy, risk identification & assessment, risk prevention, controls & mitigation, risk monitoring, reporting & escalation, risk systems & technology.",,,,"['ALM Modeling', 'R', 'Basel', 'CECL', 'SAS', 'Risk Modeling', 'CCAR models', 'Python']",2025-06-12 14:19:35
Abinitio Developer,Hexaware Technologies,6 - 9 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']",Experience - 6 years - 9 years\nLocation - Pune / Chennai / Mumbai / Bangalore\n\nStrong in-depth knowledge of databases and database concepts to support\nDesign/development of Datawarehouse/Datalake application\nAnalyze the business requirements and work with the business and data modeler to support dataflow from source to target destination,,,,"['Unix', 'DWH', 'Ab Initio', 'ETL', 'SQL']",2025-06-12 14:19:38
Senior Enterprise Operations Engineer,Mastercard,4 - 11 years,Not Disclosed,['Pune'],"Senior Enterprise Operations Engineer\nOverview\nThis position involves providing comprehensive support to internal teams through the delivery of detailed analysis, reports, and inventory insights. The role is integral to supporting various internal teams, with a specific focus on the Asia Pacific and LAC (Latin American) region.\nRole\nThe Operations Support Analyst is an individual contributor role requiring advanced expertise in the discipline. The analyst will lead several initiatives within the Operations Support team to support the Asia Pacific region.\nAssist team in supporting Operations Support activities: Collaborate with various internal teammjms to ensure smooth execution of operations support activities, providing guidance and expertise as needed.\nEngage in Post Incident Management, Problem Management, and Root Cause Analysis: Investigate incidents to identify their root causes and facilitate the resolution of underlying problems, ensuring continuous improvement in operational processes.\nProvide Daily Incident Review and Post-Incident Analysis: Conduct daily reviews of incidents and analyse post-incident data to derive actionable insights that inform strategic decision-making.\nDeliver Data Analysis and Custom-Made Reports: Generate and present tailored reports based on comprehensive data analysis, addressing specific needs and requirements of internal teams.\nPerform support functions for internal teams within the Operations & Technology team: Offer operational support to various internal teams, facilitating the seamless integration and implementation of technology solutions.\nResponsibilities\nPost Incident Management, Problem Management, and Root Cause Analysis: Lead efforts to manage incidents and problems effectively, employing root cause analysis techniques to prevent future occurrences.\nConduct Daily Incident Review and Post-Incident Analysis: Systematically review incidents daily and perform thorough post-incident analyses to enhance operational efficiency.\nExecute Data Analysis and deliver Custom-Made Reports: Perform in-depth data analysis and produce customized reports that cater to the specific needs of internal stakeholders.\nEnsure regional coverage and support for the Asia Pacific region and LAC region: Provide comprehensive support to the Asia Pacific/LAC region, ensuring that all operations support activities are effectively managed and executed.\nAll about you\nWe are seeking a dedicated IT Specialist with comprehensive experience in IT projects, particularly in networking, security technologies, and data analysis. The ideal candidate will have a strong background in Cisco, Splunk, and Netscout products, and possess knowledge of network diagnostics and various network technologies.\nQualifications\nIT experience, including full-time involvement in IT projects\nNetworking experience, including LAN/WAN, wireless, and security technologies\nKnowledge of Cisco, Splunk, Netscout, and other relevant technology product portfolios\nKnowledge of network diagnostics, PfR, BGP, SNMP, IPVPN, SSH, MPLS technologies\nBasic knowledge of Data Center standards\nProficiency in Excel, with the ability to create reports using macros preferred\nCCNA or equivalent certification preferred\nTeam Overview\nThe primary role of the AP-OS team is to deliver operational support to internal teams by analysing incidents, conducting both post-incident and recurring incident analyses, managing problems, and providing regular summary reports with detailed analysis on incident and network performance. Additionally, the team produces ad hoc reports tailored to the requirements of various internal teams.",Industry Type: Financial Services,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Wireless', 'Data analysis', 'WAN', 'Information security', 'LAN', 'Incident management', 'CCNA', 'Continuous improvement', 'Macros', 'cisco']",2025-06-12 14:19:40
Senior Software Quality Engineer,Mastercard,4 - 9 years,Not Disclosed,['Pune'],"Senior Software Quality Engineer\n?\n\nMastercard is a global technology company in the payments industry. We work to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\n\n\n\nOverview:\n\nTransfer Solutions is responsible for driving Mastercard s expansion into new payment flows such as Disbursements & Remittances. The team is working on creating a market-leading money transfer proposition, Mastercard Move, to power the next generation of payments between people and businesses, whether money is moving domestically or across borders, by delivering the ability to pay and get paid with choice, transparency, and flexibility.\n\nThe Product & Engineering teams within Transfer Solutions are responsible for designing, developing, launching, and maintaining products and services designed to capture these flows from a wide range of customer segments. By addressing customer pain points for domestic and cross-border transfers, the goal is to scale Mastercard s Disbursements & Remittances business, trebling volume over the next 4 years.\n\nThe Role:\narticipate in requirements discussion, test planning, test data creation and execution of testing Plan in adherence with MasterCard standards, processes and best practices.\nWork with project teams to meet scheduled due dates, while identifying emerging issues and recommending solutions for problems and independently perform assigned tasks.\nDesign and develop test automation frameworks to validate system to system interfaces and complete software solutions (for Database/ETL, API and UI tests)\nInteract with business and development stakeholders to define test plans and schedules\nTranslate complex system requirements into test requirements and testing methods\nIdentify and implement complex automation efforts, including refactoring of automation code where needed\nDevelop test scripts and perform automated and manual exploratory testing to ensure software meets business and security requirements and established practices.\nDesign and develop test data management for defined test cases, recognize test environment preparation needs, and execute existing test plans and report results\nOwn responsibility for defect management and oversight and escalation of issues discovered during the testing phase\nDocument as per Software Development Best Practices and follow MasterCard Quality Assurance and Quality Control processes.\nDocument performance test strategies and test plans, and execute performance validation\nCollect quality metric data and communicate test status/risks to stakeholders\nAct as first-review for project-level reviews, walkthroughs and inspections\nProvide technical support and mentoring to junior team members\nPerform demos of new product functionality to stakeholders\nDevelop business and product knowledge over time.\nIdentify opportunities to improve effectiveness and time-to-market\nProvide training and guidance to team members on quality best practices and principles\nFacilitate knowledge sharing sessions to promote a culture of quality awareness\nBe a strong individual contributor to the implementation efforts of product solutions\n\nAll About You:\n\nBachelors degree in Information Technology, Computer Science or Management Information Systems or equivalent work experience\n8+ years of experience in the Software Engineering with a focus on Quality Engineering methodologies\nTechnical skills in Java, Selenium, Cucumber, Soap UI, Spring framework, REST, JSON, Eclipse, GIT, Jmeter/Blazemeter\nExcellent SQL skills to work on large and complex data sources and capability of comprehending and writing complex queries\nExperience testing APIs (REST and SOAP), web user interface, and/or reports\nExperience in implementing CI/CD build pipelines with tools like Git/Bit Bucket, Jenkins and Maven\nSuccessfully validated one or more application codebases via automation, for new feature functionality and regression testing\nExperience working in Agile teams and conversant with Agile/SAFe tenets and ceremonies. Strong analytical and problem-solving abilities, with quick adaptation to new technologies, methodologies, and systems\nExcellent English communication skills (both written and verbal) to effectively interact with multiple technical teams and other stakeholders\nHigh-energy, detail-oriented and proactive, with ability to function under pressure in an independent environment along with a high degree of initiative and self-motivation to drive results\nEager to experiment with new team processes and innovate on testing approach\nPrior experience with Data Analysis and Data Engineering is a plus\nStrong collaboration skills and ability to work effectively in a cross-functional, interdependent team environment",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Maven', 'Manager Quality Assurance', 'Eclipse', 'Information security', 'Agile', 'JSON', 'Selenium', 'Information technology', 'Technical support', 'SQL']",2025-06-12 14:19:42
Senior Enterprise Operations Engineer,Dynamic Yield,2 - 7 years,Not Disclosed,['Pune'],"Our Purpose\nTitle and Summary\nSenior Enterprise Operations Engineer\nOverview\nThis position involves providing comprehensive support to internal teams through the delivery of detailed analysis, reports, and inventory insights. The role is integral to supporting various internal teams, with a specific focus on the Asia Pacific and LAC (Latin American) region.\nRole\nThe Operations Support Analyst is an individual contributor role requiring advanced expertise in the discipline. The analyst will lead several initiatives within the Operations Support team to support the Asia Pacific region.\nAssist team in supporting Operations Support activities: Collaborate with various internal teammjms to ensure smooth execution of operations support activities, providing guidance and expertise as needed.\nEngage in Post Incident Management, Problem Management, and Root Cause Analysis: Investigate incidents to identify their root causes and facilitate the resolution of underlying problems, ensuring continuous improvement in operational processes.\nProvide Daily Incident Review and Post-Incident Analysis: Conduct daily reviews of incidents and analyse post-incident data to derive actionable insights that inform strategic decision-making.\nDeliver Data Analysis and Custom-Made Reports: Generate and present tailored reports based on comprehensive data analysis, addressing specific needs and requirements of internal teams.\nPerform support functions for internal teams within the Operations & Technology team: Offer operational support to various internal teams, facilitating the seamless integration and implementation of technology solutions.\nResponsibilities\nPost Incident Management, Problem Management, and Root Cause Analysis: Lead efforts to manage incidents and problems effectively, employing root cause analysis techniques to prevent future occurrences.\nConduct Daily Incident Review and Post-Incident Analysis: Systematically review incidents daily and perform thorough post-incident analyses to enhance operational efficiency.\nExecute Data Analysis and deliver Custom-Made Reports: Perform in-depth data analysis and produce customized reports that cater to the specific needs of internal stakeholders.\nEnsure regional coverage and support for the Asia Pacific region and LAC region: Provide comprehensive support to the Asia Pacific/LAC region, ensuring that all operations support activities are effectively managed and executed.\nAll about you\nWe are seeking a dedicated IT Specialist with comprehensive experience in IT projects, particularly in networking, security technologies, and data analysis. The ideal candidate will have a strong background in Cisco, Splunk, and Netscout products, and possess knowledge of network diagnostics and various network technologies.\nQualifications\nIT experience, including full-time involvement in IT projects\nNetworking experience, including LAN/WAN, wireless, and security technologies\nKnowledge of Cisco, Splunk, Netscout, and other relevant technology product portfolios\nKnowledge of network diagnostics, PfR, BGP, SNMP, IPVPN, SSH, MPLS technologies\nBasic knowledge of Data Center standards\nProficiency in Excel, with the ability to create reports using macros preferred\nCCNA or equivalent certification preferred\nTeam Overview\nThe primary role of the AP-OS team is to deliver operational support to internal teams by analysing incidents, conducting both post-incident and recurring incident analyses, managing problems, and providing regular summary reports with detailed analysis on incident and network performance. Additionally, the team produces ad hoc reports tailored to the requirements of various internal teams.",Industry Type: Software Product,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Wireless', 'Data analysis', 'WAN', 'Information security', 'LAN', 'Incident management', 'CCNA', 'Continuous improvement', 'Macros', 'cisco']",2025-06-12 14:19:44
Officer - MIS,Relaxo,2 - 7 years,4-7.5 Lacs P.A.,['Delhi / NCR'],"Officer-MIS\nFunction:\n\nSales & Marketing\n\nWork Location:\n\nDelhi HO\nCompensation:\n\n3.0 Lacs to 7.0 Lacs\n\nExperience in years:\n\n3-8\nReporting to:\n\nAVP-New Channel\n\nNumber of Employees Reporting to Position and Designations:\n\nNil\nAmount of travel required:\n\nNil\n\nWork-Level:\n\nOfficer/ Senior Officer(O1-O2)\nAcademic/Trade Qualifications\nEssential:\n\nAny Graduation\nDesirable:\n\nMBA\nTechnical/Functional Certifications Required:\n\nYes No\nIf Yes, please specify:\nPurpose of the Position (Job Summary)\nTo Report AVP New Channel and support by co-ordination and administering the sales information system. To Prepare daily, weekly, monthly sales related MIS reports including Daily sales tracking/ forecasting report, market share analysis, gross margin analysis by market. Provide all other administration services for the regional sales department and staff. Make a positive contribution to Sales Department.\nKey Roles and Responsibilities\nBusiness\n\nPrepare and Produce daily, weekly, monthly sales reports for Sales team, within required deadlines.\nGeneration MIS and Sales reports through SAP System and SAP (BI).\nCreate power point presentations as per business requirements\nManaging in various office utilities and other administrative work of the Regional Office.\nFinancial\n\nTracking and clearance all Utilitie bills etc.\nCoordinate with sales teams for daily orders, collections, UTR No and submission of scheme documents.\nCustomer Oriented\n\nManaging Distributor Relationship, handling their grievances.\nAssist Sales Team in providing all relevant data / MIS support.\nPeople Oriented\n\nManaging internal & external stakeholders basis business needs\nCompetencies\nTechnical/Functional\n\nBehavioral\n1.Advanced Microsoft Office (especially Excel spreadsheets)\n2.SAP System and SAP (BI)\n3.Decent communication skills (English - Written & Spoken)\n\n1. Organized, analytical and methodical approach\n2. Self-motivated\n3. Team player\n4. Ability to communicate to staff of all levels\nPerformance Measures\nQuantitative\n\nQualitative\n1. Sales Reporting & Analysis\n2. Cost reduction & Maintenance (Cleaning, supply, etc.)\n3. Coordination with distributors and vendors\n\n1. Accuracy to Data\n2. Taking care of House Keeping\n3. Infrastructure Management\nKey Stakeholder Management\nInternal\n\nExternal\nGM, AGM, Sr. Manager, KAMs, SO/SR, HO-MIS\n\nDistributors/Retailers/Venders",Industry Type: Textile & Apparel (Fashion),"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Sales MIS', 'MIS', 'Management Information System', 'MIS Operations', 'VLOOKUP', 'Advanced Excel', 'Excel Report Preparation']",2025-06-12 14:19:46
HR Business Partner Sales,Condor Footwear,10 - 20 years,Not Disclosed,['Surat( Sachin )'],"Role & responsibilities\nPosition Overview:\n\nThe HR Business Partner for Sales at Condor Footwear India Limited plays a critical role in aligning business objectives with employees and management in the sales department. This position is responsible for implementing HR strategies and initiatives that support the overall growth of the sales team and enhance employee engagement and performance.\nKey Responsibilities:\n1. Strategic HR Partnership:\n- Collaborate with sales leadership to understand business goals and challenges.\n- Participate in developing and executing HR strategies that support sales objectives.\n2. Talent Management:\n- Oversee recruitment efforts for sales roles, ensuring the selection of high-quality candidates.\n- Conduct workforce planning and succession planning activities to develop sales talent.\n3. Performance Management:\n- Support the performance appraisal process, providing guidance to managers on evaluation and feedback.\n- Implement performance improvement plans for underperforming employees.\n4. Employee Engagement:\n- Foster a positive work environment by promoting employee engagement initiatives.\n- Conduct employee surveys and analyze feedback to identify areas for improvement.\n5. Training and Development:\n- Identify training needs for the sales team and coordinate training programs to enhance skills.\n- Support career development programs to nurture talent within the sales department.\n6. Policy Implementation:\n- Ensure compliance with company policies and labor laws within the sales function.\n- Communicate HR policies and support managers in understanding and applying these policies effectively.\n7. Employee Relations:\n- Act as a point of contact for employee concerns within the sales team, addressing issues promptly and fairly.\n- Mediate conflicts and promote effective resolution strategies.\n8. Data Analysis and Reporting:\n- Analyze HR metrics related to the sales workforce to inform decision-making.\n- Prepare reports for management on HR initiatives and their impact on sales performance.\nQualifications:\n- Bachelors degree in Human Resources, Business Administration, or related field (Masters preferred).\n- 8+ years of HR experience, with a focus on sales or commercial environments.\n- Strong interpersonal and communication skills.\n- Proven capability in talent management, employee engagement, and conflict resolution.\n- Familiarity with HR software and data analytics tools.\nSkills:\n- Strong business acumen with the ability to align HR strategies to business needs.\n- Excellent organizational and project management skills.\n- Ability to work collaboratively with diverse teams and drive change.\n\n\nPreferred candidate profile",Industry Type: Textile & Apparel,Department: Human Resources,"Employment Type: Full Time, Permanent","['HRBP', 'Business Partnering', 'Sales HR', 'Performance Management System', 'Strategic HR', 'Competency Mapping', 'Corporate HR', 'HR Strategy', 'Business HR', 'Talent Management']",2025-06-12 14:19:48
Business System Specialist,Global Payments,4 - 9 years,Not Disclosed,['Pune'],".\nSummary of This Role\nWorks throughout the software development life cycle and performs in a utility capacity to create, design, code, debug, maintain, test, implement and validate applications with a broad understanding of a variety of languages and architectures. Analyzes existing applications or formulate logic for new applications, procedures, flowcharting, coding and debugging programs. Maintains and utilizes application and programming documents in the development of code. Recommends changes in development, maintenance and system standards. Creates appropriate deliverables and develops application implementation plans throughout the life cycle in a flexible development environment.\nWhat Part Will You Play?\nDevelops basic to moderately complex code using front and / or back end programming languages within multiple platforms as needed in collaboration with business and technology teams for internal and external client software solutions. Designs, creates, and delivers routine to moderately complex program specifications for code development and support on multiple projects/issues with a wide understanding of the application / database to better align interactions and technologies.\nAnalyzes, modifies, and develops moderately complex code/unit testing in order to develop concise application documentation. Performs testing and validation requirements for moderately complex code changes. Performs corrective measures for moderately complex code deficiencies and escalates alternative proposals.\nParticipates in client facing meetings, joint venture discussions, vendor partnership teams to determine solution approaches.\nProvides support to leadership for the design, development and enforcement of business / infrastructure application standards to include associated controls, procedures and monitoring to ensure compliance and accuracy of data. Applies a full understanding of procedures, methodology and application standards to include Payment Card Industry (PCI) security compliance.\nConducts and provides basic billable hours and resource estimates on initiatives, projects and issues.\nAssists with on-the-job training and provides guidance to other software engineers.\nWhat Are We Looking For in This Role? Minimum Qualifications\nBS in Computer Science, Information Technology, Business / Management Information Systems or related field\nTypically minimum of 4 years - Professional Experience In Coding, Designing, Developing And Analyzing Data. Typically has an advanced knowledge and use of one or more front / back end languages / technologies and a moderate understanding of the other corresponding end language / technology from the following but not limited to; t wo or more modern programming languages used in the enterprise, e xperience working with various APIs, external Services, e xperience with both relational and NoSQL Databases.\nPreferred Qualifications\nBS in Computer Science, Information Technology, Business / Management Information Systems or related field\n6+ years professional Experience In Coding, Designing, Developing And Analyzing Data and experience with IBM Rational Tools\nWhat Are Our Desired Skills and Capabilities?\nSkills / Knowledge - A seasoned, experienced professional with a full understanding of area of specialization; resolves a wide range of issues in creative ways. This job is the fully qualified, career-oriented, journey-level position.\nJob Complexity - Works on problems of diverse scope where analysis of data requires evaluation of identifiable factors. Demonstrates good judgment in selecting methods and techniques for obtaining solutions. Networks with senior internal and external personnel in own area of expertise.\nSupervision - Normally receives little instruction on day-to-day work, general instructions on new assignments.\n\nOperating Systems:\nLinux distributions including one or more for the following: Ubuntu, CentOS/RHEL, Amazon Linux\nMicrosoft Windows\nz/OS\nTandem/HP-Nonstop\nDatabase - Design, familiarity with DDL and DML for one or more of the following databases Oracle, MySQL, MS SQL Server, IMS, DB2, Hadoop\nBack-end technologies - Java, Python, .NET, Ruby, Mainframe COBOL, Mainframe Assembler\nFront-end technologies - HTML, JavaScript, jQuery, CICS\nWeb Frameworks - Web technologies like Node.js, React.js, Angular, Redux\nDevelopment Tools - Eclipse, Visual Studio, Webpack, Babel, Gulp\nMobile Development - iOS, Android\nMachine Learning - Python, R, Matlab, Tensorflow, DMTK\n.",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['redux', 'dml', 'unit testing', 'ios', 'jquery', 'coding', 'software development life cycle', 'react.js', 'tensorflow', 'java', 'webpack', 'design', 'debugging', 'mysql', 'matlab', 'mainframes', 'python', 'data analysis', 'oracle', 'ubuntu', 'rhel', 'javascript', 'sql server', 'nosql', 'angular', 'r', 'babel', '.net', 'centos']",2025-06-12 14:19:51
Senior Executive / Manager - Ecommerce Operations,Zebronics,4 - 6 years,Not Disclosed,['Chennai'],"Overview\nWe are looking for a dynamic and detail-oriented Senior Executive / Manager E-commerce Operations to join our growing E-commerce team.\n\n\nRequired Skills\nE-commerce operations, Order management, Marketplace coordination, Inventory management, Listing management, Pricing control, Return and refund handling, Dispatch coordination, Data analysis, Excel proficiency, Vendor communication, Logistics coordination, SLA management, Problem-solving, Team coordination\n\n\nDetailed Description\nJob Summary:\nWe are seeking a highly driven and detail-oriented Senior Executive / Manager E-commerce Operations to join our fast-growing team at Zebronics. The ideal candidate will be responsible for handling the day-to-day operations across various e-commerce and quick commerce platforms. This includes order processing, inventory coordination, returns, and ensuring seamless backend execution to support our online sales.\nKey Responsibilities:\nManage end-to-end order processing for online marketplaces (Amazon, Flipkart, Zepto, Blinkit, etc.)\nCoordinate with internal warehouse and logistics teams for timely dispatches\nMonitor and update product listings, stock availability, pricing, and offers\nResolve operational issues such as order delays, return disputes, and escalations\nMaintain accurate reporting for returns, sales performance, and stock reconciliation\nCollaborate with marketplace account managers and internal stakeholders\nDrive process improvement and operational efficiency\nEnsure adherence to platform SLAs and compliance standards\nKey Skills Required:\nE-commerce operations, Order management, Marketplace coordination, Inventory management, Listing management, Pricing control, Return and refund handling, Dispatch coordination, Data analysis, Excel proficiency, Vendor communication, Logistics coordination, SLA management, Problem-solving, Team coordination, Quick commerce platforms, Hindi communication, Attention to detail, Process improvement, Platform compliance\nRequirements:\nBachelor's degree or above (preferred in Business, Supply Chain, or related field)\n4 to 6 years of experience in e-commerce or supply chain operations\nStrong working knowledge of e-commerce platforms (Amazon, Flipkart, Blinkit, Zepto, etc.)\nExcellent communication and coordination skills\nProficiency in MS Excel and reporting tools\nFluency in Hindi is mandatory\nFemale candidates are preferred .",Industry Type: Consumer Electronics & Appliances,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Ecommerce Operations', 'Order management', 'supply chain operations', 'Data analysis', 'Logistics coordination', 'Excel', 'Pricing control', 'Listing management', 'Inventory management', 'Dispatch coordination', 'Marketplace coordination', 'SLA management']",2025-06-12 14:19:53
Product Specialist,MNC,5 - 10 years,5.5-12 Lacs P.A.,"['Mumbai', 'Gurugram', 'Bengaluru']",Customer research for insights and pain points\nMarket analysis to identify trends and opportunities\nData analysis to support product decisions\nProduct design and pilot execution\nCross-functional strategic planning,Industry Type: Automobile (Automobile Dealers),Department: Product Management,"Employment Type: Full Time, Permanent","['Product Specialist', 'Markert research', 'Innovation', 'Product Design', 'Data Analysis', 'Strategic Planning', 'Performance Monitoring']",2025-06-12 14:19:55
Performance Marketing/Customer Success | Shiksha.com | Bangalore,Info Edge,3 - 6 years,Not Disclosed,['Bengaluru'],Role & Responsibilities\nPost-Sale Campaign Management of top clients to reach pre-defined delivery & performance commitment\nRegular monitoring of delivery from campaigns and strategizing/planning activities to meet delivery gaps\nAnalyzing & preparing regular reports w.r.t delivery performance from various products/sources,,,,"['Performance Marketing', 'Client Success', 'customer success', 'Digital Campaigns', 'Campaign Execution', 'Marketing Analytics', 'Digital Analytics', 'client marketing', 'Client Servicing', 'Campaign Analytics', 'Data Analysis', 'Client Engagement', 'Campaign Management', 'Data Analytics']",2025-06-12 14:19:58
Business Development Manager (Hotels - Bangalore/Hyderabad/Chennai),Easemytrip,2 - 7 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","About the Role:\nThe Business Development Manager (Hotels - Bangalore) will play a crucial role in establishing and maintaining robust partnerships with hotels in the Bangalore region. This role involves strategic negotiations, active market analysis, and engagement with hotel partners to ensure competitive pricing, optimal availability, and excellent service standards.\n\nRole & responsibilities:\nStrategic Partner Acquisition: Proactively identify and engage potential hotel partners, expanding our network in the region.\nContract Negotiation: Skillfully negotiate terms and conditions with both new and existing hotel partners to secure advantageous agreements.\nPerformance Optimization: Monitor and enhance partner performance through regular analysis and strategic advice.\nMarket and Competitive Analysis: Keep abreast of market trends and competitor strategies to inform and adjust our approach.\nStakeholder Communication: Ensure effective communication with both internal teams and external partners to align strategies and expectations.\nPartner Training and Support: Provide ongoing training and support to hotel partners, ensuring they are proficient in using our platform and tools.\nQuality Control: Maintain high standards of partner compliance with our service quality and guest experience expectations.\nRegular Visits and Relationship Building: Conduct regular visits to partner hotels to strengthen relationships and gather insights.\nRevenue Growth Strategies: Develop and implement strategies aimed at maximizing revenue for both the partners and EaseMyTrip.com.\nPerformance Reporting: Generate detailed reports and provide constructive feedback to partners based on performance metrics.\n\nPreferred candidate profile:\nEducational Background: Masters degree in Business Administration or a related field from a recognized institution.\nProfessional Experience: 3-5 years of relevant experience in hotel contracting, business development, or B2B sales in the travel and hospitality industry.\nSector Expertise: Comprehensive understanding of the hotel and travel industry, particularly in the Bangalore market.\nNegotiation Proficiency: Exceptional negotiation skills with a successful track record in deal-making.\nAnalytical Skills: Strong capability in data analysis and decision-making based on market insights.\nCommunication and Interpersonal Skills: Outstanding communication skills for effective partnership management.\nProblem-Solving: Quick and effective problem-solving with innovative solutions.\nTech Savviness: Proficiency in MS Excel and CRM systems to manage data and relationships efficiently.\nTeam Collaboration: Proven ability to collaborate within a team to meet collective goals.\nAdaptability: Flexibility to adapt strategies in dynamic market conditions.",Industry Type: Travel & Tourism,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Negotiation', 'Hotel Contracting', 'Negotiation Skills', 'Revenue Management', 'Onboarding', 'Hospitality', 'Performance Metrics', 'Contract Management', 'Sales Strategy', 'Partnerships', 'Alliances', 'Contract Negotiations', 'Tourism', 'Hotel Accounts', 'Market Analysis', 'Stakeholder Management', 'CRM']",2025-06-12 14:20:00
Job Opportunity For Trainee/Jr.Engineer/Asst.Engineer/Engineer/Sr.Eng,Foxconn,2 - 4 years,Not Disclosed,['Chennai'],"Job description\n\nWe are thrilled to announce the foxconn Hon Hai Technology India Mega Development Private Limited Is Hiring For a Variety Positions across different functions and levels at Our TN Location\n\nLocation: Foxconn Hon Hai Technology India Mega Development Pvt Ltd (6th Gate)\nSipcot Hi-Tech Sez, Sipcot Industrial Park, Phase-II Chennai-Bangalore National Highway(NH-4) Suguvarchatiram, Sriperumbadur",,,,"['Procurement Executive', 'Security Auditor', 'Cctv Monitoring', 'CCTV Technician & Operator', 'Security Officer']",2025-06-12 14:20:03
Business Intelligence Lead,Trantor,8 - 10 years,Not Disclosed,[],"We are seeking a highly skilled Lead BI Developer with deep expertise in Tableau and Business\nIntelligence solutions to join our growing team. In this role, you will design and develop end-to-end BI solutions that empower data-driven decisions across the organization. You will collaborate closely with cross-functional teams, manage complex BI environments, and ensure seamless data visualization and reporting.\n1. Key Responsibilities\n\nBI Development & Data Visualization",,,,"['Business Intelligence', 'Tableau', 'ETL', 'Domo', 'SQL', 'Data Visualization']",2025-06-12 14:20:05
Senior Product Manager- Bangalore,Alice Blue Financial Services,6 - 10 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\n\nResponsibilities:\n• Define, understand, and identify key success metrics.\n• Develop insights on customer segments, personas, and pain points to refine GTM strategies\nand ensure product-market fit.\n• Track and analyze performance and constantly identify improvements to drive maximum\nusage and achieve business objectives.",,,,"['Product Strategy', 'Api Integration', 'Product Life Cycle Management', 'Go-to-market Strategy', 'Product Roadmap', 'User Research']",2025-06-12 14:20:07
Senior Software Engineer,Xoom,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Summary\nWhat you need to know about the role\nAs a Software Engineer in our Risk department, you will play a critical role in developing and maintaining cutting-edge risk detection and prevention systems that protect PayPals users and merchants from financial loss. You will work closely with cross-functional teams to design, build, and deploy scalable and efficient solutions that leverage machine learning, data analytics, and automation to identify and mitigate potential risks, ensuring the integrity of our platform and driving business growth.\n\nMeet our team\nAs an engineer in Global Fraud Risk - Automation team, You will work closely with data scientists, engineering, and analytical teams, understand the requirements and drive full development lifecycle of the teams products, transforming research work to real products. We are looking for strong technologists who are passionate about technology and able to continuously deliver state of the art software solutions in scalable way.\nJob Description\nYour way to impact\nAt PayPal, Backend Software Engineers are the architects of our global payment platform. Youll design, develop, and optimize core systems that power millions of transactions daily, directly impacting our customers experiences and our companys success.\nYour day-to-day\nAs a Senior Software Engineer - Backend, youll design and implement backend solutions. Youll collaborate with cross-functional teams to deliver high-quality products.\nDesign and develop scalable backend systems.\nOptimize system performance and reliability.\nMentor junior engineers.\nWhat do you need to bring\nBachelors degree in Computer Science or related field.\n3-5 years of backend development experience.\nProficiency in at least one backend language (Python, Java, Ruby on Rails)\nAdvanced proficiency in backend development with either Java EE frameworks, including experience with Spring MVC, or Hibernate.\nExperience designing and implementing RESTful services, focusing on scalability and reliability, using Java.\nProven ability to mentor junior engineers and contribute to code reviews and design discussions.\nExperience with cloud platforms (AWS, GCP, Azure)\nExperience with databases (SQL, NoSQL)\nStrong understanding of database design, including SQL and NoSQL databases, and experience with ORM tools.\nPreferred Qualifications\nExperience with large-scale, high-performance systems.\nKnowledge of the payment processing industry and relevant regulations.\nExperience with cloud platforms (AWS, GCP, Azure).\nContributions to open-source projects .\n**We know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please dont hesitate to apply.\nPreferred Qualification\nSubsidiary\nPayPal\nTravel Percent\n0\nFor the majority of employees, PayPals balanced hybrid work model offers 3 days in the office for effective in-person collaboration and 2 days at your choice of either the PayPal office or your home workspace, ensuring that you equally have the benefits and conveniences of both locations.\nOur Benefits\nWe have great benefits including a flexible work environment, employee shares options, health and life insurance and more. To learn more about our benefits please visit https//www.paypalbenefits.com .\nWho We Are\nClick Here to learn more about our culture and community.\nCommitment to Diversity and Inclusion\nPayPal provides equal employment opportunity (EEO) to all persons regardless of age, color, national origin, citizenship status, physical or mental disability, race, religion, creed, gender, sex, pregnancy, sexual orientation, gender identity and/or expression, genetic information, marital status, status with regard to public assistance, veteran status, or any other characteristic protected by federal, state, or local law. In addition, PayPal will provide reasonable accommodations for qualified individuals with disabilities. .\nBelonging at PayPal\nOur employees are central to advancing our mission, and we strive to create an environment where everyone can do their best work with a sense of purpose and belonging. Belonging at PayPal means creating a workplace with a sense of acceptance and security where all employees feel included and valued. We are proud to have a diverse workforce reflective of the merchants, consumers, and communities that we serve, and we continue to take tangible actions to cultivate inclusivity and belonging at PayPal.\nAny general requests for consideration of your skills, please Join our Talent Community .\nWe know the confidence gap and imposter syndrome can get in the way of meeting spectacular candidates. Please don t hesitate to apply.",Industry Type: Internet,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Hibernate', 'Automation', 'Backend', 'Database design', 'Analytical', 'Machine learning', 'Open source', 'SQL', 'Python']",2025-06-12 14:20:10
Sr. Executive- MSP Coordinator,Movin Express,5 - 10 years,5-8 Lacs P.A.,"['Bengaluru', 'Mumbai (All Areas)']","Job descriptionJOB ROLE & RESPONSIBILITIES:\n\nIdentify suitable MSPs for Last Mile and First Mile operations across the country.2. Monitors Existing Movin Service Providers (MSP) Maintains customer relationships to improve service and identify growth opportunities.3. Coordinates with departments to setup MSPs to monitor services on a daily basis.4. Audits MSP processes to ensure compliance and identify possible optimization.5. Implements safety procedures and policies with MSPs to provide a safe, proficient work environment.6. Implements New MSPs Initiates and performs training for MSP representatives to ensure UPS policies and procedures are communicated to the MSP.7. Works with the region functions to develop new MSP contracts, reporting templates, tools and service agreements.8. Coordinates day to day business, reports, BSC, Volume growth, Vehicle appearance.9. Creates strong contact with relevant MSPs to identify potential strategic MSPs.10. Negotiates with MSPs to represent the MOVIN position to get best service for best rates.11. Sets up Business Plan for relevant MSP businesses to support the MOVIN Business Planning process.12. Trains the MSP in using MOVIN Operations process to ensure consistency to MOVIN and customer systems.13. Trains the MSPs on MOVIN services and shares MOVIN methodology and best practices to lead the MSP to become an efficient strategic MOVIN partner who provides best service for best rates.14. Maintains quality control documents to maintain standards.15. Creates standard operating procedures for the training group to promote consistency and improve performance.16. Works with others throughout the district to troubleshoot system, operational, and service inefficiencies and create new processes that result in improved performance.17. Assists in monthly business plan reviews with MSPs to identify and address performance issues. Implements solution support of effective, practical plans to minimize cost/mile and maximize performance by meeting service commitments.18. Supervises and Develops Others Determines employees training needs to produce continuous development plans.19. Provides on-going feedback and support to improve performance. Conducts performance evaluations in a consistent, fair, and objective manner to encourage continuous performance improvement.20. Holds others accountable to established performance levels to achieve individual and group goals. Resolves individual and group performance issues in accordance with company's policies and procedures in a timely manner to motivate and foster teamwork.Educational Qualifications:\nBachelors Degree or equivalentRole & responsibilities\nPreferred candidate profile Role & responsibilities\n\n\nPreferred candidate profile\n\n\nPerks and benefits",Industry Type: Courier / Logistics (Logistics Tech),Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Transportation Operations', 'Last Mile', 'Vehicle Tracking', 'Route Planning', 'Gps Tracking', 'Fleet Operations', 'Tracking', 'Shipment Tracking', 'Data Analysis', 'Vendor Coordination', 'Logistics Operations']",2025-06-12 14:20:12
AI Test Lead,Naukri,8 - 13 years,20-32.5 Lacs P.A.,['Bengaluru'],"Role & responsibilities\nKey Responsibilities:\nAI Testing Strategy and Planning\nCollaborate with cross-functional teams to develop comprehensive AI testing strategies and plans for AI-powered applications.\nWork closely with product managers, data scientists, and developers to understand AI model requirements, use cases, and project goals.\nDefine the scope and objectives of AI testing efforts, including performance, accuracy, bias detection, and robustness of AI models. Test Execution for AI Models and Algorithms\nDesign, develop, and execute test cases for AI systems and models (including machine learning and deep learning algorithms).\nTest and validate AI solutions across various stages of the development lifecycle, including model training, testing, and deployment.\nEnsure that AI models meet business requirements and perform accurately under various real-world conditions.\nEvaluate the performance of AI models by assessing speed, efficiency, scalability, and resource utilization.\nPerform manual and automated testing on AI-based applications, platforms, and solutions.\nAI Model Accuracy and Validation\nTest AI models for accuracy, precision, recall, F1 score, and other performance metrics.\nEnsure AI models' fairness by conducting tests for potential bias in decisionmaking processes, especially in clinical or medical applications.\nValidate AI model predictions against real-world data, ensuring that results are consistent, reliable, and actionable. Also, need to look the test results from a business perspective and help evaluate the balance between risks and benefits.\nCollaboration and Knowledge Sharing\nWork with data scientists, AI engineers and Test Manager to improve testing methodologies and continuously optimize AI model testing processes.\nProvide feedback on AI models, pointing out any potential improvements in testing coverage or areas for model retraining.\nCommunicate findings, bugs, and issues related to AI models to technical teams, ensuring prompt resolution.\nHelp the team set up AI Testing standards, make informed decisions, and build knowledge across projects\nHelp the team in decision-making processes, such as whether to continue or stop investments based on testing results. Test Automation for AI Projects\nDevelop and implement automated testing scripts and frameworks specifically designed for AI applications.\nUtilize AI testing tools and frameworks (RAGAS etc.) to automate the validation of AI models and algorithms.\nIntegrate automated AI testing within continuous integration and continuous deployment (CI/CD) pipelines.\nCompliance and Regulatory Testing\nEnsure that AI applications comply with industry-specific regulations, especially in the pharma and healthcare sectors (e.g., FDA regulations, HIPAA compliance).\nVerify that all AI-driven processes adhere to ethical standards and data privacy laws.\nContinuous Improvement and Research\nStay up-to-date with the latest trends, tools, and techniques in AI testing and apply these advancements to optimize the testing process.\nParticipate in AI testing forums and workshops, contributing insights to improve best practices within the team. Reporting and Documentation\nDocument test results, methodologies, and issues clearly, providing insights into test coverage, risk analysis, and performance benchmarks.\nPrepare detailed reports for both technical and non-technical stakeholders, summarizing testing outcomes and potential risks associated with AI implementations.\nAssist in the creation and maintenance of knowledge-sharing platforms related to AI testing best practices.\nKey Skills and Qualifications:\nTechnical Expertise\nStrong knowledge of AI/ML testing methodologies and best practices.\nExperience with any AI development frameworks and libraries such as TensorFlow, Keras, PyTorch, scikit-learn, RAGAS and MLlib.\nExperience in testing tools and environments for AI-based systems (e.g., Jupyter Notebooks, Apache Spark, and DataRobot).\nExperience with performance testing tools like Grafana K6 and JMeter for AI solutions.\nKnowledge of Python (Must to have), R, JavaScript or other programming languages frequently used in AI/ML.\nKnowledge of cloud technologies like Microsoft Azure / AWS.\nUnderstanding of test automation frameworks and experience in tools like Cypress, Playwright and Pytest for automating AI tests. AI Model Evaluation\nSolid understanding of machine learning and deep learning models, including supervised and unsupervised learning techniques.\nFamiliarity with evaluating AI models on metrics such as accuracy, precision, recall, F1 score, confusion matrices, and AUC.\nAbility to identify and test for model biases, fairness, and ethical implications, especially in sensitive applications like healthcare and pharma. Analytical and Problem-Solving Skills\nStrong problem-solving abilities and keen attention to detail, with a systematic approach to diagnosing and resolving AI-related issues.\nAbility to perform root cause analysis of issues in AI algorithms and suggest actionable fixes.\nCollaboration and Communication\nExcellent teamwork and communication skills, with the ability to collaborate with cross-functional teams, including data scientists, engineers, and product managers.\nStrong verbal and written communication skills to convey technical information clearly and concisely to both technical and non-technical stakeholders.\nExperience\nMinimum of 8+ years experience in software testing, with at least 2 years focused on testing AI/ML models or AI-based applications.\nProven experience in testing AI/ML algorithms in production or staging environments.\nExperience in testing Visual AI Assistant Applications is good to have.\nExperience working in a regulated industry (such as pharmaceuticals or healthcare) is a plus.\nPreferred Qualifications:\nExperience with cloud platforms (e.g., AWS, Azure) for deploying AI applications and models. Certification in AWS/Azure will be good to have.\nFamiliarity with DevOps practices and integrating AI testing into CI/CD pipelines.\nCertification in AI/ML or related testing frameworks (e.g. ISTQB AI Tester)\nThis AI Tester role is a unique opportunity to shape the future of AI in the pharmaceutical industry. If youre passionate about AI, testing, and making a difference in healthcare, we encourage you to apply.\n\nPreferred candidate profile",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation Testing', 'AI/ ML', 'Python', 'Performance Testing', 'Automation Strategy', 'AI Framework', 'AI testing']",2025-06-12 14:20:14
Senior Project Manager with Scrum Master,Luxoft,8 - 10 years,Not Disclosed,['Bengaluru'],"Lead end-to-end project delivery for treasury initiatives, including planning, execution, monitoring, and closure, ensuring alignment with business objectives.\nManage the full project lifecycle using Agile (Scrum/Kanban) or Waterfall methodologies, depending on project requirements.\nFacilitate Scrum ceremonies (Sprint Planning, Daily Stand-ups, Sprint Reviews, and Retrospectives) and ensure effective collaboration among team members.\nDevelop and maintain detailed project plans, timelines, risk registers, and stakeholder management plans.\nConduct stakeholder analysis and maintain clear communication channels with senior management, business teams, technology teams, and external vendors.\nEnsure project scope, objectives, and deliverables are well-defined, documented, and agreed upon by stakeholders.\nProactively identify project risks, issues, and dependencies, and develop mitigation strategies.\nMonitor and manage project budgets, forecasts, and resource allocations.\nImplement change management best practices to ensure smooth transition and adoption of new solutions by end-users.\nPrepare and present project status reports, executive dashboards, and other communication materials to stakeholders.\nFoster a culture of continuous improvement by identifying and implementing process enhancements.\nCoach and mentor team members, ensuring adherence to best practices in project management and Agile principles.\nSkills\nMust have\nProven experience 8+ years as a Project Manager and Scrum Master, with experience in treasury or financial services domain.\nStrong understanding of treasury processes, including liquidity management, cash management, risk management, and regulatory compliance.\nProficiency in Agile (Scrum/Kanban) and Waterfall methodologies with hands-on experience in leading Scrum ceremonies and managing Agile teams.\nExcellent stakeholder management skills, with the ability to communicate effectively with senior executives, business teams, and technical teams.\nDemonstrated ability to manage complex, cross-functional projects with multiple stakeholders.\nStrong problem-solving skills with the ability to identify, analyze, and resolve issues in a fast-paced environment.\nProficiency in project management tools (JIRA, Confluence, MS Project, Trello, etc.) and Agile collaboration tools.\nSolid understanding of project financial management, including budgeting and forecasting.\nProfessional certifications such as PMP, CSM, or Agile Coach.\nExcellent written and verbal communication skills.\nNice to have\nExperience with treasury management systems (TMS) such as Murex, Calypso, Wallstreet Suite (WSS), or Kyriba.\nUnderstanding of regulatory frameworks impacting treasury operations (e.g., Basel III/IV, IFRS, local regulatory guidelines).\nPrior experience working in a large financial institution or global bank.\nExposure to DevOps practices and tools for continuous integration and deployment in treasury projects.\nKnowledge of cloud technologies (AWS, Azure, or Google Cloud) and their application in financial services.\nExperience in leading cross-regional teams in a distributed environment.\nAdvanced data analysis skills, including experience with BI tools (Power BI, Tableau) for treasury reporting.\nFamiliarity with Lean or Six Sigma methodologies for process optimization.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['PMP', 'Data analysis', 'Change management', 'Project management', 'calypso', 'Scrum', 'Risk management', 'JIRA', 'Monitoring', 'Six sigma']",2025-06-12 14:20:16
Senior Software Engineer - Python Developer,FactSet,5 - 10 years,Not Disclosed,['Hyderabad'],"FactSet creates flexible, open data and software solutions for over 200,000 investment professionals worldwide, providing instant access to financial data and analytics that investors use to make crucial decisions.\nAt FactSet, our values are the foundation of everything we do. They express how we act and operate , serve as a compass in our decision-making, and play a big role in how we treat each other, our clients, and our communities. We believe that the best ideas can come from anyone, anywhere, at any time, and that curiosity is the key to anticipating our clients needs and exceeding their expectations.",,,,"['Computer science', 'C++', 'Data analysis', 'GCP', 'Analytical', 'Machine learning', 'Technical leadership', 'Monitoring', 'SQL', 'Python']",2025-06-12 14:20:19
Python/Pyspark developer,Zensar,4 - 5 years,Not Disclosed,"['Pune', 'Bengaluru']","Job Description:\nWe are seeking a highly skilled and motivated Python/PySpark Developer to join our growing team. In this role, you will be responsible for designing, developing, and maintaining high-performance data processing pipelines using Python and the PySpark framework. You will work closely with data engineers, data scientists, and other stakeholders to deliver impactful data-driven solutions.\nResponsibilities:\n- Design, develop, and implement scalable and efficient data pipelines using PySpark.\n- Write clean, well-documented, and maintainable Python code.\n- Optimize data processing performance and resource utilization.\n- Implement ETL (Extract, Transform, Load) processes to migrate and transform data across various systems.\n- Collaborate with data scientists and analysts to understand data requirements and translate them into technical solutions.\n- Troubleshoot and debug data processing issues.\n- Stay up-to-date with the latest advancements in big data technologies and best practices.\nQualifications:\n- Bachelor's degree in Computer Science, Engineering, or a related field.\n- 3+ years of experience in Python development.\n- 2+ years of experience with PySpark and Spark ecosystem.\n- Strong understanding of data structures, algorithms, and object-oriented programming.\n- Experience with SQL and relational databases.\n- Familiarity with cloud platforms such as AWS, Azure, or GCP (preferred).\n- Excellent problem-solving and analytical skills.\n- Strong communication and teamwork skills.\nBonus Points:\n- Experience with data visualization tools (e.g., Tableau, Power BI).\n- Knowledge of machine learning and data science concepts.\n- Experience with containerization technologies (e.g., Docker, Kubernetes).\n- Contributions to open-source projects.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Cloud Technologies', 'SQL', 'Python']",2025-06-12 14:20:21
Senior Software Engineer,Dynamic Yield,5 - 8 years,Not Disclosed,['Pune'],"Our Purpose\nTitle and Summary\nSenior Software Engineer\nWho is Mastercard?\nMastercard is a global technology company in the payments industry. Our mission is to connect and power an inclusive, digital economy that benefits everyone, everywhere by making transactions safe, simple, smart, and accessible. Using secure data and networks, partnerships and passion, our innovations and solutions help individuals, financial institutions, governments, and businesses realize their greatest potential.\nOur decency quotient, or DQ, drives our culture and everything we do inside and outside of our company. With connections across more than 210 countries and territories, we are building a sustainable world that unlocks priceless possibilities for all.\n\nOur Team:\n\nThe AI & DPE team is responsible for product management and innovative product development of products and services to address the evolving risk and security needs of all of Mastercard s various customer segments. Platform Services team in AI & DPE focuses on defining the strategic direction for underlying platforms to enable the successful implementation of real-time, data-driven innovative products and services focused on network, security, fraud, digital identity and authentication. The team is responsible to look across all the products/services across AI & DPE and drive efficiency, re-usability and increase speed to market for our products and services.\n\nThe candidate for this position will focus on Data Unification across different data assets, enabling a single unified view of data from multiple sources and support the development of new innovative data driven cyber products, services and actionable insights.\n\nThe Role:\nWe are seeking a Senior Software Engineer who will:\n\nPerform data ingestion, aggregation, processing to drive and enable relevant insights from available data sets.\nPartner with various teams (i.e., Product Manager, Data Science, Platform Strategy, Technology) on data needs/requirements in order to deliver data solutions that generate business value.\nManipulate and analyze complex, high-volume, high-dimensionality data from varying sources using a variety of tools and data analysis techniques.\nIdentify innovative ideas and deliver proof of concepts, prototypes to deliver against the existing and future needs and propose new products, services and enhancements.\nIntegrate & Unify new data assets which increase the value proposition for our customers and enhance our existing solutions and services.\nAnalyse large volumes of transaction and product data to generate insights and actionable recommendations to drive business growth\nCollect and synthesize feedback from clients, development, product and sales teams for new solutions or product enhancements.\nApply knowledge of metrics, measurements, and benchmarking to complex and demanding solutions.\n\nAll about You\nMinimum 5-8 years of relevant experience.\nGood understanding of programming language preferably PySpark and Big Data technologies.\nExperience with Enterprise Business Intelligence Platform/Data platform.\nStrong SQL and higher-level programming languages with solid knowledge of data mining, machine learning algorithms and tools\nExperience with data integration tools - ETL/ELT tools (i.e. Apache NiFi, Azure Data Factory, Databricks)\nExposure to collecting and/or working with data including standardizing, summarizing, offering initial observations and highlighting inconsistencies.\nStrong understanding of the application of analytical methods and data visualization to support business decisions.\nAbility to understand complex operational systems and analytics/business intelligence tools for the delivery of information products and analytical offerings to a large, global user base.\nAble to work in a fast-paced, deadline-driven environment as part of a team and as an individual contributor\nAbility to easily move between business, analytical, and technical teams and articulate solution requirements for each group",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Product management', 'Data analysis', 'Information security', 'Analytical', 'Network security', 'Data mining', 'Business intelligence', 'Operations', 'Analytics', 'SQL']",2025-06-12 14:20:23
Oracle/ Informatica/ PLSQL/ ETL/ Snaplogic,Photon,5 - 10 years,Not Disclosed,"['Chennai', 'Bengaluru']","Job Description:\n\nRole: Orcale, Informatica, PLSQL, ETL\nLocation: Chennai/ Bangalore\nExperience: 5+ Years\nMust have: Orcale, Informatica, PLSQL, ETL\n\nLooking for a candidate with expertise on Oracle Database,  Snaplogic and Oracle PL/SQL with knowledge on AWS cloud.",,,,"['Snaplogic', 'PLSQL', 'Informatica', 'ETL', 'ORACE']",2025-06-12 14:20:26
Senior Generative AI Engineer - Python Programming,Zettamine Labs,7 - 8 years,Not Disclosed,['Bengaluru'],"We are looking for a Senior Generative AI Engineer who is passionate about cutting-edge AI innovation and has significant hands-on experience in building and deploying Generative AI models. In this role, you will be responsible for designing, fine-tuning, and optimizing large language models (LLMs), implementing innovative GenAI solutions, and contributing to the architecture of AI-driven platforms that deliver real business value.\n\nYou will collaborate with cross-functional teams including data scientists, machine learning engineers, product managers, and cloud infrastructure teams to build scalable, reliable, and secure AI systems. This is a high-impact position where you will directly influence the AI roadmap and innovation strategy.\n\nKey Responsibilities :\n\n- Design, develop, and fine-tune state-of-the-art Generative AI and LLM models tailored for various business use cases.\n\n- Build, integrate, and optimize solutions using transformer-based architectures (e.g., GPT, BERT, T5, LLaMA, Mistral).\n\n- Apply techniques such as fine-tuning, prompt engineering, RLHF (Reinforcement Learning from Human Feedback), and knowledge distillation to improve model performance.\n\n- Work with vector databases (e.g., FAISS, Pinecone, Weaviate) for implementing retrieval-augmented generation (RAG) pipelines.\n\n- Develop and deploy embedding models and integrate them into LLM pipelines.\n\n- Collaborate with engineering and product teams to deploy scalable AI systems using MLOps practices and CI/CD pipelines.\n\n- Leverage LangChain, Hugging Face Transformers, OpenAI APIs, and similar frameworks/tools to accelerate development.\n\n- Optimize model performance across different environments (cloud/on-premise).\n\n- Develop end-to-end pipelines, from data preprocessing to real-time inference and monitoring.\n\n- Ensure high standards of software quality, including testing, version control, code reviews, and documentation.\n\n- Stay up to date with the latest research in Generative AI and translate breakthroughs into production-ready solutions.\n\nRequired Skills & Qualifications :\n\n- Experience : 7+ years in AI/ML, data science, or software engineering; at least 3 - 4 years in Generative AI/LLMs.\n\n- Advanced Python programming skills, including familiarity with object-oriented design and software engineering best practices.\n\n- Deep expertise in PyTorch, TensorFlow, Transformers (Hugging Face), LangChain, and OpenAI or Anthropic APIs.\n\n- Experience in LLM fine-tuning, parameter-efficient tuning methods (LoRA, PEFT), RLHF, and model evaluation.\n\n- Experience with embeddings, vector stores (FAISS, Pinecone), semantic search, and RAG systems.\n\n- Hands-on experience with AWS, GCP, or Azure; knowledge of MLOps tools (SageMaker, Vertex AI, MLflow, Kubeflow) for training, deploying, and monitoring models.\n\n- Familiarity with structured/unstructured data handling and integrating AI systems with SQL/NoSQL databases.\n\n- Strong analytical thinking, problem-solving ability, and a keen interest in research and innovation.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Tensorflow', 'PyTorch', 'Generative AI', 'MLOps', 'NoSQL', 'ChatGPT', 'Artificial Intelligence', 'Data Modeling', 'LLM', 'Python', 'SQL']",2025-06-12 14:20:28
Senior System Testing QA Engineer - Enterprise Switching,Cisco,8 - 13 years,Not Disclosed,['Bengaluru'],"We are looking for a passionate and experienced System QA Engineer to join our Cisco Meraki team, passionate about testing our enterprise switching products. In this role, you will be responsible for validating the quality and adaptability of our switching platforms through comprehensive system-level testing. Your work will directly impact the stability, scalability, and performance of our networking solutions deployed in real-world customer environments.\nYou are an ideal candidate if you have:\n8+ years of experience in software or system quality assurance, with a strong focus on system-level testing of enterprise switches.\nHands-on experience crafting and driving solution tests, scale/stress tests, and performance tests that simulate realistic deployment and traffic conditions.\nDeep understanding and strong knowledge of standard Layer 2 and Layer 3 networking protocols, including but not limited to STP, RSTP, MSTP, VLAN, Link Aggregation (LAG), OSPF, BGP, VRRP, DHCP, and multicast, ipv4, ipv6, security features and other related technologies..\nAttention to detail, proven ability to build and maintain high-quality test plans that ensure end-to-end system validation and uncover edge cases early.\nStrong experience in debugging sophisticated system-level issues, analyzing test results, and collaborating closely with development and product teams.\nFamiliarity with Cisco Meraki or other enterprise-class switches, and confidence working in Cloud-based configuration environments.\nCisco Confidential\nProficiency in working with Linux systems and using command-line tools for test execution and log analysis.\nStrong proficiency in configuring and using traffic generators such as IXIA for performance, scale, RFC testing is required.\nA strong team player mindset, with a can-do attitude and a willingness to take ownership and jump in wherever needed.\nExcellent written and verbal communication skills.\nA Bachelors or Masters degree in Computer Science, Electrical Engineering, or a related technical field, or equivalent hands-on experience.\nBonus points for:\nScripting or automation experience using Python or Ruby for test setup, Orchestration, or data analysis.\nFamiliarity with CI/CD pipelines or automated test frameworks.\nFamiliarity with SIFOs and PoE related testing experience\nExperience with Cisco IOS, Catalyst Switch",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['System Testing', 'RFC testing', 'CI/CD', 'Cisco IOS', 'Quality Assurance', 'log analysis', 'Catalyst Switch']",2025-06-12 14:20:30
Sr Product Manager,Ennoventure Technologies,5 - 10 years,Not Disclosed,['Bengaluru'],"Job_Description"":""\nAt Ennoventure, we are redefining the fight against counterfeit goods with our groundbreaking technology. Backed by key investors like Fenice Investment Group and Tanglin Venture Partners, we are ready to embark on the next phase of our journey.\n\nOur aim? To build a world where authenticity reigns, ensuring every product and experience is genuine. Here, innovation moves fast, collaboration fuels success, and your growth isn\\u2019t just encouraged\\u2014it\\u2019s inevitable.\n\nAs a Lead Product Manager, you will drive exponential business growth by shaping product strategy, delivering exceptional user\nexperiences, and leading cross-functional collaboration. You will work closely with data science, engineering, design, and commercial teams to build scalable, cutting-edge products that deliver significant value to a global customer base.\n\n\nProduct Strategy & Vision\n- Define and evolve product strategy aligned with company goals and AI capabilities.\n- Translate AI advancements into differentiated product features with clear value for end-users.\n- Work with senior leadership to articulate product vision, business value, and a scalable roadmap.\n\nCustomer Discovery & Market Analysis\n- Conduct in-depth customer research to understand user pain points, workflows, and unmet needs.\n- Analyze competitive landscape, market trends, and regulatory considerations in AI SaaS.\n\nRoadmap Ownership\n- Define product requirements and maintain a clear, prioritized roadmap.\n- Lead the product lifecycle from ideation to delivery and post-launch iterations.\n\nCross-functional Leadership\n- Collaborate with engineering, design, and data science teams to build scalable, ethical, and user-centric AI products.\n- Partner with GTM teams (Sales, Marketing, Customer Success) to ensure successful product launches and feedback\nloops.\n\nExecution Excellence\n- Write detailed product specs, define OKRs, and drive sprint planning with agile teams.\n- Ensure timely delivery without compromising on quality or customer impact.\n\nAI-Product Interface\n- Work closely with machine learning engineers and data scientists to understand model capabilities and constraints.\n- Translate AI research and experiments into real-world applications and intuitive user experiences.\n\nBe the P&L Owner\n- Demonstrate strong business judgment and data obsession.\n- Own long-term growth strategies and drive measurable impact on the product P&L.\n\nBe the Product Evangelist\n- Engage in customer discovery to unlock more value and read market evolution that ensure the product evolves to\nmeet new customer needs and market trends.\n- Be fearless and drive Product thought process across the organization.\n\n\nRequirements\n- 5+ years of product management experience, with at least 2 years in B2B SaaS.\n- Proven experience in delivering AI/ML-powered products (preferably in Computer Vision, predictive analytics, or\nintelligent automation).\n- Strong technical foundation \\u2013 able to collaborate effectively with engineering and data science teams.\n- Demonstrated ability to drive product vision, strategy, and roadmap in a fast-growing environment.\n- Has owned and delivered successful product outcomes from opportunity identification to launch\n- Strong product sense \\u2013 highly analytical, with the ability to identify the right problems, think big and long term, and\nmake data-informed decisions.\n- Well-rounded solutioning skills \\u2013 human-centered, business-focused, and technology-driven.\n- Builds lasting peer relationships and has the ability to motivate and inspire teams to perform at their best.\n- Excellent written and verbal communication skills, with the ability to influence stakeholders at all levels.\n- Strong user empathy and a passion for creating delightful user experiences with complex technology.\n- Familiarity with tools like JIRA, Figma, Product board, or similar.\n\nNice to Have\n- Experience with AI model lifecycle (training, evaluation, deployment, retraining).\n- Understanding of data privacy, security, and ethical AI frameworks.\n- Prior startup experience or having scaled AI products in early-stage environments.\n\n\n\nBenefits\nWe believe that our people are the driving force behind our success, fueling big ambitions with bigger impact. We\\u2019re building more than just a workplace, we\\u2019re crafting a space where everyone feels seen, heard, and unstoppable. Here, you don\\u2019t just thrive, you grow, innovate, and leave a mark that matters.\n\nThat\\u2019s why we\\u2019re committed to equipping you with the best: a Total Rewards Policy that integrates-\n\n- Pay: A Competitive Salary that reflects your talent and drive!\n- Financial Reward: Performance-based Rewards that recognize your impact.\n- Well-being: Comprehensive Health Insurance & Mental Health Programs to keep you at your best!\n- Learning: An ongoing investment in you and your skills.\n- Personalized Development: Self-growth plans crafted to match your performance and career aspirations.\n- Compensation Reviews: Regular reviews to ensure your value aligns with market trends.\n\n"",""",Industry Type: IT Services & Consulting,Department: Product Management,"Employment Type: Full Time, Permanent","['Product management', 'Computer vision', 'Market analysis', 'Automation', 'data science', 'Analytical', 'Machine learning', 'Agile', 'Engineering Design', 'Product strategy']",2025-06-12 14:20:33
Senior Program Manager,Kalvi Career Education,10 - 20 years,Not Disclosed,['Bengaluru'],"Senior Program Manager @ Kalvium\nLocation: Bangalore (Karnataka)\nWork Timings: Monday to Saturday, 8:45AM-6:15PM\n\nAbout Kalvium\nKalvium is an exceptional startup with a mission to make the world's education more relevant and engaging. Our flagship offering is India's BEST Undergrad program in Computer Science Engineering which is offered across 20+ Universities in India.\n\nWe are backed by 30+ industry stalwarts like top executives from Google, Microsoft, Flipkart, and PhonePe, as well as luminaries of India's unicorn ecosystem like Anupam Mittal, Kunal Shah, Rahul Chari, and Ankit Bhati.\n\nWe are on the lookout for passionate minds to champion our vision and join us on a journey to redefine the global tech education landscape.\n\nResponsibilities\n\n1. Program Management\nEnsure smooth execution of the Kalvium program on the assigned campus.\nMonitor and improve student learning progress, outcomes and experience through data analysis and dashboards.\nCollaborate with internal and external stakeholders to ensure effective program operations.\nManage student / parent / university stakeholder interactions.\nManage on-ground operations for assessments, events and other program-related activities.\nTake up and drive execution of various initiatives from time to time.\n\n2. Mentorship\nFacilitate professional development and career outcomes of a cohort of Kalvium students, ensuring successful placements and optimal performance reviews from recruiting tech companies.\nProvide counselling, guidance and support to students to help them overcome challenges during their learning journey and at work.\n\n3. Team Management\nManage a team of Academic Mentors and Campus Managers on campus to deliver and drive the necessary outcomes.\n\n4. Travel Readiness\nThis role entails frequent travel, with approximately half of the workdays spent at various Kalvium campuses, overseeing campus operations and connecting with diverse stakeholders.\n\nQualification: Masters degree in any related Engineering or Management field with a minimum of 10+ Years of relevant experience.\n\nA Kalvium Senior Program Manager serves as the glue that ties the program together and acts as a role model for our future Software Engineers. Before applying, consider the following questions:\nAre you interested in helping students succeed in their careers?\nDo you enjoy mentoring students?\nDo you possess good communication and presentation skills?\nAre you a good listener?\nAre you proficient in working with data?\nAre you obsessed with productivity?\n\nLocation: Bangalore (Karnataka)\nWork Timings: Monday to Saturday, 8:45AM-6:15PM\nCTC: Offered CTC will be based on (1) Your Current CTC and (2) Your Interview Performance\n\nInterview Process:\n1st Round:- HR Discussion.\n2nd Round:- Technical Interview with Head of Program Delivery, With An Assignment(Assignment will be shared to you if you pass the 1st Round).\n3rd Round:- With One of Our Co-Founder.\n4th Round:- Culture Round/CTC Discussion With Head of HR.\n\nKalvium Benefits:\nOpportunity to be part of an impactful movement to transform higher education for the better, with a competitive salary.\nChallenging role designed to significantly enhance your professional profile and skills.\nWork closely with the founders and the founding team.\nEnjoy an awesome work culture that helps you thrive with the team.\n\nKalvium's Core Values:\nWe obsess about student experience and outcomes above all.\nWe embrace extreme ownership, focusing on outcomes over tasks.\nWe respect and trust each other.\nWe disagree with candour and courtesy.\nWe improve things regularly, rather than chase perfection.\nWe learn continuously and seek discovery.\n\nIf you resonated with the description and answered 'Oh, that's so me' while reading along, this role is an ideal fit for you.",Industry Type: Education / Training,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Program Management', 'Senior Program Manager', 'Stakeholder Management']",2025-06-12 14:20:35
Consultant - Sr. Power BI Developer,Affine Analytics,5 - 8 years,Not Disclosed,['Bengaluru'],"Design, develop, and deploy Power BI reports and dashboards that provide key insights into business performance.\nCreate and maintain complex Power BI data models, integrating data from multiple sources.\nWrite and optimize SQL queries to extract, manipulate, and analyze data from various databases.\nCollaborate with cross-functional teams to understand business requirements and translate them into effective BI solutions.\nPerform data analysis using Excel, Power Query, and other tools to support reporting and analytics needs.",,,,"['Power BI', 'Excel', 'Power BI Online Services', 'Power Query', 'SQL', 'Power BI Dax']",2025-06-12 14:20:37
Senior Designer UI UX,The Printers Mysore,5 - 10 years,12-18 Lacs P.A.,['Bengaluru'],"Digital Division of Deccan Herald/Prajavani\n\nJob Description for Senior Designer UI UX\n\nLocation Bangalore (Head Office)\n\nReporting to: Digital Business Head\n\nJob Description:\nWe are looking for a passionate and highly skilled Senior UI/UX Designer to join our dynamic digital team. You will be instrumental in creating intuitive, engaging, and user-centered designs for our digital products (Web+App+Epaper - www.deccanherald.com & www.prajavani.net) and potentially future digital products. You will be responsible for the end-to-end design process, from user research and concept development to detailed UI specifications and visual design. You will collaborate closely with product managers, developers, editorial teams, and other stakeholders to ensure our digital platforms meet user needs and business objectives.\n\nKey Responsibilities:\nLead and execute the full UI/UX design process for our digital products, including user research, information architecture, wireframing, prototyping, visual design, and usability testing.\nDevelop a deep understanding of our users through various research methods, including user interviews, surveys, and analytics analysis.\nTranslate user needs, business requirements, and technical constraints into effective and innovative design solutions.\n¢ Create user flows, wireframes, prototypes, and high-fidelity mockups to effectively communicate design ideas and concepts.\n¢ Develop and maintain UI style guides, design systems, and component libraries to ensure consistency and scalability across our digital platforms.\n¢ Collaborate closely with front-end developers to ensure accurate and efficient implementation of designs.\n¢ Work iteratively based on user feedback, data analysis, and technical feasibility.\n¢ Conduct usability testing and gather feedback to identify areas for improvement and iterate on designs.\n¢ Stay up-to-date with the latest UI/UX trends, best practices, and emerging technologies.\n¢ Present design concepts and rationale to stakeholders effectively.\n¢ Mentor and guide junior designers (if applicable).\n¢ Contribute to the overall digital strategy and product roadmap.\n\n\nQualifications & Experience\n\n¢ Bachelor's or Master's degree in Design, Human-Computer Interaction (HCI), or a related field.\n¢ Proven experience (typically 5+ years) as a UI/UX Designer, with a strong portfolio showcasing user-centered design solutions for web and mobile platforms.\n¢ Deep understanding of user-centered design principles, interaction design, information architecture, and usability best practices.\n¢ Proficiency in industry-standard design and prototyping tools such as Figma, Sketch, Adobe XD, InVision, etc.\n¢ Experience with user research methodologies and usability testing.\n¢ Solid understanding of web development technologies (HTML, CSS, JavaScript) and their impact on design feasibility.\n¢ Excellent visual design skills with a strong understanding of typography, color theory, and layout principles.\n¢ Strong communication, presentation, and interpersonal skills, with the ability to articulate design rationale clearly and persuasively.\n¢ Ability to work independently, manage multiple projects, and meet deadlines in a fast-paced environment.\n¢ Experience working in an agile development environment is a plus.\n¢ Familiarity with the media industry and content-heavy websites is a plus.\n¢ Experience with data analytics tools (e.g., Google Analytics) and using data to inform design decisions is a plus.\n\nAbout Us\nThe Printers Mysore limited is a leading Media Company in India with iconic media brands like Deccan Herald and Prajavani. The Printers Mysore is going from being an integral part of the print media ecosystem to a diversified media group.\nCapitalizing on the strength of its media brands, it has embarked on a journey to develop a digital media business for the 21st century media consumer.\nCurrently Deccan Herald and Prajavani are available across various digital products such as desktop and mobile sites, mobile apps and e-papers. The brands have incrementally increased their focus on digital and social media, by creating specialized content in this area.\nKnow more about us -\nhttps://printersmysore.com| https://www.deccanherald.com | https://www.prajavani.net/\nhttps://www.facebook.com/deccanherald | https://www.facebook.com/prajavani.net\nManagement Council & Executive Leadership info: https://printersmysore.com/Team -----------------------------------------------------------------------------------------------------------",Industry Type: Printing & Publishing,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent",['UI/UX Designer'],2025-06-12 14:20:39
Junior Executive MIS - HR (No B.tech Applicants),GMR Airports Infrastructure,3 - 7 years,4.25-5 Lacs P.A.,['Hyderabad'],"Job Title: Junior Executive - Talent Acquisition- (LJ- Grade)\nJOB PURPOSE\nExecute all transactions related to gratuity policies and superannuation settlements for all employees across the\nGroup to ensure compliance to statutory policies.\nYou will play a vital role in supporting data-driven decision-making and providing valuable insights to the Human\nResources (HR) function. Your primary focus will be on collecting, analysing, and interpreting HR /TA data to\nidentify trends, patterns, and opportunities for improving HR processes and initiatives. This role requires a strong\nanalytical mindset, proficiency in data analysis tools, and the ability to translate complex HR data into meaningful\nreports and presentations.\nORGANISATION CHART\nKEY ACCOUNTABILITIES\nTo work on all the MIS tracker/data of HR like recruitment, joining, employee database, YTD etc and update\nthe record accordingly\nUpdate various HR MIS on daily, weekly, monthly , quarterly and annually\nResponsible for maintaining and updating data within TAT\nGenerate and share reports/dashboards in an accurate and timely manner\nProvide strong reporting and analytical information supporting to the HR team\nProvide recommendation to update current MIS to improve reporting efficiency and consistency\nManaging the HR business MIS in excel for all the relevant records of employees\nWill be responsible for transformation of all documents in digital platforms\nAny other task as assigned by Head-HR/HOD\nKEY ACCOUNTABILITIES - Additional Details\nEXTERNAL INTERACTIONS\nRecruitment Consultants, Background Verification\nVendor, Pre-Employment Medical Vendor, Thomas\nAssessment, Naukri Portal etc.\nINTERNAL INTERACTIONS\nAll Business HR, TA SPOC, Hiring Managers, CHROs, FMS, IT, MAG Department and other stake holders.\nFINANCIAL DIMENSIONS\nThe funds in both Gratuity & Superannuation Trusts appox. Rs.85 crores\nOTHER DIMENSIONS\nNo.of employees covered under both the Trusts - About 9000\nEDUCATION QUALIFICATIONS\n¢Any Graduation\nRELEVANT EXPERIENCE\n3-5 years of similar HR data experience\nIn-depth knowledge of HR processes, metrics, and KPIs.\nStrong analytical and problem-solving skills, with the ability to extract insights from complex HR data sets.\nProficiency in using data analysis tools and programming languages such as advanced excel",,,,"['HR MIS', 'Excel', 'Hr Reporting', 'Dashboards', 'Pivot Table', 'VLOOKUP']",2025-06-12 14:20:41
Sr ETL/SSIS developer,Sagility India,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Summary\nWe are seeking a highly skilled and self-driven SSIS with strong communication and client-facing skills to join our healthcare analytics team. This role requires a combination of deep technical expertise in SSIS and data integration along with the ability to consult and collaborate directly with clients to understand and address their data needs.\nThe ideal candidate will be experienced in building and maintaining scalable data pipelines, working with diverse healthcare data sources, and ensuring data quality and availability for downstream analytics. You will play a key role in delivering clean, trusted, and timely data for insights and reporting.\nKey Responsibilities\nDesign, develop, and maintain robust and scalable SSIS to support healthcare analytics and reporting platforms.\nEngage directly with clients to gather requirements, provide consultation, and translate business needs into technical solutions.\nIntegrate and normalize data from diverse healthcare data sources, including claims, EMR, lab, pharmacy, and eligibility systems.\nEnsure data accuracy, completeness, and consistency throughout ingestion and transformation processes.\nOptimize and tune data workflows for performance and scalability in a cloud or on-premise data platform.\nTroubleshoot and resolve data issues in a timely and proactive manner to support high data availability.\nCollaborate with analysts, data scientists, and business stakeholders to ensure data pipelines meet analytical needs.\nCreate and maintain comprehensive technical documentation for data pipelines, data dictionaries, and workflows.\nStay informed on healthcare compliance requirements (e.g., HIPAA), and ensure data handling practices follow regulatory standards.\nRequired Skills and Qualifications\n6+ years of experience in SSIS development and data engineering\nProven ability to interact directly with clients and translate business problems into data solutions\nStrong experience with SQL, SSIS, or PySpark for data processing\nDeep understanding of data warehousing concepts and dimensional modeling\nExperience working with healthcare datasets (e.g., claims, eligibility, clinical data)\nFamiliarity with cloud platforms (Azure, AWS, or GCP) and data lakes\nStrong troubleshooting, problem-solving, and performance tuning skills\nExcellent verbal and written communication skills\nBachelor's or Masters degree in Computer Science, Engineering, Information Systems, or a related field\nPreferred Qualifications\nProficiency in building data pipelines using tools such as Azure Data Factory, Informatica, Databricks, or equivalent\nExperience with FHIR, HL7, or other healthcare data standards\nFamiliarity with HIPAA and healthcare compliance requirements\nKnowledge of reporting tools like Power BI or Tableau\nExposure to CI/CD and data pipeline automation\nWhy Join Us?\nWork on high-impact healthcare projects with meaningful outcomes\nEngage directly with clients and make a tangible difference in their data strategy\nCollaborative team culture and continuous learning opportunities\nFlexible work arrangements and competitive compensation\n\nLocation - Bangalore\nShit Timing - 2 Pm to 11 PM\nWork - Hybrid\n\nRegards,\nnaveen.vediyappan@sagility.com",Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SSIS', 'SQL', 'ETL']",2025-06-12 14:20:43
SQL Developer- Healthcare Provider Experience Required,Optum,2 - 6 years,Not Disclosed,['Hyderabad'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together \n\n  \n\n Primary Responsibilities: \n\nGather and analyze requirements for clinical data conversion projects\nCollaborate with clients and vendors to define project scope, timelines, and deliverables\nPrepare and transform clinical data for conversion activities\nAddress and resolve data-related issues reported by clients\nDevelop and maintain documentation and specifications for data conversion processes\nMonitor project progress and ensure timely completion of milestones\nTroubleshoot common database issues and provide technical support\nEnsure compliance with US healthcare regulations and standards\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\n Required Qualifications: \nFamiliarity with US healthcare systems and regulations\nKnowledge of standard EHR/EMR clinical data workflows\nUnderstanding of healthcare clinical dictionaries\nProficiency in EHR database architecture and data extraction/transformation using MS SQL Server\nSolid knowledge of stored procedures, triggers, and functions\nProven excellent problem-solving and troubleshooting skills\nSolid communication and collaboration abilities",Industry Type: Retail,Department: Healthcare & Life Sciences,"Employment Type: Full Time, Permanent","['stored procedures', 'data extraction', 'triggers', 'ehr', 'troubleshooting', 'hipaa', 'us healthcare', 'emr', 'icd', 'sql', 'spark', 'hims', 'medical billing', 'rcm', 'python', 'project management', 'data analysis', 'business analysis', 'epic', 'sql server', 'hl7', 'pharmacy', 'agile', 'aws', 'revenue cycle management']",2025-06-12 14:20:45
Software Engineer II,Chegg,3 - 8 years,Not Disclosed,['New Delhi'],"About the Team\nChegg's engineering team is a group of passionate engineers who, in close collaboration with data scientists, product managers, designers, and other backend developers, build the future of the online education industry. We develop our products to scale and to last, we dont take shortcuts (hello unit tests and documentation), and we take pride in delivering high-quality solutions on time. We are cloud native.\nRole\nWe are looking for software engineers passionate about solving real-world problems for students in online education using technology. The ideal candidate can think outside the box, is passionate about technology, is adaptable, thinks big, and is passionate about making an impact. Chegg is evolving very fast, and we are constantly redefining our offerings to match the requirements of our student community; the candidate should have the appetite to pivot fast and be interested in continuous improvement and learning. Chegg has a very open and vibrant engineering culture where the candidate will get the opportunity to work with the best in the industry; the role demands ideating and sharing creative ideas as you never know the next big thing Chegg works on can come from you !! If you have dreamt of leveraging your skills and knowledge to impact something big enough to matter, Chegg provides those opportunities, and the candidate should make the best use of them.\nResponsibilities\nDetermine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions;\nCross-team collaboration in driving the end-to-end delivery of SDN on Edge;\nParticipating in the code reviews and design discussions of other engineers;\nHave a strong sense of end-to-end ownership;\nAdhere to key principles: Code and design for best performance, scalability, and resiliency;\nParticipate in daily SCRUM meetings;\nParticipates in the testing process through test review and analysis, test witnessing, and certification of software;\nBe a self-starter, capable of solving ambiguous and challenging technical problems with wide scope;\nFull stack development of new features/tools, including design, documentation, implementation, and testing;\nWork alongside other engineers on the team to elevate technology and consistently apply best practices.\nSkills and Qualifications [Must Have]\nB.E., B.Tech, . degree in Computer Science or a related technical field\n3+ years of product lifecycle experience (from customer requirements -> functional spec -> design -> development/testing -> deployment and monitoring);\nStrong interpersonal and communication skills;\nStrong hands-on development/scripting experience with Python and shell.\nUse tools and methodologies to create representations of workflows, user interfaces, data schemas, etc;\nSolid understanding of software design and development;\nExperience with third-party libraries and APIs;\nExcellent design and problem-solving skills.\nStrong experience with Cloud technologies such as AWS\nExperience with Unit testing frameworks for TDD (Test Driven Development) methodology\nSkills and Qualifications [Good To Have]\nSolid understanding of Agile methodologies and experience working in Agile teams.\nHands-on experience with CI/CD pipelines, preferably using GitLab.\nDevelopment knowledge of mobile apps (android/iOS)",Industry Type: E-Learning / EdTech,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'schema', 'continuous integration', 'software testing', 'software design', 'unit testing', 'android', 'ci/cd', 'solution development', 'ios', 'cloud technologies', 'tdd', 'full stack', 'scrum', 'gitlab', 'shell scripting', 'software engineering', 'code review', 'agile', 'api', 'agile methodology']",2025-06-12 14:20:48
Specialist - Performance Marketing,Chegg,5 - 10 years,Not Disclosed,['New Delhi'],"Responsibilities\nLeverage your channel expertise to identify opportunities and provide strategic recommendations to optimize and drive performance marketing channel growth.\nCollaborate with internal stakeholders to gather campaign requirements, set up campaigns, and ensure accurate implementation across multiple ad platforms (Google Ads & Meta primarily).\nUpdate channel performance reports and provide actionable insights through timely commentary.\nCarry out regular health checks on the accounts to ensure they are set up and running as per best practice.\nDesign & implement optimisation best practices for ad platforms.\nConduct keyword research, expansion, and refinement to enhance campaign relevancy and performance.\nProactively troubleshoot and resolve issues to ensure seamless campaign delivery and accurate reporting.\nSupport in Q&A of testing documentation and implementation of experiments.\nDevelop, document & implement relevant workflow processes.\nWork closely with the UK team and external partners on strategic projects and make recommendations for market or campaign expansion.\nStay updated with industry trends, best practices, beta offerings and emerging technologies in ad operations. Apply new insights and knowledge to improve channel strategies and campaign tactics.\nRequirements\nDemonstrable expertise managing Google Ads campaigns with a track record of driving successful results. Candidates should have at least 5 years hands-on performance marketing experience.\nPreferred: knowledge of Meta or other paid social advertising platforms.\nStrong written and verbal communication skills are critical in this role, as it involves close collaboration with UK-based teams.\nData analysis and reporting skills, with advanced Google Sheets / Excel skills required, and Tableau data visualization and GA4 experience beneficial.\nA bachelor's degree in marketing, communications, or similar.\nBias towards action: quickly actioning opportunities, communicating effectively with stakeholders, and adapting approach in a fast-paced environment.",Industry Type: E-Learning / EdTech,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['Marketing', 'marketing Planning', 'Google Ads campaigns', 'Tableau data visualization', 'Performance Marketing']",2025-06-12 14:20:50
"Specialist, Technical Professional Services",Fiserv,5 - 7 years,Not Disclosed,['Noida'],"The Setup and Config specialist is responsible to Analyse current system setup (Account Processing), configure, and verify it on new system based on discussions with clients in close collaboration with the team. This is a full-time position with career growth opportunities and a competitive benefits package. If you want to in financial institutions and businesses worldwide solve complex business challenges every day, this is the right opportunity for you.\nWhat you will do\nMust take complete ownership of setup/configuration for the assigned conversion/implementation.\nManages multiple clients and adhere to project timelines.\nMonitors project progress by tracking activity, resolving problems, publishing progress reports, recommending actions in accordance with stated procedure.\nAssists management with the planning and design of improvements to business processes.\nUtilizes system and data to resolve business issues in the most effective manner.\nAnalyse and identifies root cause; providing input to solutions that lead to success of the project.\nCommunicate progress and any potential problems to Project Manager for awareness and/or resolution.\nMaintain the tools used to ensure the efficiency and effectiveness of the conversion process (system studies, timelines, and questionnaires).\nWork in late night shift (up to 11 PM IST) to provide overlap with US working hours.\nProvide post implementation support for 2 weeks. (US shift timing will depend on time zone of client)\nWhat you will need to have\nB.Tech/MCA/MSC (IT/CS)/BCA/BBA\n5 to 7 years of experience in IT Industry.\nExcellent knowledge of Account Processing applications (US)\nGood understanding of Excel\nShould have good understanding of activities performed in conversion/implementation of core Banking application.\nKnowledge of Banking domain.\nExperienced problem solving and data analysis skills.\nExcellent verbal and written communication and interpersonal skills\nWhat would be great to have\nExperience supporting Banking Core Conversions.\nExperience on Account Processing core is a plus.\nExposure to Banking and Financial Services industry with a good understanding of Banking Products, Services & Procedures.\nUnderstanding of Mainframe.\nStrong analytical skills, good verbal and written communication skills and the ability to interact professionally with a diverse group. .",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Data analysis', 'Publishing', 'Finance', 'Diversity and Inclusion', 'Revenue generation', 'Financial services', 'Technical Professional', 'Core banking']",2025-06-12 14:20:52
Mechatronics Technician,FORVIA HELLA,3 - 5 years,Not Disclosed,['Gurugram'],"FORVIA HELLA is a listed international automotive supplier. As a company of the FORVIA Group, FORVIA HELLA stands for high-performance lighting technology and vehicle electronics and, with the Lifecycle Solutions Business Group, also covers a broad service and product portfolio for the spare parts and workshop business as well as for manufacturers of special vehicles. With currently around 36,500 employees at over 125 locations, the Company is active worldwide and generated adjusted sales of 8.1 billion in fiscal year 2024.\nYOUR TASKS\nKey Responsibilities/ Job Description\n1. Utility System Operation & Maintenance:\nEnsure uninterrupted operation of air compressors, water chillers, and nitrogen generation plant.\nManage daily operations and maintenance of HT VCBs, LT ACBs, panels, and all plant electrical and pneumatic systems.\nOversee the fire pump house operations, including equipment readiness and testing.\nSupervise and manage the operation and upkeep of the STP (Sewage Treatment Plant).\n\n2. Preventive and Predictive Maintenance:\nPlan and execute preventive maintenance schedules for all utility equipment.\nMonitor equipment performance and implement predictive maintenance techniques to avoid unplanned downtime.\nMaintain equipment history records and service reports.\n\n3. Energy Monitoring and Optimization:\nMonitor, record, and analyze energy data, including electricity, air, water, and nitrogen consumption.\nIdentify areas for energy savings and implement energy efficiency initiatives.\n\n4. Documentation & Reporting:\nMaintain daily logs and reports for all utility systems.\nPrepare and share weekly/monthly utility performance and maintenance reports with the management and global teams.\nMaintain documentation for audits, safety compliance, and standard procedures.\n\n5. Team Management & Coordination:\nLead and guide a team of technicians and operators in day-to-day activities.\nCoordinate with production, maintenance, and safety teams for seamless plant operations.\nCommunicate and collaborate with global teams for reporting, data sharing, and implementation of best practices.\n\n6. Safety & Compliance:\nEnsure adherence to safety protocols and statutory compliance related to utility operations.\nConduct risk assessments and implement corrective actions for identified hazards.\nYOUR QUALIFICATIONS\nKey Skills and Competencies:\nStrong knowledge of utility systems and maintenance practices.\nUnderstanding of electrical systems, HT/LT panels, pneumatic systems, and water treatment operations.\nFamiliarity with energy monitoring and reporting tools.\nGood communication and interpersonal skills.\nProficiency in MS Excel, Word, and basic data analysis tools.\nAdditional Requirements:\nWillingness to respond to emergencies, if needed.\nStrong commitment to safety, reliability, and continuous improvement",Industry Type: Automobile,"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['Plant operations', 'Water treatment', 'Mechatronics', 'Data analysis', 'Team management', 'Spare parts', 'Continuous improvement', 'Automotive', 'STP', 'Preventive maintenance']",2025-06-12 14:20:54
Hiring ER Escalation Investigator-work place investigation-Gurugram,Amazon,5 - 10 years,20-30 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","We are hiring Escalation Investigator ( Work place investigations,mandatory ) based of Gurugram location.\n\nIf interested please apply on our portal\nhttps://www.amazon.jobs/en/jobs/3003294/er-escalation-investigator-india-ops-er-investigations\n\n\nKey skils:Work place investigations,mandatory",,,,"['investigation', 'Industrial Relations', 'employment laws', 'Employee Relations', 'labour laws']",2025-06-12 14:20:56
Biomedical Engineer (BME),Sodexo,5 - 10 years,3.5-4.5 Lacs P.A.,['Prayagraj'],"1. Assist in design, development, and testing of medical devices/equipment\n2. Conduct data analysis, research, and experimentation\n3. Collaborate with cross-functional teams (engineering, clinical, research)\n4. Support documentation, reporting, and regulatory compliance\n5. Troubleshoot and resolve technical issues\n\nRequirements:",,,,"['Biomedical', 'Biomedical Engineering', 'Health Care Services', 'Healthcare Management', 'Hospital equipments', 'Medical Services', 'Hospital Management', 'Medical Devices', 'BME', 'Medical Equipment']",2025-06-12 14:20:58
Ai Ml Engineer,Optum,5 - 10 years,Not Disclosed,['Noida'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.  \nAI Engineer is tasked with the design, development, and deployment of advanced generative AI models and systems. This position requires close collaboration with data scientists, product managers, and other stakeholders to integrate generative AI solutions into existing products and develop new innovative features. Proficiency in the Agentic AI framework is vital for coordinating multiple autonomous AI agents to accomplish complex tasks.\n\nPrimary Responsibilities:\nImplement Generative AI Models: Develop sophisticated generative AI algorithms and models to create new data samples, patterns, or content based on existing data or inputs\nData Processing: Collaborate with stakeholders to preprocess, analyze, and interpret extensive datasets\nModel Deployment: Deploy generative AI models into production environments, ensuring scalability and robustness\nOptimization: Conduct model testing, validation, and optimization to enhance performance\nIntegration: Work with cross-functional teams to seamlessly integrate generative AI solutions into products\nResearch: Stay current with the latest advancements in generative AI technologies and practices\nAgentic AI Framework: Utilize the Agentic AI framework to coordinate multiple AI agents for the completion of complex tasks\nMentorship: Provide mentorship to junior team members and offer technical guidance\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\nRequired Qualifications:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field\n5+ years of experience in software engineering with a focus on AI/ML\nExperience with data preprocessing and analysis\nKnowledge of the Agentic AI framework and its application in AI systems\nProficiency in machine learning frameworks such as TensorFlow and PyTorch\nSolid programming skills in Python, Java, or C++\nFamiliarity with cloud platforms (e.g., AWS, Google Cloud, Azure)\nProven excellent problem-solving abilities and algorithmic thinking\nProven solid communication and teamwork skills\n\nPreferred Qualifications:\nExperience with data processing\nKnowledge of version control systems like Git\nUnderstanding of Generative AI, associated technologies and frameworks like RAG, agents etc.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Agentic Ai', 'Gen AI', 'Cloud', 'RAG', 'LLM']",2025-06-12 14:21:00
Finance & Accounts Consultant,JSW Steel,3 - 8 years,Not Disclosed,"['karnataka', 'Vijayanagara']","About us: The Inspire Institute of Sport is a cutting-edge environment founded to craft champions in India with an eye on success at the Olympic Games. Located in Vijayanagara, Karnataka, the IIS has been stitched together with state-of-the-art facilities and sports science, and has some of the finest coaching minds from across the world to guide our athletes towards the Indian Olympic dream.\n\nOur Vision: To position India at the forefront of Olympic and Paralympic sports, cultivating a legacy of champions through exemplary dedication to sports and para-sports excellence.\n\nOur Mission: To develop and sustain a nationwide network of world-class high-performance Centres and development programs across multiple sports, including dedicated support for para-athletes. To provide holistic and interdisciplinary training environments that empower all athletes to maximize their potential and significantly contribute to India's Olympic and Para-Olympic medal achievements.\nPosition: Finance & Accounts Consultant\nDepartment: Finance and Account\nJob Location: Vijayanagara, Karnataka\nNature of Work\n\nOnsite\nWe are looking for a dedicated and detail-oriented Finance & Accounts Consultant to join our dynamic team. The ideal candidate will have strong accounting knowledge, excellent analytical skills, and experience in financial reporting, taxation, and banking operations. This role requires a proactive professional who can manage multiple finance-related responsibilities while ensuring compliance with statutory requirements.\n\nKey Responsibilities:\nAccounting & Bookkeeping:\nEnsure accurate and timely entries in the books of accounts.\nAssist in month-end, quarter-end, and year-end book closures.\nConduct thorough document and invoice verification before passing entries\nFinancial Reporting & Compliance:\nGenerate and analyze relevant MIS reports as required.\nCompile accurate data for TDS and GST return filings.\nAssist in statutory, internal, and donor audits.\nAssist in the preparation of budgets.\nBanking & Reconciliation:\nPerform bank reconciliations regularly.\nHandle sundry creditors/debtors reconciliation and ageing analysis\nObtain statements of accounts from vendors and customers.\nManage day-to-day banking operations and coordination.\nPayroll & Invoicing:\nAssist in payroll processing from the finance and accounts perspective.\nPrepare invoices and ensure accurate financial documentation\nRequirements:\nAccounting Knowledge: Strong understanding of fundamental accounting principles\nTaxation: Working knowledge of GST and TDS regulations.\nBanking Operations: Experience in handling day-to-day banking transactions and coordination.\nCost Centres: Good understanding of Cost Centre accounting.\nStrong analytical and problem-solving skills.\nEffective communication and interpersonal skills.\nAbility to work under tight deadlines and manage multiple tasks.\nAttention to detail and accuracy in financial reporting.\nTechnical Financial Software:\nTally Prime (Version 3 and above): Proficiency in ledger configuration, statutory adjustments, and financial reporting.\nMicrosoft Office Suite: Advanced proficiency in Excel (including formulas, pivot tables, and data analysis), Word, and PowerPoint.\nPower BI: Working knowledge preferred.\nPreferred Qualifications and Experience:\nCA Intermediate having completed article ship with a CA Firm with 3 years of experience.\nMasters (Finance): Minimum of 3 years of experience in finance and accounts.\nBachelors (Finance): Minimum of 6 years of relevant experience\nCandidate Requirements & Professional Expectations:\nIndustry Preference: Experience in the Non-Profit Organization sector is preferred.\nWork Attitude: Must exhibit an enabling attitude towards work and have a reasonable understanding of the dynamics of a fast-paced corporate environment.\nHow to Apply:\nPlease submit your resume and cover letter detailing your qualifications and experience with mary.appospet@inspireinstituteofsport.com",Industry Type: Sports / Leisure & Recreation,Department: Finance & Accounting,"Employment Type: Full Time, Temporary/Contractual","['TDS', 'Financial Reporting', 'GST', 'Bank Reconciliation', 'Internal Audit', 'creditors', 'Accounting', 'Donor Management', 'statement of Accounts', 'Trust Accounting', 'payroll processing', 'MIS', 'Book Keeping', 'Sundry Debtors', 'Cost Center Accounting']",2025-06-12 14:21:03
Wipro Hiring For Inventory Planner- Retail,Wipro,2 - 4 years,5-8.5 Lacs P.A.,['Pune'],Job description\nRole & responsibilities\nCollaboration for product life cycle within functions\nDemand Forecasting: Read and analysis and updating of demand forecasts\nInventory Management: Understand concept and make business decision on inventory management for seasons\nData Interpretation: Utilize Tableau to generate and interpret exception reports for inventory management,,,,"['Stock Replenishment', 'Purchase Order', 'Communication Skills', 'Retail Sales', 'Pricing Analysis', 'Retail Merchandising', 'Power Bi', 'Sales Forecasting', 'Data Analysis']",2025-06-12 14:21:05
Windchill Support Consultant,Cognizant,2 - 3 years,Not Disclosed,['Pune'],Job Summary\nWe are seeking a dedicated Product Analyst with 2 to 3 years of experience to join our team. The ideal candidate will have expertise in Windchill and a strong understanding of the Provider domain. This hybrid role requires a proactive individual who can work effectively in a day shift. The position does not require travel allowing you to focus on delivering impactful solutions that align with our companys goals.,,,,"['product documentation', 'data analysis', 'life cycle', 'analytical', 'product analysis', 'continuous improvement', 'customer satisfaction', 'strong communication skills', 'product development', 'analysis tools', 'technical specifications', 'windchill', 'product testing', 'communication skills']",2025-06-12 14:21:07
AI--Content Expert-Amazon Hiring!!--Chennai,Amazon,3 - 8 years,8-10 Lacs P.A.,['Chennai'],"External job description\n\nAmazon is looking for an AI Content Expert II to help with annotations, content generation, and data analysis. As part of the Data Team, you will be responsible for delivering high-quality training data to improve and expand AGI's Large Language Models' (LLMs) capabilities.Key job responsibilities As an AI Content Expert, you will be responsible for creating training data that are complex in nature and will require you to make informed and high judgement decisions in each case. You will be working closely with scientists and engineers to review and update guidelines, identify tooling improvement opportunities, and engage in conversations regarding the quality of data.",,,,"['Content Writing', 'Strong Communication Skills', 'SEO Writing', 'Content Creation', 'Business Writing', 'Script Writing', 'Blog Posting', 'Creative Writing', 'Content Editing', 'Research Writing', 'Content Development', 'Web Content Writing', 'Copy Writing', 'Article Writing', 'Content Research']",2025-06-12 14:21:10
AI--Content Expert-Amazon Hiring!!--Hyderabad,Amazon,3 - 8 years,8-10 Lacs P.A.,['Hyderabad'],"External job description\nAmazon is looking for an AI Content Expert II to help with annotations, content generation, and data analysis. As part of the Data Team, you will be responsible for delivering high-quality training data to improve and expand AGI's Large Language Models' (LLMs) capabilities.\nKey job responsibilities\nAs an AI Content Expert, you will be responsible for creating training data that are complex in nature and will require you to make informed and high judgement decisions in each case. You will be working closely with scientists and engineers to review and update guidelines, identify tooling improvement opportunities, and engage in conversations regarding the quality of data.",,,,"['Content Creation', 'Content Writing', 'SEO Writing', 'Proof Reading', 'Business Writing', 'Blog Writing', 'Script Writing', 'Content Strategy', 'Creative Writing', 'Content Management', 'Content Editing', 'Content Development', 'Web Content Writing', 'Copy Writing', 'Article Writing', 'Content Research']",2025-06-12 14:21:12
Artificial Intelligence Architect,Emerson,10 - 20 years,Not Disclosed,['Pune'],"Role & responsibilities\nDesign robust and scalable AI/ML architectures that support the development and deployment of machine learning models and AI solutions.\nDevelop and guide the implementation of end-to-end AI/ML solutions, including model development, data processing, and system integration.\nEvaluate and recommend the latest AI/ML technologies, frameworks, and tools to enhance system capabilities and performance.\nCollaborate with software engineers and other development teams to integrate AI/ML solutions into existing systems and applications. Ensure seamless operation and performance.\nWork with cross-functional teams, including developers, data scientists, machine learning engineers, and business stakeholders, to understand requirements and design solutions that align with business objectives.\n\nPreferred candidate profile\nBachelors degree in computer science, Data Science, Statistics, or a related field or a master's degree or higher is preferred.\nMore than 3 years of experience in designing and implementing AI/ML architectures, with a proven track record of successful projects.\nExtensive experience with machine learning frameworks (e.g., Go, TensorFlow, PyTorch), programming languages C#, .Net, NodeJS and data processing tools.\nStrong understanding of system architecture principles, including distributed systems, microservices, and cloud computing.\nExperience with Microsoft Azure cloud services and their AI/ML offerings\nExperience with event-handling systems such as Kafka\nExperience with big data technologies and data engineering practices.\nExcellent verbal and written communication skills, with the ability to convey complex technical concepts to non-technical stakeholders.",Industry Type: Industrial Automation,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Aiml', 'Ml', 'Python', 'Tensorflow', 'Pytorch', 'Architecture', 'Artificial Intelligence', '.Net', 'Machine Learning', 'Scikit-Learn']",2025-06-12 14:21:14
