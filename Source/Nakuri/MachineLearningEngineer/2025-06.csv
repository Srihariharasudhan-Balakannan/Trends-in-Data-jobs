job_title,company,experience,salary,locations,description,industry,department,employment_type,skills,scraped_at
Machine Learning Engineer,Draft N Craft Legal Outsourcing,2 - 3 years,10-15 Lacs P.A.,['New Delhi'],"Role Overview:\n\nAs an ML Engineer you will embark on a wonderful journey of developing and implementing various Machine Learning models that will ultimately act as an enabler in the companys growth.\nSince Draft Craft is a legal services-oriented company in which we serve clients from across the border, your work will be majorly aimed towards creating ML workflows that will serve the legal industry and help improve efficiency of the in-house teams. Draft n Craft offers you the perfect opportunity to grow and hone your ML/Data Engineering skills while contributing towards building a worthwhile product.\n\nKey Responsibilities:\nDeveloping data ingestion & data preprocessing pipelines for transforming data presented for legal requirements to extract key and actionable insights. \nData cleaning for supplying accurate, consistent & relevant content to ML models.\nExploring and experimenting with different ML models and architectures that can be used with data from the legal industry in a safe and compliant manner.\nDeveloping and deploying ML models that can function in production environments for the use-cases required by the company.\nAnalyzing key metrics for model performance and devising methods to improve efficiencies of the models.\nDocument the steps involved in data preprocessing, model development, and optimizations undertaken.\nExplore techniques for feature extraction, transformation, and selection to improve model performance.\nUnderstanding software development related terminologies to collaborate with the existing team of software engineers within the company.\nDevise methods of integration of the ML models within the company’s already developed software solutions and employee workflows.\n\nRequired Qualifications:\nDegree holder from Computer Science Engineering, Data Science or related fields.\nMinimum experience of 2 years working as an ML engineer or Data Scientist in a professional capacity.\nStrong programming skills including python and familiarity with related libraries Tensorflow, PyTorch, Pandas etc.\nDatabase Querying in terms of SQL/NoSQL.\nWorking with data extracting and ETL pipelines for pre-processing of data/documents.\nRelevant experience working in NLP, Neural Networks, and Gen AI technologies.\nFamiliarity with working or applying transfer-learning on LLM models like Llama, etc.\nSome experience in software development is preferred.\nKnowledge of deploying ML models and data pipelines to cloud services like AWS/Azure.",Industry Type: Legal,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'Retrieval Augmented Generation', 'Python', 'NoSQL', 'Large Language Model', 'Data Extraction', 'Machine Learning', 'SQL']",2025-06-12 06:29:20
Machine Learning Engineer,CADFEM India,1 - 4 years,4-9 Lacs P.A.,['Hyderabad'],"Job Description\nDesign and develop machine learning models tailored to mechanical engineering challenges, including predictive modelling, simulation optimisation, and failure analysis.\nUtilise deep learning and other advanced ML techniques to improve the accuracy and efficiency of CAE simulations.\nPreprocess and analyse large datasets from CAE simulations, experimental tests, and manufacturing processes for modelling.\nTrain, validate, and fine-tune machine learning models using real-world engineering data.\nOptimise models for performance, scalability, and robustness in production environments.\nCollaborate with CAE engineers to integrate ML models into existing simulation workflows (e.g., FEA, CFD, structural analysis).\nAutomate repetitive simulation tasks and enable predictive analytics for design optimisation.\nWork closely with mechanical engineers, data scientists, and software developers to identify business challenges and develop data-driven solutions.\nDeploy machine learning models into production environments and monitor their performance.\nMaintain and update models to ensure reliability and continuous improvement.\nStay abreast of the latest advancements in machine learning, AI, and CAE technologies.\nApply innovative approaches to solve complex engineering problems.\nRequirements\nBachelors or Master’s degree in Mechanical Engineering, Computer Science, or a related field\nProven 2-3 years of experience in developing and deploying machine learning models, preferably in mechanical engineering or CAE domain\nHands-on experience with CAE tools such as ANSYS, Abaqus, or similar FEA/CFD software\nStrong programming skills in Python, R, or Java\nProficiency in machine learning frameworks (TensorFlow, PyTorch, scikit-learn)\nExperience with data preprocessing, feature engineering, and statistical analysis\nSolid understanding of mathematics, statistics, and problem-solving skills\nExcellent analytical thinking and ability to tackle complex engineering challenges\nStrong communication and teamwork skills to collaborate across disciplines\nPreferred: Experience with physics-informed machine learning and digital twin technologies\nPreferred: Familiarity with automation of CAE workflows and predictive modelling for product design\n\nBenefits\nChallenging job and a chance to team up with a young and dynamic professional group\nChance to build yourself as WE grow.\nRemuneration that stays competitive and attractive to retain the best.\nOpportunity to join an organization experiencing year on year growth.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Scientist', 'ML/DL Engineer', 'Applied Machine Learning', 'AI Engineer', 'Machine Learning Engineer', 'F1-score', 'FastAPI', 'RMSE', 'Flask']",2025-06-12 06:29:23
Machine Learning Engineer,CompIndia,0 - 1 years,Not Disclosed,"['Tirupati', 'Chennai( Aminjikarai )']",Value-Added Skills:\nCompleted Courses in Python & ML\nCompleted Academic projects involving ML\nParticipated in Kaggle competitions and Hackathons\nBuilt ML projects with real-world datasets,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Python', 'Kaggle', 'Hackathon']",2025-06-12 06:29:26
Machine Learning Engineer,goML,3 - 8 years,Not Disclosed,[],"Looking for a culture to thrive & build a rewarding career for yourself, join the core team of young hustlers building the next generation of Machine Learning platform & services. You will develop training and deployment pipelines for machine learning, implement model compression algorithms, and productionize machine learning research solving challenging business problems.\n\nWe are Hiring Machine Learning Engineers at goML!\n\nKey Responsibilities:\nDesign and develop generative AI models using techniques like RAG, transformers, and other relevant approaches.\nFine-tune pre-trained LLMs for specific tasks and domains.\nConduct research on new techniques for improving the performance and capabilities of generative AI models.\nApply software engineering rigor and best practices to machine learning /Generative AI pipelines.\nEvaluate and analyse the performance of ML/generative AI models.\nStay up to date on the latest advancements in generative AI research.\nFacilitate the development and deployment of proof-of-concept Generative AI systems.\n\nQualifications:\nBachelors/Masters degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n3-8 years of experience in generative AI or related fields.\nExperience in building data pipelines, deploying ML/GenAI models in production, and monitoring and maintaining their performance.\nStrong programming skills in Python.\nFamiliarity with RAG and other techniques for building generative models.\nExtensive experience with Git, Docker and a good understanding of Linux for managing servers.\nExperience with cloud-based ecosystems, especially AWS ML/GenAI services.\nExposure to ML/GenAI frameworks and tools.\nExcellent communication and collaboration skills.\nAbility to work independently and in a team-oriented environment.\nMethodical and meticulous towards work and planning.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative AI', 'Machine Learning', 'AWS', 'Natural Language Processing', 'Computer Vision', 'Deep Learning']",2025-06-12 06:29:28
Machine Learning Engineer - Recommender Systems,Thomson Reuters,3 - 8 years,Not Disclosed,['Bengaluru'],"Senior Machine Learning Engineer - Recommender Systems\n\nJoin our team at Thomson Reuters and contribute to the global knowledge economy. Our innovative technology influences global markets and supports professionals worldwide in making pivotal decisions. Collaborate with some of the brightest minds on diverse projects to craft next-generation solutions that have a significant impact. As a leader in providing intelligent information, we value the unique perspectives that foster the advancement of our business and your professional journey.\n\nAre you excited about the opportunity to leverage your extensive technical expertise to guide a development team through the complexities of full life cycle implementation at a top-tier companyOur Commercial Engineering team is eager to welcome a skilled Senior Machine Learning Engineer to our established global engineering group. Were looking for someone enthusiastic, an independent thinker, who excels in a collaborative environment across various disciplines, and is at ease interacting with a diverse range of individuals and technological stacks. This is your chance to make a lasting impact by transforming customer interactions as we develop the next generation of an enterprise-wide experience.\n\nAbout the Role:\n\nAs a Machine Learning Engineer, you will:\n\nSpearhead the development and technical implementation of machine learning solutions, including configuration and integration, to fulfill business, product, and recommender system objectives.\n\nCreate machine learning solutions that are scalable, dependable, and secure.\n\nCraft and sustain technical outputs such as design documentation and representative models.\n\nContribute to the establishment of machine learning best practices, technical standards, model designs, and quality control, including code reviews.\n\nProvide expert oversight, guidance on implementation, and solutions for technical challenges.\n\nCollaborate with an array of stakeholders, cross-functional and product teams, business units, technical specialists, and architects to grasp the project scope, requirements, solutions, data, and services.\n\nPromote a team-focused culture that values information sharing and diverse viewpoints.\n\nCultivate an environment of continual enhancement, learning, innovation, and deployment.\n\n\nAbout You:\n\nYou are an excellent candidate for the role of Machine Learning Engineer if you possess:\n\n\nAt least 3 years of experience in addressing practical machine learning challenges, particularly with Recommender Systems, to enhance user efficiency, reliability, and consistency.\n\nA profound comprehension of data processing, machine learning infrastructure, and DevOps/MLOps practices.\n\nA minimum of 2 years of experience with cloud technologies (AWS SageMaker, AWS is preferred), including services, networking, and security principles.\n\nDirect experience in machine learning and orchestration, developing intricate multi-tenant machine learning products.\n\nProficient Python programming skills, SQL, and data modeling expertise, with DBT considered a plus.\n\nFamiliarity with Spark, Airflow, PyTorch, Scikit-learn, Pandas, Keras, and other relevant ML libraries.\n\nExperience in leading and supporting engineering teams.\n\nRobust background in crafting data science and machine learning solutions.\n\nA creative, resourceful, and effective problem-solving approach.\n\n\n#LI-HG1\n\nWhat’s in it For You\n\n\n\nHybrid Work Model We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.\n\n\nFlexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.\n\n\nCareer Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.\n\n\nIndustry Competitive Benefits We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.\n\n\nCulture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our valuesObsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.\n\n\nSocial Impact Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives.\n\n\nMaking a Real-World Impact:We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.\n\n\nAbout Us\n\nThomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.\n\nWe are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound excitingJoin us and help shape the industries that move society forward.\n\nAs a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.\n\nWe also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.\n\nLearn more on how to protect yourself from fraudulent job postings here.\n\nMore information about Thomson Reuters can be found on thomsonreuters.com.",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'cloud technologies', 'sql', 'data modeling', 'natural language processing', 'scikit-learn', 'airflow', 'data processing', 'aws sagemaker', 'pandas', 'deep learning', 'recommender systems', 'data science', 'spark', 'devops', 'pytorch', 'keras', 'code review', 'aws', 'win', 'ml']",2025-06-12 06:29:31
Machine Learning Engineer,Target,4 - 9 years,Not Disclosed,['Bengaluru'],"About us:\n\nWorking at Target means helping all families discover the joy of everyday life. We bring that vision to life through our values and culture. Learn more about Target here .\n\n\n\nWe are building Machine Learning Platform to enable MLOPs capabilities to help Data scientists and ML engineers at Target to implement ML solutions at scale. It encompasses building the Featurestore, Model ops, experimentation, iteration, monitoring, explainability, and continuous improvement of the machine learning lifecycle. You will be part of a team building scalable applications by leverage latest technologies. Connect with us if you want to join us in this exiting journey.\n\n\n\n\n\n\n\nAs a Engineer, you ll take the lead as you\n\nYou will build applications for Target s MLPlatform to enable capabilities to help data scientists, ML engineers and Data engineers at Target . You will be part of a team building highly scalable, event driven applications and leverage technologies. You understand Target's business and technical environments, resolve complex challenges via technical solutions as well as be a significant code contributor, manage software development cycle, drive best practices and ensure development of high-quality code with compliance & security standards. The Engineer is a practitioner of rapid prototyping and Agile, DevOps, CI/CD, test-driven development and stays current with new technology to be able to assess viability and applicability to Target's business and technical environments.\n\n\n\n\n\nTech stack Java, SpringBoot, Microservices, Python, Cassandra, Elastic Search, Postgres, Kafka, Docker, CICD, GCP cloud skills, GCP Machine Learning Engineer skills , GCP VertexAI skills\n\n\n\n\n\nAbout you:\n\n4 year degree or equivalent experience\n\n1.5+ years of software development experience\n\nExperience in building applications using JVM languages like Java, Kotlin\n\nExposure in building high-performance scalable APIs.\n\nGood to have experience in building Python applications, Fast API etc\n\nGood to have Machine Learning Engineer skills\n\nHaving GCP cloud skills, GCP Machine Learning Engineer skills , GCP VertexAI skills would be added advantage\n\nExperience in microservices, Spring Boot, cloud development, NoSQL databases, and event driven architecture\n\nExperience with NoSQL technologies Cassandra, Elastic search, MongoDB is a plus\n\nDeep experience writing unit and functional tests and test-driven development\n\nExperience building CI/CD pipelines\n\nStrong problem solving and debugging skills",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software development', 'software testing', 'functional testing', 'java', 'debugging', 'jvm', 'continuous integration', 'python', 'kotlin', 'ci/cd', 'machine learning', 'microservices', 'docker', 'nosql', 'spring boot', 'elastic search', 'postgresql', 'cassandra', 'gcp', 'devops', 'kafka', 'agile', 'api', 'mongodb']",2025-06-12 06:29:34
Machine Learning Engineer,Adobe,12 - 15 years,Not Disclosed,[],"The engineer will be part of a team working on the development, operations and support of Adobe s AI Platform team. They will be responsible for the design, architecture and development of new features and maintenance of existing features. They will also handle all phases of development, from early specs and definition to release. They are encouraged to be hands-on problem solver and we'll conversant in analyzing, architecting and implementing Golang/python-based world class high-quality software. Prior experience on ML solutions and cloud platform services, workflow orchestrators, data pipeline solutions would be a plus.\n\nWhat you'll Do\nThis is an individual contributor position.\nHands on product/solution development knowledge are a must.\nThe position involves conceptualization of a product, design, development, debugging/triaging, deployment at scale, monitoring, analyzing, etc\nPlanning, effort estimation and risk analysis of a project.\nThe incumbent will plan, evaluate industry alternatives, design and drive new components, solutions, workflow, features, etc\nShould take the initiative to drive frugality through optimizations without compromising stability or resiliency.\n  Requirements\nbachelors / masters degree in engineering.\n12+ years of relevant industry experience.\n3+ years of experience as a lead/architect.\nA proven expertise with building large scale platforms on Kubernetes.\nProven programming skills with languages such as python and go-lang.\nExperience of the latest ML development tools.\nTrack record of delivering cloud-scale, data-driven products, and services that are widely adopted with large customer bases\nExposure to container runtime environments\nExperience in building, deploying, and managing infrastructures in public clouds (specifically AWS)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Debugging', 'Machine learning', 'Cloud', 'Conceptualization', 'Programming', 'Product design', 'Adobe', 'Monitoring', 'Python']",2025-06-12 06:29:36
Machine Learning Engineer,Whats On India Media,3 - 8 years,Not Disclosed,"['Mumbai', 'Gurugram', 'Bengaluru']","Nielsen is seeking an organized, detail oriented, team player, to join the Engineering team in the role of Software Machine Learning Engineer. Nielsen's Audience Measurement Engineering platforms support the measurement of television viewing in more than 30 countries around the world. The Software Engineer will be responsible to define, develop, test, analyze, and deliver technology solutions within Nielsen's Collections platforms.\nRequired Skills\nBachelor's degree in Computer Science or equivalent degree.\n3+ years of software experience\nExperience with Machine learning frameworks and models. Pytorch experience preferred\nStrong understanding of statistical analysis and mathematical data manipulation\nWork with web technology including Java, Python, JavaScript, React/Redux, Kotlin.\nFollow best practices for software development and deployment\nUnderstanding of relational database, big data, and experience in SQL\nProficient at using GIT, GitFlow, JIRA, Gitlab and Confluence.\nStrong analytical and problem solving skills.\nOpen-minded and passionate to learn and grow technology skills\nStrong sense of accountability\nSolution-focused and ability to drive change within the organization\nExperience in writing unit/integration tests including test automation.\nStrong testing and debugging abilities, functional, analytical and technical abilities, ability to find bugs, attention to detail, troubleshooting\nAdditional Useful Skills\nA fundamental understanding of the AWS ecosystem (EC2, S3, EMR, Lambda, etc)\nExperienced in building RESTful APIs.\nExperience in writing unit/integration tests including test automation.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Ml Algorithms', 'Python', 'Pytorch']",2025-06-12 06:29:39
Staff Machine Learning Engineer,Zscaler Softech,4 - 8 years,Not Disclosed,['Bengaluru'],"About Zscaler\nServing thousands of enterprise customers around the world including 40% of Fortune 500 companies, Zscaler (NASDAQ: ZS) was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. As the operator of the world’s largest security cloud, Zscaler accelerates digital transformation so enterprises can be more agile, efficient, resilient, and secure. The pioneering, AI-powered Zscaler Zero Trust Exchange™ platform, which is found in our SASE and SSE offerings, protects thousands of enterprise customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.\nWhat We're Looking for (Minimum Qualifications)\nWhat Will Make You Stand Out (Preferred Qualifications)",,,,"['algorithms', 'kubernetes', 'orchestration', 'anomaly detection', 'networking', 'tools', 'sql', 'cloud', 'tensorflow', 'data science', 'end', 'software engineering', 'ml', 'architecture', 'python', 'software testing', 'airflow', 'time series', 'machine learning', 'r', 'ml algorithms', 'production processes', 'metrics', 'agile', 'statistics']",2025-06-12 06:29:41
Machine Learning Engineer,Panacorp Software Solutions,0 - 5 years,Not Disclosed,"['Nagercoil', 'Kanyakumari']","Research Programmer (Python/ MATLAB) Fresher & Experienced\nAbout Panacorp Software Solutions\nPanacorp Software Solutions is a research-driven organization specializing in providing technical assistance for PhD research projects. Our focus is on supporting research scholars with programming, simulations, and computational analysis in various domains, including AI, Machine Learning, and numerical computing.\n\nJob Role & Responsibilities\nAssist in research-based projects related to PhD studies.\nPerform simulations, numerical computing, and data analysis using Python, MATLAB, and Simulink.\nSupport research scholars in implementing Machine Learning (ML) and Deep Learning (DL) models.\nAutomate processes and optimize research workflows through scripting.\nDocument research methodologies, findings, and technical reports.\nWork closely with scholars to analyze and interpret computational results.\nEligibility Criteria\nQualification: BE/B.Tech/MCA\nExperience: 0 5+ years (Freshers with strong academic knowledge can apply).\nStrong understanding of research methodologies and computational tools.\nPreferred Skills\nProficiency in Python, MATLAB, and Simulink.\nKnowledge of data analysis, AI/ML techniques, and numerical simulations.\nAbility to interpret and validate research outcomes.\nStrong analytical and problem-solving skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Machine Learning', 'matlab', 'simulink', 'python', 'data analysis', 'research methodology', 'artificial intelligence']",2025-06-12 06:29:43
Staff Data Engineer - Machine Learning,Netradyne,5 - 8 years,22.5-35 Lacs P.A.,['Bengaluru'],"Role and Responsibilities:\n\nYou will be embedded within a team of machine learning engineers and data scientists; responsible for building and productizing generative AI and deep learning solutions. You will:\nDesign, develop and deploy production ready scalable solutions that utilizes GenAI, Traditional ML models, Data science and ETL pipelines\nCollaborate with cross-functional teams to integrate AI-driven solutions into business operations.\nBuild and enhance frameworks for automation, data processing, and model deployment.\nUtilize Gen-AI tools and workflows to improve the efficiency and effectiveness of AI solutions.\nConduct research and stay updated with the latest advancements in generative AI and related technologies.\nDeliver key product features within cloud analytics.\n\nRequirements:\n\nB. Tech, M. Tech or PhD in Computer Science, Data Science, Electrical Engineering, Statistics, Maths, Operations Research or related domain.\nStrong programming skills in Python, SQL and solid fundamentals in computer science, particularly in algorithms, data structures, and OOP.\nExperience with building end-to-end solutions on AWS cloud infra.\nGood understanding of internals and schema design for various data stores (RDBMS, Vector databases and NoSQL).\nExperience with Gen-AI tools and workflows, and large language models (LLMs).\nExperience with cloud platforms and deploying models at scale.\nStrong analytical and problem-solving skills with a keen attention to detail.\nStrong knowledge of statistics, probability, and estimation theory.\n\nDesired Skills:\n\nFamiliarity with frameworks such as PyTorch, TensorFlow and Hugging Face.\nExperience with data visualization tools like Tableau, Graphana, Plotly-Dash.\nExposure to AWS services like Kinesis, SQS, EKS, ASG, lambda etc.\nExpertise in at least one popular Python web-framework (like FastAPI, Django or Flask).\nExposure to quick prototyping using Streamlit, Gradio, Dash etc.\nExposure to Big Data processing (Snowflake, Redshift, HDFS, EMR)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'AWS', 'Generative Artificial Intelligence', 'Python', 'Big Data Technologies']",2025-06-12 06:29:46
Hiring Machine Learning Engineer,Motivity Labs,5 - 10 years,14-22.5 Lacs P.A.,['Hyderabad'],"Role - Machine Learning Engineer\nRequired Skills & Experience\n\n5+ years of hands-on experience in building, training, and deploying machine learning models in a professional, production-oriented setting.\nDemonstrable experience with database creation and advanced querying (e.g., SQL, NoSQL), with a strong understanding of data warehousing concepts.\nProven expertise in data blending, transformation, and feature engineering, adept at integrating and harmonizing both structured (e.g., relational databases, CSVs) and unstructured (e.g., text, logs, images) data.\nStrong practical experience with cloud platforms for machine learning development and deployment; significant experience with Google Cloud Platform (GCP) services (e.g., Vertex AI, BigQuery, Dataflow) is highly desirable.\nProficiency in programming languages commonly used in data science (e.g., Python is preferred, R).\nSolid understanding of various machine learning algorithms (e.g., regression, classification, clustering, dimensionality reduction) and experience with advanced techniques like Deep Learning, Natural Language Processing (NLP), or Computer Vision.\nExperience with machine learning libraries and frameworks (e.g., scikit-learn, TensorFlow, PyTorch).\nFamiliarity with MLOps tools and practices, including model versioning, monitoring, A/B testing, and continuous integration/continuous deployment (CI/CD) pipelines.\nExperience with containerization technologies like Docker and orchestration tools like Kubernetes for deploying ML models as REST APIs.\nProficiency with version control systems (e.g., Git, GitHub/GitLab) for collaborative development.\n\nInterested candidates share cv to dikshith.nalapatla@motivitylabs.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['GCP', 'Machine Learning', 'Deep Learning', 'Python', 'BigQuery', 'MLOps', 'Git', 'Vertex AI', 'GitHub/GitLab', 'A/B testing', 'Dataflow', 'Kubernetes']",2025-06-12 06:29:48
Machine Learning Engineer,Cadfem Engineering Services,2 - 3 years,Not Disclosed,['Hyderabad'],"Design and develop machine learning models tailored to mechanical engineering challenges, including predictive modelling, simulation optimisation, and failure analysis.\nUtilise deep learning and other advanced ML techniques to improve the accuracy and efficiency of CAE simulations.\nPreprocess and analyse large datasets from CAE simulations, experimental tests, and manufacturing processes for modelling.\nTrain, validate, and fine-tune machine learning models using real-world engineering data.\nOptimise models for performance, scalability, and robustness in production environments.\nCollaborate with CAE engineers to integrate ML models into existing simulation workflows (e.g., FEA, CFD, structural analysis).\nAutomate repetitive simulation tasks and enable predictive analytics for design optimisation.\nWork closely with mechanical engineers, data scientists, and software developers to identify business challenges and develop data-driven solutions.\nDeploy machine learning models into production environments and monitor their performance.\nMaintain and update models to ensure reliability and continuous improvement.\nStay abreast of the latest advancements in machine learning, AI, and CAE technologies.\nApply innovative approaches to solve complex engineering problems.\n\n\nRequirements\nBachelor\\u2019s or Master\\u2019s degree in Mechanical Engineering, Computer Science, or a related field\nProven 2-3 years of experience in developing and deploying machine learning models, preferably in mechanical engineering or CAE domain\nHands-on experience with CAE tools such as ANSYS, Abaqus, or similar FEA/CFD software\nStrong programming skills in Python, R, or Java\nProficiency in machine learning frameworks (TensorFlow, PyTorch, scikit-learn)\nExperience with data preprocessing, feature engineering, and statistical analysis\nSolid understanding of mathematics, statistics, and problem-solving skills\nExcellent analytical thinking and ability to tackle complex engineering challenges\nStrong communication and teamwork skills to collaborate across disciplines\nPreferred: Experience with physics-informed machine learning and digital twin technologies\nPreferred: Familiarity with automation of CAE workflows and predictive modelling for product design\n\n\nBenefits\nChallenging job and a chance to team up with a young and dynamic professional group\nChance to build yourself as WE grow.\nRemuneration that stays competitive and attractive to retain the best.\nOpportunity to join an organization experiencing year on year growth",Industry Type: Engineering & Construction,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['CFD', 'Abaqus', 'Automation', 'Simulation', 'Analytical', 'Failure analysis', 'Ansys', 'Product design', 'Structural analysis', 'Python']",2025-06-12 06:29:50
Machine Learning Engineer,Bay Area Tek Solutions LLC,2 - 5 years,Not Disclosed,['Bengaluru'],"Must have: Strong on programming languages like Python, Java One cloud hands-on experience (GCP preferred) Experience working with Dockers Environments managing (e.g venv, pip, poetry, etc.) Experience with orchestrators like Vertex AI pipelines, Airflow, etc Understanding of full ML Cycle end-to-end Data engineering, Feature Engineering techniques Experience with ML modelling and evaluation metrics Experience with Tensorflow, Pytorch or another framework Experience with Models monitoring Advance SQL knowledge Aware of Streaming concepts like Windowing , Late arrival , Triggers etc",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['GCP', 'Machine learning', 'Cloud', 'Programming', 'Management', 'Monitoring', 'SQL', 'Python']",2025-06-12 06:29:53
Cloud Machine Learning LLM Serving Engineer,Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nJD for Cloud Machine Learning LLM Serving engineer\n\nJob Overview:\n\nThe Qualcomm Cloud Computing team is developing hardware and software for Machine Learning solutions spanning the data center, edge, infrastructure, automotive market. We are seeking ambitious, bright, and innovative engineers with experience in machine learning framework development. Job activities span the whole product life cycle from early design to commercial deployment. The environment is fast-paced and requires cross-functional interaction daily so good communication, planning and execution skills are a must.\n\nKey Responsibilities\nImprove and optimize key Deep Learning models on Qualcomm AI 100.\nBuild deep learning framework extensions for Qualcomm AI 100 in upstream open-source repositories.\nImplement Kernels for AI workloads\nCollaborate and interact with internal teams to analyze and optimize training and inference for deep learning.\nBuild software tools and ecosystem around AI SW Stack.\nWork on vLLM, Triton, ExecuTorch, Inductor, TorchDynamo to build abstraction layers for inference accelerator.\nOptimize workloads for both scale-up (multi-SoC) and scale-out (multi-card) systems.\nOptimize the entire deep learning pipeline including graph compiler integration.\nApply knowledge of software engineering best practices.\n\n\nDesirable Skills and Aptitudes\nDeep Learning experience or knowledge- LLMs, Natural Language Processing, Vision, Audio, Recommendation systems.\nKnowledge of the structure and function of different components of Pytorch, TensorFlow software stacks.\nExcellent C/C++/Python programming and software design skills, including debugging, performance analysis, and test design.\nAbility to work independently, define requirements and scope, and lead your own development effort.\nWell versed with open-source development practices.\nStrong developer with a research mindset- strives to innovate.\nAvid problem solver- should be able to find solutions to key engineering and domain problems.\n\n\nKnowledge of tiling and scheduling a Machine learning operator is a plus.\nExperience in using C++ 14 (advanced features)\nExperience of profiling software and optimization techniques\nHands on experience writing SIMD and/or multi-threaded high-performance code is a plus.\nExperience of ML compiler, Auto-code generation (using MLIR) is a plus.\nExperiences to run workloads on large scale heterogeneous clusters is a plus.\nHands-on experience with CUDA, CUDNN is a plus.\n\n\nQualifications:\nBachelor's / Masters/ PHD degree in Engineering, Machine learning/ AI, Information Systems, Computer Science, or related field.\n2+ years Software Engineering or related work experience.\n2+ years experience with Programming Language such as C++, Python.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'c++', 'c', 'software design', 'software engineering', 'cuda', 'natural language processing', 'scale', 'machine learning', 'artificial intelligence', 'deep learning', 'tensorflow', 'code generation', 'computer science', 'pytorch', 'debugging', 'machine learning algorithms', 'ml']",2025-06-12 06:29:56
Machine Learning Engineer,Welldoc Software,4 - 8 years,Not Disclosed,['Bengaluru'],"We are seeking a skilled and experienced Machine Learning Engineer to join our team.The ideal candidate will have a strong background in Python and PyTorch, along with 4-8 years of experience deploying ML/AI models to production. This role requires excellent analytics skills and a good working knowledge of Databricks. You will work closely with data scientists, clinicians, software engineers, and product teams to design, build, and optimize scalable machine learning solutions.\n\nRole & responsibilities\nDevelop, train, and optimize machine learning models using PyTorch and other ML frameworks.\nDeploy and maintain ML models in production environments, ensuring scalability, performance, and reliability.\nUtilize Databricks for data processing, model training, model deployment, and pipeline optimization.\nDeploy Retrieval-Augmented Generation (RAG) pipelines to production for improved AI-driven applications.\nCollaborate with data engineers to design and implement ETL workflows and data pipelines.\nPerform rigorous testing, validation, and monitoring of deployed models.\nOptimize model inference for low latency and high throughput applications.\nWork with stakeholders to translate business problems into ML solutions.\nStay up to date with the latest advancements in machine learning, deep learning, and AI deployment strategies.\n\nPreferred candidate profile\nProficiency in Python and ML frameworks such as PyTorch.\n4-8 years of experience deploying machine learning models to production.\nKnowledge of MLflow for experiment tracking and model management.\nStrong experience with Databricks for ML development and deployment.\nHands-on experience with MLOps, CI/CD pipelines, and cloud-based deployment (AWS, Azure, or GCP).\nSolid understanding of data structures, algorithms, and software engineering principles.\nExperience working with large-scale datasets and distributed computing frameworks.\nExperience with deploying Retrieval-Augmented Generation (RAG) pipelines to production.\nExcellent analytical and problem-solving skills.\nStrong communication skills and ability to work in a collaborative team environment.\n\nPreferred Qualifications\nExperience deploying models in the healthcare domain.\nExperience with feature engineering, data preprocessing, and model explainability.\nKnowledge of containerization (Docker, Kubernetes) and workflow orchestration tools\nFamiliarity with LLMs, NLP, or reinforcement learning is a plus.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pytorch', 'RAG', 'Data Bricks', 'Python', 'MLops']",2025-06-12 06:29:58
Principal Machine Learning Engineer,Amgen Inc,2 - 7 years,Not Disclosed,['Hyderabad'],"What you will do\nWe are seeking a highly skilled Machine Learning Engineer with a strong MLOps background to join our team. You will play a pivotal role in building and scaling our machine learning models from development to production. Your expertise in both machine learning and operations will be essential in creating efficient and reliable ML pipelines.\nRoles & Responsibilities:\nCollaborate with data scientists to develop, train, and evaluate machine learning models.\nBuild and maintain MLOps pipelines, including data ingestion, feature engineering, model training, deployment, and monitoring.\nLeverage cloud platforms (AWS, GCP, Azure) for ML model development, training, and deployment.\nImplement DevOps/MLOps best practices to automate ML workflows and improve efficiency.\nDevelop and implement monitoring systems to track model performance and identify issues.\nConduct A/B testing and experimentation to optimize model performance.\nWork closely with data scientists, engineers, and product teams to deliver ML solutions.\nGuide and mentor junior engineers in the team\nStay updated with the latest trends and advancements\n\nBasic Qualifications:\nDoctorate degree and 2 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nMasters degree and 8 to 10 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nBachelors degree and 10 to 14 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nDiploma and 14 to 18 years of years of Computer Science, Statistics, and Data Science, Machine Learning experience\nPreferred Qualifications:\nMust-Have Skills:\nStrong foundation in machine learning algorithms and techniques\nExperience in MLOps practices and tools (e.g., MLflow, Kubeflow, Airflow); Experience in DevOps tools (e.g., Docker, Kubernetes, CI/CD)\nProficiency in Python and relevant ML libraries (e.g., TensorFlow, PyTorch, Scikit-learn)\nOutstanding analytical and problem-solving skills; Ability to learn quickly; Excellent communication and interpersonal skills\nGood-to-Have Skills:\nExperience with big data technologies (e.g., Spark), and performance tuning in query and data processing\nExperience with data engineering and pipeline development\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification\nKnowledge of NLP techniques for text analysis and sentiment analysis\nExperience in analyzing time-series data for forecasting and trend analysis\nFamiliar with AWS, Azure, or Google Cloud;\nFamiliar with Databricks platform for data analytics and MLOps\nProfessional Certifications\nCloud Computing and Databricks certificate preferred\nSoft Skills:\nExcellent analytical and fixing skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Azure', 'NLP', 'MLOps', 'Databricks', 'AWS', 'Google Cloud']",2025-06-12 06:30:01
Principal Machine Learning Engineer,Horizon Therapeutics,2 - 7 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description Join Amgen s Mission of Serving Patients\nAt Amgen, if you feel like you re part of something bigger, it s because you are. Our shared mission to serve patients living with serious illnesses drives all that we do.\nSince 1980, we ve helped pioneer the world of biotech in our fight against the world s toughest diseases. With our focus on four therapeutic areas -Oncology, Inflammation, General Medicine, and Rare Disease- we reach millions of patients each year. As a member of the Amgen team, you ll help make a lasting impact on the lives of patients as we research, manufacture, and deliver innovative medicines to help people live longer, fuller happier lives.\nOur award-winning culture is collaborative, innovative, and science based. If you have a passion for challenges and the opportunities that lay within them, you ll thrive as part of the Amgen team. Join us and transform the lives of patients while transforming your career.\nWhat you will do\nLet s do this. Let s change the world. We are seeking a highly skilled Machine Learning Engineer with a strong MLOps background to join our team. You will play a pivotal role in building and scaling our machine learning models from development to production. Your expertise in both machine learning and operations will be essential in creating efficient and reliable ML pipelines.\nRoles & Responsibilities:\nCollaborate with data scientists to develop, train, and evaluate machine learning models.\nBuild and maintain MLOps pipelines, including data ingestion, feature engineering, model training, deployment, and monitoring.\nLeverage cloud platforms (AWS, GCP, Azure) for ML model development, training, and deployment.\nImplement DevOps/MLOps best practices to automate ML workflows and improve efficiency.\nDevelop and implement monitoring systems to track model performance and identify issues.\nConduct A/B testing and experimentation to optimize model performance.\nWork closely with data scientists, engineers, and product teams to deliver ML solutions.\nGuide and mentor junior engineers in the team\nStay updated with the latest trends and advancements\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nBasic Qualifications:\nDoctorate degree and 2 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nMaster s degree and 8 to 10 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nBachelor s degree and 10 to 14 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nDiploma and 14 to 18 years of years of Computer Science, Statistics, and Data Science, Machine Learning experience\nPreferred Qualifications:\nMust-Have Skills:\nStrong foundation in machine learning algorithms and techniques\nExperience in MLOps practices and tools (e.g., MLflow, Kubeflow, Airflow); Experience in DevOps tools (e.g., Docker, Kubernetes, CI/CD)\nProficiency in Python and relevant ML libraries (e.g., TensorFlow, PyTorch, Scikit-learn)\nOutstanding analytical and problem-solving skills; Ability to learn quickly; Excellent communication and interpersonal skills\nGood-to-Have Skills:\nExperience with big data technologies (e.g., Spark), and performance tuning in query and data processing\nExperience with data engineering and pipeline development\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification\nKnowledge of NLP techniques for text analysis and sentiment analysis\nExperience in analyzing time-series data for forecasting and trend analysis\nFamiliar with AWS, Azure, or Google Cloud;\nFamiliar with Databricks platform for data analytics and MLOps\nProfessional Certifications\nCloud Computing and Databricks certificate preferred\nSoft Skills:\nExcellent analytical and fixing skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills.\nWhat you can expect of us\nAs we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, we ll support your journey every step of the way.\nIn addition to the base salary, Amgen offers competitive and comprehensive Total Rewards Plans that are aligned with local industry standards.\nApply now and make a lasting impact with the Amgen team. careers.amgen.com\nAs an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other and live the Amgen values to continue advancing science to serve patients. Together, we compete in the fight against serious disease.\nAmgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other basis protected by applicable law.\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n.",Industry Type: Biotechnology,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Cloud computing', 'Performance tuning', 'GCP', 'Analytical', 'Machine learning', 'Oncology', 'Forecasting', 'Monitoring', 'Python']",2025-06-12 06:30:03
Machine Learning Engineer,Catalyst Clinical Research,5 - 10 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","{""company"":""\nCatalyst Clinical Research provides customizable solutions to the biopharmaceutical and biotechnology industries through , a full-service oncology CRO, and multi-therapeutic global functional and CRO services through . The companys customer-centric flexible service model, innovative technology, expert team members, and global presence advance clinical studies. Visit .\n\nThe Machine Learning Engineer is a pivotal contributor responsible for designing and implementing cutting-edge machine learning solutions with a focus on generative AI technologies. You will drive the development and deployment of advanced models and pipelines that enable the creation of AI-driven applications and enhance organizational decision-making capabilities. Additionally, you will support data engineering initiatives to enable utilization of data across the organization. Collaborating closely with internal and external stakeholders, you will translate complex requirements into innovative solutions that advance Catalysts AI strategies while ensuring alignment with broader enterprise goals.\n"",""role"":""\nPosition Responsibilities/ Accountabilities:\n\nDesign, build, and optimize machine learning workflows, with a focus on generative AI models such as large language models (LLMs) and diffusion-based architectures.\nDevelop and deploy scalable machine learning pipelines using frameworks like TensorFlow, PyTorch, and Databricks MLflow.\nDevelop AI solutions using tools like Azure AI/Copilot Studio and Databricks AI Builder.\nLead the creation of domain-specific generative AI models, ensuring ethical AI practices and bias mitigation throughout the model lifecycle.\nDesign, build, and maintain scalable data pipelines with Delta Live Tables for model integration into enterprise applications.\nEnhance and expand CI/CD strategies for automated testing, model monitoring, and continuous delivery of ML artifacts.\nManage data preprocessing, feature engineering, and synthetic data generation for machine learning use cases.\nCollaborate with cross-functional teams to align AI-driven solutions with business goals and ensure high availability for end-to-end systems.\nProvide technical expertise in the exploration of novel generative AI methods, tools, and frameworks.\nSupport team members in understanding data science and AI best practices, encouraging a culture of innovation and continuous learning. Represent AI as a key member of the Data & Architecture Review Committee.\n\nPosition Qualification Requirements :\nEducation\n: B.S. or M.S. Computer Science, Engineering, Economics, Mathematics, related field, or relevant experience.\n\nExperience:\n5+ years of experience in machine learning engineering, including model development and deployment.\nHands-on experience with generative AI models (e.g., GPT, GANs, VAEs) and frameworks like PyTorch or TensorFlow.\n5+ years of experience with cloud computing technologies (Azure, AWS, GCP), especially AI and ML services.\nProficiency in developing data pipelines and integrating ML models into production environments.\nExpertise in model evaluation and monitoring, including techniques for explainability and fairness in AI.\nExperience collaborating with DevOps and MLOps teams to ensure scalability and reliability of AI solutions.\nFamiliarity with project management tools such as JIRA.\n\nRequired Skills:\nAdvanced proficiency in Python or PySpark for ML applications.\nDeep understanding of generative AI principles, model architecture, and training methodologies.\nExpertise in large-scale data processing and engineering using Spark, Kafka, and Databricks.\nProficiency with big data technologies and data structures like delta, parquet, YAML, JSON, and HTML.\nStrong knowledge of cloud-based AI platforms (e.g. Databricks, Azure ML, etc).\nSolid understanding of machine learning pipelines and MLOps practices.\nExceptional problem-solving and analytical skills.\nAbility to manage priorities and workflow effectively.\nProven ability to handle multiple projects and meet tight deadlines.\nStrong interpersonal skills with an ability to work collaboratively across teams.\nCommitment to excellence and high standards.\nCreative, flexible, and innovative team player.\nAbility to work independently and as part of various committees and teams.\nNice to Have: Data Engineering experience, including Webhooks, API, ELT/ETL, rETL, Data Lakehouse Architecture, and Event-Driven Architectures.\n\nFamiliarity with deep learning frameworks for generative AI (e.g., Hugging Face Transformers).\nKnowledge of synthetic data generation techniques and tools.\nExperience with data visualization tools (e.g., Tableau, Power BI) for AI model interpretability.\nFamiliarity with ethical AI principles, including explainability and bias reduction strategies.\nExperience with containerization and orchestration tools like Docker and Kubernetes.\nBackground or familiarity with clinical trials or pharmaceutical development.\n\nWorking Hours\nEveryday: 1:30 PM - 9:00 PM IST\nOR\nMonday, Wednesday, Friday: 2:30 PM - 10:30 PM IST\nTuesday, Thursday: 9:00 AM - 5:00 PM IST\nNote: Working hours may vary based on individual seniority, business demand, and ability to work independently. This will be evaluated on a case-by-case basis.\n""},""",Industry Type: Clinical Research / Contract Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'CRO', 'Project management', 'Pharma', 'Clinical trials', 'Clinical research', 'Data processing', 'Workflow', 'HTML', 'Monitoring']",2025-06-12 06:30:06
Data Engineer with Machine Learning Specialization,Ortseam Technologies,5 - 10 years,Not Disclosed,[],"Job Requirement for Offshore Data Engineer (with ML expertise)\nWork Mode: Remote\nBase Location: Bengaluru\nExperience: 5+ Years\n\nTechnical Skills & Expertise:\n\nPySpark & Apache Spark:\nExtensive experience with PySpark and Spark for big data processing and transformation.\nStrong understanding of Spark architecture, optimization techniques, and performance tuning.\nAbility to work with Spark jobs in distributed computing environments like Databricks.\nData Mining & Transformation:\nHands-on experience in designing and implementing data mining workflows.\nExpertise in data transformation processes, including ETL (Extract, Transform, Load) pipelines.\nExperience in large-scale data ingestion, aggregation, and cleaning.\nProgramming Languages:\nPython & Scala: Proficient in Python for data engineering tasks, including using libraries like Pandas and NumPy. Scala proficiency is preferred for Spark job development.\nBig Data Concepts: In-depth knowledge of big data frameworks and paradigms, such as distributed file systems, parallel computing, and data partitioning.\nBig Data Technologies:\nCassandra & Hadoop: Experience with NoSQL databases like Cassandra and distributed storage systems like Hadoop.\nData Warehousing Tools: Proficiency with Hive for data warehousing solutions and querying.\nETL Tools: Experience with Beam architecture and other ETL tools for large-scale data workflows.\nCloud Technologies (GCP):\nExpertise in Google Cloud Platform (GCP), including core services like Cloud Storage, BigQuery, and DataFlow.\nExperience with DataFlow jobs for batch and stream processing.\nFamiliarity with managing workflows using Airflow for task scheduling and orchestration in GCP.\nMachine Learning & AI:\nGenAI Experience: Familiarity with Generative AI and its applications in ML pipelines.\nML Model Development: Knowledge of basic ML model building using tools like Pandas, NumPy, and visualization with Matplotlib.\nML Ops Pipeline: Experience in managing end-to-end ML Ops pipelines for deploying models in production, particularly LLM (Large Language Models) deployments.\nRAG Architecture: Understanding and experience in building pipelines using Retrieval-Augmented Generation (RAG) architecture to enhance model performance and output.\n\nTech stack : Spark, Pyspark, Python, Scala, GCP data flow, Data composer (Air flow), ETL, Databricks, Hadoop, Hive, GenAI, ML Modeling basic knowledge, ML Ops experience , LLM deployment, RAG",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Engineering', 'Machine Learning', 'Gcp Cloud', 'Python', 'Airflow', 'Hadoop', 'Data Bricks', 'Hive', 'SCALA', 'Data Flow', 'Spark', 'ETL']",2025-06-12 06:30:08
Senior ML Compiler Engineer,Qualcomm,0 - 5 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nInterested in accelerating machine learning and artificial intelligence on mobile devices for millions of usersCome join our team. We are building software platforms that enable users of Qualcomms silicon to construct optimized neural networks and machine learning algorithms. We are looking for software engineers with a machine learning or compiler background who will help us build these software platforms. In this role, you will construct and tune machine learning frameworks, build compilers and tools, and collaborate with Qualcomm hardware and software engineers to enable efficient usage of Qualcomms silicon for machine learning applications.\n\nMinimum qualifications:\nBachelors degree in Engineering, Information Systems, Computer Science, or related field.\nProgramming in C/C++\n0 to 10 years of software engineering or related work experience\n\n\nPreferred qualifications:\nExperience in machine learning frameworks such as MxNet/NNVM/TVM, Pytorch, Tensorflow, Caffe\n\nOR experience in compilers with an interest in machine learning\nDeep knowledge of software engineering\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'software engineering', 'algorithms', 'c++', 'natural language processing', 'caffe', 'neural networks', 'mxnet', 'artificial intelligence', 'sql', 'deep learning', 'r', 'java', 'data science', 'computer vision', 'machine learning algorithms', 'ml']",2025-06-12 06:30:11
Data Scientist,Ltimindtree,7 - 12 years,Not Disclosed,['Hyderabad'],Data Scientist\n\nJob Description\n\nResponsibilities\n\nWork with team members across multiple disciplines to understand the data behind product features user behaviors the security landscape and our goals\nAnalyze data from several large sources then automate solutions using scheduled processes models and alerts\nWork with partners to design and improve metrics that guide our decisions for the product\nDetect patterns associated with fraudulent accounts and anomalous behavior\nSolve scientific problems and create new methods independently\nTranslate requirements and security questions into data insights\nSet up alerting mechanisms so our leadership is always aware of the security posture\n\nQualifications\n\nPostgraduate degree with specialization in machine learning artificial intelligence statistics or related fields or 2 years of equivalent work experience in applied machine learning and analytics\nExperience with SQL Snowflake and NoSQL databases\nProficiency in Python programming\nFamiliarity with statistics modeling and data visualization\n\nExperience\n\nExperience building statistical and machine learning models applying techniques such as regression classification clustering and anomaly detection Time series and Classical ML modeling\nFamiliarity with Snowflake SQL\nFamiliarity with cloud platforms such as AWS\nSome experience to software development or data engineering\nAnalyze business problems or research questions identify relevant data points and extract meaningful insights,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Snowflake Sql', 'AWS']",2025-06-12 06:30:13
Machine Learning Scientist,Glynac,2 - 7 years,6-12 Lacs P.A.,['Bengaluru'],Responsibilities:\n* Develop machine learning models using PyTorch.\n* Optimize model performance through data analysis and experimentation.\n* Collaborate with cross-functional teams on product development.\n\n\nWork from home,Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Pytorch', 'Artificial Intelligence', 'Natural Language Processing']",2025-06-12 06:30:16
Engineer,Qualcomm,10 - 15 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nJob Overview:\n\nThe Qualcomm Cloud Computing team is developing hardware and software for Machine Learning solutions spanning the data center, edge, infrastructure, automotive market. We are seeking ambitious, bright, and innovative engineers with experience in machine learning framework development. Job activities span the whole product life cycle from early design to commercial deployment. The environment is fast-paced and requires cross-functional interaction daily so good communication, planning and execution skills are a must.\n\nWe are seeking a highly skilled and motivated Language Model Engineer to join our team. The primary role of the engineer will be to train Large Language Models (LLMs) from scratch and fine-tune existing LLMs on various datasets using state-of-the-art techniques.\n\nResponsibilities:\n\n\n\nModel Training and Fine-tuning: Train LLMs from scratch using various datasets. Fine-tune pre-trained models on specific tasks or datasets to improve performance. Implement state-of-the-art LLM training techniques such as Reinforcement Learning from Human Feedback (RLHF), ZeRO (Zero Redundancy Optimizer), Speculative Sampling, and other speculative techniques.\n\n\nData Management: Handle large datasets effectively. Ensure data quality and integrity. Implement data cleaning and preprocessing techniques. Hands-on with EDA is a plus.\n\n\nModel Evaluation: Evaluate model performance using appropriate metrics. Understand the trade-offs between different evaluation metrics.\n\n\nLLM metrics: Sound understanding of various LLM metrics like MMLU, Rouge, BLEU, Perplexity etc.\n\nAWQ: Understanding of Quantization is a plus. Knowledge on QAT will be a plus.\n\n\nResearch and Development: Stay updated with the latest research in NLP and LLMs. Implement state-of-the-art techniques and contribute to research efforts.\n\n\nCollaboration: Work closely with other teams to understand requirements and implement solutions.\n\n\nRequired Skills and Experience:\n\n\nDeep Learning Frameworks: Hands-on experience with PyTorch at a granular level. Familiarity with tensor operations, automatic differentiation, and GPU acceleration in PyTorch.\n\n\nNLP and LLMs: Strong understanding of Natural Language Processing (NLP) and experience working with LLMs.\n\n\nProgramming: Proficiency in Python and experience with software development best practices.\n\n\nData Handling: Experience working with large datasets. Familiarity with data version control tools is a plus.\n\n\nEducation: A degree in Computer Science, Machine Learning, AI, or related field. Advanced degree is a plus.\n\n\nCommunication: Excellent written and verbal communication skills.\n\n\nWork experience : Open, 2- 10 years of relevant experience.\n\n\nPreferred\n\nSkills:\n\n\n\nOptimization: Knowledge of optimization techniques for training large models.\n\n\nNeural Architecture Search (NAS): Experience with NAS techniques for optimizing model architectures is a plus. Hands-on experience with CUDA, CUDNN is a plus.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['cuda', 'python', 'natural language processing', 'pytorch', 'machine learning algorithms', 'nas', 'eda', 'version control', 'sampling', 'machine learning', 'deep learning', 'data center', 'computer science', 'product life cycle', 'research and development', 'software engineering']",2025-06-12 06:30:18
Freelance Online Data Analyst - Hindi Speaker,TELUS Digital,0 - 5 years,Not Disclosed,[],Job description\nAre you a detail-oriented individual with a passion for research and a good understanding of national and local geography? This freelance opportunity allows you to work at your own pace and from the comfort of your own home.\n\n\nA Day in the Life of an Online Data Analyst:,,,,"['Artificial Intelligence', 'Data Analytics', 'Ai Solutions', 'Data Analysis', 'Information Technology']",2025-06-12 06:30:21
Data Engineer,AMERICAN EXPRESS,2 - 4 years,13-17 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Role & responsibilities\nUnderstanding business use cases and be able to convert to technical design\nPart of a cross-disciplinary team, working closely with other data engineers, software engineers, data scientists, data managers and business partners.\nYou will be designing scalable, testable and maintainable data pipelines\nIdentify areas for data governance improvements and help to resolve data quality problems through the appropriate choice of error detection and correction, process control and improvement, or process design changes",,,,"['Spark', 'SQL', 'Python', 'Hadoop', 'Big Data']",2025-06-12 06:30:24
"AI/ML Engineer (Specializing in NLP/ML, Large Data Processing,",Synechron,8 - 10 years,Not Disclosed,"['Pune', 'Hinjewadi']","job requisition idJR1027361\n\nJob Summary\nSynechron seeks a highly skilled AI/ML Engineer specializing in Natural Language Processing (NLP), Large Language Models (LLMs), Foundation Models (FMs), and Generative AI (GenAI). The successful candidate will design, develop, and deploy advanced AI solutions, contributing to innovative projects that transform monolithic systems into scalable microservices integrated with leading cloud platforms such as Azure, Amazon Bedrock, and Google Gemini. This role plays a critical part in advancing Synechrons capabilities in cutting-edge AI technologies, enabling impactful business insights and product innovations.\n\nSoftware\n\nRequired Proficiency:\nPython (core librariesTensorFlow, PyTorch, Hugging Face transformers, etc.)\nCloud platformsAzure, AWS, Google Cloud (familiarity with AI/ML services)\nContainerizationDocker, Kubernetes\nVersion controlGit\nData management toolsSQL, NoSQL databases (e.g., MongoDB)\nModel deployment and MLOps toolsMLflow, CI/CD pipelines, monitoring tools\nPreferred\n\nSkills:\nExperience with cloud-native AI frameworks and SDKs\nFamiliarity with AutoML tools\nAdditional programming languages (e.g., Java, Scala)\nOverall Responsibilities\nDesign, develop, and optimize NLP models, including advanced LLMs and Foundation Models, for diverse business use cases.\nLead the development of large data pipelines for training, fine-tuning, and deploying models on big data platforms.\nArchitect, implement, and maintain scalable AI solutions in line with MLOps best practices.\nTransition legacy monolithic AI systems into modular, microservices-based architectures for scalability and maintainability.\nBuild end-to-end AI applications from scratch, including data ingestion, model training, deployment, and integration.\nImplement retrieval-augmented generation techniques for enhanced context understanding and response accuracy.\nConduct thorough testing, validation, and debugging of AI/ML models and pipelines.\nCollaborate with cross-functional teams to embed AI capabilities into customer-facing and enterprise products.\nSupport ongoing maintenance, monitoring, and scaling of deployed AI systems.\nDocument system designs, workflows, and deployment procedures for compliance and knowledge sharing.\nPerformance Outcomes:\nProduction-ready AI solutions delivering high accuracy and efficiency.\nRobust data pipelines supporting training and inference at scale.\nSeamless integration of AI models with cloud infrastructure.\nEffective collaboration leading to innovative AI product deployment.\nTechnical Skills (By Category)\n\nProgramming Languages:\nEssential: Python (TensorFlow, PyTorch, Hugging Face, etc.)\nPreferred: Java, Scala\nDatabases/Data Management:\nSQL (PostgreSQL, MySQL), NoSQL (MongoDB, DynamoDB)\nCloud Technologies:\nAzure AI, AWS SageMaker, Bedrock, Google Cloud Vertex AI, Gemini\nFrameworks and Libraries:\nTransformers, Keras, scikit-learn, XGBoost, Hugging Face engines\nDevelopment Tools & Methodologies:\nDocker, Kubernetes, Git, CI/CD pipelines (Jenkins, Azure DevOps)\nSecurity & Compliance:\nKnowledge of data security standards and privacy policies (GDPR, HIPAA as applicable)\nExperience\n8 to 10 years of hands-on experience in AI/ML development, especially NLP and Generative AI.\nDemonstrated expertise in designing, fine-tuning, and deploying LLMs, FMs, and GenAI solutions.\nProven ability to develop end-to-end AI applications within cloud environments.\nExperience transforming monolithic architectures into scalable microservices.\nStrong background with big data processing pipelines.\nPrior experience working with cloud-native AI tools and frameworks.\nIndustry experience in finance, healthcare, or technology sectors is advantageous.\nAlternative Experience:\nCandidates with extensive research or academic experience in AI/ML, especially in NLP and large-scale data processing, are eligible if they have practical deployment experience.\n\nDay-to-Day Activities\nDevelop and optimize sophisticated NLP/GenAI models fulfilling business requirements.\nLead data pipeline construction for training and inference workflows.\nCollaborate with data engineers, architects, and product teams to ensure scalable deployment.\nConduct model testing, validation, and performance tuning.\nImplement and monitor model deployment pipelines, troubleshoot issues, and improve system robustness.\nDocument models, pipelines, and deployment procedures for audit and knowledge sharing.\nStay updated with emerging AI/ML trends, integrating best practices into projects.\nPresent findings, progress updates, and technical guidance to stakeholders.\nQualifications\nBachelors degree in Computer Science, Data Science, or related field; Masters or PhD preferred.\nCertifications in AI/ML, Cloud (e.g., AWS, Azure, Google Cloud), or Data Engineering are a plus.\nProven professional experience with advanced NLP and Generative AI solutions.\nCommitment to continuous learning to keep pace with rapidly evolving AI technologies.\nProfessional Competencies\nStrong analytical and problem-solving capabilities.\nExcellent communication skills, capable of translating complex technical concepts.\nCollaborative team player with experience working across global teams.\nAdaptability to rapidly changing project scopes and emerging AI trends.\nInnovation-driven mindset with a focus on delivering impactful solutions.\nTime management skills to prioritize and manage multiple projects effectively.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data management', 'data processing', 'pipeline', 'big data', 'continuous integration', 'kubernetes', 'deploying models', 'natural language processing', 'ci/cd', 'fms', 'artificial intelligence', 'docker', 'sql', 'microservices', 'tensorflow', 'java', 'pytorch', 'jenkins', 'keras', 'aws']",2025-06-12 06:30:27
Data Scientist For DMAI,Prodapt Solutions,2 - 5 years,Not Disclosed,['Chennai'],"Overview\n\nThe Senior Data Science Engineer will leverage advanced data science techniques to solve complex business problems, guide decision-making processes, and mentor junior team members. This role requires a combination of technical expertise in data analysis, machine learning, and project management skills.\n\nResponsibilities\n\n Data Analysis and Modeling Analyze large-scale telecom datasets to extract actionable insights and build predictive models for network optimization and customer retention.\n Conduct statistical analyses  to validate models and ensure their effectiveness.\n Machine Learning Development Design and implement machine learning algorithms for fraud detection, churn prediction, and network failure analysis.\n Telecom-Specific Analytics Apply domain knowledge to improve customer experience by analyzing usage patterns, optimizing services, and predicting customer lifetime value.\n ETL Processes Develop robust pipelines for extracting, transforming, and loading telecom data from diverse sources.\n Collaboration Work closely with data scientists, software engineers, and telecom experts to deploy solutions that enhance operational efficiency.\n Data Governance :  Ensure data integrity, privacy, security and compliance with industry standards\n\n\nAdvanced degree in Data Science, Statistics, Computer Science, or a related field.\nExtensive experience in data science roles with a strong focus on machine learning and statistical modeling.\nProficiency in programming languages such as Python or R and strong SQL skills.\nFamiliarity with big data technologies (e.g., Hadoop, Spark) is advantageous.\nExpertise in cloud platforms such as AWS or Azure.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'machine learning', 'sql', 'statistical modeling', 'algorithms', 'python', 'big data technologies', 'microsoft azure', 'cloud platforms', 'r', 'data science', 'spark', 'data governance', 'hadoop', 'aws', 'etl', 'machine learning algorithms', 'statistics']",2025-06-12 06:30:31
Data Scientist,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nThe Data Scientist is responsible for developing and implementing AI-driven solutions to enhance cybersecurity measures within the organization. This role involves leveraging data science techniques to analyze security data, detect threats, and automate security processes. The Data Scientist will work closely with cybersecurity teams to identify data-driven automation opportunities, strengthening the organizations security posture.\nRoles & Responsibilities:\nDevelop analytics to address security concerns, enhancements, and capabilities to improve the organization's security posture.\nCollaborate with Data Engineers to translate security-focused algorithms into effective solutions.\nWork in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\nPerform exploratory and targeted data analyses using descriptive statistics and other methods to identify security patterns and anomalies.\nDesign and implement security-focused analytics pipelines leveraging MLOps practices.\nCollaborate with data engineers on data quality assessment, data cleansing, and the development of security-related data pipelines.\nContribute to data engineering efforts to refine data infrastructure and ensure scalable, efficient security analytics.\nGenerate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\nFunctional Skills:\nBasic Qualifications:\nMasters degree and 1 to 3 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python) OR\nBachelors degree and 3 to 5 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python) OR\nDiploma and 7 to 9 years of experience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python)\nPreferred Qualifications:\nExperience with one or more analytic software tools or languages (e.g., SAS, SPSS, R, Python)\nDemonstrated skill in the use of applied analytics, descriptive statistics, feature extraction and predictive analytics on industrial datasets\nStrong foundation in machine learning algorithms and techniques\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification\nGood-to-Have Skills:\nProficiency in Python and relevant ML libraries (e.g., TensorFlow, PyTorch, Scikit-learn)\nOutstanding analytical and problem-solving skills; Ability to learn quickly; Excellent communication and interpersonal skills\nExperience with data engineering and pipeline development\nExperience in analyzing time-series data for forecasting and trend analysis\nExperience with AWS, Azure, or Google Cloud\nExperience with Databricks platform for data analytics and MLOps\nExperience with Generative AI models (e.g., GPT, DALLE, Stable Diffusion) and their applications in cybersecurity and data analysis\nExperience working in Product team's environment\nExperience working in an Agile environment\nProfessional Certifications:\nAny AWS Developer certification (preferred)\nAny Python and ML certification (preferred)\nAny SAFe Agile certification (preferred)\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'R', 'PyTorch', 'SAS', 'predictive analytics', 'Scikit-learn', 'SPSS', 'machine learning', 'data engineering', 'Python', 'TensorFlow']",2025-06-12 06:30:34
Data Scientist,Apcfss,2 - 6 years,Not Disclosed,"['Vijayawada', 'Guntur', 'Mangalagiri']","Location: Vijayawada, Andhra Pradesh\nExperience: 2 to 6 years\nEmployment Type: Full-Time\n\nJob Opening: Data Scientist\nWe are seeking a data-driven problem solver to join our team as a Data Scientist. You will play a key role in transforming data into actionable insights and building models that support strategic decisions across the organization. Collaborating with cross-functional teams, youll help turn complex data into clear value.\nKey Responsibilities\nAnalyze large and complex datasets to uncover trends, patterns, and insights\nBuild, validate, and deploy predictive and statistical models\nWork closely with engineering and product teams to integrate models into production systems\nCommunicate analytical findings and insights clearly to both technical and non-technical stakeholders\nRequirements\nProficiency in Python or R, and strong command of SQL\nHands-on experience with machine learning and statistical modeling\nStrong analytical and problem-solving skills\nExperience with cloud platforms such as AWS, GCP, or Azure\nNice to Have\nExperience in Natural Language Processing (NLP), deep learning, or time-series forecasting\nPrior work in [industry-specific domain, e.g., fintech, healthcare, e-commerce]",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'GCP', 'Machine Learning', 'AWS', 'Deep Learning', 'SQL']",2025-06-12 06:30:36
Data Scientist,Celebal Technologies,3 - 6 years,Not Disclosed,"['Navi Mumbai', 'Mumbai (All Areas)']","Job Title: Data Scientists\nLocation: Navi Mumbai\nDuration: Fulltime\nPositions: Multiple\n\nWe are looking for a highly skilled Data Scientists with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus.",,,,"['Demand Forecasting', 'Data Bricks', 'Time Series', 'Pyspark', 'Arima', 'Customer Lifecycle', 'Forecasting', 'Machine Learning', 'Optimization', 'Data Science', 'Xgboost', 'Time Series Analysis', 'Prophet', 'Python']",2025-06-12 06:30:38
Data Scientist,Celebal Technologies,3 - 6 years,Not Disclosed,"['Mumbai', 'Navi Mumbai']","About Us: Celebal Technologies is a leading Solution Service company that provide Services the field of Data Science, Big Data, Enterprise Cloud & Automation. We are at the forefront of leveraging cuttingedge technologies to drive innovation and enhance our business processes. As part of our commitment to staying ahead in the industry, we are seeking a talented and experienced Data & AI Engineer with strong Azure cloud competencies to join our dynamic team.\n\nJob Summary: We are looking for a highly skilled Data Scientist with deep expertise in time series forecasting, particularly in demand forecasting and customer lifecycle analytics (CLV). The ideal candidate will be proficient in Python or PySpark, have hands-on experience with tools like Prophet and ARIMA, and be comfortable working in Databricks environments. Familiarity with classic ML models and optimization techniques is a plus.\n\nKey Responsibilities\n• Develop, deploy, and maintain time series forecasting models (Prophet, ARIMA, etc.) for demand forecasting and customer behavior modeling.\n• Design and implement Customer Lifetime Value (CLV) models to drive customer retention and engagement strategies.\n• Process and analyze large datasets using PySpark or Python (Pandas).\n• Partner with cross-functional teams to identify business needs and translate them into data science solutions.\n• Leverage classic ML techniques (classification, regression) and boosting algorithms (e.g., XGBoost, LightGBM) to support broader analytics use cases.\n• Use Databricks for collaborative development, data pipelines, and model orchestration.\n• Apply optimization techniques where relevant to improve forecast accuracy and business decision-making.\n• Present actionable insights and communicate model results effectively to technical and non-technical stakeholders.\n\nRequired Qualifications\n• Strong experience in Time Series Forecasting, with hands-on knowledge of Prophet, ARIMA, or equivalent Mandatory.\n• Proven track record in Demand Forecasting Highly Preferred.\n• Experience in modeling Customer Lifecycle Value (CLV) or similar customer analytics use cases Highly Preferred.\n• Proficiency in Python (Pandas) or PySpark Mandatory.\n• Experience with Databricks Mandatory.\n• Solid foundation in statistics, predictive modeling, and machine learning",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning Operations', 'Demand Forecasting', 'Data Bricks', 'Pyspark', 'Large Language Model', 'Time Series', 'Spark', 'Machine Learning', 'Python']",2025-06-12 06:30:41
WLAN Phy RTL Design- Sr lead/Staff/Sr Staff/Principal Engineer,Qualcomm,1 - 3 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nQualcomm's Bangalore WLAN PHY (Baseband) team is seeking VLSI Digital Design Engineers to lead IP development for the latest WiFi standards.\n\nOur WLAN PHY team, comprised of highly passionate and seasoned domain experts, prides itself on years of experience in taking WLAN PHY designs from concept to silicon independently.\n\nWLAN PHY team is responsible for delivering the end-to-end Tx/Rx DSP chains- all the way from antenna samples post ADC to raw bits for upper layers and on the reverse path from raw bits to DAC. The team specializes in working with challenges of practical high-speed wireless communication systems and finding innovative solutions to counter them.\n\nThe team works extensively on typical signal processing functions like filters, matrix transformations (e.g.QR, Cholesky decomposition), channel estimation, equalization (MMSE, MRC, ML), decoders/encoders (e.g.LDPC, Viterbi) , demodulators, FFT etc. on a day-to-day basis, and contributes to the development/ enhancement/ evaluation of signal processing algorithms to cater to new requirements.\n\nWe are looking for someone as passionate as us and takes pride in their work.\n\nWiFi's ubiquity in modern times is undeniable, and the IEEE 802.11 Working Group is continually developing new standards to satisfy the growing demand for high throughput and low-latency real-time applications, such as VR and AR.\n\nQualcomm is at the forefront of the WiFi revolution, aiming to become the global leader in WiFi chip solutions. The WLAN PHY team in Bangalore is instrumental in realizing this vision.\n\n\n:\n\nLooking for a candidate with 1 to 3 years of hands-on experience in micro-architecting and developing complex IPs.\n\nExpertise in digital design, VLSI concepts, and experience in creating power/area-efficient IPs across multiple clock domains are essential.\n\nProficiency in RTL coding and familiarity with RTL QA flows such as PLDRC, CDC, and CLP (optional) is expected.\n\nCandidates should be capable of proposing design alternatives to meet area/power/performance specifications and presenting these options for review.\n\nExperience in leading, guiding, or managing junior team members is advantageous.\n\nRepeated success in taking IP designs from requirements to silicon is required.\n\nWhile not mandatory, having developed IPs for wireless technologies (WLAN, LTE, NR, BT, UWB, etc.) or past HLS experience would be beneficial.\n\n\n\n\nSkills:\n\n\n\nMust have: Proficient in Verilog RTL coding, uArch, CDC check, PLDRC, Timing constraints, Python/Perl. Experience in design/debugging complex data-path/control-path IPs. Good communication, analytical & leadership skills.\n\n\nGood to have: System Verilog, Visio, Knowledge of signal processing concepts/algorithms and Wi-Fi standards (802.11a/b/g/n/ac/ax), experience with HLS.\n\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['rtl coding', 'perl', 'python', 'cdc', 'verilog', 'antenna', 'enodeb', 'gsm', 'architecting', 'node b', 'digital design', 'wireless communication', 'rtl design', '5g', '3g', 'wcdma', 'debugging', 'telecom', 'system verilog', 'lte', 'ran', 'c', 'clp', 'rnc', 'hardware engineering', 'rtl', 'baseband', 'silicon', '4g', '2g', 'visio', 'vlsi']",2025-06-12 06:30:44
Senior Engineer - Data Science,Sasken Technologies,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Summary\nPerson at this position has gained significant work experience to be able to apply their knowledge effectively and deliver results. Person at this position is also able to demonstrate the ability to analyse and interpret complex problems and improve change or adapt existing methods to solve the problem.\nPerson at this position regularly interacts with interfacing groups / customer on technical issue clarification and resolves the issues. Also participates actively in important project/ work related activities and contributes towards identifying important issues and risks. Reaches out for guidance and advice to ensure high quality of deliverables.\nPerson at this position consistently seek opportunities to enhance their existing skills, acquire more complex skills and work towards enhancing their proficiency level in their field of specialisation.\nWorks under limited supervision of Team Lead/ Project Manager.\n\n\nRoles & Responsibilities\nResponsible for design, coding, testing, bug fixing, documentation and technical support in the assigned area. Responsible for on time delivery while adhering to quality and productivity goals. Responsible for adhering to guidelines and checklists for all deliverable reviews, sending status report to team lead and following relevant organizational processes. Responsible for customer collaboration and interactions and support to customer queries. Expected to enhance technical capabilities by attending trainings, self-study and periodic technical assessments. Expected to participate in technical initiatives related to project and organization and deliver training as per plan and quality.\n\n\nEducation and Experience Required\nEngineering graduate, MCA, etc Experience: 2-5 years\n\nCompetencies Description\nData Science TCB is applicable to one who\n1) Analyses data to arrive at patterns/Insights/models\n2) Come up with models based on the data to provide recommendations, predictive analytics etc\n3) Provides implementation of the models in R, Matlab etc\n4) Can understand and apply machine learning/AI techniques\nPlatforms-\nUnix\nTechnology Standard-\nNA\nTools-\nR, Matlab, Spark Machine Learning, Python-ML, SPSS, SAS\nLanguages-\nR, Perl, Python, Scala\nSpecialization-\nCOGNITIVE ANALYTICS INCLUDING COMPUTER VISION, AI and ML, STATISTICS.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'R', 'SAS', 'Scala', 'Perl', 'SPSS', 'Spark', 'machine learning', 'Python']",2025-06-12 06:30:46
Data Analyst-Having Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Analyst\n\nLocation: Bangalore\nExperience: 8 - 15 Yrs\nType: Full-time\n\nRole Overview\n\nWe are seeking a skilled Data Analyst to support our platform powering operational intelligence across airports and similar sectors. The ideal candidate will have experience working with time-series datasets and operational information to uncover trends, anomalies, and actionable insights. This role will work closely with data engineers, ML teams, and domain experts to turn raw data into meaningful intelligence for business and operations stakeholders.\n\nKey Responsibilities\n\nAnalyze time-series and sensor data from various sources\nDevelop and maintain dashboards, reports, and visualizations to communicate key metrics and trends.\nCorrelate data from multiple systems (vision, weather, flight schedules, etc) to provide holistic insights.\nCollaborate with AI/ML teams to support model validation and interpret AI-driven alerts (e.g., anomalies, intrusion detection).\nPrepare and clean datasets for analysis and modeling; ensure data quality and consistency.\nWork with stakeholders to understand reporting needs and deliver business-oriented outputs.\n\n\nQualifications & Required Skills\n\nBachelors or Masters degree in Data Science, Statistics, Computer Science, Engineering, or a related field.\n5+ years of experience in a data analyst role, ideally in a technical/industrial domain.\nStrong SQL skills and proficiency with BI/reporting tools (e.g., Power BI, Tableau, Grafana).\nHands-on experience analyzing structured and semi-structured data (JSON, CSV, time-series).\nProficiency in Python or R for data manipulation and exploratory analysis.\nUnderstanding of time-series databases or streaming data (e.g., InfluxDB, Kafka, Kinesis).\nSolid grasp of statistical analysis and anomaly detection methods.\nExperience working with data from industrial systems or large-scale physical infrastructure.\n\n\nGood-to-Have Skills\n\nDomain experience in airports, smart infrastructure, transportation, or logistics.\nFamiliarity with data platforms (Snowflake, BigQuery, Custom-built using open-source).\nExposure to tools like Airflow, Jupyter Notebooks and data quality frameworks.\nBasic understanding of AI/ML workflows and data preparation requirements.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Kafka', 'SQL', 'airports', 'InfluxDB', 'Airflow', 'structured Data', 'time-series', 'JSON', 'Tableau', 'Grafana', 'R', 'AI/ML', 'Kinesis', 'Snowflake', 'time-series databases', 'Data Preparation', 'Python', 'smart infrastructure', 'BigQuery', 'streaming data', 'Power BI', 'CSV', 'transportation', 'logistic', 'reporting tools']",2025-06-12 06:30:49
Senior Big Data Engineer,Qualcomm,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\n\nGeneral Summary\n\nPreferred Qualifications\n\n3+ years of experience as a Data Engineer or in a similar role\n\nExperience with\n\ndata modeling, data warehousing, and building ETL pipelines\n\nSolid working experience with\n\nPython, AWS analytical technologies and related resources (Glue, Athena, QuickSight, SageMaker, etc.,)\n\nExperience with\n\nBig Data tools, platforms and architecture with solid working experience with SQL\n\nExperience working in a very large data warehousing environment,\n\nDistributed System.\n\nSolid understanding on various data exchange formats and complexities\n\nIndustry experience in software development, data engineering, business intelligence, data science, or related field with a track record of manipulating, processing, and extracting value from large datasets\n\nStrong data visualization skills\n\nBasic understanding of Machine Learning; Prior experience in ML Engineering a plus\n\nAbility to manage on-premises data and make it inter-operate with AWS based pipelines\n\nAbility to interface with Wireless Systems/SW engineers and understand the Wireless ML domain; Prior experience in Wireless (5G) domain a plus\n\n\nEducation\n\nBachelor's degree in computer science, engineering, mathematics, or a related technical discipline\n\nPreferred QualificationsMasters in CS/ECE with a Data Science / ML Specialization\n\n\nMinimum Qualifications:\n\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\n\nOR\n\nMaster's degree in Engineering, Information Systems, Computer Science, or related field\n\nOR\n\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n3+ years of experience with Programming Language such as C, C++, Java, Python, etc.\n\n\nDevelops, creates, and modifies general computer applications software or specialized utility programs. Analyzes user needs and develops software solutions. Designs software or customizes software for client use with the aim of optimizing operational efficiency. May analyze and design databases within an application area, working individually or coordinating database development as part of a team. Modifies existing software to correct errors, allow it to adapt to new hardware, or to improve its performance. Analyzes user needs and software requirements to determine feasibility of design within time and cost constraints. Confers with systems analysts, engineers, programmers and others to design system and to obtain information on project limitations and capabilities, performance requirements and interfaces. Stores, retrieves, and manipulates data for analysis of system capabilities and requirements. Designs, develops, and modifies software systems, using scientific analysis and mathematical models to predict and measure outcome and consequences of design.\n\nPrincipal Duties and Responsibilities:\n\nCompletes assigned coding tasks to specifications on time without significant errors or bugs.\n\nAdapts to changes and setbacks in order to manage pressure and meet deadlines.\n\nCollaborates with others inside project team to accomplish project objectives.\n\nCommunicates with project lead to provide status and information about impending obstacles.\n\nQuickly resolves complex software issues and bugs.\n\nGathers, integrates, and interprets information specific to a module or sub-block of code from a variety of sources in order to troubleshoot issues and find solutions.\n\nSeeks others' opinions and shares own opinions with others about ways in which a problem can be addressed differently.\n\nParticipates in technical conversations with tech leads/managers.\n\nAnticipates and communicates issues with project team to maintain open communication.\n\nMakes decisions based on incomplete or changing specifications and obtains adequate resources needed to complete assigned tasks.\n\nPrioritizes project deadlines and deliverables with minimal supervision.\n\nResolves straightforward technical issues and escalates more complex technical issues to an appropriate party (e.g., project lead, colleagues).\n\nWrites readable code for large features or significant bug fixes to support collaboration with other engineers.\n\nDetermines which work tasks are most important for self and junior engineers, stays focused, and deals with setbacks in a timely manner.\n\nUnit tests own code to verify the stability and functionality of a feature.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'sql', 'software engineering', 'data visualization', 'aws', 'quicksight', 'c', 'software development', 'glue', 'aws sagemaker', 'data warehousing', 'machine learning', 'business intelligence', 'data engineering', 'java', 'data science', 'data modeling', 'athena', 'wireless', 'big data', 'etl', 'ml']",2025-06-12 06:30:51
"Senior Data Scientist (AI/ML, Data Analysis, Cloud (AWS), and Model",Synechron,8 - 13 years,Not Disclosed,['Pune'],"job requisition idJR1027352\n\nJob Summary\nSynechron is seeking an analytical and innovative Senior Data Scientist to support and advance our data-driven initiatives. The ideal candidate will have a solid understanding of data science principles, hands-on experience with AI/ML tools and techniques, and the ability to interpret complex data sets to deliver actionable insights. This role contributes to the organizations strategic decision-making and technology innovation by applying advanced analytics and machine learning models in a collaborative environment.\n\nSoftware\n\nRequired\n\nSkills:\nPython (including libraries such as pandas, scikit-learn, TensorFlow, PyTorch) proficiency in developing and deploying models\nR (optional, but preferred)\nData management tools (SQL, NoSQL databases)\nCloud platforms (preferably AWS or Azure) for data storage and ML deployment\nJupyter Notebooks or similar interactive development environments\nVersion control tools such as Git\nPreferred\n\nSkills:\nBig data technologies (Spark, Hadoop)\nModel deployment tools (MLflow, Docker, Kubernetes)\nData visualization tools (Tableau, Power BI)\nOverall Responsibilities\nAnalyze and interpret large and complex data sets to generate insights for business and technology initiatives.\nAssist in designing, developing, and implementing AI/ML models and algorithms to solve real-world problems.\nCollaborate with cross-functional teams including data engineers, software developers, and business analysts to integrate models into production systems.\nStay current with emerging trends, research, and best practices in AI/ML/Data Science and apply them to ongoing projects.\nDocument methodologies, modeling approaches, and insights clearly for technical and non-technical stakeholders.\nSupport model validation, testing, and performance monitoring to ensure accuracy and reliability.\nContribute to the development of data science workflows and standards within the organization.\nPerformance Outcomes:\nAccurate and reliable data models that support strategic decision-making.\nClear documentation and communication of findings and recommendations.\nEffective collaboration with technical teams to deploy scalable models.\nContinuous adoption of best practices in AI/ML and data management.\nTechnical Skills (By Category)\n\nProgramming Languages:\nEssential: Python (best practices in ML development), SQL\nPreferred: R, Java (for integration purposes)\nDatabases/Data Management:\nSQL databases, NoSQL (MongoDB, Cassandra)\nCloud data storage solutions (AWS S3, Azure Blob Storage)\nCloud Technologies:\nAWS (S3, EC2, SageMaker, Lambda)\nAzure Machine Learning (preferred)\nFrameworks & Libraries:\nTensorFlow, PyTorch, scikit-learn, Keras, XGBoost\nDevelopment Tools & Methodologies:\nJupyter Notebooks, Git, CI/CD pipelines\nAgile and Scrum processes\nSecurity Protocols:\nBest practices in data security and privacy, GDPR compliance\nExperience\n8+ years of professional experience in AI, ML, or Data Science roles.\nProven hands-on experience designing and deploying ML models in real-world scenarios.\nDemonstrated ability to analyze complex data sets and translate findings into business insights.\nPrevious experience working with cloud-based data science solutions is preferred.\nStrong portfolio showcasing data science projects, models developed, and practical impact.\nAlternative Pathways:\nCandidates with extensive research or academic experience in AI/ML can be considered, provided they demonstrate practical application of skills.\n\nDay-to-Day Activities\nConduct data exploration, cleaning, feature engineering, and model development.\nCollaborate with data engineers to prepare data pipelines for model training.\nBuild, validate, and refine machine learning models.\nPresent insights, models, and recommendations to technical and business stakeholders.\nSupport deployment of models into production environments.\nMonitor model performance and iterate to improve effectiveness.\nParticipate in team meetings, project planning, and reviewing progress.\nDocument methodologies and maintain version control of codebase.\nQualifications\nBachelors degree in Computer Science, Mathematics, Statistics, Data Science, or a related field; Masters or PhD highly desirable.\nEvidence of relevant coursework, certifications, or professional training in AI/ML.\nProfessional certifications (e.g., AWS Certified Machine Learning Specialty, Microsoft Certified Data Scientist) are a plus.\nCommitment to ongoing professional development in AI/ML methodologies.\nProfessional Competencies\nStrong analytical and critical thinking to solve complex problems.\nEffective communication skills for technical and non-technical audiences.\nDemonstrated ability to work collaboratively in diverse teams.\nAptitude for learning new tools, techniques, and technologies rapidly.\nInnovation mindset with a focus on applying emerging research.\nStrong organizational skills to manage multiple projects and priorities.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['java', 'data science', 'python', 'deploying models', 'aws', 'continuous integration', 'kubernetes', 'scikit-learn', 'ci/cd', 'artificial intelligence', 'sql', 'docker', 'tensorflow', 'spark', 'pytorch', 'keras', 'hadoop', 'big data', 'mongodb', 'microsoft azure', 'nosql', 'pandas', 'amazon ec2', 'r', 'cassandra', 'agile']",2025-06-12 06:30:54
Lead Data Engineer,Conduent,8 - 13 years,Not Disclosed,['Noida'],"Job Overview \n\nWe are looking for a Data Engineer who will be part of our Analytics Practice and will be expected to actively work in a multi-disciplinary fast paced environment. This role requires a broad range of skills and the ability to step into different roles depending on the size and scope of the project; its primary responsibility is the acquisition, transformation, loading and processing of data from a multitude of disparate data sources, including structured and unstructured data for advanced analytics and machine learning in a big data environment.\n\n\n Responsibilities: \nEngineer a modern data pipeline to collect, organize, and process data from disparate sources.\nPerforms data management tasks, such as conduct data profiling, assess data quality, and write SQL queries to extract and integrate data\nDevelop efficient data collection systems and sound strategies for getting quality data from different sources\nConsume and analyze data from the data pool to support inference, prediction and recommendation of actionable insights to support business growth.\nDesign and develop ETL processes using tools and scripting. Troubleshoot and debug ETL processes. Performance tuning and opitimization of the ETL processes.\nProvide support to new of existing applications while recommending best practices and leading projects to implement new functionality.\nCollaborate in design reviews and code reviews to ensure standards are met. Recommend new standards for visualizations.\nLearn and develop new ETL techniques as required to keep up with the contemporary technologies.\nReviews the solution requirements and architecture to ensure selection of appropriate technology, efficient use of resources and integration of multiple systems and technology.\nSupport presentations to Customers and Partners\nAdvising on new technology trends and possible adoption to maintain competitive advantage\n\n\n Experience Needed: \n8+ years of related experience is required.\nA BS or Masters degree in Computer Science or related technical discipline is required\nETL experience with data integration to support data marts, extracts and reporting\nExperience connecting to varied data sources\nExcellent SQL coding experience with performance optimization for data queries.\nUnderstands different data models like normalized, de-normalied, stars, and snowflake models. Worked with transactional, temporarl, time series, and structured and unstructured data.\nExperience on Azure Data Factory and Azure Synapse Analytics\nWorked in big data environments, cloud data stores, different RDBMS and OLAP solutions.\nExperience in cloud-based ETL development processes.\nExperience in deployment and maintenance of ETL Jobs.\nIs familiar with the principles and practices involved in development and maintenance of software solutions and architectures and in service delivery.\nHas strong technical background and remains evergreen with technology and industry developments.\nAt least 3 years of demonstrated success in software engineering, release engineering, and/or configuration management.\nHighly skilled in scripting languages like PowerShell.\nSubstantial experience in the implementation and exectuion fo CI/CD processes.\n\n\n Additional  \nDemonstrated ability to have successfully completed multiple, complex technical projects\nPrior experience with application delivery using an Onshore/Offshore model\nExperience with business processes across multiple Master data domains in a services based company\nDemonstrates a rational and organized approach to the tasks undertaken and an awareness of the need to achieve quality.\nDemonstrates high standards of professional behavior in dealings with clients, colleagues and staff.\nIs able to make sound and far reaching decisions alone on major issues and to take full responsibility for them on a technical basis.\nStrong written communication skills. Is effective and persuasive in both written and oral communication.\nExperience with gathering end user requirements and writing technical documentation\nTime management and multitasking skills to effectively meet deadlines under time-to-market pressure",Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sql coding', 'sql', 'configuration management', 'software engineering', 'release engineering', 'continuous integration', 'rdbms', 'sql queries', 'performance tuning', 'azure synapse', 'ci/cd', 'azure data factory', 'machine learning', 'data engineering', 'powershell', 'olap', 'etl', 'big data']",2025-06-12 06:30:57
Lead Engineer - Data Science,Sasken Technologies,5 - 8 years,Not Disclosed,['Bengaluru'],"Job Summary\nPerson at this position takes ownership of a module and associated quality and delivery. Person at this position provides instructions, guidance and advice to team members to ensure quality and on time delivery.\nPerson at this position is expected to be able to instruct and review the quality of work done by technical staff.\nPerson at this position should be able to identify key issues and challenges by themselves, prioritize the tasks and deliver results with minimal direction and supervision.\nPerson at this position has the ability to investigate the root cause of the problem and come up alternatives/ solutions based on sound technical foundation gained through in-depth knowledge of technology, standards, tools and processes.\nPerson has the ability to organize and draw connections among ideas and distinguish between those which are implementable.\nPerson demonstrates a degree of flexibility in resolving problems/ issues that atleast to in-depth command of all techniques, processes, tools and standards within the relevant field of specialisation.\n\n\nRoles & Responsibilities\nResponsible for requirement analysis and feasibility study including system level work estimation while considering risk identification and mitigation.\nResponsible for design, coding, testing, bug fixing, documentation and technical support in the assigned area. Responsible for on time delivery while adhering to quality and productivity goals.\nResponsible for traceability of the requirements from design to delivery Code optimization and coverage.\nResponsible for conducting reviews, identifying risks and ownership of quality of deliverables.\nResponsible for identifying training needs of the team.\nExpected to enhance technical capabilities by attending trainings, self-study and periodic technical assessments.\nExpected to participate in technical initiatives related to project and organization and deliver training as per plan and quality.\nExpected to be a technical mentor for junior members.\nPerson may be given additional responsibility of managing people based on discretion of Project Manager.\n\nEducation and Experience Required\nEngineering graduate, MCA, etc Experience: 5-8 years\n\n\nCompetencies Description\nData Science TCB is applicable to one who\n1) Analyses data to arrive at patterns/Insights/models\n2) Come up with models based on the data to provide recommendations, predictive analytics etc\n3) Provides implementation of the models in R, Matlab etc\n4) Can understand and apply machine learning/AI techniques\nPlatforms-\nUnix\nTools-\nR, Matlab, Spark Machine Learning, Python-ML, SPSS, SAS\nLanguages-\nR, Perl, Python, Scala\nSpecialization-\nCOGNITIVE ANALYTICS INCLUDING COMPUTER VISION, AI and ML, STATISTICS",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Unix', 'R', 'SAS', 'Scala', 'Perl', 'SPSS', 'Machine Learning', 'Python']",2025-06-12 06:30:59
Senior Data Engineer,Qualcomm,5 - 10 years,Not Disclosed,['Hyderabad'],"Job Area: Information Technology Group, Information Technology Group > IT Data Engineer\n\nGeneral Summary:\n\nDeveloper will play an integral role in the PTEIT Machine Learning Data Engineering team. Design, develop and support data pipelines in a hybrid cloud environment to enable advanced analytics. Design, develop and support CI/CD of data pipelines and services. - 5+ years of experience with Python or equivalent programming using OOPS, Data Structures and Algorithms - Develop new services in AWS using server-less and container-based services. - 3+ years of hands-on experience with AWS Suite of services (EC2, IAM, S3, CDK, Glue, Athena, Lambda, RedShift, Snowflake, RDS) - 3+ years of expertise in scheduling data flows using Apache Airflow - 3+ years of strong data modelling (Functional, Logical and Physical) and data architecture experience in Data Lake and/or Data Warehouse - 3+ years of experience with SQL databases - 3+ years of experience with CI/CD and DevOps using Jenkins - 3+ years of experience with Event driven architecture specially on Change Data Capture - 3+ years of Experience in Apache Spark, SQL, Redshift (or) Big Query (or) Snowflake, Databricks - Deep understanding building the efficient data pipelines with data observability, data quality, schema drift, alerting and monitoring. - Good understanding of the Data Catalogs, Data Governance, Compliance, Security, Data sharing - Experience in building the reusable services across the data processing systems. - Should have the ability to work and contribute beyond defined responsibilities - Excellent communication and inter-personal skills with deep problem-solving skills.\n\nMinimum Qualifications:\n3+ years of IT-related work experience with a Bachelor's degree in Computer Engineering, Computer Science, Information Systems or a related field.\nOR\n5+ years of IT-related work experience without a Bachelors degree.\n\n2+ years of any combination of academic or work experience with programming (e.g., Java, Python).\n1+ year of any combination of academic or work experience with SQL or NoSQL Databases.\n1+ year of any combination of academic or work experience with Data Structures and algorithms.\n5 years of Industry experience and minimum 3 years experience in Data Engineering development with highly reputed organizations- Proficiency in Python and AWS- Excellent problem-solving skills- Deep understanding of data structures and algorithms- Proven experience in building cloud native software preferably with AWS suit of services- Proven experience in design and develop data models using RDBMS (Oracle, MySQL, etc.)\n\nDesirable - Exposure or experience in other cloud platforms (Azure and GCP) - Experience working on internals of large-scale distributed systems and databases such as Hadoop, Spark - Working experience on Data Lakehouse platforms (One House, Databricks Lakehouse) - Working experience on Data Lakehouse File Formats (Delta Lake, Iceberg, Hudi)\n\nBachelor's or Master's degree in Computer Science, Software Engineering, or a related field.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['algorithms', 'python', 'data quality', 'data structures', 'aws', 'schema', 'continuous integration', 'glue', 'amazon redshift', 'event driven architecture', 'ci/cd', 'data engineering', 'sql', 'alerts', 'java', 'data modeling', 'spark', 'devops', 'data flow', 'nosql databases', 'sql database']",2025-06-12 06:31:02
"Data Analytics Fresher , Data Analyst Fresher",Ablycon Global Angalore,0 - 1 years,4.25-6.5 Lacs P.A.,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","NOTE- Please do not call. Apply through Naukri or email your resume at ankit@ablyconglobal.com. or whatsapp on 9821833955 - Don't CALL Please .\n\n\nJob Title: Data Analytics Fresher\nEmployment Type: Full-Time\nExperience: 0 - 1 Year\nQualification- ANY UG , ANY PG\n\n\nAbout the Role:\nWe are seeking a highly motivated and detail-oriented individual to join our Data Analytics team as a Data Analyst Fresher. This position offers a launchpad into the world of data analytics. Youll work on structured and unstructured datasets, assist in building dashboards and models, and get practical exposure to tools like SQL, Python, and BI platforms. Ideal for someone with a strong analytical foundation and a hunger to grow into a full-stack data professional.\n\nKey Responsibilities:\n\nCollect, organize, and analyze large datasets from various internal and external sources.\nAssist in preparing dashboards, reports, and visualizations to present insights and findings.\nSupport the team in identifying trends, anomalies, and patterns that impact business performance.\nWork with different departments (marketing, sales, operations, etc.) to understand data requirements.\nPerform exploratory data analysis (EDA) to help refine business strategies.\nMaintain and ensure data integrity and consistency across databases and reporting tools.\nSupport the automation of repetitive reporting processes using scripting or BI tools.\n\nRequired Skills & Qualifications:\n\nStrong analytical and problem-solving skills.\nProficiency in Excel and a basic understanding of SQL.\nFamiliarity with data visualization tools (e.g., Tableau, Power BI) is a plus.\nKnowledge of programming languages such as Python or R is an advantage.\nStrong communication skills to explain technical results to non-technical audiences.\nAttention to detail and a strong sense of responsibility.\nEagerness to learn new tools, technologies, and business domains.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Data Analytics', 'Business Analytics', 'Power Bi', 'Artificial Intelligence', 'Data Interpretation', 'Data Management', 'Data Extraction', 'Tableau', 'Machine Learning', 'Statistics', 'data analyst', 'SQL', 'Data Science', 'Excel', 'MySQL', 'Data Analysis', 'Data Visualization', 'Data Processing', 'Python']",2025-06-12 06:31:05
"Lead Engineer, Senior - Model Orchestration and Accuracy Tools",Qualcomm,5 - 10 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Systems Engineer, you will research, design, develop, simulate, and/or validate systems-level software, hardware, architecture, algorithms, and solutions that enables the development of cutting-edge technology. Qualcomm Systems Engineers collaborate across functional teams to meet and exceed system-level requirements and standards.\n\nThe AI SW team at Qualcomm is focused on advancing state-of-the-art in Artificial Intelligence across various business segments, including Mobile, AR & VR Technology, IoT, and Auto ADAS. The AISW stack leverages Qualcomm chips' extensive heterogeneous computing capabilities, enabling the running of trained neural networks on devices without needing a cloud connection. This allows neural network models trained in various frameworks on Snapdragon platforms to run at blazing speeds while consuming minimal power. As a Senior Lead Engineer, you will see your work directly impact billions of devices worldwide.\n\nKey Responsibilities:\n\nTo design, development, and implementation of AI/ML solutions across multiple domains.\n\nCollaborate with cross-functional teams to ensure seamless integration of AI/ML components within the broader framework\n\nAddress and resolve issues related to AI models finetuning, quantization, compression and graph level optimizations, ensuring high performance and accuracy of AI models.\n\nShould possess good analytical skills - Consistently gather, integrate, and interpret information from different sources and conduct in depth analysis to find the root causes, provide recommendations, and effectively solve moderate to highly complex problems.\n\nConduct research on industry trends and innovations in AI/ML to adopt best practices in solutions and deliverables.\n\nDevelop and optimize quantization techniques for AI/ML models, ensuring efficient execution on Qualcomm hardware\n\nManage project timelines, objectives, and goals, ensuring efficient use of resources across functional areas.\n\nMentor and coach junior engineers, providing development experiences and networking opportunities.\n\n\nMinimum Qualifications:\n\nBachelor's degree in Engineering, Computer science or a related field and 5+ years of experience of Software engineering or related work experience\n\nOR\n\nMasters degree in Engineering, Computer science or a related field and 4+ years of experience of Software engineering or related work experience:\n\nExperience with SW architecture and programming languages.\n\nExperience with tools and frameworks such as PyTorch, TensorFlow, ONNX, and others.\n\n\nPreferred Qualifications:\n\nExcellent development skills in Python / C++\n\nProficient in Data structures and algorithms\n\nHands on expertise in deep learning frameworks such as ONNX, PyTorch, etc\n\nIn depth knowledge of state-of-the-art Computer Vision, NLP, LLM, LVM and LMM.\n\nGood understanding of Quantization (8-bit, 4-bit) and Calibration algorithms\n\nGood understanding of machine learning compiler techniques and graphs optimizations\n\nExcellent analytical, development, and debugging skills\n\nGood understanding of SW design patterns and design philosophies (SOLID principles, design patterns)\n\nKnowledge of machine learning runtimes like ONNX Runtime and execuTorch.\n\nKnowledge of AI model efficiency toolkit (AIMET), Snapdragon Neural processing engine is a plus.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['algorithms', 'python', 'c++', 'natural language processing', 'data structures', 'deep learning frameworks', 'lvm', 'sw', 'machine learning', 'artificial intelligence', 'tool engineering', 'deep learning', 'tensorflow', 'pytorch', 'debugging', 'software engineering', 'onnx', 'system engineering']",2025-06-12 06:31:07
Senior Data Scientist,Epsilon,6 - 9 years,Not Disclosed,['Bengaluru'],"Responsibilities: -\nContribute and build an internal product library that is focused on solving business problems related to prediction & recommendation.\nResearch unfamiliar methodologies, techniques to fine tune existing models in the product suite and, recommend better solutions and/or technologies.\nImprove features of the product to include newer machine learning algorithms in the likes of product recommendation, real time predictions, fraud detection, offer personalization etc\nCollaborate with client teams to on-board data, build models and score predictions.\nParticipate in building automations and standalone applications around machine learning algorithms to enable a One Click solution to getting predictions and recommendations.\nAnalyze large datasets, perform data wrangling operations, apply statistical treatments to filter and fine tune input data, engineer new features and eventually aid the process of building machine learning models.\nRun test cases to tune existing models for performance, check criteria and define thresholds for success by scaling the input data to multifold.\nDemonstrate a basic understanding of different machine learning concepts such as Regression, Classification, Matrix Factorization, K-fold Validations and different algorithms such as Decision Trees, Random Forrest, K-means clustering.\nDemonstrate working knowledge and contribute to building models using deep learning techniques, ensuring robust, scalable and high-performance solutions\nMinimum Qualifications:\nEducation: Master's or PhD in a quantitative discipline (Statistics, Economics, Mathematics, Computer Science) is highly preferred.\nDeep Learning Mastery: Extensive experience with deep learning frameworks (TensorFlow, PyTorch, or Keras) and advanced deep learning projects across various domains, with a focus on multimodal data applications.\nGenerative AI Expertise: Proven experience with generative AI models and techniques, such as RAG, VAEs, Transformers, and applications at scale in content creation or data augmentation.\nProgramming and Big Data: Expert-level proficiency in Python and big data/cloud technologies (Databricks and Spark) with a minimum of 4-5 years of experience.\nRecommender Systems and Real-time Predictions: Expertise in developing sophisticated recommender systems, including the application of real-time prediction frameworks.\nMachine Learning Algorithms: In-depth experience with complex algorithms such as logistic regression, random forest, XGBoost, advanced neural networks, and ensemble methods.\nExperienced with machine learning algorithms such as logistic regression, random forest, XG boost, KNN, SVM, neural network, linear regression, lasso regression and k-means.\nDesirable Qualifications:\nGenerative AI Tools Knowledge: Proficiency with tools and platforms for generative AI (such as OpenAI, Hugging Face Transformers).\nDatabricks and Unity Catalog: Experience leveraging Databricks and Unity Catalog for robust data management, model deployment, and tracking.\nWorking experience in CI/CD tools such as GIT & BitBucket",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Engineering', 'Pyspark', 'Azure Aws', 'Generative AI', 'Big Data', 'AWS', 'Data Bricks', 'Deep Learning', 'Python', 'SQL']",2025-06-12 06:31:10
Data Scientist - Immediate Joiners Only,Reyika,5 - 10 years,Not Disclosed,"['Pune', 'Gurugram', 'Bengaluru']","Role: Data Scientist\nExperience: 5+ years\nLocation: Any - Hybrid (Bangalore, Hyderabad, Pune, Chennai and Gurgaon)\nJob Summary:\nWe're seeking a highly skilled NLP Engineer with expertise in Large Language Models (LLMs) and text summarization to join our team. The ideal candidate will have hands-on experience with Amazon Bedrock, OpenAI, or Hugging Face transformers and a strong background in Python programming. This role involves working with unstructured audio-to-text data, such as call transcripts, and developing innovative solutions using LLMs.\n\nRequirements:\nStrong expertise in NLP, text summarization, semantic search, and LLM APIs.\nPractical experience with Amazon Bedrock, OpenAI, or Hugging Face transformers.\nFamiliar with prompt tuning and few-shot learning.\nPython (pandas, langchain, boto3, NumPy, etc.)\nExperience working with unstructured audio-to-text data (e.g., call transcripts).\n\nKey Responsibilities:\nDesign and Development: Design, develop, and deploy LLM-based solutions for text summarization, semantic search, and other NLP tasks\nLLM APIs: Integrate LLM APIs from Amazon Bedrock, OpenAI, or Hugging Face transformers into existing applications\nPrompt Tuning and Few-Shot Learning: Implement prompt tuning and few-shot learning techniques to improve LLM performance\nUnstructured Audio-to-Text Data: Work with unstructured audio-to-text data, such as call transcripts, to develop accurate and efficient NLP models\nPython Programming: Utilize Python libraries like pandas, LangChain, boto3, and NumPy for data processing and model development.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Large Language Model', 'Natural Language Processing', 'Python']",2025-06-12 06:31:12
Principal Engineer,Wells Fargo,7 - 12 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Principal Engineer\n\nIn this role, you will:\nAct as an advisor to leadership to develop or influence applications, network, information security, database, operating systems, or web technologies for highly complex business and technical needs across multiple groups",,,,"['Underwriting', 'VSAM', 'JCL', 'Git', 'DB2', 'REXX', 'COBOL', 'SonarQube', 'debugging', 'IMS']",2025-06-12 06:31:15
Principal Engineer,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 8+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 7+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 6+ years of Software Engineering or related work experience.\n\n4+ years of work experience with Programming Language such as C, C++, Java, Python, etc.\n\nAdditional\n\nPreferred requirements:\n15+ or more overall years of relevant experience in software design, including debugging, performance analysis.\nWorking knowledge of operating systems and hypervisors like Linux, QNX and other RTOSs\nSystem SW development experience including kernels, device drivers and BSP.\nUnderstanding of OS internals, storage, peripherals, and interfaces e.g., UFS/EMMC, PCIe, SPI/UART/I2C, USB, Ethernet etc.\nUnderstanding of secure and safe automotive SW architecture design and development involving safety subsystems and monitors,\nSystem level boot, power, performance, and latency optimizations.\nExposure to automotive SW development processes and standards (e.g., ASPCE, ISO26262 and ISO21434).\n\n\nPrincipal Duties and Responsibilities:\nThe idle candidate might have demonstrated ability to work with engineers/partners/customers across different geographies and contribute to large-scale SoC SW product development and customer support.\nHands-on technical lead/engineer who is not hesitant to dig into the details where needed to get first-hand knowledge of the issues and play an active role in steering team success.\nWork with management team on roadmap and strategy planning\nWorking with Automotive T1/OEMs and commercialization of Automotive HW/SW platforms is a plus.\n\nLeverages advanced Software knowledge and experience to design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs.\nDesign, develop, code, test software modules\nGather customer requirements, distill requirements to software architecture, create software architecture documents.\nAnalyzes user needs, software requirements, and time and cost constraints to design and customize software for optimal operational efficiency.\nDesigns and implements software modules for large-scale products and systems.\nParticipates in and leads design, coding, unit testing, debugging, and integration efforts to ensure projects are completed to specifications and schedules.\nPerforms complex code reviews and regression tests as well as triages and fixes issues to ensure the quality of code.\nCollaborates with individuals outside the software function (e.g., Hardware, Systems, and Test engineers) to ensure solutions work with other components of a specific project.\nWrites detailed technical documentation for complex Software projects.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'software design', 'linux', 'debugging', 'software engineering', 'usb', 'soc', 'unit testing', 'device drivers', 'hw', 'test engineering', 'java', 'computer science', 'product development', 'voip', 'sip', 'python', 'c', 'sw', 'spi', 'ethernet', 'cucm', 'uart', 'qnx', 'technical documentation', 'h323', 't1', 'bsp']",2025-06-12 06:31:17
"Lead, Engineer",Qualcomm,10 - 15 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nJob Overview:\n\nThe Qualcomm Cloud Computing team is developing hardware and software for Machine Learning solutions spanning the data center, edge, infrastructure, automotive market. We are seeking ambitious, bright, and innovative engineers with experience in machine learning framework development. Job activities span the whole product life cycle from early design to commercial deployment. The environment is fast-paced and requires cross-functional interaction daily so good communication, planning and execution skills are a must.\n\nWe are seeking a highly skilled and motivated Language Model Engineer to join our team. The primary role of the engineer will be to train Large Language Models (LLMs) from scratch and fine-tune existing LLMs on various datasets using state-of-the-art techniques.\n\nResponsibilities:\n\nModel Training and Fine-tuning:\n\nTrain LLMs from scratch using various datasets. Fine-tune pre-trained models on specific tasks or datasets to improve performance. Implement state-of-the-art LLM training techniques such as Reinforcement Learning from Human Feedback (RLHF), ZeRO (Zero Redundancy Optimizer), Speculative Sampling, and other speculative techniques.\n\n\nData Management: Handle large datasets effectively. Ensure data quality and integrity. Implement data cleaning and preprocessing techniques. Hands-on with EDA is a plus.\n\n\nModel Evaluation: Evaluate model performance using appropriate metrics. Understand the trade-offs between different evaluation metrics.\n\n\nLLM metrics: Sound understanding of various LLM metrics like MMLU, Rouge, BLEU, Perplexity etc.\n\n\nAWQ: Understanding of Quantization is a plus. Knowledge on QAT will be a plus.\n\n\nResearch and Development: Stay updated with the latest research in NLP and LLMs. Implement state-of-the-art techniques and contribute to research efforts.\n\n\nCollaboration: Work closely with other teams to understand requirements and implement solutions.\n\n\nRequired Skills and Experience:\n\n\n\nDeep Learning Frameworks: Hands-on experience with PyTorch at a granular level. Familiarity with tensor operations, automatic differentiation, and GPU acceleration in PyTorch.\n\n\nNLP and LLMs: Strong understanding of Natural Language Processing (NLP) and experience working with LLMs.\n\n\nProgramming: Proficiency in Python and experience with software development best practices.\n\n\nData Handling: Experience working with large datasets. Familiarity with data version control tools is a plus.\n\n\nEducation: A degree in Computer Science, Machine Learning, AI, or related field. Advanced degree is a plus.\n\n\nCommunication: Excellent written and verbal communication skills.\n\n\nWork experience : Open, 2- 10 years of relevant experience.\n\n\n\n\nPreferred\n\nSkills:\n\n\n\n\nOptimization: Knowledge of optimization techniques for training large models.\n\n\nNeural Architecture Search (NAS): Experience with NAS techniques for optimizing model architectures is a plus. Hands-on experience with CUDA, CUDNN is a plus.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'c++', 'natural language processing', 'pytorch', 'software engineering', 'cuda', 'nas', 'eda', 'version control', 'sampling', 'machine learning', 'deep learning', 'java', 'data center', 'computer science', 'product life cycle', 'research and development', 'machine learning algorithms']",2025-06-12 06:31:20
Senior Data Scientist - AI/ML,Inumellas Consultancy Services,9 - 14 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Role - Senior Data Scientist / Senior Gen AI Engineer\nExp Range - 8 to 18 yrs\nPosition - Permanent Fulltime\nCompany - Data Analytics & AIML MNC\nLocation - Hyderabad, Pune, Bangalore (Relocation accepted)\nAbout the Role:\n\nWe are seeking a Software Engineer with expertise in Generative AI and Microsoft technologies to design, develop, and deploy AI-powered solutions using the Microsoft ecosystem. You will work with cross-functional teams to build scalable applications leveraging generative AI models and Azure services.\n\nSkills Required:\n\nExperience with Large Language Models (LLMs) like GPT, LLaMA, Claude, etc.\nProficiency in Python for building and fine-tuning AI/ML models\nFamiliarity with LangChain, LLMOps, or RAG (Retrieval-Augmented Generation) pipelines\nExperience with Vector Databases (e.g. FAISS, Pinecone, Weaviate)\nKnowledge of Prompt Engineering and model evaluation techniques\nExposure to cloud platforms (Azure, AWS or GCP) for deploying GenAI solutions\n\nPreferred Skills:\n\nExperience with Azure OpenAI, Databricks or Microsoft Fabric\nHands-on with Hugging Face Transformers, OpenAI APIs or custom model training",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Deep Learning', 'Prompt Engineering', 'Large Language Model', 'Vector Database', 'Retrieval Augmented Generation', 'GenAI', 'Langchain', 'Artificial Intelligence', 'LLMOps', 'LLaMa', 'GPT', 'Azure OpenAI', 'Machine Learning', 'ML Models', 'Model Evaluation', 'Huggingface', 'Aiml', 'OpenAI', 'Azure Machine Learning', 'Python']",2025-06-12 06:31:22
Lead AI/ML Engineer,Synechron,8 - 12 years,Not Disclosed,['Bengaluru'],"job requisition idJR1027508\n\nOverall Responsibilities:\nExperience with Machine Learning, Deep Learning, Computer Vision, NLP, Generative AI.\nKnowledge of algorithms, object-oriented and functional design principles, and best-practice patterns\nSolid understanding of common programming languages used in AI, such as Python, Java, C++, and R\nAdvanced knowledge of statistical and algorithmic models as well as of fundamental mathematical concepts, such as linear algebra and probability\nExperience working with large data sets and writing efficient code capable of processing large data streams at speed.\n\n\nSkills:\nMachine Learning, Deep Learning, Computer Vision, NLP\nStrong hands-on experience in AI/ML/Data Science, including machine learning algorithms, deep learning, NLP, computer vision, etc.\nKnowledge of programming languages such as Python, R, SQL, etc.\nExperience with AI/ML/Data Science tools and frameworks such as TensorFlow, PyTorch, etc.\nExcellent problem-solving skills and ability to find creative solutions to complex data science problems.\nStrong communication and interpersonal skills to effectively collaborate with cross-functional teams and clients\nExperience:\nMinimum 8-12 years of experience in AI/ML/Data Science, with at least 8+ years in a leadership role\nProven track record of successfully delivering AI/ML/Data Science projects\nExperience in mentoring and leading a team of AI/ML/Data Science professionals\nDay-to-Day Activities:\nLead AI/ML/Data Science projects, ensuring successful delivery\nMentor and guide junior team members\nCollaborate with cross-functional teams to provide subject matter expertise in AI/ML/Data Science\nStay updated with latest AI/ML/Data Science trends and technologies\nIdentify and evaluate new business opportunities in AI/ML/Data Science\nQualification:\nBachelor's or Master's degree in Computer Science, Data Science, AI, or related field\nSoft\n\nSkills:\nExcellent leadership and team management skills\nStrong interpersonal and communication skills\nAbility to work in a fast-paced and dynamic environment\nGood negotiation and stakeholder management skills\nPassionate about AI/ML/Data Science and staying updated with latest trends and technologies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['team management', 'aiml', 'artificial intelligence', 'data science', 'ml', 'algorithms', 'python', 'c++', 'data analytics', 'natural language processing', 'machine learning', 'sql', 'deep learning', 'tensorflow', 'r', 'java', 'computer vision', 'pytorch', 'machine learning algorithms', 'statistics']",2025-06-12 06:31:24
Security and Access control-Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Systems Engineer, you will research, design, develop, simulate, and/or validate systems-level software, hardware, architecture, algorithms, and solutions that enables the development of cutting-edge technology. Qualcomm Systems Engineers collaborate across functional teams to meet and exceed system-level requirements and standards.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.\n\nJob Overview\n\nWork with Qualcomm's security architecture / IP and access control team on next generation SOC for smartphone, tablet, automotive and IOT product categories. is responsible for assisting product development teams throughout the company to apply secure HW design principles to individual blocks, computing cores, and at the SoC level. SW/HW co-design, HW development experience. Familiarity with debug architectures such as JTAG and ARM coresight are a plus\n\nSuccessful candidates will be able to engage with product teams independently with minimal supervision to detect and mitigate security vulnerabilities in hardware architecture and implementations, involve in access control issues at both SW and HW.\n\nMinimum Qualifications\n\n5 to 7+ years of industry or academic experience in Security are required.\n\nAdditionally,",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['vhdl', 'hypervisor', 'system verilog', 'system engineering', 'verilog', 'jtag', 'arm architecture', 'c++', 'storage domain', 'soc', 'artificial intelligence', 'power analysis', 'fpga', 'access control', 'i2c', 'ml', 'asic', 'python', 'side', 'c', 'systemc', 'cryptography', 'aiml', 'spi', 'asic design', 'embedded c', 'uart']",2025-06-12 06:31:27
V&V Vehicle System Test Lead Engineer (Staff - AD/ADAS),Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Test Engineering\n\nGeneral Summary:\n\nAt Qualcomm, we are transforming the automotive industry with our Snapdragon Digital Chassis and building the next generation software defined vehicle (SDV).\n\nSnapdragon Ride is an integral pillar of our Snapdragon Digital Chassis, and since its launch it has gained momentum with a growing number of global automakers and Tier1 suppliers. Snapdragon Ride aims to address the complexity of autonomous driving and ADAS by leveraging its high-performance, power-efficient SoC, industry-leading artificial intelligence (AI) technologies and pioneering vision and drive policy stack to deliver a comprehensive, cost and energy efficient systems solution.\n\nThe Software Test and Quality infrastructure team is centrally defining, establishing, and rolling out the software test frameworks and software quality infrastructure used by multiple projects within Automated Driving.\n\nWe are looking for smart, innovative, and motivated individuals with strong vehicle testing background and experience to test the ADAS SW platform. The chosen candidate will get an opportunity to lead ADAS vehicle validation team working for a leading Indian car manufacturer.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Test Engineering or related work experience.\n\n2+ years of work or academic experience with Software Test or System Test, developing and automating test plans and/or tools (e.g., Source Code Control Systems, Continuous Integration Tools, and Bug Tracking Tools).\nPrepare test strategy based on customer requirement/Tier1 Catalogue. Review on and Test Cases.\n\nPlan and execute multiple level testing smoke test, L0/L1 testing, software in loop testing and vehicle testing for AD entry +/ Mid\n\nDesigns test plans, test cases, test scenarios, scripts, or procedures with the target to ensure the best coverage of the requirements for features.\n\nResponsible for preparing consolidated test report with test coverage, Known issues, functional/nonfunctional test results, observations, and bugs\n\nReprocess and analyze the events regression testing in application dataset from OEM project.\n\nSupport team to test in vehicle the System integration OEM specific hardware, error guessing, configurability testing, issue reproducibility, exploratory and feature combining tests for ADAS SW platform for features like:\n\no Adaptive Cruise Control\n\no Autonomous Emergency Braking\n\no Collision avoidance features (Lane Support System, Traffic Assist, Risk Mitigation Support)\n\no Road Sign Information\n\nDocuments systems-level defects, using a bug tracking system, and report defects to developers.\n\nIdentifies, analyzes, troubleshoots, and documents problems with program function, output, or content. Develops testing programs that assess effectiveness of a new system or modification of an existing system.\n\nAssure that the project is developed according to Qualcomm quality standards.\n\nPreferred Qualifications:\n\nBachelor's degree in Computer Science, Informatics or equivalent.\n\nMinimum of 7+ years of relevant work experience.\n\nKnowledge of CAN/Ethernet communication protocol experience with the associated tools form Vector (i.e. CANoe, CANalyzer, CANdela) and Star Corporation tools (i.e. Fl3X)\n\nExperience with flashing ADAS systems\n\nFamiliarity with C, CAPL programming languages\n\nExcellent analytical skills\n\nDriver Certification\n\nNice to have:\n\nAdvanced pilot passenger vehicle tests driver certification\n\nExperience in designing test cases and test automation solutions.\n\nGIT knowledge\n\nBasic C++ Programming\n\nPython scripting\n\nContinuous Integration knowledge\n\nISTQB certification\n\nAgile mindset and experience with SCRUM",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['canoe', 'test engineering', 'system testing', 'canalyzer', 'automating', 'c++', 'redhat openshift', 'hiring', 'candela', 'staffing', 'git', 'data warehouse testing', 'microsoft visual studio', 'can bus', 'python', 'c', 'software testing', 'svn', 'siebel', 'seibel', 'ethernet', 'capl', 'visio', 'siebel crm', 'sdlc', 'mqc']",2025-06-12 06:31:30
Principal Engineer - GCP,Wells Fargo,7 - 12 years,Not Disclosed,['Bengaluru'],"In this role, you will:\nAct as an advisor to leadership to develop or influence applications, network, information security, database, operating systems, or web technologies for highly complex business and technical needs across multiple groups\nLead the strategy and resolution of highly complex and unique challenges requiring in-depth evaluation across multiple areas or the enterprise, delivering solutions that are long-term, large-scale and require vision, creativity, innovation, advanced analytical and inductive thinking",,,,"['GCP', 'architecture roadmap', 'architects engineering', 'ETL Tools', 'enterprise principles', 'Google Cloud Platform', 'Informatica', 'Abinitio']",2025-06-12 06:31:32
Principal Engineer - .Net Full Stack,Wells Fargo,7 - 9 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Principal Engineer\n\nIn this role, you will:\nAct as an advisor to leadership to develop or influence applications, network, information security, database, operating systems, or web technologies for highly complex business and technical needs across multiple groups",,,,"['.Net', 'Java', 'Gen AI', 'DevOps', 'CI/CD', 'micro services architecture', 'Full Stack', 'ETL', 'SDLC', 'Python']",2025-06-12 06:31:34
Automotive Software Lead Engineer Sr. - C/C++,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nAt Qualcomm, we are transforming the automotive industry with our Snapdragon Digital Chassis and building the next generation software defined vehicle (SDV).\n\nSnapdragon Ride is an integral pillar of our Snapdragon Digital Chassis, and since its launch it has gained momentum with a growing number of global automakers and Tier1 suppliers. Snapdragon Ride aims to address the complexity of autonomous driving and ADAS by leveraging its high-performance, power-efficient SoC, industry-leading artificial intelligence (AI) technologies and pioneering vision and drive policy stack to deliver a comprehensive, cost and energy efficient systems solution.\n\nEnabling safe, comfortable, and affordable autonomous driving includes solving some of the most demanding and challenging technological problems. From centimeter-level localization to multimodal sensor perception, sensor fusion, behavior prediction, maneuver planning, and trajectory planning and control, each one of these functions introduces its own unique challenges to solve, verify, test, and deploy on the road.\n\nWe are looking for smart, innovative, and motivated individuals with strong SW background and programming experience with languages such as C/C++, python, and more. Job responsibilities include design and development of SW framework and middleware. Development of sensor drivers to bring in sensors (IMU, GPS, Camera, Radar, Lidar, Ultrasonic) to our platform, sensor synchronization, and efficient techniques to share sensor across different SW modules. Work closely with different teams to implement SW optimization on Snapdragon Ride platform as well as involved in Ride SDK development. Work closely with test engineers to develop test plans and validation of SW. Will be\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\n5 to 8 years of C++ development, C++11 and C++14 is a strong plus\n\nEmbedded SW design and development for safety critical systems is a strong plus\n\nExperience with Programming languages such as C++, Python, Shell, etc.\n\nExperience with multi-threaded / multi-core SW development and design\n\nKnowledge/experience on Linux and embedded platform with QNX, AGL, Safe Linux, etc.\n\nKnowledge of Linux network stack and any experience with network device drivers is a plus\n\nFamiliarity with ROS/ROS2, DDS, Adaptive AUTOSAR middleware and frameworks\n\nKnowledge / experience with safety critical software development process (Functional Safety), including ASPICE, ASIL, ISO26262, MISRA C++, AUTOSAR C++\n\nFamiliarity with static analysis tools, code coverage metrics, unit test generation\n\nExperience with source code management tools such as git, git-lfs, github/gitlab\n\nExcellent written and verbal communication skills, ability to work with a cross-functional",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'java', 'linux', 'software engineering', 'qnx', 'dd', 'sw design', 'python', 'github', 'aspice', 'c', 'embedded sw', 'device drivers', 'static analysis', 'embedded sw development', 'autosar', 'rts', 'git', 'misra', 'adas', 'shell scripting', 'multithreading', 'gitlab', 'functional safety']",2025-06-12 06:31:37
Design Verification WLAN - Principal Engr / Mgr,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 8+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 7+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\n\n\nAs a design verification engineer you will work with a fast paced Integrated Wireless Technology (IEEE 802.11) team, with various wireless technologies embedded into an ARM based SOC infrastructure.\n\n\nYou will be responsible for developing HW blocks (IP design), conduct High/Mid/Low level Design review and delivery IP to Subsystem team for making complex SoCs.\n\nYou will be a critical part of the WLAN subsystem, contribute to IP design, sign-off the core to the SOC design team.\n\nSkills/Experience:\n\n- 6-15 years experience in Digital Design with a leading chipset company\n\n- Decent knowledge in Wireless connectivity technologiesIEEE 802.11 a/b/g/n/ac/ax/be\n\n- Knowledge in SoC architecture, including CPUs (preferably ARM), communications peripherals, multi-domain clocking, bus & interconnect structures, and power management\n\n- Strong fundamentals in one or few of these domain areas - Wireless and Mobile communications, Information theory, Coding theory, Signal processing\n\n- Strong knowledge on fixed-point implementation Truncation/Rounding/Saturation concepts\n\n- Strong knowledge on Digital communication engines viz., Demodulator, Deinterleaver, Viterbi/Turbo Decoders, Sigma-Delta modulation, Base band filters, FFT etc.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['signal processing', 'digital design', 'mobile communication', 'digital communication', 'wireless', 'soc', 'gts', 'hardware engineering', 'system testing', 'packaging', 'design management', 'vhdl', 'verilog', 'electricals', 'rtl design', 'fpga', 'soc design', 'rtl coding', 'design review', 'arm']",2025-06-12 06:31:40
Principal Engineer - Post Si Validation,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 8+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 7+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\n\nSilicon Validation Lead - Graphics Silicon Team, Bangalore\n\nThe Qualcomm Graphics Silicon Team in Bangalore is seeking a Silicon Validation Lead. Our power-efficient GPU solutions are fundamental to enabling exciting new markets such as Virtual Reality (VR), Internet of Things (IoT), Artificial Intelligence (AI), drones, and autonomous driving. We are looking for a talented Silicon Lead to deliver power-optimized, high-quality, high-performance graphics and computing solutions. The Graphics Silicon team in Bangalore is part of a global team responsible for developing and delivering GPU solutions that set industry benchmarks. Qualcomm boasts a strong portfolio of GPU cores, providing engineers with the opportunity to work with a world-class engineering team that leads the industry through innovation and disciplined execution.\n\nRoles and Responsibilities\n\nAs a GPU Silicon Validation Engineer, you will be part of the GPU Silicon Team and drive:\n\nThe new feature, use case enablement, and their validation.\n\nCollaboration with GPU design and verification teams to develop GPU bring-up and validation test plans.\n\nPreparation for GPU bring-up through pre-work on emulation and FPGA platforms.\n\nCoordination with SoC bring-up teams and software teams to plan GPU bring-up.\n\nTriage and debugging of failures on silicon.\n\nDevelopment of test contents and testing strategies to assist in the validation of GPU on silicon.\n\nWorking with GPU verification teams to reproduce silicon failures on emulators and FPGAs.\n\nCollaboration with the design team to suggest and architect new debug features to improve future GPU bring-ups.\n\nPower and performance characterization of GPU.\n\nPlanning and implementation of new efficiency improvement methodologies in GPU.\n\n\nQualifications\n\nThe ideal candidate should possess deep knowledge of scripting and software languages, including PERL/TCL, Linux/Unix shell, and C.\n\nMinimum Qualifications\n\nBachelor's or Masters degree in Electrical or Electronic Engineering from a reputed institution.\n\nOver 14 years of experience in silicon validation and bring-up.\n\n\nMinimum\n\nStrong understanding of microprocessor architecture.\n\nStrong understanding of power management.\n\nExperience in silicon bring-up and validation of GPU features.\n\nExperience in debugging functional, power, performance, and/or physical design issues in silicon.\n\nExperience in GPU silicon validation and debug basics.\n\nExperience in test development for validation of GPU features on silicon.\n\nExperience in developing test vectors for tester bring-up.\n\nImplementation of assembly, C, and Python language programming.\n\nExperience with HW tools like JTAG, Kratos, LA, Emulation platforms, DMM, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['python', 'hardware engineering', 'silicon validation', 'power management', 'perl', 'jtag', 'c', 'soc', 'system testing', 'spi', 'artificial intelligence', 'emulators', 'hw', 'silicon', 'fpga', 'fpga platforms', 'test development', 'linux', 'debugging', 'shell scripting', 'tcl', 'electronics engineering', 'fpgas']",2025-06-12 06:31:43
"Embedded Platform Dev- Lead Engineer, Senior",Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nQualcomm ADAS/Autonomy team is engaged in offering optimized solutions built on DSP, computer vision and machine learning algorithms for the Qualcomm ADAS/Autonomy SoCs. We are seeking engineers with experience in system and SoC SW level functional safety concepts. The job requires understanding and defining of the Safety Concept and Architecture, Software Safety requirements, defining and deploying safety processes and development of Safety software by following the ISO26262 software processes. Interaction with customers, architects and test/integration teams are required as part of the job. The job also involves working with the Software quality team for adherence of ISO26262 and ASPICE processes.\n\nIn this role, the candidate will work with local and global teams to understand, define and implement and productize Automotive specific features including software enablement (drivers/BSP/RTOS/AUTOSAR MCAL), security, functional safety, and power applied to Automotive products on our current and next generation SoCs. The candidate will also have the responsibility to coordinate and execute plans which will encompass validation of all the feature requirements. The Candidate will have the responsibility to identify and address any abnormal discoveries by root-causing and providing detailed corrective actions in the form of optimizations and/or fixes. When possible, the candidate is expected to prototype and pre-validate recommended fixes. Additionally, the candidate will be responsible for any automation of design under test along with validation efforts and working closely with design/production/bench IP teams.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\n\n 3-6 years of Embedded Software Development experience, including low level drivers, and RTOS \n\n The candidate should possess 3 to 6 years of industry experience in embedded software driver development and having expertise in one or more below areas would be preferred: \n\n Should be able to ramp up fast and must have the attitude to work with the team. \n\n Strong C and Assembly Programming with OS & Multi-Processor concepts \n\n Embedded software development in C and C++ on ARM or similar cores. \n\n Hands on experience of driver development on any RTOS, \n\n Experience in SafeRTOS/FreeRTOS based development is nice to have \n\n Experience in Autosar MCAL development is nice to have \n\n Experience in Autosar BSW integration and validation is nice to have \n\n ARM Trust-Zone & ARMv7/v8 architecture. \n\n Good debugging skills with experience on debugging with Lauterbach JTAG debuggers. \n\n Work on challenging customer requirements and issues. \n\n Basic understanding one or more of hardware blocks - Clocks, PLLs, GPIO, Interrupt Controllers (GIC), Peripherals (SPI/I2C/UART/CAN/Ethernet/Clock/etc)  \n\n Automotive SW development experience is must have \n\n Experience in ISO26262/functional safety and ASPICE is highly desirable \n\n Basic knowledge on Power Mgmt. IC is desirable \n\n Knowledge of Software/Hardware Security concepts is desirable \nClosely work with the hardware team to contribute/suggest modifications to the hardware design.\nAny past working experience on Qualcomm chips nice to have",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['embedded software development', 'assembly programming', 'c', 'sw', 'embedded software', 'dsp', 'algorithms', 'jtag', 'c++', 'aspice', 'freertos', 'rtos', 'java', 'debugging', 'software engineering', 'ic', 'i2c', 'can bus', 'arm', 'functional safety', 'python', 'spi', 'autosar', 'ethernet', 'mcal', 'uart', 'adas', 'bsp']",2025-06-12 06:31:46
Display System Performance - Lead Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nJob Summary:\n\nWe are seeking a highly motivated and skilled Performance and Power Analysis Engineer to join our Display Systems team in Bengaluru. In this critical role, you will be responsible for the analysis, modeling, and optimization of performance and power consumption across various stages of our cutting-edge chip development process. You will take the lead and collaborate closely with architecture, design, Software and verification teams to ensure our products meet stringent performance targets and power efficiency requirements. As an independent collaborator, contribute with cross functional teams, SoC performance and SW/HW teams to enhance or optimize the process. This is an exciting opportunity to contribute to the development of next-generation semiconductor technology.\n\nResponsibilities:\nDevelop and maintain architectural-level and/or cycle-accurate models for performance and power estimation.\nAnalyze trade-offs between performance, power, and area (PPA) at the architecture and microarchitecture levels.\nDrive performance and power analysis early in the design cycle to influence architecture and design decisions.\nCollaborate with architecture and design teams to explore and evaluate different design options and trade-offs to optimize performance and power.\nConduct detailed analysis to identify performance bottlenecks and power inefficiencies in chip architectures and microarchitectures.\nPerform power profiling and characterization of designs under various operating conditions and workloads.\nDevelop and implement power reduction techniques at different design stages (e.g., clock gating, power gating, voltage scaling).\nAnalyze and debug performance and power-related issues during simulation, emulation, and silicon bring-up.\nGenerate comprehensive reports and presentations summarizing analysis results and providing actionable recommendations to the design teams, cross-functional teams and senior leadership.\nStay abreast of the latest industry trends, tools, and methodologies in performance and power analysis.\nContribute to the development and improvement of internal tools and flows for performance and power analysis.\nCollaborate with verification teams to define and execute performance and power validation plans.\nValidate model accuracy through correlation with RTL simulations, emulation, and silicon measurements.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.\n\nQualifications:\nBachelor's or Master's degree in Electrical Engineering, Computer Engineering, or a related field.\n5 to 8+ years of experience in performance and power analysis for ASIC or SoC designs.\nStrong understanding of computer architecture, microarchitecture, and digital design principles.\nStrong experience in developing and utilizing performance and power models using languages such as SystemC, Python, C++, or custom in-house frameworks.\nProficiency in using industry-standard performance and power analysis tools (e.g., Synopsys PrimeTime PX)\nSolid understanding of power management techniques and low-power design methodologies.\nExperience with simulation and emulation environments.\nStrong analytical and problem-solving skills with the ability to interpret complex data and draw meaningful conclusions.\nExcellent communication and interpersonal skills with the ability to collaborate effectively with cross-functional teams.\nFamiliarity with silicon bring-up and post-silicon power/performance characterization is a plus.\nExperience with machine learning techniques for power/performance prediction is a plus.\nExperience with IOS and Xcode profiling/development is a plus",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['digital design', 'microservices', 'computer architecture', 'analysis tools', 'design principles', 'asic', 'python', 'c++', 'systemc', 'xcode', 'ios', 'machine learning', 'power analysis', 'silicon', 'power management', 'soc design', 'machine learning algorithms', 'system engineering']",2025-06-12 06:31:48
Big Data Developer/Data Engineer,Grid Dynamics,5 - 10 years,Not Disclosed,['Bengaluru'],"Role & responsibilities\nExperience: 5 - 8 years\nEmployment Type: Full-Time\n\nJob Summary:\nWe are looking for a highly skilled Scala and Spark Developer to join our data engineering team. The ideal candidate will have strong experience in building scalable data processing solutions using Apache Spark and writing robust, high-performance applications in Scala. You will work closely with data scientists, data analysts, and product teams to design, develop, and optimize large-scale data pipelines and ETL workflows.\n\nKey Responsibilities:\nDevelop and maintain scalable data processing pipelines using Apache Spark and Scala.\nWork on batch and real-time data processing using Spark (RDD/DataFrame/Dataset).\nWrite efficient and maintainable code following best practices and coding standards.\nCollaborate with cross-functional teams to understand data requirements and implement solutions.\nOptimize performance of Spark jobs and troubleshoot data-related issues.\nIntegrate data from multiple sources and ensure data quality and consistency.\nParticipate in design reviews, code reviews, and provide technical leadership when needed.\nContribute to data modeling, schema design, and architecture discussions.\nRequired Skills:\nStrong programming skills in Scala.\nExpertise in Apache Spark (Core, SQL, Streaming).\nHands-on experience with distributed computing and large-scale data processing.\nExperience with data formats like Parquet, Avro, ORC, and JSON.\nGood understanding of functional programming concepts.\nFamiliarity with data ingestion tools (Kafka, Flume, Sqoop, etc.).\nExperience working with Hadoop ecosystem (HDFS, Hive, YARN, etc.) is a plus.\nStrong SQL skills and experience working with relational and NoSQL databases.\nExperience with version control tools like Git.\nPreferred Qualifications:\nBachelor's or Masters degree in Computer Science, Engineering, or related field.\nExperience with cloud platforms like AWS, Azure, or GCP (especially EMR, Databricks, etc.).\nKnowledge of containerization (Docker, Kubernetes) is a plus.\nFamiliarity with CI/CD tools and DevOps practices.ndidate profile",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Scala', 'Pyspark', 'Spark']",2025-06-12 06:31:51
CPU Micro-architect/RTL Designer -Principal Engineer,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nGeneral Summary Qualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in. We are hiring talented engineers for CPU RTL development targeted for high performance, low power devices. As a CPU Micro-architecture and RTL Design Engineer, you will work with chip architects to conceive of the micro-architecture, and also help with architecture/product definition through early involvement in the product life-cycle.\n\nRoles And Responsibilities\n\nPerformance exploration. Explore high performance strategies working with the CPU modeling team.\n\nMicroarchitecture development and specification. From early high-level architectural exploration, through micro architectural research and arriving at a detailed specification.\n\nRTL ownership. Development, assessment and refinement of RTL design to target power, performance, area and timing goals.\n\nFunctional verification support. Help the design verification team execute on the functional verification strategy.\n\nPerformance verification support. Help verify that the RTL design meets the performance goals.\n\nDesign delivery. Work with multi-functional engineering team to implement and validate physical design on the aspects of timing, area, reliability, testability and po\n\n\nPreferred Qualifications\n\nThorough knowledge of microprocessor architecture including expertise in one or more of the following areasinstruction fetch and decode, branch prediction, instruction scheduling and register renaming, out-of-order execution, integer and floating point execution, load/store execution, prefetching, cache and memory subsystems\n\nKnowledge of Verilog and/or VHDL. Experience with simulators and waveform debugging tools\n\nKnowledge of logic design principles along with timing and power implications\n\nUnderstanding of low power microarchitecture techniques\n\nUnderstanding of high performance techniques and trade-offs in a CPU microarchitecture\n\nExperience using a scripting language such as Perl or Python\n\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 8+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 7+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\n\nPreferred Qualifications:\n\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field.\n\n15+ years of Hardware Engineering or related work experience.\n4+ years of experience with circuit/logic design/validation (e.g., digital, analog, RF).\n\n4+ years of experience utilizing schematic capture and circuit stimulation software.\n\n4+ years of experience with hardware design and measurement instruments such as oscilloscopes, spectrum analyzers, RF tools, etc.\n\n4+ years in a technical leadership role with or without direct reports.\n\nPrincipal Duties and Responsibilities:\n\nLeverages expert Hardware knowledge and experience to plan, optimize, verify, and test highly critical electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems.\n\nDrives the development of design rules and processes for electronic hardware, equipment, and/or integrated circuitry.\n\nServes as an expert resource for conducting highly complex simulations and analyses of designs as well as for the implementation of designs with the best power, performance, and area.\n\nCollaborates with high-level representatives across functions (e.g., design, verification, validation, software and systems engineering, architecture development teams, etc.) to implement and drive new requirements and the latest test solutions in the production program to improve the yield, test time, and quality.\n\nEvaluates, characterizes, and develops the novel manufacturing solutions for leading edge products in highly advanced processes and bring-up product to meet customer expectations and schedules.\n\nServes as an expert resource for the evaluation of reliability for highly critical materials, properties, and techniques and brings innovation, automation, and optimization to maximize productivity.\n\nAdvises multiple teams of engineers in the development of complex hardware designs, evaluating various design features to identify potential flaws or issues.\n\nWrites detailed technical documentation for highly complex Hardware projects; reviews technical documentation for experienced engineers.\n\nLevel of Responsibility:\n\nProvides supervision to direct reports.\n\nDecision-making is critical in nature and highly impacts program, product, or project success.\n\nRequires verbal and written communication skills to convey highly complex and/or detailed information. May require strong negotiation and influence with large groups or high-level constituents.\n\nWorks within the prescribed budgetary objectives of the department.\n\nHas a great degree of influence over key organizational decisions.\n\nTasks often require multiple steps which can be performed in various orders; extensive planning, problem-solving, and prioritization must occur to complete the tasks effectively.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['circuit', 'hardware engineering', 'order execution', 'hardware design', 'logic design', 'python', 'physical design', 'data validation', 'simulation', 'design verification', 'rtl', 'vhdl', 'uvm', 'verilog', 'schematic capture', 'rtl design', 'instruments', 'axi', 'fpga', 'debugging', 'perl', 'system verilog']",2025-06-12 06:31:54
SOC Thermal engineer,Qualcomm,1 - 3 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field.\n\nJob Function:\n\nSOC Thermal analysis methodology developmentencompassing SoC, package and systems, for various Qualcomm products going into smartphones, laptops, automotives and virtual reality headsets.\n\nDeveloping strategies to predict and improve thermally constrained scores (AnTuTu/Geekbench) and also measure/tune it on post-Si platforms, including infrared imaging.\n\nThermal measurement The candidate will be responsible for improving thermal mitigation strategies through power and thermal management to achieve optimal system thermal performance.\n\n\n\n\nSkills:\n\n\nShould possess strong analytical skills and mathematical modeling abilities.\n\nKnowledge of SOC stack up is must\n\nGood knowledge of scripting in PERL/Python required; some exposure to Machine Learning algorithms/frameworks will be a plus.\n\nNeed to have thorough knowledge of heat transfer mechanisms and CFD.\n\nProficiency with state-of-the-art thermal analysis tools- Ansys Icepak/Flotherm\n\nThermal Measurement will be preferred skill\n\n\nExperience: BE/ME graduates with 1 to 3 years of experience.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['python', 'soc', 'machine learning', 'mathematical modeling', 'perl', 'dsp', 'data analytics', 'natural language processing', 'hardware engineering', 'sql', 'deep learning', 'r', 'fpga', 'data science', 'predictive modeling', 'machine learning algorithms', 'logistic regression', 'statistics']",2025-06-12 06:31:56
Data Bricks,PwC India,7 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary:\n\nWe are seeking a talented Data Engineer with strong expertise in Databricks, specifically in Unity Catalog, PySpark, and SQL, to join our data team. Youll play a key role in building secure, scalable data pipelines and implementing robust data governance strategies using Unity Catalog.\n\nKey Responsibilities:",,,,"['DataBricks', 'Data Bricks', 'Pyspark', 'Delta Lake', 'Databricks Engineer', 'Unity Catalog', 'SQL']",2025-06-12 06:31:58
It Recruiter,IonIdea,0 - 3 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nTalent Sourcing: Utilize various channels such as job boards, social media, LinkedIn, networking events, and internal databases to source and attract high-quality candidates for a variety of technical positions (software developers, systems engineers, data scientists, etc.).\nCandidate Screening: Review resumes, conduct initial phone screenings, and assess candidates technical skills, experience, and cultural fit.\nInterview Coordination: Schedule and facilitate interviews with hiring managers, ensuring a smooth and efficient process for all parties involved.\nCandidate Engagement: Build relationships with both active and passive candidates to maintain a strong pipeline of qualified talent. Keep candidates informed throughout the hiring process.\nOffer Management: Work with HR and hiring managers to present offers, negotiate terms, and ensure a positive candidate experience during the offer process.\n\nQualifications:\nExperience: Fresher-3years\n\nTechnical Knowledge: A solid understanding of IT roles, including knowledge of programming languages, software development frameworks, network infrastructure, cloud technologies, and emerging IT trends.\nRecruitment Tools: Proficient in using Applicant Tracking Systems (ATS), job boards (e.g., LinkedIn, Indeed), and social media platforms for sourcing candidates.\nCommunication Skills: Excellent written and verbal communication skills with the ability to engage with both technical and non-technical stakeholders.",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['IT Recruitment', 'C2H', 'Contract Hiring']",2025-06-12 06:32:02
XR Perception Systems Engineer,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nAt Qualcomm XR Perception, were a passionate team of engineers who want to change the world through virtual and augmented reality products and technologies. We develop state-of-the-art, power efficient XR perception algorithms optimized for Qualcomm hardware. The perception algorithms enable XR systems to map the users environment and track the user within the environment.\n\nTo scale and strengthen our offering, Qualcomm XR Perception team in Bengaluru is rapidly expanding and seeking candidates to investigate and develop the fundamental perception algorithm that enables self-contained XR platforms. We are looking for innovators who will push the boundaries of mobile perception technology to offer a robust platform to our customers.\n\nJob Function/General Responsibilities\n\nIn this job the candidate would\n\nBe part of a world-class XR team researching and developing XR perception\n\nWork with building blocks of Simultaneous Localization and Mapping (SLAM)\n\no Multi-view geometry\n\no Sensor Fusion\n\no Pose estimation\n\no Non-linear optimization\n\nApply ML/ DL techniques to enhance accuracy and robustness of traditional SLAM systems\n\nImplement efficient and optimized algorithms in C++\n\nUnderstand and analyze requirements for perception systems for XR platforms\n\nHave excellent verbal and written communication and presentation skills\n\n\n\nCandidate that fits this role should be well versed in the basics of\n\nLinear algebra\n\nProbability\n\nMulti-view geometry\n\nSensor fusion\n\nEstimation techniques\n\nNon-linear optimization\n\nMachine learning techniques\n\nObject oriented programming in C++\n\n\n\nKeywords\n\nVirtual reality, Augmented reality, Computer vision, Machine learning, Perception, VIO, SLAM\n\n\n\nEducational requirements:\n\nBachelor's degree in Engineering, Applied Mathematics, Computer Science, or related field\n\n+3 years of work experience OR Master's degree in Engineering, Applied Mathematics, Computer Science, or related field\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['presentation skills', 'fusion', 'geometry', 'sensor', 'linear algebra', 'algorithms', 'c++', 'python', 'machine learning', 'estimation', 'slam', 'deep learning', 'tensorflow', 'computer science', 'computer vision', 'keras', 'object oriented programming', 'vio', 'system engineering']",2025-06-12 06:32:05
Lead Data Scientist,Bizopp Management Consultants,11 - 18 years,25-35 Lacs P.A.,['Chennai'],"• Proficiency in Python and SQL for data extraction, manipulation, and analysis\n\n• Exploratory data analysis (EDA), developing, and deploying machine learning models\n\n• Expertise in deploying ML models on cloud platforms such as AWS or Azure",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['EDA', 'Data Scientist', 'Python', 'SQL', 'Azure', 'Exploratory data analysis', 'Machine Learning', 'AWS', 'ML']",2025-06-12 06:32:08
Sr Engineer/Sr. Lead - Generative AI,Qualcomm,3 - 8 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\n\n\nLocation - Hyderabad\n\n\nExperience - 3-8 Years\n\n\nWe are seeking an experienced Machine Learning Engineers specializing in Generative AI to join our core AI team.\n\nThe ideal candidate will be responsible for designing, developing, and deploying cutting-edge generative AI solutions, with a focus on Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Intelligent agent systems.\n\nKey Responsibilities:\n\nDesign and implement RAG-based solutions to enhance LLM capabilities with external knowledge sources\n\nDevelop and optimize LLM fine-tuning strategies for specific use cases and domain adaptation\n\nCreate robust evaluation frameworks for measuring and improving model performance\n\nBuild and maintain agentic workflows for autonomous AI systems\n\nCollaborate with cross-functional teams to identify opportunities and implement AI solutions\n\n\nRequired Qualifications:\n\nBachelor's or Master's degree in Computer Science, or related technical field\n\n3+ years of experience in Machine Learning/AI engineering\n\nStrong programming skills in Python and experience with ML frameworks (PyTorch, TensorFlow)\n\nPractical experience with LLM deployments and fine-tuning\n\nExperience with vector databases and embedding models\n\nFamiliarity with modern AI/ML infrastructure and cloud platforms (AWS, GCP, Azure)\n\nStrong understanding of RAG architectures and implementation\n\n\nPreferred Qualifications:\n\nExperience with popular LLM frameworks (Langchain, LlamaIndex, Transformers)\n\nKnowledge of prompt engineering and chain-of-thought techniques\n\nExperience with containerization and microservices architecture\n\nBackground in NLP and deep learning\n\nBackground in Reinforcement Learning\n\nContributions to open-source AI projects\n\nExperience with ML ops and model deployment pipelines\n\n\nSkills and Competencies:\n\nStrong problem-solving and analytical skills\n\nExcellent communication and collaboration abilities\n\nExperience with agile development methodologies\n\nAbility to balance multiple projects and priorities\n\nStrong focus on code quality and best practices\n\nUnderstanding of AI ethics and responsible AI development",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'software engineering', 'c++', 'c', 'natural language processing', 'microsoft azure', 'artificial intelligence', 'microservices', 'reinforcement learning', 'deep learning', 'java', 'computer science', 'gcp', 'agile', 'aws', 'ml']",2025-06-12 06:32:10
Lead Data Scientist,Trion Consultancy Services,10 - 18 years,20-35 Lacs P.A.,['Chennai'],"LD Scientist with 12 yrs of industry exp, including at least 5 yrs of hands-on exp in data science & a proven track record of delivering impactful data science solutions.\nData Analysis &Exploration\nTime Series Analysis\nModel Deployment & Integration\n\nRequired Candidate profile\n12+ yrs/including 5+ yrs in data science\nExp in Python and SQL for data extraction, manipulation & analysis\nDS & Model Development: Demonstrated exp in performing exploratory data analysis (EDA)",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Lead Data science', 'Machine Learning', 'Python']",2025-06-12 06:32:13
Data Engineering Lead,Yotta Techports,10 - 15 years,30-35 Lacs P.A.,['Hyderabad'],"Responsibilities:\nLead and manage an offshore team of data engineers, providing strategic guidance, mentorship, and support to ensure the successful delivery of projects and the development of team members.\nCollaborate closely with onshore stakeholders to understand project requirements, allocate resources efficiently, and ensure alignment with client expectations and project timelines.\nDrive the technical design, implementation, and optimization of data pipelines, ETL processes, and data warehouses, ensuring scalability, performance, and reliability.\nDefine and enforce engineering best practices, coding standards, and data quality standards to maintain high-quality deliverables and mitigate project risks.\nStay abreast of emerging technologies and industry trends in data engineering, and provide recommendations for tooling, process improvements, and skill development.\nAssume a data architect role as needed, leading the design and implementation of data architecture solutions, data modeling, and optimization strategies.\nDemonstrate proficiency in AWS services such as:\nExpertise in cloud data services, including AWS services like Amazon Redshift, Amazon EMR, and AWS Glue, to design and implement scalable data solutions.\nExperience with cloud infrastructure services such as AWS EC2, AWS S3, to optimize data processing and storage.\nKnowledge of cloud security best practices, IAM roles, and encryption mechanisms to ensure data privacy and compliance.\nProficiency in managing or implementing cloud data warehouse solutions, including data modeling, schema design, performance tuning, and optimization techniques.\nDemonstrate proficiency in modern data platforms such as Snowflake and Databricks, including:\nDeep understanding of Snowflake's architecture, capabilities, and best practices for designing and implementing data warehouse solutions.\nHands-on experience with Databricks for data engineering, data processing, and machine learning tasks, leveraging Spark clusters for scalable data processing.\nAbility to optimize Snowflake and Databricks configurations for performance, scalability, and cost-effectiveness.\nManage the offshore team's performance, including resource allocation, performance evaluations, and professional development, to maximize team productivity and morale.\n\nQualifications:\nBachelor's degree in Computer Science, Engineering, or a related field; advanced degree preferred.\n10+ years of experience in data engineering, with a proven track record of leadership and technical expertise in managing complex data projects.\nProficiency in programming languages such as Python, Java, or Scala, as well as expertise in SQL and relational databases (e.g., PostgreSQL, MySQL).\nStrong understanding of distributed computing, cloud technologies (e.g., AWS), and big data frameworks (e.g., Hadoop, Spark).\nExperience with data architecture design, data modeling, and optimization techniques.\nExcellent communication, collaboration, and leadership skills, with the ability to effectively manage remote teams and engage with onshore stakeholders.\nProven ability to adapt to evolving project requirements and effectively prioritize tasks in a fast-paced environment.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Team Handling', 'Snowflake', 'Data Services', 'Cloud Infrastructure', 'Data Bricks']",2025-06-12 06:32:15
AI/ML framework Staff Engineer,Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nLooking for ""ML framework and AI compiler Engineer"" responsible for\nDesigning, implementing, and deploying machine learning models using PyTorch\nFocusing on backend infrastructure and system architecture.\nResponsibilities often include developing framework, integrating with other AI tools, and ensuring scalability and reliability.\n\nHere's a more detailed breakdown of what you might see in such a job description:\n\nKey Responsibilities:\n\n\nModel Development and DeploymentDesigning, building, and deploying AI models, particularly those leveraging PyTorch for deep learning.\n\n\nBackend InfrastructureDeveloping and maintaining the backend systems that power AI applications, including data ingestion, processing, and storage.\n\n\nSystem ArchitectureDesigning scalable and high-performance backend architectures to handle AI workloads.\n\n\nModel OptimizationOptimizing model performance for speed, accuracy, and resource efficiency.\n\n\nIntegrationIntegrating AI models with other systems and applications.\n\n\nAPI DevelopmentCreating and maintaining APIs for communication between frontend and backend components.\n\n\nData HandlingManaging data ingestion, preprocessing, and storage for AI training and inference.\n\n\nCollaborationWorking with data scientists, product managers, and other engineers to bring AI solutions to life.\n\nTools, Technologies, Skills and Programming:\n\n\nC, C++: Strong programming capability using advanced techniques to design and develop AI compilers and backends.\n\n\nScripting: Strong expertise in Python with design, develop, release and maintain projects.\n\n\nAI Frameworks: Familiarity with other AI frameworks like PyTorch, TensorFlow, Hugging Face, etc.\n\n\nMachine Learning Knowledge: Understanding of machine learning principles and algorithms starting Computer vision to large language models and continuously update to new trends.\nExpertise to deep learning accelerator programming (GPU, NPU). Any parallel programming experience (Like CUDA, OpenCL, MKLDNN ..etc) is a plus.\nExperience with deep leaning compilers like Glow, TVM ""etc is a plus.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'system engineering', 'c#', 'cuda', 'algorithms', 'c++', 'parallel programming', 'artificial intelligence', 'opencl', 'deep learning', 'java', 'product management', 'computer vision', 'asp.net', 'multithreading', 'mvc', 'ml']",2025-06-12 06:32:17
Sr Engineer,Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nCPU architecture team is driving the core math libraries needed for ML/AI acceleration. This position/s will expose you to Qualcomms cutting edge SoC and ML/AI platforms in the industry. Participate in Optimizing the core ML kernels using the latest advancements like SME, SVE of the ARM CPU architecture and enhance the performance of the ML models on the CPU of the QCOM Soc\n\nRequired Skills==\n3+ experince with Understanding of ARM CPU architecture fundamentals and ARM Arch64 ISA\nOptimizing kernels for vector Processors\nUnderstanding of the basic linear algebra functions used in AI/ML\nAlgorithm design (logic, critical thinking)\nPerformance Evaluation and Optimization of the applications for ARM architecture\nInferencing of the ML models written in Pytorch/TensorFlow/Keras\nUnderstanding of the typical Open-Source Library framework design\n\n\n\nPreferred Skills===\nStrong Programming skills and deep understanding of the ARM ISA\nunderstanding of the algorithms suitable for Vector and matrix accelerators\nStrong Analytical and debugging skills\nGood understanding of Optimizing the Linear Algebra algorithms\nPerformance evaluation using QEMU, Simulators, Emulators and on Real Hardware\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['cpu', 'isa', 'debugging', 'software engineering', 'arm', 'algorithms', 'python', 'c++', 'c', 'natural language processing', 'soc', 'neural networks', 'machine learning', 'artificial intelligence', 'deep learning', 'tensorflow', 'java', 'computer science', 'computer vision', 'pytorch', 'keras', 'dhcp']",2025-06-12 06:32:20
Sr. Data Scientist-Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist\n\nLocation: Onsite Bangalore\nExperience: 8+ years\n\nRole Overview\n\nWe are seeking a Senior Data Scientist with a strong foundation in machine learning, deep learning, and statistical modeling, with the ability to translate complex operational problems into scalable AI/ML solutions. In addition to core data science responsibilities, the role involves building production-ready backends in Python and contributing to end-to-end model lifecycle management. Exposure to computer vision is a plus, especially for industrial use cases like identification, intrusion detection, and anomaly detection.\n\nKey Responsibilities\n\nDevelop, validate, and deploy machine learning and deep learning models for forecasting, classification, anomaly detection, and operational optimization\nBuild backend APIs using Python (FastAPI, Flask) to serve ML/DL models in production environments\nApply advanced computer vision models (e.g., YOLO, Faster R-CNN) to object detection, intrusion detection, and visual monitoring tasks\nTranslate business problems into analytical frameworks and data science solutions\nWork with data engineering and DevOps teams to operationalize and monitor models at scale\nCollaborate with product, domain experts, and engineering teams to iterate on solution design\nContribute to technical documentation, model explainability, and reproducibility practices\n\n\nRequired Skills\n\nStrong proficiency in Python for data science and backend development\nExperience with ML/DL libraries such as scikit-learn, TensorFlow, or PyTorch\nSolid knowledge of time-series modeling, forecasting techniques, and anomaly detection\nExperience building and deploying APIs for model serving (FastAPI, Flask)\nFamiliarity with real-time data pipelines using Kafka, Spark, or similar tools\nStrong understanding of model validation, feature engineering, and performance tuning\nAbility to work with SQL and NoSQL databases, and large-scale datasets\nGood communication skills and stakeholder engagement experience\n\n\nGood to Have\n\nExperience with ML model deployment tools (MLflow, Docker, Airflow)\nUnderstanding of MLOps and continuous model delivery practices\nBackground in aviation, logistics, manufacturing, or other industrial domains\nFamiliarity with edge deployment and optimization of vision models\n\n\nQualifications\n\nMasters or PhD in Data Science, Computer Science, Applied Mathematics, or related field\n7+ years of experience in machine learning and data science, including end-to-end deployment of models in production",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scikit-learn', 'time-series modeling', 'ML/DL libraries', 'data science', 'Python', 'Airflow', 'Kafka', 'MLflow', 'logistics', 'anomaly detection', 'aviation', 'SQL', 'PyTorch', 'NoSQL', 'MLOps', 'forecasting techniques', 'Docker', 'manufacturing', 'FastAPI', 'Spark', 'TensorFlow', 'Flask']",2025-06-12 06:32:22
Data Engineer-Having Stratup-Mid-Size company Exp.@ Bangalore_Urgent,"As a leader in this space, we deliver wo...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Engineer\n\nLocation: Bangalore - Onsite\nExperience: 8 - 15 years\nType: Full-time\n\nRole Overview\n\nWe are seeking an experienced Data Engineer to build and maintain scalable, high-performance data pipelines and infrastructure for our next-generation data platform. The platform ingests and processes real-time and historical data from diverse industrial sources such as airport systems, sensors, cameras, and APIs. You will work closely with AI/ML engineers, data scientists, and DevOps to enable reliable analytics, forecasting, and anomaly detection use cases.\nKey Responsibilities\nDesign and implement real-time (Kafka, Spark/Flink) and batch (Airflow, Spark) pipelines for high-throughput data ingestion, processing, and transformation.\nDevelop data models and manage data lakes and warehouses (Delta Lake, Iceberg, etc) to support both analytical and ML workloads.\nIntegrate data from diverse sources: IoT sensors, databases (SQL/NoSQL), REST APIs, and flat files.\nEnsure pipeline scalability, observability, and data quality through monitoring, alerting, validation, and lineage tracking.\nCollaborate with AI/ML teams to provision clean and ML-ready datasets for training and inference.\nDeploy, optimize, and manage pipelines and data infrastructure across on-premise and hybrid environments.\nParticipate in architectural decisions to ensure resilient, cost-effective, and secure data flows.\nContribute to infrastructure-as-code and automation for data deployment using Terraform, Ansible, or similar tools.\n\n\nQualifications & Required Skills\n\nBachelors or Master’s in Computer Science, Engineering, or related field.\n6+ years in data engineering roles, with at least 2 years handling real-time or streaming pipelines.\nStrong programming skills in Python/Java and SQL.\nExperience with Apache Kafka, Apache Spark, or Apache Flink for real-time and batch processing.\nHands-on with Airflow, dbt, or other orchestration tools.\nFamiliarity with data modeling (OLAP/OLTP), schema evolution, and format handling (Parquet, Avro, ORC).\nExperience with hybrid/on-prem and cloud platforms (AWS/GCP/Azure) deployments.\nProficient in working with data lakes/warehouses like Snowflake, BigQuery, Redshift, or Delta Lake.\nKnowledge of DevOps practices, Docker/Kubernetes, Terraform or Ansible.\nExposure to data observability, data cataloging, and quality tools (e.g., Great Expectations, OpenMetadata).\nGood-to-Have\nExperience with time-series databases (e.g., InfluxDB, TimescaleDB) and sensor data.\nPrior experience in domains such as aviation, manufacturing, or logistics is a plus.\n\nRole & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['aviation', 'Data Modeling', 'Python', 'OLAP', 'Cloud', 'ORC', 'logistics', 'Avro', 'Terraform', 'Snowflake', 'manufacturing', 'AWS', 'Parquet', 'Java', 'Azure', 'BigQuery', 'Data', 'Redshift', 'SQL', 'TimescaleDB', 'GCP', 'InfluxDB', 'dbt', 'Ansible', 'OLTP', 'Kubernetes']",2025-06-12 06:32:25
Senior Software Engineer - AI/ML,Qualcomm,5 - 10 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nThe AI SW team at Qualcomm is focused on advancing state-of-the-art in Artificial Intelligence across various business segments, including Mobile, AR & VR Technology, IoT, and Auto ADAS. The AISW stack leverages Qualcomm chips' extensive heterogeneous computing capabilities, enabling the running of trained neural networks on devices without needing a cloud connection. This allows neural network models trained in various frameworks on Snapdragon platforms to run at blazing speeds while consuming minimal power. As a Senior Lead Engineer, you will see your work directly impact billions of devices worldwide.\n\nKey Responsibilities:\n\nDesign, develop, and maintain high-quality software solutions using Python for running machine learning models on Qualcomm devices.\n\nContribute to the development and optimization of AI models, using popular frameworks like Pytorch.\n\nBuild tools and infrastructure for onboarding, debugging and analysis of AI models.\n\nParticipate in code reviews and ensure adherence to best practices and coding standards.\n\nDebug accuracy and performance on devices, addressing any challenges that arise.\n\nCollaborate with cross-functional teams to define, design, and ship new features.\n\nOwn end-to-end development and release of features and lead and mentor a sub-team of engineers.\n\n\nMinimum Qualifications:\n\nBachelors degree in engineering, Computer science or a related field and 5+ years of professional experience in software engineering or related work experience\n\nOR\n\nMasters degree in engineering, Computer science or a related field and 4+ years of experience of Software engineering or related work experience\n\nSolid understanding of fundamental computer science concepts, general programming principles and practices.\n\n4+ years of hands-on professional experience in programming with Python (preferred) / Java / C++.\n\nStrong problem-solving skills and the ability to work independently and as part of a team.\n\nBasic knowledge of AI concepts and techniques\n\nExcellent communication skills and the ability to articulate complex technical concepts.\n\nWillingness to learn advanced concepts in AI and machine learning and keep updated with latest industry trends\n\n\nPreferred Qualifications:\n\nExperience with machine learning frameworks and tools such as PyTorch, ONNX.\n\nFamiliarity with Large Language Models (LLMs) and Transformers\n\nFamiliarity working with Linux systems and hardware devices\n\nExperience with mobile development frameworks and tools (e.g., Android SDK, Kotlin).\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'computer science', 'software engineering', 'system engineering', 'algorithms', 'c++', 'natural language processing', 'android', 'kotlin', 'c+', 'aiml', 'artificial intelligence', 'iot', 'deep learning', 'tensorflow', 'java', 'linux', 'computer vision', 'pytorch', 'onnx', 'ml']",2025-06-12 06:32:28
MLOps Engineer,Affine Analytics,4 - 8 years,Not Disclosed,['Bengaluru'],"Machine Learning & Data Pipelines\nStrong understanding of Machine Learning principles, lifecycle, and deployment practices\nExperience in designing and building ML pipelines\nKnowledge of deploying ML models on AWS Lambda, EKS, or other relevant services\nWorking knowledge of Apache Airflow for orchestration of data workflows\nProficiency in Python for scripting, automation, and ML model development with Data Scientists",,,,"['Machine Learning', 'S3', 'AWS Lambda', 'MLOps', 'SQS', 'AWS Glue', 'SNS', 'EKS', 'Lambda', 'Python']",2025-06-12 06:32:30
Data Engineer II - Marketplace (Experimentation Track),Booking Holdings,5 - 10 years,Not Disclosed,['Bengaluru'],"We are looking for a Data Engineer to join our team and help us to improve the platform that supports one of the best experimentation tools in the world.\nYou will work side by side with other data engineers and site reliability engineers to improve the reliability, scalability, maintenance and operations of all the data products that are part of the experimentation tool at Booking.com.\nYour day to day work includes but is not limited to: maintenance and operations of data pipelines and products that handles data at big scale; the development of capabilities for monitoring, alerting, testing and troubleshooting of the data ecosystem of the experiment platform; and the delivery of data products that produce metrics for experimentation at scale. You will collaborate with colleagues in Amsterdam to achieve results the right way. This will include engineering managers, product managers, engineers and data scientists.\nKey Responsibilities and Duties\nTake ownership of multiple data pipelines and products and provide innovative solutions to reduce the operational workload required to maintain them\nRapidly developing next-generation scalable, flexible, and high-performance data pipelines.\nContribute to the development of data platform capabilities such as testing, monitoring, debugging and alerting to improve the development environment of data products\nSolve issues with data and data pipelines, prioritizing based on customer impact.\nEnd-to-end ownership of data quality in complex datasets and data pipelines.\nExperiment with new tools and technologies, driving innovative engineering solutions to meet business requirements regarding performance, scaling, and data quality.\nProvide self-organizing tools that help the analytics community discover data, assess quality, explore usage, and find peers with relevant expertise.\nServe as the main point of contact for technical and business stakeholders regarding data engineering issues, such as pipeline failures and data quality concerns\nRole requirements\nMinimum 5 years of hands-on experience in data engineering as a Data Engineer or as a Software Engineer developing data pipelines and products.\nBachelors degree in Computer Science, Computer or Electrical Engineering, Mathematics, or a related field or 5 years of progressively responsible experience in the specialty as equivalent\nSolid experience in at least one programming language. We use Java and Python\nExperience building production data pipelines in the cloud, setting up data-lakes and server-less solutions\nHands-on experience with schema design and data modeling\nExperience designing systems E2E and knowledge of basic concepts (lb, db, caching, NoSQL, etc)\nKnowledge of Flink, CDC, Kafka, Airflow, Snowflake, DBT or equivalent tools\nPractical experience building data platform capabilities like testing, alerting, monitoring, debugging, security\nExperience working with big data.\nExperience working with teams located in different timezones is a plus\nExperience with experimentation, statistics and A/B testing is a plus",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Airflow', 'Java', 'CDC', 'NoSQL', 'Snowflake', 'DBT', 'Kafka', 'Python']",2025-06-12 06:32:32
Data Engineer,Aqilea Softech,5 - 9 years,13-20 Lacs P.A.,"['Bangalore Rural', 'Bengaluru']","Job Title: Data Engineer\nCompany : Aqilea India(Client : H&M India)\nEmployment Type: Full Time\nLocation: Bangalore(Hybrid)\nExperience: 4.5 to 9 years\nClient : H&M India\n\nAt H&M, we welcome you to be yourself and feel like you truly belong. Help us reimagine the future of an entire industry by making everyone look, feel, and do good. We take pride in our history of making fashion accessible to everyone and led by our values we strive to build a more welcoming, inclusive, and sustainable industry. We are privileged to have more than 120,000 colleagues, in over 75 countries across the world. Thats 120 000 individuals with unique experiences, skills, and passions. At H&M, we believe everyone can make an impact, we believe in giving people responsibility and a strong sense of ownership. Our business is your business, and when you grow, we grow.\nWebsite : https://career.hm.com/\n\nWe are seeking a skilled and forward-thinking Data Engineer to join our Emerging Tech team. This role is designed for someone passionate about working with cutting-edge technologies such as AI, machine learning, IoT, and big data to turn complex data sets into actionable insights.\nAs the Data Engineer in Emerging Tech, you will be responsible for designing, implementing, and optimizing data architectures and processes that support the integration of next-generation technologies. Your role will involve working with large-scale datasets, building predictive models, and utilizing emerging tools to enable data-driven decision-making across the business. You ll collaborate with technical and business teams to uncover insights, streamline data pipelines, and ensure the best use of advanced analytics technologies.\n\nKey Responsibilities:\nDesign and build scalable data architectures and pipelines that support machine learning, analytics, and IoT initiatives.\nDevelop and optimize data models and algorithms to process and analyse large-scale, complex data sets.\nImplement data governance, security, and compliance measures to ensure high-quality\nCollaborate with cross-functional teams (engineering, product, and business) to translate business requirements into data-driven solutions.\nEvaluate, integrate, and optimize new data technologies to enhance analytics capabilities and drive business outcomes.\nApply statistical methods, machine learning models, and data visualization techniques to deliver actionable insights.\nEstablish best practices for data management, including data quality, consistency, and scalability.\nConduct analysis to identify trends, patterns, and correlations within data to support strategic business initiatives.\nStay updated on the latest trends and innovations in data technologies and emerging data management practices.\n\nSkills Required :\nBachelors or masters degree in data science, Computer Science, Engineering, Statistics, or a related field.\n4.5-9 years of experience in data engineering, data science, or a similar analytical role, with a focus on emerging technologies.\nProficiency with big data frameworks (e.g., Hadoop, Spark, Kafka) and experience with modern cloud platforms (AWS, Azure, or GCP).\nSolid skills in Python, SQL, and optionally R, along with experience using machine learning libraries such as Scikit-learn, TensorFlow, or PyTorch.\nExperience with data visualization tools (e.g., Tableau or Power BI or D3.js) to communicate insights effectively.\nFamiliarity with IoT and edge computing data architectures is a plus.\nUnderstanding of data governance, compliance, and privacy standards.\nAbility to work with both structured and unstructured data.\nExcellent problem-solving, communication, and collaboration skills, with the ability to work in a fast-paced, cross-functional team environment.\nA passion for emerging technologies and a continuous desire to learn and innovate.\nInterested Candidates can share your Resumes to mail id karthik.prakadish@aqilea.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Powerbi', 'Hadoop', 'Kafka', 'Tableau', 'Azure', 'GCP', 'Data Engineer', 'Spark', 'AWS', 'Python', 'SQL']",2025-06-12 06:32:35
Senior Data Scientist,Straive,5 - 10 years,Not Disclosed,"['Hyderabad', 'Gurugram', 'Bengaluru']","Role & responsibilities\nRequires 5-8 years of proven experience in banking/payments/other domains\nStrong experience in developing Machine Learning models, Python & SQL\nExperience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases\nDetailed oriented with a proactive mindset towards problem-solving\nExcellent communication and presentation skills with the ability to convey complex information clearly and concisely",,,,"['Machine Learning', 'Python', 'SQL', 'Xgboost', 'Neural Networks', 'Random Forest']",2025-06-12 06:32:39
Staff System Test Engineer,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Test Engineering\n\nGeneral Summary:\n\n\n\nWe are seeking a Senior Staff AI System-Level Test Engineer to lead end-to-end testing of Retrieval-Augmented Generation (RAG) AI systems for Hybrid, Edge-AI Inference solutions. This role will focus on designing, developing, and executing comprehensive test strategies for evaluating the reliability, accuracy, usability and scalability of large-scale AI models integrated with external knowledge retrieval systems.\n\nThe ideal candidate needs to have deep expertise in AI testing methodologies, experience with large language models (LLMs), expertise in building test solutions for AI Inference stacks, RAG, search/retrieval architecture, and a strong background in automation frameworks, performance validation, and building E2E automation architecture.\n\nExperience testing large-scale generative AI applications, familiarity with LangChain, LlamaIndex, or other RAG-specific frameworks, and knowledge of adversarial testing techniques for AI robustness are preferred qualifications\n\nKey Responsibilities:\n\nTest Strategy & Planning\nDefine end-to-end test strategies for RAG, retrieval, generation, response coherence, and knowledge correctness\nDevelop test plans & automation frameworks to validate system performance across real-world scenarios.\nHands-on experience in benchmarking and optimizing Deep Learning Models on AI Accelerators/GPUs\nImplement E2E solutions to integrate Inference systems with customer software workflows\nIdentify and implement metrics to measure retrieval accuracy, LLM response quality\n\n\nTest Automation\nBuild automated pipelines for regression, integration, and adversarial testing of RAG workflows.\nValidate search relevance, document ranking, and context injection into LLMs using rigorous test cases.\nCollaborate with ML engineers and data scientists to debug model failures and identify areas for improvement.\nConduct scalability and latency tests for retrieval-heavy applications. Analyze failure patterns, drift detection, and robustness against hallucinations and misinformation.\n\n\nCollaboration\nWork closely with AI research, engineering teams & customer teams to align testing with business requirements.\nGenerate test reports, dashboards, and insights to drive model improvements.\nStay up to date with the latest AI testing frameworks, LLM evaluation benchmarks, and retrieval models.\n\n\nRequired Qualifications:\n8+ years of experience in AI/ML system testing, software quality engineering, or related fields.\nBachelors or masters degree in computer science engineering/ data science / AI/ML\nHands-on experience with test automation frameworks (e.g., PyTest, Robot Framework, JMeter).\nProficiency in Python, SQL, API testing, vector databases (e.g., FAISS, Weaviate, Pinecone) and retrieval pipelines.\nExperience with ML model validation metrics (e.g., BLEU, ROUGE, MRR, NDCG).\nExpertise in CI/CD pipelines, cloud platforms (AWS/GCP/Azure), and containerization (Docker, Kubernetes).\n\n\nWhy Join Us\nWork on cutting-edge AI retrieval-augmented generation technologies\nCollaborate with world-class AI researchers and engineers.\n\nIf you are passionate about AI system testing and ensuring the reliability of next-generation generative models, apply now!\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Systems Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Systems Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Test Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['automation framework', 'continuous integration', 'python', 'sql', 'ci cd pipeline', 'kubernetes', 'ci/cd', 'cloud platforms', 'software quality', 'artificial intelligence', 'docker', 'test engineering', 'quality engineering', 'e2e', 'testing methodologies', 'vector', 'aws', 'api testing']",2025-06-12 06:32:41
Senior Data Engineer,Talentien Global Solutions,4 - 8 years,12-18 Lacs P.A.,"['Hyderabad', 'Chennai', 'Coimbatore']","We are seeking a skilled and motivated Data Engineer to join our dynamic team. The ideal candidate will have experience in designing, developing, and maintaining scalable data pipelines and architectures using Hadoop, PySpark, ETL processes, and Cloud technologies.\n\nResponsibilities:\nDesign, develop, and maintain data pipelines for processing large-scale datasets.\nBuild efficient ETL workflows to transform and integrate data from multiple sources.\nDevelop and optimize Hadoop and PySpark applications for data processing.\nEnsure data quality, governance, and security standards are met across systems.\nImplement and manage Cloud-based data solutions (AWS, Azure, or GCP).\nCollaborate with data scientists and analysts to support business intelligence initiatives.\nTroubleshoot performance issues and optimize query executions in big data environments.\nStay updated with industry trends and advancements in big data and cloud technologies.\nRequired Skills:\nStrong programming skills in Python, Scala, or Java.\nHands-on experience with Hadoop ecosystem (HDFS, Hive, Spark, etc.).\nExpertise in PySpark for distributed data processing.\nProficiency in ETL tools and workflows (SSIS, Apache Nifi, or custom pipelines).\nExperience with Cloud platforms (AWS, Azure, GCP) and their data-related services.\nKnowledge of SQL and NoSQL databases.\nFamiliarity with data warehousing concepts and data modeling techniques.\nStrong analytical and problem-solving skills.\n\nInterested can reach us at +91 7305206696/ saranyadevib@talentien.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Engineering', 'Hadoop', 'Spark', 'ETL', 'Airflow', 'Etl Pipelines', 'Big Data', 'EMR', 'Gcp Cloud', 'Data Bricks', 'Azure Cloud', 'Data Pipeline', 'SCALA', 'Snowflake', 'Data Lake', 'Data Warehousing', 'Data Modeling', 'AWS', 'Python']",2025-06-12 06:32:44
GStreamer multimedia framework Lead Engineer Senior,Qualcomm,3 - 8 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nWe are seeking a skilled Engineer with extensive experience in the GStreamer multimedia framework. The ideal candidate will be responsible for designing, developing, and optimizing multimedia applications and systems. This role requires a deep understanding of multimedia processing, pipeline architecture, and the ability to work on complex projects.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\nExperience with majority in Multimedia framework & Gstreamer plugins development. Strong programming skills in C and C++ for embedded systems Good knowledge about AI/ML applications developements Exposure to developing solutions on Linux is must Strong in multi-threaded programming, synchronization and IPCs Strong Software design skills and ability to guide team of engineers Good knowledge on software development processes Need very good Communication skills and ability to work with cross functional teams Exposure to other media frameworks such as ffmpeg, directshow, stagefright is a plus Good knowledge on V4L2, Pulseaudio, Alsa, OpenGLES is a plus",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'c', 'embedded systems', 'linux', 'gstreamer', 'python', 'software development', 'software design', 'plugins', 'pipeline architecture', 'artificial intelligence', 'multimedia', 'stagefright', 'multimedia framework', 'java', 'synchronization', 'multithreading', 'software engineering', 'ffmpeg', 'ml']",2025-06-12 06:32:46
Data & Gen AI Specialist,Altimetrik,1 - 4 years,Not Disclosed,['Bengaluru'],"Job Title: Data & GenAI AWS Specialist\nExperience: 1-4 Years\nLocation: Bangalore\nMandatory Qualification: B.E./ B.Tech/ M.Tech/ MS from IIT or IISc ONLY\nJob Overview:\nWe are seeking a seasoned Data & GenAI Specialist with deep expertise in AWS Managed Services (PaaS) to join our innovative team. The ideal candidate will have extensive experience in designing sophisticated, scalable architectures for data pipelines and Generative AI (GenAI) solutions leveraging cloud services.",,,,"['Generative Ai', 'Cloud', 'Data Science', 'Open Source', 'Data Pipeline', 'GCP', 'Azure Cloud', 'Snowflake', 'Machine Learning', 'AWS']",2025-06-12 06:32:49
Auto AI Systems Engineer,Qualcomm,1 - 6 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nSummary - We are seeking experts with a robust background in the field of deep learning (DL) to design state-of-the-art low-level perception (LLP) as well as end-to-end AD models, with a focus on achieving accuracy-latency Pareto optimality. This role involves comprehending state-of-the-art research in this field and deploying networks on the Qualcomm Ride platform for L2/L3 Advanced Driver Assistance Systems (ADAS) and autonomous driving.\n\nThe ideal candidate must be well-versed in recent advancements in Vision Transformers (Cross-attention, Self-attention), lifting 2D features to Bird's Eye View (BEV) space, and their applications to multi-modal fusion. This position offers extensive opportunities to collaborate with advanced R&D teams of leading automotive Original Equipment Manufacturers (OEMs) as well as Qualcomm's internal stack teams. The team is responsible for enhancing the speed, accuracy, power consumption, and latency of deep networks running on Snapdragon Ride AI accelerators.\n\nA thorough understanding of machine learning algorithms, particularly those related to automotive use cases (autonomous driving, vision, and LiDAR processing ML algorithms), is essential. Research experience in the development of efficient networks, various Neural Architecture Search (NAS) techniques, network quantization, and pruning is highly desirable.\n\nStrong communication and interpersonal skills are required, and the candidate must be able to work effectively with various horizontal AI teams.\n\nMinimum Qualifications:\n\nBachelor's degree in Computer Science, Engineering, Information Systems, or related field and 1+ years of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience.ORMaster's degree in Computer Science, Engineering, Information Systems, or related field and 1+ year of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience.ORPhD in Computer Science, Engineering, Information Systems, or related field.\n\nPreferred Qualifications:\nGood at software development with excellent analytical, development, and problem-solving skills.\nStrong understanding of Machine Learning fundamentals\nHands-on experience with deep learning network design and implementation. Ability to define network from scratch in PyTorch, ability to add new loss function, modify network with torch.fx. Adept at version control system like GIT.\nExperience in neural network quantization, compression, pruning algorithms.\nExperience in deep learning kernel/compiler optimization\nStrong communication skills\n\n\nPrincipal Duties and Responsibilities:\n\nApplies Machine Learning knowledge to extend training or runtime frameworks or model efficiency software tools with new features and optimizations.\n\nModels, architects, and develops machine learning hardware (co-designed with machine learning software) for inference or training solutions.\n\nDevelops optimized software to enable AI models deployed on hardware (e.g., machine learning kernels, compiler tools, or model efficiency tools, etc.) to allow specific hardware features; collaborates with team members for joint design and development.\n\nAssists with the development and application of machine learning techniques into products and/or AI solutions to enable customers to do the same.\n\nDevelops, adapts, or prototypes complex machine learning algorithms, models, or frameworks aligned with and motivated by product proposals or roadmaps with minimal guidance from more experienced engineers.\n\nConducts complex experiments to train and evaluate machine learning models and/or software independently.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['hardware engineering', 'machine learning', 'software engineering', 'machine learning algorithms', 'system engineering', 'switching', 'pruning', 'algorithms', 'eigrp', 'kernel', 'rstp', 'networking', 'vrrp', 'ospf', 'deep learning', 'routing', 'git', 'computer science', 'vlan', 'adas', 'hsrp', 'control system']",2025-06-12 06:32:51
Data Annotation hiring For Fresher || Excellent communication skills,Multinational Company,0 - 4 years,1-3 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Lead data annotation and collection projects.\nDevelop and implement data annotation guidelines and processes.\nTrain and manage data annotation teams.\nCollaborate with data scientists and engineers to understand data requirements.\n\nHR - 63980 09438\n\nRequired Candidate profile\nQualification - Graduate\nSalary :-\nCTC\n25,000 / experience\n20,000 / fresher\nExperience - Data Annotation only\nTransport:- Both Side\n\n5 Day working / Rotation shift / 2 day Rotation week off",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Object Detection', 'Data Annotation', 'Business Intelligence', 'Digital Image Processing', 'Data Management', 'Image Recognition', 'Image Analysis', 'Annotation', 'Deep Learning', 'Pattern Recognition', 'Image Processing', 'Imaging', 'Content Moderation', 'Data Warehousing', 'Data Analytics']",2025-06-12 06:32:53
STEM Innovation Engineer,Stemrobo,0 - 4 years,2.5-3.5 Lacs P.A.,"['Kottayam', 'Delhi / NCR', 'Mumbai (All Areas)']","1. Develop strong expertise in the field of Robotics, IOT, AI, Drone & Coding.\n2. Regular visits to schools and provide mentorships to K-12 students.\n3. Organize, Develop and coordinate special STEM Engineering and technology based events/activities\n\nRequired Candidate profile\nPractical knowledge of Arduino, Raspberry Pi and other microcontrollers is required.\nSound knowledge in C and Python Language.\nGood verbal and written communication.\nFlexible with working hours.",Industry Type: Education / Training,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Arduino', 'IOT', 'Mechatronics', 'C', 'Coding', 'Artificial Intelligence', 'Electronics', 'Drone', 'Robotics', 'Python']",2025-06-12 06:32:55
Senior Associate Data Scientist,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will identify trends, root causes, and potential improvements in our products and processes, ensuring that patient voices are heard and addressed with utmost precision.\nAs the Sr Associate Data Scientist at Amgen, you will be responsible for developing and deploying basic machine learning, operational research, semantic analysis, and statistical methods to uncover structure in large data sets. This role involves creating analytics solutions to address customer needs and opportunities.\nCollect, clean, and manage large datasets related to product performance and patient complaints.\nEnsure data integrity, accuracy, and accessibility for further analysis.\nDevelop and maintain databases and data systems for storing patient complaints and product feedback.\nAnalyze data to identify patterns, trends, and correlations in patient complaints and product issues.\nUse advanced statistical methods and machine learning techniques to uncover insights and root causes.\nDevelop analytics or predictive models to foresee potential product issues and patient concerns to address customer needs and opportunities.\nPrepare comprehensive reports and visualizations to communicate findings to key collaborators.\nPresent insights and recommendations to cross-functional teams, including product development, quality assurance, and customer service.\nCollaborate with regulatory and compliance teams to ensure adherence to healthcare standards and regulations.\nFind opportunities for product enhancements and process improvements based on data analysis.\nWork with product complaint teams to implement changes and monitor their impact.\nStay abreast of industry trends, emerging technologies, and standard methodologies in data science and healthcare analytics.\nEvaluate data to support product complaints.\nWork alongside software developers and software engineers to translate algorithms into commercially viable products and services.\nWork in technical teams in development, deployment, and application of applied analytics, predictive analytics, and prescriptive analytics.\nPerform exploratory and targeted data analyses using descriptive statistics and other methods.\nWork with data engineers on data quality assessment, data cleansing and data analytics\nGenerate reports, annotated code, and other projects artifacts to document, archive, and communicate your work and outcomes.\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience OR\nBachelors degree and 3 to 5 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience OR\nDiploma and 7 to 9 years of Data Science and with one or more analytic software tools or languages, and data visualization tools experience\nPreferred Qualifications:\nDemonstrated skill in the use of applied analytics, descriptive statistics, feature extraction and predictive analytics on industrial datasets.\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification.\nExperience in analyzing time-series data for forecasting and trend analysis.\nExperience with Data Bricks platform for data analytics.\nExperience working with healthcare data, including patient complaints, product feedback, and regulatory requirements.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'data bricks', 'hypothesis testing', 'predictive analytics', 'data visualization', 'machine learning', 'statistics']",2025-06-12 06:32:58
AutoIT Solutioning Engineer-Staff,Qualcomm,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n \n\nQualcomm Overview: \nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.\n\nGeneral Summary:\n\nAs a Site Reliability Engineer (SRE), youll be part of a highly collaborative team focused on provisioning and maintaining infrastructure and services with stability, sustainability, and security always on your mind. You will work in a self-guided, cross-functional team responsible for everything from modernizing traditional services and applications to deploying new technology. You'll collaborate closely with software engineers, data scientists, and product managers to maintain and optimize our systems. If you're passionate about automotive technology, software reliability, and continuous improvement, this role is perfect for you.\n\nYour Guiding Principles:\n\n\nAutomationYou understand the power of automation and ""infrastructure as code"" concepts. Automation is your primary consideration in problem-solving.\n\n\nCollaboration: You share a common language with fellow engineers, understand their needs, and thrive working in a high trust collaborate culture in which people are rewarded for taking risks.\n\n\nData-drivenYou understand why decisions are supported by facts and not opinions. You have experience applying logical approach to decision making. Skilled at metric collection and using that data to drive change.\n\n\nDebuggingYou understand debugging principles and are adept at applying them routinely and successfully.\n\n\nDevSecOps: You understand that DevSecOps is a culture which needs to be cultivated and you can help nurture those philosophies.\n\n\nSecurityYou know how to layer appropriate security within solutions across the lifecycle. You understand the security implications and consequences of any deployment.\n\n\nSelf-Driven: You understand how to prioritize work and time allocation at a personal and team level.\n\n\nStability: You know what it means to deliver a service with a high degree of reliability and are intimately familiar with how disruptions impact consumers.\n\n\nSustainability: You avoid one off solutions which are challenging to support. Instead, your solutions are aligned with team goals and strategic vision. You routinely dedicate cycles to reducing technical debt.\n\n\nWhat you have:\nExtensive Linux experience with servers and workstations. You can easily navigate the CLI, knowledgeable with typical Linux troubleshooting tools, and have a broad understanding of Ubuntu and RedHat.\nThe ability to automate through scripting languages such as Python, Bash, Go, etc.\nThe skill to provide sufficient automated test coverage of various implementations.\nYou have familiarity with Jenkins, Puppet, Splunk, JIRA, Vault, Docker, AWS, Cloud services, etc.\nAbility to respond rapidly to changing landscapes while providing stable, reliable, and secure services to customers.\nYou have a passion for continuous learning and leverage the scientific method to ensure nothing is taken for granted.\n\n\nResponsibilities:\nSystem Monitoring and Incident Response:\nMonitor system health, detect anomalies, and respond promptly to incidents.\nInvestigate and troubleshoot issues related to services.\nImplement proactive measures to prevent service disruptions.\nInfrastructure Automation:\nDevelop and maintain infrastructure-as-code (IaC) scripts for deployment and scaling.\nAutomate routine tasks to improve efficiency and reduce manual intervention.\nPerformance Optimization:\nCollaborate with development teams to optimize software performance.\nIdentify bottlenecks and implement solutions to enhance system speed and reliability.\nCapacity Planning:\nForecast resource requirements based on traffic patterns and business growth.\nScale infrastructure to accommodate increasing demand.\nSecurity and Compliance:\nEnsure compliance with industry standards and best practices.\nImplement security controls and participate in security audits.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['docker', 'linux', 'python', 'puppet', 'aws', 'kubernetes', 'owasp', 'golang', 'redhat linux', 'vulnerability assessment', 'ansible', 'microservices', 'java', 'devops', 'jenkins', 'debugging', 'penetration testing', 'vault', 'jira', 'cloud services', 'ubuntu', 'microsoft azure', 'splunk', 'bash', 'devsecops', 'terraform']",2025-06-12 06:33:00
Senior/Lead MLops Engineer,Tiger Analytics,7 - 10 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","JOB DESCRIPTION\n\nSenior MLE / Architect MLE (ML Ops) Chennai / Bangalore / Hyderabad (Hybrid)\n\nWho we are Tiger Analytics is a global leader in AI and analytics, helping Fortune 1000 companies solve their toughest challenges. We offer fullstack AI and analytics services & solutions to empower businesses to achieve real outcomes and value at scale. We are on a mission to push the boundaries of what AI and analytics can do to help enterprises navigate uncertainty and move forward decisively. Our purpose is to provide certainty to shape a better tomorrow. Our team of 4000+ technologists and consultants are based in the US, Canada, the UK, India, Singapore and Australia, working closely with clients across CPG, Retail, Insurance, BFS, Manufacturing, Life Sciences, and Healthcare. Many of our team leaders rank in Top 10 and 40 Under 40 lists, exemplifying our dedication to innovation and excellence. We are a Great Place to Work-Certified (2022-24), recognized by analyst firms such as Forrester, Gartner, HFS, Everest, ISG and others. We have been ranked among the Best and Fastest Growing analytics firms lists by Inc., Financial Times, Economic Times and Analytics India Magazine.",,,,"['MLops', 'Azure', 'Snowflake', 'Deployment', 'Ci/Cd', 'Machine Learning']",2025-06-12 06:33:03
"Principal Engineer/Manager/Director, CAD tools & Methodology",Qualcomm,8 - 13 years,Not Disclosed,['Noida'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 8+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 7+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nPosition- Principal Engineer/Manager, CAD tools & Methodology\n\nLocationNoida\n\n:\nWe are looking for a senior leader to lead a 20+ CAD team in Noida.\nThe Noida CAD team delivers tools/flows/methodologies to enable Qualcomm to build its most complex SoCs in cutting edge process nodes.\nThe person will be responsible for:\nManaging all CAD functions in Noida- including front-end and RTL2GDS tools.\nDrive tools, flows, methodologies globally as part of world-wide CAD organization.\nDrive local EDA vendor eco-system.\nBe the interface to Qualcomm execution teams in Noida.\nExperience:\nAtleast 15 years experience in development of tools/flows/methodologies in either RTL, DV, synthesis, PnR or Signoff.\nShould have a proven record of driving new innovative tool/flow/methodology solutions.\nShould have managed a medium sized team.\nEducational Qualification:\nPreferred- Masters in VLSI or Computer Science\nMinimum- Bachelors in Electronics/Electrical Engineering/Computer Science",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['synthesis', 'cad', 'hardware engineering', 'rtl', 'pnr', 'catia v5', 'system testing', 'cad tools', 'electrical engineering', 'design engineering', 'autocad', 'vhdl', 'catia', 'verilog', 'electricals', 'rest assured', 'solid works', 'creo', 'pro-e', 'electronics engineering', 'digital transformation', 'gd']",2025-06-12 06:33:05
MDM Data Scientist,Amgen Inc,4 - 9 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nWe are seeking an accomplished and visionary Data Scientist/ GenAIdeveloper to join Amgens Enterprise Data Management team. As part of MDM team, you will be responsible for designing, developing, and deploying Generative AI and ML models to power data-driven decisions across business domains. This role is ideal for an AI practitioner who thrives in a collaborative environment and brings a strategic mindset to applying advanced AI techniques to solve real-world problems.\nTo succeed in this role, the candidate must have strong AI/ML, Data Science, GenAI experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have AI/ML, data science and GenAI experience on technologies like (PySpark/PyTorch, TensorFlow, LLM, Autogen, Hugging FaceVectorDB,Embeddings, RAGsetc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nDevelop enterprise-level GenAI applications using LLM frameworks such as Langchain, Autogen, and Hugging Face.\nDesign and develop intelligent pipelines using PySpark, TensorFlow, and PyTorch within Databricks and AWS environments.\nImplement embedding models andmanage VectorStores for retrieval-augmented generation (RAG) solutions.\nIntegrate and leverage MDM platforms like Informatica and Reltio to supply high-quality structured data to ML systems.\nUtilize SQL and Python for data engineering, data wrangling, and pipeline automation.\nBuild scalable APIs and services to serve GenAI models in production.\nLead cross-functional collaboration with data scientists, engineers, and product teams to scope, design, and deploy AI-powered systems.\nEnsure model governance, version control, and auditability aligned with regulatory and compliance expectations.\nBasic Qualifications and Experience:\nMasters degree with 4 - 6 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 6 - 9 years of experience in Business, Engineering, IT or related field OR\nDiploma with 10 - 12 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n6+ years of experience working in AI/ML or Data Science roles, including designing and implementing GenAI solutions.\nExtensive hands-on experience with LLM frameworks and tools such as Langchain, Autogen, Hugging Face, OpenAI APIs, and embedding models.\nStrong programming background with Python, PySpark, and experience in building scalable solutions using TensorFlow, PyTorch, and SK-Learn.\nProven track record of building and deploying AI/ML applications in cloud environments such as AWS.\nExpertise in developing APIs, automation pipelines, and serving GenAI models using frameworks like Django, FastAPI, and DataBricks.\nSolid experience integrating and managing MDM tools (Informatica/Reltio) and applying data governance best practices.\nGuide the team on development activities and lead the solution discussions\nMust have core technical capabilities in GenAI, Data Science space\nGood-to-Have Skills:\nPrior experience in Data Modeling, ETL development, and data profiling to support AI/ML workflows.\nWorking knowledge of Life Sciences or Pharma industry standards and regulatory considerations.\nProficiency in tools like JIRA and Confluence for Agile delivery and project collaboration.\nFamiliarity with MongoDB, VectorStores, and modern architecture principles for scalable GenAI applications.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nData Science and ML Certification\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'GenAI', 'Langchain', 'PySpark', 'Hugging Face', 'OpenAI API', 'Autogen', 'PyTorch', 'Django', 'MDM', 'FastAPI', 'Data Modeling', 'ETL', 'TensorFlow', 'Python']",2025-06-12 06:33:08
Sr Staff Video Codec Systems Engineer,Qualcomm,15 - 20 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nResponsibilities:\n\nPart of video IP systems team and will be responsible for video technology roadmap ; interaction with different teams including design, verification, system, firmware, software, SOC and power teams; video algorithms, image quality analysis; video processing and compression trends with standardization committees.\n\nQualcomm is the innovation leader in the area of integrated chipsets that power advanced mobile devices, XR/IoT/Automotive & compute platforms. We are building on and expanding our reputation as the industry powerhouse for innovation in both wireless technologies and enabling advanced multimedia capabilities. We are seeking experienced system engineers for our cutting-edge efforts in the architecture and design of our video codec hardware. The video Systems group provides video solutions on all of Qualcomms Snapdragon mobile processors. The teams scope includes video processing algorithms and IP architecture design for video compression, visual signal processing and analytics, with power and performance optimization.\n\nThe selected candidate, along with his/her colleagues and other team members, will have responsibilities in one or more of the following areas:\n\nDesigning and evaluating video algorithms to be implemented in hardware video encoders and decoders .\n\nDefine systems architecture for video solutions including data flow, task partition, interface and systems interoperation.\n\nImplement models to accurately model the HW (functional, performance), and supporting HW verification & SW development via behavioral model vectors .\n\nCollaborate with systems, software, hardware teams at various stages of chipset life in design/validation/commercialization.\n\nResearch and develop video algorithms for mobile, automotive, compute and VR/AR applications with performance and power efficiency.\n\n\nMinimum Qualifications:\n\nMasters degree in Electrical/Electronics Engineering, Computer Science, or related field and 15+ years of systems engineering experience\n\nPhD in Electrical/Electronics Engineering, Communications - Signal Processing, Computer Science, or related field and 12+ years of systems engineering experience\n\nKnowledge & Experience in video coding standards such as VVC, AV1, HEVC, H.264/AVC, VP9.\n\nHands on Knowledge & Experience in Video Codec Design and implementation with in-depth understanding of codec algorithms and flow\n\nSolid C/C++ programming, Python scripting skills.\n\nStrong communication skills\n\nGood analytical and problem solving skills.\n\n\nPreferred Qualifications:\n\nHW C modeling experience\n\nImage quality evaluation and metric comparisons\n\nSignal / Image processing basicsComputer Vision and Machine Learning algorithms for Video Compression and Video/Image processing.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 8+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 7+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 6+ years of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['algorithms', 'c++', 'system engineering', 'python', 'c', 'dsp', 'cuda', 'vod', 'dvb', 'embedded systems', 'linux', 'hevc', 'data structures', 'multithreading', 'ffmpeg', 'stb', 'image processing', 'matlab', 'video codecs', 'machine learning', 'ott', 'av', 'mpeg', 'computer vision', 'embedded c', 'h264', 'vp']",2025-06-12 06:33:10
Principal Engineer Software Developer,Indian / Global Engineering & Manufactur...,9 - 14 years,Not Disclosed,['Manesar'],"Key Skills: Embedded Software Development, C++, Microcontroller, Embedded C, Automotive embedded, LIN, CAN, CANalyzer\nRoles and Responsibilities:\nResponsible for Automotive Embedded Technology Product like ECU, TCU, Controllers, On/Off board charger based Embedded Electronics like Analog, Digital, MCU, Sensors, Power Supplies and Power Electronics\nSoftware requirement understanding and product architecture.\nSoftware flaw less launch of product/Product life cycle management, align with group Goals.\nDevelops new function/module, contribute for new process development/tailoring existing process.\nResponsible for software development, design documents and test setup.\nAlign hardware test activities to meet Product Development Process schedules using best practices and tools.\nTesting automation and maintaining manual documentation regression suites for Part components for Software releases.\nParticipating in project team discussions on product design and presenting test results to development teams and management.\nContributing in a meaningful way to team goals and initiatives to increase quality and efficiency of software test processes.\nSkills Required:\nTechnical/Functional Competencies Embedded Software/Hardware:\nHands-on experience in application software and embedded software in automotive application.\nExperience in digital controls and interfaces like PID/ PWM timers/LCD/EEPROM/interface of sensors for volt, current, and temperature etc.\nwork experience in Embedded C/C++.\nMust have worked on 8 bit, 16bit, 32bit, Renesas, Cypress, Fujitsu, ARM M0/M1/M2/M3/M4 microcontrollers.\nPreferable if candidate has worked on Renesas microcontrollers.\nWork experience on PWM Timer and controls, LCD interface, UART, ADC, DAC, PGA, DMA, GPIO, Interrupts handling, Exception handling, WatchDog Timer, Software Timers/UART etc.\nMust have hands-on experience in communication protocols like LIN, CAN, I2C, SPI, UART, RS232, RS485.\nFirmware debugging experience with JTAG, Single wire debug interface, RS232, UART.\nUnderstanding of IVN Network, UDS, KWP2000, IO vehicle test.\nHands on Toll like CANalyser, CANoe, CAPL scripting etc.\nShould have ability to create test cases for Embedded C code and design documents.\nTechnical/Functional Competencies Hardware:\nExperience in writing/Software debugging, Software Compliance Standard\nInterpret test cases as per the OEM test case with relevant test standards.\nGood organizational and communication skills.\nAbility to work effectively with cross-functional teams and suppliers.\nA knowledge of Controller Area Network CAN and LIN communications protocols\nEducation: Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field",Industry Type: Electronics Manufacturing,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Embedded C', 'C++', 'Microcontroller', 'Automotive embedded', 'Embedded Software Development', 'LIN', 'CAN', 'CANalyzer']",2025-06-12 06:33:12
WLAN Test- Staff/ Sr Staff/ Principal Engineer,Qualcomm,6 - 11 years,Not Disclosed,['Chennai'],"Job Area: Engineering Group, Engineering Group > Systems Test Engineering\n\nGeneral Summary:\n\nYou will join the System Test team that is responsible for defining and implementing the overall testing strategy for WiFi & Networking access points. This involves development of test plans, tools and automation framework for validating and qualifying the WiFi routers. You will work closely with systems team, development, and architecture team to understand the features and define test plans and solutions needed to deliver production grade software/firmware to the end customer.\n\nYou will be collaborating with a variety of internal teams in Qualcomm covering multiple engineering disciplines including software, systems, and hardware. The successful applicant should have a diverse skill set and a strong background in continuous testing and automation strategies\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Systems Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Systems Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Test Engineering or related work experience.\n\nResponsibilities:\n\nMust be responsible for analyzing new feature and develop/create new test plans and adding new test cases\n\nManage Infrastructure, develop test topologies and prepare use cases for validation\n\nWork with cross functional teams for supporting end-to-end release\n\nDirects small team of engineers on gathering, integrating, and interpreting information from a variety of sources in-order to troubleshoot issues and find solutions.\n\nDevelop the right skill and train the team. Serves as a mentor to Engineers and Senior Engineers and teaches them about complex features, systems, testing strategies, and automation.\n\nConduct log analysis with team members to identify where an issue has occurred and makes recommendations for how to address the issue.\n\nNetworks with colleagues within own domain to gain insight, ideas, and connections. Shares information with peers and junior engineers.\n\nCollaborates with functional and lab teams, IO teams, network operators, field teams, and product management teams to ensure that the testing plan is accurate for addressing feature issues.\n\nMinimum Qualifications\n\nBachelor's or Masters degree in Engineering, Information Systems, Computer Science, Electronics & communications or related field.\n\n15+ years in WiFi/Networking Test, automation or Software Engineering\n\nExperience with Programming Language such as Python, Shell Script (optional)\n\nRequired Skills and Aptitudes\n\nShould possess strong knowledge in WLAN/networking and manual testing of networking products\n\nMust have good experience in testing of layer-2 to layer 7 protocols\n\nPossess high Debugging capability\n\nStrong problem-solving skills\n\nAbility to prioritize and execute tasks across multiple projects with tight deadlines and aggressive goals.\n\nExperience in scripting languages like python (optional)\n\nExperience in shell scripting and windows batch commands (optioinal)\n\nExcellent English communication (written and verbal) and interpersonal skills",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software testing', 'manual testing', 'networking', 'networking products', 'layer 2', 'python', 'regression testing', 'automation testing', 'functional testing', 'test engineering', 'wlan testing', 'linux', 'test planning', 'debugging', 'software engineering', 'shell scripting']",2025-06-12 06:33:15
"Machine Learning, Technical Lead - NLP / LLM",Avalara Technologies,6 - 10 years,Not Disclosed,[],"What You'll Do\nWe are looking for experienced Machine Learning Engineers with a background in software development and a deep enthusiasm for solving complex problems. You will lead a dynamic team dedicated to designing and implementing a large language model framework to power diverse applications across Avalara.\nYour responsibilities will span the entire development lifecycle, including conceptualization, prototyping and delivery of the LLM platform features. You will build core agent infrastructureA2A orchestration and MCP-driven tool discoveryso teams can launch secure, scalable agent workflows. You will be reporting to Senior Manager, Machine Learning",,,,"['Machine Learning', 'NLP', 'Docker', 'Terraform', 'MLFlow', 'Prometheus', 'LLM', 'AWS', 'Grafana', 'GitLab', 'Kubernetes']",2025-06-12 06:33:17
Automotive cybersecurity engineer Sr/Staff,Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Hardware Engineer, you will plan, design, optimize, verify, and test electronic systems, bring-up yield, circuits, mechanical systems, Digital/Analog/RF/optical systems, equipment and packaging, test systems, FPGA, and/or DSP systems that launch cutting-edge, world class products. Qualcomm Hardware Engineers collaborate with cross-functional teams to develop solutions and meet performance requirements.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\n\n\nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in. systems architecture.ADAS/Autonomy/Infotainment Qualcomm is utilizing its traditional strengths in digital wireless technologies to play a central role in the evolution of automotive infotainment and autonomous driving. We are investing in several supporting technologies including 4G, 5G, ADAS, and Deep Learning. The Qualcomm Automotive Security team is engaged in offering optimized solutions built on Safety CPU cores, DSP, computer vision and machine learning algorithms for the Qualcomm\n\nWe are seeking engineers with experience in system and SoC level automotive cybersecurity concepts and implementations and knowledge of the ISO21434 cyber security standards and process. This position will be a hands-on role in in analyzing and improving the current cybersecurity hardware development process to meet ISO 21434. Candidate must have thorough knowledge on ISO 21434 and ISO 26262 standards to independently perform functional safety and cybersecurity audits and assessments.\n\nResponsibilities shall include the following\n\nDevelopment/ enhancement of hardware development process and related work products meeting cyber security standards.\n\nProvide training on ISO 21434/ ISO 26262 with respect to application of Qualcomms best practices.\n\nFacilitate TARA and VARA and review them\n\nIndependently carry out cybersecurity audits and assessments, guiding the hardware design and development teams in the process. Provide feedback and identify process improvements and follow up with internal teams.\n\nWork closely with SoC Design and IP teams, 3rd party IP vendors, Software team, the functional safety and cybersecurity manager(s), Quality team as well as customers to ensure the defined process is deployed.\n\nParticipate in external and customer cybersecurity and functional safety audits and assessments and assist in corrective actions.\n\nMaintain a strong knowledge of Automotive Industry cybersecurity best practices. Influence internal stakeholders with actionable data to ensure gaps to expectations are closed in a timely fashion.\n\nEstablish and maintain healthy relationships with influential/decision making on Cybersecurity, Functional Safety, and ongoing Quality assessments throughout the organization.\n\nFacilitate in qualitative and quantitative safety analyses and review of them.\n\nMinimum Qualifications\n\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.\n\n8+ years Systems Engineering / VLSI design or related work experience.\n\nHas knowledge of product development flow and validation.\n\nHas led audits of different development processes and is comfortable with assessments and reporting Quality metrics.\n\nHands-on experience with automotive quality processesISO 21434, ISO 26262, TARA, VARA, DFMEA, FTA, FMEDA, 8D, quality agreements, PCNs / EOLs, customer audits, AEC- Q100 requirements, ISO9001, IATF 16949, etc.\n\nStructured problem-solving capability and ability to work with teams on root cause analyses.\n\nExcellent verbal/written communication, interpersonal skills, and presentation skills",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['vlsi design', 'presentation skills', 'hardware engineering', 'dfmea', 'system engineering', 'matlab', 'c++', 'python', 'c', 'hiring', 'networking', 'vhdl', 'verilog', 'staffing', 'talent acquisition', 'technical support', 'recruitment', 'desktop engineering', 'embedded systems', 'desktop support']",2025-06-12 06:33:19
WiFi Connectivity - Sr Staff/ Principal Engineer,Qualcomm,15 - 20 years,Not Disclosed,['Chennai'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\nMinimum 15 yrs in SW Engineering life cycle.\nMinimum 10 yrs in SW engineering roles that covers SW development and test.\nStrong technology focus and experience in networking technology areas that include WLAN, Ethernet, Bridging and Routing.\nStrong understanding SW architecture and real time embedded system design with Linux Operating System\nExperience in detailed planning, reporting, defining and managing engineering / technology metrics\nDecisive and ability to quickly identify problems & make decisions to solve them.\nStrong interpersonal and communication skills\nOwnership of commercialization of the key Wi-Fi access point products\nTechnical product owner of the releases responsible of driving all technology areas to deliver world class AP and Wi-Fi Routers\nPrimary technology and commercialization interface with product management and engineering teams\nEnd to End ownership to drive programs from start to the post launch in the field.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience.\n\n3+ years of work experience with Programming Language such as C, C++, Java, Python, etc.\nExperience in managing programs & meets required program specifications with required quality, content & cost\nGlobal program management experience across geos\nWorking with cross geo teams in US and China\nCustomer interactions and Product Marketing interfacing experience",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'linux', 'software engineering', 'sw', 'embedded system design', 'switching', 'eigrp', 'networking', 'routing', 'java', 'rtos', 'computer science', 'embedded systems', 'lan', 'pcb designing', 'arm', 'tcp', 'matlab', 'python', 'c', 'software testing', 'ospf', 'ethernet', 'embedded c', 'microsoft windows', 'ccna']",2025-06-12 06:33:22
Process Associate- Invoice To Cash,Genpact,0 - 3 years,Not Disclosed,['Jodhpur'],"Ready to shape the future of work?\nAt Genpact, we don't just adapt to changewe drive it. AI and digital innovation are redefining industries and wereleading the charge. Genpact’s AI Gigafactory, our industry-first accelerator,is an example of how advanced technology solutions were scaling to help globalenterprises work smarter, grow faster, and transform at scale. From large-scalemodels to agentic AI, our breakthrough solutions tackle companies’ most complexchallenges.\nIf you thrive in a fast-moving, tech-drivenenvironment, love solving real-world problems, and want to be part of a teamthat’s shaping the future, this is your moment",,,,"['accounts receivable', 'law', 'verbal communication', 'interpersonal skills', 'pay', 'hrsd', 'accounting', 'order to cash', 'cash applications', 'reconciliation', 'technology solutions', 'artificial intelligence', 'operations', 'automation', 'recruitment', 'writing', 'english', 'operational excellence']",2025-06-12 06:33:24
Automotive Platform - Engineer Sr.,Qualcomm,3 - 8 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nQualcomm ADAS/Autonomy team is engaged in offering optimized solutions built on DSP, computer vision and machine learning algorithms for the Qualcomm ADAS/Autonomy SoCs. We are seeking engineers with experience in system and SoC SW level functional safety concepts. The job requires understanding and defining of the Safety Concept and Architecture, Software Safety requirements, defining and deploying safety processes and development of Safety software by following the ISO26262 software processes. Interaction with customers, architects and test/integration teams are required as part of the job. The job also involves working with the Software quality team for adherence of ISO26262 and ASPICE processes.\n\nIn this role, the candidate will work with local and global teams to understand, define and implement and productize Automotive specific features including software enablement (drivers/BSP/RTOS/AUTOSAR MCAL), security, functional safety, and power applied to Automotive products on our current and next generation SoCs. The candidate will also have the responsibility to coordinate and execute plans which will encompass validation of all the feature requirements. The Candidate will have the responsibility to identify and address any abnormal discoveries by root-causing and providing detailed corrective actions in the form of optimizations and/or fixes. When possible, the candidate is expected to prototype and pre-validate recommended fixes. Additionally, the candidate will be responsible for any automation of design under test along with validation efforts and working closely with design/production/bench IP teams.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\n\n 3-6 years of Embedded Software Development experience, including low level drivers, and RTOS \n\n The candidate should possess 3 to 6 years of industry experience in embedded software driver development and having expertise in one or more below areas would be preferred: \n\n Should be able to ramp up fast and must have the attitude to work with the team. \n\n Strong C and Assembly Programming with OS & Multi-Processor concepts \n\n Embedded software development in C and C++ on ARM or similar cores. \n\n Hands on experience of driver development on any RTOS, \n\n Experience in SafeRTOS/FreeRTOS based development is nice to have \n\n Experience in Autosar MCAL development is nice to have \n\n Experience in Autosar BSW integration and validation is nice to have \n\n ARM Trust-Zone & ARMv7/v8 architecture. \n\n Good debugging skills with experience on debugging with Lauterbach JTAG debuggers. \n\n Work on challenging customer requirements and issues. \n\n Basic understanding one or more of hardware blocks - Clocks, PLLs, GPIO, Interrupt Controllers (GIC), Peripherals (SPI/I2C/UART/CAN/Ethernet/Clock/etc)  \n\n Automotive SW development experience is must have \n\n Experience in ISO26262/functional safety and ASPICE is highly desirable \n\n Basic knowledge on Power Mgmt. IC is desirable \n\n Knowledge of Software/Hardware Security concepts is desirable \nClosely work with the hardware team to contribute/suggest modifications to the hardware design.\nAny past working experience on Qualcomm chips nice to have",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['assembly programming', 'c', 'sw', 'embedded software development', 'embedded software', 'aspice', 'python', 'c++', 'canoe', 'spi', 'freertos', 'autosar', 'mcal', 'rtos', 'java', 'embedded systems', 'embedded c', 'uart', 'debugging', 'software engineering', 'ic', 'i2c', 'can bus', 'functional safety']",2025-06-12 06:33:27
Data Scientist IV - Python / LLM,Sadup Soft,6 - 8 years,Not Disclosed,['Hyderabad'],"Must have skills :\n\n- 6+ Years of Experience.\n\n- Statics, SQL, Big query, LLM, AI, Python\n\n- Work experience in the payments, ecommerce, or financial services industry is a plus .\n\nResponsibilities :\n\n- At least 6 years of experience analyzing large, multi-dimensional data sets and synthesizing insights into actionable solutions\n\n- Bachelor's/Master's degree in a quantitative field (such as Analytics, Statistics, Mathematics, Economics or Engineering) or equivalent field experience\n\n- Advanced SQL experience, preferable with Big Query analytics (Google Cloud) on Jupyter Notebooks and experience analyzing very large, complex, multi-dimensional data sets.\n\n- Understanding of statistics (e.g hypothesis testing, statistical inference, regression) and experience designing and evaluating complex experiments-\n\n- Ability to solve problems analytically and create actionable recommendations\n\n- Advanced ability to use reporting tools like Tableau and/or Excel to share analysis\n\n- Strong written and verbal communication skills with the ability to translate complex problems into simpler terms, expertise in stitching together findings to convey coherent insights and effectively influence both peers and senior leadership\n\n- Prior work experience in a product analytics space would be highly valued\n\n- A passion for problem-solving and comfort with ambiguity\n\n- Work experience in the payments, ecommerce, or financial services industry is a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Data Science', 'BigQuery', 'Data Management', 'Jupyter', 'LLM', 'Statistics']",2025-06-12 06:33:29
RTL Design - Sr Staff/ Principal Engineer,Qualcomm,15 - 20 years,Not Disclosed,['Chennai'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n15+ years of experience in SoC design\nShould have knowledge of AMBA protocols - AXI, AHB, APB, SoC clocking/reset/debug architecture and peripherals like USB, PCIE and SDCC.\nUnderstanding of Memory controller designs and microprocessors is an added advantage\nHands on experience in constraint development and timing closure\nWork closely with the SoC verification and validation teams for pre/post Silicon debug\nHands on experience in Low power SoC design is required\nExperience in Synthesis / Understanding of timing concepts for ASIC is required.\nHands on experience in Multi Clock designs, Asynchronous interface is a must.\nExperience in using the tools in ASIC development such as Lint, CDC, Design compiler and Primetime is required\n\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 6+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 5+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\n12+ years of experience with a Bachelor's/ Masters degree in Electrical/ Electronics engineering",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['asynchronous', 'soc design', 'asic development', 'hardware engineering', 'lint', 'soc verification', 'usb', 'soc', 'amba', 'apex', 'salesforce', 'design compiler', 'apb', 'rtl design', 'axi', 'ahb', 'microprocessors', 'protocols', 'synthesis', 'asic', 'cdc', 'primetime', 'rtl', 'verilog', 'silicon', 'timing closure', 'pcie']",2025-06-12 06:33:32
Lead Engineer - App F/W&MW - Linux,Sasken Technologies,5 - 8 years,Not Disclosed,['Bengaluru'],"Job Summary\nPerson at this position takes ownership of a module and associated quality and delivery. Person at this position provides instructions, guidance and advice to team members to ensure quality and on time delivery.\nPerson at this position is expected to be able to instruct and review the quality of work done by technical staff.\nPerson at this position should be able to identify key issues and challenges by themselves, prioritize the tasks and deliver results with minimal direction and supervision.\nPerson at this position has the ability to investigate the root cause of the problem and come up alternatives/ solutions based on sound technical foundation gained through in-depth knowledge of technology, standards, tools and processes.\nPerson has the ability to organize and draw connections among ideas and distinguish between those which are implementable.\nPerson demonstrates a degree of flexibility in resolving problems/ issues that atleast to in-depth command of all techniques, processes, tools and standards within the relevant field of specialisation.\n\n\nRoles & Responsibilities\nResponsible for requirement analysis and feasibility study including system level work estimation while considering risk identification and mitigation.\nResponsible for design, coding, testing, bug fixing, documentation and technical support in the assigned area. Responsible for on time delivery while adhering to quality and productivity goals.\nResponsible for traceability of the requirements from design to delivery Code optimization and coverage.\nResponsible for conducting reviews, identifying risks and ownership of quality of deliverables.\nResponsible for identifying training needs of the team.\nExpected to enhance technical capabilities by attending trainings, self-study and periodic technical assessments.\nExpected to participate in technical initiatives related to project and organization and deliver training as per plan and quality.\nExpected to be a technical mentor for junior members.\nPerson may be given additional responsibility of managing people based on discretion of Project Manager.\nEducation and Experience Required\nEngineering graduate, MCA, etc Experience: 5-8 years\n\nCompetencies DescriptionApplication Protocol & Engines - Linux engineer is one:\nwho has done one or more of the following on Embedded Linux\ndesign, development/customization, bug fixing/sustenance\nwho has experience in one or more of the following domains\nMultimedia\nTelephony\nConnectivity\nSensor\nSecurity\nPlatforms-\nMandatory to have worked on one or more of the following:\nEmbedded Linux\nTools-\nMandatory to have worked on one or more of the following;\ngdb/ddd; linux editors; top; ps; meminfo\nLanguages-\nMandatory to have worked on one or more of the following;\nC; C++\nSpecialization-\nMULTIMEDIA, CONNECTIVITY, TELEPHONY, CARRIER GRADE PLATFORM, GENERIC FRAMEWORK",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['LINUX', 'Unix', 'R', 'SAS', 'Scala', 'Perl', 'SPSS', 'Machine Learning', 'Python']",2025-06-12 06:33:34
Artificial Intelligence Intern,Kumaran Systems,0 - 1 years,4.5-5 Lacs P.A.,['Chennai( Siruseri Sipcot IT Park )'],"We are looking for a passionate and motivated AI Developer Fresher to join our growing AI team. This role will focus on Generative AI (GenAI) technologies such as large language models (LLMs), diffusion models, and other cutting-edge machine learning techniques.\n\nAs a fresher, youll work closely with senior AI engineers and data scientists to build and fine-tune generative models, contribute to prompt engineering, and support model integration into real-world applications.",,,,"['Data Science', 'Mechine Learning', 'Artificial Intelligence', 'GEN AI', 'Python']",2025-06-12 06:33:37
Deep Learning Research Engineer (Vision & Audio Focus),HIREXpert,4 - 7 years,15-20 Lacs P.A.,"['Bhubaneswar', 'Bengaluru']","Strong programming skills in Python, with experience in PyTorch or TensorFlow.\nHands-on experience with CNNs\nSolid knowledge of Vision Transformers, including recent architectures (e.g., Swin, DeiT).\nYOLO, SSD, Faster R-CNN, RetinaNet, DETR\n\nRequired Candidate profile\nExperience in video analysis and temporal modeling.\nStrong grasp of audio classification workflows and features.\nlarge-scale datasets and designing data pipelines.",Industry Type: Medical Services / Hospital (Diagnostics),Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Pytorch', 'Deep Learning', 'Deep Learning Frameworks', 'Research And Development', 'Machine Learning', 'Python']",2025-06-12 06:33:39
Senior ML Compiler Engineer,Qualcomm,2 - 4 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nInterested in accelerating machine learning and artificial intelligence on mobile devices for millions of usersCome join our team. We are building software platforms that enable users of Qualcomms silicon to construct optimized neural networks and machine learning algorithms. We are looking for software engineers with a machine learning or compiler background who will help us build these software platforms. In this role, you will construct and tune machine learning frameworks, build compilers and tools, and collaborate with Qualcomm hardware and software engineers to enable efficient usage of Qualcomms silicon for machine learning applications.\n\nMinimum qualifications:\nBachelors degree in Engineering, Information Systems, Computer Science, or related field.\nProgramming in C/C++\n2 to 4 years of software engineering or related work experience\n\n\nPreferred qualifications:\nExperience in machine learning frameworks such as MxNet/NNVM/TVM, Pytorch, Tensorflow, Caffe\n\nOR experience in compilers with an interest in machine learning\nDeep knowledge of software engineering\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'software engineering', 'algorithms', 'c++', 'natural language processing', 'caffe', 'neural networks', 'mxnet', 'artificial intelligence', 'sql', 'deep learning', 'r', 'java', 'data science', 'computer vision', 'machine learning algorithms', 'ml']",2025-06-12 06:33:41
Data Engineer,Xenonstack,2 - 5 years,Not Disclosed,['Mohali( Phase 8B Mohali )'],"At XenonStack, We committed to become the Most Value Driven Cloud Native, Platform Engineering and Decision Driven Analytics Company. Our Consulting Services and Solutions towards the Neural Company and its Key Drivers.\nXenonStacks DataOps team is looking for a Data Engineer who will be responsible for employing techniques to create and sustain structures that allow for the analysis of data while remaining familiar with dominant programming and deployment strategies in the field.\nYou should demonstrate flexibility, creativity, and the capacity to receive and utilize constructive criticism. The ideal candidate should be highly skilled in all aspects of Python, Java/Scala, SQL and analytical skills.\nJob Responsibilities:\nDevelop, construct, test and maintain Data Platform Architectures\nAlign Data Architecture with business requirements\nLiaising with co-workers and clients to elucidate the requirements for each task.\nScalable and High Performant Data Platform Infrastructure that allows big data to be accessed and analysed quickly by BI & AI Teams.\nReformulating existing frameworks to optimize their functioning.\nTransforming Raw Data into InSights for manipulation by Data Scientists.\nEnsuring that your work remains backed up and readily accessible to relevant co-workers.\nRemaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.\nRequirements:\nTechnical Requirements\nExperience of Python, Java/Scala\nGreat Statistical / SQL based Analytical Skills\nExperience of Data Analytics Architectural Design Patterns for Batch, Event Driven and Real-Time Analytics Use Cases\nUnderstanding of Data warehousing, ETL tools, machine learning, Data EPIs\nExcellent in Algorithms and Data Systems\nUnderstanding of Distributed System for Data Processing and Analytics\nFamiliarity with Popular Data Analytics Framework like Hadoop , Spark , Delta Lake , Time Series / Analytical Stores Stores.\nProfessional Attributes:\nExcellent communication skills & Attention to detail.\nAnalytical mind and problem-solving Aptitude with Strong Organizational skills & Visual Thinking.\nBenefits:\nDiscover the benefits of joining our team:\nDynamic and purposeful work culture in a people-oriented organization contributing to multi-million-dollar projects with guaranteed job security.\nOpen, authentic, and transparent communication fostering a warm work environment.\nRegular constructive feedback and exposure to diverse technologies.\nRecognition and rewards for exceptional performance achievements.\nAccess to certification courses & Skill Sessions to develop continually and refine your skills.\nAdditional allowances for team members assigned to specific projects.\nSpecial skill allowances to acknowledge and compensate for unique expertise.\nComprehensive medical insurance policy for your health and well-being.\nTo Learn more about the company -\nWebsite - http://www.xenonstack.com/",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Hadoop', 'Spark', 'ETL', 'Python', 'SQL', 'Java', 'Data Processing', 'Machine Learning']",2025-06-12 06:33:43
Data Engineer,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"Role Description:\nAs part of the cybersecurity organization, In this vital role you will be responsible for designing, building, and maintaining data infrastructure to support data-driven decision-making. This role involves working with large datasets, developing reports, executing data governance initiatives, and ensuring data is accessible, reliable, and efficiently managed. The role sits at the intersection of data infrastructure and business insight delivery, requiring the Data Engineer to design and build robust data pipelines while also translating data into meaningful visualizations for stakeholders across the organization. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture, ETL processes, and cybersecurity data frameworks.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in design and development of the data pipeline.\nBuild data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nDevelop and maintain interactive dashboards and reports using tools like Tableau, ensuring data accuracy and usability\nSchedule and manage workflows the ensure pipelines run on schedule and are monitored for failures.\nCollaborate with multi-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nCollaborate with data scientists to develop pipelines that meet dynamic business needs.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\n\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of experience of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience\nPreferred Qualifications:\nHands on experience with data practices, technologies, and platforms, such as Databricks, Python, GitLab, LucidChart, etc.\nHands-on experience with data visualization and dashboarding toolsTableau, Power BI, or similar is a plus\nProficiency in data analysis tools (e.g. SQL) and experience with data sourcing tools\nExcellent problem-solving skills and the ability to work with large, complex datasets\nUnderstanding of data governance frameworks, tools, and best practices\nKnowledge of and experience with data standards (FAIR) and protection regulations and compliance requirements (e.g., GDPR, CCPA)\n\nGood-to-Have Skills:\nExperience with ETL tools and various Python packages related to data processing, machine learning model development\nStrong understanding of data modeling, data warehousing, and data integration concepts\nKnowledge of Python/R, Databricks, cloud data platforms\nExperience working in Product team's environment\nExperience working in an Agile environment\n\nProfessional Certifications:\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\n\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to handle multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data engineering', 'data analysis', 'data modeling', 'analysis tools', 'data warehousing', 'troubleshooting', 'data architecture', 'data integration', 'etl process']",2025-06-12 06:33:45
AI Engineer,HCLTech,10 - 14 years,Not Disclosed,['Noida'],"Seniority: Senior\nDescription & Requirements\nPosition Summary\nThe Senior AI Engineer with GenAI expertise is responsible for developing advanced technical solutions, integrating cutting-edge generative AI technologies. This role requires a deep understanding of modern technical and cloud-native practices, AI, DevOps, and machine learning technologies, particularly in generative models. You will support a wide range of customers through the Ideation to MVP journey, showcasing leadership and decision-making abilities while tackling complex challenges.",,,,"['AI engineering', 'VMware', 'Java', 'Azure', 'Data engineering', 'AI models', 'Node.js', 'NLP', 'Azure AKS', 'Machine Learning Operations', 'AWS', 'Kubernetes', 'Python']",2025-06-12 06:33:48
Business Analyst/ Data Scientist - SAS & SQL,Khushboo,3 - 8 years,10-20 Lacs P.A.,['Hyderabad'],"hands on SQL/ SAS programming experience & handling complex/large data\nMust have experience inTableau/Power BI\nExperience in campaign performance measurement, customer targeting framework\nProven ability to design and lead strategic projects\n\nRequired Candidate profile\nMust - SAS , SQL, Python\nGood in Statistical model , Predictive model, Logistic regression, Linear regression\nBFSI Mandatory - Credit risk, Credit Card, Retail Banking",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Decision Tree', 'sas', 'sql', 'Advanced Analytics', 'Strategy Building', 'Predictive Modeling', 'python', 'Logistic Regression', 'Segmentation', 'Random Forest', 'Linear Regression', 'Classification', 'Statistical Modeling', 'Credit Risk']",2025-06-12 06:33:51
Business Development Executive // Naukri,Info Edge,0 - 1 years,6-10 Lacs P.A.,"['Hyderabad', 'Chennai', 'Coimbatore']","About Info Edge India Ltd\n\nInfo Edge is Indias leading consumer internet company known for its strong brands in recruitment (naukri.com, naukrigulf.com, iimjobs.com, firstnaukri.com), real estate (99acres.com), matrimony (Jeevansathi.com) and education (shiksha.com).\n\nStarting with a classified recruitment online business, naukri.com, the Company has grown and diversified rapidly, setting benchmarks as a pioneer for others to follow either through setting up of in-house brands or through the route of strategic investments and acquisitions. Zomato.com, policybazaar.com & Happily Unmarried Marketing Private Limited are our investee companies to name a few out of many. With years of experience in the domain, strong cash flow generation and a diversified business portfolio, Info Edge is one of the very few profitable pure play internet companies in the country.\n\nThese are exciting times for Info Edge as we continue to grow in all our businesses, and continue to scale newer heights. We are investing across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI) to increase our predictive powers on customer behavior and continuously optimize and improve our systems.\n\nAt Info Edge, people are our core competitive advantage and we will continue doing all that is needed to attract and retain the best available talent. Driven by innovation, an experienced and talented leadership team and a strong entrepreneurial orientation, we pride ourselves on having a culture that promotes meritocracy. Our numerous milestones can largely be credited to an incredibly smart team working in an environment that encourages creativity and going the extra mile to develop products that people love to use and add value to our clients.\n\n\nNaukri.com, online recruitment classifieds, is a significant player and a market leader in Indias well-established business space. The recruitment space provides all the job seeker with advisory services and caters to different elements of the job listing, employer branding, resume short-listing, career site management and campus recruitment. With over 67 Million resumes searches daily, Naukri.com has 5 Million job listings, 59 Thousand+ unique clients and 4.9 Million recruiters connect with the job seekers via emails.\nThe platform, on the online recruitment space, continues to reinforce its established leadership position in India that has given it a competitive edge in the market.\n\n\nThis role has been developed to oversee the relationships of the region with few of its most important clients. You will be responsible for obtaining and maintaining long term key customers by comprehending their requirements.\n\nThe ideal candidate will be skillful in building strong relationships with strategic customers. You will be able to identify needs and requirements to promote our companys solutions and achieve the clients objectives to mutual benefit.\n\nThe goal is to contribute in sustaining and growing our business to achieve long-term success.",,,,"['B2B SALES', 'Business Development', 'Verbal And Written', 'Lead Generation', 'Corporate Sales']",2025-06-12 06:33:53
Data Science_ Lead,Rishabh Software,8 - 13 years,Not Disclosed,"['Ahmedabad', 'Bengaluru', 'Vadodara']","Job Description\n\nWith excellent analytical and problem-solving skills, you should understand business problems of the customers, translate them into scope of work and technical specifications for developing into Data Science projects. Efficiently utilize cutting edge technologies in AI, Generative AI areas and implement solutions for business problems. Good exposure technology platforms for Data Science, AI, Gen AI, cloud with implementation experience. Ability to provide end to end technical solutions leveraging latest AI, Gen AI tools, frameworks for the business problems. This Job requires the following:",,,,"['Data Science', 'gen ai', 'Computer Vision', 'Machine Learning', 'Deep Learning', 'Tensorflow', 'NLP', 'Artificial Intelligence', 'Dl', 'Python']",2025-06-12 06:33:55
Manager Data Science,Optum,12 - 17 years,Not Disclosed,['Noida'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by diversity and inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health equity on a global scale. Join us to start  Caring. Connecting. Growing together. \n\nAt Optum AI, we leverage data and resources to make a significant impact on the healthcare system. Our solutions have the potential to improve healthcare for everyone. We work on cutting-edge projects involving ML, NLP, and LLM techniques, continuously developing and improving generative AI methods for structured and unstructured healthcare data. Our team collaborates with world-class experts and top universities to develop innovative AI/ML solutions, often leading to patents and published papers.\n\n Primary Responsibilities \nDevelop and implement AI and machine learning strategies for several healthcare domains\nCollaborate with cross-functional teams to identify and prioritize AI and machine learning initiatives\nManage the development and deployment of AI and machine learning solutions\nDevelop and run pipelines for data ingress and model output egress\nDevelop and run scripts for ML model inference\nDesign, implement, and maintain CI/CD pipelines for MLOps and DevOps functions\nIdentify technical problems and develop software updates and fixes\nDevelop scripts or tools to automate repetitive tasks\nAutomate the provisioning and configuration of infrastructure resources\nProvide guidance on the best use of specific tools or technologies to achieve desired results\nCreate documentation for infrastructure design and deployment procedures\nUtilize AI/ML frameworks and tools such as MLFlow, TensorFlow, PyTorch, Keras, Scikit-learn, etc.\nLead and manage AI/ML teams and projects from ideation to delivery and evaluation\nApply expertise in various AI/ML techniques, including deep learning, NLP, computer vision, recommender systems, reinforcement learning, and large language models\nCommunicate complex AI/ML concepts and results to technical and non-technical audiences effectively\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\n Required Qualifications: \nBachelors/master degree in computer science, engineering, mathematics, statistics, or a related discipline\n12+ years of experience in Software Engineering, Data Science, or Analytics with 8+ years of experience in AI/ML engineering or related fields\nExperience with cloud platforms and services, such as AWS, Azure, GCP, etc.\nExperience in developing solutions in the NLP space and relevant projects\nHands on Experience in AI and drive the development of innovative AI and machine learning solutions\nDemonstrated experience in leading and managing AI/ML teams and projects, from ideation to delivery and evaluation\nExperience with Azure development environments\nKnowledge of NLP literature, thrust areas, conference venues, and code repositories\nFamiliarity with both open-source and OpenAI LLMs and RAG architecture\nFamiliarity with UI tools like Streamlit, Flask, FAST APIs, Rest APIs, Docker containers\nUnderstanding of common NLP tasks such as text classification, entity recognition, entity extraction, and question answering\nProficient in Python and one of PySpark or Scala. Familiarity with python tools for data processing\nProficiency in multiple machine learning and AI techniques such as supervised, unsupervised, reinforcement learning, deep learning, and NLP\nProficiency in Python, R, or other programming languages for data analysis and AI/ML development\nProficiency in libraries such as Hugging Face and OpenAI API\nProven ability to develop and deploy data pipelines, machine learning models, or applications on cloud platforms (Azure, Databricks, AzureML)\nProven excellent communication, presentation, and interpersonal skills, with the ability to explain complex AI/ML concepts and results to technical and non-technical audiences\nProven solid analytical, problem-solving, and decision-making skills, with the ability to balance innovation and pragmatism\nProeven passion for learning and staying updated with the latest AI/ML trends and research",Industry Type: Retail,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'pyspark', 'machine learning', 'artificial intelligence', 'r', 'continuous integration', 'data analysis', 'scala', 'scikit-learn', 'presentation skills', 'ci/cd', 'microsoft azure', 'docker', 'tensorflow', 'data science', 'ai techniques', 'devops', 'pytorch', 'keras', 'software engineering', 'aws']",2025-06-12 06:33:58
"Data Engineer Openings at Advantum Health, Hyderabad",Advantum Health,3 - 5 years,Not Disclosed,['Hyderabad'],"Data Engineer openings at Advantum Health Pvt Ltd, Hyderabad.\nOverview:\nWe are looking for a Data Engineer to build and optimize robust data pipelines that support AI and RCM analytics. This role involves integrating structured and unstructured data from diverse healthcare systems into scalable, AI-ready datasets.\nKey Responsibilities:\nDesign, implement, and optimize data pipelines for ingesting and transforming healthcare and RCM data.\nBuild data marts and warehouses to support analytics and machine learning.\nEnsure data quality, lineage, and governance across AI use cases.\nIntegrate data from EMRs, billing platforms, claims databases, and third-party APIs.\nSupport data infrastructure in a HIPAA-compliant cloud environment.\nQualifications:\nBachelors in Computer Science, Data Engineering, or related field.\n3+ years of experience with ETL/ELT pipelines using tools like Apache Airflow, dbt, or Azure Data Factory.\nStrong SQL and Python skills.\nExperience with healthcare data standards (HL7, FHIR, X12) preferred.\nFamiliarity with data lake house architectures and AI integration best practices\nPh: 9177078628\nEmail id: jobs@advantumhealth.com\nAddress: Advantum Health Private Limited, Cyber gateway, Block C, 4th floor Hitech City, Hyderabad.\nDo follow us on LinkedIn, Facebook, Instagram, YouTube and Threads\nAdvantum Health LinkedIn Page:\nhttps://lnkd.in/gVcQAXK3\n\nAdvantum Health Facebook Page:\nhttps://lnkd.in/g7ARQ378\n\nAdvantum Health Instagram Page:\nhttps://lnkd.in/gtQnB_Gc\n\nAdvantum Health India YouTube link:\nhttps://lnkd.in/g_AxPaPp\n\nAdvantum Health Threads link:\nhttps://lnkd.in/gyq73iQ6",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'SQL', 'Python', 'Airflow', 'ETL', 'Elt']",2025-06-12 06:34:00
Data Engineer,Amgen Inc,1 - 6 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nAs part of the cybersecurity organization, the Data Engineer is responsible for designing, building, and maintaining data infrastructure to support data-driven decision-making. This role involves working with large datasets, developing reports, executing data governance initiatives, and ensuring data is accessible, reliable, and efficiently managed. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture, ETL processes, and cybersecurity data frameworks.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in design and development of the data pipeline.\nCreate data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nSchedule and manage workflows the ensure pipelines run on schedule and are monitored for failures.\nCollaborate with cross-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nCollaborate with data scientists to develop pipelines that meet dynamic business needs.\nShare and discuss findings with team members practicing SAFe Agile delivery model.\nFunctional Skills:\nBasic Qualifications:\nMasters degree and 1 to 3 years of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience\nPreferred Qualifications:\nHands on experience with data practices, technologies, and platforms, such as Databricks, Python, Gitlab, LucidChart,etc.\nProficiency in data analysis tools (e.g. SQL) and experience with data sourcing tools\nExcellent problem-solving skills and the ability to work with large, complex datasets\nUnderstanding of data governance frameworks, tools, and best practices\nKnowledge of and experience with data standards (FAIR) and protection regulations and compliance requirements (e.g., GDPR, CCPA)\nGood-to-Have Skills:\nExperience with ETL tools and various Python packages related to data processing, machine learning model development\nStrong understanding of data modeling, data warehousing, and data integration concepts\nKnowledge of Python/R, Databricks, cloud data platforms\nExperience working in Product team's environment\nExperience working in an Agile environment\nProfessional Certifications:\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\nSoft Skills:\nInitiative to explore alternate technology and approaches to solving problems\nSkilled in breaking down problems, documenting problem statements, and estimating efforts\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data engineering', 'data security', 'Agile', 'cloud data platforms', 'Databricks', 'data governance frameworks', 'ETL', 'AWS', 'SQL', 'Python']",2025-06-12 06:34:02
Enterprise Data Operations Manager,Pepsico,12 - 17 years,Not Disclosed,['Hyderabad'],"Overview\n\nDeputy Director - Data Engineering\n\nPepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCos global business scale to enable business insights, advanced analytics, and new product development. PepsiCos Data Management and Operations team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.\nIncrease awareness about available data and democratize access to it across the company.\nAs a data engineering lead, you will be the key technical expert overseeing PepsiCo's data product build & operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be empowered to create & lead a strong team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premises data sources as well as cloud and remote systems.\nResponsibilities\n\nData engineering lead role for D&Ai data modernization (MDIP)\n\nIdeally Candidate must be flexible to work an alternative schedule either on tradition work week from Monday to Friday; or Tuesday to Saturday or Sunday to Thursday depending upon coverage requirements of the job. The candidate can work with immediate supervisor to change the work schedule on rotational basis depending on the product and project requirements.\nResponsibilities\nManage a team of data engineers and data analysts by delegating project responsibilities and managing their flow of work as well as empowering them to realize their full potential.\nDesign, structure and store data into unified data models and link them together to make the data reusable for downstream products.\nManage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.\nCreate reusable accelerators and solutions to migrate data from legacy data warehouse platforms such as Teradata to Azure Databricks and Azure SQL.\nEnable and accelerate standards-based development prioritizing reuse of code, adopt test-driven development, unit testing and test automation with end-to-end observability of data\nBuild and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality, performance and cost.\nCollaborate with internal clients (product teams, sector leads, data science teams) and external partners (SI partners/data providers) to drive solutioning and clarify solution requirements.\nEvolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects to build and support the right domain architecture for each application following well-architected design standards.\nDefine and manage SLAs for data products and processes running in production.\nCreate documentation for learnings and knowledge transfer to internal associates.\nQualifications\n\n12+ years of engineering and data management experience\n\nQualifications\n12+ years of overall technology experience that includes at least 5+ years of hands-on software development, data engineering, and systems architecture.\n8+ years of experience with Data Lakehouse, Data Warehousing, and Data Analytics tools.\n6+ years of experience in SQL optimization and performance tuning on MS SQL Server, Azure SQL or any other popular RDBMS\n6+ years of experience in Python/Pyspark/Scala programming on big data platforms like Databricks\n4+ years in cloud data engineering experience in Azure or AWS.\nFluent with Azure cloud services. Azure Data Engineering certification is a plus.\nExperience with integration of multi cloud services with on-premises technologies.\nExperience with data modelling, data warehousing, and building high-volume ETL/ELT pipelines.\nExperience with data profiling and data quality tools like Great Expectations.\nExperience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets.\nExperience with at least one business intelligence tool such as Power BI or Tableau\nExperience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes.\nExperience with version control systems like ADO, Github and CI/CD tools for DevOps automation and deployments.\nExperience with Azure Data Factory, Azure Databricks and Azure Machine learning tools.\nExperience with Statistical/ML techniques is a plus.\nExperience with building solutions in the retail or in the supply chain space is a plus.\nUnderstanding of metadata management, data lineage, and data glossaries is a plus.\nBA/BS in Computer Science, Math, Physics, or other technical fields.\nCandidate must be flexible to work an alternative work schedule either on tradition work week from Monday to Friday; or Tuesday to Saturday or Sunday to Thursday depending upon product and project coverage requirements of the job.\nCandidates are expected to be in the office at the assigned location at least 3 days a week and the days at work needs to be coordinated with immediate supervisor\nSkills, Abilities, Knowledge:\nExcellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.\nProven track record of leading, mentoring data teams.\nStrong change manager. Comfortable with change, especially that which arises through company growth.\nAbility to understand and translate business requirements into data and technical requirements.\nHigh degree of organization and ability to manage multiple, competing projects and priorities simultaneously.\nPositive and flexible attitude to enable adjusting to different needs in an ever-changing environment.\nStrong leadership, organizational and interpersonal skills; comfortable managing trade-offs.\nFoster a team culture of accountability, communication, and self-management.\nProactively drives impact and engagement while bringing others along.\nConsistently attain/exceed individual and team goals.\nAbility to lead others without direct authority in a matrixed environment.\nComfortable working in a hybrid environment with teams consisting of contractors as well as FTEs spread across multiple PepsiCo locations.\nDomain Knowledge in CPG industry with Supply chain/GTM background is preferred.",Industry Type: Beverage,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Pyspark', 'Azure', 'Power BI', 'Github', 'Azure Databricks', 'Tableau', 'ADO', 'Scala programming', 'SQL', 'Azure Data Factory', 'Azure Machine learning', 'Data Lakehouse', 'Azure Data Engineering', 'CI/CD', 'Data Warehousing', 'Data Analytics', 'AWS', 'Python']",2025-06-12 06:34:06
Walk In || Corporate Sales Role || Naukri.com || Ahmedabad,Info Edge,0 - 2 years,Not Disclosed,['Ahmedabad'],"About Info Edge India Ltd\nInfo Edge is Indias leading consumer internet company known for its strong brands in recruitment (naukri.com, naukrigulf.com, iimjobs.com, firstnaukri.com), real estate (99acres.com), matrimony (Jeevansathi.com) and education (shiksha.com).\nStarting with a classified recruitment online business, naukri.com, the Company has grown and diversified rapidly, setting benchmarks as a pioneer for others to follow either through setting up of in-house brands or through the route of strategic investments and acquisitions. Zomato.com, policybazaar.com & Happily Unmarried Marketing Private Limited are our investee companies to name a few out of many. With years of experience in the domain, strong cash flow generation, and a diversified business portfolio, Info Edge is one of the very few profitable pure play internet companies in the country.",,,,"['Sales', 'B2B Sales', 'Lead Generation', 'Client Acquisition', 'Corporate Sales']",2025-06-12 06:34:08
"4 To 8 years of exp. as a Data Analyst @ Banglore, Hyderabad , Chennai",A Client of Career Focus Consultancy,4 - 8 years,5-10 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Strong proficiency in Advanced SQL with experience in writing optimized queries for large datasets.\nMandatory skill : Data Analyst, Python ,SQL, Power BI\n\n\nExposure in, including predictive modeling and machine learning techniques.\n\nRequired Candidate profile\nHands-on experience with Python, R, or similar analytical tools is a plus.\nFamiliarity with cloud platforms such as AWS, Azure, or GCP for data processing and analytics.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['R', 'Power BI', 'Data Analyst', 'Python', 'SQL', 'Azure', 'GCP', 'AWS']",2025-06-12 06:34:11
Manager Data Engineer – Research Data and Analytics,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will create and develop data lake solutions for scientific data that drive business decisions for Research. You will build scalable and high-performance data engineering solutions for large scientific datasets and collaborate with Research collaborators. You will also provide technical leadership to junior team members. The ideal candidate possesses experience in the pharmaceutical or biotech industry, demonstrates deep technical skills, is proficient with big data technologies, and has a deep understanding of data architecture and ETL processes.\nRoles & Responsibilities:\nLead, manage, and mentor a high-performing team of data engineers\nDesign, develop, and implement data pipelines, ETL processes, and data integration solutions\nTake ownership of data pipeline projects from inception to deployment, manage scope, timelines, and risks\nDevelop and maintain data models for biopharma scientific data, data dictionaries, and other documentation to ensure data accuracy and consistency\nOptimize large datasets for query performance\nCollaborate with global multi-functional teams including research scientists to understand data requirements and design solutions that meet business needs\nImplement data security and privacy measures to protect sensitive data\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions\nCollaborate with Data Architects, Business SMEs, Software Engineers and Data Scientists to design and develop end-to-end data pipelines to meet fast paced business needs across geographic regions\nIdentify and resolve data-related challenges\nAdhere to best practices for coding, testing, and designing reusable code/component\nExplore new tools and technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The [vital attribute] professional we seek is a [type of person] with these qualifications.\nBasic Qualifications:\nDoctorate Degree OR\nMasters degree with 4 - 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 6 - 8 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 10 - 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nPreferred Qualifications:\n3+ years of experience in implementing and supporting biopharma scientific research data analytics (software platforms)\n\n\nFunctional Skills:\nMust-Have Skills:\nProficiency in SQL and Python for data engineering, test automation frameworks (pytest), and scripting tasks\nHands on experience with big data technologies and platforms, such as Databricks, Apache Spark (PySpark, SparkSQL), workflow orchestration, performance tuning on big data processing\nExcellent problem-solving skills and the ability to work with large, complex datasets\nAble to engage with business collaborators and mentor team to develop data pipelines and data models\n\n\nGood-to-Have Skills:\nA passion for tackling complex challenges in drug discovery with technology and data\nGood understanding of data modeling, data warehousing, and data integration concepts\nGood experience using RDBMS (e.g. Oracle, MySQL, SQL server, PostgreSQL)\nKnowledge of cloud data platforms (AWS preferred)\nExperience with data visualization tools (e.g. Dash, Plotly, Spotfire)\nExperience with diagramming and collaboration tools such as Miro, Lucidchart or similar tools for process mapping and brainstorming\nExperience writing and maintaining technical documentation in Confluence\nUnderstanding of data governance frameworks, tools, and best practices\n\n\nProfessional Certifications:\nDatabricks Certified Data Engineer Professional preferred\n\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nDemonstrated presentation skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Spotfire', 'PySpark', 'PostgreSQL', 'Plotly', 'SparkSQL', 'SQL server', 'SQL', 'process mapping', 'Dash', 'MySQL', 'ETL', 'Oracle', 'data governance frameworks', 'Python']",2025-06-12 06:34:13
Senior Data Engineer : 7+ Years,Jayam Solutions Pvt Ltd - CMMI Level III Company,5 - 9 years,Not Disclosed,['Hyderabad( Madhapur )'],"Job Description:\nPosition: Sr.Data Engineer\nExperience: Minimum 7 years\nLocation: Hyderabad\nJob Summary:\n\nWhat Youll Do\n\nDesign and build efficient, reusable, and reliable data architecture leveraging technologies like Apache Flink, Spark, Beam and Redis to support large-scale, real-time, and batch data processing.\nParticipate in architecture and system design discussions, ensuring alignment with business objectives and technology strategy, and advocating for best practices in distributed data systems.\nIndependently perform hands-on development and coding of data applications and pipelines using Java, Scala, and Python, including unit testing and code reviews.\nMonitor key product and data pipeline metrics, identify root causes of anomalies, and provide actionable insights to senior management on data and business health.\nMaintain and optimize existing datalake infrastructure, lead migrations to lakehouse architectures, and automate deployment of data pipelines and machine learning feature engineering requests.\nAcquire and integrate data from primary and secondary sources, maintaining robust databases and data systems to support operational and exploratory analytics.\nEngage with internal stakeholders (business teams, product owners, data scientists) to define priorities, refine processes, and act as a point of contact for resolving stakeholder issues.\nDrive continuous improvement by establishing and promoting technical standards, enhancing productivity, monitoring, tooling, and adopting industry best practices.\n\nWhat Youll Bring\n\nBachelors degree or higher in Computer Science, Engineering, or a quantitative discipline, or equivalent professional experience demonstrating exceptional ability.\n7+ years of work experience in data engineering and platform engineering, with a proven track record in designing and building scalable data architectures.\nExtensive hands-on experience with modern data stacks, including datalake, lakehouse, streaming data (Flink, Spark), and AWS or equivalent cloud platforms.\nCloud - AWS\nApache Flink/Spark , Redis\nDatabase platform- Databricks.\nProficiency in programming languages such as Java, Scala, and Python(Good to have) for data engineering and pipeline development.\nExpertise in distributed data processing and caching technologies, including Apache Flink, Spark, and Redis.\nExperience with workflow orchestration, automation, and DevOps tools (Kubernetes,git,Terraform, CI/CD).\nAbility to perform under pressure, managing competing demands and tight deadlines while maintaining high-quality deliverables.\nStrong passion and curiosity for data, with a commitment to data-driven decision making and continuous learning.\nExceptional attention to detail and professionalism in report and dashboard creation.\nExcellent team player, able to collaborate across diverse functional groups and communicate complex technical concepts clearly.\nOutstanding verbal and written communication skills to effectively manage and articulate the health and integrity of data and systems to stakeholders.\n\nPlease feel free to contact us: 9440806850\nEmail ID : careers@jayamsolutions.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Apache Flink', 'Redis', 'Spark', 'Python', 'SCALA', 'Ci/Cd', 'Devops', 'AWS']",2025-06-12 06:34:15
Data Engineer,Databeat,3 - 7 years,Not Disclosed,['Hyderabad( Rai Durg )'],"Experience Required: 3+ years\n\nTechnical knowledge: AWS, Python, SQL, S3, EC2, Glue, Athena, Lambda, DynamoDB, RedShift, Step Functions, Cloud Formation, CI/CD Pipelines, Github, EMR, RDS,AWS Lake Formation, GitLab, Jenkins and AWS CodePipeline.\n\n\n\nRole Summary: As a Senior Data Engineer,with over 3 years of expertise in Python, PySpark, SQL to design, develop and optimize complex data pipelines, support data modeling, and contribute to the architecture that supports big data processing and analytics to cutting-edge cloud solutions that drive business growth. You will lead the design and implementation of scalable, high-performance data solutions on AWS and mentor junior team members.This role demands a deep understanding of AWS services, big data tools, and complex architectures to support large-scale data processing and advanced analytics.\nKey Responsibilities:\nDesign and develop robust, scalable data pipelines using AWS services, Python, PySpark, and SQL that integrate seamlessly with the broader data and product ecosystem.\nLead the migration of legacy data warehouses and data marts to AWS cloud-based data lake and data warehouse solutions.\nOptimize data processing and storage for performance and cost.\nImplement data security and compliance best practices, in collaboration with the IT security team.\nBuild flexible and scalable systems to handle the growing demands of real-time analytics and big data processing.\nWork closely with data scientists and analysts to support their data needs and assist in building complex queries and data analysis pipelines.\nCollaborate with cross-functional teams to understand their data needs and translate them into technical requirements.\nContinuously evaluate new technologies and AWS services to enhance data capabilities and performance.\nCreate and maintain comprehensive documentation of data pipelines, architectures, and workflows.\nParticipate in code reviews and ensure that all solutions are aligned to pre-defined architectural specifications.\nPresent findings to executive leadership and recommend data-driven strategies for business growth.\nCommunicate effectively with different levels of management to gather use cases/requirements and provide designs that cater to those stakeholders.\nHandle clients in multiple industries at the same time, balancing their unique needs.\nProvide mentoring and guidance to junior data engineers and team members.\n\n\n\nRequirements:\n3+ years of experience in a data engineering role with a strong focus on AWS, Python, PySpark, Hive, and SQL.\nProven experience in designing and delivering large-scale data warehousing and data processing solutions.\nLead the design and implementation of complex, scalable data pipelines using AWS services such as S3, EC2, EMR, RDS, Redshift, Glue, Lambda, Athena, and AWS Lake Formation.\nBachelor's or Masters degree in Computer Science, Engineering, or a related technical field.\nDeep knowledge of big data technologies and ETL tools, such as Apache Spark, PySpark, Hadoop, Kafka, and Spark Streaming.\nImplement data architecture patterns, including event-driven pipelines, Lambda architectures, and data lakes.\nIncorporate modern tools like Databricks, Airflow, and Terraform for orchestration and infrastructure as code.\nImplement CI/CD using GitLab, Jenkins, and AWS CodePipeline.\nEnsure data security, governance, and compliance by leveraging tools such as IAM, KMS, and AWS CloudTrail.\nMentor junior engineers, fostering a culture of continuous learning and improvement.\nExcellent problem-solving and analytical skills, with a strategic mindset.\nStrong communication and leadership skills, with the ability to influence stakeholders at all levels.\nAbility to work independently as well as part of a team in a fast-paced environment.\nAdvanced data visualization skills and the ability to present complex data in a clear and concise manner.\nExcellent communication skills, both written and verbal, to collaborate effectively across teams and levels.\n\nPreferred Skills:\nExperience with Databricks, Snowflake, and machine learning pipelines.\nExposure to real-time data streaming technologies and architectures.\nFamiliarity with containerization and serverless computing (Docker, Kubernetes, AWS Lambda).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Aws Glue', 'SQL', 'Data Pipeline', 'Python', 'Amazon Ec2', 'Data Engineering', 'Data Bricks', 'Aws Lambda', 'Amazon Redshift', 'Azure Cloud', 'Data Lake', 'Data Modeling', 'Athena']",2025-06-12 06:34:18
Data Engineer IV - Big Data / Spark,Sadup Soft,5 - 7 years,Not Disclosed,['Chennai'],"Must have skills :\n\n- Minimum of 5-7 years of experience in software development, with a focus on Java and infrastructure tools.\n\n- Min 6+ years of experience as a Data Engineer.\n\n- Good Experience in handling Big Data Spark, Hive SQL, BigQuery, SQL.\n\n- Candidate worked on cloud platforms and GCP would be an added advantage.\n\n- Good understanding of Hadoop based ecosystem including hard sequel, HDFS would be very essential.\n\n- Very good professional knowledge of PySpark or using Scala\n\nResponsibilities :\n\n- Collaborate with cross-functional teams such as Data Scientists, Product Partners and Partner Team Developers to identify opportunities for Big Data, Query ( Spark, Hive SQL, BigQuery, SQL ) tuning opportunities that can be solved using machine learning and generative AI.\n\n- Write clean, high-performance, high-quality, maintainable code.\n\n- Design and develop Big Data Engineering Solutions Applications for above ensuring scalability, efficiency, and maintainability of such solutions.\n\nRequirements :\n\n- A Bachelor or Master's degree in Computer Science or a related field.\n\n- Proven experience working as a Big Data & MLOps Engineer, with a focus on Spark, Scala Spark or PySpark, Spark SQL, BigQuery, Python, Google Cloud,.\n\n- Deep understanding and experience in tuning Dataproc, BigQuery, Spark Applications.\n\n- Solid knowledge of software engineering best practices, including version control systems (e.g Git), code reviews, and testing methodologies.\n\n- Strong communication skills to effectively collaborate and present findings to both technical and non-technical stakeholders.\n\n- Proven ability to adapt and learn new technologies and frameworks quickly.\n\n- A proactive mindset with a passion for continuous learning and research.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Big Data', 'Data Engineering', 'BigQuery', 'GCP', 'Spark', 'Machine Learning', 'Python', 'SQL']",2025-06-12 06:34:20
Senior Data Engineer,Amgen Inc,3 - 7 years,Not Disclosed,['Hyderabad'],"What you will do\nRole Description:\nWe are seeking a Senior Data Engineer with expertise in Graph Data technologies to join our data engineering team and contribute to the development of scalable, high-performance data pipelines and advanced data models that power next-generation applications and analytics. This role combines core data engineering skills with specialized knowledge in graph data structures, graph databases, and relationship-centric data modeling, enabling the organization to leverage connected data for deep insights, pattern detection, and advanced analytics use cases. The ideal candidate will have a strong background in data architecture, big data processing, and Graph technologies and will work closely with data scientists, analysts, architects, and business stakeholders to design and deliver graph-based data engineering solutions.\nRoles & Responsibilities:\nDesign, build, and maintain robust data pipelines using Databricks (Spark, Delta Lake, PySpark) for complex graph data processing workflows.\nOwn the implementation of graph-based data models, capturing complex relationships and hierarchies across domains.\nBuild and optimize Graph Databases such as Stardog, Neo4j, Marklogic or similar to support query performance, scalability, and reliability.\nImplement graph query logic using SPARQL, Cypher, Gremlin, or GSQL, depending on platform requirements.\nCollaborate with data architects to integrate graph data with existing data lakes, warehouses, and lakehouse architectures.\nWork closely with data scientists and analysts to enable graph analytics, link analysis, recommendation systems, and fraud detection use cases.\nDevelop metadata-driven pipelines and lineage tracking for graph and relational data processing.\nEnsure data quality, governance, and security standards are met across all graph data initiatives.\nMentor junior engineers and contribute to data engineering best practices, especially around graph-centric patterns and technologies.\nStay up to date with the latest developments in graph technology, graph ML, and network analytics.\nWhat we expect of you\nMust-Have Skills:\nHands-on experience in Databricks, including PySpark, Delta Lake, and notebook-based development.\nHands-on experience with graph database platforms such as Stardog, Neo4j, Marklogic etc.\nStrong understanding of graph theory, graph modeling, and traversal algorithms\nProficiency in workflow orchestration, performance tuning on big data processing\nStrong understanding of AWS services\nAbility to quickly learn, adapt and apply new technologies with strong problem-solving and analytical skills\nExcellent collaboration and communication skills, with experience working with Scaled Agile Framework (SAFe), Agile delivery practices, and DevOps practices.\nGood-to-Have Skills:\nGood to have deep expertise in Biotech & Pharma industries\nExperience in writing APIs to make the data available to the consumers\nExperienced with SQL/NOSQL database, vector database for large language models\nExperienced with data modeling and performance tuning for both OLAP and OLTP databases\nExperienced with software engineering best-practices, including but not limited to version control (Git, Subversion, etc.), CI/CD (Jenkins, Maven etc.), automated unit testing, and Dev Ops\nEducation and Professional Certifications\nMasters degree and 3 to 4 + years of Computer Science, IT or related field experience\nBachelors degree and 5 to 8 + years of Computer Science, IT or related field experience\nAWS Certified Data Engineer preferred\nDatabricks Certificate preferred\nScaled Agile SAFe certification preferred\nSoft Skills:\nExcellent analytical and troubleshooting skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals.\nAbility to learn quickly, be organized and detail oriented.\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'SPARQL', 'Maven', 'PySpark', 'GSQL', 'Subversion', 'AWS services', 'Stardog', 'Cypher', 'SAFe', 'Jenkins', 'DevOps', 'Git', 'Neo4j', 'Delta Lake', 'Graph Databases', 'Spark', 'Marklogic', 'Gremlin']",2025-06-12 06:34:23
Ai Ml Engineer,Optum,5 - 10 years,Not Disclosed,['Noida'],"Optum is a global organization that delivers care, aided by technology to help millions of people live healthier lives. The work you do with our team will directly improve health outcomes by connecting people with the care, pharmacy benefits, data and resources they need to feel their best. Here, you will find a culture guided by inclusion, talented peers, comprehensive benefits and career development opportunities. Come make an impact on the communities we serve as you help us advance health optimization on a global scale. Join us to start Caring. Connecting. Growing together.  \nAI Engineer is tasked with the design, development, and deployment of advanced generative AI models and systems. This position requires close collaboration with data scientists, product managers, and other stakeholders to integrate generative AI solutions into existing products and develop new innovative features. Proficiency in the Agentic AI framework is vital for coordinating multiple autonomous AI agents to accomplish complex tasks.\n\nPrimary Responsibilities:\nImplement Generative AI Models: Develop sophisticated generative AI algorithms and models to create new data samples, patterns, or content based on existing data or inputs\nData Processing: Collaborate with stakeholders to preprocess, analyze, and interpret extensive datasets\nModel Deployment: Deploy generative AI models into production environments, ensuring scalability and robustness\nOptimization: Conduct model testing, validation, and optimization to enhance performance\nIntegration: Work with cross-functional teams to seamlessly integrate generative AI solutions into products\nResearch: Stay current with the latest advancements in generative AI technologies and practices\nAgentic AI Framework: Utilize the Agentic AI framework to coordinate multiple AI agents for the completion of complex tasks\nMentorship: Provide mentorship to junior team members and offer technical guidance\nComply with the terms and conditions of the employment contract, company policies and procedures, and any and all directives (such as, but not limited to, transfer and/or re-assignment to different work locations, change in teams and/or work shifts, policies in regards to flexibility of work benefits and/or work environment, alternative work arrangements, and other decisions that may arise due to the changing business environment). The Company may adopt, vary or rescind these policies and directives in its absolute discretion and without any limitation (implied or otherwise) on its ability to do so\n\nRequired Qualifications:\nBachelor's or Master's degree in Computer Science, Engineering, or a related field\n5+ years of experience in software engineering with a focus on AI/ML\nExperience with data preprocessing and analysis\nKnowledge of the Agentic AI framework and its application in AI systems\nProficiency in machine learning frameworks such as TensorFlow and PyTorch\nSolid programming skills in Python, Java, or C++\nFamiliarity with cloud platforms (e.g., AWS, Google Cloud, Azure)\nProven excellent problem-solving abilities and algorithmic thinking\nProven solid communication and teamwork skills\n\nPreferred Qualifications:\nExperience with data processing\nKnowledge of version control systems like Git\nUnderstanding of Generative AI, associated technologies and frameworks like RAG, agents etc.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Agentic Ai', 'Gen AI', 'Cloud', 'RAG', 'LLM']",2025-06-12 06:34:25
"Engineer, Staff",Qualcomm,4 - 9 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nJob description:\n\nSkill set\n\nlooking for Python programming, Machine Learning concepts and Automation Testing ( Python framework) Mandatory\n\nPrincipal Duties and Responsibilities:\n\nApplies Software knowledge to assist and support the design, development, creation, modification, and validation of embedded and cloud edge software, applications, and/or specialized utility programs.\n\nAnalyzes user needs and software requirements.\n\nDesigns and implements small software features for products and systems.\n\nParticipates in the design, coding for small features, unit testing, minor debugging fixes, and integration efforts to ensure projects are completed on schedule.\n\nAssists in performing code reviews and regression tests as well as the triaging of issues to ensure the quality of code.\n\nCollaborates with others inside project team to accomplish project objectives.\n\nWrites technical documentation for Software projects.\n\nLevel of Responsibility:\n\nWorks under supervision.\n\nDecision-making affects direct area of work and/or work group.\n\nRequires verbal and written communication skills to convey basic, routine factual information.\n\nTasks require multiple steps which can be performed in various orders; some planning, problem-solving, and prioritization must occur to complete the tasks effectively.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\n\n2+ years of work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software engineering', 'python', 'automation testing', 'machine learning', 'python framework', 'css', 'jquery', 'sql', 'react.js', 'java', 'git', 'selenium', 'debugging', 'html', 'mysql', 'data structures', 'rest', 'c', 'python development', 'javascript', 'django framework', 'node.js', 'django', 'php', 'agile', 'aws']",2025-06-12 06:34:27
Staff Engineer,Qualcomm,8 - 13 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\n\n\nIf youre interested in advancing and applying mathematics, programming languages theory, and advanced algorithms to program optimization for cutting-edge machine learning accelerators, then you really want to be talking to us!\n\n\n\nWe are looking to hire ML Compiler engineers to join our team. We work tactically on improving existing ML compilers and strategically on developing new and innovative ML compilers.\n\n\n\nOur technical approach to compilers emphasizes powerful representations for precisely and compactly modeling programs and the optimization challenges and using advanced mathematics and algorithms for performing optimizations.\n\n\n\nWe are also solid in using ""old school"" compiler technologies as they apply to contemporary ML challenges, and in meticulous software engineering to produce beautiful compilers. We are also keen about seeing our compilers used and having large impacts on Qualcomms business.\n\n\n\nMapping ML algorithms to ML accelerators is currently one of the most interesting and challenging problems for compilers. Our compiler targets include the Qualcomm Neural Signal Processor, Adreno GPUs, low-power ML accelerators, and CPU accelerators.\n\nThis job description spans multiple levels, from entry to experienced. Our team is a good home for compiler developers with advanced degrees, and we have solid mentoring and give substantial responsibility quickly for entry level engineers.\n\n\n\nResponsibilities Work on a wide range of ML compilers\n\nImprove ML compiler optimization capabilities through benchmark analysis and profiling\n\nInnovate new ML compiler and optimization algorithms\n\nUpstream compiler algorithms to open-source compiler projects Author research publications and represent the company in conferences and industry forums\n\n\n\nRequired\n\nExperience with compiler development and computer architecture\n\nML experience\n\nA degree in the field of computer science or applied mathematics\n\nExperience with software engineering\n\nSolid intellectual ability, motivation, and a strong history of achievementExcellent oral and written communication skills\n\nDesired Experience with MLIR, MLIR Dialects (LinAlg, Affine), Pytorch 2.0, TVM, Triton, and/or LLVM\n\nSYCL experience\n\nML applications and ML optimization experience\n\nML architecture experience\n\nHigh performance computing experience\n\nPolyhedral compiler optimization experience\n\nLoop transformation and vectorization experience\n\nGPU programming, parallel programming experience\n\nGeneral optimization experience\n\n8+ years of relevant work experience\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\n\n2+ years of work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'gps', 'java', 'software engineering', 'algorithms', 'database management system', 'c', 'software development', 'dbms', 'sql', 'spring', 'rtos', 'computer architecture', 'design patterns', 'embedded systems', 'linux', 'oops', 'embedded c', 'multithreading', 'data structures', 'html']",2025-06-12 06:34:30
Staff Engineer - Camera Systems,Qualcomm,3 - 8 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Systems Engineer, you will research, design, develop, simulate, and/or validate systems-level software, hardware, architecture, algorithms, and solutions that enables the development of cutting-edge technology. Qualcomm Systems Engineers collaborate across functional teams to meet and exceed system-level requirements and standards.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.\nCandidate should have 10+ years of experience\n\nExperience in C/C++, Computer vision/ Image processing is must\n\nExperience in camera technology, ML/DL is good to have\n\nExperience in Embedded/arm programming is good to have but not necessary\n\nResponsibilities\n\nThe job responsibilities may include a subset of the following\n\nDesigning computer vision /image processing for mobile devices\nDesigning and evaluating algorithms to be implemented in hardware on software prototypes\nDeveloping or Optimizing image processing and computer vision algorithms for HW acceleration\nSupport product teams for commercialization, such as solution optimization, performance profiling and benchmarking.\nTest regression and release support\n\nPreferred Qualifications:\n\nExposure or working experience in Vision or Multimedia accelerators\nWorking experience with image processing algorithms.\nKnowledge/working experience in computer vision algorithms\nStrong knowledge in data structures and working experience with C/C++ programming\nSoftware optimizations experience in various SIMD and multi-threading",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['image processing', 'c++', 'c', 'computer vision', 'data structures', 'python', 'natural language processing', 'scikit-learn', 'dl', 'machine learning', 'artificial intelligence', 'deep learning', 'tensorflow', 'data science', 'embedded systems', 'keras', 'multithreading', 'arm', 'system engineering', 'ml']",2025-06-12 06:34:33
Software Engineer II,Chegg,3 - 8 years,Not Disclosed,['New Delhi'],"About the Team\nChegg's engineering team is a group of passionate engineers who, in close collaboration with data scientists, product managers, designers, and other backend developers, build the future of the online education industry. We develop our products to scale and to last, we dont take shortcuts (hello unit tests and documentation), and we take pride in delivering high-quality solutions on time. We are cloud native.\nRole\nWe are looking for software engineers passionate about solving real-world problems for students in online education using technology. The ideal candidate can think outside the box, is passionate about technology, is adaptable, thinks big, and is passionate about making an impact. Chegg is evolving very fast, and we are constantly redefining our offerings to match the requirements of our student community; the candidate should have the appetite to pivot fast and be interested in continuous improvement and learning. Chegg has a very open and vibrant engineering culture where the candidate will get the opportunity to work with the best in the industry; the role demands ideating and sharing creative ideas as you never know the next big thing Chegg works on can come from you !! If you have dreamt of leveraging your skills and knowledge to impact something big enough to matter, Chegg provides those opportunities, and the candidate should make the best use of them.\nResponsibilities\nDetermine operational feasibility by evaluating analysis, problem definition, requirements, solution development, and proposed solutions;\nCross-team collaboration in driving the end-to-end delivery of SDN on Edge;\nParticipating in the code reviews and design discussions of other engineers;\nHave a strong sense of end-to-end ownership;\nAdhere to key principles: Code and design for best performance, scalability, and resiliency;\nParticipate in daily SCRUM meetings;\nParticipates in the testing process through test review and analysis, test witnessing, and certification of software;\nBe a self-starter, capable of solving ambiguous and challenging technical problems with wide scope;\nFull stack development of new features/tools, including design, documentation, implementation, and testing;\nWork alongside other engineers on the team to elevate technology and consistently apply best practices.\nSkills and Qualifications [Must Have]\nB.E., B.Tech, . degree in Computer Science or a related technical field\n3+ years of product lifecycle experience (from customer requirements -> functional spec -> design -> development/testing -> deployment and monitoring);\nStrong interpersonal and communication skills;\nStrong hands-on development/scripting experience with Python and shell.\nUse tools and methodologies to create representations of workflows, user interfaces, data schemas, etc;\nSolid understanding of software design and development;\nExperience with third-party libraries and APIs;\nExcellent design and problem-solving skills.\nStrong experience with Cloud technologies such as AWS\nExperience with Unit testing frameworks for TDD (Test Driven Development) methodology\nSkills and Qualifications [Good To Have]\nSolid understanding of Agile methodologies and experience working in Agile teams.\nHands-on experience with CI/CD pipelines, preferably using GitLab.\nDevelopment knowledge of mobile apps (android/iOS)",Industry Type: E-Learning / EdTech,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'schema', 'continuous integration', 'software testing', 'software design', 'unit testing', 'android', 'ci/cd', 'solution development', 'ios', 'cloud technologies', 'tdd', 'full stack', 'scrum', 'gitlab', 'shell scripting', 'software engineering', 'code review', 'agile', 'api', 'agile methodology']",2025-06-12 06:34:35
Staff Engineer- Compiler and library development,Qualcomm,4 - 9 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Systems Engineer, you will research, design, develop, simulate, and/or validate systems-level software, hardware, architecture, algorithms, and solutions that enables the development of cutting-edge technology. Qualcomm Systems Engineers collaborate across functional teams to meet and exceed system-level requirements and standards.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nBelow is the JD\n\nInterested in enabling open source developers to build software for millions of devicesInterested in leading optimization solutions for AI on the EdgeCome join our team! Our team builds open source compiler toolsets for Qualcomm silicon. This includes compilers, assemblers, linkers, libraries, debuggers, profilers, and other developer tools. The toolsets enable internal and external developers to build software ecosystems on Qualcomm hardware. We are looking for engineers who will work actively in open source communities to establish and augment compiler and system software toolsets. In this role, you will add and enhance support for Qualcomm hardware in open source projects. You will collaborate with Qualcomm hardware and software engineers to enable efficient usage of Qualcomms silicon for a broad set of applications including machine learning. You will work with the team on the entire compilation stack including optimizing code generation, improving performance, and programmer usability.Responsibilities:Work in the GCC, LLVM, glibc, and related open source communities to add features and improve performance for Qualcomm processorsIdentify areas for improvement in compiler toolsets via benchmarking and code analysisCollaborate with hardware teams to plan, identify, and contribute support in open source projects for hardware features in Qualcomm siliconIdentify areas for improvement in tool usability via interaction with users.Explore new optimization frameworks for leveraging advance CPU features.Design, develop and contribute features to open source ML frameworks.Minimum qualifications:Knowledge and/or experience in compiler frameworks such as GCC or LLVMExperience in working with open source communitiesProgramming in C/C++Bachelors degree in Engineering, Information Systems, Computer Science, or related field.Preferred qualifications:Masters degree or PhD. in Engineering, Information Systems, Computer Science, or related field.Established record of contributions to open source compiler project.Strong background in computer architecture",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['gcc', 'machine learning', 'computer architecture', 'system engineering', 'ml', 'c#', 'algorithms', 'rest', 'developer tools', 'simulation', 'system software', 'javascript', 'sql server', 'sql', 'visual studio', 'open source', 'silicon', 'java', 'computer science', 'asp.net', 'html', 'digital transformation']",2025-06-12 06:34:38
Python Developer Lead {ENG - Infosys @ Pan India - G },Infosys,4 - 9 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Process->Testing processes->Test Automation Process,Technology->Machine Learning->Python\n\nPreferred Skills: Process->Testing processes->Test Automation Process\nTechnology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BE,BSc,BTech Role & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Django Framework', 'Python Development', 'Python']",2025-06-12 06:34:40
Speech Engineer,BUSINESSNEXT,2 - 5 years,Not Disclosed,['Noida'],"What would you do?\nSystem Design: Architect and design end-to-end speech processing pipelines, from data acquisition to model deployment. Ensure systems are scalable, efficient, and maintainable.\nAdvanced Modeling: Develop and implement advanced machine learning models for speech recognition, speaker diarization, and related tasks. Utilize state-of-the-art techniques such as deep learning, transfer learning, and ensemble methods.\nResearch and Development: Conduct research to explore new methodologies and tools in the field of speech processing. Publish findings and present at industry conferences.",,,,"['Tensorflow', 'Pytorch', 'Stt', 'Speech Recognition', 'transfer learning', 'deep speech', 'Natural Language Processing', 'model deployment', 'Data Acquisition', 'Machine Learning', 'Deep Learning', 'Sts', 'speech processing', 'whisper', 'text to speech']",2025-06-12 06:34:42
Software tools development Engineer,Qualcomm,2 - 7 years,Not Disclosed,['Chennai'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nQualcomm's Corporate Engineering division in Chennai is looking for software tools development engineer. The candidate will work in a development role to put together software for tool development and test automation across various technologies that are part of Access points, mobile platform, RF, Machine learning platforms. The candidate is expected to have full proficiency on C++ or C# or Python and have experience on developing applications, APIs, software automation using a combination of commercial test equipment and custom hardware designs.\n\nThe ideal candidate will be responsible for implementing novel test plans and supporting those test plans from the R&D lab environment through manufacturing. Candidate will also be responsible for evaluating new complex hardware designs and providing feedback regarding design for testability. Candidate will be responsible to own the test infrastructure, build automation framework and enable other developers towards achieving deployable, scalable test frameworks. Candidate will be responsible for implementing automated test solutions for those hardware designs using a combination of custom test software/hardware and commercial test equipment.\n\nThe candidate will interface with internal staff and outside partners in the fast-paced execution of a variety of multi-disciplined projects. The candidate will have an opportunity to influence and help adopt new test, tool development methodologies and enhance existing processes. International travel might be required. All Qualcomm employees are expected to actively support diversity on their teams, and in the Company.\n\nMinimum Qualifications:\n\nB.E/B.Tech. with industry experience in the following areas:\n\n2+ years of programming experience across C++ / C# / Python\n\nStrong lab skills and experience with standard lab equipment is required\n\nStrong experience in various software technologies, methodologies and applied software engineering practices/standards such as Object-Oriented Design (OOD), cloud and embedded software test automation\n\nPreferred Qualifications:\n\nStrong programming skills in C++/C#\n\nExperience with embedded software and device drivers\n\nApplication UI design Winforms/WPF\n\nExperience with hardware debug equipment such as JTAG and scope\n\nExperience with scripting languages (Perl, Python etc.)\n\nFamiliarity with AI frameworks models performance, quantization, and accuracy metrics\n\nGood analytical, debug and problem-solving abilities\n\nGood communication skills and ability to work in a cross-functional team environment\n\nEffectively delegates tasks to other team members, multitasks and meets aggressive schedules in a dynamic environment.\n\nFPGA/CPLD design, JTAG/boundary scan\n\nExperience with RF test equipment measurements such as signal generator and spectrum analyzer and HW/SW issue troubleshooting\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.\nEducation requirements:\n\nRequiredB.E. or B.Tech. in Electronics and Communication or Electrical engineering or Computer Science or equivalent. PreferredMasters",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c#', 'c++', 'python', 'software engineering', 'perl', 'rest', 'software development', 'ood', 'device drivers', 'wpf', 'machine learning', 'artificial intelligence', 'software programming', 'winforms', 'embedded software', 'computer science', 'debugging', 'troubleshooting', 'api', 'scripting languages']",2025-06-12 06:34:45
AI Model System Software Performance Optimization Engineer,Qualcomm,1 - 6 years,Not Disclosed,['Hyderabad'],"Title : AI Model System Software Performance Optimization Engineer / Senior Engineer / Lead Engineer / Staff\n\nJob Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nWe are seeking candidates with strong optimized software development knowledge and hands-on experience AI. You will be working in a team responsible for comprehensiveness and enhancement of Performance Optimization tools of state-of-the-art machine learning solutions on Snapdragon platform.You will be working on technical initiatives to continuously benchmark the AI optimization workflow that will serve as relevant, reference case studies for application developers for Windows on Snapdragon. You will drive improvements into the SW stack including SDK, Tools, and documentation that will directly impact the ease of use and performance realization by Windows Application Developers on Snapdragon. You will work closely with development leads, software and hardware architects, customer engineers, and application developers.\n\nResponsibilities:\nUnderstand trends in ML model design, and workflow through application developer engagements and latest academic research\nContinuously measure KPIs for AI development tools on Windows on Snapdragon in terms of level of automation, ease of use, and resulting performance and accuracy preservation\nCompetitive benchmarking of tools and workflow on competitive platforms on state-of-the-art models\nEnhancement of AI performance debug, analysis, and optimization tools for AI application development for Windows on Snapdragon so that Application Developers have nil to very low barrier to entry for Windows on Snapdragon\nInterface with 3rd party application developers and other cross-site and cross-functional teams to arrive at best-in-class performant tools, and documentation that are directly leveraged by 3rd party app developers for Windows on Snapdragon\nContribute new features and designs to the Qualcomm AI toolkit to enhance the workflow experience of Application Developers\n\nSkills and Experience:\n1-10 years experience in AI application development\nExperience in building LLM applications using AI/ML tools/workflow preferably on Windows on CPU, GPU, NPU\nAbility to code in C, C++, and Python\nExperience with performance optimization of AI on GPU, NPU, CPU a plus\nStrong communication skills (written and verbal)\nDemonstrated ability to learn, think and adapt in a fast-changing environment\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software development', 'c', 'application development', 'java', 'software engineering', 'rest', 'algorithms', 'python', 'c++', 'system software', 'cpu', 'gps', 'machine learning', 'artificial intelligence', 'sql server', 'sql', 'computer science', 'microsoft windows', 'oops', '.net', 'data structures', 'sdk', 'ml']",2025-06-12 06:34:47
Senior AI Camera Systems Engineer,Qualcomm,2 - 4 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n2-4 years of experiences in image processing/computer vision/camera domain.\nWorking experience with machine learning framework/packages (e.g, PyTorch, TensorFlow, Keras etc.)\nStrong hands on experience on developing object detection, tracking or face detection algorithms.\nStrong background in image and signal processing, statistics, and data analysis.\nDeveloping machine learning algorithms for advanced imaging features\nStrong programming skills and working experience in C/C++\\ assembly programming skills, multithreading and RTOS/OS concepts\\fundamentals and Python.\nStrong debugging skills to debug complex system level issues.\nCollaborate with cross-functional teams to design, implement and debug camera\\multimedia features for mobiles.\nGood analytical and problem-solving skills.\n\n\nResponsibilities:\nDevelopment and productize camera essential features on Qualcomm chipsets for mobile\nInfluence camera HW architecture in Qualcomm chipsets\nCollaborate with systems, software, hardware teams at various stages of chipset life in design/validation/commercialization.\nCustomer interaction to commercialize Qualcomm camera solutions.\nIndividual contributions and working with cross functional teams on camera essential features design/planning/execution/commercialization for future Snapdragon chipsets\n\n\nEducation requirements:\nRequiredBachelor's/Masters/PHd Computer Engineering and/or Electrical / Electronic Engineering\nPreferred Masters\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['algorithms', 'data analysis', 'signal processing', 'debugging', 'statistics', 'image processing', 'python', 'c++', 'c', 'object detection', 'machine learning', 'imaging', 'mac', 'hw', 'tensorflow', 'rtos', 'computer science', 'computer vision', 'pytorch', 'keras', 'multithreading', 'system engineering']",2025-06-12 06:34:49
Automation Engineer,Synechron,3 - 8 years,Not Disclosed,"['Pune', 'Hinjewadi']","job requisition idJR1027505\n\nOverall Responsibilities:\nLead the development and implementation of projects using emerging technologies\nMentor and guide team members to ensure the successful delivery of projects\nIdentify and evaluate new technology solutions to improve business processes\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nStay up-to-date with the latest technological advancements and industry trends\n\n\nSkills:\nStrong expertise in emerging technologies such as blockchain, IoT, AI, etc.\nStrong technical knowledge of software development lifecycle\nExcellent problem-solving and critical thinking skills\nGood understanding of software architecture and design patterns\nAbility to lead and manage a team of technical experts\nExperience:\nAt least 3+ years of experience in software development and leading technology projects\nProven track record of delivering projects using emerging technologies\nExperience in mentoring and guiding junior team members\nExperience in working with cross-functional teams\nDay-to-Day Activities:\nManage the development and delivery of projects using emerging technologies\nProvide technical guidance and mentorship to junior team members\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nEvaluate and recommend new technology solutions to improve business processes\nStay up-to-date with the latest technological advancements and industry trends\nQualification:\nBachelor's or Master's degree in Computer Science, Information Technology, or related field\nRelevant certifications in emerging technologies\nSoft\n\nSkills:\nStrong communication and leadership skills\nAbility to work well under pressure and meet tight deadlines\nExcellent interpersonal and team-working skills\nAbility to effectively communicate technical information to non-technical stakeholders\nPassionate about technology and a desire to stay up-to-date with the latest advancements.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['emerging technologies', 'artificial intelligence', 'iot', 'software development life cycle', 'blockchain', 'project management', 'python', 'software development', 'information technology', 'business analysis', 'machine learning', 'java', 'automation engineering', 'design patterns', 'agile']",2025-06-12 06:34:53
"Platform Dev & Support Engineer (Python, NoSQL, Devops)",Qualcomm,3 - 7 years,Not Disclosed,['Hyderabad'],"Job Area: Information Technology Group, Information Technology Group > IT Software Developer\n\nGeneral Summary:\n\nQualcomm EDAAP (Engineering Solutions and AIML) team is seeking an experienced develop and support scalable Machine learning platform. The ideal candidate will have a strong background in building and operating distributed systems, with expertise in Rust, Python, Kubernetes, and Linux. You will play a critical role in developing, supporting and debugging our Generative AI platforms.Experience:3 to 7 years of experience strong knowledge of Python or Rust, NoSQL (Mongo/Redis), working experience of developing/supporting large scale end user facing applications.Responsibilities\nDevelop, Debug and support end to end components of large-scale Generative AI platform.\nSet up and operate Kubernetes clusters for efficient deployment and management of containerized applications\nImplement distributed microservices architecture to enable scalable and fault-tolerant inference pipelines\nEnsure optimal performance, security, and reliability of inference platforms, leveraging expertise in Linux, networking, servers, and data centers\nDevelop and maintain scripts and tools for automating deployment, monitoring, and maintenance tasks\nTroubleshoot issues and optimize system performance, using knowledge of data structures and algorithms\nWork closely with users to debug issues and address performance and scalability issues.\nParticipate in code reviews, contributing to the improvement of the overall code quality and best practices/Skills\n3 to 7 years of experience in software development, with a focus on building scalable and distributed systems\nProficiency in Rust and Python programming languages, with experience in developing high-performance applications\nExperience setting up and operating Kubernetes clusters, including deployment, scaling, and management of containerized applications\nStrong understanding of distributed microservices architecture and its application in large-scale systems\nExcellent knowledge of Linux, including shell scripting, package management, and system administration\nGood understanding of networking fundamentals, including protocols, architectures, and network security\nFamiliarity with data structures and algorithms, including trade-offs and optimization techniques\nExperience debugging complex production issues in large scale application platforms.\nExperience working with cloud-native technologies, such as containers, orchestration, and service meshes\nStrong problem-solving skills, with the ability to debug complex issues and optimize system performance\nExcellent communication and collaboration skills, with experience working with cross-functional teams and customers\n\nMinimum Qualifications:\n3+ years of IT-relevant work experience with a Bachelor's degree in a technical field (e.g., Computer Engineering, Computer Science, Information Systems).\nOR\n5+ years of IT-relevant work experience without a Bachelors degree.\n\n3+ years of any combination of academic or work experience with Full-stack Application Development (e.g., Java, Python, JavaScript, etc.)\n1+ year of any combination of academic or work experience with Data Structures, algorithms, and data stores.\nDevelop, Debug and support end to end components of large-scale Generative AI platform.\nSet up and operate Kubernetes clusters for efficient deployment and management of containerized applications\nImplement distributed microservices architecture to enable scalable and fault-tolerant inference pipelines\nEnsure optimal performance, security, and reliability of inference platforms, leveraging expertise in Linux, networking, servers, and data centers\nDevelop and maintain scripts and tools for automating deployment, monitoring, and maintenance tasks\nTroubleshoot issues and optimize system performance, using knowledge of data structures and algorithms\nWork closely with users to debug issues and address performance and scalability issues.\nParticipate in code reviews, contributing to the improvement of the overall code quality and best practices\n\n3 to 7 years of experience in software development, with a focus on building scalable and distributed systems\nProficiency in Rust and Python programming languages, with experience in developing high-performance applications\nExperience setting up and operating Kubernetes clusters, including deployment, scaling, and management of containerized applications\nStrong understanding of distributed microservices architecture and its application in large-scale systems\nExcellent knowledge of Linux, including shell scripting, package management, and system administration\nGood understanding of networking fundamentals, including protocols, architectures, and network security\nFamiliarity with data structures and algorithms, including trade-offs and optimization techniques\nExperience debugging complex production issues in large scale application platforms.\nExperience working with cloud-native technologies, such as containers, orchestration, and service meshes\nStrong problem-solving skills, with the ability to debug complex issues and optimize system performance\nExcellent communication and collaboration skills, with experience working with cross-functional teams and customers\n\nBachelors (Engineering) or Masters",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['kubernetes', 'python', 'networking', 'linux', 'shell scripting', 'container', 'algorithms', 'css', 'software development', 'javascript', 'redis', 'microservices', 'nosql', 'application development', 'docker', 'ansible', 'rust', 'system administration', 'java', 'devops', 'data structures', 'html', 'aws', 'mongodb']",2025-06-12 06:34:55
Senior Engineer - Network Stack Development with AI,Qualcomm,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\nTitleSenior EngineerJob FunctionNetwork Stack Development with AISkills/Experience:\n""ƒ""ƒ3-5 years of proficiency in C/C++, Python programming languages and Linux operating systems\n""ƒ""ƒStrong understanding of Networking concepts, particularly with L3/L4 (Layer 3/Layer 4) experience\n""ƒ""ƒKnowledge of AI/ML conceptsResponsibilities:\n""ƒ""ƒContribute to the design and implementation of AI modules for network stack components\n""ƒ""ƒPerform thorough testing to ensure the reliability and performance of the developed componentsEducation :\n""ƒ""ƒBE/MTech/MS in a relevant field.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'python', 'c', 'networking concepts', 'linux', 'network expansion', 'channel sales', 'networking', 'network development', 'dealer development', 'business development', 'artificial intelligence', 'sales', 'channel development', 'marketing', 'java', 'software engineering', 'dealer management']",2025-06-12 06:34:58
Senior Engineer - Fingerprint SW,Qualcomm,2 - 7 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Software Engineer, you will design, develop, create, modify, and validate embedded and cloud edge software, applications, and/or specialized utility programs that launch cutting-edge, world class products that meet and exceed customer needs. Qualcomm Software Engineers collaborate with systems, hardware, architecture, test engineers, and other teams to design system-level software solutions and obtain information on performance requirements and interfaces.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 1+ year of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field.\n\n2+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.\n\n\nJob Overview\n\nAs a member of the Fingerprint SW team, the developer shall design, modify, and implement Fingerprint SW in Middleware Layer for Qualcomm Fingerprint Solution\n\n\n\nSW design and development on embedded platforms SW Stack development in Middleware layer. Debug and resolve issues in SW reported by internal test teams as well as by customers.Minimum Qualifications 3 to 5 years of experience with embedded systems Must be proficient in C and Database Concepts. Understanding of Linux User and Kernel space development. Good analytical and problem solving skills Strong understanding of basic real-time/embedded programming concepts & real time operating systems concepts Preferred Qualifications Good understanding of microprocessor, multiprocessor architecture. Good to have exposure with ARM based processor and Trustzone awareness. Good to have some basic understanding of Machine Learning and Deep learning techniques.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c', 'database creation', 'embedded systems', 'software engineering', 'embedded programming', 'rest', 'python', 'c++', 'kernel', 'machine learning', 'deep learning', 'test engineering', 'java', 'computer science', 'linux', 'debugging', 'arm', 'digital transformation', 'middleware']",2025-06-12 06:35:00
Senior AIML Engineer,Synechron,6 - 11 years,Not Disclosed,"['Pune', 'Hinjewadi']","job requisition idJR1027526\n\nOverall Responsibilities:\nLead the development and implementation of projects using emerging technologies\nMentor and guide team members to ensure the successful delivery of projects\nIdentify and evaluate new technology solutions to improve business processes\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nStay up-to-date with the latest technological advancements and industry trends\n\n\nSkills:\nStrong expertise in emerging technologies such as blockchain, IoT, AI, etc.\nStrong technical knowledge of software development lifecycle\nExcellent problem-solving and critical thinking skills\nGood understanding of software architecture and design patterns\nAbility to lead and manage a team of technical experts\nExperience:\nAt least 6+ years of experience in software development and leading technology projects\nProven track record of delivering projects using emerging technologies\nExperience in mentoring and guiding junior team members\nExperience in working with cross-functional teams\nDay-to-Day Activities:\nManage the development and delivery of projects using emerging technologies\nProvide technical guidance and mentorship to junior team members\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nEvaluate and recommend new technology solutions to improve business processes\nStay up-to-date with the latest technological advancements and industry trends\nQualification:\nBachelor's or Master's degree in Computer Science, Information Technology, or related field\nRelevant certifications in emerging technologies\nSoft\n\nSkills:\nStrong communication and leadership skills\nAbility to work well under pressure and meet tight deadlines\nExcellent interpersonal and team-working skills\nAbility to effectively communicate technical information to non-technical stakeholders\nPassionate about technology and a desire to stay up-to-date with the latest advancements.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['emerging technologies', 'artificial intelligence', 'iot', 'software development life cycle', 'blockchain', 'soft skills', 'project management', 'software development', 'information technology', 'program management', 'strategy consulting', 'design patterns', 'it strategy', 'agile']",2025-06-12 06:35:03
L2 Support Engineer,Synechron,5 - 10 years,Not Disclosed,"['Pune', 'Hinjewadi']","job requisition idJR1027519\n\nOverall Responsibilities:\nLead the development and implementation of projects using emerging technologies\nMentor and guide team members to ensure the successful delivery of projects\nIdentify and evaluate new technology solutions to improve business processes\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nStay up-to-date with the latest technological advancements and industry trends\n\n\nSkills:\nStrong expertise in emerging technologies such as blockchain, IoT, AI, etc.\nStrong technical knowledge of software development lifecycle\nExcellent problem-solving and critical thinking skills\nGood understanding of software architecture and design patterns\nAbility to lead and manage a team of technical experts\nExperience:\nAt least 5+ years of experience in software development and leading technology projects\nProven track record of delivering projects using emerging technologies\nExperience in mentoring and guiding junior team members\nExperience in working with cross-functional teams\nDay-to-Day Activities:\nManage the development and delivery of projects using emerging technologies\nProvide technical guidance and mentorship to junior team members\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nEvaluate and recommend new technology solutions to improve business processes\nStay up-to-date with the latest technological advancements and industry trends\nQualification:\nBachelor's or Master's degree in Computer Science, Information Technology, or related field\nRelevant certifications in emerging technologies\nSoft\n\nSkills:\nStrong communication and leadership skills\nAbility to work well under pressure and meet tight deadlines\nExcellent interpersonal and team-working skills\nAbility to effectively communicate technical information to non-technical stakeholders\nPassionate about technology and a desire to stay up-to-date with the latest advancements.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['emerging technologies', 'artificial intelligence', 'iot', 'software development life cycle', 'blockchain', 'project management', 'software development', 'engineering support', 'information technology', 'sql', 'production support', 'design patterns', 'application support', 'agile']",2025-06-12 06:35:05
Power Architecture -Staff Engineer,Qualcomm,8 - 13 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nJob Overview:\n\nWe are looking for software engineers who can define software architectures while viewing software as part of a larger system comprising both software and hardware. Previous architecture experience is not necessary as long as you have good software engineering skills and are willing to approach problems at the system level.In this role you will have two related areas of responsibilities:1) Participating in the definition of next generation architectures for future Qualcomm SoCs, and2) Driving the software design to realize the architecture on each SoC. This role is focused on power, thermal and limits management but you must also consider other important metrics such as performance and cost.Qualcomm SoCs serve many product categories including smartphones, tablets, wearables, IoT, servers, AR/VR and automotive (telemetry, IVI and ADAS). One challenge in this role is to drive commonality in the architecture across these diverse product categories.\n\nJob function / Responsibilities\nWork with engineers across a range of disciplines (e.g. hardware, software and systems) and technologies (e.g. advanced CPUs, Hexagon DSPs, Adreno GPUs, AR/VR, ML/AI, 5G modems, Wireless LAN, and GPS)\nParticipate in defining and communicating next generation architectures for Qualcomm SoCs with a focus on power, thermal and limits management\nDrive the process of converting the power, thermal and limits management architecture into a software design and software requirements for each SoC\nWork with software teams to provide guidance on the architecture and design, and to help resolve issues\nDesign tools to identify and debug power consumption issues on development platforms and commercial devices\n\n\nPreferred skills/experience\n\n8+ yrs of experience in software development for SoCs and platforms in wireless, automotive and/or IOT\n\nStrong analytical skills and the ability to approach problems at a system level\n\nOne or more of the following:\nDevice driver or board support package (BSP) knowledge or development experience\nExperience with one or more RTOSs\nExperience with ADAS or in vehicle infotainment systems\nUnderstanding of ARM processor architectures\nExperience in power, thermal and/or limits management at the system or device driver level\nExperience with virtualization and hypervisors\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\n\n2+ years of work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'software development', 'iot', 'java', 'software engineering', 'board support package', 'python', 'virtual reality', 'c', 'software design', 'vxworks', 'device drivers', 'spi', 'artificial intelligence', 'rtos', 'computer science', 'embedded systems', 'embedded c', 'linux', 'information systems', 'i2c']",2025-06-12 06:35:08
Engineer staff -Gstreamer Plugin development,Qualcomm,7 - 12 years,Not Disclosed,['Hyderabad'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nWe are seeking a skilled Engineer with extensive experience in the GStreamer multimedia framework. The ideal candidate will be responsible for designing, developing, and optimizing multimedia applications and systems. This role requires a deep understanding of multimedia processing, pipeline architecture, and the ability to work on complex projects.Minimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 7+ years of Software Engineering or related work experience. ORMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Software Engineering or related work experience. ORPhD in Engineering, Information Systems, Computer Science, or related field and 2+ year of Software Engineering or related work experience.\n7+ years of academic or work experience with Programming Language such as C, C++, Java, Python, etc.Experience with majority in Multimedia framework & Gstreamer plugins development.Strong programming skills in C and C++ for embedded systemsGood knowledge about AI/ML applications developementsExposure to developing solutions on Linux is mustStrong in multi-threaded programming, synchronization and IPCsStrong Software design skills and ability to guide team of engineersGood knowledge on software development processesNeed very good Communication skills and ability to work with cross functional teamsExposure to other media frameworks such as ffmpeg, directshow, stagefright is a plusGood knowledge on V4L2, Pulseaudio, Alsa, OpenGLES is a plus.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\n\n2+ years of work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'c', 'multimedia framework', 'linux', 'gstreamer', 'python', 'software development', 'software design', 'plugins', 'opengl es', 'pipeline architecture', 'artificial intelligence', 'multimedia', 'stagefright', 'java', 'alsa', 'computer science', 'multithreading', 'software engineering', 'ffmpeg']",2025-06-12 06:35:11
Security Engineer,Indian / Global Digital Organization,6 - 8 years,Not Disclosed,['Gurugram'],"Key Skills: Cloud Security, Cyber Security, AI Artificial intelligence.\nRoles and Responsibilities:\nSecurity Engineering:\nBuild and integrate security solutions such as firewalls, encryption tools, and intrusion detection systems to safeguard critical infrastructure and data.\nCollaborate with development teams to embed security measures throughout the software development lifecycle (SDLC).\nAutomate security workflows, vulnerability management, and incident response processes to enhance efficiency and response time.\nLead security initiatives to address emerging threats and ensure systems are resilient to evolving cyber risks.\nCloud Security:\nDesign, implement, and manage secure cloud architectures across AWS, Azure, and Google Cloud platforms.\nLeverage AI/ML-driven security tools for enhanced cloud monitoring, threat detection, and automated incident response.\nAutomate cloud security configurations and utilize AI to conduct predictive vulnerability assessments.\nWork closely with DevOps and infrastructure teams to implement robust, automated security controls in cloud environments.\nData Protection Controls:\nDesign and manage comprehensive data protection strategies including encryption, tokenization, and data masking practices to ensure data confidentiality and integrity.\nExperience Requirement:\n6-8 years of experience in building and integrating security solutions across diverse environments.\nStrong knowledge of cloud platforms such as AWS, Azure, and Google Cloud, including cloud security frameworks and best practices.\nHands-on experience with AI/ML-powered security tools for monitoring, detection, and response.\nProficiency in automating security operations and infrastructure configurations.\nExperience working in cross-functional teams, including DevOps and software engineering, to enforce security standards throughout the development lifecycle.\nFamiliarity with industry-standard protocols, tools, and methodologies in vulnerability assessment and incident management.\nEducation: B.Tech M.Tech (Dual), B.Tech.",Industry Type: Beauty & Personal Care,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Cloud Security', 'Cyber Security', 'AI Artificial intelligence.']",2025-06-12 06:35:13
J PED Engineer,Tata Technologies,2 - 5 years,Not Disclosed,"['Pune', 'Bengaluru']","Role Summary:\nThe Performance, Efficiency & Drivability (PED) Attributes Engineer is responsible for supporting the PED Lead Engineer with data analysis, summaries and judgement to support the delivery of Propulsion Efficiency Performance and Drivability Attributes and Features across various vehicle architectures and powertrains. A PED Engineer s scope of work spans the entire vehicle development cycle, contributing to targets definition, competitors benchmark analysis, management of attribute inputs and trades, vehicle development and sign off to brand DNA.\nWe are looking for a junior engineer to add to our dynamic and growing team. The successful candidate will work on the delivery of our new lineup of Battery Electric Vehicles, supporting the Lead Engineers in the delivery of Propulsion Efficiency.",,,,"['J PED Engineering', 'benchmark analysis', 'D&R', 'UK Driving License', 'vehicle development cycle', 'PED tools', 'FMA process', '8D', 'Quality processes']",2025-06-12 06:35:15
Artificial Intelligence Engineer,Winningstrategy Consulting,2 - 4 years,6-9 Lacs P.A.,['Mumbai'],"Seeking AI Engineer to build intelligent, task-driven agents using React & FastAPI. Must blend AI/ML expertise with software skills to create scalable, modular systems for API/UI interaction.\n\nRequired Candidate profile\n1. 2+ yrs in AI dev\n2. Strong in FastAPI, React, Python\n3. Built LLM-based agent workflows\n4. Used vector DB, LangChain, OpenAI\n5. Deployed on cloud(Azure, AWS, GCP)\n6. Scalable, UI-integrated systems",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Machine Learning', 'Cloud Deployment', 'Vector Db', 'Langchain', 'Natural Language Processing', 'Python Development']",2025-06-12 06:35:17
Python and Machine Learning Programmer,Panacorp Software Solutions,1 - 3 years,Not Disclosed,['Nagercoil'],"Job Overview:\nWe are looking for a skilled Python and Data Science Programmer to develop and implement data-driven solutions. The ideal candidate should have strong expertise in Python, machine learning, data analysis, and statistical modeling.\n\nKey Responsibilities:\nData Analysis & Processing: Collect, clean, and preprocess large datasets for analysis.\nMachine Learning: Build, train, and optimize machine learning models for predictive analytics.\nAlgorithm Development: Implement data science algorithms and statistical models for problem-solving.\nAutomation & Scripting: Develop Python scripts and automation tools for data processing and reporting.\nData Visualization: Create dashboards and visual reports using Matplotlib, Seaborn, Plotly, or Power BI/Tableau.\nDatabase Management: Work with SQL and NoSQL databases for data retrieval and storage.\nCollaboration: Work with cross-functional teams, including data engineers, business analysts, and software developers.\nResearch & Innovation: Stay updated with the latest trends in AI, ML, and data science to improve existing models.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'NoSQL', 'Power BI', 'Database Management', 'Plotly', 'Data Analysis', 'Seaborn', 'Tableau', 'SQL']",2025-06-12 06:35:19
Python and Machine Learning Programmer,Panacorp Software Solutions,1 - 3 years,Not Disclosed,['Nagercoil'],"Job Overview:\nWe are looking for a skilled Python and Data Science Programmer to develop and implement data-driven solutions. The ideal candidate should have strong expertise in Python, machine learning, data analysis, and statistical modeling.\n\nKey Responsibilities:\nData Analysis & Processing: Collect, clean, and preprocess large datasets for analysis.\nMachine Learning: Build, train, and optimize machine learning models for predictive analytics.\nAlgorithm Development: Implement data science algorithms and statistical models for problem-solving.\nAutomation & Scripting: Develop Python scripts and automation tools for data processing and reporting.\nData Visualization: Create dashboards and visual reports using Matplotlib, Seaborn, Plotly, or Power BI/Tableau.\nDatabase Management: Work with SQL and NoSQL databases for data retrieval and storage.\nCollaboration: Work with cross-functional teams, including data engineers, business analysts, and software developers.\nResearch & Innovation: Stay updated with the latest trends in AI, ML, and data science to improve existing models.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'tableau', 'data analysis', 'data science', 'predictive analytics', 'statistical modeling', 'machine learning', 'sql', 'nosql']",2025-06-12 06:35:22
AI Test Lead,Naukri,8 - 13 years,20-32.5 Lacs P.A.,['Bengaluru'],"Role & responsibilities\nKey Responsibilities:\nAI Testing Strategy and Planning\nCollaborate with cross-functional teams to develop comprehensive AI testing strategies and plans for AI-powered applications.\nWork closely with product managers, data scientists, and developers to understand AI model requirements, use cases, and project goals.\nDefine the scope and objectives of AI testing efforts, including performance, accuracy, bias detection, and robustness of AI models. Test Execution for AI Models and Algorithms\nDesign, develop, and execute test cases for AI systems and models (including machine learning and deep learning algorithms).\nTest and validate AI solutions across various stages of the development lifecycle, including model training, testing, and deployment.\nEnsure that AI models meet business requirements and perform accurately under various real-world conditions.\nEvaluate the performance of AI models by assessing speed, efficiency, scalability, and resource utilization.\nPerform manual and automated testing on AI-based applications, platforms, and solutions.\nAI Model Accuracy and Validation\nTest AI models for accuracy, precision, recall, F1 score, and other performance metrics.\nEnsure AI models' fairness by conducting tests for potential bias in decisionmaking processes, especially in clinical or medical applications.\nValidate AI model predictions against real-world data, ensuring that results are consistent, reliable, and actionable. Also, need to look the test results from a business perspective and help evaluate the balance between risks and benefits.\nCollaboration and Knowledge Sharing\nWork with data scientists, AI engineers and Test Manager to improve testing methodologies and continuously optimize AI model testing processes.\nProvide feedback on AI models, pointing out any potential improvements in testing coverage or areas for model retraining.\nCommunicate findings, bugs, and issues related to AI models to technical teams, ensuring prompt resolution.\nHelp the team set up AI Testing standards, make informed decisions, and build knowledge across projects\nHelp the team in decision-making processes, such as whether to continue or stop investments based on testing results. Test Automation for AI Projects\nDevelop and implement automated testing scripts and frameworks specifically designed for AI applications.\nUtilize AI testing tools and frameworks (RAGAS etc.) to automate the validation of AI models and algorithms.\nIntegrate automated AI testing within continuous integration and continuous deployment (CI/CD) pipelines.\nCompliance and Regulatory Testing\nEnsure that AI applications comply with industry-specific regulations, especially in the pharma and healthcare sectors (e.g., FDA regulations, HIPAA compliance).\nVerify that all AI-driven processes adhere to ethical standards and data privacy laws.\nContinuous Improvement and Research\nStay up-to-date with the latest trends, tools, and techniques in AI testing and apply these advancements to optimize the testing process.\nParticipate in AI testing forums and workshops, contributing insights to improve best practices within the team. Reporting and Documentation\nDocument test results, methodologies, and issues clearly, providing insights into test coverage, risk analysis, and performance benchmarks.\nPrepare detailed reports for both technical and non-technical stakeholders, summarizing testing outcomes and potential risks associated with AI implementations.\nAssist in the creation and maintenance of knowledge-sharing platforms related to AI testing best practices.\nKey Skills and Qualifications:\nTechnical Expertise\nStrong knowledge of AI/ML testing methodologies and best practices.\nExperience with any AI development frameworks and libraries such as TensorFlow, Keras, PyTorch, scikit-learn, RAGAS and MLlib.\nExperience in testing tools and environments for AI-based systems (e.g., Jupyter Notebooks, Apache Spark, and DataRobot).\nExperience with performance testing tools like Grafana K6 and JMeter for AI solutions.\nKnowledge of Python (Must to have), R, JavaScript or other programming languages frequently used in AI/ML.\nKnowledge of cloud technologies like Microsoft Azure / AWS.\nUnderstanding of test automation frameworks and experience in tools like Cypress, Playwright and Pytest for automating AI tests. AI Model Evaluation\nSolid understanding of machine learning and deep learning models, including supervised and unsupervised learning techniques.\nFamiliarity with evaluating AI models on metrics such as accuracy, precision, recall, F1 score, confusion matrices, and AUC.\nAbility to identify and test for model biases, fairness, and ethical implications, especially in sensitive applications like healthcare and pharma. Analytical and Problem-Solving Skills\nStrong problem-solving abilities and keen attention to detail, with a systematic approach to diagnosing and resolving AI-related issues.\nAbility to perform root cause analysis of issues in AI algorithms and suggest actionable fixes.\nCollaboration and Communication\nExcellent teamwork and communication skills, with the ability to collaborate with cross-functional teams, including data scientists, engineers, and product managers.\nStrong verbal and written communication skills to convey technical information clearly and concisely to both technical and non-technical stakeholders.\nExperience\nMinimum of 8+ years experience in software testing, with at least 2 years focused on testing AI/ML models or AI-based applications.\nProven experience in testing AI/ML algorithms in production or staging environments.\nExperience in testing Visual AI Assistant Applications is good to have.\nExperience working in a regulated industry (such as pharmaceuticals or healthcare) is a plus.\nPreferred Qualifications:\nExperience with cloud platforms (e.g., AWS, Azure) for deploying AI applications and models. Certification in AWS/Azure will be good to have.\nFamiliarity with DevOps practices and integrating AI testing into CI/CD pipelines.\nCertification in AI/ML or related testing frameworks (e.g. ISTQB AI Tester)\nThis AI Tester role is a unique opportunity to shape the future of AI in the pharmaceutical industry. If youre passionate about AI, testing, and making a difference in healthcare, we encourage you to apply.\n\nPreferred candidate profile",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation Testing', 'AI/ ML', 'Python', 'Performance Testing', 'Automation Strategy', 'AI Framework', 'AI testing']",2025-06-12 06:35:24
Senior Data Manager/ Lead,Codeforce 360,6 - 8 years,Not Disclosed,['Hyderabad'],"Job Description:\nWe are looking for a highly experienced and dynamic Senior Data Manager / Lead to oversee a team of Data Engineers and Data Scientists. This role demands a strong background in data platforms such as Snowflake and proficiency in Python, combined with excellent people management and project leadership skills. While hands-on experience in the technologies is beneficial, the primary focus of this role is on team leadership, strategic planning, and project delivery .\n\nJob Title : Senior Data Manager / Lead\nLocation: Hyderabad (Work From Office)\nShift Timing: 10AM-7PM\nKey Responsibilities:\nLead, mentor, and manage a team of Data Engineers and Data Scientists.\nOversee the design and implementation of data pipelines and analytics solutions using Snowflake and Python.\nCollaborate with cross-functional teams (product, business, engineering) to align data solutions with business goals.\nEnsure timely delivery of projects, with high quality and performance.\nConduct performance reviews, training plans, and support career development for the team.\nSet priorities, allocate resources, and manage workloads within the data team.\nDrive adoption of best practices in data management, governance, and documentation.\nEvaluate new tools and technologies relevant to data engineering and data science.\n\nRequired Skills & Qualifications:\n6+ years of experience in data-related roles, with at least 23 years in a leadership or management position.\nStrong understanding of Snowflake architecture, performance tuning, data sharing, security, etc.\nSolid knowledge of Python for data engineering or data science tasks.\nExperience in leading data migration, ETL/ELT, and analytics projects.\nAbility to translate business requirements into technical solutions.\nExcellent leadership, communication, and stakeholder management skills.\nExposure to tools like Databricks, Dataiku, Airflow, or similar platforms is a plus.\nBachelors or Master’s degree in Computer Science, Engineering, Mathematics, or a related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Data Bricks', 'Python', 'Airflow', 'Data Migration', 'Dataiku', 'Data Warehousing', 'ETL', 'ELT', 'SQL']",2025-06-12 06:35:26
Associate- Referral - Decision Science / Data Science,Axtria,3 - 5 years,Not Disclosed,['Gurugram'],"Position Summary \n\nThis Requisition is for the Employee Referral Campaign.\n\nWe are seeking high-energy, driven, and innovative Data Scientists to join our Data Science Practice to develop new, specialized capabilities for Axtria, and to accelerate the company’s growth by supporting our clients’ commercial & clinical strategies.\n\n Job Responsibilities \n\nBe an Individual Contributor tothe Data Science team and solve real-world problems using cutting-edge capabilities and emerging technologies.\n\nHelp clients translate the business use cases they are trying to crack into data science solutions. Provide genuine assistance to users by advising them on how to leverage Dataiku DSS to implement data science projects, from design to production.\n\nData Source Configuration, Maintenance, Document and maintain work-instructions.\n\nDeep working onmachine learning frameworks such as TensorFlow, Caffe, Keras, SparkML\n\nExpert knowledge in Statistical and Probabilistic methods such as SVM, Decision-Trees, Clustering\n\nExpert knowledge of python data-science and math packages such as NumPy , Pandas, Sklearn\n\nProficiency in object-oriented languages (Java and/or Kotlin),Python and common machine learning frameworks(TensorFlow, NLTK, Stanford NLP, Ling Pipe etc\n\n\n Education \n\nBachelor Equivalent - Engineering\nMaster's Equivalent - Engineering\n\n Work Experience \n\nData Scientist 3-5 years of relevant experience in advanced statistical and mathematical models and predictive modeling using Python. Experience in the data science space prior relevant experience in Artificial intelligence and machine Learning algorithms for developing scalable models supervised and unsupervised techniques likeNLP and deep Learning Algorithms. Ability to build scalable models using Python, R-Studio, R Shiny, PySpark, Keras, and TensorFlow. Experience in delivering data science projects leveraging cloud infrastructure. Familiarity with cloud technology such as AWS / Azure and knowledge of AWS tools such as S3, EMR, EC2, Redshift, and Glue; viz tools like Tableau and Power BI. Relevant experience in Feature Engineering, Feature Selection, and Model Validation on Big Data. Knowledge of self-service analytics platforms such as Dataiku/ KNIME/ Alteryx will be an added advantage.\n\nML Ops Engineering 3-5 years of experience with MLOps Frameworks like Kubeflow, MLFlow, Data Robot, Airflow, etc., experience with Docker and Kubernetes, OpenShift. Prior experience in end-to-end automated ecosystems including, but not limited to, building data pipelines, developing & deploying scalable models, orchestration, scheduling, automation, and ML operations. Ability to design and implement cloud solutions and ability to build MLOps pipelines on cloud solutions (AWS, MS Azure, or GCP). Programming languages like Python, Go, Ruby, or Bash, a good understanding of Linux, knowledge of frameworks such as Keras, PyTorch, TensorFlow, etc. Ability to understand tools used by data scientists and experience with software development and test automation. Good understanding of advanced AI/ML algorithms & their applications.\n\nGen AI :Minimum of 4-6 years develop, test, and deploy Python based applications on Azure/AWS platforms.Must have basic knowledge on concepts of Generative AI / LLMs / GPT.Deep understanding of architecture and work experience on Web Technologies.Python, SQL hands-on experience.Expertise in any popular python web frameworks e.g. flask, Django etc. Familiarity with frontend technologies like HTML, JavaScript, REACT.Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT.Can interact with client on GenAI related capabilities and use cases.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'gpm', 'machine learning', 'python data', 'statistics', 'kubernetes', 'microsoft azure', 'numpy', 'javascript', 'sql', 'docker', 'pandas', 'tensorflow', 'java', 'django', 'predictive modeling', 'python web framework', 'mathematical modeling', 'pytorch', 'keras', 'aws', 'flask', 'advanced statistical']",2025-06-12 06:35:28
Director - Data Science,Axtria,12 - 17 years,Not Disclosed,['Noida'],"Minimum 12+ years of relevant experience in building software applications in data and analytics field\nEnhance the go-to-market strategy by designing new and relevant solution frameworks to accelerate our clients’ journeys for impacting patient outcomes. Pitch for these opportunities and craft winning proposals to grow the Data Science Practice.\nBuild and lead a team of data scientists and analysts, fostering a collaborative and innovative environment.\nOversee the design and delivery of the models, ensuring projects are completed on time and meet business objectives.\nEngaging in consultative selling with clients to grow/deliver business.\nDevelop and operationalize scalable processes to deliver on large & complex client engagements.\nExtensive hands-on experience with Python, R, or Julia, focusing on data science and generative AI frameworks.\nExpertise in working with generative models such as GPT, DALL-E, Stable Diffusion, Codex, and MidJourney for various applications.\nProficiency in fine-tuning and deploying generative models using libraries like Hugging Face Transformers, Diffusers, or PyTorch Lightning.\nStrong understanding of generative techniques, including GANs, VAEs, diffusion models, and autoregressive models.\nExperience in prompt engineering, zero-shot, and few-shot learning for optimizing generative AI outputs across different use cases.\nExpertise in managing generative AI data pipelines, including preprocessing large-scale multimodal datasets for text, image, or code generation.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['application software', 'python', 'artificial intelligence', 'r', 'julia', 'hive', 'natural language processing', 'neural networks', 'predictive analytics', 'machine learning', 'sql', 'deep learning', 'java', 'data science', 'spark', 'predictive modeling', 'pytorch', 'hadoop', 'statistics']",2025-06-12 06:35:31
Associate Director - Data Science,Axtria,10 - 15 years,Not Disclosed,['Noida'],"Minimum of 10+ years in development, testing and deployment of React, JavaScript, Python based applications on Azure/AWS platforms\nExtensive experience with frontend and backend technologies to develop AI/GenAI applications.\nSoftware development experience in REACT, JavaScript/TypeScript, Python, FastAPI/Flask/Django is needed for UI based applications.\nMust have experience in building production grade application with frontend & backend technologies like HTML, JavaScript, REACT, Python etc.\nDeep understanding of architecture and work experience on Web Technologies\nPython, SQL hands-on experience\nExpertise in any popular python web frameworks e.g. flask, Django etc.",Industry Type: Analytics / KPO / Research,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'production', 'javascript', 'react.js', 'python web framework', 'software testing', 'natural language processing', 'neural networks', 'microsoft azure', 'aws stack', 'machine learning', 'sql', 'deep learning', 'django', 'data science', 'html', 'typescript', 'flask', 'aws']",2025-06-12 06:35:33
Information Security Engineer,BMC Software,4 - 9 years,Not Disclosed,['Pune'],"In this role, your primary responsibilities include implementing, configuring, and supporting application security and identity access management technology solutions including generate reports and threat identification\nThe candidate needs to have experience in application security and identity management area.\n\n\nHere is how, through this exciting role, YOU will contribute to BMC's and your own success:\n\nResponsible for developing and maintaining application security and identify access management technology solutions including Sailpoint/IIQ, Okta Single Sign On, Azure AD, AWS SSO, Cloudflare Web application firewall, penetration testing, developing and maintaining internally developed Python tools and utilities.\nIdentify and develop integration opportunities between security solutions and automation but not exclusively.\nWork with virtual team/management to collect and prioritize system requirements, develop delivery plans and meet aggressive deadlines, develop code, perform unit as well as system integration testing, participate in architecture of new capabilities and debug, troubleshoot production support.\nCoordinate quality assurance and testing with users of the new functionalities/capabilities.\nGenerate reports for capability implementation\nReview report data and identify threats to discuss with management for mitigation\nEnsure that project issues are communicated in a timely and effective manner\nOther duties as assigned.\n\nTo ensure you re set up for success, you will bring the following skillset & experience:\n\nExperiences in Sailpoint IIQ, Python and Java development (automation, integration, etc) and application security are must-have.\nFamiliar with security tools in software development lifecycle as well as Azure AD, AWS APIs/CLI, containers experiences are nice to have.\nKnowledge of Artificial Intelligence learning model\nAbility to work with little supervision as well as being a team player\nExcellent verbal, written, and interpersonal communication skills\nExperience working with remote teams\n4 years + experience\nShould be willing to work in 12.30 PM to 9.30 PM shift",Industry Type: Software Product,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Information Security', 'python', 'java', 'application security', 'sailpoint', 'java development', 'aws', 'artificial intelligence']",2025-06-12 06:35:36
Python Engineer - ML/Big Query - Hyd/Chennai/Bangalore,People staffing Solutions,5 - 10 years,12-20 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Key Responsibilities:\nDesign, develop, and maintain scalable and optimized ETL pipelines using Python and SQL.\nWork with Google BigQuery and other cloud-based platforms to build data warehousing solutions.\nDevelop and deploy ML models; collaborate with Data Scientists for productionizing models.\nWrite efficient and optimized SQL queries for large-scale data processing.\nBuild APIs using Flask/Django for machine learning and data applications.\nWork with both SQL and NoSQL databases including Elasticsearch.\nImplement data ingestion using batch and streaming technologies.\nEnsure data quality, integrity, and governance across the data lifecycle.\nAutomate and optimize CI/CD pipelines for data solutions.\nCollaborate with cross-functional teams to gather data requirements and deliver solutions.\nTroubleshoot and monitor data pipelines for seamless operations.\nRequired Skills & Qualifications:\nBachelor's or Master's degree in Computer Science, Engineering, or related field.\n5+ years of experience with Python in a data engineering and/or ML context.\nStrong hands-on experience with SQL, BigQuery, and cloud data platforms (preferably GCP).\nPractical knowledge of ML concepts and experience developing ML models.\nProficiency in frameworks such as Flask and Django.\nExperience with NoSQL databases and data streaming technologies.\nSolid understanding of data modeling, warehousing, and ETL frameworks.\nFamiliarity with CI/CD tools and automation best practices.\nExcellent communication, problem-solving, and collaboration skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Machine Learning', 'Python', 'SQL', 'Pandas', 'Numpy', 'Ml', 'Flask']",2025-06-12 06:35:38
Senior Associate - Data Science,Axtria,3 - 8 years,Not Disclosed,['Noida'],"Job Summary-\nData Scientist with good hands-on experience of 3+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nJob Responsibilities-\n\n1. Hands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\n2. Proficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\n3. Experience of working in large teams and using collaboration tools like GIT, Jira and Confluence\n4. Good understanding of any of the cloud platform - AWS, Azure or GCP\n5. Understanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\n6. Should have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\n7. Should be able to mentor and guide mid to large sized teams under him/her\n\nJob -\n1. Strong experience on Spark with Scala/Python/Java\n2. Strong proficiency in building/training/evaluating state of the art machine learning models and its deployment\n3. Proficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\n4. Proficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'keras', 'spark mllib', 'jira', 'sentiment analysis', 'lingpipe', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-12 06:35:41
Senior Associate - Data Science,Axtria,2 - 5 years,Not Disclosed,['Noida'],"Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT\nSoftware development experience in python is needed as backend for UI based applications\nBe a part of large delivery teams working on advanced projects when expert assistance is required.\nDeliver advanced Data Science capabilities to businesses in a meaningful manner through successful proof-of-concept solutions, and later smoothly transition the proof-of-concept into production.\nCreate Technical documents, develop, test, and deploy data analytics processes using Python, SQL on Azure/AWS platforms\nCan interact with client on GenAI related capabilities and use cases\n\n\nMust have\n\nSkills:\n\n\nMinimum of 3-5years develop, test, and deploy Python based applications on Azure/AWS platforms\nMust have basic knowledge on concepts of Generative AI / LLMs / GPT\nDeep understanding of architecture and work experience on Web Technologies\nPython, SQL hands-on experience\nExpertise in any popular python web frameworks e.g. flask, Django etc.\nFamiliarity with frontend technologies like HTML, JavaScript, REACT",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'software testing', 'gpm', 'microsoft azure', 'python web framework', 'data analytics', 'neural networks', 'aws stack', 'machine learning', 'javascript', 'artificial intelligence', 'sql', 'react.js', 'deep learning', 'django', 'data science', 'html', 'flask', 'aws']",2025-06-12 06:35:44
Manager - Data Science,Axtria,6 - 11 years,Not Disclosed,['Noida'],"Job Summary-\n\nData Scientist with good hands-on experience of 6+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nJob Responsibilities-\n\nHands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\nProficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\nExperience of working in large teams and using collaboration tools like GIT, Jira and Confluence\nGood understanding of any of the cloud platform – AWS, Azure or GCP\nUnderstanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\nShould have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\nShould be able to mentor and guide mid to large sized teams under him/her\n\n\nJob -\nStrong experience on Spark with Scala/Python/Java\nStrong proficiency in building/training/evaluating state of the art machine learning models and its deployment\nProficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\nProficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'keras', 'spark mllib', 'jira', 'sentiment analysis', 'lingpipe', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-12 06:35:46
Manager - Data Science,Axtria,6 - 11 years,Not Disclosed,['Gurugram'],"JOB OBJECTIVE Manager with good hands-on experience of 6+ years in developing state of the art and scalable Machine Learning models and their operationalization, leveraging off-the-shelf workbench production.\n\nKEY RESPONSIBILITIES\n\n\nNecessary Skills –\n6+ years of experience of model development using Python/PySpark libraries. Development on Databricks or Dataiku DSS (Data Science Studio) environment would be a plus\nStrong experience on Spark with Scala/Python/Java\nStrong proficiency in building/training/evaluating state of the art machine learning models and its deployment\nProficiency in Statistical and Probabilistic methods such as SVM, Decision-Trees, Bagging and Boosting Techniques, Clustering\nProficiency in Core NLP techniques like Text Classification, Named Entity Recognition (NER), Topic Modeling, Sentiment Analysis, etc. Understanding of Generative AI / Large Language Models / Transformers would be a plus\nHands on experience in Python data-science and math packages such as NumPy, Pandas, Sklearn, Seaborn, PyCaret, Matplotlib\nProficiency in Python and common Machine Learning frameworks (TensorFlow, NLTK, Stanford NLP, PyTorch, Ling Pipe, Caffe, Keras, SparkML and OpenAI etc.)\nExperience of working in large teams and using collaboration tools like GIT, Jira and Confluence\nGood understanding of any of the cloud platform – AWS, Azure or GCP\nUnderstanding of Commercial Pharma landscape and Patient Data / Analytics would be a huge plus\nShould have an attitude of willingness to learn, accepting the challenging environment and confidence in delivering the results within timelines. Should be inclined towards self motivation and self-driven to find solutions for problems.\nShould be able to mentor and guide mid to large sized teams under him/her",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scala', 'java', 'spark', 'machine learning algorithms', 'python', 'confluence', 'scikit-learn', 'nltk', 'pyspark', 'training', 'numpy', 'tensorflow', 'git', 'seaborn', 'gcp', 'pytorch', 'model development', 'keras', 'jira', 'sentiment analysis', 'caffe', 'microsoft azure', 'pandas', 'matplotlib', 'aws', 'statistics']",2025-06-12 06:35:50
Senior Associate - Data Science,Axtria,4 - 6 years,Not Disclosed,['Noida'],"o Minimum of 4-6 years' experience in developing, testing, and deploying Python based applications on Azure/AWS platforms\no Must have basic knowledge on concepts of Generative AI / LLMs / GPT\no Deep understanding of architecture and work experience on Web Technologies\no Python, SQL hands-on experience\no Expertise in any popular python web frameworks e.g. flask, Django etc.\no Familiarity with frontend technologies like HTML, JavaScript, REACT",Industry Type: Analytics / KPO / Research,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'gpm', 'django', 'python web framework', 'flask', 'natural language processing', 'neural networks', 'microsoft azure', 'object detection', 'machine learning', 'javascript', 'artificial intelligence', 'sql', 'react.js', 'deep learning', 'data science', 'computer vision', 'html', 'aws']",2025-06-12 06:35:52
Manager - Data Science,Axtria,4 - 6 years,Not Disclosed,['Gurugram'],"Be an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on UI\nSoftware development experience in REACT, JavaScript/TypeScript, python is needed as frontend and backend for UI based applications\nBe a part of large delivery teams working on advanced projects when expert assistance is required.\nDeliver advanced Data Science capabilities to businesses in a meaningful manner through successful proof-of-concept solutions, and later smoothly transition the proof-of-concept into production.\nCreate Technical documents, develop, test, and deploy data analytics processes using REACT, Python, SQL on Azure/AWS platforms\nCan interact with client on GenAI related capabilities and use cases\n\n\nMust have\n\nSkills:\n\n\nMinimum of 4-6 years develop, test, and deploy React, JavaScript, Python based applications on Azure/AWS platforms\nMust have experience in building production grade application with frontend & backend technologies like HTML, JavaScript, REACT, Python etc.\nDeep understanding of architecture and work experience on Web Technologies\nPython, SQL hands-on experience\nExpertise in any popular python web frameworks e.g. flask, Django etc.\nBasic knowledge on concepts of Generative AI / LLMs / GPT will be beneficial",Industry Type: Analytics / KPO / Research,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'production', 'javascript', 'react.js', 'python web framework', 'data analytics', 'software testing', 'natural language processing', 'gpm', 'neural networks', 'microsoft azure', 'aws stack', 'machine learning', 'sql', 'deep learning', 'django', 'data science', 'html', 'typescript', 'flask', 'aws']",2025-06-12 06:35:55
Senior Lead business execution consultant,Wells Fargo,7 - 12 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Senior Lead business execution consultant\n\nIn this role, you will:\nAct as a Business Execution advisor to leadership to drive performance and initiatives, and develop and implement information delivery or presentations to key stakeholders and senior management",,,,"['Business execution', 'Business Implementation', 'Data Engineering', 'NLP', 'generative AI', 'Data Mining', 'machine learning', 'Strategic Planning', 'agentic AI']",2025-06-12 06:35:57
Senior Cloud Engineer - AWS,S&P Global Market Intelligence,5 - 10 years,Not Disclosed,"['Hyderabad', 'Gurugram']","Grade Level (for internal use):\n10\nS&P Global Commodity Insights\nThe Role: Senior Cloud Engineer\nThe Location: Hyderabad, Gurgaon\nThe Team: The Cloud Engineering Team is responsible for designing, implementing, and maintaining cloud infrastructure that supports various applications and services within the S&P Global Commodity Insights organization. This team collaborates closely with data science, application development, and security teams to ensure the reliability, security, and scalability of our cloud solutions.\nThe Impact: As a Cloud Engineer, you will play a vital role in deploying and managing cloud infrastructure that supports our strategic initiatives. Your expertise in AWS and cloud technologies will help streamline operations, enhance service delivery, and ensure the security and compliance of our environments.\nWhats in it for you: This position offers the opportunity to work on cutting-edge cloud technologies and collaborate with various teams across the organization. You will gain exposure to multiple S&P Commodity Insights Divisions and contribute to projects that have a significant impact on the business. This role opens doors for tremendous career opportunities within S&P Global.\nResponsibilities:\nDesign and deploy cloud infrastructure using core AWS services such as EC2, S3, RDS, IAM, VPC, and CloudFront, ensuring high availability and fault tolerance.\nDeploy, manage, and scale Kubernetes clusters using Amazon EKS, ensuring high availability, secure networking, and efficient resource utilization.\nDevelop secure, compliant AWS environments by configuring IAM roles/policies, KMS encryption, security groups, and VPC endpoints.\nConfigure logging, monitoring, and alerting with CloudWatch, CloudTrail, and GuardDuty to support observability and incident response.\nEnforce security and compliance controls via IAM policy audits, patching schedules, and automated backup strategies.\nMonitor infrastructure health, respond to incidents, and maintain SLAs through proactive alerting and runbook execution.\nCollaborate with data science teams to deploy machine learning models using Amazon SageMaker, managing model training, hosting, and monitoring.\nAutomate and schedule data processing workflows using AWS Glue, Step Functions, Lambda, and EventBridge to support ML pipelines.\nOptimize infrastructure for cost and performance using AWS Compute Optimizer, CloudWatch metrics, auto-scaling, and Reserved Instances/Savings Plans.\nWrite and maintain Infrastructure as Code (IaC) using Terraform or AWS CloudFormation for repeatable, automated infrastructure deployments.\nImplement disaster recovery, backups, and versioned deployments using S3 versioning, RDS snapshots, and CloudFormation change sets.\nSet up and manage CI/CD pipelines using AWS services like CodePipeline, CodeBuild, and CodeDeploy to support application and model deployments.\nManage and optimize real-time inference pipelines using SageMaker Endpoints, Amazon Bedrock, and Lambda with API Gateway to ensure reliable, scalable model serving.\nSupport containerized AI workloads using Amazon ECS or EKS, including model serving and microservices for AI-based features.\nCollaborate with SecOps and SRE teams to uphold security baselines, manage change control, and conduct root cause analysis for outages.\nParticipate in code reviews, design discussions, and architectural planning to ensure scalable and maintainable cloud infrastructure.\nMaintain accurate and up-to-date infrastructure documentation, including architecture diagrams, access control policies, and deployment processes.\nCollaborate cross-functionally with application, data, and security teams to align cloud solutions with business and technical goals.\nStay current with AWS and AI/ML advancements, suggesting improvements or new service adoption where applicable.\nWhat Were Looking For:\nStrong understanding of cloud infrastructure, particularly AWS services and Kubernetes.\nProven experience in deploying and managing cloud solutions in a collaborative Agile environment.\nAbility to present technical concepts to both business and technical audiences.\nExcellent multi-tasking skills and the ability to manage multiple projects under tight deadlines.\nBasic Qualifications:\nBA/BS in computer science, information technology, or a related field.\n5+ years of experience in cloud engineering or related roles, specifically with AWS.\nExperience with Infrastructure as Code (IaC) tools such as Terraform or AWS CloudFormation.\nKnowledge of container orchestration and microservices architecture.\nFamiliarity with security best practices in cloud environments.\nPreferred Qualifications:\nExtensive Hands-on Experience with AWS Services.\nExcellent problem-solving skills and the ability to work independently as well as part of a team.\nStrong communication skills and the ability to influence stakeholders at all levels.\nExperience with greenfield projects and building cloud infrastructure from scratch.\nBenefits:\n\nHealth & Wellness: Health care coverage designed for the mind and body.\nContinuous Learning: Access a wealth of resources to grow your career and learn valuable new skills.\nInvest in Your Future: Secure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.\nFamily Friendly Perks: Its not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.\nBeyond the Basics: From retail discounts to referral incentive awardssmall perks can make a big difference.",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['AWS', 'Terraform', 'AWS CloudFormation', 'Cloud', 'cloud infrastructure']",2025-06-12 06:36:00
"Principal Engineer, Bridges & Civils, REC",Ramboll,6 - 10 years,Not Disclosed,['Gurugram'],"Principal Engineer, Bridges & Civils, REC\nCompany Description\nAbout Ramboll\nFounded in Denmark, Ramboll is a foundation-owned people company. We have more than 18,000 experts working across our global operations in 35 countries. Our experts are leaders in their fields, developing and delivering innovative solutions in diverse markets including Buildings, Transport, Planning & Urban Design, Water, Environment & Health, Energy, and Management Consulting. We invite you to contribute to a more sustainable future working in an open, collaborative, and empowering company. Combining local experience with global knowledge, we together shape the societies of tomorrow.\nEquality, diversity, and inclusion are at the heart of what we do\nWe believe in the strength of diversity and know that unique experiences and perspectives are vital for creating truly sustainable societies. Therefore, we are committed to providing an inclusive and supportive work environment where everyone can flourish and reach their potential. We welcome applications from candidates of all backgrounds and encourage you to contact our recruitment team to discuss any accommodations you need during the application process.\nJob Description\nPrincipal Engineer, Bridges & Civils, REC \nRamboll in Middle East and Asia Pacific \nAt Ramboll, our 15,000 consulting engineers and scientists; designers and management consultants are based in more than 300 offices in 35 countries across the globe. In the Middle East and Asia Pacific region, we have more than 1,500 experts working across 15 offices present in India, Malaysia, Singapore, China, Hong Kong, Australia, New Zealand, Qatar, and the United Arab Emirates. Our experts are applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health, and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative, and empowering culture. \nJob Description \nWe invite you to bring your strong knowledge on bridge design and Lusas/Sofistik into play as you would be key player in the technical delivery of the project and would carry out the design and would also be responsible of the delivery of design/drawings. To succeed in this role, you must have Knowledge of design codes like Euro code/DMRB/AASHTO/any other international standards and M. Tech degree in Structural Engineering with more than 7 years of experience. Are you our new Principal Engineer - Bridges & Civils? Click the apply-button to send your application. \nInviting bright minds \nDo you want to push the boundaries of your profession and develop your excellence in an open, collaborative, and empowering culture? We work to create a sustainable future, and our inspiring projects and innovative solutions strive to set the standard among our peers. You will join a global company that has been growing successfully since its founding in 1945. Together, we lead and leave a positive impact on societies, companies, and people around the world. \nYou will join our RECdepartment \nAs our new Principal Engineer - Bridges & Civils you will be part of a world class, innovation driven engineering design center owned by an independent trust and its employees. REC is a highly sophisticated center of engineering excellence and based in our India head office in Gurgaon. Working in partnership with all our established offices globally, the Ramboll Engineering Centre (REC) is a center for excellence in design by offering optimized solutions to the rest of the organization. \nYour key tasks and responsibilities will be: \nCarrying out the design and review of the work of Asst Engineer / Design engineers and modelers in the team and maintaining the quality of deliverables. \nParticipate in the design and delivery of Bridge Projects, coordinate with other team members of the drafting/modelling team in accomplishing complex tasks. \nMentoring and supervising asst. Engineers/ Design Engineers and provide inputs to Team Lead for the continued development of the staff in the team \nIs responsible for technical correctness and timely delivery of the design documents and 3D models corresponding to the design. \nAs a REC Project Manager for global engineering Bridge Projects, coordinated with the design team for project planning/preparation of schedule/WBS and delivering projects to time and budget. \nPerform complex analysis using computer modelling and increase efficiencies in the processes and technical design. \nParticipate in skill enhancements of the Team. \nExercises self-discipline and work ethic, respect and follow company policies and procedures.  \nYour starting point for constant growth \nFrom the moment you join Ramboll, we will support your personal and professional development so that you grow with the company. For this role, we believe your starting point is: \nWe are looking for self-motivated team members who meet the following requirements: \nME/ M. Tech degree in Structural Engineering from an institute of repute. \nShould have more than M. Tech + 7 years of experience in Bridge design preferably on existing bridges and structures (strengthening and assessments). Knowledge of design codes like Euro code is mandatory DMRB/AASHTO would be an added advantage. \nGood Knowledge of detailed design of concrete Bridges and steel composite using Lusas/Sofistik/MIDAS with Eurocodes. \nHave hands-on experience in using any of the bridge design software (LUSAS/Sofistik/MIDAS/STAAD Pro etc), \nShould be a good team member and should coordinate with other team members and the project manager for timely delivery of project \nSelf-motivated, team player and able to work independently with minimum supervision. \nFlexible attitude, in an environment with frequently changing deadlines can be relied on to meet deadlines. \nWelcome to our Transport division \nRamboll is a global transportation consultancy, and we work on some of the biggest and most innovative infrastructure projects in the world. We are close to 3,000 bright minds working within Transport worldwide, creating practical, sustainable, and economic solutions for national transport authorities, private contractors, and municipalities alike. \nRamboll in India \nRamboll has more than 1,000 experts working across five offices in India applying their passion to deliver innovative solutions in markets as diverse as Buildings, Transport, Planning & Urban Design, Water, Environment & Health, and Energy. Founded in Denmark, Ramboll is a people company. We invite you to contribute to a sustainable future working in an open, collaborative, and empowering culture. \n  Qualification\nExperience – ME/M. Tech with 7+ years of experience (preferred from IITs/NITs) \nSkills Required – Hands-on experience in detailed design of RCC & prestressed concrete and steel composite bridges based on Eurocodes of practice (Eurocode is mandatory). Exposure to working in an international environment would be preferred. Experience working with Danish bridges/Danish Annexes would be an added advantage. \nSoftware Skills - Sofistik, Midas, Lusas, basics of BIM software, computational design would be an added advantage. \nAdditional Information\nRamboll globally \nRamboll is a leading engineering, architecture, and consultancy company. Working at one of our offices in 35 countries you will join more than 16,000 fellow bright minds in creating innovative and sustainable solutions within Buildings, Transport, Energy, Environment and Health, Architecture, Landscape and Urbanism, Water and Management Consulting. Combining local experience with global knowledge, we help shape the society of tomorrow. \nAlle your information will be kept confidential according to EEO guidelines.  \nWhat we can offer you\nInvestment in your development\nLeaders you can count on, guided by our Leadership Principles\nBe valued for the unique person you are.\nNever be short of inspiration from colleagues, clients, and projects.\nThe long-term thinking of a foundation-owned company\nWe offer:\nA challenging and interesting workday characterized by continuous learning, in an environment where you have many to spar with and learn from.\nOpportunity to work with varied work tasks, across the organization.\nOpportunity to develop and influence your own area of responsibility.\nWork at the heart of sustainable change\nRamboll is a global architecture, engineering, and consultancy company. We believe that the purpose of sustainable change is to create a thriving world for both nature and people. So, that’s where we start – and how we work. At Ramboll, our core strength is our people, and our history is rooted in a clear vision of how a responsible company should act. Being open and curious is a cornerstone of our culture. We embrace an inclusive mindset that looks for fresh, diverse, and innovative perspectives. We respect, embrace, and invite diversity in all forms to actively cultivate an environment where everyone can flourish and realize their full potential.\nReady to join us?\nPlease submit your application. Be sure to include all relevant documents including your CV, cover letter, etc.\nThank you for taking the time to apply! We look forward to receiving your application.",Industry Type: IT Services & Consulting,Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['concrete', 'danish', 'structural engineering', 'project management', 'software', 'etabs', 'bridge design', 'bim', 'staad', 'staad pro', 'midas', 'bridges', 'prestressed concrete', 'environment', 'rcc', 'java', 'lusas', 'civil engineering', 'code writing', 'design', 'international', 'structural design', 'bridge engineering']",2025-06-12 06:36:03
"Data Science Specialist - R/Python, Statistical Analysis, AI/Ml",Cisco,4 - 8 years,Not Disclosed,['Bengaluru'],"Responsibilities:\nAnalysis of cross-customer and customer specific data.\nAnalysis for diagnosis of product and customers specific problems and also to demonstrate value of our data to customers.\nSupport sales and product adoption for data related use-cases (occupancy, captive portal, behavioral metrics, BMS integrations etc)\nHelp design monitoring tools to detect product and customer relative issues around product\nCustomer demonstrations of more sophisticated data products like Firehose. Engineering/Product linkages\nCollaborate with specialist teams to help deliver solutions. (Webex, Meraki etc)\nLeverage on ML based approaches for fault detection tools, for trends and also customer/category analysis\n\nQualifications:\nAdvanced degree or equivalent experience in Engineering, Computer Science, Maths or a related technical field\nProficiency in programming and scripting languagesRand/orPython\nExperience using relational database -SQL\nBasic proficiency withMachine Learning methods and applications\n\nSkills:\nPassion for problem solving.\nHighly driven and customer oriented.\nExcellent communication.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'rest', 'python', 'data analysis', 'natural language processing', 'machine learning', 'relational databases', 'artificial intelligence', 'javascript', 'sql', 'spring', 'r', 'tableau', 'java', 'computer science', 'html', 'mysql', 'data structures', 'data visualization', 'ml', 'statistics']",2025-06-12 06:36:05
AI Lead - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\nThe purpose of this role is to develop minimum viable product (MVP) and comprehensive AI solutions that meet and exceed clients expectations and add value to business.\n\nDo\nManage the product/ solution development using the desired AI techniques\nLead development and implementation of custom solutions through thoughtful use of modern AI technology\nReview and evaluate the use cases and decide whether a product can be developed to add business value\nCreate the overall product development strategy and integrating with the larger interfaces\nCreate AI models and framework and implement them to cater to a business problem\nDraft the desired user Interface and create AI models as per business problem\nAnalyze technology environment and client requirements to define product solutions using AI framework/ architecture\nImplement the necessary security features as per products requirements\nReview the used case and see the latest AI that can be used in products development\nIdentify problem areas and perform root cause analysis and provide relevant solutions to the problem\nTracks industry and application trends and relates these to planning current and future AI needs\nCreate and delegate work plans to the programming team for product development\nInteract with Holmes advisory board for knowledge sharing and best practices\nResponsible for developing and maintaining client relationships with the key strategic partners and decision makers\nDrive discussions and provide consultation around product design as per customer needs\nParticipate in client interactions and gather insights regarding product development\nInteract with vertical delivery and business teams and provide and correct responses to RFP/ client requirements\nAssist in products demonstration and receive feedback from the client\nDesign presentations for seminars, meetings and enclave primarily focused over product\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTalent Management\nEnsure adequate onboarding and training for the team members to enhance capability & effectiveness\nBuild an internal talent pool and ensure their career progression within the organization\nManage team attrition\nDrive diversity in leadership positions\nPerformance Management\nSet goals for the team, conduct timely performance reviews and provide constructive feedback to own direct reports\nEnsure that the Performance Nxt is followed for the entire team\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nDeliver\n\nNo.Performance ParameterMeasure1.Continuous technical project management & deliveryAdoption of new technologies, IP creation, MVP creation, Number of patents filed, Research papers created2.Client CentricityNo. of automation done, On-Time Delivery, cost of delivery, optimal resource allocation3.Capability Building & Team Management% trained on new age skills, Team attrition %, Number of webinars conducted (internal/external)\n\nMandatory Skills: Generative AI. Experience: 5-8 Years.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Generative AI', 'project management', 'resource allocation', 'team management', 'performance management', 'artificial intelligence']",2025-06-12 06:36:08
Artificial Intelligence Engineer,Blue Data Consulting And It Services Private Limit Ed,1 - 3 years,3-6 Lacs P.A.,['Noida( Sector-62 Noida )'],Responsibilities:\n\nDesign and develop AI models and algorithms.\nBuild and train ML systems.\nProcess large datasets.\nDeploy models to production.\nCollaborate with teams to integrate AI solutions.\nEnsure model accuracy.\nStay updated with AI trends.\n\n\nHealth insurance\nLeave encashment\nMaternity leaves\nPaternity leaves\nCourse reimbursements\nCapability building program\nPrevention of sexual harrassment policy,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Tensorflow', 'Machine Learning', 'Deep Learning', 'Data Science', 'Python', 'Matplotlib', 'Azure', 'LLMs', 'Natural Language Processing', 'Scikit-Learn', 'Numpy', 'Pytorch', 'English', 'GIT', 'Algorithms', 'Docker', 'Opencv', 'Pandas', 'Cloud', 'Transformers', 'AWS', 'Kubernetes']",2025-06-12 06:36:10
IT Software Developer,Qualcomm,2 - 7 years,Not Disclosed,['Bengaluru'],"Job Area: Information Technology Group, Information Technology Group > IT Software Developer\n\nGeneral Summary:\n\nWhats in it for you""Qualcomm is enabling a world where everyone and everything can be intelligently connected. Qualcomm 5G and AI innovations are the power behind the connected intelligent edge. You will find our technologies behind and inside the innovations that deliver significant value across multiple industries and to billions of people every day.""Qualcomm engineering teams rely heavily on the latest High-Performance Computing (HPC) technologies to design and develop new products using electronic design automation (EDA) tools. This role provides an opportunity to work on the latest HPC technologies and gain experience in building scalable and fault-tolerant software solutions that are deployed on some of the largest supercomputing infrastructures across the globe.""What are we looking for""Engineering Data Analytics and Applications team (EDAAP) is looking for an experienced developer with a strong programming background. The EDAAP team is responsible for the development of software solutions enabling High Performance Compute grid and large-scale, distributed, analytical applications. They work on components and services for HPC infrastructure optimization, hardware IP management systems, petabyte-scale cloud data platforms and development of machine learning solutions and pipelines.""This role involves designing and developing high-quality software solutions to manage compute environments, including compute grids, EDA licenses, storage, data synchronization, and IT infrastructure. The ideal candidate is an experienced software developer skilled in multiple programming languages and frameworks, parallel programming, efficient algorithms and data structures, design patterns, task automation through tools and scripting.What will you do""This roles responsibilities include:"". Design and develop high-quality software using suitable programming languages and frameworks for HPC infrastructure.. Create reusable components and libraries for future use.. Continuously monitor and upgrade existing applications to ensure they meet current standards and requirements.. Develop and maintain technical documentation to guide future software development projects.. Perform comprehensive code reviews to ensure quality, maintainability, and adherence to best pr. actices.. Collaborate with internal teams to resolve issues by leveraging expertise from various departments.What do we want to see""The ideal candidate will be able to demonstrate some of the following skills:"". Over 2 years of hands-on experience in full stack development.. Proficient in programming languages and frameworks such as Python, Java/J2EE and Angular.. Expertise in using relational databases (PostgreSQL, MySQL) and familiarity with anyone of NoSQL databases (Redis, MongoDB).. Expertise in software lifecycle management, version control, coding, and CI/CD best practices to ensure quality, agility, and security.. Exposure to AI and ML technologies is a plus.. Ability to clearly explain technical concepts and analysis implications to a diverse audience.. Team-oriented, with a strong inclination to work collaboratively.. Bachelors or Masters degree in Computer Science, Computational Science, or a related field.\n\nMinimum Qualifications:\nBachelor's degree in a technical field (e.g., Computer Engineering, Computer Science, Information Systems).\nOR\nBachelors degree in a non-technical field (e.g., Business, Humanities, Marketing) and 1+ year of IT-relevant experience.\nOR\nHigh School Diploma or equivalent and 3+ years of IT-relevant experience.\n\n2+ years of any combination of academic or work experience with programming (e.g., Java, Python, etc.).\n1+ year of any combination of academic or work experience with Data Structures, algorithms, and data stores.\nBachelors / Masters or equivalent degree in computer engineering or in equivalent stream",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'version control', 'ci/cd', 'relational databases', 'data structures', 'algorithms', 'fullstack development', 'python', 'software development', 'redis', 'artificial intelligence', 'nosql', 'angular', 'java', 'postgresql', 'computer science', 'j2ee', 'mysql', 'mongodb', 'ml']",2025-06-12 06:36:12
Python Developer Lead @ Infosys- PAN INDIA,Infosys,3 - 8 years,Not Disclosed,"['Kolkata', 'Pune', 'Delhi / NCR']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Process->Testing processes->Test Automation Process,Technology->Machine Learning->Python\n\nPreferred Skills: Process->Testing processes->Test Automation Process Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BE,BSc,BTech",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Python Development', 'Flask']",2025-06-12 06:36:14
Early Career Professional-E,Conduent,2 - 6 years,Not Disclosed,['Bengaluru'],"Join Us \nIf you are seeking an opportunity to make a real impact in a company that appreciates ideas and new ways of thinking, come join us and grow with a team of people who will challenge and inspire you to be the best!\nAbout the Role\nThis role is designed as an entry-level position for applicants with strong skill sets in programming (logical reasoning, analytical skills), systems configuration and testing related to systems that support different business functions.\n : \nBachelor\\u2019s degree in computer science, Information Technology, or a related field from a reputable institution with 7 CGPA and Above. Strong foundational knowledge of computer science principles and programming concepts.\nProficiency in at least one programming language, such as Java, Python, .Net, C, JavaScript or SQL.\nFamiliarity with software development lifecycle (SDLC) methodologies and best practices. Ability to quickly learn and adapt to new technologies and tools.\nGood understanding of data structures, algorithms, and object-oriented design principles. Excellent problem-solving skills with keen attention to detail.\nAbility to work effectively in a fast-paced, collaborative environment.\nDemonstrated ability to work independently and take initiative to complete tasks and solve problems.\nCommitment to continuous learning and professional development.\nGood to Have:\nFamiliarity with Oracle technologies, Like SQL, PLSQL, Reports, Shell Scripts Knowledge of database concepts and experience with SQL. Familiarity of REST, SOAP etc.\nUnderstanding of fundamental of cloud computing concepts Exposure to DevOps practices and tools, such as Git, Jenkins, Docker, and Kubernetes.\nUnderstanding of Artificial Intelligence & Machine Learning concepts\nParticipation in relevant internships, co-op programs, or personal projects demonstrating practical experience and initiative.\nGREAT\n OPPORTUNITY FOR FRESHERS \n Technical\n\nSkills:\n \nKnowledge of Software Development Life Cycle (SDLC) principles/concepts.\nKnowledge in Simple & Complex SQL Queries\nWrite intermediate SQL Queries\nCommunication and Excellence:\nExcellent logical and communication skills (Oral, written and listening ability)\nStrong communication and interpersonal skills, with the ability to effectively communicate.\n  \nConduent delivers mission-critical services and solutions on behalf of businesses and governments creating exceptional outcomes for its clients and the millions of people who count on them. Through process, technology, and our diverse and dedicated associates, Conduent solutions and services automate workflows, improve efficiencies, reduce costs, and enable revenue growth. It\\u2019s why most Fortune 100 companies and over 500 government entities depend on Conduent every day to manage their essential interactions and move their operations forward.\nConduent\\u2019s differentiated services and solutions improve experiences for millions of people every day, including 3 out of every 4 U.S. insured patients, 10 million employees who use its HR Services, and nearly 18 million benefits recipients. Conduent\\u2019s solutions deliver exceptional outcomes for its clients including :1c billion in savings from medical bill review of workers compensation claims, up to 40% efficiency increase in HR operations, up to 27% reduction in government benefits costs, up to 40% improvement in finance, accounting and procurement expense, and improved customer service interaction times by up to 20% with higher end-user satisfaction. Learn more at https://www.conduent.com",Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'javascript', 'sql', 'java', 'computer science', 'rest', 'algorithms', 'kubernetes', 'oracle', 'c', 'sql queries', 'machine learning', 'artificial intelligence', 'docker', 'plsql', 'software development life cycle', 'git', 'devops', 'jenkins', '.net', 'data structures', 'shell scripting', 'sdlc', 'soap']",2025-06-12 06:36:17
Development Manager AI Center of Excellence,IBM,12 - 15 years,Not Disclosed,['Bengaluru'],"Your Role & Responsibilities:\nLooking to make a significant impact\nThis is your chance to become a key part of a dynamic team of talented professionals, leading the development and deployment of innovative, industry-leading, cloud-based AI services.\nWe are seeking an experienced AI & Cloud Software Engineering Manager to join us. This leadership role focuses on guiding, mentoring, and managing a team of engineers in designing, developing, and deploying AI-based services. You will be instrumental in problem-solving, automating wide ranges of tasks, and interfacing with other teams, offering managers, and customers to solve complex problems.\nYou will build a strong, agile, and modern team culture aimed at creating world-class development and deployment environments. Your efforts will ensure industry-leading user experiences for our customers. As an essential part of the leadership team, you will contribute to the cloud services architecture and design while mentoring the next generation of cloud engineers.\nResponsibilities:\nLead, mentor, and manage a team of AI and cloud software engineers.\nOversee the planning, execution, and delivery of AI-based services and cloud solutions.\nProvide technical direction and architectural oversight for AI and cloud projects.\nInterface with other teams, managers, and customers to align project goals and deliverables.\nAddress and resolve technical challenges and roadblocks faced by the team.\nMonitor and evaluate team performance, providing feedback and development opportunities.\nStay updated with the latest trends in AI and cloud technologies to encourage continuous improvement.\nEnsure the delivery of industry-leading user experiences for customers.\nAllocate resources effectively to meet project and organizational goals.\nMaintain comprehensive documentation of projects and processes, and report progress to senior management.\nRequired education\nBachelor's Degree\nRequired technical and professional expertise\nMinimum 12-15 years of experience as Full Stack Developer with a focus on AI projects\nExperience with AI and machine learning frameworks such as scikit-learn, TensorFlow, PyTorch, LLMs, Generative AI.\nFamiliarity with AI model deployment and integration.\nSolid understanding of backend technologies, including server-side languages (Node.js, Python, Java, etc.) and databases (Cassandra, PostgreSQL, etc.).\nUnderstanding and experience with RESTful APIs, Java/J2EE, Kafka & GitHub.\nStrong experience with Cloud Technologies, Kubernetes based microservices architecture, Kafka, Object Storage, Cassandra database and docker container technologies. Knowledge on IBM Cloud Technologies will be an added advantage.\nAt least 6 years of hands-on development experience building applications with one or more of the following: Java, Spring, Liberty, Node.js, Express.js, Golang, NoSQL DB, Redis, distributed caches, containers etc.,\nAt least 3 years of experience in building and operating highly secured, distributed cloud services with one or more of the following: IBM Cloud, AWS, Azure, SRE, CI/CD, Docker, Container orchestration, performance testing, etc.,\nAt least 3 years of experience in web technologies: HTTP, REST, JSON, HTML, Ajax, JavaScript etc.,\nSolid understanding of the micro-services architecture and modern cloud programming practices. Strong ability to design a clean, developer-friendly API.\nPassionate about constant, continuous learning and applying new technologies as well as mentoring others.\nKeen troubleshooting skills and strong verbal/written communication skills.\nPreferred technical and professional experience\nPreferred Skills:\nExperience in using messaging brokers like RabbitMQ, Kafka etc.\nOperating Systems (such as Red Hat, Ubuntu, etc.)\nKnowledge of network protocols such as TCP/IP, HTTP, etc.\nExperience and working knowledge of version Control systems like Github and build tools like Maven/Gradle\nAbility to learn and apply new technologies quickly\nExperience in working on a SaaS application with high industry standard CI/CD, and development cycle processes\nStrong sense of ownership of deliverables\nUI test automation skills - Selenium and/or Puppeteer\nBeyond the requirements, candidates should be passionate about in the role:\nContinuous learning and ability to adapt to change\nWorking across global teams and collaborating across teams and organization boundaries\nFinding innovative ways to solve complex problems with cutting edge technologies.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Artificial intelligence', 'RESTful API', 'Java', 'Generative AI', 'scikit-learn', 'Kafka', 'J2EE', 'Node.js', 'LLM', 'machine learning', 'PyTorch', 'TensorFlow', 'Python']",2025-06-12 06:36:20
Conversational AI Technical Lead,Qualcomm,4 - 9 years,Not Disclosed,['Hyderabad'],"Job Area: Information Technology Group, Information Technology Group > IT Programmer Analyst\n\nGeneral Summary:\n\nQualcomm IT is seeking a Lead Conversational AI Developer for Intelligent Automation Center (IAC)Responsibilities include:\nExperience on designing and implementing Conversational AI solutions using Microsoft Azure and Copilot Stack in combination with GenAI\nHands-on experience with Microsoft Copilot Studio, Microsoft Bot Framework, NLP, Azure AI Search and Azure OpenAI\nExtensive hands-on experience in implementing end-to-end projects utilizing Generative AI using Retrieval-Augmented Generation (RAG) or Agentic AI architecture\nStrong expertise in Python for building bot solutions\nExperience with Azure Cognitive Services (LUIS/CLU, QnA Maker/CQA, Spell Check,Speech API) for advanced NLP features.\nKnowledge of Power Automate, Azure Logic Apps, and APIs for extending Copilot Agent and bot functionalities.\nExperience in software development with a focus on Conversational AI and Machine Learning.\nProficiency with tools and Frameworks such as LangChain, LlamaIndex, and Streamlit.\nKnowledge and implementation experience of chatbot technologies using Microsoft Azure Services and Power Platform.\nEnsure quality of coded components by performing thorough unit testing and develop reusable test cases\nWork collaboratively with test teams for supporting Product testing and UAT\nReport status, issues and risks to tech leads on a regular basis\nImprove skills in automation products through certifications\nTrain and coach team members on Conversational AI related technologies\nWork independently with minimal supervision and good team management skills\nExcellent communication and collaboration skills\nProvide timely status on assignments, planned activities, issues, and dependencies\n\nGood knowledge on Conversational AI on Microsoft Stack (Copilot Studio, Azure AI Foundry, Azure AI Search, Azure OpenAI)\nGood understanding of Generative AI concepts and Frameworks like Langchain\nHands-on programming experience on Python and any frontend technology like Angular\n\nMinimum Qualifications:\n4+ years of work experience in programming, scripting, and/or automation or IT-relevant work experience with a Bachelor's degree.\nOR\n6+ years of work experience in programming, scripting, and/or automation or IT-relevant work experience without a Bachelors degree.\n\n2+ years experience with Database Design structures such as Mongo DB, MySQL.\n\nGood understanding of conversational AI and Intelligent Automation methodologies and associated tools & technologies\nKnowledge of Process Mining concepts and implementation expereience using Celonis inclusing data models and dasboards\nExperience in business process diagrams and process flow charts with Automation Anywhere\nCertification in Industry Leading Robotic Automation products is a plus.\nExperience in identifying the right processes for Automation and providing estimates for implementations\nProgramming concepts and coding background in Python\nUnderstanding of RDBMS concepts and writing SQL queries\nExpereience in Cloud (preferrably AWS) and certifications is a plus\nExperience in Agile development using standard tools like Jira\n\nBachelor's degree and 5+ years IT-relevant work experience",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'microsoft azure', 'sql', 'database design', 'aws', 'luis', 'rdbms', 'microsoft bot framework', 'software development', 'natural language processing', 'data mining', 'azure cognitive services', 'machine learning', 'angular', 'cqa', 'qna maker', 'speech', 'mysql', 'agile', 'api', 'mongodb', 'jira']",2025-06-12 06:36:22
Immediate Opening For Data Science,Happiest Minds Technologies,8 - 13 years,Not Disclosed,['Bengaluru( Madiwala )'],"Machine Learning, Deep Learning models, Data Science. (Important);-R / python programming (mandatory) ;- Fast API development ;- deployment of models experience ; - any cloud Azure (good to have - for this requirement); - basics of Generative AI , NLP (optional - Good to have)\n\nGIS data, Geospatial data, Google Maps, ArcGIS, Demand pattern analysis\n\n5 to 15 Yrs",,,,"['Data Science', 'Machine Learning', 'Deep Learning', 'Python', 'GenAi', 'Natural Language Processing']",2025-06-12 06:36:25
Senior AI/ML Manager,IQVIA,9 - 14 years,Not Disclosed,"['Kochi', 'Pune', 'Bengaluru']","Project Role: Senior AI/ML Manager\nWork Experience: 8 to 14 Years\nWork location: Bengaluru/Kochi\nMust Have Skills: Machine Learning, NLP, Deep Learning, AI, Python, GenAI.\nJob Description\nDevelop/leverage fit for purpose AIML models/algorithms/foundation models/processes to address pharma/healthcare applications and innovative products upon completion of prototypes followed by the building of production grade algorithms/automation engines for client deliverables. Test for viability to deliver final products to clients. Able to bring newly researched ideas to reality quickly and on a large scale. Design, build, test, and deliver products from post-prototype to client delivery.\n\nEssential Functions\nAssists with the ongoing development and implementation of an enterprise architecture. May devise and present business cases and program release plans to senior management with priority recommendations to maintain and evolve this architecture.\nBuilds effective business relationships with business line managers and provides technical and system expertise as input to product concepts.\nMay assist product development management to define IT strategic direction and assists in the mapping of projects to that strategic direction whilst ensuring product capabilities and process improvements are delivered over time within the framework of the IQVIA enterprise architecture.\nParticipates in cross-functional product development teams, may also act as a consultant to provide system and technical advice.\nKeeps up to date with technology changes and identifies opportunities for implementation in future systems.\nParticipates in R&D projects and may run those projects in compliance with standard project management practices.\nMay mentor and assist lower-level architects and business analysts.\n\nQualifications\n10+ years of experience in engineering roles with team management experience\n6-8 relevant years experience on NLP,GenAI/LLM, Machine Learning and Deep learning\n6-8 relevant years of experience on Python\nExtensively work on NLP applications, ability to work on Machine learning model, Deep learning development\nExtensive knowledge in leveraging GenAI/LLM for developing innovative solutions to complex business problems.\nSolid understanding of LLMs, including fine-tuning methodologies and deployment strategies.\nExperience on text to transform natural language into useful features.\nFind and implement the right algorithms and tools for NLP tasks.\nExtend ML libraries and frameworks to apply in NLP tasks.\nDemonstrated experience in writing effective, scalable, and maintainable code\nExperience on Writing on effective and scalable code\nExperience on Unit Testing using Pytest or equivalent framework.\nA deep understanding and multi-process architecture and the threading limitations of Python.\nMust have experience working with REST APIs, and frameworks like Flask API and Fast API. Experience with Django or Pyramid framework is a good to have\nKnowledge of NER, Knowledge graphs is good to have.\n\nEducation Qualification\nMaster's Degree masters degree in Machine Learning, Statistics, Computer Science, Physics, Math, or related field",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Natural Language Processing', 'Aiml', 'Machine Learning', 'Python', 'Agentic AI', 'Genrative Ai', 'Deep Learning']",2025-06-12 06:36:28
RAG Architect,Qualcomm,13 - 18 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Test Engineering\n\nGeneral Summary:\n\nJob description\n\nWe are seeking an experienced AI Architect to design, develop, and deploy Retrieval-Augmented Generation (RAG) solutions for Qualcomm Cloud AI Platforms.\n\nRoles and Responsibilities\nLead the design and development of applications for RAG AI models and provide APIs for frontend consumption. Manage the interaction between retrieval-augmented techniques and generative models.\nBuild services that connect AI models (e.g., transformers, embeddings, and vector search) to handle tasks such as query retrieval, model inference, and generating responses. Leverage frameworks like Flask, FastAPI, or Django for API development.\nDesign pipelines to preprocess, clean, and prepare data for AI model training, as well as for serving the models in production environments. Optimize these pipelines to support both batch and real-time data processing. Implement RESTful APIs or GraphQL endpoints for seamless frontend-backend interaction.\nImplement cloud solutions to host Python-based services, ensuring that AI models are scalable and that the infrastructure can handle high traffic. Leverage containerization (Docker) and orchestration (Kubernetes) for model deployment and management.\nSet up monitoring, logging, and alerting for Python backend services, ensuring smooth operation of AI features. Use tools like Prometheus, Grafana, and ELK stack for real-time performance tracking.\nContinuously optimize model performance by fine-tuning and adapting Python-based AI models for real-time use cases. Manage trade-offs between computation load, response time, and quality of generated content.\nPartner with data scientists, machine learning engineers, and mobile/web developers to ensure tight integration between AI models, mobile/web front-end, and backend infrastructure.\n\n- Experience:\n13+ years of overall SW development experience\n10+ years Strong experience in working with technologies (e.g., React, React Native, Flutter, Django, Flask, FastAPI).\n5+ years of experience in building AI applications with a focus on NLP, machine learning, generative models, and retrieval-augmented systems.\nProven experience in designing and deploying AI systems that integrate retrieval-based techniques (e.g., FAISS, Weaviate) and generative models (e.g., GPT, BERT). - Expertise in cloud platforms (e.g., AWS, GCP, Azure) and deployment of Python-based microservices.\nBuilding RESTful APIs or GraphQL services (using frameworks like Flask, FastAPI, or Django).\nHandling AI model inference and data processing (using libraries like NumPy, Pandas, TensorFlow, PyTorch, and Hugging Face Transformers).\nIntegrating vector search solutions (e.g., FAISS, Pinecone, Weaviate) with the AI models for efficient retrieval-augmented generation. - Experience with containerization (Docker) and Kubernetes for deploying scalable Python-based services.\nProficient in cloud infrastructure management, with a focus on managing Python services in the cloud.\nExperience in End-to-End product development and Software Lifecycle\n\n\nKey\n\nSkills:\n\nAdvanced proficiency in Python for building backend services and data processing pipelines. Familiarity with frameworks like Flask, Django, and FastAPI. Experience with AI libraries and frameworks (TensorFlow, PyTorch, Hugging Face Transformers).\nFamiliarity with vector databases (e.g., Pinecone, FAISS, Weaviate) and integration with retrieval-augmented systems.\nStrong knowledge of RESTful API design, GraphQL, and API security best practices (e.g., OAuth, JWT).\nExcellent problem-solving abilities and a strong focus on creating highly scalable and performant solutions.\nStrong communication skills, with the ability to collaborate across different teams and geography\nAbility to mentor junior team members and lead technical discussions.\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 6+ years of Software Test Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 5+ years of Software Test Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Test Engineering or related work experience.\n\n2+ year of work experience with Software Test or System Test, developing and automating test plans, and/or tools (e.g., Source Code Control Systems, Continuous Integration Tools, and Bug Tracking Tools).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'data processing', 'cloud platforms', 'api', 'graphql', 'natural language processing', 's w development', 'rest api design', 'system testing', 'react native', 'machine learning', 'pipeline', 'react.js', 'flutter', 'test engineering', 'django', 'cloud infrastructure management', 'flask']",2025-06-12 06:36:31
"Sr Software Eng: Generative AI, Go/Python, AWS, Kubernetes 7-12 Yrs",Cisco,7 - 12 years,Not Disclosed,['Bengaluru'],"Meet The Team\nThe Cisco AI Software & Platform Group drives the development of groundbreaking generative AI applications. We empower Cisco's diverse product portfolio, spanning networking and security, with intelligent assistants and agents. We work on pioneering technologies that proactively defend against threats, safeguard critical business assets, and simplify security operations. Fueled by a passion for AI/ML, we strive to create a secure future for businesses. Our collaborative and passionate team thrives with tackling sophisticated challenges and delivering innovative solutions.",,,,"['Golang', 'Generative Ai', 'AWS', 'Python', 'Kubernetes', 'Java']",2025-06-12 06:36:33
Senior AI/ML Architect- Iqvia,IQVIA,10 - 18 years,Not Disclosed,"['Kochi', 'Noida', 'Bengaluru']","Job Description\nDevelop fit for purpose AIML models/algorithms/processes to address pharma/healthcare applications and innovative products upon completion of prototypes followed by the building of production grade algorithms/automation engines for client deliverables. Test for viability in order to deliver final products to clients. Able to bring newly researched ideas to reality quickly and on a large scale. Design, build, test, and deliver products from post-prototype to client delivery.\nEssential Functions\nAssists with the ongoing development and implementation of an enterprise architecture.\nMay devise and present business cases and program release plans to senior management with priority recommendations to maintain and evolve this architecture. Builds effective business relationships with business line managers and provides technical and system expertise as input to product concepts.\nMay assist product development management to define IT strategic direction and assists in the mapping of projects to that strategic direction whilst ensuring product capabilities and process improvements are delivered over time within the framework of the IQVIA enterprise architecture.\nParticipates in cross-functional product development teams, may also act as a consultant to provide system and technical advice.\nKeeps up to date with technology changes and identifies opportunities for implementation in future systems.\nParticipates in R&D projects and may run those projects in compliance with standard project management practices.\nMay mentor and assist lower level architects and business analysts\nQualifications\n10+ years of experience in engineering roles with team management experience\n5-7 relevant years experience on NLP, Machine Learning and Deep learning\n5-7 relevant years of experience on Python\nExtensively work on NLP applications, ability to work on Machine learning model, Deep learning development\nKnowledge of LLMs, fine tuning and deployment\nExperience annotated datasets for Supervised Learning methods and correction\nExperience on text to transform natural language into useful features\nFind and implement the right algorithms and tools for NLP tasks\nPerform statistical analysis of results and refine models\nExtend ML libraries and frameworks to apply in NLP tasks\nExperience on ORM, SQL Alchemy, Alembic is a must\nExperience on Writing on effective and scalable code\nExperience on Unit Testing using Pytest or equivalent framework\nA deep understanding and multi-process architecture and the threading limitations of Python.\nFamiliarity with server-side templating languages including Jinja 2 and Mako is good to have\nExperience on REST API, Flask API, Fast API is must, Django or Pyramid framework is good to have\nKnowledge of NER, Knowledge graphs is good to have\n\nEducation Qualification\nMaster's Degree Masters Degree in Machine Learning, Statistics, Computer Science, Physics, Math, or related field",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI', 'Machine Learning', 'Python', 'GenAI', 'NLP', 'Natural Language Processing', 'Ml']",2025-06-12 06:36:36
Lead AI Engineer,Insnapsys Technologies,4 - 8 years,Not Disclosed,[],"Lead AI Engineer: Nashik/Remote\nExperience: 7+ years in Software Engineering and 3+years in AI/ML development\n\nWhat you will do:\nLead the end-to-end design, development, and deployment of AI/ML systems and generative AI applications.\nBuild & fine-tune custom AI agents, chatbots, and automation tools.\nArchitect scalable pipelines for LLMs optimized for performance and cost-efficiency.\nImplement advanced techniques like RAG, vector search, and hybrid architectures.\nCollaborate with cross-functional Product, Engineering, and Data teams.\nEstablish MLOps infrastructure (monitoring, CI/CD, versioning, A/B testing).\nMentor and inspire a high-performing AI team.\nChampion ethical, scalable, and secure AI development practices\n\n\nWhat you Bring\n7+ years in software engineering or data science, with 3+ years in AI/ML development.\n3+ years leading AI teams and managing end-to-end projects.\nHands-on experience with LLMs like GPT, Claude, Mistral, Falcon including fine-tuning, RAG, and agent orchestration.\nStrong command over Python, PyTorch/TensorFlow, HuggingFace.\nExperience on AWS: SageMaker, Bedrock, Lambda, EC2, S3.\nKnowledge of vector databases: Pinecone, FAISS, or Weaviate.\nSystems-thinking mindset with great communication & leadership skills.\n\n\nNice to Have\nExperience with voice AI, OCR, or computer vision.\nFamiliarity with multi-agent systems, autonomous planning, or tool-using AI agents.\nContributions to open-source projects or published research in NLP, LLMs, or GenAI.\nExperience with real-time personalization, streaming data, or recommendation systems.\n\nEducation Required:\nB.Tech / M.Tech / Ph.D. in Computer Science, Artificial Intelligence, Machine Learning, or a related field from a reputed institute.\n\nWhy Join Us?\nBuild AI systems that scale and make real-world impact across industries.\nWork in a high-autonomy, innovation-driven environment using cutting-edge tools.\nJoin a team that thrives on collaboration, learning, and technical excellence.\nBe part of a mission-driven organization building ethical, secure, and transformative AI.\n\nInterested candidates please submit resumes on hr@insnapsys.com or call on 9156797671",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'LLM', 'Machine Learning', 'Python']",2025-06-12 06:36:38
Data Architect - AWS,Happiest Minds Technologies,10 - 15 years,Not Disclosed,"['Noida', 'Pune', 'Bengaluru']","Roles and responsibilities\nWork closely with the Product Owners and stake holders to design the Technical Architecture for data platform to meet the requirements of the proposed solution.\nWork with the leadership to set the standards for software engineering practices within the machine learning engineering team and support across other disciplines\nPlay an active role in leading team meetings and workshops with clients.\nChoose and use the right analytical libraries, programming languages, and frameworks for each task.",,,,"['SQL', 'data architect', 'Python', 'Pyspark', 'Apache Airflow', 'GLUE', 'Kinesis', 'Amazon Redshift', 'Data Architecture Principles', 'Data Modeling', 'Data Warehousing', 'Athena', 'Lambda', 'AWS']",2025-06-12 06:36:41
CPU Full Stack Python Developer (Staff/Sr. Staff),Qualcomm,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Hardware Engineering\n\nGeneral Summary:\n\nWe are seeking a highly skilled Full Stack Python Developer to join our dynamic team. The ideal candidate should have a strong background in tool development, data science, and automation of complex tasks. You will be responsible for developing high volume regression dashboard, parametric and power tools and contributing to both front-end and back-end development.\n\nMinimum Qualifications:\nBachelor's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 4+ years of Hardware Engineering or related work experience.\nOR\nMaster's degree in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 3+ years of Hardware Engineering or related work experience.\nOR\nPhD in Computer Science, Electrical/Electronics Engineering, Engineering, or related field and 2+ years of Hardware Engineering or related work experience.\n\nTechnical\n\nSkills:\n\n\n\nPythonProficiency in Python programming, including libraries like Pandas, NumPy, and SciPy for data science.\n\n\nFull Stack DevelopmentExperience with both front-end (HTML, CSS, JavaScript, React, Vue.js) and back-end (Django, Flask) technologies.\n\n\nTool DevelopmentAbility to develop parametric and power tools, possibly using frameworks like Vue.js , PyQt or Tkinter for GUI development.\n\n\nData ScienceStrong understanding of data analysis, machine learning (using libraries like scikit-learn, TensorFlow), and data visualization (using Matplotlib, Seaborn).\n\n\nAutomationExperience in automating complex tasks using scripting and tools like Selenium, Airflow, or custom automation scripts.\n\n\nSoft\n\nSkills:\n\n\n\nProblem-SolvingAbility to tackle complex problems and develop innovative solutions.\n\n\nCommunicationStrong communication skills to effectively collaborate with team members and stakeholders.\n\n\nAdaptabilityFlexibility to adapt to new technologies and methodologies.\n\n\nExperience:\n\n\nProjectsPrevious experience in developing tools and automation solutions.\n\n\nIndustry KnowledgeFamiliarity with the specific industry or domain you're working in can be a plus.\n\n\nKey Responsibilities:\n\nDevelop and maintain parametric and power tools using Python.\n\nDesign and implement automation solutions for complex tasks.\n\nCollaborate with data scientists to analyze and visualize data.\n\nBuild and maintain web applications using Django or Flask.\n\nDevelop front-end components using HTML, CSS, JavaScript, and React.\n\nIntegrate third-party APIs and services.\n\nOptimize applications for maximum speed and scalability.\n\nWrite clean, maintainable, and efficient code.\n\nTroubleshoot and debug applications.\n\nStay updated with the latest industry trends and technologies.\n\n\nPreferred Qualifications:\n\nBachelor's degree in Computer Science, Engineering, or related field.\n\nPrevious experience in tool development and automation.\n\nFamiliarity with industry-specific tools and technologies.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['tool development', 'data science', 'python', 'data analysis', 'machine learning', 'css', 'hiring', 'scikit-learn', 'vue.js', 'numpy', 'staffing', 'react.js', 'tensorflow', 'seaborn', 'selenium', 'pyqt', 'html', 'data visualization', 'scipy', 'hardware engineering', 'javascript', 'pandas', 'django', 'matplotlib', 'flask']",2025-06-12 06:36:44
Principal Engineer App (React Native),Endeavour Consultancy Services And Solutions,8 - 13 years,45-65 Lacs P.A.,['Bengaluru'],"Led architecture and development of high-performance React Native apps. Proficient in native build tools like Xcode and Gradle along with state management (Redux, MobX) and advanced libraries (React Navigation, Reanimated).",Industry Type: Internet (E-Commerce),Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['React Native', 'Mobile App', 'Xcode', 'Redux', 'react native apps', 'CI/CD', 'Gradle', 'MobX']",2025-06-12 06:36:47
Data Analyst - Python/Hadoop,Sadup Soft,3 - 6 years,Not Disclosed,['Bengaluru'],"- Minimum of 3 years of hands-on experience.\n\n- Python/ML, Hadoop, Spark : Minimum of 2 years of experience.\n\n- At least 3 years of prior experience as a Data Analyst.\n\n- Detail-oriented with a structured thinking and analytical mindset.\n\n- Proven analytic skills, including data analysis, data validation, and technical writing.\n\n- Strong proficiency in SQL and Excel.\n\n- Experience with Big Query is mandatory.\n\n- Knowledge of Python and machine learning algorithms is a plus.\n\n- Excellent communication skills with the ability to be precise and clear.\n\n- Learning Ability : Ability to quickly learn and adapt to new analytic tools and technologies.\n\nKey Responsibilities :\n\nData Analysis :\n\n- Perform comprehensive data analysis using SQL, Excel, and Big Query.\n\n- Validate data integrity and ensure accuracy across datasets.\n\n- Develop detailed reports and dashboards that provide actionable insights.\n\n- Create and deliver presentations to stakeholders with clear and concise findings.\n\n- Document queries, reports, and analytical processes clearly and accurately.\n\n- Leverage Python/ML for advanced data analysis and model development.\n\n- Utilize Hadoop and Spark for handling and processing large datasets.\n\n- Work closely with cross-functional teams to understand data requirements and provide analytical support.\n\n- Communicate findings effectively and offer recommendations based on data analysis.\n\nEducation : Bachelor's degree in Computer Science, Data Science, Statistics, or a related field.\n\nExperience : Minimum of 3 years of experience as a Data Analyst with a strong focus on SQL, Excel, and Big Query.\n\nTechnical Skills : Proficiency in SQL, Excel, and Big Query; experience with Python, ML, Hadoop, and Spark is preferred.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Data Validation', 'Big Query', 'Data Integrity', 'Hadoop', 'Spark', 'Python', 'SQL']",2025-06-12 06:36:49
Lead : Sales & Biz Dev (AI Tools),DNEG,5 - 10 years,Not Disclosed,['Mumbai (All Areas)( Santacruz West )'],"Role Overview:\nAs the Sales & Business Development Lead for the Media vertical, you will spearhead revenue growth by building and nurturing relationships with key stakeholders in the media ecosystem. Youll work closely with technology, product and marketing teams to bring powerful AI solutions to market, while also uncovering new business opportunities that align with evolving customer needs.\n\nKey Responsibilities:\n\nBusiness Development & Partnerships\nIdentify and cultivate new business opportunities within the media, entertainment, and publishing sectors\nBuild and maintain strategic relationships with decision-makers at broadcasters, studios, agencies, and streaming services\nLead negotiations, proposals, and contract processes for key deals and partnerships\n\nSales Strategy & Execution\nOwn the complete sales cycle from lead generation to closing across multiple media segments\nDevelop a clear go-to-market strategy tailored to the unique dynamics of the media and entertainment industries\nMaintain accurate sales forecasting and pipeline management via CRM tools\n\nIndustry Expertise & Evangelism\nRepresent the company at industry events, conferences, and client meetings\nStay ahead of media technology trends and position the company as a thought leader in AI-powered media innovation\nEducate prospects and partners on the ROI and impact of AI in creative workflows, content monetization, and audience engagement\n\nCross-functional Collaboration\nWork closely with product, marketing, and technology teams to align customer needs with platform capabilities\nProvide feedback from the field to inform product development and roadmap priorities\n\nRequirements:\n5-8 years of experience in B2B sales, business development, or partnerships ideally within the media, entertainment, or advertising sectors\nProven track record of closing complex deals with media buyers, tech vendors, or content producers\nStrong understanding of AI applications in mediasuch as generative AI, video/audio analysis, content recommendation, or digital asset management\nExcellent communication, negotiation, and relationship-building skills\nComfortable working in a fast-paced, evolving startup environment\nBachelors degree in business, marketing, communications, or a related field; MBA or technical background is a plus\n\nNice to Have:\nFamiliarity with media technology stacks (e.g., MAM, DAM, CMS, OTT platforms)\nExperience working with media/ movie agencies, ad tech firms, or global media networks\nKnowledge of AI/ML concepts (NLP, computer vision, LLMs, etc.)",Industry Type: Emerging Technologies (AI/ML),Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'New Market Development', 'Sales Lead Generation']",2025-06-12 06:36:51
Azure Data Bricks (4-15 Yrs) - Bangalore,Happiest Minds Technologies,4 - 9 years,Not Disclosed,['Bengaluru'],"Hi,\n\nGreetings from Happiest Minds Technologies\n\nCurrently we are hiring for below positions and looking for immediate joiners.\n1. Azure Databricks Bangalore 5 to 10 Yrs - Bangalore\nAs a Senior Azure Data Engineer, you will leverage Azure technologies to drive data transformation, analytics, and machine learning. You will design scalable Databricks data pipelines using PySpark, transforming raw data into actionable insights. Your role includes building, deploying, and maintaining machine learning models using MLlib or TensorFlow while optimizing cloud data integration from Azure Blob Storage, Data Lake, and SQL/NoSQL sources. You will execute large-scale data processing using Spark Pools, fine-tuning configurations for efficiency. The ideal candidate holds a Bachelors or Masters in Computer Science, Data Science, or a related field, with 7+ years in data engineering and 3+ years specializing in Azure Databricks, PySpark, and Spark Pools. Proficiency in Python PySpark, Pandas, NumPy, SciPy, Spark SQL, DataFrames, RDDs, Delta Lake, Databricks Notebooks, and MLflow is required, along with hands-on experience in Azure Data Lake, Blob Storage, and Synapse Analytics.",,,,"['Pyspark', 'Azure', 'Data Bricks', 'sql', 'ETL']",2025-06-12 06:36:54
Python Developer-PAN INDIA_RA,Infosys,3 - 6 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities\nWrite clean, maintainable, and efficient Python code for backend services or applications. Develop RESTful APIs or work on web applications using frameworks like Django or Flask. Implement data extraction, transformation, and loading (ETL) processes using Python. Collaborate with front-end developers and other team members to ensure seamless integration. Test and debug applications to ensure they meet quality and performance standards.\nParticipate in code reviews and contribute to the development of coding standards.\nKeep up-to-date with Python libraries and tools relevant to the project.\n\nTechnical and Professional Requirements:\nPrimary skills: Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities:\nSkills Required:\nStrong proficiency in Python 3.x.\nExperience with at least one Python web framework (Django, Flask, etc.).\nKnowledge of database technologies, including SQL and ORM (e.g., SQLAlchemy).\nFamiliarity with version control systems like Git.\nBasic understanding of front-end technologies (HTML, CSS, JavaScript).\nExperience with unit testing frameworks like pytest or unittest.\nKnowledge of REST API design principles.\nEducational Requirements\nBCA/MCA/B.Tech/BE/M.Tech/ME/BSC/MSC",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Flask']",2025-06-12 06:36:56
Python Developer,Infosys,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title\nPython Developer\n\nResponsibilities\nA day in the life of an Infoscion\nAs part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain.\nYou will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements.\nYou will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers.\nYou would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! Technical and Professional :\nPrimary skills:Technology-Machine Learning-Python Preferred Skills:\nTechnology-Machine Learning-Python Additional Responsibilities:\nKnowledge of design principles and fundamentals of architecture\nUnderstanding of performance engineering\nKnowledge of quality processes and estimation techniques\nBasic understanding of project domain\nAbility to translate functional / nonfunctional requirements to systems requirements\nAbility to design and code complex programs\nAbility to write test cases and scenarios based on the specifications\nGood understanding of SDLC and agile methodologies\nAwareness of latest technologies and trends\nLogical thinking and problem solving skills along with an ability to collaborate Educational Bachelor of Engineering Service LineInformation Systems* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SDLC', 'software development', 'report generation', 'MIS', 'Python development', 'Python Developer', 'CI/CD']",2025-06-12 06:36:59
Python developer - Infosys @ Pan India,Infosys,2 - 7 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTech",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Python Development']",2025-06-12 06:37:01
Applied Research Center (ARC),Infosys,5 - 10 years,Not Disclosed,['Bengaluru'],"Responsibilities\n1. Emerging Tech Trends Research - Research on emerging tech trends, ecosystem of players, use cases and their applicability and impact to client businesses. Scan & curate startups, universities and tech partnerships needed and create innovation ecosystem. Rapidly design and develop PoCs in Emerging tech areas. Share design specifications with other team members, get the components developed, integrate and test. Build reusable components and develop PoCs using relevant startups and Open-source solutions.\n2. Thought Leadership - Develop showcases that demonstrate how emerging technologies can be applied in a business context, demo scenarios for the IP. Contribute towards patents, tier-1 publications, whitepapers, blogs in the relevant emerging tech area Get certified on the emerging technology, frameworks\n3. Applied Research Center Activities - Contribute to high level design development, testing and implementation of new proof of concepts in emerging tech areas.\n4. Problem Definition, Requirements - Understand technical requirements and define detailed design. Analyze the reusable components to map the given requirement to existing implementation and identify needs for enhancements\n5. IP Development - Develop program level design, modular components to implement the proposed design. Design and develop reusable components. Ensure compliance with coding standards, secure coding, KM guidelines while developing the IP\n6. Innovation Consulting - Understand client requirements and implement first of kind solutions using emerging tech expertise. Customize and extend IP for client specific features\n7. Talent Management - Mentor the team and help them acquire the identified emerging tech skill. Participate in demo sessions, hackathons8. Emerging Tech Startup Ecosystem Work with startups in providing innovative solutions to client problems and augmenting Infosys offerings\nTechnical and Professional Requirements:\nApplied Research Center [Emerging Areas]Advanced AI [SLM, Inference Scaling, Synthetic Data, Distributed Learning, Agentic AI, ANI]New Interaction Models [Spatial computing, Mixed Reality, 3D visualizations, New Experiences]Platforms and Protocols [Architecting and engineering for Performance, Uptime, Low-latency, Scalability, Efficiency, Data, Interoperability and Low cost, Beckn, CDPI]Cybersecurity [Ethical hacking, Threat Mgmt, Supply chain security & risk, Cyber Resilience]Quantum [Quantum AI, Stack, Simulation & Optimization, Cryptography, Valued use cases]Autonomous Machines [Humanoids, Industrial Robots, Drones, Smart Products]Emerging Research [Brain, AGI, Space, Semicon ]\nPreferred Skills:\nDomain->User Experience Design->Usability Principles->HCI\nFoundational->Learning Experience Design->Learning design Management->IP Management\nTechnology->X Reality (XR)->Augmented Reality\nTechnology->X Reality (XR)->Virtual Reality\nTechnology->Blockchain->Blockchain as a Service (BaaS)->AWS Blockchain\nTechnology->Robotic Process Automation->Intelligent Process Automation\nFoundational->Cybersecurity Competency Management->Cyber Competency Strategy Planning\nFoundational ->Data privacy->Privacy by design\nTechnology->Machine Learning->Generative AI\nAdditional Responsibilities:\nTechnical Competencies\nAdvanced theoretical knowledge in specific domain\nExperimental design and methodology expertise\nData analysis and interpretation skills\nPrototype development capabilities\nResearch tool proficiency relevant to domainSoft Skills and Attributes\nCollaborative mindset for cross-disciplinary research\nCommunication skills for knowledge dissemination\nCreative problem-solving approach\nIntellectual curiosity and innovation focus\nCommercial awareness for translational research\nEducational Requirements\nPhD of Computer Science,Bachelor of Engineering\nService Line\nGlobal Delivery\n* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['User Experience Design', 'Agentic AI', '3D visualizations', 'SLM', 'Distributed Learning', 'Inference Scaling', 'Spatial computing', 'ANI', 'Mixed Reality', 'Synthetic Data', 'New Experiences']",2025-06-12 06:37:04
Developer - L4,Wipro,5 - 8 years,Not Disclosed,['Bengaluru'],"The purpose of this role is to design, test and maintain software programs for operating systems or applications which needs to be deployed at a client end and ensure its meet 100% quality assurance parameters\n\n\n\nDo\n\n1. Instrumental in understanding the requirements and design of the product/ software\nDevelop software solutions by studying information needs, studying systems flow, data usage and work processes\nInvestigating problem areas followed by the software development life cycle\nFacilitate root cause analysis of the system issues and problem statement\nIdentify ideas to improve system performance and impact availability\nAnalyze client requirements and convert requirements to feasible design\nCollaborate with functional teams or systems analysts who carry out the detailed investigation into software requirements\nConferring with project managers to obtain information on software capabilities\n\n\n2. Perform coding and ensure optimal software/ module development\nDetermine operational feasibility by evaluating analysis, problem definition, requirements, software development and proposed software\nDevelop and automate processes for software validation by setting up and designing test cases/scenarios/usage cases, and executing these cases\nModifying software to fix errors, adapt it to new hardware, improve its performance, or upgrade interfaces.\nAnalyzing information to recommend and plan the installation of new systems or modifications of an existing system\nEnsuring that code is error free or has no bugs and test failure\nPreparing reports on programming project specifications, activities and status\nEnsure all the codes are raised as per the norm defined for project / program / account with clear description and replication patterns\nCompile timely, comprehensive and accurate documentation and reports as requested\nCoordinating with the team on daily project status and progress and documenting it\nProviding feedback on usability and serviceability, trace the result to quality risk and report it to concerned stakeholders\n\n\n3. Status Reporting and Customer Focus on an ongoing basis with respect to project and its execution\nCapturing all the requirements and clarifications from the client for better quality work\nTaking feedback on the regular basis to ensure smooth and on time delivery\nParticipating in continuing education and training to remain current on best practices, learn new programming languages, and better assist other team members.\nConsulting with engineering staff to evaluate software-hardware interfaces and develop specifications and performance requirements\nDocument and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code\nDocumenting very necessary details and reports in a formal way for proper understanding of software from client proposal to implementation\nEnsure good quality of interaction with customer w.r.t. e-mail content, fault report tracking, voice calls, business etiquette etc\nTimely Response to customer requests and no instances of complaints either internally or externally\n\n\nDeliver\n\nNo.\n\nPerformance Parameter\n\nMeasure 1. Continuous Integration, Deployment & Monitoring of Software 100% error free on boarding & implementation, throughput %, Adherence to the schedule/ release plan 2. Quality & CSAT On-Time Delivery, Manage software, Troubleshoot queries,Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Machine Learning', 'software development', 'report generation', 'MIS', 'CI/CD', 'SDLC']",2025-06-12 06:37:07
AI Engineer,Lericon Informatics,5 - 7 years,Not Disclosed,"['Mumbai', 'Delhi / NCR', 'Bengaluru']","Job Summary:\nWe are seeking a passionate and skilled AI Engineer to design, develop, and deploy cutting-edge AI solutions across domains such as large language models (LLMs), computer vision, and autonomous agent workflows. You will collaborate with data scientists, researchers, and engineering teams to build intelligent systems that solve real-world problems using deep learning, transformer-based architectures, and multi-modal AI models.\n\nKey Responsibilities:\n\nDesign and implement AI/ML models, especially transformer-based LLMs (e.g., BERT, GPT, LLaMA) and vision models (e.g., ViT, YOLO, Detectron2).\nDevelop and deploy computer vision pipelines for object detection, segmentation, OCR, and image classification tasks.\nBuild and orchestrate intelligent agent workflows using prompt engineering, memory systems, retrieval-augmented generation (RAG), and multi-agent coordination.\nFine-tune and optimize pre-trained models on domain-specific datasets using frameworks like PyTorch or TensorFlow.\nCollaborate with cross-functional teams to understand problem requirements and translate them into scalable AI solutions.\nImplement inference pipelines and APIs to serve AI models efficiently using tools such as FastAPI, ONNX, or Triton Inference Server.\nConduct model evaluation, benchmarking, A/B testing, and performance tuning.\nStay updated with state-of-the-art research in deep learning, generative AI, and multi-modal learning.\nEnsure reproducibility, versioning, and documentation of all experiments and production models.\n\nQualifications:\n\nBachelors or Masters degree in Computer Science, Artificial Intelligence, Data Science, or a related field.\n35 years of hands-on experience in designing and deploying deep learning models.\nStrong knowledge of LLMs (e.g., GPT, BERT, T5), Vision Models (e.g., CNNs, Vision Transformers), and Computer Vision techniques.\nExperience building intelligent agents or using frameworks like LangChain, Haystack, AutoGPT, or similar.\nProficiency in Python, with expertise in libraries such as PyTorch, TensorFlow, Hugging Face Transformers, OpenCV, and Scikit-learn.\nFamiliarity with MLOps concepts and deployment tools (Docker, Kubernetes, MLflow).\nStrong understanding of NLP, image processing, model fine-tuning, and optimization.\nExperience with cloud platforms (AWS, GCP, Azure) and GPU environments.\nExcellent problem-solving, communication, and teamwork skills.\n\nPreferred Qualifications:\n\nExperience in building multi-modal AI systems (e.g., combining vision + language models).\nExposure to real-time inference systems and low-latency model deployment.\nContributions to open-source AI projects or research publications.\nFamiliarity with vector databases (e.g., FAISS, Pinecone, Weaviate) and RAG pipelines.\n\nLocations : Mumbai, Delhi / NCR, Bengaluru , Kolkata, Chennai, Hyderabad, Ahmedabad, Pune, India",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI Engineering', 'Object Detection', 'Vision Models', 'LLMs', 'AI Agents', 'LangChain', 'Hugging Face', 'Deep Learning', 'PyTorch', 'NLP', 'Transformer Models', 'Model Deployment', 'RAG', 'Computer Vision', 'TensorFlow', 'OCR']",2025-06-12 06:37:09
Python Developer -ENG - Infosys@ PAN India,Infosys,3 - 8 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTech responsibilities",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Python Development', 'Python', 'Django Framework']",2025-06-12 06:37:11
Application Architect - L1,Wipro,8 - 10 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of the role is to create exceptional and detailed architectural application design and provide thought leadership and enable delivery teams to provide exceptional client engagement and satisfaction.\n\nDo\n1. Develop architectural application for the new deals/ major change requests in existing deals\na. Creates an enterprise-wide architecture that ensures systems are scalable, reliable, and manageable.\nb. Manages application assets and directs the development efforts within an enterprise to improve solution delivery and agility\nc. Guides how to construct and assemble application components and services to support solution architecture and application development\nd. Maintains the frameworks and artefacts used in the implementation of an application, with reference to the systematic architecture of the overall application portfolio\ne. Responsible for application architecture paradigms such as service-oriented architecture (SOA) and, more specifically, microservices, ensuring business achieve agility and scalability for a faster time to market\n\nf. Provide solution of RFPs received from clients and ensure overall design assurance\nDevelop a direction to manage the portfolio of to-be-solutions including systems, shared infrastructure services, applications in order to better match business outcome objectives\nAnalyse technology environment, enterprise specifics, client requirements to set a collaboration design framework/ architecture\nDepending on the clients need with particular standards and technology stacks create complete RFPs\nProvide technical leadership to the design, development and implementation of custom solutions through thoughtful use of modern technology\nDefine and understand current state solutions and identify improvements, options & tradeoffs to define target state solutions\nClearly articulate and sell architectural targets, recommendations and reusable patterns and accordingly propose investment roadmaps\nEvaluate and recommend solutions to integrate with overall technology ecosystem\nTracks industry and application trends and relates these to planning current and future IT needs\ng. Provides technical and strategic inputs during the project planning phase in the form of technical architectural designs and recommendations\nh. Account mining to find opportunities in the existing clients\ni. Collaborates with all relevant parties in order to review the objectives and constraints of solutions and determine conformance with the Enterprise Architecture.\nj. Identifies implementation risks and potential impacts.\nk. Create new revenue streams within applications as APIs that can be leveraged by clients\nl. Bring knowledge of automation in application by embracing Agile and dev-ops principles to reduce manual part\n2.Understanding application requirements and design a standardize application\na. Creating Intellectual Property in forms of services, patterns, models and organizational approaches\nb. Designing patterns, best practices and reusable applications that can be used for future references\nc. Ensure system capabilities are consumed by system components and set criteria for evaluating technical and business value in terms of Tolerate, Invest, Migrate and Eliminate\nd. Provide platform to create standardize tools, uniform design and techniques are maintained to reduce costs of maintenance\ne. Coordinating input on risks, costs and opportunities for concepts\nf. Developing customised applications for the customers aligned with their needs\ng. Perform design and code reviews thoroughly on regular basis, keeping in mind the security measures\nh. Understanding design and production procedures and standards to create prototypes and finished products\ni. Work closely with systems analysts, software developers, data managers and other team members to ensure successful production of application software\nj. Offer viable solutions for various systems and architectures to different types of businesses\nk. Seamless integration of new and existing systems to eliminate potential problems and maintain data structure and bring value in terms of development\nl. Transforming all applications into digital form and implement and evolve around mesh app and service architecture that support new technologies like IOT, blockchain, machine learning, automation, BOTS etc\n\nm.Cloud Transformation: (Migration)\nUnderstanding non-functional requirements\nProducing artefacts such as deployment architecture, interface catalogue\nIdentify internal and external dependency, vendor and internal IT management\nSupport build and testing team\nn.Cloud Transformation: (Modernization)\nUnderstanding and Defining target architecture in Integration space\nAssessing project pipeline / demand and align to target architecture\nTechnical support of delivery team in terms and POC and technical guidance\no.Keep Up-to-date with the latest technologies in the market",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Application architecture', 'application design', 'Cloud Transformation', 'solution delivery', 'Application Architect', 'application development']",2025-06-12 06:37:13
Python Senior Developer,Infosys,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Title\nPython Senior Developer\n\nResponsibilities\nSolid development experience in Data Science Arch.\nExperience in Application Architecture & Design of Java Based Applications\nGood Knowledge of Architecture and related technologies\nExperience in Integration Technologies and Architecture\nWorking knowledge of frontend and database technologies\nExcellent Analytical and Debugging Skills\nFamiliarity with Agile & DevSecOps, Log Analytics, APM\nExperience in leading the teams technically\nExperience in requirements gathering, analysis & design and estimation\nGood communication and articulation skills Technical and Professional :\nWe are seeking a skilled Python and SQL Developer to join our dynamic team. The ideal candidate will have a strong background in Python programming and SQL database management.\nDevelop and maintain Python-based applications and scripts.\nWrite efficient SQL queries for data extraction and manipulation.\nCollaborate with cross-functional teams to gather requirements and deliver solutions.\nFamiliarity with Linux operating systems.\nBasic understanding of cloud platforms (e.g., AWS, Azure, Google Cloud).\nKnowledge of Model Quantization and Pruning\nExperience playing a Data Scientist role Preferred Skills:\nPython Technology-Open System-Open System- ALL-Python Technology-Full stack-Java Full stack-Frontend(Vue.js)+Enterprise layer(Python)+DB Additional Responsibilities:\nIn-depth knowledge of design issues and best practices\nSolid understanding of object-oriented programming\nFamiliar with various design, architectural patterns and software development process.\nExperience with both external and embedded databases\nCreating database schemas that represent and support business processes\nImplementing automated testing platforms and unit tests\nGood verbal and written communication skills\nAbility to communicate with remote teams in effective manner\nHigh flexibility to travelSoft Skills\nGood verbal & written communication skills articulate value of AI to business, project managers & other team members\nAbility to break complex problem into smaller problems and create hypothesis\nInnovation and experimentation Educational Master of Computer Science,Master Of Science,Master Of Technology,MCA,Bachelor Of Comp. Applications,Bachelor Of Computer Science,Bachelor of Engineering,Bachelor Of Technology Service LineApplication Development and Maintenance* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Enterprise layer', 'software development', 'report generation', 'MIS', 'CI/CD', 'Java Full stack-Frontend', 'SDLC']",2025-06-12 06:37:15
Quantitative Analytics Manager,Wells Fargo,4 - 8 years,Not Disclosed,['Bengaluru'],"In this role, you will:\nManage a team responsible for the creation and implementation of low to moderate complex financial areas\nMitigate operational risk and compute capital requirements\nDetermine scope and prioritization of work in consultation with experienced management\nParticipate in the development of strategy, policies, procedures, and organizational controls with model users, developers, validators, and technology",,,,"['Quantitative Analytics', 'strategy Planning', 'marketing', 'Git', 'GitHub', 'talent development', 'credit risk analysis']",2025-06-12 06:37:18
XR Systems Architect,Qualcomm,1 - 6 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nQualcomm's XR Technology Systems team is seeking motivated engineers with who will work on driving next generation technologies & platforms enabling the future of Augmented Reality / Virtual Reality / Mixed Reality applications. This team interfaces with product management, platform architecture, technology/IP and software implementation leads.\n\n\n\nThe successful candidate will be responsible for one or more of the following roles\n\nDriving technical workstreams across key technology tracks (perception, rendering, composition, reprojection, split-processing, user input interfaces, camera & display processing). Key role here is to have forward looking perspective and identify opportunities for prototyping, demonstrating the system level trade-offs (working with respective technology team(s), helping define the feature goodness criteria from end use case perspective. Collaborating with technology experts to drive strategic direction in cross-functional AR/MR/VR areas. Working with technology, hardware, and software experts to translate use-case requirements into implementation specifications and contributing to reference design planning. Engaging on identifying and scoping new use-cases Early engagement with customers and works on aligning with product management on platform requirements. Working with technology tracks to drive the system level what-ifs/trade-offs and helping with competitive analysis.\n\nFor this multi-disciplinary role an ideal candidate has experience in AR/VR, computer vision, perception, camera technology, hardware design, SoC architecture, HW/SW partitioning, and/or system modeling (power, performance, thermal).\n\nMinimum Qualifications\n\nBachelors degree in Electrical Engineering, Information Systems, Computer Science, or related field, and project experience in architecture/micro-architecture\n\n1+ years of system engineering or related work experience\n\nExcellent problem solving and communication skills\n\n\nPreferred Qualifications\n\nMasters and/or PhD degree in Electrical Engineering, Information Systems, Computer Science\n\n1+ years experience in HW architecture/design with emphasis on areas listed above\n\nProven experience in conducting architectural trade-offs, power/performance analysis and/or SW-HW trade-offs\n\nExtensive knowledge of graphics pipeline, computer vision pipelines, machine learning methods and/or camera pipelines\n\nExperience with system level modeling (performance and/or power)\n\nC/C++ programming\n\n\nKeywords Camera, ISP, display, composition, rendering, video coding, computer vision, embedded, multimedia, image, algorithms, SOC architecture, micro-architecture\n\n\n\nEducational\n\nRequiredBachelors, Computer Engineering and/or Electrical Engineering or equivalent experience\n\nPreferredMasters / Doctorate, Computer Engineering and/or Computer Science and/or Electrical Engineering\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['graphics', 'machine learning', 'pipeline', 'computer vision', 'system engineering', 'synthesis', 'algorithms', 'asic', 'sta', 'c++', 'c', 'soc', 'verilog', 'hw', 'rtl design', 'computer science', 'product management', 'fpga', 'embedded systems', 'system architecture', 'soc design', 'rtl coding', 'system verilog']",2025-06-12 06:37:20
XR Systems Technology Architect (2 - 10 years),Qualcomm,1 - 6 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nOrganization overview:\n\nQualcomm is a key enabler for the XR eco-system with a dominant market share. We build custom SoCs and technologies that are at the heart of existing and emerging XR products. Qualcomm XR Systems organization is responsible for architecture definition of Qualcomms next generation XR SoCs. Our portfolio of SoC offerings serve a broad range of XR products covering Mixed Reality, Augmented Reality and AI Glass product families. The span of technologies that go into these products and SoCs include high resolution immersive displays, perception features that are bulit on computer vision and deep learning technology, highly efficient DSP processors, dedicated deep learning accelerators, graphics engines supporting high resolution and high frame rate rendering and reprojection, multimedia processing engines (audio, video, imaging,..), CPUs and SoC infrastructure that ensures efficient and secure processing, as well as very low power architecture features such as power islands and power rail isolation, sleep modes etc.\n\nWe are scaling up our operations!! We are looking for engineers with background in diverse areas including architecture and micro architecture definition, design and verification of IPs and SoCs. People who have experience in areas such as SoC architecture, networks on chip, virtual memory, on-chip and off-chip memory subsystems, security architecture, CPUs, etc, also development of IPs such as camera, video, GPU, DSPs, deep learning accelerators and neural signal processors (NSP), peripherals and interfaces such as PICe, SPI etc. Also, people with strong background on pre silicon and post silicon power estimation and optimization, performance estimation, power architecture design will be highly encouraged. We have openings at senior as well as junior job levels.\n\nWe are keenly interested in you if you are someone who has gained expertise in your specific domain which could be one or more of the areas mentioned above and are excited to take the next step in your career to become architects of the SoCs that will shape the future generations of XR products!! Apart from a rewarding career and growth prospects, the organization offers a unique opportunity to learn from a diverse set of experts working collaboratively under the same roof, towards a common goal.\n\nJob Overview\n\nQualcomm's XR Systems team is seeking system architects who will work on defining the next generation SoC architectures, enabling the future of Augmented Reality / Virtual Reality / Mixed Reality applications. Responsibilities of successful candidates may span one or more of the following areas:\n\nWorking with lead XR OEMs and QCs customer-facing teams to understand end to end use cases\n\nResearching the product family roadmap to align internal IP and SoC architecture roadmap\n\nCollaborating with colleagues in the architecture team and across technology, IP and SoC teams with diverse expertise\n\nExploring architectures for power efficient and performant mapping of use cases on future SoCs and coming up with architecture proposals\n\nDefining and optimizing use case data flows\n\nUse case power modeling, estimation and optimization\n\nWorking with SoC design, and validation teams to ensure that the use case power and performance KPIs are met.\n\n\nMinimum Qualifications\n\nBachelors degree in Electrical Engineering, Information Systems, Computer Science, or related field, and project experience in architecture/micro-architecture\n\nExperience (1 - 10 years) in areas covering at least one of the followingIP and SOC design, DV, micro architecture, architecture, camera, video, GPU, DSP, NSP, CPU, security, NOCs and DRAM controller subsystems, power architecture and power and performance estimation and optimization.\n\nExcellent problem solving and communication skills\n\n\nPreferred Qualifications\n\nMasters and/or PhD degree in Electrical Engineering, Information Systems, Computer Science\n\nExperience with Mixed & Augmented reality system design, constraints, and trade-offs\n\nDeep understanding of system architecture aspects such as NOCs, DRAM controller performance issues, power domains and sleep modes of memories, IPs and cores.\n\nProven experience in conducting architectural trade-offs, power/performance analysis and/or SW-HW trade-offs\n\nExperience with system level modeling (performance and/or power)\n\nProficiency in scripting languages such as python, perl, shell etc.\n\n\nKeywords\n\nCamera, GPU, CPU, SOC, SoC architecture, NOC, DDR subsystem, LPDDR IP, caches, security, virtual memory, development, RTL design, Computer vision, Artificial Intelligence, ML, DSP, AR, VR, MR, XR\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 1+ year of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'system architecture', 'aspect', 'scripting languages', 'system engineering', 'synthesis', 'asic', 'cdc', 'soc', 'system design', 'rtl', 'vhdl', 'verilog', 'microservices', 'lint', 'rtl design', 'computer science', 'fpga', 'fpga design', 'soc design', 'rtl coding', 'shell scripting', 'perl', 'system verilog']",2025-06-12 06:37:23
Software Engineer - C | Python | Linux | Platform Infrastructure,Cisco,9 - 12 years,Not Disclosed,['Bengaluru'],"you will:\nDevelop and integrate products deployed by leading service providers worldwide.\nCollaborate with a vibrant, BU-wide technical community to exchange ideas and innovate on next-generation technology.\nExplore opportunities for personal growth while mentoring colleagues and working on cutting-edge technologies.\nAs a key member of this team, you will:\nWork alongside seasoned engineers to architect, design, and develop some of routers and solutions for the world's largest service provider, web centers, and enterprises.\nContribute to the evolution of these systems to support exciting new customer business paradigms.\nInteract and collaborate with some of the finest talent in the industry, making work both fun and challenging.\nEngage with other groups such as Product Management, Marketing, Sales, Customer Support, and Advanced Services.\nWho You Are:\nYou possess:\nIn-depth knowledge of C and a solid understanding of Python.\nExtensive experience in a Unix/Linux-based development environment.\nExcellent coding, automation, and debugging skills.\nStrong teamwork and communication skills.\nFamiliarity with hardware architectures such as PCI, PCIe, DMA, I2C, SPI, NPUs/DPUs and processors like x86, AMD, and ARM. Experience with board bringup is a plus.\nExperience with emerging technologies such as AI/ML and cloud computing is a plus.\nExperience and Qualifications:\nExperience: 9 to 12 years in embedded firmware development.\nEducation: BE/B.Tech/ME/M.Tech/MS in CS/EE/IT/ECE, MCA, or similar education.\nProven ability to derive design and code based on technical standards and write comprehensive, focused design documents.\nExperience in developing software/firmware for networking equipment.\nExcellent knowledge of software architecture and system design.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'networking', 'artificial intelligence', 'sales', 'linux', 'pci', 'debugging', 'software engineering', 'i2c', 'cloud computing', 'arm', 'firmware', 'ml', 'board bringup', 'c', 'embedded firmware development', 'software development', 'system design', 'spi', 'marketing', 'x86', 'embedded c', 'dma', 'pcie', 'unix']",2025-06-12 06:37:26
Staff Engineer Gen-AI,recex,8 - 12 years,Not Disclosed,['Bengaluru'],"Job Title: Staff Engineer Gen-AI\nExperience: 8.0 Year To 10.0 Year\nCTC Salary: 50.00 LPA To 65.00 LPA\nLocation: Bengaluru/Bangalore\n\nJob Description\nBuild Gen-AI native products: Architect, build, and ship platforms powered by LLMs, agents, and predictive AI.\nStay hands-on: Design systems, write code, debug, and drive product excellence.\nLead with depth: Mentor a high-caliber team of full stack engineers.\nSpeed to market: Rapidly ship and iterate on MVPs to maximize learning and feedback.\nOwn the full stack: From backend data pipelines to intuitive UIsfrom Airflow to React from BigQuery to embeddings.\nScale what works: Ensure scalability, security, and performance in multi-tenant, cloud-native environments (GCP).\nCollaborate deeply: Work closely with product, growth, and leadership to align tech with business priorities.\nWhat You Bring\n8+ years of experience building and scaling full-stack, data-driven products\nProficiency in backend (Node.js, Python) and frontend (React), with solid GCP experience\nStrong grasp of data pipelines, analytics, and real-time data processing\nFamiliarity with Gen-AI frameworks (LangChain, LlamaIndex, OpenAI APIs, vector databases)\nProven architectural leadership and technical ownership\nProduct mindset with a bias for execution and iteration\nOur Tech Stack\nCloud: Google Cloud Platform\nBackend: Node.js, Python, Airflow\nData: BigQuery, Cloud SQL\nAI/ML: TensorFlow, OpenAI APIs, custom agents\nFrontend: React.js\n\n\nInterested professional can share Resume at harshita.g@recex.co\n\nThanks & Regards\nHarshita\nRecex",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Airflow', 'Cloud SQL', 'Google Cloud Platform', 'OpenAI APIs', 'Node.js', 'BigQuery', 'custom agents', 'React.js', 'Python', 'TensorFlow']",2025-06-12 06:37:28
Senior Generative AI Engineer - Python Programming,Zettamine Labs,7 - 8 years,Not Disclosed,['Bengaluru'],"We are looking for a Senior Generative AI Engineer who is passionate about cutting-edge AI innovation and has significant hands-on experience in building and deploying Generative AI models. In this role, you will be responsible for designing, fine-tuning, and optimizing large language models (LLMs), implementing innovative GenAI solutions, and contributing to the architecture of AI-driven platforms that deliver real business value.\n\nYou will collaborate with cross-functional teams including data scientists, machine learning engineers, product managers, and cloud infrastructure teams to build scalable, reliable, and secure AI systems. This is a high-impact position where you will directly influence the AI roadmap and innovation strategy.\n\nKey Responsibilities :\n\n- Design, develop, and fine-tune state-of-the-art Generative AI and LLM models tailored for various business use cases.\n\n- Build, integrate, and optimize solutions using transformer-based architectures (e.g., GPT, BERT, T5, LLaMA, Mistral).\n\n- Apply techniques such as fine-tuning, prompt engineering, RLHF (Reinforcement Learning from Human Feedback), and knowledge distillation to improve model performance.\n\n- Work with vector databases (e.g., FAISS, Pinecone, Weaviate) for implementing retrieval-augmented generation (RAG) pipelines.\n\n- Develop and deploy embedding models and integrate them into LLM pipelines.\n\n- Collaborate with engineering and product teams to deploy scalable AI systems using MLOps practices and CI/CD pipelines.\n\n- Leverage LangChain, Hugging Face Transformers, OpenAI APIs, and similar frameworks/tools to accelerate development.\n\n- Optimize model performance across different environments (cloud/on-premise).\n\n- Develop end-to-end pipelines, from data preprocessing to real-time inference and monitoring.\n\n- Ensure high standards of software quality, including testing, version control, code reviews, and documentation.\n\n- Stay up to date with the latest research in Generative AI and translate breakthroughs into production-ready solutions.\n\nRequired Skills & Qualifications :\n\n- Experience : 7+ years in AI/ML, data science, or software engineering; at least 3 - 4 years in Generative AI/LLMs.\n\n- Advanced Python programming skills, including familiarity with object-oriented design and software engineering best practices.\n\n- Deep expertise in PyTorch, TensorFlow, Transformers (Hugging Face), LangChain, and OpenAI or Anthropic APIs.\n\n- Experience in LLM fine-tuning, parameter-efficient tuning methods (LoRA, PEFT), RLHF, and model evaluation.\n\n- Experience with embeddings, vector stores (FAISS, Pinecone), semantic search, and RAG systems.\n\n- Hands-on experience with AWS, GCP, or Azure; knowledge of MLOps tools (SageMaker, Vertex AI, MLflow, Kubeflow) for training, deploying, and monitoring models.\n\n- Familiarity with structured/unstructured data handling and integrating AI systems with SQL/NoSQL databases.\n\n- Strong analytical thinking, problem-solving ability, and a keen interest in research and innovation.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Programming', 'Tensorflow', 'PyTorch', 'Generative AI', 'MLOps', 'NoSQL', 'ChatGPT', 'Artificial Intelligence', 'Data Modeling', 'LLM', 'Python', 'SQL']",2025-06-12 06:37:31
XR Systems & Software Architect XR Research Staff,Qualcomm,9 - 14 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Software Engineering\n\nGeneral Summary:\n\nQualcomm XR Research India is rapidly expanding to offer state of the art XR solutions. To scale and strengthen our offering in this domain, we are seeking a systems architect who will drive the next-generation technologies and architecture, shaping the future of Augmented Reality (AR), Virtual Reality (VR), and Mixed Reality (MR) use cases.\n\nResponsibilities:\n\nYour responsibilities will span across technical leadership, system architecture, software architecture, implementation and compute analysis. Here are the key aspects of your role:\n\nDrive technical workstreams related to perception, reprojection, split-processing and other XR technologies.\n\nIdentify and deeply understand the use cases for AR/VR/MR applications. Collaborate with cross-functional teams to translate use case requirements into detailed implementation specifications.\n\nDefine system and software architecture, considering hardware/software tradeoffs, compute and memory constraints. Optimize compute workload distribution across different subsystems on the SoC for efficient performance and power.\n\nValidate and optimize architecture definitions through system-level use case modeling.\n\nPrototype new use cases to understand the compute and memory requirements, and influence future software/hardware features and reference device specification.\n\n\nMinimum Qualifications:\n\n9+ years of experience in systems engineering with a bachelors degree in electrical engineering, information systems, computer science, or related field.\n\nHands-on experience in defining systems architecture and software design for multi-core architectures (CPUs, GPUs, DSPs, etc.), including performance analysis on heterogeneous architectures (core, multi-level cache, memory, etc.).\n\nProficiency in documenting call flows and data flows for both software and hardware components.\n\nStrong communication skills and ability to work effectively in a team.\n\n\nPreferred Qualifications:\n\n8+ years of experience in systems engineering with masters and/or PhD degree in electrical engineering, information systems, computer science.\n\nProven expertise in AR/VR, computer vision, machine learning, perception, camera technology, graphics pipeline, hardware design, SoC architecture, HW/SW partitioning, and system modeling (power, performance).\n\nProficiency in C++, and Object-Oriented SW design\n\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Software Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Software Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Software Engineering or related work experience.\n\n2+ years of work experience with Programming Language such as C, C++, Java, Python, etc.",Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['virtual reality', 'c++', 'machine learning', 'computer vision', 'call flow', 'synthesis', 'python', 'c', 'data validation', 'graphics', 'prototype', 'verilog', 'hw', 'pipeline', 'rtl design', 'java', 'computer science', 'hardware design', 'soc design', 'software engineering', 'data flow', 'system engineering']",2025-06-12 06:37:33
Chipset Architect,Qualcomm,12 - 17 years,Not Disclosed,['Bengaluru'],"Job Area: Engineering Group, Engineering Group > Systems Engineering\n\nGeneral Summary:\n\nAs a leading technology innovator, Qualcomm pushes the boundaries of what's possible to enable next-generation experiences and drives digital transformation to help create a smarter, connected future for all. As a Qualcomm Chipset Architect, you will research, design, develop, simulate, and/or validate systems-level hardware, software, architecture, algorithms, and solutions that enables the development of cutting-edge technology. Qualcomm Systems Engineers collaborate across functional teams to meet and exceed system-level requirements and standards.\n\nMinimum Qualifications\n\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 12+ years of Systems Engineering or related work experience.ORMaster's degree in Engineering, Information Systems, Computer Science, or related field and 10+ years of Systems Engineering or related work experience.\n\nPreferred Qualifications\n\nMaster's Degree in Engineering, Information Systems, Computer Science or related field.\n\n15+ years of Systems Engineering or related work experience.\n\nExpert knowledge of interfaces (USB, PCIe, SD/eMMC, UFS, LPDDRx, CSI, DSI, SPI, I2C, I3C, PMBUS, SPMI, Slimbus etc)\n\n10+ years of experience working in PC or IoT industry;\n\nKnowledge of commercial, industrial and home automation systems\n\nExperience with full product lifecycle from requirements gathering, prototype development, production, knowledge of PCB design flow, EDA tools, electrical and thermal simulations.\n\nFamiliarity with software stack and hardware-software dependencies including HLOS, drivers, kernel, BIOS\n\nFamiliarity with certification, shock and vibration testing and EMI compliance\n\nIn depth knowledge of power delivery, PDN, component selection, tuning, PMICs, eBOM\n\nGood domain knowledge of 2 or more functional areas of SoCs such as Application Processor, Display, Graphics, Camera, Video, AI, Modem (4G/5G), WLAN, Power Management etc.\n\nExposure to 4G/5G/6G systems and associated cellular standards (e.g. 3GPP NR, LTE).\n\nWorking with a wide cross functional team comprising of various design and software teams, reliability, functional safety, business, sales and customer engineering\n\n\nPrincipal Duties and Responsibilities\n\nApplies Systems knowledge to evaluate Industrial customer asks and propose chipset solutions utilizing Qualcomm ICs.\n\nDevelops and analyzes system level design including requirements, interface definition, functional/performance definition, and implementation of a new system or modification of an existing system.\n\nEvaluates interface signaling for clock, data, sideband requirements and propose solution with internal and third-party components.\n\nEvaluates signal integrity needs and identifies architecture for high-speed interfaces, topologies (stacked boards, different form factors etc), timing needs, and signal conditioning techniques.\n\nUnderstand power requirements and propose suitable powering schemes for the entire platform.\n\nCollaborates with own team and other teams to complete project work, including implementing and testing features and verifying the accuracy of systems.\n\nPerforms functional analysis to drive requirements and specifications and to define and align with standards for hardware and software.\n\nReviews internal and customer board schematics\n\nDevelops new and innovative ideas (e.g. IDFs) for a product or feature area.\n\nDrives triage of problems at the system level to determine root cause and presents results of testing and debugging to team members.\n\nLevel of Responsibility\n\nWorks independently with minimum supervision.\n\nDecision-making may affect work beyond immediate work group.\n\nRequires verbal and written communication skills to convey information. May require basic negotiation, influence, tact, etc.\n\nHas a moderate amount of influence over key organizational decisions (e.g., is consulted by senior leadership to make key decisions).\n\nTasks require multiple steps which can be performed in various orders; some planning, problem-solving, and prioritization must occur to complete the tasks effectively.\n\nMinimum Qualifications:\nBachelor's degree in Engineering, Information Systems, Computer Science, or related field and 4+ years of Systems Engineering or related work experience.\nOR\nMaster's degree in Engineering, Information Systems, Computer Science, or related field and 3+ years of Systems Engineering or related work experience.\nOR\nPhD in Engineering, Information Systems, Computer Science, or related field and 2+ years of Systems Engineering or related work experience.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['usb', 'sd', 'i2c', 'spi', 'pcie', 'algorithms', 'ufs', 'power system', 'simulation', '3gpp', 'pcb', 'sales', 'artificial intelligence', 'iot', '5g', 'ebom', 'computer science', 'debugging', 'lte', 'digital transformation', 'functional safety', 'system engineering', 'prototype', 'component selection', 'pc', '4g', 'csi']",2025-06-12 06:37:36
Staff HPC Software Developer,Qualcomm,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Area: Information Technology Group, Information Technology Group > IT Software Developer\n\nGeneral Summary:\n\nWhats in it for youQualcomm is enabling a world where everyone and everything can be intelligently connected. Qualcomm 5G and AI innovations are the power behind the connected intelligent edge. Youll find our technologies behind and inside the innovations that deliver significant value across multiple industries and to billions of people every day.Qualcomm engineering teams rely heavily on the latest High Performance Computing (HPC) technologies to design and develop new products using electronic design automation (EDA) tools. This role provides an opportunity to work on the latest HPC technologies and gain experience in building scalable and fault-tolerant software solutions that are deployed on some of the largest supercomputing infrastructures across the globe.What are we looking forEngineering Software Solutions and Data Services team (ESSDS) is looking for an experienced software developer with strong HPC background. The ESSDS team is responsible for development of software solutions enabling High Performance Compute grid and large-scale, distributed, analytical applications. They work on components and services for HPC infrastructure optimization, hardware IP management systems, petabyte-scale cloud data platforms and development of machine learning solutions and pipelines.This is an individual contributor technical role providing subject matter expertise (SME) across the portfolio of HPC software products and services being developed by ESSDS team. The ideal candidate would be a seasoned software developer who is skilled in many of the following areascluster infrastructure management, job scheduling and orchestration, parallel programming, performance tuning and optimizations, efficient algorithms and data structures, compute/storage/network architectures, cloud computing, GPU computing, and EDA workflows.What will you doThis roles responsibilities include:- Design and develop software solutions and services for HPC infrastructure running EDA workflows and AI workloads- Identify opportunities and deliver solutions for EDA workflow optimizations- Provide HPC expertise across portfolio of projects, guiding and mentoring a team of software developers as needed- Execute projects in partnership with global Engineering IT teams- Manage and track the software development process from development to production release in collaboration with other software developersWhat do we want to seeThe ideal candidate will be able to demonstrate some of the following skills:- 8+ years of hand-on experience in developing software solutions for HPC grid infrastructure- Broad knowledge of latest compute, storage and networking architectures- Experience of building HPC infrastructure in public cloud environments such as AWS, Azure or Google Cloud- Proven expertise in parallel and distributed programming, GPU computing and performance engineering- Proficiency in programming languages such as Python, C++, Java, Rust- Deep understanding of HPC job schedulers such as LSF, Slurm and PBS- Familiarity with EDA and semiconductor design process- Exposure to AI and ML workloads running on HPC infrastructure- Expertise in software lifecycle management, version control, and CI/CD best practices for quality, agility and security- Ability to explain technical concepts and analysis implications in a clear manner to a wide audience.- Bachelors or Masters in Computer Science, Computational Science or related field\n\nMinimum Qualifications:\n5+ years of IT-relevant work experience with Bachelor's degree in a technical field (e.g., Computer Engineering, Computer Science, Information Systems).\nOR\n7+ years of IT-relevant work experience without a Bachelors degree.\n\n4+ years of work experience with Full-stack Application Development (e.g., Java, Python, JavaScript, etc.).\n3+ years of work experience with Data Structures, algorithms, and data stores.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'version control', 'ci/cd', 'networking', 'performance engineering', 'algorithms', 'python', 'c++', 'microsoft azure', 'distributed architecture', 'javascript', 'application development', 'java', 'gcp', 'infrastructure', 'hpc', 'data structures', 'aws', 'parallel computing']",2025-06-12 06:37:38
AI Engineer,Shashwath Solution,5 - 8 years,Not Disclosed,['Bengaluru'],"Job Summary:\nWe are seeking a highly skilled and hands-on AI Engineer with 3+ years of proven experience in building and deploying solutions using Generative AI and Large Language Models (LLMs). You will work on cutting-edge applications leveraging transformer-based architectures, fine-tuning, prompt engineering, and scalable AI deployments.\n\nThis role is ideal for engineers passionate about AI research and real-world productization of generative AI technologies.\n\nKey Responsibilities:\nDesign, develop, and deploy solutions using LLMs (e.g., GPT, LLaMA, Mistral, Claude, PaLM, etc.) for various NLP and content generation tasks.\n\nWork on fine-tuning, prompt engineering, and retrieval-augmented generation (RAG) pipelines.\n\nIntegrate LLMs into enterprise applications with APIs and orchestrate workflows using Python, LangChain, or similar frameworks.\n\nOptimize model performance, latency, and cost for production use.\n\nCollaborate with data scientists, MLOps engineers, and product managers to deliver scalable AI features.\n\nConduct experiments, analyze results, and publish internal findings or contribute to whitepapers.\n\nEnsure ethical, secure, and responsible use of AI technologies in all implementations.\n\nRequired Skills & Experience:\n3+ years of hands-on experience working with Generative AI, LLMs, and NLP technologies.\n\nStrong programming skills in Python and experience with libraries like Transformers (Hugging Face), LangChain, PyTorch, TensorFlow, etc.\n\nProven track record of fine-tuning LLMs, developing embeddings, and working with vector databases (e.g., FAISS, Pinecone, Weaviate).\n\nExperience deploying models on cloud platforms (AWS, Azure, GCP) and using ML pipelines or MLOps tools.\n\nSolid understanding of deep learning, NLP architectures, tokenization, and evaluation metrics for generative models.\n\nExperience in API development and integration of LLMs into user-facing applications.\n\nPreferred Qualifications:\nMasters or PhD in Computer Science, AI/ML, Data Science, or related field.\n\nExperience with OpenAI APIs, Anthropic, Cohere, or open-source LLMs (e.g., Mistral, Falcon, LLaMA 3).\n\nUnderstanding of RLHF (Reinforcement Learning from Human Feedback) and model alignment techniques.\n\nContributions to open-source AI projects or publications in GenAI/LLM.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Generative AI', 'LLaMA', 'GPT', 'Large Language Models', 'Azure', 'LangChain', 'Hugging Face', 'deep learning', 'OpenAI API', 'NLP', 'PyTorch', 'MLOps', 'GCP', 'PaLM', 'AWS', 'Python', 'TensorFlow']",2025-06-12 06:37:41
"Senior Java Developer (Microservices, Emerging Technologies & Cloud)",Synechron,5 - 10 years,Not Disclosed,['Bengaluru'],"job requisition idJR1027430\n\nOverall Responsibilities:\nLead the development and implementation of projects using emerging technologies\nMentor and guide team members to ensure the successful delivery of projects\nIdentify and evaluate new technology solutions to improve business processes\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nStay up-to-date with the latest technological advancements and industry trends\n\n\nSkills:\nStrong expertise in emerging technologies such as blockchain, IoT, AI, etc.\nStrong technical knowledge of software development lifecycle\nExcellent problem-solving and critical thinking skills\nGood understanding of software architecture and design patterns\nAbility to lead and manage a team of technical experts\nExperience:\nAt least 5+ years of experience in software development and leading technology projects\nProven track record of delivering projects using emerging technologies\nExperience in mentoring and guiding junior team members\nExperience in working with cross-functional teams\nDay-to-Day Activities:\nManage the development and delivery of projects using emerging technologies\nProvide technical guidance and mentorship to junior team members\nCollaborate with cross-functional teams to ensure alignment with the organization's overall strategy\nEvaluate and recommend new technology solutions to improve business processes\nStay up-to-date with the latest technological advancements and industry trends\nQualification:\nBachelor's or Master's degree in Computer Science, Information Technology, or related field\nRelevant certifications in emerging technologies\nSoft\n\nSkills:\nStrong communication and leadership skills\nAbility to work well under pressure and meet tight deadlines\nExcellent interpersonal and team-working skills\nAbility to effectively communicate technical information to non-technical stakeholders\nPassionate about technology and a desire to stay up-to-date with the latest advancements.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['emerging technologies', 'artificial intelligence', 'iot', 'software development life cycle', 'blockchain', 'software development', 'information technology', 'technology solutions', 'microservices', 'java', 'design patterns', 'project delivery', 'leadership development']",2025-06-12 06:37:44
Python Developer,Coartha Technosolutions,0 - 1 years,Not Disclosed,['Hyderabad( Madhapur )'],"Seeking a passionate Python Developer (Fresher) to work on innovative projects in Python, AI, and ML. Great opportunity to build and maintain high-quality product features and grow your skills in a dynamic, collaborative environment.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Large Language Model', 'Pandas', 'MongoDB', 'Machine Learning', 'Deep Learning', 'Numpy', 'Elastic Search', 'Flask']",2025-06-12 06:37:47
Artificial Intelligence Architect,Ltimindtree,12 - 16 years,Not Disclosed,"['Hyderabad', 'Bengaluru', 'Mumbai (All Areas)']",We are looking for an experienced AI ML Developers experience in data science specializing in machine learning python statistical modelling and big data technologies pyspark sql.\n\nThe ideal candidate will have a strong background in developing and deploying machine learning models optimizing ML pipelines and handling largescale structured and unstructured data to drive business impact.\n\nDeep understanding of supervised and unsupervised learning including regression classification Multiclass classification clustering and NLP Proficiency in statistical analysis AB testing and causal inference techniques Experience with model deployment and MLOps in cloud environments AWS GCP \n\nKey Responsibilities\n\nDevelop and deploy machine learning models and predictive analytics solutions for business impact\nWork with largescale structured and unstructured data to extract insights and build scalable models\nDesign implement and optimize ML pipelines for realtime and batch processing\nCollaborate with engineering product and business stakeholders to translate business problems into data science solutions\nApply statistical modeling AB testing and causal inference techniques to evaluate business performance\nApply machine learning and statistical techniques for audience segmentation helping to identify patterns and optimise business strategies\nDrive research and innovation by staying updated with cuttingedge MLAI advancements and incorporating them into our solutions\nOptimize data science models for performance scalability and interpretability in production environments\nMentor junior data scientists and contribute to best practices in data science and engineering,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Architect', 'MLOps', 'Machine Learning', 'Ai Solutions', 'Aiml', 'Ml']",2025-06-12 06:37:49
Python Developer (3-5 Years)-RA @ Infosys,Infosys,3 - 5 years,Not Disclosed,"['Chandigarh', 'Pune', 'Bengaluru']","Responsibilities\nWrite clean, maintainable, and efficient Python code for backend services or applications. Develop RESTful APIs or work on web applications using frameworks like Django or Flask. Implement data extraction, transformation, and loading (ETL) processes using Python. Collaborate with front-end developers and other team members to ensure seamless integration. Test and debug applications to ensure they meet quality and performance standards.\nParticipate in code reviews and contribute to the development of coding standards.\nKeep up-to-date with Python libraries and tools relevant to the project.\nTechnical and Professional Requirements:\nPrimary skills: Technology->Machine Learning->Python\nPreferred Skills: Technology->Machine Learning->Python\nAdditional Responsibilities:\nSkills Required:\nStrong proficiency in Python 3.x.\nExperience with at least one Python web framework (Django, Flask, etc.).\nKnowledge of database technologies, including SQL and ORM (e.g., SQLAlchemy).\nFamiliarity with version control systems like Git.\nBasic understanding of front-end technologies (HTML, CSS, JavaScript).\nExperience with unit testing frameworks like pytest or unittest.\nKnowledge of REST API design principles.\nEducational Requirements\nMCA, MTech, Bachelor of Engineering, BCA, BSc, BTech",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Flask']",2025-06-12 06:37:52
Hiring BTech freshers - (Full stack),Guidehouse,0 - 1 years,Not Disclosed,['Thiruvananthapuram'],"Roles and Responsibilities :\nMust be a graduate in\nBE/BTech/MCA in IT/CS or a related field.\nExcellent technical and interpersonal communication skills.\nBasic understanding of programming languages such as GoLang.\nFamiliarity with web development frameworks like React, Angular, Blazor, or Vue.js.\nKnowledge of cloud platforms such as Azure, AWS, or Google Cloud Platform.\nUnderstanding of containerization technologies like Docker.\nBasic knowledge of database management systems such as MSSQL, MySQL, PostgreSQL, or MongoDB.\nGood understanding of SDLC, STLC, Agile methodologies, and business process analysis.\nFamiliarity with RESTful APIs, microservices concepts, and DevOps practices.\nBasic understanding of security best practices in software development.\nFamiliarity with version control systems like Git.\nPreferred/Good to Have\nInternship or project experience in software development, DevOps, cloud, or related fields.\nFamiliarity with business intelligence tools (e.g., Power BI, Tableau).\nKnowledge of identity and access management solutions.\nInterest or coursework in artificial intelligence, machine learning, or data science.\nExperience with scripting languages (e.g., Bash, PowerShell).\nActive participation in technical forums (e.g., Stack Overflow) or GitHub contributions.\nExposure to UI/UX design principles.\nExperience with mobile app development (Android/iOS/Flutter/React Native) is a plus.\nAwareness of CI/CD pipelines and infrastructure as code tools (e.g., Terraform, Ansible).\nExperience working with orchestration technologies like Kubernetes.\nStrong logical, analytical, and problem-solving skills; experience in hackathons, coding challenges, or open-source contributions is a plus.\nAny certifications (e.g., Microsoft, AWS, Google, Scrum) are an added advantage.",Industry Type: Management Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Golang', 'Golang Development', 'React.Js']",2025-06-12 06:37:54
AI/ML Engineer/Architect -,Choice Consultants,6 - 10 years,20-35 Lacs P.A.,"['New Delhi', 'Bengaluru']","Automotive, Business Relationship Management, Collaborative Leadership, Communication, Computer Vision, AI, Machine Learning, Team Leadership, Technological Innovation, Proposal",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['C/C++', 'AI/ML', 'PYTHON', 'COMPUTER VISION', 'AIML', 'Medical Imaging', 'DEEP LEARING']",2025-06-12 06:37:56
Sr. Technology Auditor,AMERICAN EXPRESS,2 - 4 years,13-18 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Role & responsibilities\n•       Translate business risks, controls and supporting data into analytic requirements and partners with colleagues to build effective analytics and insights\n•       Responsible for multiple simultaneous audit projects of all sizes and complexity across multiple business areas within and outside of local region, in unfamiliar areas, and for different audit leaders\n•       Link analytics and insights to ongoing strategic initiatives\n•       Apply proven/ advanced data algorithms, advanced analytic and modeling techniques to draw insights essential to driving improvement initiatives",,,,"['Natural Language Processing', 'Tableau', 'Machine Learning', 'SQL', 'Python']",2025-06-12 06:37:58
Full Stack AI Engineer (Lead),Inclusive Business Solutions,3 - 8 years,20-35 Lacs P.A.,[],"AI specialists for Full Stack, Computer Vision, and Speech Processing roles. Responsibilities include real-time data integration, emotion recognition, and speech analysis. Must have expertise in AI frameworks, ML models, and optimization techniques.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Speech Recognition', 'Natural Language Processing', 'Computer Vision', 'Machine Learning', 'Python', 'Tensorflow', 'Large Language Model', 'Artificial Intelligence', 'AWS', 'Deep Learning']",2025-06-12 06:38:01
Sr. Data Analyst,Icims,4 - 9 years,Not Disclosed,['Hyderabad'],"Overview\nThe Senior Data Analyst is responsible for serving as a subject matter expert who can lead efforts to analyze data with the goal of delivering insights that will influence our products and customers. This position will report into the Data Analytics Manager, and will work closely with members of our product and marketing teams, data engineers, and members of our Customer Success organization supporting client outreach efforts. The chief functions of this role will be finding and sharing data-driven insights to deliver value to less technical audiences, and instilling best practices for analytics in the rest of the team.",,,,"['server', 'data', 'vlookup', 'market data', 'data mapping', 'dashboards', 'research', 'sql', 'analytics', 'tables', 'prep', 'pivot', 'data visualization', 'communication skills', 'python', 'data analytics', 'data analysis', 'insights', 'pivot table', 'data engineering', 'graph', 'excel', 'data quality', 'tableau', 'data governance', 'root cause']",2025-06-12 06:38:03
Scientific Business Analyst (Associate) – ELN,Amgen Inc,0 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nThis role involves working closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements scientific software platforms such as Laboratory Information Management Systems (LIMS) that enable the capture of lab workflows & experimental data and Electronic Lab Notebooks (ELN) that act as Amgens System of Record ensuring data integrity and business continuity. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the technology ecosystem for in vivo study data management and ensure that the platform meets their requirements for data analysis and data integrity\nTranslate complex scientific and technological needs into clear, actionable requirements for development teams\nDevelop and maintain a product roadmap that clearly outlines the planned features and enhancements, timelines, and landmarks\nIdentify and manage risks associated with the systems, including technological risks, scientific validation, and user acceptance\nDevelop documentations, communication plans and training plans for end users\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\nCollaborate with geographically dispersed teams, including those in the US and other international locations.\nFoster a culture of collaboration, innovation, and continuous improvement.\n\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nBachelors degree with 0 - 3 years of experience in Life Sciences, Computer Science, IT, Computational Chemistry/Cheminformatics, Computational Biology/Bioinformatics or related field, OR\nDiploma with 4 - 7years of experience in Life Sciences, Computer Science, IT, Computational Chemistry/Cheminformatics, Computational Biology/Bioinformatics or related field, OR\nDemonstrated expertise in a scientific domain area and related technology needs\nExcellent problem-solving skills and a passion for tackling complex challenges in drug discovery with technology and data\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience with Benchling, Revvity, IDBS, or similar LIMS/ELN platforms\nPreferred Qualifications:\nExperience with Agile software development methodologies (Scrum)\nExperience performing or enabling data capture and analysis from instruments in a research laboratory or vivarium\nAbility to communicate technical or complex subject matters in business terms\nKnowledge of business analysis standard processes, DevOps, Continuous Integration, and Continuous Delivery methodology\nExperience with cloud (e.g. AWS) and on-premise infrastructure\nExperience supporting ELN/LIMS platforms in biopharma\n\n\n\nProfessional Certifications:\nSAFe for Teams certification (preferred)\n\n\n\nSoft\n\nSkills:\nAble to work under minimal supervision\nExcellent analytical and gap/fit assessment skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Business Analysis', 'LIMS platforms', 'ELN platforms']",2025-06-12 06:38:05
Lead AI Engineer,Insnapsys Technologies,7 - 10 years,8.4-18 Lacs P.A.,['Nashik'],"We're hiring a Lead AI Engineer (Remote/Nashik) to build & lead AI/ML & LLM solutions. 7+ yrs exp, strong in Python, LLMs, AWS, MLOps, vector DBs. Bonus: voice AI, agents, open-source.\n\nTeam Leading Experience is Mandatory\n\nApply: hr@insnapsys.com.\n\n\nWork from home\nHouse rent allowance",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Machine Learning', 'Data Science', 'English', 'Marathi', 'Team Leading', 'Hindi', 'Deep Learning', 'Ml', 'Python']",2025-06-12 06:38:08
Python/Pyspark developer,Zensar,4 - 5 years,Not Disclosed,"['Pune', 'Bengaluru']","Job Description:\nWe are seeking a highly skilled and motivated Python/PySpark Developer to join our growing team. In this role, you will be responsible for designing, developing, and maintaining high-performance data processing pipelines using Python and the PySpark framework. You will work closely with data engineers, data scientists, and other stakeholders to deliver impactful data-driven solutions.\nResponsibilities:\n- Design, develop, and implement scalable and efficient data pipelines using PySpark.\n- Write clean, well-documented, and maintainable Python code.\n- Optimize data processing performance and resource utilization.\n- Implement ETL (Extract, Transform, Load) processes to migrate and transform data across various systems.\n- Collaborate with data scientists and analysts to understand data requirements and translate them into technical solutions.\n- Troubleshoot and debug data processing issues.\n- Stay up-to-date with the latest advancements in big data technologies and best practices.\nQualifications:\n- Bachelor's degree in Computer Science, Engineering, or a related field.\n- 3+ years of experience in Python development.\n- 2+ years of experience with PySpark and Spark ecosystem.\n- Strong understanding of data structures, algorithms, and object-oriented programming.\n- Experience with SQL and relational databases.\n- Familiarity with cloud platforms such as AWS, Azure, or GCP (preferred).\n- Excellent problem-solving and analytical skills.\n- Strong communication and teamwork skills.\nBonus Points:\n- Experience with data visualization tools (e.g., Tableau, Power BI).\n- Knowledge of machine learning and data science concepts.\n- Experience with containerization technologies (e.g., Docker, Kubernetes).\n- Contributions to open-source projects.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Cloud Technologies', 'SQL', 'Python']",2025-06-12 06:38:10
Analytics & Visualization Developer,Qualcomm,7 - 10 years,Not Disclosed,['Hyderabad'],"Job Area: Information Technology Group, Information Technology Group > IT Programmer Analyst\n\nGeneral Summary:\n\nQualcomms Engineering IT EDAAP team is looking for an independent contributor experienced in development and sustaining enterprise level software applications. Experience:7-10 years of experience developing dashboard with reporting tools- Tableau (Tableau API), Power BI, OBIEE. SkillsMust:\nExpert in developing visualizations/dashboards with Tableau\nStrong knowledge with SQL\nFundamentals in object-oriented design, data structures, algorithms and problem solving.\nTest, debug and performance tuning of dashboards/reports\nExperience working in an agile development environment.\nTranslate ad hoc report requests into common dashboards and application requirements\nKnowledge of different types of enterprise systems, their interaction, boundaries within an enterprise.\nUnderstanding of complex data models.\nExperience working with Oracle/MySQl/Postgres\nWILLINGNESS to multi task and work in a fast paced environment.\nMust be willing to take ownership and drive tasks to completion. Desirable:\nPython programming experience.\nExperience developing dashboards with Power BI.\nExposure to Qlikview, OBIEE and ThoughtSpot\nExperience with semiconductor industry.\nExperience working with NoSQL Databases (MongoDB) as well as relational DBs (MySQL/Oracle) Education\nBachelor's degree in technical discipline or equivalent experience required.\n\nQualifications\n5 or more years of experience in applying AI and machine learning techniques to practical and comprehensive technology solutions.\nA strong background in machine learning, deep learning, and natural language processing.\nExpertise in ML, deep learning, Py Torch, Python, NLP and Transformer architecture.\nExperience in deploying LLMs, embedding model/sentence transformers in production use cases.\nThorough knowledge in basic algorithms, object-oriented and functional design principles, and best-practice patterns\nStrong expertise in programming (Rust/Python)\nExperience in fine-tuning a large language model using custom content (documents, data, code).\nExperience in developing Generative AI applications, Agentic Systems and Retrieval Augmented Generation.\nExperience working with large-scale datasets, preprocess them, and create appropriate data representations.\nSolid understanding of statistics, linear algebra, and probability theory.\n\nPreferred Qualifications\nBachelors/masters degree in computer science, Artificial Intelligence, Data Science, or a related field.\nExperience in implementing projects involving end to end ML/NLP systems from development to deployment.\nExperience with transformer-based models (e.g., BERT, GPT, T5, Llama).\nExperience working in a distributed team.\nExperience with cloud environments (GCP/AWS).\nWorking knowledge of Rust is a plus.\n\nMinimum Qualifications:\n4+ years of work experience in programming, scripting, and/or automation or IT-relevant work experience with a Bachelor's degree.\nOR\n6+ years of work experience in programming, scripting, and/or automation or IT-relevant work experience without a Bachelors degree.\n\n2+ years experience with Database Design structures such as Mongo DB, MySQL.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'deep learning', 'pytorch', 'algorithms', 'functional design', 'dashboards', 'artificial intelligence', 'sql', 'database design', 'tableau', 'data visualization', 'design principles', 'linear algebra', 'ml', 'statistics']",2025-06-12 06:38:13
Mlops Engineer,Rarr Technologies,8 - 13 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']",Key Responsibilities\nResponsible for building and maintaining robust machine learning pipelines ensuring efficient model deployment monitoring and lifecycle management within a cloud-based environment\nExtensive expertise in MLOps specifically with Google Cloud Platform GCP and Vertex AI and a deep understanding of model performance drift detection and GPU accelerators\nBuild and maintain scalable MLOps pipelines in GCP Vertex AI for endtoend machine learning workflows\nManage the full MLOps lifecycle from data preprocessing model training and deployment to model monitoring and drift detection\nImplement realtime model monitoring and drift detection to ensure optimal model performance over time\nOptimize model training and inference processes using GPU accelerators and CUDA\nCollaborate with cross functional teams to automate and streamline machine learning model deployment and monitoring\nUtilize Python 310 with libraries such as pandas NumPy and TensorFlow to handle data processing and model development\nSet up infrastructure for continuous training testing and deployment of machine learning models\nEnsure scalability security and high availability in all machine learning operations by implementing best practices in MLOps\nRequirements\n5 years of experience in MLOps and building ML pipelines 3 years of experience in GCP Vertex AI\nDeep understanding of the MLOps lifecycle and automation of ML workflows\nProficient in Python 310 and related libraries such as pandas NumPy and TensorFlow\nStrong experience in GPU accelerators and CUDA for model training and optimization\nProven experience in model monitoring drift detection and maintaining model accuracy over time\nStrong problemsolving skills with the ability to work in a fast paced environment\nKnowledge of data versioning and model version control techniques\nFamiliarity with TensorFlow Extended TFX or other ML workflow orchestration frameworks,Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['GCP', 'vertexai', 'mlops']",2025-06-12 06:38:15
Senior Engineering Manager,Product Base Company,12 - 18 years,Not Disclosed,['Bengaluru'],"About Client:\n\nOur Client is revolutionizing how the world plans, builds, and manages infrastructure projects with Masterworks, our industry-leading enterprise SaaS platform. Trusted by over 300 customers managing $300 billion in capital programs, Masterworks is setting new standards for project delivery and asset management. Recognized as one of the Top 25 AI Companies of 2024 and a Great Place to Work for three consecutive years, we are leveraging artificial intelligence to create a smarter, more connected future for customers in transportation, water and utilities, healthcare, higher education, and the government, with over 40,000 projects across North America. Our Client dont just develop softwareThey shape the future. If youre excited to join a fastgrowing company and collaborate with some of the brightest minds in the industry to solve realworld challenges, lets connect.\n\n\nJob Summary :\n\nThe Senior Engineering Manager will lead multiple engineering teams responsible for designing, developing, and scaling software products using Microsoft technologies. This role combines strong leadership capabilities with deep technical expertise, particularly in C#, ASP.NET, .NET Core, SQL Server, and IIS. The Senior Engineering Manager will set the technical direction, ensure engineering excellence, and collaborate with cross-functional teams to deliver high-quality, scalable solutions that align with business goals.\n\nKey Responsibilities\n\n1. Technical Leadership & Strategy:\n\nLead the development and implementation of scalable software solutions, with a strong focus on Microsoft technologies (C#, ASP.NET, .NET Core, SQL Server, IIS).\n\no Define the technical strategy and roadmap, ensuring alignment with overall product and business objectives.\n\no Provide hands-on technical guidance to engineering teams, including architecture, design, and code reviews, to ensure high-quality, scalable solutions.\n\n2. Engineering Excellence: o Establish best practices for software development, focusing on clean code, maintainability, performance, and security, especially for Microsoft stack-based solutions.\n\no Drive innovation in technology choices and design patterns, ensuring efficient use of C#, ASP.NET Core, SQL Server, and other key Microsoft frameworks.\n\no Collaborate with the infrastructure team to optimize the deployment and performance of applications on IIS and cloud environments like AWS or Azure.\n\n3. Project & Delivery Management:\n\no Oversee the execution of multiple software development projects, ensuring that engineering teams are aligned with the technical roadmap.\n\no Ensure effective sprint planning, task prioritization, and on-time delivery of projects using Agile methodologies, with a focus on .NET technologies",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['C#', 'Engineering Manager', 'ASP.NET', 'roadmap', '.NET Core', 'design', 'code reviews', 'SQL Server']",2025-06-12 06:38:17
CDnA - Data Science Manager,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will collaborate with business partners, service owners and IS peers to develop predictive models and insights across the US Commercial Organization. This position will innovate and build significant business impact through the use of sophisticated analytics techniques to help Amgen with its mission to serve patients by helping them get the therapies they need.\n\nFlexible Commuter role to Amgen India office. You will work on-site 2-3 days a week.\n\nThis position will be primarily responsible for:\nWorking collaboratively with multi-functional teams on projects and/or programs with aims to systematically derive insights that ultimately derive substantial business value for Amgen and our patients\nIdentifying business needs and proposing potential analytics approaches for solutions\nCrafting and deploying a framework to supervise the performance of various campaigns, and tactics at a granular level\nLeading measurement and tracking of various omnichannel CX enablement initiatives\nSupporting the development of data science, machine learning prototypes, proof of concepts and models for testing various omnichannel strategies\nCommunicating analysis ideas, progress and results to leadership and business partners\n\n\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nDoctorate degree OR\nMasters degree and 4 to 6 years of data science and/or analytics experience OR\nBachelors degree and 6 to 8 years of data science and/or analytics experience OR\nDiploma and 10 to 12 years of data science and/or analytics experience\nPreferred Qualifications:\nRelevant work experience in campaign measurement, marketing analytics and resource optimization in the pharma domain\nProgramming experience with Python, R, or SAS and experience with ML libraries like scikit-learn, MLib, or TensorFlow\nExperience working with large datasets, experience working with distributed computing tools (Spark, Hive, etc.) is a plus\nAbility to communicate analysis in a clear, detailed, and practical manner\nPassion for learning and staying on top of current developments in sophisticated analytics\nBiotech / Pharma experience",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'hive', 'python', 'tensorflow', 'r', 'scikit-learn', 'spark', 'MLib']",2025-06-12 06:38:19
Solution Design Lead & implimantation,Excellerate Global Solutions,13 - 23 years,10-20 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Solution Design & Implementation:\nLead and participate in the full project lifecycle of SAP S/4HANA Public Cloud implementations, focusing on Procurement (Sourcing & Procurement/MM), Finance (FI/CO), and Sales & Distribution (SD) modules.\nConduct in-depth business process analysis, gather requirements, and translate them into robust and scalable SAP S/4HANA Public Cloud solutions aligned with SAP best practices.\nDesign, configure, and customize SAP S/4HANA Public Cloud functionalities for Order-to-Cash (O2C), Procure-to-Pay (P2P), Record-to-Report (R2R), and other relevant cross-functional processes.\nEnsure seamless integration between Procurement, Finance, and SD modules, as well as with other SAP Cloud modules (e.g., EWM, PP) and third-party applications where applicable.\nLeverage SAP Activate methodology for project delivery, guiding clients through fit-to-standard workshops and solution design.\nFunctional Expertise:\nProcurement (MM): Expertise in Material Master, Vendor Master, Purchase Requisitions, Purchase Orders, Contracts, Sourcing, Inventory Management, Invoice Verification, and supplier collaboration.\nFinance (FI/CO): Strong knowledge of General Ledger, Accounts Payable, Accounts Receivable, Asset Accounting, Bank Accounting, Cost Center Accounting, Profit Center Accounting, Internal Orders, Product Costing, Profitability Analysis (CO-PA), and treasury functions. Understanding of the Universal Journal (ACDOCA) and its impact.\nSales & Distribution (SD): Proficiency in Sales Order Management, Pricing, Delivery Processing, Billing, Credit Management, Returns Management, and ATP (Available-to-Promise).\nTechnical Acumen (Public Cloud Specific):\nUnderstanding of SAP S/4HANA Public Cloud architecture, standard scope, extensibility options (e.g., in-app extensibility, side-by-side extensions using SAP BTP).\nFamiliarity with SAP Fiori applications and user interfaces for relevant modules.\nKnowledge of data migration strategies and tools within the Public Cloud environment (e.g., Migration Cockpit).\nExperience with SAP Cloud ALM for implementation, operations, and monitoring.\nClient Engagement & Leadership:\nAct as a trusted advisor to clients, effectively communicating complex technical and functional concepts to both business and IT stakeholders.\nLead workshops, facilitate discussions, and drive decisions throughout the project lifecycle.\nProvide expert guidance on cloud transformation strategies, change management, and user adoption.\nMentor and guide junior consultants, fostering a culture of knowledge sharing and continuous improvement.\nTesting, Training & Support:\nDevelop and execute comprehensive test plans (unit, integration, UAT) to ensure the solution meets business requirements and is defect-free.\nPrepare detailed training materials and conduct engaging training sessions for end-users.\nProvide post-implementation support, troubleshoot issues, and drive resolution in collaboration with technical teams.\nContinuous Improvement & Innovation:\nStay updated with the latest SAP S/4HANA Public Cloud releases, functionalities, and industry best practices.\nIdentify opportunities for process optimization and leverage new SAP innovations (e.g., AI, Machine Learning capabilities within S/4HANA) to enhance client value.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Sap Hana', 'Solution Design', 'SAP FICO', 'SAP SD', 'SAP MM', 'SAP Finance']",2025-06-12 06:38:21
Hiring FCT Mentor( Education Loan Team Leader)-Shiksha.com,Info Edge,3 - 7 years,Not Disclosed,['Noida'],"About Info Edge\nInfoEdges mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['Education Loan', 'Client Management', 'Team Handling', 'sales orientation', 'account manager', 'overseas education', 'study abroad', 'loan counsellor']",2025-06-12 06:38:24
"Sr. QA Engineer, AI",Conga,5 - 8 years,Not Disclosed,"['Pune', 'Ahmedabad', 'Bengaluru']","Job Title: Sr. QA Engineer\nLocations: Ahmedabad/ Bangalore/ Pune\nReports to: Manager, Quality Engineering\n\nA quick snapshot\n\nAs Senior QA Engineer your responsibilities will include designing and implementing tests, debugging, and defining corrective actions. You will also review system requirements and track quality assurance metrics. These tests entail other tasks such as developing and running new tests and reporting their results to stakeholders, who will collaborate to fix program bugs or problems. You will mentor juniors, collect daily updates, and circulate to managers/ higher forums making this role more important in the system.\n\nWhy its a big deal\n\nA Senior QA Engineer role has significance in the Testing Center of Excellence (TCoE) team at Conga, managing the production of test documents, the creation of test procedures, and ensuring high-quality products. Your expertise in agile methodology, and automation tools, will help in accelerating a continuous enhancement of our product features is a truly Big Deal in Conga Way. Your extensive contribution to scrum teams in the implementation of automation footprints with a Sprint/Release will bring a high-quality impact on Congas products. Your collaboration with cross-functional teams ensures the smooth running of the QA department and ultimately customer satisfaction.\n\nAre you the person were looking for?\n\nProven success in testing (Automation and Manual).Your experiences will include at least 5 years in test case planning, assessments, script development, and maintenance. You have hands-on experience with automation tools and frameworks and developing automation scripts.\n\nSelenium and API. You have expertise with automation tools such as Selenium web driver, frameworks, and developing automation scripts using Java. Strong hands-on experience with API approach using Rest Assured or any such client. Hands-on with test management software such as qTest, JIRA, Jmeter, Load Runner.\n\nAI Technology. You have experience in Large Language model, machine learning experience, AI Git knowledge for Advance Automation as well as familiar with AI Microsoft CoPilot. Candidate should be aware with attorney use cases for variety of documents\n\nAgile Methodology. You are proficient with Agile and a collaborative cross-functional approach to building awesome software. You are comfortable working with teams and collaborating on best practices across multiple Agile teams. You constantly seek opinions and solicit feedback to create the best work possible. You dont know any other way. Its a team effort and you completely appreciate that. Strong experience in software testing lifecycle (STLC) and knowledge of software development lifecycle (SDLC).\n\nEducation. A bachelors degree in engineering or equivalent.\n\nHere’s what will give you an edge\n\nStrong attention to detail. The Conga revenue lifecycle management solution showcases a wide variety of use cases, across multiple regions and languages. As a senior QA paying attention to the smallest details can help identify bugs that others might miss.\n\nStrong testing skills and logic based thinking is your forte. This is an absolute must. Your proven ability to analyze and apply logical thinking to determine the root cause of an issue is fundamental to success in this role. You can easily understand how systems interact/integrate with each other and as well as how changes in one application will affect others.\n\nInitiative. As a Senior QA, we need to own and initiate multiple things to make the quality better. Functional aspects, Non-functional aspects, Broader thinking, Integration approach, Reuse approach in Automation, Performance, Security, Database testing, and a lot more.\n\nAwareness. This role should be aware of the company vision, Goals, and Requirements, and work towards that direction to deliver quality so participation in multiple forums makes it more vital.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['copilot', 'Rest Assured', 'Playwright', 'Selenium With Java']",2025-06-12 06:38:27
Job opening For Data Warehouse + ADF + ETL,bct,3 - 6 years,Not Disclosed,['Pune'],"Greetings of the Day !!!\n\nWe have job opening for Data Warehouse + ADF + ETL with one of our Client .If you are interested for this role , kindly share update resume along with below details in this email id : shaswati.m@bct-consulting.com\n\nJob Description:\nSenior Data Engineer\nAs a Senior Data Engineer, you will support the European World Area using the Windows & Azure suite of Analytics & Data platforms. The focus of the role is on the technical aspects and implementation of data gathering, integration and database design.\nWe look forward to seeing your application!\nIn This Role, Your Responsibilities Will Be:\nData Ingestion and Integration: Collaborate with Product Owners and analysts to understand data requirements & design, develop, and maintain data pipelines for ingesting, transforming, and integrating data from various sources into Azure Data Services.\nMigration of existing ETL packages: Migrate existing SSIS packages to Synapse pipelines\nData Modelling: Assist in designing and implementing data models, data warehouses, and databases in Azure Synapse Analytics, Azure Data Lake Storage, and other Azure services.\nData Transformation: Develop ETL (Extract, Transform, Load) processes using SQL Server Integration Services (SSIS), Azure Synapse Pipelines, or other relevant tools to prepare data for analysis and reporting.\nData Quality and Governance: Implement data quality checks and data governance practices to ensure the accuracy, consistency, and security of data assets.\nMonitoring and Optimization: Monitor and optimize data pipelines and workflows for performance, scalability, and cost efficiency.\nDocumentation: Maintain comprehensive documentation of processes, including data lineage, data dictionaries, and pipeline schedules.\nCollaboration: Work closely with cross-functional teams, including data analysts, data scientists, and business stakeholders, to understand their data needs and deliver solutions accordingly.\nAzure Services: Stay updated on Azure data services and best practices to recommend and implement improvements in our data architecture and processes\nFor This Role, You Will Need:\n3-5 years of experience in Data Warehousing with On-Premises or Cloud technologies\nStrong practical experience of Synapse pipelines / ADF.\nStrong practical experience of developing ETL packages using SSIS.\nStrong practical experience with T-SQL or any variant from other RDBMS.\nGraduate degree educated in computer science or a relevant subject.\nStrong analytical and problem-solving skills.\nStrong communication skills in dealing with internal customers from a range of functional areas.\nWillingness to work flexible working hours according to project requirements.\nTechnical documentation skills.\nFluent in English.\nPreferred Qualifications that Set You Apart:\nOracle PL/SQL.\nExperience in working on Azure Services like Azure Synapse Analytics, Azure Data Lake.\nWorking experience with Azure DevOps paired with knowledge of Agile and/or Scrum methods of delivery.\nLanguages: French, Italian, or Spanish would be an advantage.\nAgile certification.\nThanks,\nShaswati",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['ADF', 'ETL', 'SSIS', 'Data ware house']",2025-06-12 06:38:29
Data Governance & Data Quality Sr Associate Analyst,Amgen Inc,2 - 5 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\nRole Description:\nYou will play a key role in the implementation and adoption of the data governance framework which will modernize Amgen's data ecosystem, positioning Amgen as a leader in biopharma innovation. This role leveragesstate-of-the-art technologies, including Generative AI, Machine Learning, and integrated data. This role involves working closely with business stakeholder and data analysts to ensure implementation and adoption of the data governance framework. You will collaborate with Data Product Owners, Data Stewards and technology teams to increase the trust and reuse of data across Amgen.\nRoles & Responsibilities:\nResponsible for the execution of data governance framework for a given domain of expertise (Research, Development, Supply Chain, etc.).\nContribute to the operationalization of the Enterprise data governance framework and aligning broader stakeholder community with their data governance needs, including data quality, data access controls, compliance with privacy and security regulations, foundational master data management, data sharing, communication and change management.\nWorks with Enterprise MDM and Reference Data to enforce standards and data reusability.\nContribute to the cross functional alignment in his/her domain(s) of expertise to ensure adherence to Data Governance principles.\nMaintain documentation on data definitions, data standards, data flows, legacy data structures / hierarchies, common data models, data harmonization etc. for assigned domains.\nPartner with business teams to identify compliance requirements with data privacy, security, and regulatory policies for the assigned domains\nJointly with Technology teams, business functions, and enterprise teams (e.g., MDM, Enterprise Data Fabric, etc.) delivers data foundations.\nBuild strong relationship with key business leads and partners to ensure their needs are met.\nFunctional Skills:\nMust-Have Functional Skills:\nTechnical skills (Advanced SQL, Python etc) with knowledge of Pharma processes with specialization in a domain (e.g., Research, Clinical Trials, Commercial, etc.)\nExperience of working with or supporting systems used to data governance framework. E.g. Collibra, Alation\nGeneral knowledge of data management, common data models, metadata management, data quality, master data management, data stewardship, data protection, etc.\nExperience with data products development life cycle, including the enablement of data dictionaries, business glossary to increase data products reusability and data literacy.\nCustomer focused with excellent written and verbal communication skills who can confidently work with internal Amgen business stakeholders and external service partners on business process and technology topics\nExcellent problem-solving skills and a committed attention to detail in finding solutions\nGood-to-Have Functional Skills:\nExperience with Agile software development methodologies (Scrum)\nSoft Skills:\nExcellent analytical skills\nAbility to work effectively with global, virtual teams\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nAbility to build business relationships and understand end-to-end data use and needs.\nStrong verbal and written communication skills\nBasic Qualifications:\nExperience with 5 - 9 years of experience in Business, Engineering, IT or related field",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Governance', 'data quality', 'Collibra', 'data stewardship', 'metadata management', 'Agile software development methodologies', 'Alation', 'data protection', 'master data management', 'SQL', 'Python']",2025-06-12 06:38:31
Jr.AI Engineer,Tekone It Services,1 - 3 years,1.5-6.5 Lacs P.A.,['Hyderabad'],"Position Overview\nWe are hiring five AI Engineers with 12 years of experience to join our dynamic team in Hyderabad. The ideal candidates will have a solid foundation in Large Language Models (LLMs), LangChain, and Generative AI (GenAI) frameworks. This is a great opportunity to work on innovative AI solutions, contributing to projects that integrate LLMs, prompt engineering, RAG pipelines, and cloud-based deployments.\nKey Responsibilities\nContribute to the design and development of AI-powered applications utilizing LLMs (GPT-3.5, GPT-4, Gemini).\nAssist in building LangChain-based pipelines and workflows, including LangSmith and LangGraph.\nSupport the implementation of Retrieval-Augmented Generation (RAG) frameworks using vector databases such as ChromaDB.\nApply prompt engineering techniques to optimize model responses and improve contextual accuracy.\nDevelop RESTful APIs using Flask or FastAPI to enable model consumption in production environments.\nWrite and manage data workflows using SQL, PySpark, and Spark SQL.\nDeploy and monitor models on Azure Machine Learning or AWS Bedrock platforms.\nCollaborate with cross-functional teams, including data scientists, engineers, and business stakeholders.\nRequired Skills\nProficiency in Python, SQL, PySpark, and Spark SQL\nHands-on experience with LLMs: GPT-3.5, GPT-4, Gemini\nKnowledge of LangChain, LangSmith, LangGraph\nFamiliarity with Vector Databases (e.g., ChromaDB) and embeddings\nExperience with prompt engineering and RAG-based architectures\nExposure to cloud platforms such as Azure ML or AWS Bedrock\nStrong understanding of REST APIs and version control systems (Git/GitHub)\nPreferred Qualifications\nBachelor's degree in Computer Science, Artificial Intelligence, Data Science, or a related field\nInternship or academic project experience in NLP, LLMs, or GenAI technologies\nFamiliarity with MLOps tools and practices (e.g., CI/CD, Airflow)\nStrong problem-solving abilities, attention to detail, and a collaborative mindset",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'Prompt Engineering', 'Artificial Intelligence', 'llm']",2025-06-12 06:38:34
Python Developer @ Infosys- Pan India,Infosys,4 - 9 years,Not Disclosed,"['Pune', 'Delhi / NCR', 'Mumbai (All Areas)']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills: Process->Testing processes->Test Automation Process, Technology->Machine Learning->Python\n\nPreferred Skills: Process->Testing processes->Test Automation Process Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational Requirements MCA,MSc,MTech,Bachelor of Engineering,BCA,BE,BSc,BTech",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Python Development', 'Flask']",2025-06-12 06:38:36
Applied AI Engineer,Xenonstack,3 - 5 years,Not Disclosed,['Mohali'],"XenonStack's Artificial Intelligence team is looking for a Machine Learning (ML) Engineer to help us create artificial intelligence products. Machine Learning Engineer responsibilities include creating machine learning models and retraining systems. To do this job successfully, you need exceptional skills in statistics and programming. Your goal will be to shape and build efficient self-learning applications.\n\n\nKey Responsibilities:\nStudy and transform data science prototypes\nDesign machine learning systems\nResearch and implement appropriate ML algorithms and tools\nDevelop machine learning applications according to requirements\nSelect relevant datasets and data representation methods\nRun machine learning tests and experiments\nPerform statistical analysis and fine-tuning using test results\nTrain and retrain systems when necessary\nExtend existing ML libraries and frameworks\nKeep abreast of developments in the field\n\nRequirements\nTechnical Requirement:\n\nKnowledge in Machine Learning Engineer or similar role\nUnderstanding of data structures, data modelling, and software architecture\nDeep knowledge of maths, probability, statistics, and algorithms\nAbility to write robust code in Python, Java, and R\nFamiliarity with machine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn)\n\nProfessional Attributes:\nExcellent communication skills & Attention to detail.\nAnalytical mind and problem-solving Aptitude with Strong Organizational skills & Visual Thinking.\nEducation: Technical Graduates (BCA, BSC, B. Tech), MCA, MSC, and M.Tech with strong data structure and algorithm Skills \n\nBenefits:\nDynamic and purposeful work culture in a people-oriented organization contributing to multi-million-dollar projects with guaranteed job security.\nOpen, authentic, and transparent communication fostering a warm work environment.\nRegular constructive feedback and exposure to diverse technologies.\nRecognition and rewards for exceptional performance achievements.\nAccess to certification courses & Skill Sessions to develop continually and refine your skills.\nAdditional allowances for team members assigned to specific projects.\nSpecial skill allowances to acknowledge and compensate for unique expertise.\nComprehensive medical insurance policy for your health and well-being.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Programming', 'Machine Learning', 'Tensorflow', 'Algorithm Development', 'Cnn', 'Natural Language Processing', 'Neural Networks', 'Deep Learning', 'Cuda', 'Pytorch', 'Pattern Recognition', 'Rnn', 'Image Processing', 'Keras', 'Data Processing', 'Computer Vision', 'Python']",2025-06-12 06:38:39
Chat Bot Developer,Capgemini,2 - 7 years,Not Disclosed,"['Hyderabad', 'Pune', 'Chennai']","Key Responsibilities:\nDesign and develop chatbot solutions using platforms like Dialogflow, Microsoft Bot Framework, Rasa, or similar.\nIntegrate chatbots with messaging platforms (e.g., WhatsApp, Facebook Messenger, Slack, web chat).\nImplement NLP and machine learning techniques to improve chatbot understanding and responses.\nCollaborate with UX/UI designers to create engaging conversational flows.\nConnect chatbots to backend systems, APIs, and databases.\nMonitor chatbot performance and continuously improve based on analytics and user feedback.\nEnsure security, scalability, and reliability of chatbot solutions.\nRequired Skills:\nProficiency in programming languages such as Python, JavaScript, or Node.js.\nExperience with chatbot development platforms (Dialogflow, Rasa, IBM Watson, etc.).\nUnderstanding of NLP concepts and tools (spaCy, NLTK, BERT, etc.).\nFamiliarity with RESTful APIs and webhook integration.\nKnowledge of cloud platforms (AWS, Azure, GCP) is a plus.\nStrong problem-solving and communication skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Bot', 'Chatbot Development', 'Chatbot']",2025-06-12 06:38:41
Computer Vision Engineer,Agelix Consulting,2 - 5 years,5-10 Lacs P.A.,['Noida'],"Role & responsibilities\n\nDeep understanding of computer vision principles, best practices, image processing techniques, and machine learning algorithms.\nExperience in developing and implementing machine vision systems, preferably in the Railroad, Airport, Heavy engineering, and Utilities business domains.\nProficiency in programming languages such as Python, and experience with relevant libraries and frameworks (e.g., TensorFlow, PyTorch).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Tensorflow', 'Pytorch', 'Computer Vision', 'Deep Learning']",2025-06-12 06:38:43
Tech Education Engineer ( AI & Robotics ),"Delhi Public School, Indirapuram",3 - 8 years,Not Disclosed,['Ghaziabad( Indirapuram )'],"Job Overview:\nWere seeking a technically strong Curriculum Developer who can bridge the gap\nbetween technology and student-ready learning experiences. Your job is to ensure technical\nintegrity and industry alignment across the curriculum for Robotics, AI, and IoT. Youll help\nensure our programs remain relevant, scalable, and future-proof.\n\nKey Responsibilities:\n• Research and vet tools, sensors, microcontrollers, platforms, and programming\nlanguages used in industry and education.\n• Co-design curriculum content while ensuring technical accuracy and industry\napplicability.\n• Identify trends in AI, robotics, embedded systems, and translate them into teachable\nmodules.\n• Design projects that simulate real-world industry applications of skills (AI models,\nedge computing, automation).\n• Test hardware and software tools in use with the curriculum, ensuring feasibility and\nscalability.\n\nRequired Skills & Qualifications:\n• Have a background in Engineering, Computer Science, or a related tech domain.\n• Can explain why certain tools matter in the tech world and how to teach them.\n• Are fluent in Python/C++, ML frameworks (Keras, PyTorch), and microcontroller\nprogramming.\n• Have industry experience or deep project experience with robotics, embedded AI, or\nhardware integration.\n• Can support the team with training content, walkthroughs, and tool testing.\n\nInterested candidates may send their updated CV at hr@dpsindirapuram.com",Industry Type: Education / Training,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Curriculum Designing', 'Robotics', 'Curriculum Development']",2025-06-12 06:38:45
Ai Ml Engineer,Compunnel,4 - 9 years,Not Disclosed,"['Noida', 'Chandigarh']","Company: Compunnel INC\nJob Location: Noida/Chandigarh\nExperience Required: 4+ years\nMode of Work: 5 days work from the office\nJob Title: AI /ML Engineer\n\nWe are seeking a talented and innovative Generative AI Engineer to join our team. The ideal candidate will have expertise in training and testing large language models (LLMs) for applications like speech-to-text and text-to-speech, with a focus on the Hindi language. This role requires proficiency in cutting-edge AI technologies, including transformers, GPU acceleration, and CUDA, along with strong Python programming skills.\n\nKey Responsibilities:\nDesign, train, and fine-tune LLMs for speech-to-text and text-to-speech applications in Hindi.\nDevelop and optimize transformer-based architectures for natural language processing (NLP) tasks.\nLeverage GPU acceleration and CUDA for efficient model training and deployment.\nPre process and manage large datasets to ensure high-quality data for model training.\nCollaborate with cross-functional teams to integrate AI models into production systems.\nConduct rigorous testing and evaluation of models to ensure accuracy, efficiency, and scalability.\nStay updated with the latest advancements in generative AI and NLP technologies.\n\nRequired Skills and Qualifications:\nProficiency in Python and experience with deep learning frameworks like TensorFlow or PyTorch.\nStrong understanding of transformer architectures (e.g., BERT, GPT, T5).\nHands-on experience with GPU acceleration and CUDA programming.\nFamiliarity with Hindi language processing, including phonetics, grammar, and linguistic nuances.\nExperience in developing and deploying speech-to-text and text-to-speech systems.\nKnowledge of data preprocessing techniques for audio and text datasets.\nStrong problem-solving skills and ability to work in a collaborative environment.\n\nPreferred Qualifications:\nExperience with tools like Hugging Face Transformers, Kaldi, or Mozilla Deep Speech.\nFamiliarity with cloud platforms (e.g., AWS, Azure, or Google Cloud) for AI model deployment.\nUnderstanding of end-to-end speech recognition and synthesis pipelines.\nA background in linguistics or computational linguistics is a plus.\n\nPlease fill in all the essential details which are given below & attach your updated resume, and send it to ralish.sharma@compunnel.com\n1. Total Experience:\n2. Relevant Experience in Python :\n3. Experience in Pytorch :\n4. Experience in Tensorflow:\n5. Experience in LLM :\n6. Experience in RAG :\n7. Experience in NLP :\n8. Experience in GPT :\n9. Experience in Bert:\n10 . Experience in CUDA :\n11. Current company :\n12. Current Designation :\n13. Highest Education :\n14. Notice Period:\n15. Current CTC:\n16. Expected CTC:\n17. Current Location:\n18. Preferred Location:\n19. Hometown:\n20. Contact No:\n21. If you have any offer from some other company, please mention the Offer amount and Offer Location:\n22. Reason for looking for change:\n\nIf the job description is suitable for you, please get in touch with me at the number below: 9910044363.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pytorch', 'Tensorflow', 'Bert', 'LLM', 'Python', 'NLP', 'RAG', 'Cuda']",2025-06-12 06:38:48
AI/ML Engineer,Oak Tree Cloud Software,3 - 5 years,Not Disclosed,['Indore'],"Job Title: Python Developer AI/ML & Generative AI\nExperience: 3+ Years\nLocation: Indore (WFO)\nEmployment Type: Full-Time\nIndustry: AI / Technology / Software Development\n\nJob Description\nWe are seeking a skilled Python Developer with 3+ years of hands-on experience in Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL) and Generative AI (GenAI). The ideal candidate will be passionate about building intelligent systems and creating real-world applications using modern AI tools and frameworks.\n\nKey Responsibilities:\nDevelop and deploy AI/ML models using Python for real-world use cases including classification, regression, clustering, NLP, and computer vision.\nDesign and fine-tune Generative AI models, including transformers, large language models (LLMs), and text-to-image/audio tools.\nImplement data preprocessing pipelines, feature engineering, and model evaluation metrics.\nCollaborate with cross-functional teams (data scientists, backend developers, and product managers) to integrate models into applications or APIs.\nOptimize and scale ML/AI pipelines for performance and accuracy using techniques like model compression or distributed training.\nWork with GenAI frameworks/tools such as Hugging Face Transformers, LangChain, OpenAI API, or LLaMA.\nPerform research and experimentation with state-of-the-art models and suggest improvements for production use.\nMaintain clear documentation for models, datasets, experiments, and deployment procedures.\nRequired Skills & Qualifications:\nStrong proficiency in Python with focus on data structures, OOPs, and libraries like NumPy, Pandas, Scikit-learn, and Matplotlib.\nExperience with AI/ML frameworks such as TensorFlow, PyTorch, or Keras.\nPractical knowledge of Gen AI tools, including Hugging Face Transformers, OpenAI GPT models, or LLM fine-tuning.\nUnderstanding of ML lifecycle, from data cleaning to model deployment and monitoring.\nDevelop and implement data extraction pipelines for unstructured documents using OCR techniques and libraries (e.g., Tesseract, EasyOCR) to extract text and structured data from PDFs (PyMuPDF), scanned images, and DOCX files.\nExperience with NLP techniques, text generation, summarization, or vector embeddings.\nHands-on experience with REST APIs, FastAPI or Flask to deploy and serve models.\nFamiliarity with version control (Git), CI/CD pipelines, and containerization (Docker).\nBachelor's/Master’s in Computer Science, Artificial Intelligence, Data Science, or related field.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'Machine Learning', 'Deep Learning', 'Python']",2025-06-12 06:38:50
Manager - Software Development,Amway,8 - 12 years,Not Disclosed,['Hyderabad'],"Primary Responsibilities\nCloud Expertise: Familiarity or hands-on experience with AWS and Google Cloud Platform (GCP) technologies to support data transformation, data structures, metadata management, dependency tracking, and workload orchestration.\nCollaboration & Independence: Self-motivated and capable of supporting the data needs of multiple teams, systems, and products within Amways data ecosystem.\nBig Data & Distributed Systems: Strong understanding of distributed systems for large-scale data processing and analytics, with a proven track record of manipulating, processing, and deriving insights from large, complex, and disconnected datasets.",,,,"['Data Transformation', 'GCP', 'Cloud', 'AWS']",2025-06-12 06:38:53
"Technical Training Specialist, Staff",Qualcomm,6 - 11 years,Not Disclosed,['Gurugram'],"Job Area: Engineering Services Group, Engineering Services Group > Technical Training\n \n\nQualcomm Overview: \nQualcomm is a company of inventors that unlocked 5G ushering in an age of rapid acceleration in connectivity and new possibilities that will transform industries, create jobs, and enrich lives. But this is just the beginning. It takes inventive minds with diverse skills, backgrounds, and cultures to transform 5Gs potential into world-changing technologies and products. This is the Invention Age - and this is where you come in.\n\nGeneral Summary:\n\nJob TitleTechnical Training Specialist, Staff\n\nJob Overview:\n\nIn collaboration with subject matter experts, develop high-quality technical training materials for use in training courses geared towards engineers and business professionals, with keen attention to quality and engaging learning experience.\n\nJob Overview:\n\nThe primary responsibility of this role is to teach AI courses, with a strong emphasis on AI-related Qualcomm technologies. In collaboration with subject matter experts, you will develop and deliver high-quality technical training materials for engineers and business professionals, ensuring an engaging and effective learning experience.\n\nAdditional :\n\nKnowledge and\n\nSkills:\n\nDemonstrated proficiency in designing, developing, and delivering a variety of technical training programs, with a strong focus on AI and AI-related Qualcomm technologies, for a technical workforce encompassing engineering, business, IT, and other technical professionals.\nRobust practical knowledge of Instructional Design Methodologies and Adult Learning Theory, particularly as they apply to AI and advanced technology training.\nExcellent written and verbal communication skills in English, with the ability to convey complex AI concepts and Qualcomm technologies clearly and effectively.\nUncompromising approach towards content quality, accuracy, and effectiveness, ensuring that training materials are both informative and engaging.\nDemonstrable prior leadership experienceproven track record to successfully lead a team and drive a variety of projects to completion in a dynamic work environment.\nSuperb organizational skills, with the ability to prioritize and manage multiple simultaneous tasks in a systematic, process-oriented manner.\nAbility to work with and gain a deep understanding of highly technical content spanning multiple domains such as 5G, Artificial Intelligence, Extended Reality, etc.\nExperience in developing and managing self-paced online training using tools like Adobe Captivate and Camtasia is a plus.\n\n\nPreferred Qualifications:\nMasters degree in Educational Technology, Instructional Design, or related fields.\n6+ years of relevant experience, preferably in the technology industry.\n\n\nA degree in engineering/technology fields is a must.\n\n\nAdditional Skills & Qualifications:\nPrior experience or ability to work with a variety of AI tools applicable to learning environments, with a focus on Qualcomm technologies.\nWillingness and ability to be available for online work meetings according to US time zones.\nAbility to provide prior work samples is a plus.\n\nIf you are a self-driven leader who excels in a collaborative environment and has a consultative, customer service orientation, we want to hear from you.",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['hiring', 'artificial intelligence', 'camtasia', 'staffing', 'online tutoring', 'technical writing', 'head hunting', 'leadership hiring', 'screening', 'framemaker', 'sourcing', 'technical hiring', 'talent acquisition', 'it recruitment', 'technical recruitment', 'recruitment', 'lateral hiring']",2025-06-12 06:38:55
AI Engineer Consultant,Cosentia Solutions Pvt. Ltd.,7 - 12 years,8-18 Lacs P.A.,['Pune'],"Job Title: AI Engineer Consultant\n\nKey Responsibilities:\n\nWe are seeking a highly skilled and experienced AI Engineer Consultant to join our Business Development (BD) team and provide Subject Matter Expertise (SME) in Artificial Intelligence.\nThe ideal candidate will have at least 7 years of experience in AI development and deployment, along with the ability to bridge technical expertise and business requirements.\n\nThis role requires an individual who can help shape business solutions by collaborating with cross-functional teams, understanding market needs, and translating them into scalable, technical AI solutions.\n\nConsulting Expertise: Provide AI/ML subject matter expertise to the BD team, helping to define and refine business requirements and solutions that align with client needs.\nTechnical Leadership: Lead the development and implementation of AI models, algorithms, and frameworks, ensuring they meet business objectives and technical feasibility.\nCollaborative Solution Design: Work closely with both technical and non-technical stakeholders to translate business goals into actionable AI solutions. Help refine technical specifications based on client and internal feedback.\nClient Interaction: Act as a technical advisor during client discussions, helping explain complex AI concepts in a clear, accessible manner.\nBusiness Requirements Gathering: Collaborate with the BD team to gather and prioritize business requirements, turning them into scalable AI solutions that can be effectively marketed and deployed.\nProposal Support: Provide support in crafting proposals, RFP responses, and project documentation that reflect a deep understanding of AI technologies and their business applications.\nQualifications:\n\nExperience: At least 7 years of hands-on experience in AI, machine learning, and data science, with a strong portfolio of successful projects in these domains.\nTechnical Skills: Expertise in AI/ML algorithms, programming languages (Python, R, Java, etc.), data analysis tools, and frameworks (TensorFlow, PyTorch, Scikit-learn, etc.).\nBusiness Acumen: Strong ability to translate complex technical information into clear business requirements and solutions. Experience in client-facing roles is a plus.\nProblem-Solving: Ability to quickly analyze problems and design practical, cost-effective AI solutions.\nCommunication Skills: Excellent communication skills, both written and verbal. Experience explaining complex AI concepts to non-technical stakeholders and decision-makers.\nConsulting Experience: Previous experience working in a consulting or advisory role, especially in helping businesses adopt AI-driven solutions.\nDesirable Skills:\n\nExperience with AI applications in industries such as healthcare, finance, or retail.\nFamiliarity with cloud platforms (AWS, Google Cloud, Azure) and deployment of AI solutions in cloud environments.\nAdvanced degree (MS, PhD) in AI, Machine Learning, Data Science, or related fields is a plus.\n\nThis is an exciting opportunity for a results-driven professional. If you have a passion, we encourage you to apply.\n\nApply Now: Drop your resume on 8308907577 or kmaran@sevenmentor.com.\nReferences are highly appreciated!",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['AI', 'Tensorflow', 'Java', 'Machine Learning', 'Scikit-Learn', 'Data Science', 'Pytorch', 'Healthcare Domain', 'R', 'Azure Cloud', 'Aiml', 'Microsoft Azure', 'AWS', 'Ml', 'Python']",2025-06-12 06:38:58
Spark Scala + AWS & SQL,Cognizant,10 - 12 years,Not Disclosed,['Chennai'],Job Summary\nAs a Technical Lead specializing in Generative AI and Python you will play a pivotal role in driving innovation and excellence within our team. With 10 to 12 years of experience you will leverage your expertise to develop cutting-edge solutions that align with our companys strategic goals. This office-based position offers the opportunity to work in a dynamic environment during day shifts contributing to impactful projects that enhance our technological capabilities.,,,,"['algorithms', 'python', 'data analysis', 'technical leadership', 'software development', 'workflow', 'scala', 'machine learning', 'hibernate', 'artificial intelligence', 'scalability', 'sql', 'microservices', 'spring', 'spring boot', 'security', 'java', 'spark', 'ai techniques', 'j2ee', 'agile', 'aws', 'programming', 'agile methodology']",2025-06-12 06:39:00
AIML Security Risk Assessment Specialist - Information Security,Hdfc Bank,7 - 12 years,Not Disclosed,['Mumbai (All Areas)'],"Job Summary\nThe AIML Security Risk Assessment Specialist will play a critical role in validating reports and making final risk assessments for AIML models used in various business applications and use cases. This role will work closely with the Digital Risk Management Portfolio team to ensure the security and integrity of AIML models, use case along with applications.\nKey Responsibilities\n1. Risk Assessment: understand the business requirement, finalise the scope and perform end to end risk assessment.",,,,"['Generative Ai', 'Cyber Security', 'Information Security']",2025-06-12 06:39:03
Ai Ml Engineer,Openeyes Software Solutions,8 - 10 years,Not Disclosed,['Vadodara'],"Location : Vadodara (Onsite only)\n\nJob Summary:\nWe are looking for a highly skilled and experienced AI/ML Engineer with 8 to 10 years of relevant experience in developing end-to-end machine learning solutions. The ideal candidate will be well-versed in deep learning, natural language processing (NLP), computer vision, and large language models (LLMs). You will be responsible for designing, developing, and deploying scalable AI models tailored to real-world business use cases.\n\nKey Responsibilities:\n\nDesign, train, evaluate, and deploy machine learning and deep learning models aligned with business goals.\nWork with various ML tasks such as classification, regression, and clustering.\nHandle NLP, LLMs, computer vision, and speech-to-text use cases.\nImplement and fine-tune models like LLaMA, Falcon, BERT, T5 Transformer, and Hugging Face models.\nUse libraries such as NumPy, Pandas, Matplotlib, SpaCy, Scikit-learn, TensorFlow, and PyTorch.\nWrite clean, efficient Python code for data processing and model development.\nUtilize tools like Google Colab, Jupyter Notebook, and AWS SageMaker for experimentation and deployment.\nMonitor data drift and automate model retraining pipelines as required.\nDeploy AI models on cloud infrastructure (preferably AWS) using services like SageMaker, EC2, ECS, and Kubernetes.\nCollaborate with cross-functional teams to translate complex problems into AI solutions.\nGood to Have:\n\nExperience working with LangChain or LLaMAIndex.\nFamiliarity with RAG-based (Retrieval-Augmented Generation) application development.\nHands-on experience with Google Cloud Platform (GCP) for model deployment.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Natural Language Processing', 'Machine Learning', 'Deep Learning', 'Python', 'Communication Skills', 'Artificial Intelligence', 'Pandas', 'Problem Solving', 'Aws Sagemaker', 'Numpy']",2025-06-12 06:39:05
Java Engineer (Senior),Agileengine,4 - 8 years,Not Disclosed,[],"What you will do\nBe part of a small team developing multi-cloud platform services;\nBuild and maintain automation frameworks to execute developer-written tests in private and public cloud environments;\nOptimize code, ensure best coding practices are followed, and support the existing team in overcoming technical challenges;\nMonitor and support service providers using the app in the field.\n\nMust haves\n5+ years of experience in web development in similar environments;\nBachelors degree in Computer Science, Information Security, or a related technology field;\nStrong knowledge of Java 8 and 17, Spring, and Spring Boot;\nExperience with microservices and events;\nGreat experience and passion for creating documentation for code and business processes;\nExpertise in architectural design and code review, with a strong grasp of SOLID principles;\nSkilled in gathering and analyzing complex requirements and business processes;\nContribute to the development of our internal tools and reusable architecture;\nExperience creating optimized code and performance improvement for production systems and applications;\nExperience debugging, refactoring applications, and replicating scenarios to solve issues and understand the business;\nFamiliarity with unit and system testing frameworks (e.g., JUnit, Mockito);\nProficient in using Git;\nDedicated: own the apps you and your team are developing and take quality very seriously;\nProblem Solving: proactively solve problems before they can become real problems;\nConstantly upgrading your skill set and applying those practices;\nUpper-Intermediate English level.\n\nNice to haves\nExperience with Test Driven Development;\nExperience with logistics software (delivery, transportation, route planning), RSA domain;\nExperience with AWS, like ECS, SNS, SQS, and RedShift.\n\nAbout us\nAgileEngine delivers top software solutions to Fortune 500 and Global 500 companies.\nWe’re a certified Google Cloud Partner, featured on the Inc. 5000 list of fastest-growing US companies 5 years in a row, and recognized as a Top Machine Learning Company by Clutch.\nJoin us to work with top talent on impactful projects across 17+ industries.\nThere’s no better place to grow — guaranteed! :)\n\nThe benefits of joining us\nRemote work & Local connection: Work where you feel most productive and connect with your team in periodic meet-ups to strengthen your network and connect with other top experts.\nLegal presence in India: We ensure full local compliance with a structured, secure work environment tailored to Indian regulations.\nCompetitive Compensation in INR: Fair compensation in INR with dedicated budgets for your personal growth, education, and wellness.\nInnovative Projects: Leverage the latest tech and create cutting-edge solutions for world-recognized clients and the hottest startups.\n\nNext Steps After You Apply\nThe next steps of your journey will be shared via email within a few hours. Please check your inbox regularly and watch for updates from our Internal Applicant site, LaunchPod, which will guide you through the process.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Javascript', 'Java', 'GIT', 'Debugging', 'Spring Boot', 'Architectural Design', 'Code Review', 'Spring', 'Microservices']",2025-06-12 06:39:41
Senior High Performance Computing Engineer,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will.\nRole Description:\nThe role is responsible for the design, integration, and management of high performance computing (HPC) systems that encompass both hardware and software components into the organizations network infrastructure. This individual will be responsible for all activities related to handling and supporting the Business and platforms including system administration, as well as incorporating new technologies under the challenge of a sophisticated and constantly evolving technology landscape. This role involves ensuring that all parts of a system work together seamlessly to meet the organizations requirements.\nRoles & Responsibilities:\nImplement, and manage cloud-based infrastructure that supports HPC environments that support data science (e.g. AI/ML workflows, Image Analysis).\nCollaborate with data scientists and ML engineers to deploy scalable machine learning models into production.\nEnsure the security, scalability, and reliability of HPC systems in the cloud.\nOptimize cloud resources for cost-effective and efficient use.\nKeep abreast of the latest in cloud services and industry standard processes.\nProvide technical leadership and guidance in cloud and HPC systems management.\nDevelop and maintain CI/CD pipelines for deploying resources to multi-cloud environments.\nMonitor and fix cluster operations/applications and cloud environments.\nDocument system design and operational procedures.\nBasic Qualifications:\nMasters degree with a 4 - 6 years of experience in Computer Science, IT or related field with hands-on HPC administration OR\nBachelors degree with 6 - 8 years of experience in Computer Science, IT or related field with hands-on HPC administration OR\nDiploma with 10-12 years of experience in Computer Science, IT or related field with hands-on HPC administration\nDemonstrable experience in cloud computing (preferably AWS) and cloud architecture.\nExperience with containerization technologies (Singularity, Docker) and cloud-based HPC solutions.\nExperience with infrastructure-as-code (IaC) tools such as Terraform, CloudFormation, Packer, Ansible and Git.\nExpert with scripting (Python or Bash) and Linux/Unix system administration (preferably Red Hat or Ubuntu).\nProficiency with job scheduling and resource management tools (SLURM, PBS, LSF, etc.).\nKnowledge of storage architectures and distributed file systems (Lustre, GPFS, Ceph).\nUnderstanding of networking architecture and security best practices.\nPreferred Qualifications:\nExperience supporting research in healthcare life sciences.\nExperience with Kubernetes (EKS) and service mesh architectures.\nKnowledge of AWS Lambda and event-driven architectures.\nExposure to multi-cloud environments (Azure, GCP).\nFamiliarity with machine learning frameworks (TensorFlow, PyTorch) and data pipelines.\nCertifications in cloud architecture (AWS Certified Solutions Architect, Google Cloud Professional Cloud Architect, etc.).\nExperience in an Agile development environment.\nPrior work with distributed computing and big data technologies (Hadoop, Spark).\nProfessional Certifications (please mention if the certification is preferred or mandatory for the role):\nRed Hat Certified Engineer (RHCE) or Linux Professional Institute Certification (LPIC)\nAWS Certified Solutions Architect Associate or Professional\nSoft Skills:\nStrong analytical and problem-solving skills.\nAbility to work effectively with global, virtual teams\nEffective communication and collaboration with cross-functional teams.\nAbility to work in a fast-paced, cloud-first environment.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['cloud computing', 'resource management', 'Ubuntu', 'Unix system administration', 'linux', 'unix production support', 'Python']",2025-06-12 06:39:44
Senior High Performance Computing Engineer,Amgen Inc,6 - 8 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will be responsible for deploying, maintaining and supporting HPC infrastructure in a multi-cloud environment. Hands-on engineering which requires\n\ndeep technical expertise in HPC technology and standard methodologies.\nImplement, and manage cloud-based infrastructure that supports HPC environments that support data science (e.g. AI/ML workflows, Image Analysis).\nCollaborate with data scientists and ML engineers to deploy scalable machine learning models into production.\nEnsure the security, scalability, and reliability of HPC systems in the cloud.\nOptimize cloud resources for cost-effective and efficient use.\nStay ahead of with the latest in cloud services and industry standard processes.\nProvide technical leadership and guidance in cloud and HPC systems management.\nDevelop and maintain CI/CD pipelines for deploying resources to multi-cloud environments.\nMonitor and fix cluster operations/applications and cloud environments.\nDocument system design and operational procedures.\n\n\n\nMust-Have\n\nSkills:\nExpert with Linux/Unix system administration (RHEL, CentOS, Ubuntu, etc.).\nProficiency with job scheduling and resource management tools (SLURM, PBS, LSF, etc.).\nGood understanding of parallel computing, MPI, OpenMP, and GPU acceleration (CUDA, ROCm).\nKnowledge of storage architectures and distributed file systems (Lustre, GPFS, Ceph).\nExperience with containerization technologies (Singularity, Docker) and cloud-based HPC solutions.\nExpert in scripting languages (Python, Bash) and containerization technologies (Docker, Kubernetes).\nFamiliarity with automation tools (Ansible, Puppet, Chef) for system provisioning and maintenance.\nUnderstanding of networking protocols, high-speed interconnects, and security best practices.\nDemonstrable experience in cloud computing (AWS, Azure, GCP) and cloud architecture.\nExperience with infrastructure as code (IaC) tools like Terraform or CloudFormation and Git.\n\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. Expert knowledge in\n\nlarge Linux environments, networking, storage, and cloud related technologies. Also, the candidate will have\n\nexpertise in root-cause analysis and fix while working with a team and stakeholders.\n\nTop-level communication and documentation skills are required.\n\nExpertise in coding in\n\nPython, Bash, YAML is expected.\n\n\n\nGood-to-Have\n\nSkills:\nExperience with Kubernetes (EKS) and service mesh architectures.\nKnowledge of AWS Lambda and event-driven architectures.\nFamiliarity with AWS CDK, Ansible, or Packer for cloud automation.\nExposure to multi-cloud environments (Azure, GCP).\nBasic Qualifications:\nBachelors degree in computer science, IT, or related field with 6-8 years of hands-on HPC administration or a related field.\n\n\n\nProfessional Certifications (preferred):\nRed Hat Certified Engineer (RHCE) or Linux Professional Institute Certification (LPIC)\nAWS Certified Solutions Architect Associate or Professional\nPreferred Qualifications:\n\n\n\nSoft\n\nSkills:\nStrong analytical and problem-solving skills.\nAbility to work effectively with global, virtual teams\nEffective communication and collaboration with cross-functional teams.\nAbility to work in a fast-paced, cloud-first environment.\nShift Information: This position is required to be onsite and participate in 24/5 and weekend on call in rotation fashion and may require you to work a later shift. Candidates must be willing and able to work off hours, as required based on business requirements.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Performance Computing', 'python', 'cloud architecture', 'linux', 'bash', 'networking', 'linux internals', 'cloud computing', 'scripting languages']",2025-06-12 06:39:46
Media AdTech Specialist,Capgemini,5 - 10 years,Not Disclosed,['Kolkata'],"Provide ad operations and/or AdTech operations expertise\nExecute and help implement an AdTech compliance program\nStrong understanding of Programmatic Ad Eco system and Retail Media bidding advertisement.\nYouTube, Connected TV and Video Ads advertisement and hands on ad set up experience.\nDesign and implement advertising solutions tailored for retail media needs.\nBuild operational systems that enhances the productivity of our Ad Operations team\nCollaborate with other departments and stakeholders to identify and solve complex problems\nContinuously testing and improving software solutions to ensure optimal performance and user experience\nCreate and manage strong relationships with DSPs and other relevant players in the ad tech space that can help our clients achieve their objectives.\nSpearhead initiatives to refine and expand digital media services.\nCollaborate with a diverse team of experts to drive innovation. (data scientists, developers, engineers, clients and stakeholders).\nEnsure seamless integration and service delivery.\nApply the latest industry trends and best practices to achieve our clients outcomes\nStay abreast of media regulations and trends affecting digital advertising.\nBuild highly performant AdTech platforms that will support our future growth in the Ads Space\n\nQualifications:\n5 years experience in advertising operations (AdTech ops) and/or revenue operations (Revops).\nStrong understanding of DSPs, digital advertising ecosystems, ad networks, and/or advertising exchanges.\nDemonstrated excellence in client relationship management.\nDemonstrated ability to build and work across teams.\nExperience in Technical Solutions Architecture and design leadership.\nManage multiple projects and prioritize tasks effectively\nBroad knowledge across multiple technology areas Marketing Operation, Ecommerce Domain and Retail Media.\nStrong organizational skills and attention to detail.\nAbility to work independently and as part of a team.\n\nTools:\nFacebook Ads Manager, Pinterest Ad Manager, Instagram ads, DV360, Programmatic, Campaign Manager 360, Google Ad Manager, TTD\nPower-Bi, Excel, PowerPoint will be a plus point.\nYouTube, Videos, CTV related ad platforms.",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['DSP', 'Programmatic Buying', 'DV360', 'Facebook Ads Manager', 'Bidding', 'Display Video', 'Google Ads', 'Media Buying', 'Atl', 'Media Planning', 'Pinterest', 'Campaign Management', 'Btl']",2025-06-12 06:39:49
Erection Commissioning Engineer,M E Energy,4 - 6 years,Not Disclosed,['Pune'],Position: Principal Engineer (E&C)\nReporting to: Dy. Manager/ Manager Projects\nLocation: Pune\nExperience level required: 4-6 years\nQualification: Diploma /BE in Mechanical Engineering\nRemuneration: Commensurate with capabilities and industry standards\n\nRole & Responsibilities:,,,,"['Site Engineering', 'Boiler', 'Erection Commissioning', 'Thermal Power Plant', 'Boiler Erection', 'Power Plant', 'Heat Exchangers', 'Site Supervision', 'Site Execution', 'Whrb', 'Quality Engineering', 'Pressure Vessels', 'Material Handling', 'Thermal Power', 'Safety', 'Thermal Power Project']",2025-06-12 06:39:53
Generative AI Engineer,Easemytrip,1 - 4 years,10-20 Lacs P.A.,['Gurugram'],"About the Role:\nWe are looking for a talented Generative AI Engineer to join our AI innovation team at EaseMyTrip.com and help power the next generation of intelligent travel experiences. In this role, you will lead the integration and optimization of Large Language Models (LLMs) to create conversational travel agents that can understand, recommend, and assist travelers across platforms. You will work at the intersection of backend systems, AI models, and natural language understanding, bringing smart automation to every travel interaction.\n\nKey Responsibilities:\nLLM Integration: Deploy and integrate LLMs (e.g., GPT-4, Claude, Mistral) to process natural language queries and deliver personalized travel recommendations.\nPrompt Engineering & RAG: Design optimized prompts and implement Retrieval-Augmented Generation (RAG) workflows to enhance contextual relevance in multi-turn conversations.\nConversational Flow Design: Build and manage robust conversational workflows capable of handling complex travel scenarios such as booking modifications and cancellations.\nLLM Performance Optimization: Tune models and workflows to balance performance, scalability, latency, and cost across diverse environments.\nBackend Development: Develop scalable, asynchronous backend services using FastAPI or Django, with a focus on secure and efficient API architectures.\nDatabase & ORM Design: Design and manage data using PostgreSQL or MongoDB, and implement ORM solutions like SQLAlchemy for seamless data interaction.\nCloud & Serverless Infrastructure: Deploy solutions on AWS, GCP, or Azure using containerized and serverless tools such as Lambda and Cloud Functions.\nModel Fine-Tuning & Evaluation: Fine-tune open-source and proprietary LLMs using techniques like LoRA and PEFT, and evaluate outputs using BLEU, ROUGE, or similar metrics.\nNLP Pipeline Implementation: Develop NLP functionalities including named entity recognition, sentiment analysis, and dialogue state tracking.\nCross-Functional Collaboration: Work closely with AI researchers, frontend developers, and product teams to ship impactful features rapidly and iteratively.\n\nPreferred Candidate Profile:\nExperience: Minimum 2 years in backend development with at least 1 year of hands-on experience working with LLMs or NLP systems.\nProgramming Skills: Proficient in Python with practical exposure to asynchronous programming and frameworks like FastAPI or Django.\nLLM Ecosystem Expertise: Experience with tools and libraries such as LangChain, LlamaIndex, Hugging Face Transformers, and OpenAI/Anthropic APIs.\nDatabase Knowledge: Strong understanding of relational and NoSQL databases, including schema design and performance optimization.\nModel Engineering: Familiarity with prompt design, LLM fine-tuning (LoRA, PEFT), and evaluation metrics for language models.\nCloud Deployment: Comfortable working with cloud platforms (AWS/GCP/Azure) and building serverless or containerized deployments.\nNLP Understanding: Solid grasp of NLP concepts including intent detection, dialogue management, and text classification.\nProblem-Solving Mindset: Ability to translate business problems into AI-first solutions with a user-centric approach.\nTeam Collaboration: Strong communication skills and a collaborative spirit to work effectively with multidisciplinary teams.\nCuriosity and Drive: Passionate about staying at the forefront of AI and using emerging technologies to build innovative travel experiences.",Industry Type: Travel & Tourism,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'LLM', 'Conversational Ai', 'OpenAI', 'Python', 'Database Design', 'Serverless Architecture', 'Sentiment Analysis', 'Named entity', 'Backend Development', 'Prompt Engineering', 'Large Language Model', 'Chatgpt', 'GCP', 'Restful Application Programming', 'API', 'MongoDB', 'Dialogue state']",2025-06-12 06:39:56
Hiring SSE Backend _ Ambition Box _ Info Edge _ Noida,Info Edge,1 - 3 years,17-19 Lacs P.A.,['Noida'],"About Info Edge:\nInfo Edges mission is to create world-class platforms that transform lives by continuously innovating.\nOur products and services are built keeping our customers in mind. We always delight our customers by\ndelivering superior value through enhanced offerings on the internet and other platforms. Through our\ncontinuous investment across various businesses, especially in cutting-edge technology, machine",,,,"['DSA', 'Design Patterns', 'Java Fundamentals', 'Springboot Java', 'Java', 'Data Structures And Algorithms']",2025-06-12 06:39:59
Data Science Consultant,Techf Solutions,8 - 13 years,22.5-30 Lacs P.A.,['Indore'],"As a Senior AI Developer/ AI Architect in the AI team, you will work and mentor a team of developers, working on the Fusion AI Team and its AI engine AI Talos alongside research in the space, such as large language models, simulations, & agentic AI.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['RAG architecture', 'Python', 'full-stack developer', 'GitHub', 'Hugging Face', 'Jira', 'Pytorch', 'Gen AI', 'Llama2', 'Docker', 'Pandas', 'Pydantic', 'Pyarrow', 'Scikit', 'Mistral AI']",2025-06-12 06:40:02
AI Product Engineer,Tekone It Services,1 - 2 years,1-6 Lacs P.A.,['Hyderabad'],"Position Overview\nWe are seeking AI Product Engineers with 12 years of experience who can bridge the gap between product development and advanced AI technologies. This role involves working closely with AI models, APIs, and data pipelines, while also contributing to product design, user experience, and deployment strategies. You will work at the intersection of technology, user experience, and business outcomes.\nKey Responsibilities\nCollaborate with product managers and AI teams to design and develop AI-driven products leveraging LLMs (GPT-3.5, GPT-4, Gemini).\nTranslate business requirements into AI product features and work on building functional prototypes.\nDevelop and integrate LangChain-based workflows, including LangSmith and LangGraph, to enable intelligent app interactions.\nImplement Retrieval-Augmented Generation (RAG) pipelines and integrate vector databases (e.g., ChromaDB) to enhance AI performance.\nApply prompt engineering to customize model outputs based on product needs and use cases.\nBuild REST APIs and microservices using Flask or FastAPI to support model integration.\nWork with SQL, PySpark, and Spark SQL to manage and process structured and unstructured data.\nCollaborate with UI/UX teams to ensure seamless user interaction with AI components.\nSupport product deployment and monitoring on Azure ML or AWS Bedrock.\nRequired Skills\nStrong programming skills in Python, SQL, PySpark, Spark SQL\nUnderstanding of Generative AI, LLMs, and prompt engineering\nExperience with LangChain, LangGraph, LangSmith\nFamiliarity with vector databases and embedding techniques\nExposure to cloud platforms: Azure ML or AWS Bedrock\nREST API development using Flask or FastAPI\nExcellent problem-solving skills and product-oriented mindset\nPreferred Qualifications\nBachelor’s degree in Computer Science, AI/ML, Data Science, or related field\nInternship or academic experience in AI product development or applied NLP\nFamiliarity with MLOps concepts and product lifecycle best practices\nBasic understanding of UI/UX principles and user-centric design",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Langchain', 'Lang graph', 'Python', 'SQL']",2025-06-12 06:40:04
Associate- Decision Science,Axtria,2 - 4 years,Not Disclosed,['Noida'],"Position Summary \n\nThis role will be responsible for in-patient journey analysis and working with patient-level data to develop a robust solution for the client's teams. An expert in Patient Analytics who can guide and lead the team supporting pharma clients\n\n Job Responsibilities \nEffectively manage the client/ onshore stakeholders, as per the business needs, to ensure successful business delivery.\nWork closely with the project manager to define the algorithm, break down the problem into execution steps, and run the analysis\nEnsure high-quality analytics solutions/reports to the client\nDelivery role will include project scoping, solution design, execution, and communication of the analysis in the client-ready formats\nContribute towards Axtria tools and capabilities as per the business requirements.\nBuild organization capabilities by participating in Hackathon, solution design, and process automation\nEffectively communicate with onshore/ client (as per business needs)\n\n\n Education \n\nBachelor of Engineering in Statistics\n\n Work Experience \n\n Behavioural Competencies \n\nTeamwork & Leadership\nMotivation to Learn and Grow\nOwnership\nCultural Fit\nProject Management\nCommunication\n\n Technical Competencies \n\nPython\nR\nSQL\nEXCEL\nMMx\nForecasting\nMachine Learning\nPharma Commercial Know How\nHEOR EPI and Economic Analysis\nHEOR Simulation Analysis\nPatient Data Analytics Know How\nDataiku\nKNIME\nOthers",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'data analytics', 'sql', 'r', 'statistics', 'medical writing', 'pharmaceutical', 'forecasting', 'simulation', 'drug safety', 'scientific writing', 'machine learning', 'pharmacovigilance', 'heor', 'solution design', 'clinical research', 'clinical trials', 'life sciences', 'process automation']",2025-06-12 06:40:07
Python Automation Engineer,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will collaborate closely with cybersecurity departments to identify and define automation requirements that streamline security processes and incident responses. The engineer will create and refine automation playbooks using low-code platforms, integrate new and existing security tools, and develop custom APIs to ensure seamless inter-connectivity among systems. Additionally, the engineer will engage in the selection and tuning of machine learning algorithms tailored to address specific security challenges faced by the organization. A key component of the role is to maintain up-to-date technical documentation and user guides to support the ongoing use and understanding of automated systems. The Security Automation Engineer must also keep abreast of the latest cybersecurity trends and technologies, sharing insights and best practices with the team to continually enhance the organizations security posture.\n\n\n\nRoles & Responsibilities:\nCreate playbooks using a low-code platform to streamline security operations\nIntegrate new and existing security tools and platforms; Design, code, and integrate custom APIs.\nCreate technical documentation and user guides\nContinuously monitor and maintain the automation platform and ensure that all systems and applications are up to date with the latest security patches and updates\nEnsure compliance with relevant regulations (e.g., GDPR, HIPAA) and industry standards (e.g., ISO 27001, NIST)\nKeep up to date with the latest security threats, trends, and technologies, and provide recommendations for improving security operations\nTriage issues found by tools, external reports, and various tests, to accurately assess the real risks\nOffer remediation guidance to partners for identified issues and serve as a customer concern resource for developers as they reduce issues\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of directly related experience OR\nBachelors degree and 3 to 5 years of directly related experience OR\nDiploma and 7 to 9 years of directly related experience\nPreferred Qualifications:\n\n\n\nFunctional\n\nSkills:\nMust-Have Skills (Not more than 3 to 4):\nProficiency in Python scripting and automation\nExperience with REST API technology\nExperience with Linux is a MUST\nExperience with Security Orchestration Automation and Response (SOAR) tools (e.g. Swimlane, Cortex XSOAR, etc.)\nExperience with development of automation playbooks and integrating multiple security tools to enhance efficiency and effectiveness\n\n\n\nGood-to-Have\n\nSkills:\nKnowledge of cybersecurity frameworks, technologies, and best practices\nExperience in risk management, incident response, and security governance\nKnowledge of security architecture frameworks and principles\nProfessional Certifications (please mention if the certification is preferred or mandatory for the role):\nCEH (preferred)\nCompTIA Security+ (preferred)\nRHCSA (preferred)\nCISSP (preferred)\n\n\n\nSoft\n\nSkills:\nExcellent analytical and troubleshooting skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Automation', 'rest', 'algorithms', 'python', 'linux', 'HIPAA', 'presentation skills', 'troubleshooting', 'machine learning algorithms', 'GDPR']",2025-06-12 06:40:09
Python Technical Lead with AI/ML& AWS,JOBWORLD India...,8 - 13 years,18-33 Lacs P.A.,"['Hyderabad', 'Pune', 'Bengaluru']","Please find the below job Description for Python Technical Lead with AI/ML and Cloud And revert with your details and a Passport size photo\nPlease fill in the details below to proceed further.\n\nRole: Python Technical Lead with AI/ML with Cloud\nExperience : 8+ Years\nWork Location: Hyderabad, Pune, Bangalore\nWork : Initially 5-Days from Office\nClient: its for an MNC\nCTC Budget : 34 LPA\n\nFull Name (as per Aadhar Card):\nEmail ID:\nMobile Number:\nAlternate No:\nAlternative Mail ID:\nGraduation:\nRegular Course:\nGraduation Year:\nTotal Experience:\nRelevant experience:\nCurrent Organization:\nWorking as Permanent Employee:\nPayroll Company:\nYear of Experience in Python Development:\nYear of Experience as Technical Lead:\nYears Of Experience in AI/ML:\nYear of Experience in AWS :\nYear of Experience in Cloud :\nNotice period:\nCurrent location:\nPreferred location:\nCurrent CTC:\nExp CTC:\nPan Card Number:\nDate of Birth :\nAny Offer in Hand\nLWD:\nAny Offer in hand:\nServing Notice Period:\nReady to work from Office :\nAvailable time & Date for the Virtual Discussion :\nCan you join Immediately :\nPlease confirm that you are ready to 5 Days work from the office from Day 1.\n\nJob Description :\n\nJob Location : Bangalore/ Hyderabad/ Pune\nEXP : 8+ Years\nLocation : Bangalore/ Hyderabad/ Pune\nNotice period : Imm to 15 Days\nPOSITION / TITLE: Python Technical Lead with AI/ML\nLocation: Offshore Hyderabad/Pune/Bangalore\nWho are we looking for?\nWe are seeking a highly motivated and skilled Python Technical Lead with minimum 8-10 years of experience to join our team and build innovative applications that leverage the power of artificial intelligence and machine learning. Who has expertise in Design, develop, and maintain robust and scalable back-end APIs using Python and relevant frameworks.\nYou will be responsible for the entire development lifecycle, from designing and implementing back-end functionalities to integrating AI/ML models for intelligent solutions.\nResponsibilities:\n• Proven work experience as a Technical Lead or similar role\n• Experience in managing/working with projects/products across the lifecycle (Design to rollout)\n• Basic understanding of frontend development\n• Assessing the business requirements architecture and working with technical staff to implement/recommend solutions.\n• Experience and responsibility include defining, prototyping and recommending the technology solutions, detailing the implementation design and identifying interfaces with other products for integration.\n• Experience in customer & employee-facing business applications\nTechnical Skills Must have:\n• Strong application development experience in Python\n• Knowledge of AI, NLP, ML, Chat bots will be added advantage.\n• Experience in WebServices using REST, SOAP\n• Knowledge on Linux / Unix flavors\n• Experience with cloud platforms (AWS, GCP, Azure) and containerization (Docker, Kubernetes).\n• Knowledge of different authentication and authorization techniques\nOTHER SKILLS WE'D APPRECIATE\n• Understanding of Smart bots development and integration with NLP engines.\n• Understanding of NLP engines, Artificial Intelligence, Machine Learning frameworks etc.,\n• Experience with relevant Cloud services like Amazon Bedrock, Sagemaker, Google Vertex.AI\n• Familiarity with AI/ML APIs and services (e.g., Google Cloud AI, Azure AI Services, AWS SageMaker).\nEDUCATION QUALIFICATION\n• Graduate in Engineering OR Masters in Computer Applications.\nProcess Skills:\n• General SDLC processes\n• Understanding of utilizing Agile and Scrum software development methodologies\n• Skill in gathering and documenting user requirements and writing technical specifications.\nBehavioral Skills :\n• Good Attitude and Quick learner.\n• Well-developed design, analytical & problem-solving skills\n• Strong oral and written communication skills\n• Excellent team player, able to work with virtual teams.\n• Self-motivated and capable of working independently with minimal management supervision.\n• Able to talk to client directly and report to client/onsite.\nNote: Kindly acknowledge the Mail and revert with updated resume\nRegards,\n\nRejeesh S\nMobile: +91- 9188336668\nMail: rejeesh.s@jobworld.jobs",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python Development', 'AWS', 'Rest', 'Cloud', 'Aiml', 'Webservice Development', 'SOAP', 'Python']",2025-06-12 06:40:11
Associate- Decision Science,Axtria,2 - 4 years,Not Disclosed,['Noida'],"Position Summary \n\nThis role will be responsible for in-patient journey analysis and working with patient-level data to develop a robust solution for the client's teams. An expert in Patient Analytics who can guide and lead the team supporting pharma clients\n\n Job Responsibilities \nEffectively manage the client/ onshore stakeholders, as per the business needs, to ensure successful business delivery.\nWork closely with the project manager to define the algorithm, break down the problem into execution steps, and run the analysis\nEnsure high-quality analytics solutions/reports to the client\nDelivery role will include project scoping, solution design, execution, and communication of the analysis in the client-ready formats\nContribute towards Axtria tools and capabilities as per the business requirements.\nBuild organization capabilities by participating in Hackathon, solution design, and process automation\nEffectively communicate with onshore/ client (as per business needs)\n\n\n Education \n\nBE/B.Tech in IT or Computer\nMaster Diploma - Business Administration in Business Administration\n\n Work Experience \nOverall, 3-5years of rich experience in the Pharmaceutical / Life Sciences Domain.\nWe are looking for experts in the space of commercial pharmaceutical analytics- HCP analytics, payer analytics, and patient analytics.\nWorked on advanced analytics in the pharma domain throughout the patient journey, like the line of therapy, switch analysis, source of business, segmentation, persistence & compliance, adherence, and patient identification, etc, using various data sources\nExperience using various patient-level data like APLD, LAAD, EMR, patient registries, Prescription data, formulary data, etc\nStrong in logical reasoning, structuring of analysis, asking the right questions, and logical approach to analyze data, problems, and situations.\nExperience in pharmaceutical sales and marketing analytics would be preferred\nRelevant experience in Statistical/ modeling knowledge, ability to transform data to insights, good data visualization/ reporting skills\nGood to have work experience in building statistical modeling and/or AI/ML models using Python, R-Studio, PySpark, Keras, and TensorFlow.\nTechnical knowledge- R/ Python/ SQL. Knowledge of self-service analytics platforms such as DataiKU/ KNIME/ Alteryx will be an added advantage. MS Excel knowledge is mandatory.\n\n\n Behavioural Competencies \n\nTeamwork & Leadership\nMotivation to Learn and Grow\nOwnership\nCultural Fit\nProject Management\nCommunication\n\n Technical Competencies \n\nPython\nR\nSQL\nEXCEL\nPharma Commercial Know How\nOthers\nPatient Data Analytics",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['pharmaceutical', 'python', 'logical approach', 'statistical modeling', 'life sciences', 'data analytics', 'pyspark', 'knime', 'dataiku', 'artificial intelligence', 'sales', 'sql', 'alteryx', 'pharmaceutical sales', 'tensorflow', 'r', 'hcp', 'marketing analytics', 'keras', 'data visualization', 'statistics']",2025-06-12 06:40:14
Senior BI Analyst - Tableau Expert,BMC Software,7 - 12 years,Not Disclosed,['Pune'],"BU Description:\nOur Analytics and Automation team is at the forefront of leveraging data-driven insights to enhance business performance across sales, marketing, product development, and VSE. We specialize in harnessing advanced analytics and automation techniques to provide actionable intelligence, drive efficiency, and foster innovation. Our commitment to excellence ensures that we deliver impactful solutions that propel our organization's strategic goals forward.\n\nAbout You:\n\nYou like to develop, design, and deliver data visualization solutions that deliver sustained business value from our and associated solutions\nYou enjoy working cross-functionally across Sales, Marketing, Operations, and IT organizations for supporting the customer success organization\nYou re a team player and believe in building synergies across BMC to create/continually evolve one integrated customer journey.\nYou like to innovate, and have a passion for solving business problems, to continuously improve our quality of service\nYou have a passion for development, and challenge yourself to learn new things\nYou know how to have fun and connect with people.\n\nKey Responsibility/Role Expectations:\n\nThe Senior BI Analyst supports senior leadership by providing data-driven insights and analytics, enabling informed decision-making, and driving strategic initiatives to enhance customer success and align with business objectives. You should be responsible to\n\nDesign, develop, and maintain advanced and interactive Tableau dashboards to provide actionable insights into customer success metrics.\nAnalyze customer behavior, trends, and performance metrics to identify actionable opportunities for improvement.\nMonitor key customer success indicators (e.g., retention, churn, satisfaction) and provide insights to drive enhanced customer engagement and satisfaction.\nCreate visually compelling and interactive reports tailored for senior leadership to support data-driven strategic decision-making.\nCollaborate with cross-functional teams, including Customer Success, Product, and Support, to gather requirements and deliver tailored BI solutions.\nIntegrate data from multiple sources (e.g., CRM systems like Salesforce, support tools, and internal databases) to create a unified view of performance.\nProvide data-driven recommendations to senior leadership to align customer success efforts with organizational objectives.\nIdentify and report on key trends and anomalies in customer success data, proactively addressing potential challenges.\nDevelop and implement automated workflows for reporting and analytics to enhance efficiency and reduce manual effort.\nStay updated on Tableau and broader BI trends, implementing best practices in data visualization and analysis.\n\nProfessional Experience:\n\nMinimum of 7+ years of experience in Business Intelligence and data analysis.\nExpert proficiency in Tableau, with demonstrated ability to build advanced visualizations.\nStrong understanding of relational databases with expertise in advanced SQL writing.\nProven ability to extract and analyze data from sources such as Snowflake, Excel, CSV, and text files.\nProficient knowledge of Salesforce.com, with experience in CRM data analysis and integration.\nAdvanced skills in Excel, PowerPoint, and Word for creating reports and presentations.\nStrong analytical skills to critically evaluate data, reconcile discrepancies, and ensure accuracy.\nAbility to translate user requirements into technical solutions and design effective BI implementations.\nExcellent organizational skills, with the ability to manage multiple complex projects in a fast-paced, dynamic environment.\nSelf-motivated, detail-oriented, and able to deliver quality outcomes under tight deadlines.\nStrong communication and presentation skills to effectively collaborate with stakeholders, including senior leaders such as Sr. Directors and VPs.\nDemonstrated ability to influence and build long-term relationships with cross-functional teams and business partners.\nExperience mentoring and training team members on technical skills and BI best practices.\nQuick learner, adaptable to changing tools, environments, and priorities.\nCustomer-oriented mindset, with a proven ability to partner with stakeholders to achieve shared business goals.\nFamiliarity with programming languages like Python or R, cloud-based platforms like AWS are a plus.\nBasic understanding of machine learning concepts and predictive analytics is a bonus.\n\nEducation\n\nBachelor s or master s degree in computer science, Information Systems, or a related field (Advanced degree preferred).",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Tableau', 'salesforce', 'python', 'data analysis', 'predictive analytics', 'presentation skills', 'relational databases', 'machine learning', 'business intelligence', 'sql']",2025-06-12 06:40:16
IT Recruiter II Naukri.com II Noida II Niche Hiring,Info Edge,3 - 8 years,2-7 Lacs P.A.,"['Noida', 'New Delhi', 'Greater Noida']","About Info Edge\nInfoEdge mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['IT Recruitment', 'Niche Hiring', 'Consulting', 'ERP', 'Lateral Hiring', 'Architecture', 'End To End Recruitment', 'It Hiring', 'Senior Level Hiring', 'Technical Recruitment', 'Technical Hiring', 'Sourcing Profiles', 'Cloud Technologies', 'Mid Level Hiring', 'Leadership Hiring', 'Oracle', 'Client Handling']",2025-06-12 06:40:19
IT Recruiter II Naukri.com II Noida II Bulk Hiring,Info Edge,2 - 4 years,1-5 Lacs P.A.,"['Noida', 'New Delhi', 'Greater Noida']","About Info Edge\nInfoEdge mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['IT Recruitment', 'Consulting', 'Bulk Hiring', 'Volume Hiring', 'End To End Recruitment', 'It Hiring', 'Technical Recruitment', 'Recruitment', 'Talent Acquisition', 'Technical Hiring', 'Sourcing Profiles', 'Mass Recruitment', 'Mass Hiring', 'Shortlisting', 'Head Hunting', 'Recruitment Consulting', 'Client Handling']",2025-06-12 06:40:21
R&D Member of Technical Staff- II - Test,Aveva,4 - 7 years,Not Disclosed,['Hyderabad'],"job requisition idR010036\n\nAVEVA is creating software trusted by over 90% of leading industrial companies.\n\nPosition R&D Member of Technical Staff-II, Product Test\n\nPrevious experienceDesign and development of commercial software either individually or or a combination of an on-prem, Web or Cloud, using .Net. Ideally couple of year of recent experience on developing AI capabilities in these products would be.\n\nLocation: Hyderabad, India Hybrid (~60% office, ~40% remote)\n\nEmployment type: Full-time regular (flexible working options available)\n\nBenefits: Competitive salary; Gratuity, Medical and accidental insurance, very attractive leave entitlement, Emergency leave days, childcare support, maternity, paternity and adoption leaves, Education Assistance Program, home office set up support (for hybrid roles), well-being support.\n\nThe job\n\nAs part of our global AI development group, youll collaborate with a team of skilled software engineers in designing and implementing AI capabilities and solutions into our product suite. The work will primarily involve testing of our AI capabilities that we introduce in our products ensuring that they are of top-notch quality. You will have the opportunity to work with the latest technologies to ensure that we build and bring meaningful AI capabilities to the market through our product suite.\n\nKey responsibilities\nWork with Product Owners and conduct detailed review of workflows, be it process or domain workflow.\nPrepare Test Strategy, work out Test plans and continuously improve on existing QA processes.\nUse tools including test automation frameworks and data to make testing efficient and easily repeatable for regression purposes.\nCoaching and mentoring of junior team members will be expected.\nCollaboration with stakeholders be it architects, domain experts and engineers from other product teams will be key to success in this role.\nYou may also work on products which could be a mix of on-prem, SaaS, desktop based or web/mobile app\nIdeal experience\n4 -7 Years Hands-on experience of functional and non-functional testing on client-server/distributed systems/cloud computing on a commercial scale.\nYou can demonstrate examples of automation testing skills using Selenium-C#/Java Script etc.\n1-2 Years hands-on development experience on AI & Machine Learning with good knowledge of basic statistical and mathematical concepts.\nExperience with CI/CD tools and processes in an Agile environment.\nYou have a demonstrated development experience with client-server/distributed systems/cloud computing on a commercial scale.\nGreat skills to have\nOrganization: The pace at AVEVA can be exciting and fast, so whilst you will need excellent time management and effective prioritisation, we will do all we can to support a balanced portfolio of work, and your wellbeing.\nQuality Software: You are passionate about delivering software that is reliable, performant and scales well.\nProblem-solving: Youll need to enjoy figuring how to get out of sticky problems, as troubleshooting and solving challenging problems is a big part of this role.\nThe team youll join\n\n""We're a global team of brilliant minds tackling unsolved customer problems with AI/ML. We're all geographically spread out, but that fuels our diverse skillsets and experiences. The best partIt's incredibly fun and collaborative environment! Beyond development, we're passionate about rigorously testing AIML solutions to ensure top-notch performance. If you're a talented individual who thrives in a dynamic environment and wants to push the boundaries of AI/ML testing, then let's connect on !"" Srikanth Podugu\n\nR&D at AVEVA\n\nOur global team of 2000+ developers work on an incredibly diverse portfolio of over 75 industrial automation and engineering products, which cover everything from data management to 3D design. AI and cloud are at the centre of our strategy, and we have over 150 patents to our name.\n\nOur track record of innovation is no fluke its the result of a structured and deliberate focus on learning, collaboration and inclusivity. If you want to build applications that solve big problems, join us!\n\nIndia Benefits include:\n\nGratuity, Medical and accidental insurance, very attractive leave entitlement, emergency leave days, childcare support, maternity, paternity and adoption leaves, education assistance program, home office set up support (for hybrid roles), well-being support\n\nIts possible were hiring for this position in multiple countries, in which case the above benefits apply to the primary location. Specific benefits vary by country, but our packages are similarly comprehensive.\n\nFind out moreaveva.com/en/about/careers/benefits/\n\nHybrid working\n\nBy default, employees are expected to be in their local AVEVA office three days a week, but some positions are fully office-based. Roles supporting particular customers or markets are sometimes remote.\n\nHiring process\n\nInterestedGreat! Get started by submitting your cover letter and CV through our application portal. AVEVA is committed to recruiting and retaining people with disabilities. Please let us know in advance if you need reasonable support during your application process.\n\nFind out moreaveva.com/en/about/careers/hiring-process",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['automation testing', 'distribution system', 'machine learning', 'artificial intelligence', 'cloud computing', 'c#', 'continuous integration', 'software testing', 'ci/cd', 'javascript', 'functional testing', 'selenium', 'test strategy', 'web technologies', 'test planning', '.net', 'agile', 'ml']",2025-06-12 06:40:23
Associate Product Developer,BMC Software,5 - 10 years,Not Disclosed,['Pune'],"Assist in developing AI-powered QA automation tools using LLMs\nCollaborate with QA engineers to understand test requirements and translate them into automated scripts\nUse LLMs to generate test cases, validation scripts, and test data automatically\nMaintain, debug, and optimize automated test scripts and frameworks\nIntegrate LLM-based solutions into existing CI/CD pipelines and QA workflows\nDocument automation processes and assist with training teams on new AI-driven QA tools\nContinuously research and apply advancements in LLMs and AI for QA improvements\nTo ensure youre set up for success, you will bring the following skillset & experience:\nYou have 3-5 years for software development experience\nYou have experince of basic programming skills in Python, JavaScript, or relevant languages for automation\nYou have understanding of software testing concepts and QA automation tools (e.g., Selenium, Cypress, JUnit)\nYou have some experience in AI, NLP, or machine learning concepts\nYou are familiarity with version control systems such as Git\nYou have strong problem-solving skills and ability to learn quickly in a dynamic environment\n\nWhilst these are nice to have, our team can help you develop in the following skills:\nExperience with AI/ML frameworks like PyTorch or TensorFlow\nFamiliarity with Large Language Models such as GPT, BERT, or OpenAI APIs\nKnowledge of continuous integration tools (Jenkins, GitHub Actions)\nExposure to writing or maintaining automated test frameworks\nUnderstanding of cloud environments for deploying automation solutions",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software development', 'AI/ML frameworks', 'Jenkins', 'automation', 'GitHub Actions', 'Open AI API', 'JUnit', 'Cypress', 'CI/CD', 'Selenium', 'Quality Assurance']",2025-06-12 06:40:26
Associate- Decision Science,Axtria,4 - 6 years,Not Disclosed,['Noida'],"Position Summary \n\nTo be a driven business analyst who can work on complex Analytical problems and help the customer in better business decision making especially in the area of Pharma (domain).\n\n Job Responsibilities \nEffectively manage the client/ onshore stakeholders, as per the business needs, to ensure successful business delivery.\nWork closely with the project manager to define the algorithm, break down the problem into execution steps, and run the analysis\nEnsure high-quality analytics solutions/reports to the client\nDelivery role will include project scoping, solution design, execution, and communication of the analysis in the client-ready formats\nContribute towards Axtria tools and capabilities as per the business requirements.\nBuild organization capabilities by participating in Hackathon, solution design, and process automation\nEffectively communicate with onshore/ client (as per business needs)\n\n\n Education \n\nBachelor of Engineering in Statistics\n\n Work Experience \nOverall, 4-6 years of rich experience in the Pharmaceutical / Life Sciences Domain.\nWe are looking for experts in the space of commercial pharmaceutical analytics- HCP analytics, payer analytics, and patient analytics.\nWorked on advanced analytics in the pharma domain throughout the patient journey like the line of therapy, switch analysis, source of business, segmentation, persistence & compliance, adherence, and patient identification, etc using various data sources\nExperience using various patient-level data like APLD,LAAD, EMR, patient registries, Prescription data, formulary data, etc\nCan work across a variety of projects from advanced analytics, ad-hoc analysis, and reporting\nEffectively communicate with onshore/ client (as per business needs)\nRelevant experience in Statistical/ modeling knowledge, ability to transform data to insights, good data visualization/ reporting skills\nGood to have work experience in building statistical modeling and/or AI/ML models using Python, R-Studio, PySpark, Keras, and TensorFlow.\nTechnical knowledge- R/ Python/ SQL. Knowledge of self-service analytics platforms such as DataiKU/ KNIME/ Alteryx will be an added advantage. MS Excel knowledge is mandatory.\n\n\n Behavioural Competencies \n\nTeamwork & Leadership\nMotivation to Learn and Grow\nOwnership\nCultural Fit\nProject Management\nCommunication\n\n Technical Competencies \n\nPython\nR\nSQL\nEXCEL\nMMx\nForecasting\nMachine Learning\nPharma Commercial Know How\nHEOR EPI and Economic Analysis\nHEOR Simulation Analysis\nPatient Data Analytics Know How\nDataiku\nKNIME\nOthers",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['pharmaceutical', 'python', 'tensorflow', 'keras', 'life sciences', 'data analytics', 'forecasting', 'simulation', 'pyspark', 'knime', 'dataiku', 'machine learning', 'artificial intelligence', 'sql', 'alteryx', 'heor', 'r', 'statistical modeling', 'data visualization', 'process automation', 'statistics']",2025-06-12 06:40:29
IT Recruiter II Naukri.com II Noida II Niche Hiring,Info Edge,3 - 8 years,2-7 Lacs P.A.,"['Noida', 'New Delhi', 'Greater Noida']","About Info Edge\nInfoEdge mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['IT Recruitment', 'Niche Hiring', 'Consulting', 'Volume Hiring', 'End To End Recruitment', 'It Hiring', 'Technical Recruitment', 'Recruitment', 'Talent Acquisition', 'Technical Hiring', 'Sourcing Profiles', 'Mass Recruitment', 'Mass Hiring', 'Head Hunting', 'Recruitment Consulting', 'Client Handling']",2025-06-12 06:40:32
Hiring|Escalation Management-Inbound Process| Naukri| Noida,Info Edge,1 - 4 years,4-5.5 Lacs P.A.,['Noida'],"Hi,\nNaukri.com is hiring for Customer Support for Noida location. As discussed, please find the mentioned JD for the said role\nAbout Info Edge\nInfoEdges mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['Escalations', 'Escalation Management', 'social media escalations', 'Customer Escalation', 'escalation specialist', 'L2', 'Customer Complaints', 'Complaint Handling', 'Customer Queries', 'Resolution']",2025-06-12 06:40:34
"R&D Member of Technical Staff II, Product Development",Aveva,2 - 6 years,Not Disclosed,['Hyderabad'],"job requisition idR010044\n\nAVEVA is creating software trusted by over 90% of leading industrial companies.\n\nJob TitleR&D Member of Technical Staff II, Product Development\n\nLocationHyderabad\n\nEmployment Type Full-time\n\nBenefits Gratuity, Medical and accidental insurance, very attractive leave entitlement, emergency leave days, childcare support, maternity, paternity and adoption leaves, education assistance program, home office set up support (for hybrid roles), well-being support\n\nThe job\n\nAs a part of this function, the Cloud Unified Engineering team of R&D Technology and Execution Development, the development engineer will be responsible for ensuring the high quality of AVEVA Software Product deliveries to customers on the CONNECT cloud platform.\n\nKey responsibilities\n\nWe are looking for a Developer with skills to design and develop required functionality in the Cloud Unified Engineering solution / platform. This will include implement new user stories, write unit tests and fixing the reported defects by system test, DevOps teams.\n\nAlso, proactively identify improvements and enhancements to existing unit test cases test suites. This role reports into Development manager located in Hyderabad, India.\n\nEssential requirements\n\nDevelopment experience with exposure to programming skills, e.g. C#, .NET.\nProven experience on Amazon Web Services (AWS)Desired skills and competenciesKnowledge of PowerShell or Node JS scripting.Knowledge of AWS CloudFormation and Infrastructure as Code (IaC).\nKnowledge of API, REST, microservices and serverless architecture\nKnowledge and experience of operational support, software development and deployment methodologies and principles.\nHands-on in AWS administration, AWS APIs and tools or equivalent Azure experience.\nStrong written, verbal and presentation skills, able to convey information clearly and concisely to technical and non-technical audiences.R&D at AVEVA Our global team of 2000+ developers work on an incredibly diverse portfolio of over 75 industrial automation and engineering products, which cover everything from data management to 3D design. AI and cloud are at the centre of our strategy, and we have over 150 patents to our name.Our track record of innovation is no fluke its the result of a structured and deliberate focus on learning, collaboration and inclusivity. If you want to build applications that solve big problems, join us.Find out moreaveva.com/en/about/careers/r-and-d-careers/ India Benefits include:Gratuity, Medical and accidental insurance, very attractive leave entitlement, emergency leave days, childcare support, maternity, paternity and adoption leaves, education assistance program, home office set up support (for hybrid roles), well-being support Its possible were hiring for this position in multiple countries, in which case the above benefits apply to the primary location. Specific benefits vary by country, but our packages are similarly comprehensive.Find out moreaveva.com/en/about/careers/benefits/ Hybrid workingBy default, employees are expected to be in their local AVEVA office three days a week, but some positions are fully office-based. Roles supporting particular customers or markets are sometimes remote.Hiring processInterestedGreat! Get started by submitting your cover letter and CV through our application portal. AVEVA is committed to recruiting and retaining people with disabilities. Please let us know in advance if you need reasonable support during your application process.Find out moreaveva.com/en/about/careers/hiring-process",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['presentation skills', 'aws administration', 'microsoft azure', 'aws cloudformation', 'aws', 'c#', 'rest', 'software development', 'web services', 'artificial intelligence', 'microservices', 'node.js', 'devops', 'powershell', 'product development', '.net', 'api', 'product engineering']",2025-06-12 06:40:37
Artificial Intelligence Developer,Arya Omnitalk,3 - 8 years,Not Disclosed,['Pune'],"Position : Edge AI developer\n\nSkill Set\n\nExperience of at least 2.5 years in development of Video based analytics at Camera level such as perimeter based alert, person detection, movement detection etc\nExperience on Linux, C and Python\nPreferred if worked on Tiny Model\nWork experience on Realtek or Raspberry pi boards for above activities",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Raspberry Pi', 'Linux', 'Edge Ai', 'Aiml', 'Computer Vision', 'Machine Learning', 'Edge', 'Ml', 'Python']",2025-06-12 06:40:39
R&D Senior Member of Technical Staff,Aveva,10 - 15 years,Not Disclosed,['Hyderabad'],"job requisition idR010567\n\nAVEVA is creating software trusted by over 90% of leading industrial companies.\n\nJob TitleR&D Senior Member of Technical Staff-Test\n\nLocationHyderabad India\n\nEmployment Type Full Time\n\nThe job\n\nAs part of our global AI development group, youll collaborate with a team of skilled software engineers in designing and implementing AI capabilities and solutions into our product suite. The work will primarily involve testing of our AI capabilities that we introduce in our products ensuring that they are of top-notch quality. You will have the opportunity to work with the latest technologies to ensure that we build and bring meaningful AI capabilities to the market through our product suite.\n\nKey responsibilities\nParticipate in Scrum meetings with other team members including sprint planning and estimating; backlog refinement; daily Scrum meetings; sprint retrospectives and sprint reviews.\nWork collaboratively with scrum colleagues to identify, implement and execute functional and non-functional test scenarios to validate the functionality of the software.\nBe responsible for defining stories, test strategy, test ideas and translating those into automated and manual tests as part of a cross-functional development team.\nUse tools including test automation frameworks and data to make testing efficient and easily repeatable for regression purposes.\nYou may be required to update existing frameworks or modify them or build new ones depending on the need.\nDesign, implement, and execute test strategies for AI-powered applications, including LLM-based assistants, computer vision models, and predictive analytics systems.\nYou may be required to mentor junior team members. Handle large amounts of data, as is normally the case with AI models.\nEssential requirements\nMinimum 10+ years of functional/domain testing experience within the engineering or a related industry.\nExpertise in non-functional requirement gathering and identifying critical business scenarios.\nStrong knowledge and hands-on experience in API testing via automation .\nExperience in application/functional testing .\nShould have working knowledge in designing and implementing and executing test strategies for AI-powered applications like LLM-based assistants, computer vision models, and predictive analytics systems .\nProficiency with CI/CD tools such as GIT, TFS, MS Test, and Azure DevOps.\nFamiliarity with Agile methodologies and processes.\nExperience in test automation using Selenium with C#/JavaScript or similar scripting languages.\nUnderstanding of Microservices and Service-Oriented Architectures .\nGood grasp of Machine Learning life cycle .\nAbility to design and implement unit and integration tests for machine learning models using varied datasets.\nShould have working knowledge in designing and implementing and executing test strategies for AI-powered applications like LLM-based assistants, computer vision models, and predictive analytics systems\nExceptional communication skills to collaborate with Product Owners, System Testers, and Product Support teams .\nExperience mentoring and coaching less experienced colleagues.\nStrong problem-solving skills with a proactive and positive approach.\nDesired skills and competencies\nOrganization: The pace at AVEVA can be exciting and fast, so whilst you will need excellent time management and effective prioritization, we will do all we can to support a balanced portfolio of work, and your wellbeing.\nQuality Software: You are passionate about delivering software that is reliable, performant and scales well.\nProblem-solving: Youll need to enjoy figuring how to get out of sticky problems, as troubleshooting and solving challenging problems is a big part of this role.\nR&D at AVEVA\n\nOur global team of 2000+ developers work on an incredibly diverse portfolio of over 75 industrial automation and engineering products, which cover everything from data management to 3D design. AI and cloud are at the centre of our strategy, and we have over 150 patents to our name.\n\nOur track record of innovation is no fluke its the result of a structured and deliberate focus on learning, collaboration and inclusivity. If you want to build applications that solve big problems, join us.\n\nFind out moreaveva.com/en/about/careers/r-and-d-careers/\n\nIndia Benefits include:\n\nGratuity, Medical and accidental insurance, very attractive leave entitlement, emergency leave days, childcare support, maternity, paternity and adoption leaves, education assistance program, home office set up support (for hybrid roles), well-being support\n\nIts possible were hiring for this position in multiple countries, in which case the above benefits apply to the primary location. Specific benefits vary by country, but our packages are similarly comprehensive.\n\nFind out moreaveva.com/en/about/careers/benefits/\n\nHybrid working\n\nBy default, employees are expected to be in their local AVEVA office three days a week, but some positions are fully office-based. Roles supporting particular customers or markets are sometimes remote.\n\nHiring process\n\nInterestedGreat! Get started by submitting your cover letter and CV through our application portal. AVEVA is committed to recruiting and retaining people with disabilities. Please let us know in advance if you need reasonable support during your application process.\n\nFind out moreaveva.com/en/about/careers/hiring-process",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'software testing', 'cd tools', 'ci/cd', 'ci / cd tools', 'tfs', 'c#', 'automation testing', 'machine learning', 'javascript', 'azure devops', 'artificial intelligence', 'microservices', 'git', 'mstest', 'selenium', 'computer vision', 'scrum', 'agile', 'api testing']",2025-06-12 06:40:42
Specialist Software Engineer,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nYou will play a key role as part of Operations Generative AI (GenAI) Product team to deliver cutting edge innovative GEN AI solutions across various Process Development functions (Drug Substance, Drug Product, Attribute Sciences & Combination Products) in Operations functions. The role involves developing, implementing and sustaining GEN AI solutions to help find relevant, actionable information quickly and accurately.\nRole Description:\nThe Specialist Software Engineer is responsible for designing, developing, and maintaining GEN AI solutions software applications and solutions that meet business needs and ensure high availability and performance of critical systems and applications in Process development under Operation. This role involves working closely with Data Scientists, business SMEs, and other engineers to create high-quality, scalable GEN AI software solutions to help find relevant, actionable information quickly and accurately, monitoring system health, and responding to incidents to minimize downtime.\nRoles & Responsibilities:\nTake ownership of complex software projects from conception to deployment, Manage software delivery scope, risk, and timeline.\nRapidly prototype concepts into working code.\nProvide technical guidance and mentorship to junior developers.\nContribute to front-end and back-end development using cloud technology.\nDevelop innovative solutions using generative AI technologies.\nIntegrate with other systems and platforms to ensure seamless data flow and functionality.\nConduct code reviews to ensure code quality and adherence to best practices.\nCreate and maintain documentation on software architecture, design, deployment, disaster recovery, and operations.\nAnalyze and understand the functional and technical requirements of applications, solutions, and systems and translate them into software architecture and design specifications.\nWork closely with product team, cross-functional teams, enterprise technology teams and QA, to deliver high-quality and compliant software on time.\nEnsure high quality software deliverables free of bugs and performance issues through proper design and comprehensive testing strategies.\nProvide ongoing support and maintenance for applications, ensuring that they operate smoothly and efficiently.\nArchitect and lead the development of scalable, intelligent search systems leveraging NLP, embeddings, LLMs, and vector search\nOwn the end-to-end lifecycle of search solutions, from ingestion and indexing to ranking, relevancy tuning, and UI integration\nIntegrate AI models that improve search precision, query understanding, and result summarization (e.g., generative answers via LLMs).\nDevelop solutions for handling structured/unstructured data in AI pipelines.\nPartner with platform teams to deploy search solutions on scalable infrastructure (e.g., Kubernetes, Databricks).\nExperience in integrating Generative AI capabilities and Vision Models to enrich content quality and user engagement.\nBasic Qualifications:\nMasters degree with 4 - 6 years of experience in Computer Science, IT or related field OR\nBachelors degree with 6 - 8 years of experience in Computer Science, IT or related field OR\nDiploma with 10 - 12 years of experience in Computer Science, IT or related field\nExperience in Python, Java, AI/ML based Python libraries(PyTorch),\nExperienced with Web frameworks like Flask, Django, Fast API\nExperience with design patterns, data structures, data modelling, data algorithms\nFamiliarity with MLOps, CI/CD for ML, and monitoring of AI models in production.\nExperienced with AWS /Azure Platform, building and deploying the code\nExperience in PostgreSQL /Mongo DB SQL database, vector database for large language models, Databricks or RDS, S3 Buckets\nExperience with popular large language models\nExperience with Retrieval-augmented generation (RAG) framework, AI Agents, Vector stores, AI/ML platforms, embedding models ex Open AI, Langchain, Redis, pgvector\nExperience with prompt engineering, model fine tuning\nExperience with generative AI or retrieval-augmented generation (RAG) frameworks\nExperience in Agile software development methodologies\nExperience in End-to-End testing as part of Test-Driven Development\nPreferred Qualifications:\nStrong understanding of cloud platforms (e.g., AWS, GCP, Azure) and containerization technologies (e.g., Docker, Kubernetes).\nExperience with monitoring and logging tools (e.g., Prometheus, Grafana, Splunk).\nExperience with data processing tools like Hadoop, Spark, or similar.\nExperience with Langchain or llamaIndex framework for language models; Experience with prompt engineering, model fine-tuning.\nExperience working on Full stack Applications\nProfessional Certifications:\nAWS, Data Science Certifications(preferred)\nSoft Skills:\nExcellent analytical and troubleshooting skills.\nStrong verbal and written communication skills.\nAbility to work effectively with global, virtual teams.\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals.\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Software engineering', 'kubernetes', 'algorithms', 'microsoft azure', 'cloud platforms', 'sql', 'django', 'spark', 'grafana', 'gcp', 'troubleshooting', 'data structures', 'hadoop', 'flask']",2025-06-12 06:40:44
Core AI/ML Developer (Remote),Innova Solutions,4 - 8 years,Not Disclosed,[],"Job Summary:\nWe are looking for a skilled AI/ML Developer to join our team, responsible for integrating Amazon Connect with Amazon Lex and Salesforce. The ideal candidate will leverage Amazon Lex to understand and respond to customer queries (such as booking a rental showing), call Salesforce for data processing, and integrate the response back into the customer conversation seamlessly within Amazon Connect. This is a key role for automating and enhancing customer interactions using AI-driven technologies and cloud services.\n\nKey Responsibilities:\nIntegration Development & Solution Design:\nDesign and develop intelligent customer service workflows using Amazon Connect and Amazon Lex to handle customer requests, such as booking rental showings, by processing customer inputs (e.g., voice commands) and querying Salesforce for information.\nBuild and maintain Amazon Connect Contact Flows that integrate seamlessly with Amazon Lex to automate customer interactions, such as understanding requests and responding in a human-like manner.\nIntegrate Salesforce with Amazon Lex via AWS Lambda to retrieve relevant data, such as availability for rental showings or property details, and pass that information back to Amazon Lex for dynamic responses.\n\nBot Development and AI Model Management:\nLeverage Amazon Lex to design and implement conversational AI models that can handle complex interactions, including NLP (Natural Language Processing) to understand customer intent.\nEnsure the Lex bot can query Salesforce for available data, using Lambda functions for API calls to Salesforce.\n Implement and optimize AI models to respond to customers in a human-like manner, ensuring natural conversation flow from the bot.\n\nAWS Lambda & Salesforce Integration:\nDevelop AWS Lambda functions to facilitate communication between Amazon Lex and Salesforce, ensuring seamless data flow. For example, when a customer asks for details, Lex will query Salesforce for available data and then provide a confirmation to the user.\nEnsure that Lambda functions are designed to handle real-time API requests to Salesforce, extract relevant data , and return that data to Amazon Lex for appropriate responses.\n\nQualifications:\n Bachelor's or Master's degree in Computer Science, Artificial Intelligence, Data Science, or a related field.\nMinimum of 5+ years of experience in AI/ML development with a strong focus on AWS technologies, especially Amazon Connect, Lambda, and Bedrock.\nHands-on experience with AWS services like Amazon Lex,\nAmazon Polly, Amazon Transcribe, Amazon Rekognition, and Amazon SageMaker.\nProven experience working with Amazon Bedrock for deploying machine learning models at scale.\nStrong knowledge of serverless architecture and AWS Lambda to process real-time events and data streams.\nExperience with NLP (Natural Language Processing) and speech-to-text technologies.\nFamiliarity with AI/ML frameworks such as TensorFlow, PyTorch, or Scikit-learn.\nKnowledge of data pipelines, ETL processes, and data integration techniques for AI/ML applications.\nStrong experience with REST APIs, AWS SDKs, and integrating third-party services into the AWS ecosystem.\nUnderstanding of Amazon Connect architecture and contact flow customization.\nProficiency in Python, JavaScript, or Node.js for implementing AI/ML models and Lambda functions.\n\nPreferred Skills:\nAWS Certified Cloud Practitioner (Mandatory)\nAWS Certified Developer Associate (Mandatory)\nAWS Certified Machine Learning - Specialty or similar AWS certifications (Good to have)\nAWS Certified Solutions Architect Associate (Good to have)\nExperience with AWS Glue, AWS Sagemaker, and Amazon Kendra for advanced AI/ML integrations.\nExperience with Chatbot development and Voice AI systems using Amazon Lex and Amazon polly.\nStrong problem-solving skills, with the ability to troubleshoot and optimize complex systems.\nExcellent communication and team collaboration skills, with the ability to present complex technical information clearly.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['AI/ML', 'Artificial Intelligence', 'Amazon Connect', 'Machine Learning', 'AWS', 'Amazon Transcribe', 'Amazon Lex', 'Amazon Polly', 'Amazon SageMaker', 'Amazon Rekognition']",2025-06-12 06:40:47
AI/ML - Contract-to-hire,SP Software,5 - 10 years,18-22.5 Lacs P.A.,"['Gurugram', 'Bengaluru']","Notice - Immediate - 15 days serving.\nPF Mandatory!\n\nRole & responsibilities\n5+ years of experience in machine learning, with a focus on generative models or autonomous agents.\nProficiency in Python and ML frameworks such as PyTorch\nExperience with LLMs (e.g., GPT, Claude, LLaMA, Cortex), transformers, and diffusion models.\nFamiliarity with agent frameworks (e.g., LangChain, AutoGPT, ReAct, OpenAgents).\nExperience with AWS and Snowflake services\nPrior Healthcare experience\nStrong understanding of reinforcement learning, planning algorithms, and multi-agent systems.\nExcellent problem-solving and communication skills.\n\n--\nThanks & Regards,\n\nKarthik Kumar,\nIT Recruiter\nSP Software (P) Limited (An ISO, ISMS & CMMI Level-3 Certified company)\nAn SP Group Enterprise.\nConnect on : linkedin.com/in/b-karthik-kumar-116990179",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Temporary/Contractual","['GenAI', 'LLM', 'Python']",2025-06-12 06:40:49
F2F Weekend Drive - Bangalore- 14th June - DS Gen AI,Ltimindtree,6 - 11 years,Not Disclosed,['Bengaluru'],"Job description\nWe are having a F2F weekend drive for the requirement of a Data Scientist + Gen AI at our LTIM Bangalore Whitefield office.\nDate - 14th June 2025\nExperience - 6+ Years\nMandatory Skills - Data Science, Gen AI, Python, RAG and Azure/AWS, AI/ML, NLP\nLocation - LTIMindtree Bangalore Whitefield Office\nSecondary - (Any) Machine Learning, Deep Learning, ChatGPT, Langchain, Prompt, vector stores, RAG, llama, Computer vision, Deep learning, Machine learning, OCR, Transformer, regression, forecasting, classification, hyper parameter tunning, MLOps, Inference, Model training, Model Deployment\n\nGeneric JD-\nMore than 6 years of experience in Data Engineering, Data Science and AI / ML domain\nExcellent understanding of machine learning techniques and algorithms, such as GPTs, CNN, RNN, k-NN, Naive Bayes, SVM, Decision Forests, etc.\nExperience using business intelligence tools (e.g. Tableau, PowerBI) and data frameworks (e.g. Hadoop)\nExperience in Cloud native skills.\nKnowledge of SQL and Python; familiarity with Scala, Java or C++ is an asset\nAnalytical mind and business acumen and Strong math skills (e.g. statistics, algebra)\nExperience with common data science toolkits, such as TensorFlow, KERAs, PyTorch, PANDAs, Microsoft CNTK, NumPy etc. Deep expertise in at least one of these is highly desirable.\nExperience with NLP, NLG and Large Language Models like BERT, LLaMa, LaMDA, GPT, BLOOM, PaLM, DALL-E, etc.\nGreat communication and presentation skills. Should have experience in working in a fast-paced team culture.\nExperience with AIML and Big Data technologies like AWS SageMaker, Azure Cognitive Services, Google Colab, Jupyter Notebook, Hadoop, PySpark, HIVE, AWS EMR etc.\nExperience with NoSQL databases, such as MongoDB, Cassandra, HBase, Vector databases\nGood understanding of applied statistics skills, such as distributions, statistical testing, regression, etc.\nShould be a data-oriented person with analytical mind and business acumen.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Generative AI', 'Machine Learning', 'Deep Learning', 'Python', 'Azure']",2025-06-12 06:40:51
Gen AI Architect,Alphacom Systems And Solutions,8 - 12 years,20-30 Lacs P.A.,"['Hyderabad', 'Bengaluru', 'Mumbai (All Areas)']","Dear Candidate,\n\nWe are actively hiring for GEN AI position open for PAN India location.\n\nRole Summary\nWe are seeking a seasoned Generative AI Technology Architect to lead the design and implementation of enterprise grade Gen AI solutions This role demands deep technical expertise in AIML a strong architectural mindset and the ability to translate business needs into scalable secure and responsible AI systems You will serve as a thought leader mentor and strategic advisor across AI initiatives\n\nKey Responsibilities\nArchitect end-to-end Gen AI solutions including LLM based applications RAG pipelines and multimodal systems\nDefine and enforce architectural standards design patterns and best practices for Gen AI systems\nLead the evaluation and selection of Gen AI platforms frameworks and infrastructure eg vector DBs orchestration layers model hubs\nCollaborate with data scientists MLOps engineers and business stakeholders to align AI capabilities with enterprise goals\nDrive PoCs and pilots to validate Gen AI use cases and scale successful patterns into production\nEnsure compliance with data privacy security and responsible AI principles\nContribute to internal knowledge assets such as reference architectures whitepapers and reusable components\n\nRequired Skills\nProven experience in designing and deploying AIML systems at scale including Gen AI applications\nDeep understanding of LLMs prompt engineering finetuning and RAG workflows\nProficiency in Python and frameworks like PyTorch TensorFlow Hugging Face LangChain or LlamaIndex\nStrong grasp of cloudnative architectures AWS Azure GCP and containerization Docker Kubernetes\nExperience with MLOps tools MLflow SageMaker Vertex AI etc and CICD for AI pipelines\nFamiliarity with vector databases eg FAISS Pinecone Weaviate and embedding strategies\nShould have understanding of LLM models like Vision MultiModal etc\nStrong Experience in Python programming and related frameworks eg Django Flask\nExtensive experience in building scalable and robust applications using Python\nHandson Experience to all SDLC Phases\nKnowledge of cloud platforms eg AWS Azure GCP and their AIML services\nExperience with database systems eg SQL NoSQL and data modeling\nStrong problem-solving and analytical skills with the ability to translate business requirements into technical solutions\nExcellent leadership and team management skills with the ability to motivate and develop a high performing team Strong communication and collaboration skills with the ability to work effectively in cross functional teams\nSelf-motivated and proactive with a passion for learning and staying up to date with emerging technologies and industry trends\n\nPreferred Qualifications\nBachelors or Masters in Computer Science AI or related field\nExperience integrating Gen AI into enterprise platforms eg ERP CRM HRMS\nExposure to multimodal AI text image audio and agentbased architectures\nStrong communication and stakeholder management skills\nContributions to opensource AI projects or published research\n\nIf interested, kindly share your resume with below details to Richa.Rane@alphacom.in\nFull Name:\nPan Card No:\nDOB:\nTotal Experience:\nRelevant Experience:\nCurrent/Last Company: \nCurrent CTC:\nExpected CTC:\nNotice Period:\nCurrent Location:\nPreferred Location:\nReason for job change:\nShare your passport size photo:\n\nThanks & Regards,\nRicha Rane\nTalent Acquisition\nRicha.Rane@alphacom.in",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Gen AI', 'Artificial Intelligence', 'AI Architect', 'Aiml', 'Tensorflow', 'Pytorch', 'Ai Algorithms', 'Ai Techniques', 'Ai Solutions', 'ai', 'Ai Platform']",2025-06-12 06:40:54
Consultant - Solution Specialist - AI/ML,Affine Analytics,5 - 7 years,Not Disclosed,['Bengaluru'],"As a Solution Specialist, you will collaborate with multiple teams such as sales, delivery & marketing to put forth Affine in front of our clients/partners. This position will give you opportunities to work on a wide range of problems and businesses as a part of the business team. You will often be working closely with senior management including founders and VPs to define solutioning strategies and engagement workflows. The role requires people with a good mix of technical knowledge and business acumen, and who are prepared to learn every day.\nResponsibilities",,,,"['AI/ML', 'Business Intelligence', 'AI/ML Pre-Sales Support', 'AI Solution', 'Advanced Analytics Solutioning', 'Data Visualization']",2025-06-12 06:40:56
Python Technical Lead Developer - Only Male candidates,AM Infoweb,2 - 7 years,Not Disclosed,['Pune( Kalyani Nagar )'],"Job Title: Technical Lead Python Developer\nLocation: Kalyani Nagar, Pune\nShift Timing: 3:00 PM to 12:00 AM IST\nAbout the Role:\nWe are looking for a highly skilled and passionate Python Technical Lead to join our growing team at AM Infoweb. This role is purely backend and hands-on coding focused, and ideal for someone who is not only technically strong but also has the capability to design, architect, and lead backend projects.\n\nAs a Technical Lead, you'll take ownership of the backend architecture, manage complex data-driven systems, and guide the team through technical challenges using best-in-class tools and practices.\n\nKey Responsibilities:\nLead backend development efforts using Python and associated frameworks.\nDesign, develop, and maintain scalable backend architecture for web and AI-based applications.\nArchitect solutions around given datasets and business logic.\nGuide junior developers, conduct code reviews, and ensure best coding practices.\nCollaborate with cross-functional teams including AI engineers, frontend developers, DevOps, and product owners.\nWork with CI/CD pipelines to ensure rapid and stable deployment cycles.\nIntegrate and manage databases such as MySQL, PostgreSQL, and MongoDB.\nDeploy, monitor, and maintain services on AWS and Azure cloud platforms.\n\nTechnical Requirements:\nStrong experience with Python backend frameworks Django, Flask, FastAPI (at least two).\nExperience with relational and non-relational databases MySQL, PostgreSQL, MongoDB.\nSolid understanding of API development, RESTful services, and system architecture.\nExperience working with cloud platforms AWS, Azure.\nFamiliarity with CI/CD tools and DevOps practices.\nStrong problem-solving and communication skills.\n\nPreferred Qualifications:\n6+ years of experience in backend development.\n12 years in a technical leadership role.\nExposure to AI and machine learning integrations is a plus.\nExperience with microservices and containerization (Docker, Kubernetes) is an advantage.\n\nWhat You Get:\nInternational exposure to global projects and clients.\nWork with trending AI tools and intelligent bots.\nOnsite cafeteria and break facilities.\nFun and engaging team events and celebrations.\n\n* Know your organization - https://www.aminfoweb.in/\n* Know your workspace! - https://www.youtube.com/watch?v=T1UKFelepCk\n* Our Annual RNR'2022 - https://www.youtube.com/watch?v=T1UKFelepCk\n* Exploring the myths surrounding outsourced healthcare management - https://www.youtube.com/watch?v=fwf3jFa2T-A",Industry Type: Analytics / KPO / Research,Department: Product Management,"Employment Type: Full Time, Permanent","['Python', 'Data Structures And Algorithms', 'Lead Architect', 'Django', 'Postgresql', 'MySQL', 'FastAPI', 'MongoDB', 'Data Architecture', 'AWS', 'Flask', 'Backend Development']",2025-06-12 06:40:58
AI Engineer,Vichara Technologies,7 - 12 years,50-60 Lacs P.A.,"['Pune', 'Chennai', 'Delhi / NCR']","Use GPT API or Llama to develop custom frameworks for investment management alternate data analysis\nUse Orchestration tools like N8n for document ingestion\nSetup on cloud or private using Coreweave\nLead Machine Learning and UI Engineers\n\nRequired Candidate profile\n5+ years of development experience in .NET , Python and Azure\n3+ years of experience in Data Science along with hands on GenAI and LLMs\nExperience with VectorDB, documentation ingestion workflows etc.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['LLM', 'Tesseract', 'agentic AI', 'Llamaindex', 'Python', 'Tensorflow', 'Generative Ai', 'Coreweave', 'Cognitive Services', 'Image Recognition', 'Chatbot', 'Azure OpenAI', 'Document intelligence', 'Azure Bot Framework', 'Azure Functions', '.NET', 'React.Js', 'Microsoft Bot Framework', 'Azure Cognitive Services', 'OCR']",2025-06-12 06:41:00
"AI Technical Lead Openings at Advantum Health, Hyderabad",Advantum Health,7 - 8 years,Not Disclosed,['Hyderabad'],"AI Technical Lead openings at Advantum Health Pvt Ltd, Hyderabad.\nOverview:\nWe are seeking an experienced AI Technical Lead to drive the architecture, development, and deployment of advanced AI and machine learning solutions, with a strong focus on healthcare and revenue cycle automation. You will oversee a cross-functional team to design intelligent systems, guide technical decisions, and ensure successful delivery of AI-enabled products.\nKey Responsibilities:\nLead the design and development of scalable AI/ML solutions for healthcare automation and RCM workflows.\nCollaborate with stakeholders to translate business requirements into machine learning problems.\nProvide technical leadership on model selection, training, evaluation, and deployment.\nMentor a team of data scientists, engineers, and developers.\nEnsure model governance, version control, auditability, and ethical use of AI.\nEvaluate emerging technologies and make recommendations for adoption.\nQualifications:\nBachelors or Masters in Computer Science, AI, or related field.\n7+ years of experience in software development; 3+ in AI/ML leadership.\nProven experience deploying AI models in production (e.g., NLP, computer vision, anomaly detection).\nProficiency in Python, Tensorflow, Pytorch, and cloud-based AI platforms.\nStrong knowledge of RCM or healthcare data preferred.\nPh: 9177078628\nEmail id: jobs@advantumhealth.com\nAddress: Advantum Health Private Limited, Cyber gateway, Block C, 4th floor Hitech City, Hyderabad.\nDo follow us on LinkedIn, Facebook, Instagram, YouTube and Threads\nAdvantum Health LinkedIn Page:\nhttps://lnkd.in/gVcQAXK3\n\nAdvantum Health Facebook Page:\nhttps://lnkd.in/g7ARQ378\n\nAdvantum Health Instagram Page:\nhttps://lnkd.in/gtQnB_Gc\n\nAdvantum Health India YouTube link:\nhttps://lnkd.in/g_AxPaPp\n\nAdvantum Health Threads link:\nhttps://lnkd.in/gyq73iQ6",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pytorch', 'Tensorflow', 'Python']",2025-06-12 06:41:02
Gen AI Architect,client of edge,9 - 12 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","The Company\nIndia's marquee global technology & consulting company. They are an international flag-bearer of technical and managerial excellence. With offices around the globe, the company has a comprehensive presence across multiple segments of the technology product and service industries as well as a blue-chip roster of clients for their Consulting engagements. They are a respected career company and a long-term wealth creator.\nThe Job\nWe are seeking a highly skilled Generative AI Architect with 10+ Years of IT industry experience in which 5/6 years should be in AI/ML/DS domain, including Gen AI technologies to lead the design and deployment of cutting-edge AI solutions. The ideal candidate will possess deep expertise in Generative AI, strong analytical skills, and excellent communication abilities to engage with clients and internal teams. This role involves designing AI architectures, implementing scalable models, and ensuring solutions align with business objectives.\nKey Responsibilities\nCollaborate with clients to understand AI project needs and define measurable success metrics\nDesign end-to-end Generative AI solutions with a focus on performance, security, and ethical AI\nDevelop models using GANs, VAEs, NLP transformers, and other generative techniques\nImplement AI solutions utilizing cloud platforms (AWS, Azure, GCP) and ML frameworks (TensorFlow, PyTorch, LangChain, Semantic Kernels)\nEnsure compliance with Responsible AI and Data Privacy principles, mitigating bias and ensuring ethical AI practices\nWork alongside engineers and data scientists to integrate and optimize AI models into real-world applications\nConduct performance monitoring, troubleshooting, and continuous improvements for AI systems\nStay updated with AI advancements and share knowledge with internal teams\nYour Profile\nPrimary Skills\nExpertise in Generative AI techniques, including image generation, text synthesis, and function calling\nStrong understanding of AI/ML algorithms, cloud computing, NLP, and computer vision\nProficiency in data science tools (NumPy, SciPy, Pandas, Matplotlib, TensorFlow, Keras)\nSolid grasp of Responsible AI, fairness in algorithms, and bias mitigation strategies\nExcellent communication and solution design skills, capable of translating business needs into technical AI architectures.\nSecondary Skills\nKnowledge of industry-specific AI applications (healthcare, finance, manufacturing, etc.)\nBasic project management abilities to oversee timelines and deliverables\nFoundational data preprocessing and quality assurance expertise",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Genrative Ai', 'Natural Language Processing', 'Python', 'Computer Vision', 'Solution Design', 'Ml']",2025-06-12 06:41:05
AI/ML Architect @ Bangalore_Urgent,"A leader in this space, we deliver world...",10 - 15 years,Not Disclosed,['Bengaluru'],"AI/ML Architect\n\nExperience\n10+ years in total, 8+ years in AI/ML development\n3+ years in AI/ML architecture\nEducation\nBachelors/Masters in CS, AI/ML, Engineering, or similar\n\nTitle: AI/ML Architect\nLocation: Onsite Bangalore\nExperience: 10+ years\nPosition Summary:\nWe are seeking an experienced AI/ML Architect to lead the design and deployment of scalable AI solutions. This role requires a strong blend of technical depth, systems thinking, and leadership in machine learning, computer vision, and real-time analytics. You will drive the architecture for edge, on-prem, and cloud-based AI systems, integrating 3rd party data sources, sensor and vision data to enable predictive, prescriptive, and autonomous operations across industrial environments.\nKey Responsibilities:\nArchitecture & Strategy\nDefine the end-to-end architecture for AI/ML systems including time series forecasting, computer vision, and real-time classification.\nDesign scalable ML pipelines (training, validation, deployment, retraining) using MLOps best practices.\nArchitect hybrid deployment models supporting both cloud and edge inference for low-latency processing.\nModel Integration\nGuide the integration of ML models into the IIoT platform for real-time insights, alerting, and decision support.\nSupport model fusion strategies combining disparate data sources, sensor streams with visual data (e.g., object detection + telemetry + 3rd party data ingestion).\nMLOps & Engineering\nDefine and implement ML lifecycle tooling, including version control, CI/CD, experiment tracking, and drift detection.\nEnsure compliance, security, and auditability of deployed ML models.\nCollaboration & Leadership\nCollaborate with Data Scientists, ML Engineers, DevOps, Platform, and Product teams to align AI efforts with business goals.\nMentor engineering and data teams in AI system design, optimization, and deployment strategies.\nStay ahead of AI research and industrial best practices; evaluate and recommend emerging technologies (e.g., LLMs, vision transformers, foundation models).\nMust-Have Qualifications:\nBachelors or Master’s degree in Computer Science, AI/ML, Engineering, or a related technical field.\n8+ years of experience in AI/ML development, with 3+ years in architecting AI solutions at scale.\nDeep understanding of ML frameworks (TensorFlow, PyTorch), time series modeling, and computer vision.\nProven experience with object detection, facial recognition, intrusion detection, and anomaly detection in video or sensor environments.\nExperience in MLOps (MLflow, TFX, Kubeflow, SageMaker, etc.) and model deployment on Kubernetes/Docker.\nProficiency in edge AI (Jetson, Coral TPU, OpenVINO) and cloud platforms (AWS, Azure, GCP).\nNice-to-Have Skills:\nKnowledge of stream processing (Kafka, Spark Streaming, Flink).\nFamiliarity with OT systems and IIoT protocols (MQTT, OPC-UA).\nUnderstanding of regulatory and safety compliance in AI/vision for industrial settings.\nExperience with charts, dashboards, and integrating AI with front-end systems (e.g., alerts, maps, command center UIs).\nRole Impact:\nAs AI/ML Architect, you will shape the intelligence layer of our IIoT platform — enabling smarter, safer, and more efficient industrial operations through AI. You will bridge research and real-world impact, ensuring our AI stack is scalable, explainable, and production-grade from day one.",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI/ML architecture', 'cloud', 'PyTorch', 'TensorFlow', 'time series modeling', 'MLflow', 'object detection', 'anomaly detection', 'Kubeflow', 'Docker', 'OpenVINO', 'MLOps tools', 'AWS', 'facial', 'Azure', 'TFX', 'IIoT platforms', 'SageMaker', 'intrusion', 'CI/CD pipelines', 'GCP', 'Jetson', 'Coral', 'computer vision', 'edge AI', 'Kubernetes']",2025-06-12 06:41:08
R Analytics Lead,Smartavya Analytica,6 - 11 years,Not Disclosed,"['Chennai', 'Mumbai (All Areas)']","Department: Business Analytics\nJob Overview:\nWe are seeking a talented R Analytics to join our analytics team.\nThe ideal candidate will possess a strong background in data analysis, statistical modeling, and proficiency in the R programming language.\nYou will be responsible for analyzing complex datasets, providing insights, and developing statistical models to support business decisions.",,,,"['R Studio', 'Shiny', 'SQL', 'data analysis', 'hypothesis testing', 'Time Series Analysis', 'Database Management', 'Data Visualization', 'statistical modeling']",2025-06-12 06:41:10
IT OPS Consultant- EMS & Observability,Leading MNC,7 - 10 years,Not Disclosed,"['Bangalore Rural', 'Bengaluru']","Role & responsibilities:\n\nDesign end-to-end monitoring and observability solutions to provide comprehensive visibility into infrastructure, applications, and networks.\nImplement monitoring tools and frameworks (e.g., Prometheus, Grafana, OpsRamp, Dynatrace, New Relic) to track key performance indicators and system health metrics.\nIntegration of monitoring and observability solutions with IT Service Management Tools.\nDevelop and deploy dashboards, alerts, and reports to proactively identify and address system performance issues.\nArchitect scalable observability solutions to support hybrid and multi-cloud environments.\nCollaborate with infrastructure, development, and DevOps teams to ensure seamless integration of monitoring systems into CI/CD pipelines.\nContinuously optimize monitoring configurations and thresholds to minimize noise and improve incident detection accuracy.\nAutomate alerting, remediation, and reporting processes to enhance operational efficiency.\nUtilize AIOps and machine learning capabilities for intelligent incident management and predictive analytics.\nWork closely with business stakeholders to define monitoring requirements and success metrics.\nDocument monitoring architectures, configurations, and operational procedures.\nRequired Skills:\nStrong understanding of infrastructure and platform development principles and experience with programming languages such as Python, Ansible, for developing custom scripts.\nStrong knowledge of monitoring frameworks, logging systems (ELK stack, Fluentd), and tracing tools (Jaeger, Zipkin) along with the OpenSource solutions like Prometheus, Grafana.\nExtensive experience with monitoring and observability solutions such as OpsRamp, Dynatrace, New Relic, must have worked with ITSM integration (e.g. integration with ServiceNow, BMC remedy, etc.)\nWorking experience with RESTful APIs and understanding of API integration with the monitoring tools.\nFamiliarity with AIOps and machine learning techniques for anomaly detection and incident prediction.\nKnowledge of ITIL processes and Service Management frameworks.\nFamiliarity with security monitoring and compliance requirements.\nExcellent analytical and problem-solving skills, ability to debug and troubleshoot complex automation issues\n\nCVs to angel@anveta,com",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['observability', 'Monitoring', 'Python', 'ansible']",2025-06-12 06:41:12
Technical Lead (Java),Prodapt Solutions,6 - 10 years,Not Disclosed,"['Chennai', 'Guindy']","Overview\n\n:\nWe are seeking an experienced Technical Lead with a strong background in Java software development . The ideal candidate should possess hands-on coding expertise , architectural understanding , and leadership abilities to drive development teams in building scalable and high-performance applications . This role involves technical mentorship, solution architecture, and ensuring best development practices are followed.\n\nResponsibilities\n\nRoles and Responsibilities:\n1. Technical Leadership & Solution Architecture\nDefine technical architecture and design for Java-based applications.\nProvide technical direction and mentor software engineers.\nConduct code reviews to ensure high-quality standards.\nDefine best practices for development, security, and performance optimization .\nGuide the migration of legacy applications to modern frameworks .\n\n2. Software Development & Deployment\nDesign, develop, and maintain scalable Java microservices .\nWork on database architecture & optimization .\nImplement automated CI/CD pipelines for seamless deployments.\nOptimize backend performance, caching, and data processing .\n\n3. Cross-Team Collaboration\nWork closely with Product Owners, UX/UI Designers, and DevOps .\nCollaborate with Cloud, Security, and Data Engineering Teams .\nEnsure alignment with business goals & technical feasibility .\n\n4. Cloud & DevOps Implementation\nDeploy applications to AWS, Azure, or GCP using containerization (Docker, Kubernetes) .\nManage scalability, monitoring, and logging (Azure Monitor, AWS CloudWatch, Prometheus, ELK Stack) .\nAutomate infrastructure provisioning & cloud resource management .\n\n5. Agile & Team Management\nParticipate in sprint planning, standups, retrospectives .\nTrack and manage work using JIRA, Trello, or Azure DevOps .\nTrain and mentor junior developers and ensure knowledge sharing.\n\nPrimary\n\nSkills:\nCore Java, Java 8+ (or latest version)\nSpring Boot, Spring Framework (Spring MVC, Spring Security, Spring Cloud)\nMicroservices Architecture & API Development\nRESTful Web Services, GraphQL (optional but preferred)\nDatabase Management (MySQL, PostgreSQL, MongoDB)\nMessage Brokers (Kafka, RabbitMQ)\nCloud Services (AWS, Azure, GCP Any one preferred)\nDevOps & CI/CD (Docker, Kubernetes, Jenkins, GitHub Actions, Terraform)\nSecurity & Authentication (OAuth2, JWT, SSO, OpenID)\nPerformance Optimization & System Scalability\n\nSecondary\n\nSkills:\nFrontend Framework Knowledge (React.js, Angular, or Vue.js)\nContainerization & Orchestration (Docker, Kubernetes)\nEvent-Driven Architecture (Kafka, RabbitMQ, ActiveMQ)\nInfrastructure as Code (Terraform, CloudFormation)\nUnit Testing & Automation (JUnit, Mockito, Cypress)\nAgile & Scrum Practices (JIRA, Confluence, Standups, Sprint Planning)\nTechnical Documentation & Architectural Design Patterns\nAI & Machine Learning Basics (Optional but good to have)",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['microservices', 'spring', 'java', 'spring cloud', 'spring boot', 'continuous integration', 'kubernetes', 'ci/cd', 'mockito', 'docker', 'react.js', 'spring mvc', 'devops', 'jenkins', 'api', 'jira', 'rest', 'junit', 'software development', 'microsoft azure', 'rabbitmq', 'spring security', 'kafka', 'terraform', 'agile', 'aws']",2025-06-12 06:41:15
DERM : Human Resource : Pune : 15 LPA : Apply Now,Leading ITES Company,10 - 15 years,10-15 Lacs P.A.,['Pune'],"Hi,\nWe are hiring for the ITES Company for the DERM Human Resource Role.\n\nOverview\nThe DERM Human Resource role focuses on driving transformation, process improvement, and delivery excellence across HR operations (HRO), finance (FAO), and supply chain (SCM) functions. With experience in Lean Six Sigma or transformation roles, the professional leads continuous improvement initiatives using LSS methodologies, automation, and digital technologies such as data analytics, AI, and ML. Key responsibilities include mentoring improvement projects, engaging stakeholders, conducting thought leadership workshops, managing risk and delivering measurable business value. The role requires strong certification credentials (e.g., LSS Green Belt, PMP, Agile).\nKey Skills:\n\na) Overall 10+ plus years of work experience with Exposure to Service industry is must\nb) Atleast 4 years of experience as Lean Six Sigma or Transformation professional for Finance and Accounts, SCM, HRO processes is must\nc) Six Sigma Black Belt Certification is Preferred\nd) MCOM, MBA in Finance, CA/ICWA or Engineering background\nTo Apply, WhatsApp 'Hi' @ 9151555419\n\nFollow the Steps Below:\n>Click on Start option to Apply and fill the details\n>Select the location as Other (to get multiple location option)\na)To Apply for above Job Role (Pune) Type : Job Code # 37\n\nJob Description\nOverall 10+ plus years of work experience with proven expertise in business problem solving and delivering significant business value to the clients and internal stakeholders. Exposure to Service industry is must.\nAtleast 4 years of experience as Lean Six Sigma or Transformation professional for FAO, SCM, HRO processes is must\nShould be able to demonstrate experience in practical application of Lean Six Sigma techniques, Automation, etc. Experience in deploying Data analytics, Machine learning, Artificial Intelligence, etc would be an advantage\nLSS Green belt must. QMS, Black Belt, Master Black belt, Agile, Digital competencies and PMP certifications would be an advantage.\nConduct Thought leadership workshops and develop continuous improvement roadmap for the associated client accounts.\nLead & mentor Process Improvement projects leveraging Lean Six Sigma methodologies to deliver targeted Business value and productivity improvements.\nBuild and develop competencies on Quality Management Systems, Lean Six Sigma and digital transformation techniques.\nDrive innovation and automation projects to deliver award winning case studies in internal and external forums.\nDrive effective No Surprise framework to ensure process risks are proactively identified and mitigated for the associated client accounts.\nEffectively engage with clients and internal stakeholders to ensure Delivery Excellence Initiatives are effectively deployed and recognized.\nEducational Requirements: MCOM, MBA in Finance, CA/ICWA or Engineering background with proven black belt or transformation expertise in FAO,SCM,HRO processes\nShift: Willing to work in all shifts (currently afternoon shift) and willing to travel to any location as per client/organization requirements.",Industry Type: BPM / BPO,Department: Human Resources,"Employment Type: Full Time, Permanent","['Wipro', 'Genpact', 'Quality Management', 'Black Belt', 'Infosys', 'Cognizant', 'Accenture', 'Artificial Intelligence', 'HR Operations', 'Data analytics', 'Lean Six Sigma', 'Human Resource', 'PMP', 'Green Belt', 'FAO', 'Finance And Accounts', 'Master Black Belt', 'Business Excellence', 'Derm', 'SCM', 'Amazon', 'WNS', 'PwC']",2025-06-12 06:41:18
Senior Manager - Global HEOR Economic Modeling Leader,Amgen Inc,2 - 7 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will serve as an operational and technical leader responsible for overseeing a team of Global HEOR Economic Modelers. This role ensures the development of innovative, scientifically rigorous, and high-quality economic models supporting Amgens global market access and pricing strategies. The position requires close collaboration with Global HEOR TA Heads to align health economics deliverables with product strategies.\nLead, mentor, and develop a team of Global HEOR Economic Modelers to ensure dedication and continuous professional growth.\nProvide technical direction and oversight for the development of economic models, including cost-effectiveness/cost-utility (e.g., markov, partitioned survival model), cost minimization, budget impact, and other techniques, as appropriate.\nDrive innovation and standardization in health economic modeling methodologies across portfolio.\nEnsure alignment of modeling activities with HEOR TA Heads and product strategies.\nMaintain expert-level understanding of global HTA requirements and evolving payer needs, integrating them into the teams economic modeling approaches.\nOversee model documentation and ensure quality control and compliance with internal and external standards.\nContribute to hiring, training, and performance evaluations within the team.\nContinuously improve workflows, tools, and methodologies to enhance efficiency and quality of work.\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The Economic Modeling Leader we seek should possess these qualifications.\nBasic Qualifications:\nDoctorate degree in Health Economics, Econometry, Biostatistics, Mathematics, Engineering or a related field and 2 years of experience in health economic modeling within the pharmaceutical, biotechnology, or consulting sectors OR,\nMasters degree in Health Economics, Econometry, Biostatistics, Mathematics, Engineering or a related field and 8 to 10 years of experience in health economic modeling within the pharmaceutical, biotechnology, or consulting sectors OR,\nBachelors degree in Health Economics, Econometry, Biostatistics, Mathematics, Engineering or a related field and 10 to 14 years of experience in health economic modeling within the pharmaceutical, biotechnology, or consulting sectors OR,\nDiploma in Health Economics, Econometry, Biostatistics, Mathematics, Engineering or a related field and 14 to 18 years of experience in health economic modeling within the pharmaceutical, biotechnology, or consulting sectors\n3+ years of experience in team management capacity.\nConsistent track record of supporting HTA submissions and payer evidence generation globally.\nExpert proficiency with modeling and statistical tools such as Excel, R, SAS, or STATA.\nSkills & Competencies:\nStrong leadership and key customer engagement skills.\nExcellent English oral and written communication, with ability to tailor content to different customers.\nAdvanced quantitative and analytical abilities with exceptional attention to detail.\nDeep knowledge of HTA processes and payer landscapes across major markets.\nInnovative use of artificial intelligence to boost efficiency.\nOrganizational Behaviors:\nProactive leadership with a collaborative approach.\nComfortable working in a distributed team across time zones and cultures.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['key customer engagement', 'HTA processes', 'R', 'team management', 'SAS', 'STATA', 'artificial intelligence']",2025-06-12 06:41:20
Senior MERN Stack Developer,Morae Services,5 - 10 years,Not Disclosed,['Bengaluru'],"MERN Stack Developer (Product-Based Role MorAI)\n\nLocation: Bengaluru, IN(Hybrid)\nExperience Level: Mid\nType: Full-time\n\nAbout Morae\n\nMorae is a global leader in legal and compliance technology solutions. Our latest innovation, MorAI, is an advanced Generative AI-powered suite designed to transform legal and compliance operations.\n\nMorAI leverages cutting-edge artificial intelligence to streamline legal workflows, automate document analysis, enhance contract management, and ensure regulatory compliance. By combining AI-driven insights with industry best practices, MorAI helps corporate legal departments, compliance teams, and law firms increase efficiency, reduce risks, and improve decision-making.\n\nWe are looking for a MERN Stack Developer to join our product development team and play a key role in building and optimizing MorAIs scalable, high-performance AI-driven legal solutions.\n\nResponsibilities\n• Develop and maintain scalable, high-performance applications using MongoDB, Express.js, React.js, and Node.js.\n• Collaborate with AI/ML teams to integrate Generative AI-driven features into MorAI.\n• Build and optimize secure, efficient APIs to support legal automation and compliance workflows.\n• Work closely with product managers, designers, and AI engineers to enhance platform capabilities.\n• Ensure a seamless and intuitive user experience with modern UI/UX best practices.\n• Implement authentication, authorization, and role-based access controls for secure legal applications.\n• Optimize database performance, indexing, and aggregation in MongoDB.\n• Maintain code quality, documentation, and unit testing to ensure reliability and scalability.\n\nRequirements\n3+ years of experience as a MERN Developer in a product-based environment.\nStrong proficiency in React.js, Redux, Hooks, Context API for front-end development.\nHands-on experience with Node.js, Express.js, and building RESTful APIs.\nSolid understanding of MongoDB (Aggregation, Indexing, Optimization).\nKnowledge of GraphQL (Preferred but not mandatory).\nFamiliarity with cloud platforms (AWS, Azure) and CI/CD pipelines.\nExperience with authentication (JWT, OAuth) and security best practices.\nUnderstanding of microservices architecture and containerization (Docker, Kubernetes nice to have).\nStrong problem-solving skills and ability to work in an Agile environment.\n\nPreferred Skills\nExperience working with next JS and nest JS in production.\nKnowledge of LLMs (Large Language Models) and AI-powered APIs (OpenAI, LangChain).\nExposure to legal tech or compliance platforms.\n\nWhy Join Us?\nWork on cutting-edge AI-powered products that are revolutionizing legal and compliance operations.\nJoin a global, innovative team shaping the future of legal tech.\nBe part of a product-based company building scalable and impactful solutions.\nCompetitive salary, flexible work culture, and exciting challenges every day",Industry Type: Legal,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Mern Stack', 'Express', 'Node.Js', 'MongoDB', 'React.Js']",2025-06-12 06:41:23
"Account Executive, AI",Cisco,7 - 9 years,Not Disclosed,['Bengaluru'],"Meet the Team\nThis Internet and Mass-Scale Infrastructure (I&MI) Account Executive (AE) must be able to develop strong working relationships with Sales Leaders, Account Managers, and Engineers to ensure alignment of sales strategies for I&MI technology and overall Cisco business within our customers environments.??Additionally, the Account Executive needs to be able to engage resources, including the I&MI business units, marketing, and Cisco partners to drive the overall growth of the technology within their assigned territory.?\nYour Impact?\nYou will be responsible for driving optics, service provider routing, optical, and automation sales to?customers building large-scale?Artificial Intelligence (AI) networks and AI Infrastructure. You must be able to develop strong relationships with key customers, including at the executive level, to understand customer business drivers and influence their tactical and strategic plans and how Cisco can help solve these challenges and support their goals. You will be accountable for leading new and emerging customers through major architecture transitions to support AI service offerings. You will work closely with the Cisco team members and partners to capture and acceleratenew franchises.\n\nYou will build a complete business plan which to drive the business and exceed your goals. Extensive knowledge of Cisco optics, optical, and routing offers is needed for success in this role.\nUnderstanding competitors solutions in these areas is also critical. You must have an understanding of the growing data centre environment including Ethernet and Infiniband. You have a proven success record in developing new sales strategies, hunting new accounts and establishing strong new relationships. Your capabilities should include opportunity discovery, forecasting, excellent presentation skills, and short-term, mid-term, and long-term opportunity management skills.\nStrong spoken and verbal communication skills are essential. You will display strong time management skills, an ability to prioritise multiple tasks and opportunities, and generate product demand at large scale.\nMinimum Qualifications\n7+ years of sales experience in a fast-paced, high-technology environment.\nUnderstanding and experience with optics and optical networking is required\nUnderstanding and experience with routing technologies is required\nUnderstanding of switching, front-end and back-end AI networking is required\nUnderstanding and experience with automation and assurance solutions is a plus\nPreferred Qualifications\nBusiness planning skills\nAn autonomous work ethic\nAn innate ability to work effectively in a large, matrixed organization\nBA/BS degree or equivalent experience",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Accounting', 'automation', 'time management', 'Business planning', 'AI networking', 'sales']",2025-06-12 06:41:25
Java Backend Developer - Kotlin,Sadup Soft,5 - 10 years,Not Disclosed,"['Chennai', 'Delhi / NCR', 'Bengaluru']","We are seeking a talented Java backend Software Engineer with expertise in software engineering to join our team. As a Full Stack Software Engineer, your primary responsibility will be to develop & integrate Generative AI solutions that focus on technology improvements. Specifically, you will be working on projects involving Generative AI solutions for Technology Assistants & Data Management Efficiencies and will contribute for Java backend development such as IDE plugins Data Connections & Integrators.\n\nResponsibilities :\n\n- Collaborate with cross-functional teams such as Data Scientists, Product Partners and Partner Team Developers to identify opportunities for process improvements that can be solved using machine learning and generative AI.\n\n- Write clean, high-performance, high-quality, maintainable code.\n\n- Create connectors to various Content and Collaboration tools using tool specific API's such as Jira, Slack, Git etc\n\n- Create backend applications using Java, docker & in-house frameworks to orchestrate AI applications\n\n- Design and develop Engineering Solutions & generative AI Applications for above ensuring scalability, efficiency, and maintainability of such solutions.\n\n- Implement prompt engineering techniques to fine-tune and enhance LLMs for better performance and application-specific needs.\n\n- Stay abreast of the latest advancements in the field of Generative AI Application Development and actively contribute to the research and development of new Generative AI Applications.\n\nRequirements:\n\n- A Master's or Ph.D. degree in Computer Science or a related field.\n\n- Proven experience working as a Software Engineer, with a focus on Java, and exposure to Generative AI Applications such as chatGPT.\n\n- Strong proficiency in programming languages such as Java, Kotlin, Scala etc ( Mandatory)\n\n- Experience or Exposure in creating IDE Plugins for PyCharm, VS Code, IntelliJ & Web Consoles ( Nice to have )\n\n- Experience in python and data pipelines ( nice to have)\n\n- Solid knowledge of software engineering best practices, including version control systems (e.g., Git), code reviews, and testing methodologies.\n\n- Experience with large language models (LLMs) & prompt engineering techniques, vector DB's ( Nice to have )\n\n- Strong communication skills to effectively collaborate and present findings to both technical and non-technical stakeholders.\n\n- Proven ability to adapt and learn new technologies and frameworks quickly.\n\n- A proactive mindset with a passion for continuous learning and research.\nLocation: Delhi NCR,Bangalore,Chennai,Pune,Kolkata,Ahmedabad,Mumbai,Hyderabad",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Java', 'Application Designing', 'Prompt Engineering', 'Generative AI', 'ChatGPT', 'Full Stack', 'LLM', 'Kotlin', 'Python']",2025-06-12 06:41:28
Program Management Lead ( Sr TSG Operations Lead ),HMH,8 - 10 years,Not Disclosed,['Pune'],"Our Technology Solutions Group (TSG) is driving the development of next-generation services by leveraging modern cloud platform development technologies and cutting-edge technologies, including microservices, progressive web apps, advanced data platforms, machine learning, and cloud-native solutions.\n\nOverview:\nAs Program Management Lead within our Technology Solutions Group (TSG), you will support the Senior Director of Portfolio, Planning and Program Governance by providing cross-portfolio delivery insight, driving alignment across scrum teams, and enabling the consistent delivery of high-priority initiatives. You will focus on enhancing the TSG Operations, which include delivery visibility, supporting governance and portfolio planning, and facilitating coordination across multiple product and engineering teams.",,,,"['Program Management', 'product lifecycle planning', 'stakeholder engagement', 'documentation', 'Program Management Lead', 'agile software delivery']",2025-06-12 06:41:30
Solution Designer / BA with Lead To Cash & Telecom Domain,Prodapt Solutions,4 - 8 years,Not Disclosed,['Chennai'],"Overview\n\nProdapt is looking for a Solution Designer / Business Analyst, who is a highly specialized professional who possesses in-depth knowledge and expertise in designing, implementing, managing, and troubleshooting networks.\n\nNeed Solution designer, Business Analyst with telecom domain experience.\nShould have handson in Lead to Cash journey - Processes and Systems for Cellular Mobile service for Enterprise or End to End VPN service for Enterprise, Non-Terrestrial Network, Cloud PBX.\nShould have solid understanding on different Service Fulfilment journey metrics.\nShould have solid understanding of different OSS applications that support Lead to Cash journey.\nShould have conducted workshops to gather requirements from stakeholders, presenting different solution options to architects.\nExposure to deriving insights using data, identify improvements in the journey/processes, propose solutions on the identified improvement areas and provide consulting service to the telecom service providers is desirable.\n\nResponsibilities\n\n*Following Network OSS applications knowledge is mandatory - Inventory management (Service inventory/Physical inventory), Provisioning & Activation Syetem, Element Management System, Network performance management (monitoring, collecting data, reporting), Order orchestration. Knowledge on Network Monitoring System, Test & Diagnostics application, Incident and Change management system is desirable.\nServiceNow TNI module is mandatory (Telecom Network Inventory).\nKnowledge on Telecom Access/Backhaul network, different network topologies, different network nodes for 5G Mobile service or VPN services or Non-Terrestrial Network or Cloud PBX is mandatory.\nKnowledge on CRM/BPM systems is optional. Knowledge on Salesforce, ServiceNow is optional.\nAbility to use telecoms, IT and enterprise architecture best practice methodologies, processes, functions, and data maps.\nTechnical specialist skills in software design and implementations, with experience of cloud and on-premises systems architecture\ngathering for creating OSS service and solution design; Accountable for ensuring project delivery of multi-domain OSS solutions.\nAbility to define and articulate complex architectures to non-technical stakeholders.\nProduce and support the production of High Level Designs, Low Level Designs, test plans, Deployment Guidelines and TTO`s.\nWork in cross-functional delivery teams including partners and vendors to support delivery throughout the delivery lifecycle and ensure solutions are delivered into production on time and meet the operational acceptance criteria.\nWork closely with Network Design, Systems Development, Testing team, E2E Solution Architects, Operations teams.\nKnowledge on APIs, Frameworx, Microservices, UML, TOSCA, NetConf/YANG, CI/CD, REST/Webservices, JSON, Postman, Agile Development is needed.\nFunctional DomainsAdvanced knowledge in atleast one listed belowNetwork Service LCM, Network Orchestration/MANO, Telemetry/RCA 5G, AI/ML, OTT domain knowledge is a plus.\nEnsure the delivery of the solutions conforms to contractual outcomes and timescales.\nSupport the Programme and Project Manager in project planning, risk and issue management and the budgeting process.\nExperience in working in Service Fulfilment related proposals.\nPerformed the role of team lead (leading a team of atleast 4 members) is desirable.\n\n\nAbility to work with stakeholders to create and define problem statements and root cause analysis.\nCreate and gather requirements from stakeholders, draw process diagrams, write user stories, ensuring documentation is complete, understandable, and unambiguous.\nValidation of the documentation with stakeholders.\nCapture and report back essential information from meetings.\nFamiliar with Agile principles and in using JIRA or ServiceNow SPM tool knowledge.\nUse of collaboration and presentation tools like Mural.\nMinimum Educational LevelBachelor Degree.\nMin Experience (Years):8\nMax Experience (Years):18",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['5g', 'telecom', 'tni', 'cloud telephony', 'network topologies', 'continuous integration', 'web services', 'ci/cd', 'artificial intelligence', 'change management', 'microservices', 'salesforce', 'postman', 'uml', 'json', 'netconf', 'api', 'jira', 'crm', 'ml', 'tosca', 'rest', 'aiml', 'node', 'servicenow', 'vpn', 'agile']",2025-06-12 06:41:33
Python Developer,IDFC FIRST Bank,3 - 6 years,8-18 Lacs P.A.,['Chennai'],"Required Qualifications, Capabilities, and Skills:\nSolid understanding of backend performance optimization and debugging.\nFormal training or certification on software engineering concepts and proficient applied experience • Strong hands-on experience with Python\nExperience in developing microservices using Python with FastAPI.\nCommercial experience in both backend and frontend engineering\nHands-on experience with AWS Cloud-based applications development, including EC2, ECS, EKS, Lambda, SQS, SNS, RDS Aurora MySQL & Postgres, DynamoDB, EMR, and Kinesis.\nStrong engineering background in machine learning, deep learning, and neural networks.\nExperience with containerized stack using Kubernetes or ECS for development, deployment, and configuration\n.Experience with Single Sign-On/OIDC integration and a deep understanding of OAuth, JWT/JWE/JWS.\nKnowledge of AWS SageMaker and data analytics tools.\nProficiency in frameworks TensorFlow, PyTorch, or similar. Preferred Qualifications, Capabilities, and Skills:\nFamiliarity with LangChain, Langgraph, or any Agentic Frameworks is a strong plus.\nPython engineering experience.",Industry Type: Banking,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Agentic Ai', 'python', 'Fast Api', 'Tensorflow', 'Pytorch', 'GenAI', 'Genrative Ai', 'Langchain', 'Langgraph']",2025-06-12 06:41:35
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Lucknow'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI development', 'deep learning', 'python', 'data science', 'natural language processing', 'AI research', 'machine learning', 'artificial intelligence']",2025-06-12 06:41:37
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Lucknow'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy.\nDesign and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson.\nEnsure seamless chatbot integration with existing platforms and CRM systems.\nWork closely with data scientists to improve machine learning models.\nMust have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Chatbot Development', 'deep learning', 'chatbot', 'python', 'r', 'data analytics', 'predictive modeling', 'machine learning', 'artificial intelligence', 'chatbot analytics']",2025-06-12 06:41:40
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Surat'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy. Design and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson. Ensure seamless chatbot integration with existing platforms and CRM systems. Work closely with data scientists to improve machine learning models. Must have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['artificial intelligence', 'deep learning', 'chatbot integration', 'Python', 'CRM systems', 'chatbot analytics']",2025-06-12 06:41:42
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Patna'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy. Design and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson. Ensure seamless chatbot integration with existing platforms and CRM systems. Work closely with data scientists to improve machine learning models. Must have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['artificial intelligence', 'deep learning', 'chatbot integration', 'Python', 'CRM systems', 'chatbot analytics']",2025-06-12 06:41:44
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Agra'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy.\nDesign and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson.\nEnsure seamless chatbot integration with existing platforms and CRM systems.\nWork closely with data scientists to improve machine learning models.\nMust have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Chatbot Development', 'deep learning', 'chatbot', 'python', 'r', 'data analytics', 'predictive modeling', 'machine learning', 'artificial intelligence', 'chatbot analytics']",2025-06-12 06:41:46
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Mysuru'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy. Design and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson. Ensure seamless chatbot integration with existing platforms and CRM systems. Work closely with data scientists to improve machine learning models. Must have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['artificial intelligence', 'deep learning', 'chatbot integration', 'Python', 'CRM systems', 'chatbot analytics']",2025-06-12 06:41:48
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Agra'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI development', 'deep learning', 'python', 'data science', 'natural language processing', 'AI research', 'machine learning', 'artificial intelligence']",2025-06-12 06:41:51
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Chandigarh'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy.\nDesign and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson.\nEnsure seamless chatbot integration with existing platforms and CRM systems.\nWork closely with data scientists to improve machine learning models.\nMust have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['AI', 'deep learning techniques', 'Rasa', 'NLP algorithms', 'Dialogflow', 'Python', 'chatbot analytics']",2025-06-12 06:41:53
"Product Manager, AI",Conga,3 - 5 years,Not Disclosed,['Bengaluru( Kadubeesanahalli )'],"Job Title: Product Manager\nLocation: Bangalore\nReports to: Manager, Product Management\n\nA quick snapshot\n\nAs a Product Manager on the Conga Discovery AI team, you will help define, build, and launch AI-driven metadata extraction solutions on top of the Conga platform. Youll bring your experience in AIand ideally Contract Lifecycle Management (CLM)—to shape products that help enterprises discover, process, and analyze critical business data. This role is hands-on, requiring you to be comfortable demonstrating features, collaborating on implementations, and working closely with scrum teams to drive value for our customers.\n\nWhy it’s a big deal\n\nMetadata extraction is at the core of how businesses understand their documents and processes. By leveraging Discovery AI, you’ll help enterprises transform manual, time-consuming tasks into automated workflows that reduce errors, improve compliance, and deliver actionable insights. Your role will be central to creating and refining solutions that can scale to handle the most complex enterprise needs.\n\nAre you the person we’re looking for?\n\nRelevant Experience. You should have more than 3 years of experience in Product Management in B2B SaaS, preferably with data extraction, AI, or document automation products.\n\nDemonstrate. A success in conceptualizing and launching new product features from initial idea to market adoption.\n\nAI or machine learning. Knowledge of fundamentals and an interest in applying them to solve real-world business challenges.\n\nCLM. Exposure or understanding in CLM is a strong plus, as it ties closely into many metadata extraction use cases.\n\nResearch and Creativity. Conduct market and user research to identify new opportunities for AI-driven features.\n\nCustomer feedback. You will gather continuous customer feedback to iterate and prioritize feature development that delivers tangible customer value.\n\nMaintain strong partnerships. With professional services and support teams to address implementation details and customer escalations.\n\nDemo. You should confidently demo features to internal stakeholders, customers, and prospects to showcase Discovery AI capabilities.\n\nAnalyze and prioritize. You will use data analytics, user feedback, and market insights to guide product decisions and roadmap priorities.\n\nBalance. customer requirements, technical feasibility, and time-to-market considerations in a fast-paced environment.\n\nCustomer experience. You will regularly engage with customers to understand their needs and pain points, ensuring Discovery AI addresses real-world challenges.\n\nDocument. New workflows, provide training materials or guidelines, and gather post-launch feedback.\n\nEducation. Bachelor’s degree in Engineering or equivalent; a higher degree is a plus.\n\nHere’s what will give you an edge\n\nChampion the Customer. You appreciate that customers are the heart of the business, and you’re dedicated to delivering solutions that solve their problems while meeting them where they are.\n\nNatural collaborator. You thrive in an Agile, cross-functional setting, seeking input from engineers, designers, data scientists, and peers to make well-rounded product decisions.\n\nPassion. Your genuine enthusiasm for AI and data-driven solutions is evident in your work. You love delving into technical details, exploring new possibilities, and shaping products that redefine how companies operate.\n\nStrong Communication. You will communicate releases, risks, and timelines effectively to leadership and cross-functional stakeholders.\n\nCollaborate. With marketing to position and promote new features that drive adoption and user satisfaction.\n\nLeadership skills. You will work closely with scrum teams to ensure clear backlog priorities, smooth sprint planning, and timely delivery.",Industry Type: Software Product,Department: Product Management,"Employment Type: Full Time, Permanent","['Product Strategy', 'Product Management', 'Product Portfolio', 'Product Life Cycle Management', 'Product Planning']",2025-06-12 06:41:55
Technical Manager - AI/ML,Thryve Digital,12 - 15 years,Not Disclosed,"['Hyderabad', 'Chennai']","Role Summary:\nThis job involvesmanaging the day to day delivery of AI ML team, which will be responsible forbuilding, deploying and maintaining robust, scalable, and efficient ML models\nEssentialResponsibilities\nLead and mentor team of data engineers, MLOps engineers, and machine learning engineers, to achieve project objectives & deliverables (development and deployment of ML models for AI use cases across the platform)\nCollaborate with business, engineering, infrastructure and data science teams to translate their needs or challenges into production-grade Artificial Intelligence and Machine Learning models for batch and real-time requirements\nPrimary point of contact for US & Thryve leaders, ensuring clear communication and aligning with project goals and objectives\nGuide team of AI ML engineers with respect to business objectives and connecting the dots, helping to team to come up with optimal ML models based on use cases\nManage day to day operation and ensure adherence to process, scope, quality and timelines\nIncumbent to assume role of an engagement coordinator between Thryve India team and US counterparts (techno functional)\nHighlight risks and concerns to leadership team, work with multiple stakeholders to establish alignment, contingency and or mitigation plans as required\nExperienced and proactive in tracking delivery statuses, project progress and take ownership of all deliverables from Thryve\nEffective communicator with team members, US stakeholders and management\nStay up-to-date with the latest trends andadvancements in AI and ML and identify opportunities for the team to implementnew models and technologies\nOther duties as assigned or requested approximately 50% technical and 50% management\nProposeand implement best engineering and research practices for scaling ML-poweredfeatures, with a goal to enable fast iteration of and efficient experimentationwith novel features\nTheexperience we are looking to add to our team\nRequired\nBachelor's degree in engineering or computerScience or related field\n12 to 15 years of total experience with atleast 1+ year experience in leading / managing AI - ML projects achieving clear& measurable business objectives\nGood understanding of US Health insurance withat least 3+ years experience in the same\nGood experience / understanding of the entire MLOps from data ingestion to production\nGood understanding of AI-ML concepts &algorithms,including supervised, unsupervised, and reinforcement learning, as well as MLOps\nAbility to take successful, complex ideas fromexperimentation to production\nKnowledge / experience in Google cloud [GCP]or any public cloud platforms\nExcellent communication, presentation, andinterpersonal skills\nProven experience in leading, motivating &inspiring teams to foster collaboration\nProficient in identifying, assessing andcalling out risks and mitigation plans to stakeholders\nExperience in implementing processimprovements and learning from past projects to enhance future performance\nAble to analyze external and internalprocesses, and creating strategies for service delivery optimization\nExperience in working with diverse teams andstakeholders, understanding their needs and managing expectations",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI/ML', 'Technical Management', 'MLOps', 'ML models', 'US Health insurance', 'Google cloud']",2025-06-12 06:41:57
TA Manager- Only IT Hiring Experts- Immediate Joiners,Mascot E Services,9 - 14 years,9-15 Lacs P.A.,['Bengaluru'],"Read Carefully:-\n\nRecruitment (IC & Lead ) Mandatory Skills in hiring- Full stack , Data scientist , AI and Data Analytics(Data Mining & Data Governance), sourcing and has hands on stakeholder mgmt exp\n\nWhatsapp CV to Saurabh 9818385050@ Write TA\n\nRequired Candidate profile\nRecruitment (IC & Lead ) Skills – Full stack , Data scientist, AI and Data Analytics(Data Mining & Governance), sourcing, hands on stakeholder management\n\nWhatsapp CV to Saurabh 9818385050 @ Write TA",Industry Type: Analytics / KPO / Research,Department: Human Resources,"Employment Type: Full Time, Permanent","['Talent Acquisition', 'Technical Hiring', 'IT Staffing', 'IT Recruitment', 'Technology Recruitment', 'Technology Hiring', 'It Hiring', 'Technical Recruitment', 'TA']",2025-06-12 06:42:00
AI/ML Architect,Airport IT Services Ltd.,10 - 15 years,Not Disclosed,['Bengaluru'],"AI/ML Architect\nLocation: Bangalore (Hybrid)\nExperience: 1015 years\nKey Requirements:\nExperience & Education\n10+ years in total, 8+ years in AI/ML development\n3+ years in AI/ML architecture\nBachelor’s/Master’s in CS, AI/ML, Engineering, or similar\nCore Technical Skills\nStrong in TensorFlow, PyTorch\nExpertise in time series modeling and computer vision (object detection, facial/intrusion/anomaly detection)\nHands-on with MLOps tools: MLflow, TFX, Kubeflow, SageMaker\nExperience in cloud (AWS, Azure, GCP) and edge AI (Jetson, Coral, OpenVINO)\nProficient with Docker, Kubernetes, CI/CD pipelines\nArchitecture & Integration\nDesigned hybrid edge-cloud AI systems\nIntegrated ML models into IIoT platforms\nImplemented model fusion with sensor, visual, and 3rd party data\nLeadership & Collaboration\nMentored cross-functional teams (ML, Data, DevOps)\nEnsured security, compliance, and production readiness of AI models\nTranslated AI strategy into business-aligned solutions",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['MLOps', 'Azure Cloud', 'Artificial Intelligence', 'Ml Pipelines', 'Ml', 'Ci Cd Pipeline', 'Docker', 'Aws Sagemaker', 'Gcp Cloud']",2025-06-12 06:42:02
"Sr. Product Manager, AI",Conga,3 - 5 years,Not Disclosed,['Bengaluru( Kadubeesanahalli )'],"Job Title: Sr. Product Manager\nLocation: Bangalore\nReports to: Manager, Product Management\n\nA quick snapshot\n\nAs a Product Manager on the Conga Discovery AI team, you will help define, build, and launch AI-driven metadata extraction solutions on top of the Conga platform. Youll bring your experience in AIand ideally Contract Lifecycle Management (CLM)to shape products that help enterprises discover, process, and analyze critical business data. This role is hands-on, requiring you to be comfortable demonstrating features, collaborating on implementations, and working closely with scrum teams to drive value for our customers.\n\nWhy it’s a big deal\n\nMetadata extraction is at the core of how businesses understand their documents and processes. By leveraging Discovery AI, you’ll help enterprises transform manual, time-consuming tasks into automated workflows that reduce errors, improve compliance, and deliver actionable insights. Your role will be central to creating and refining solutions that can scale to handle the most complex enterprise needs.\n\nAre you the person we’re looking for?\n\nRelevant Experience. You should have more than 5 years of experience in Product Management in B2B SaaS, preferably with data extraction, AI, or document automation products.\n\nDemonstrate. A success in conceptualizing and launching new product features from initial idea to market adoption.\n\nAI or machine learning. Knowledge of fundamentals and an interest in applying them to solve real-world business challenges.\n\nCLM. Exposure or understanding in CLM is a strong plus, as it ties closely into many metadata extraction use cases.\n\nResearch and Creativity. Conduct market and user research to identify new opportunities for AI-driven features.\n\nCustomer feedback. You will gather continuous customer feedback to iterate and prioritize feature development that delivers tangible customer value.\n\nMaintain strong partnerships. With professional services and support teams to address implementation details and customer escalations.\n\nDemo. You should confidently demo features to internal stakeholders, customers, and prospects to showcase Discovery AI capabilities.\n\nAnalyze and prioritize. You will use data analytics, user feedback, and market insights to guide product decisions and roadmap priorities.\n\nBalance. customer requirements, technical feasibility, and time-to-market considerations in a fast-paced environment.\n\nCustomer experience. You will regularly engage with customers to understand their needs and pain points, ensuring Discovery AI addresses real-world challenges.\n\nDocument. New workflows, provide training materials or guidelines, and gather post-launch feedback.\n\nEducation. Bachelor’s degree in Engineering or equivalent; a higher degree is a plus.\n\nHere’s what will give you an edge\n\nChampion the Customer. You appreciate that customers are the heart of the business, and you’re dedicated to delivering solutions that solve their problems while meeting them where they are.\n\nNatural collaborator. You thrive in an Agile, cross-functional setting, seeking input from engineers, designers, data scientists, and peers to make well-rounded product decisions.\n\nPassion. Your genuine enthusiasm for AI and data-driven solutions is evident in your work. You love delving into technical details, exploring new possibilities, and shaping products that redefine how companies operate.\n\nStrong Communication. You will communicate releases, risks, and timelines effectively to leadership and cross-functional stakeholders.\n\nCollaborate. With marketing to position and promote new features that drive adoption and user satisfaction.\n\nLeadership skills. You will work closely with scrum teams to ensure clear backlog priorities, smooth sprint planning, and timely delivery.",Industry Type: Software Product,Department: Product Management,"Employment Type: Full Time, Permanent","['Product Strategy', 'Product Management', 'Product Portfolio', 'Product Life Cycle Management', 'Product Planning']",2025-06-12 06:42:05
Moogsoft AIOps _ Contract Role _ Pan India,Cygnus Professionals,8 - 13 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","ROLE AND RESPONSIBILITIES\n\nDesign, implement, configure, and maintain both the Moogsoft AIOps platform and the Apex AIOps\nIncident Management platform.\nDevelop and manage integrations between Moogsoft, Apex AIOps, and other relevant IT monitoring,\nlogging, and ITSM tools.\nDevelop and implement automation workflows and runbooks within both AIOps platforms to\nstreamline incident management and remediation processes.\nCollaborate with various IT teams (monitoring, application, infrastructure, security, operations) to\nunderstand their AIOps requirements and translate them into effective solutions on both platforms.\nDefine and enforce best practices for the configuration, utilization, and administration of both\nMoogsoft and Apex AIOps.\nTroubleshoot issues related to platform performance, data ingestion, correlation logic, integrations,\nand automation within both environments.\nCreate and maintain comprehensive documentation for configurations, integrations, workflows, and\noperational procedures for both Moogsoft and Apex AIOps.\nDevelop and implement metrics and dashboards within both platforms to provide visibility into IT\nhealth, incident trends, and the effectiveness of AIOps implementations.\nEnsure the security and compliance of both Moogsoft and Apex AIOps platforms and their integrations.\nQUALIFICATIONS AND EDUCATION REQUIREMENTS\nBachelor's degree in Computer Science, Information Technology, Engineering, or a related field.\nProven experience (typically 8+ years) in a technical role focused on AIOps platforms, event\nmanagement, or systems integration, with specific experience in both Moogsoft and Apex AIOps.\nHands-on experience implementing, configuring, and administering both Moogsoft and Apex AIOps in a production environment is essential. • Familiarity with a wide range of IT monitoring tools, logging systems, and ITSM platforms. • Understanding of ITIL frameworks and incident management processes. PREFERRED SKILLS • Deep hands-on expertise in configuring and managing the Moogsoft AIOps platform. • Deep hands-on expertise in configuring and managing the Apex AIOps Incident Management platform. • Strong understanding of AIOps concepts, machine learning algorithms used for event correlation, and noise reduction techniques within both platforms. • Proven ability to integrate both Moogsoft and Apex AIOps with various IT systems using APIs and other integration methods. • Excellent analytical, problem-solving, and troubleshooting skills across both AIOps platforms. • Strong scripting and automation skills (e.g., Python, Shell) for automating tasks within and around both platforms. • Excellent communication (both written and verbal) and collaboration skills, with the ability to work effectively with diverse technical teams. • Ability to document technical solutions clearly and concisely for both platforms. • Experience with version control systems (e.g., Git). GOOD TO HAVE SKILLS • Experience with other AIOps platforms or event management tools. • Knowledge of cloud platforms (e.g., AWS, Azure, GCP) and their monitoring and event management services, and how they integrate with Moogsoft and Apex AIOps. • Understanding of security best practices for AIOps platforms and integrations. • Experience with agile development methodologies. ADDITIONAL NOTES • The successful candidate will be a self-starter with a passion for data visualization and problem-solving. • This role may involve working closely with cross-functional teams to implement and support their monitoring needs.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Temporary/Contractual","['Moogsoft AIOps', 'AIOps', 'Moogsoft', 'Apex', 'Integration', 'Monitoring']",2025-06-12 06:42:07
Business Development Manager - AI,Manpower Group,3 - 6 years,15-17 Lacs P.A.,['Mumbai (All Areas)'],"We are urgently Hiring for a Business Development Manager - AI Role\nLocation - Mumbai, Goregaon\nExperience - 3+Years\n\nJob Description\nJob Summary: We are looking for a results-driven AI Sales Specialist with experience in AI sales and customer relationship management. The role involves identifying and engaging potential clients, presenting AI solutions, and building long-term client relationships.\n\nSales Strategy Development:\n\nFormulate a strategy and act upon it that will allow the company to reach its sales and other targets on AI solutions.\n\nCustomer Relationship Management:\n\nDevelop and nurture client relationships so that high customer satisfaction and repeat business can be assured.\n\nLead Generation:\n\nCreate and screen potential clients or customers using various methods, including conferences, networking, and digital methods.\n\nConsultative Selling:\n\nOffer consulting services to the clients, assisting them to optimize the potential of our AI .solutions to help meet their goals as well as address challenges.\n\nSales Presentations:\n\nPresent products and services to the potential client or customer with the help of audiovisuals that will effectively persuade clients\n\nNegotiation and Closing:\n\nParticipate with the sales team from the initial customer contact to contract signing and all negotiations of the deal.\n\nCandidate requirements:\n\nExperience: Three or more years of selling experience in the field of technology or AI, achieving the sales metrics set.\nSales Skills: Good sales and presentation abilities with the skills of pitching negotiations to clients on complex technical ideas.\nClient Focus: The capacity to win and retain the trust of key clients and stakeholders was evident.\nProblem-Solving: Problem- solving and critical thinking are strong with the ability to make\nEducation: Bachelors degree in Business, Computer Science, Engineering, or a related field. Advanced degrees or certifications in AI or sales are a plus.\n\nInterested Candidates can share CVS on - insiya.galabhaiwala@in.experis.com",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Sales', 'Artificial Intelligence', 'AI', 'Business Development', 'Software Sales', 'B2B Sales', 'IT Sales']",2025-06-12 06:42:09
Principal IS Architect – Clinical Computation Platform,Amgen Inc,8 - 10 years,Not Disclosed,['Hyderabad'],"What you will do\nAmgens Clinical Computation Platform Product Team manages a core set of clinical computation solutions that support global clinical development. This team is responsible for building and maintaining systems for clinical data storage, data auditing and security management, analysis and reporting capabilities. These capabilities are pivotal in Amgens goal to serve patients.\nThe Principal IS Architect will define the architecture vision, create roadmaps and support the design and implementation of advanced computational platforms to support clinical development, ensuring that IT strategies align with business goals. The Principal IS Architect will work closely with partners across departments, including CfDA, GDO, CfOR, CfTI, CPMS and IT teams, to design and implement scalable, reliable, and hard-working solutions.\nDevelop and maintain the enterprise architecture vision and strategy, ensuring alignment with business objectives\nCreate and maintain architectural roadmaps that guide the evolution of IT systems and capabilities\nEstablish and enforce architectural standards, policies, and governance frameworks\nEvaluate emerging technologies and assess their potential impact on the enterprise/domain/solution architecture\nIdentify and mitigate architectural risks, ensuring that IT systems are scalable, secure, and resilient\nMaintain comprehensive documentation of the architecture, including principles, standards, and models\nDrive continuous improvement in the architecture by finding opportunities for innovation and efficiency\nWork with partners to gather and analyze requirements, ensuring that solutions meet both business and technical needs\nEvaluate and recommend technologies and tools that best fit the solution requirements\nEnsure seamless integration between systems and platforms, both within the organization and with external partners\nDesign systems that can scale to meet growing business needs and performance demands\nDevelop and maintain logical, physical, and conceptual data models to support business needs\nEstablish and enforce data standards, governance policies, and best practices\nDesign and manage metadata structures to enhance information retrieval and usability\n\nBasic Qualifications:\nMasters degree with 8 to 10 years of experience in Computer Science, IT or related field OR\nBachelors degree with 10 to 14 years of experience Computer Science, IT or related field OR\nDiploma with 14 to 18 years of experience Computer Science, IT or related field\nProficiency in designing scalable, secure, and cost-effective solutions.\nExpertise in cloud platforms (AWS, Azure, GCP), data lakes, and data warehouses.\nExperience in evaluating and selecting technology vendors.\nAbility to create and demonstrate proof of concept solutions to validate technical feasibility.\nStrong knowledge of Clinical Research and Development Domain\nExperience working in agile methodology, including Product Teams and Product Development models\nPreferred Qualifications:\nStrong solution design and problem-solving skills\nExperience in developing differentiated and deliverable solutions\nAbility to analyze client requirements and translate them into solutions\nExperience with machine learning and artificial intelligence applications in clinical research.\nStrong programming skills in languages such as Python, R, or Java.\nExperience of DevOps, Continuous Integration, and Continuous Delivery methodology\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nDemonstrated awareness of presentation skills",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Clinical Computation Platform', 'java', 'solution design', 'data warehousing', 'cloud platforms', 'data lake', 'Python']",2025-06-12 06:42:11
Genesys Senior Developer,CIEL HR,6 - 11 years,Not Disclosed,"['Chennai', 'Bengaluru']",We are seeking a highly experienced Genesys Cloud Developer with strong experience in Genesys Cloud 6 to 8 years of experience to join our team As a Genesys Developer\nResponsible for designing and architecting Genesys Cloud solutions based on business requirements and technical considerations\nCollaborate with stakeholders lead the implementation and configuration of Genesys Cloud solutions and oversee the integration with other systems and applications\nAdditionally stay up to date with the latest Genesys Cloud AI features and capabilities\nRoles Responsibilities\nDevelop and configure AIdriven features like Agent Assist Intent Miner and A3S Artificial Intelligence Services in Genesys\nCreate and optimize IVR flows chatbots and AIpowered customer interactions\nIntegrate AI models to enhance selfservice capabilities and agent productivity\nWork on speech analytics intent recognition and realtime transcription in Genesys Cloud\nGenesys Architect experience\nData Tables and Call routing in Genesys Experience\nGenesys Developer Data actions experience best practices\nGenesys Participant data familiarization\nData Actions development experience\nDevelop and maintain Genesys Cloud APIs and integrations with third party applications eg CRMs databases analytics tools\nAutomate workflows using Genesys Cloud Architect Webhooks and AWS Azure services\nFamiliar with Genesys APIs and data\nFamiliar with Genesys support cases and escalations\nContact Center for health care domain knowledge nice to have\nUnderstanding of natural language IVR implementations\nGenesys Chat experience Build support\nNice to Have\nWFM experience in Genesys\nCertification in Genesys Cloud or similar contact canter solutions\nExperience with agile development methodologies\nStrong understanding of security best practices including encryption and access control\nSoft Skills\nExcellent problem solving and analytical skills\nStrong communication and interpersonal skills\nAbility to work in a fastpaced environment and prioritize multiple tasks\nStrong attention to detail and ability to meet deadlines\nConvert the below reading as a customer deliverable item without changing its meaning\nAsIs Process Maps\nBaseline KPIs for the business process\nDefine RACI and develop SIPOC\nToBe Process Maps\nBusiness process Assessment Summary documentation,Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Genesys', 'Java', 'Node.Js']",2025-06-12 06:42:14
Sap Hana Consultant,Globant,5 - 8 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","At Globant, we are working to make the world a better place, one step at a time. We enhance business development and enterprise solutions to prepare them for a digital future. With a diverse and talented team present in more than 30 countries, we are strategic partners to leading global companies in their business process transformation.\n\nWe seek a SAP Native Hana Consultant - Senior Level who shares our passion for innovation and change. This role is critical to helping our business partners evolve and adapt to consumers' personalized expectations in this new technological era.",,,,"['Bods', 'Sap Native Hana', 'SQL']",2025-06-12 06:42:16
Sr ETL/SSIS developer,Sagility India,6 - 11 years,Not Disclosed,['Bengaluru'],"Job Summary\nWe are seeking a highly skilled and self-driven SSIS with strong communication and client-facing skills to join our healthcare analytics team. This role requires a combination of deep technical expertise in SSIS and data integration along with the ability to consult and collaborate directly with clients to understand and address their data needs.\nThe ideal candidate will be experienced in building and maintaining scalable data pipelines, working with diverse healthcare data sources, and ensuring data quality and availability for downstream analytics. You will play a key role in delivering clean, trusted, and timely data for insights and reporting.\nKey Responsibilities\nDesign, develop, and maintain robust and scalable SSIS to support healthcare analytics and reporting platforms.\nEngage directly with clients to gather requirements, provide consultation, and translate business needs into technical solutions.\nIntegrate and normalize data from diverse healthcare data sources, including claims, EMR, lab, pharmacy, and eligibility systems.\nEnsure data accuracy, completeness, and consistency throughout ingestion and transformation processes.\nOptimize and tune data workflows for performance and scalability in a cloud or on-premise data platform.\nTroubleshoot and resolve data issues in a timely and proactive manner to support high data availability.\nCollaborate with analysts, data scientists, and business stakeholders to ensure data pipelines meet analytical needs.\nCreate and maintain comprehensive technical documentation for data pipelines, data dictionaries, and workflows.\nStay informed on healthcare compliance requirements (e.g., HIPAA), and ensure data handling practices follow regulatory standards.\nRequired Skills and Qualifications\n6+ years of experience in SSIS development and data engineering\nProven ability to interact directly with clients and translate business problems into data solutions\nStrong experience with SQL, SSIS, or PySpark for data processing\nDeep understanding of data warehousing concepts and dimensional modeling\nExperience working with healthcare datasets (e.g., claims, eligibility, clinical data)\nFamiliarity with cloud platforms (Azure, AWS, or GCP) and data lakes\nStrong troubleshooting, problem-solving, and performance tuning skills\nExcellent verbal and written communication skills\nBachelor's or Masters degree in Computer Science, Engineering, Information Systems, or a related field\nPreferred Qualifications\nProficiency in building data pipelines using tools such as Azure Data Factory, Informatica, Databricks, or equivalent\nExperience with FHIR, HL7, or other healthcare data standards\nFamiliarity with HIPAA and healthcare compliance requirements\nKnowledge of reporting tools like Power BI or Tableau\nExposure to CI/CD and data pipeline automation\nWhy Join Us?\nWork on high-impact healthcare projects with meaningful outcomes\nEngage directly with clients and make a tangible difference in their data strategy\nCollaborative team culture and continuous learning opportunities\nFlexible work arrangements and competitive compensation\n\nLocation - Bangalore\nShit Timing - 2 Pm to 11 PM\nWork - Hybrid\n\nRegards,\nnaveen.vediyappan@sagility.com",Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SSIS', 'SQL', 'ETL']",2025-06-12 06:42:18
Job Opportunity_Data Science_Noida,Tradeindia,1 - 5 years,Not Disclosed,['Noida( Noida-Greater Noida Expressway )'],"About the Role:\nWe are seeking a highly skilled and innovative AI/ML Engineer with a strong background in Generative AI (LLMs, RAG, Multimodal models, Agentic AI), core Machine Learning (including Deep Learning, NLP, and Vision), and hands-on experience with Data Visualization tools like Tableau. The ideal candidate should also be familiar with deploying solutions on cloud platforms, particularly AWS.\n\nKey Responsibilities:\nDesign, develop, and fine-tune Large Language Models (LLMs) for diverse use cases using prompt engineering, fine-tuning, and embeddings.\nImplement Retrieval-Augmented Generation (RAG) pipelines with semantic search and vector databases (e.g., FAISS, Pinecone).\nWork on multimodal AI models involving text, image, and audio data for advanced AI capabilities.\nBuild agentic AI systems using frameworks like LangChain, OpenAgents, or similar libraries.\nDevelop, train, and evaluate Machine Learning /Deep Learning models for NLP and Computer Vision (object detection, OCR, etc.).\nCreate insightful data dashboards and visualizations using Tableau to support business decision-making.\nDeploy ML pipelines and models on AWS cloud services (e.g., S3, SageMaker, Airflow, Glue).\nFamiliarity with Microsoft Azure especially for OpenAI\nCollaborate with cross-functional teams to understand business problems and translate them into AI/ML solutions.\nKeep up-to-date with the latest advancements in Gen-AI, open-source tools, and cloud technologies.\nPreferred Qualifications:\nBachelors or Masters in Computer Science, Data Science, or related field\n\nRequired Skills:\n\nGen-AI & LLMs:\nExperience with OpenAI, HuggingFace Transformers, LangChain, LlamaIndex, RAG architectures\nExperience in LLM evaluation, prompt optimization, fine-tuning/customizing base models\nFamiliarity with agentic workflows, function calling, and orchestration tools\n\nMachine Learning:\nStrong fundamentals in deep learning, NLP, and computer vision\nExperience with TensorFlow, PyTorch, Scikit-learn\nGood grasp of model deployment, monitoring, and evaluation metrics\n\nVisualization & Storytelling:\nProficient in Tableau for data visualization, dashboards, and storytelling with data\n\nCloud & DevOps:\nFamiliarity with AWS services (S3, Lambda, SageMaker, Glue , MWAA)\nComfortable with Bitbucket (Git) and CI/CD pipelines",Industry Type: Internet (E-Commerce),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Python', 'SQL', 'Machine Learning', 'AWS', 'Large Language Models', 'Deep Learning']",2025-06-12 06:42:20
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Varanasi'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI adoption', 'AI-driven business models', 'data science', 'AI research', 'regulatory compliance', 'innovation strategies']",2025-06-12 06:42:23
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Nagpur'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI development', 'deep learning', 'python', 'data science', 'natural language processing', 'AI research', 'machine learning', 'artificial intelligence']",2025-06-12 06:42:25
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Visakhapatnam'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy.\nDesign and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson.\nEnsure seamless chatbot integration with existing platforms and CRM systems.\nWork closely with data scientists to improve machine learning models.\nMust have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Chatbot Development', 'deep learning', 'chatbot', 'python', 'r', 'data analytics', 'predictive modeling', 'machine learning', 'artificial intelligence', 'chatbot analytics']",2025-06-12 06:42:27
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Nagpur'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy.\nDesign and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson.\nEnsure seamless chatbot integration with existing platforms and CRM systems.\nWork closely with data scientists to improve machine learning models.\nMust have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Chatbot Development', 'deep learning', 'chatbot', 'python', 'r', 'data analytics', 'predictive modeling', 'machine learning', 'artificial intelligence', 'chatbot analytics']",2025-06-12 06:42:30
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Chandigarh'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI adoption', 'deep learning', 'python', 'tableau', 'data analysis', 'data science', 'predictive analytics', 'machine learning', 'artificial intelligence', 'natural language']",2025-06-12 06:42:32
Product Architect - AI,Conversehr Business Solutions,10 - 15 years,40-50 Lacs P.A.,['Hyderabad'],"What is the AI Adoption and Solutions team responsible for?\nThe AI Adoption and Solutions team drives innovation and transformation within our organization. This dynamic team is responsible for identifying opportunities where artificial intelligence can be leveraged to solve complex business challenges and enhance operational efficiency. They work closely with various departments to understand their needs and develop tailored AI solutions that align with the company's strategic goals. From implementing AI/ML/GenAI models to automating processes, the AI Adoption and Solutions team ensures that AI technologies are seamlessly integrated into the business, providing AI insights, driving growth and enterprise impact. Their expertise in AI adoption and product solutions helps FT stay competitive in a rapidly evolving digital landscape, making them an essential part of the company's success.\nWhat is the Product Architect-AI responsible for?\nAs an AI Solution Architect, you will be responsible for designing, developing, and implementing AI solutions that address complex business challenges. You will work closely with cross-functional teams to ensure the successful integration of AI technologies into our products and services.\nWhat are the ongoing responsibilities of the Product Architect-AI?\nTechnical: Design and architect AI solutions that meet business value streams and requirements. Own the solution outcome for responsible focus areas.\nCollaboration: Work closely with stakeholders to understand their business needs and technical specifications. Build partnerships across Technology, Business and control groups.\nAI Product Management: Lead the development and deployment of AI algorithms for solutions. Ensure scalability, performance, monitoring, security, privacy and ethics of AI solutions.\nIndustry Research and Thought Leadership: Stay informed about the latest trends and advancements in AI technology. Share insights with clients and internal teams to drive continuous improvement and innovation.\nLeadership: Provide technical guidance and knowledge sharing to teams and partners. Influence AI culture, solutions and mindset among cross-functional teams.\nWhat ideal qualifications, skills & experience would help someone to be successful?\nBachelors degree in computer science, Engineering, Data Science, or a related field or equivalent experience. Advanced degrees and certifications in AI, Machine Learning, or related areas are preferred.\n10+ years of experience in Product, Artificial Intelligence (AI).\nDemonstrated experience in AI consulting, AI solution design, implementation, and deployment. Familiarity with AI industry trends and use cases. Experience in a client-facing role is necessary. 5+ years of experience.\nUnderstanding business processes related to Asset Management, Retail, Advisory, Retirement, Wealth, Insurance.\nExperience in product lifecycle processes, including product research, market research, competitive analysis, planning positioning, roadmap development, requirements definition, and product launches and go-to-market strategies.\nExperience in project management, with the ability to manage multiple projects simultaneously and deliver results within deadlines.\nComprehensive knowledge of AI technologies, including machine learning algorithms, data analytics, natural language processing, and computer vision. Proficiency in programming languages such as Python, R, or Java.\nStrong analytical and problem-solving abilities to evaluate client requirements and develop effective AI strategies.\nExcellent written and verbal communication skills, with the ability to convey business needs to technical solutions and articulate to stakeholders.\nJob Level - Individual Contributor\nWork Shift Timings - 2:00 PM - 11:00 PM IST",Industry Type: Financial Services (Asset Management),Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'Generative Ai', 'Architecture', 'Product Design', 'Generative Artificial Intelligence', 'Ai Solutions', 'AI']",2025-06-12 06:42:34
Advisory Board Members - AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Visakhapatnam'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI development', 'deep learning', 'python', 'data science', 'natural language processing', 'AI research', 'machine learning', 'artificial intelligence']",2025-06-12 06:42:37
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Bhubaneswar'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI adoption', 'deep learning', 'python', 'tableau', 'data analysis', 'data science', 'predictive analytics', 'machine learning', 'artificial intelligence', 'natural language']",2025-06-12 06:42:39
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Indore'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI adoption', 'deep learning', 'python', 'tableau', 'data analysis', 'data science', 'predictive analytics', 'machine learning', 'artificial intelligence', 'natural language']",2025-06-12 06:42:42
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Indore'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy.\nDesign and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson.\nEnsure seamless chatbot integration with existing platforms and CRM systems.\nWork closely with data scientists to improve machine learning models.\nMust have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['AI', 'deep learning techniques', 'Rasa', 'NLP algorithms', 'Dialogflow', 'Python', 'chatbot analytics']",2025-06-12 06:42:44
AI Conversational Chatbot Developer,Benovymed Healthcare,1 - 4 years,Not Disclosed,['Bhubaneswar'],"Develop and enhance AI-driven chatbot solutions to automate customer interactions and optimize response accuracy.\nDesign and implement NLP algorithms using frameworks like Rasa, Dialogflow, or IBM Watson.\nEnsure seamless chatbot integration with existing platforms and CRM systems.\nWork closely with data scientists to improve machine learning models.\nMust have strong proficiency in Python, deep learning techniques, and chatbot analytics.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['AI', 'deep learning techniques', 'Rasa', 'NLP algorithms', 'Dialogflow', 'Python', 'chatbot analytics']",2025-06-12 06:42:46
Generative AI Developer,Prodapt Solutions,2 - 5 years,Not Disclosed,['Chennai'],"Overview\n\nWe are looking for a talented Generative AI Developer to join our dynamic team and contribute to our projects in transforming data into actionable insights.\n\nResponsibilities\n\nDesign, develop, and implement generative AI models using Python and relevant libraries.\nCollaborate with data scientists to analyze data and improve model performance.\nDevelop and maintain Flask APIs to serve AI models and facilitate integration with frontend applications.\nUtilize SQL for data manipulation and retrieval to support AI model training and evaluation.\nEngage in code reviews and contribute to best practices for software development.\nStay updated with the latest trends and advancements in AI and machine learning technologies.\n\n\n Primary\n\nSkills:\n \nProficient in Python (including libraries such as TensorFlow, PyTorch, or similar frameworks).\nStrong experience with SQL for database management and data querying.\nFamiliarity with Generative AI tools and platforms (e.g., Gemini Pro).\nExperience in developing RESTful APIs using Flask.\n\n Secondary\n\nSkills:\n \nUnderstanding of machine learning concepts and algorithms.\nFamiliarity with cloud computing services (e.g., AWS, Google Cloud) is a plus.\nKnowledge of data preprocessing and feature engineering techniques.\nExcellent problem-solving skills and ability to work in a collaborative team environment.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'sql', 'database management', 'tensorflow', 'rest', 'algorithms', 'software development', 'natural language processing', 'numpy', 'artificial intelligence', 'deep learning', 'data science', 'gcp', 'computer vision', 'pytorch', 'keras', 'flask', 'aws', 'cloud computing']",2025-06-12 06:42:49
Senior AI/ML Trainer | Generative AI Expert,Skillecta,5 - 10 years,Not Disclosed,['Delhi / NCR'],"Now Hiring: Senior AI/ML Trainer | Generative AI Expert | Full-Time | Delhi-NCR, Indore & Ludhiana\nAre you passionate about teaching the next generation of AI innovators? Do you have deep expertise in Artificial Intelligence, Machine Learning, and Generative AI tools like GPT-4 and LangChain? If yes, join us as a Senior AI/ML Faculty/Trainer and shape the future of AI education!\nWhy This Role?\nWe are expanding our AI skilling programs and looking for a dynamic AI/ML professional who thrives in a learning environment. Youll deliver real-world training, guide learners through hands-on projects, and play a pivotal role in developing industry-ready tech talent.\nKey Responsibilities\nLead Instructor: Deliver interactive classroom sessions in Applied AI/ML and Generative AI with a strong focus on hands-on coding, tool demonstrations, and live use cases.\nProject Mentorship: Guide students in real-world AI projects, including computer vision applications, RAG systems, and generative AI models.\nTech Labs: Conduct lab sessions using state-of-the-art tools like GPT-4, LangChain, TensorFlow, PyTorch, and Vector Databases.\nContent Collaboration: Work with the curriculum team to keep training materials aligned with the latest AI trends and technologies.\nContinuous Improvement: Track learner performance and continuously refine teaching methods for maximum impact.\nInnovation Evangelist: Integrate cutting-edge concepts like MLOps, LLMOps, and Responsible AI into classroom instruction.\nQualifications\nEducation: Bachelors or Master’s in Computer Science, AI, Data Science, or a related domain.\nExperience:\n5+ years of experience in AI/ML development (NLP, Computer Vision, Deep Learning, Generative AI).\n2+ years in training or teaching (preferably for engineers, graduates, or professionals).\nTechnical Expertise:\nStrong command of Python for scripting and automation, with advanced capabilities in data analysis using NumPy and Pandas, and data visualization using Matplotlib, Seaborn, and Plotly for actionable insights.\nRobust foundation in statistics and mathematical modeling—including probability, distributions, hypothesis testing, linear algebra, and calculus—essential for understanding algorithms and tuning ML/DL models effectively.\nProficient in Git and GitHub for version control, collaborative development, and managing machine learning projects across teams.\nHands-on experience in building and deploying Deep Learning models using CNNs, RNNs, and Transformers for tasks such as image recognition, text classification, and predictive modeling.\nExpertise in NLP (Natural Language Processing) techniques like sentiment analysis, named entity recognition, text summarization, and language generation using modern frameworks such as Hugging Face Transformers.\nApplied knowledge of Generative AI technologies, including LLMs (e.g., GPT-4), Prompt Engineering, Retrieval-Augmented Generation (RAG), and Vector Databases like Pinecone or FAISS.\nSkilled in designing and deploying data analysis pipelines end-to-end—from data ingestion and preprocessing to model training, evaluation, and monitoring—leveraging cloud platforms (AWS, GCP, Azure) and containerized workflows (Docker, Kubernetes).\nExperience with Gen AI and Agentic AI solutions in real-world applications such as automating customer interactions, intelligent data summarization, marketing campaign optimization, and building autonomous agents using LangChain or AutoGPT.\nKnowledge of MLOps best practices, including CI/CD pipelines for ML, model versioning, monitoring, and scalability using tools like MLflow, DVC, and Kubeflow.",Industry Type: Education / Training,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Machine Learning', 'Deep Learning', 'Python', 'Agentic Ai', 'Ci / Cd Tools', 'Artificial Neural Networks', 'Ai Solutions', 'Natural Language Processing', 'Ml Algorithms', 'Ml Pipelines', 'Generative Artificial Intelligence', 'SQL']",2025-06-12 06:42:51
Scientific Business Analyst (Specialist) – Biological Studies (LIMS),Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\n\n\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that the technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role leverages scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams. This enables the delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\n\nYou will join a multi-functional team of scientists and software professionals that enables technology and data capabilities to evaluate drug candidates and assess their abilities to affect the biology of drug targets. This team implements LIMS platforms that enable the capture, analysis, storage, and report of pre-clinical and clinical studies as well as those that manage biological sample banks. You will collaborate with Product Owners and developers to maintain an efficient and consistent process, ensuring quality work from the team. You will implement and manage scientific software platforms across the research informatics ecosystem, and provide technical support, training, and infrastructure management, and ensure it meets the needs of our Amgen Research community.\n\nRoles & Responsibilities:\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the technology ecosystem for in vivo study data management and ensure that the platform meets their requirements for data analysis and data integrity\nTranslate complex scientific and technological needs into clear, actionable requirements for development teams\nDevelop and maintain a product roadmap that clearly outlines the planned features and enhancements, timelines, and achievements\nIdentify and manage risks associated with the systems, including technological risks, scientific validation, and user acceptance\nDevelop documentations, communication plans and training plans for end users\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\nCollaborate with geographically dispersed teams, including those in the US and other international locations.\nFoster a culture of collaboration, innovation, and continuous improvement.\nWhat we expect of you\n\nWe are all different, yet we all use our unique contributions to serve patients.\n\nBasic Qualifications:\nMasters degree and 4 to 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree and 6 to 8 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma and 10 to 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nMust-Have\n\nSkills:\nDemonstrated expertise in a scientific domain area and related technology needs\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience in configuration and administration of LIMS/ELN platforms such as Benchling, Revvity, IDBS, STARLIMS, Watson, LabVantage, etc.\nExperience using platforms such as Spotfire, Tableau, Power BI, etc., to build dashboards and reports\nPreferred Qualifications:\n5+ years of experience in designing and supporting biopharma scientific software platforms\nExperience leading the implementation of scientific software platforms, Electronic Lab Notebook (ELN), or Laboratory Information Management Systems (LIMS)\nExperience handling GxP data and system validation, and knowledge of regulatory requirements affecting laboratory data (e.g., FDA 21 CFR Part 11, GLP, GCP)\nKnowledge of bioanalytical workflows and/or biospecimen management\nExperience in AI and machine learning for drug discovery research and preclinical development\nExperience with cloud (e.g. AWS) and on-premise infrastructure\nIn-depth knowledge of Agile processes and principles for coordinated solutions and teams via SAFe\nExperience in establishing business partnerships and IS governance practices involving senior business collaborators\nKnowledge of business analysis standard methodologies, DevOps, Continuous Integration, and Continuous Delivery methodology\nProfessional Certifications:\nSAFe for Teams certification (preferred)\nSoft\n\nSkills:\nAble to work under minimal supervision\nExcellent analytical and gap/fit assessment skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation\nAbility to manage multiple priorities successfully\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills\nAs we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, well support your journey every step of the way.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Biological Studies', 'computational biology', 'FDA 21 CFR Part 11', 'biopharma', 'GCP', 'bioinformatics', 'system validation', 'GLP', 'computational chemistry', 'GxP data']",2025-06-12 06:42:54
Business Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role we are seeking a Business Systems Analyst with a good background in data and analytics to define and manage product requirements for AI-driven applications.\nPartner with Data Scientists, ML Engineers, and Product Managers to define business processes, product needs, and AI solution requirements.\nCapture and document epics, user stories, acceptance criteria, and data process flows for AI-powered analytics applications.\nWork closely with partners to define scope, priorities, and impact of new AI and data initiatives.\nEnsure non-functional requirements, such as data security, model interpretability, and system performance, are included in product backlogs.\nFacilitate the breakdown of Epics into Features and Sprint-Sized User Stories and lead backlog grooming sessions.\nEnsure alignment of technical requirements and UX for AI-based applications and interactive dashboards.\nCollaborate with engineers to define data ingestion, transformation, and model deployment processes.\nDevelop and implement product demonstrations showcasing AI-driven insights and analytics.\nMaintain detailed documentation of data pipelines, model lifecycle management, and system integrations.\nStay engaged throughout software development, providing proactive feedback to ensure business needs are met\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. This role bridges the gap between business needs and technical execution, ensuring the development of high-quality, scalable AI solutions. You will collaborate with data scientists, engineers, and product managers to shape product roadmaps, refine requirements, and drive alignment between business objectives and technical capabilities.\nBasic Qualifications:\nMasters degree and 1 to 3 years expereince in Computer Science, Data Science, Information Systems, or related field OR\nBachelors degree and 3 to 5 years of in Computer Science, Data Science, Information Systems, or related field OR\nDiploma and 7 to 9 years of in Computer Science, Data Science, Information Systems, or related field\nPreferred Qualifications:\nExperience defining requirements for AI/ML models, data pipelines, or analytics dashboards.\nFamiliarity with cloud platforms (AWS, Azure, GCP) for AI and data applications.\nUnderstanding of data security, governance, and compliance in AI solutions.\nAbility to communicate complex AI concepts and technical constraints to non-technical partners.\nKnowledge of MLOps, model monitoring, and CI/CD for AI applications.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business analysis', 'continuous integration', 'data science', 'gcp', 'ci/cd', 'microsoft azure', 'information systems', 'aws', 'artificial intelligence']",2025-06-12 06:43:29
Scientific Business Analyst ( Specialist ) – Large Molecule Discovery,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will work closely with Amgen Research partners and Technology peers to ensure that they technology/ data needs for drug discovery research are translated into technical requirements for solution implementation. The role demonstrates scientific domain and business process expertise to detail product requirements as epics and user stories, along with supporting artifacts like business process maps, use cases, and test plans for the software development teams.\nFunction as a Scientific Business Systems Analyst within a Scaled Agile Framework (SAFe) product team\nServe as a liaison between global Research Informatics functional areas and global research scientists, prioritizing their needs and expectations\nManage a suite of custom internal platforms, commercial off-the-shelf (COTS) software, and systems integrations\nLead the Large Molecule Discovery technology ecosystem and ensure that the platform meets the requirements for data analysis and data integrity\nEnsure scientific data operations are scoped into building Research-wide Artificial Intelligence/Machine Learning capabilities\nEnsure operational excellence, cybersecurity and compliance.\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. The delivery team to estimate, plan, and commit to delivery with high confidence and identify test cases and scenarios to ensure the quality and performance of IT Systems.\nBasic Qualifications:\nMasters degree with 4 - 6 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 6- 8years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 10 - 12 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\nPreferred Qualifications:\n5+ years of experience in implementing and supporting biopharma scientific software platforms.\n\n\nFunctional Skills:\nMust-Have Skills:\nProven expertise in a scientific domain area and related technology needs\nExperience with writing user requirements and acceptance criteria in agile project management systems such as JIRA\nExperience in configuration and administration of LIMS/ELN platforms (e.g. Benchling), Discovery software tools (e.g. Geneious, Genedata Screener) and Instrument Automation and Analysis platforms\nExperience using platforms such as Spotfire, Tableau, Power BI, etc., to build dashboards and reports and understanding of basic data querying using SQL, Databricks, etc.\n\n\nGood-to-Have Skills:\nExperience leading the implementation of scientific software platforms, Electronic Lab Notebook (ELN), or Laboratory Information Management Systems (LIMS)\nKnowledge of the antibody discovery design, make, test, and analyze cycle.\nExperience in AI and machine learning for drug discovery research and preclinical development\nExperience with leveraging LLM tools to accelerate software development processes.\nExperience with cloud (e.g. AWS) and on-premise infrastructure.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analysis', 'Spotfire', 'Power BI', 'Tableau', 'Databricks', 'JIRA', 'LLM', 'AWS', 'SQL']",2025-06-12 06:43:32
Senior Associate - Next Gen Forecasting,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will support an ambitious program to evolve how Amgen does forecasting, moving from batch processes (e.g., sales forecasting to COGS forecast, clinical study forecasting) to a more continuous process. The hardworking professional we seek is curious by nature, organizationally and data savvy, with a strong record of Finance transformation, partner management and accomplishments in Finance, Accounting, or Procurement.\nThis role will help redesign existing processes to incorporate Artificial Intelligence and Machine Learning capabilities to significantly reduce time and resources needed to build forecasts. As the Next Gen Forecasting Senior Associate at Amgen India, you will drive innovation and continuous improvement in Finances planning, reporting and data processes with a focus on maximizing current technologies and adapting new technologies where relevant. This individual will collaborate with cross-functional teams and support business objectives. This role reports directly to the Next Gen Forecasting Manager in Hyderabad, India.\nRoles & Responsibilities:\nPriorities can often change in a fast-paced technology environment like Amgens, so this role includes, but is not limited to, the following:\nSupport implementation of real-time / continuous forecasting capabilities\nEstablish baseline analyses, define current and future state using traditional approaches and emerging digital technologies\nIdentify which areas would benefit most from automation / AI / ML\nIdentify additional process / governance changes to move from batch to continuous forecasting\nClosely partner with Business, Accounting, FP&A, Technology and other impacted functions to define and implement proposed changes\nPartners with Amgen Technology function to support both existing and new finance platforms\nPartners with local and global teams on use cases for Artificial Intelligence (AI), Machine Learning (ML) and Robotic Process Automation (RPA)\nCollaborate with cross-functional teams and Centers of Excellence globally to drive operational efficiency\nContributes to a learning environment and enhances learning methodologies of technical tools where applicable.\nServe as local financial systems and financial data subject matter expert, supporting local team with questions\nSupports global finance teams and business partners with centrally delivered financial reporting via tableau and other tools\nSupports local adoption of Anaplan for operating expense planning / tracking\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nBasic Qualifications:\nMasters degree and 1 to 3 years of Finance experience OR\nBachelors degree and 3 to 5 years of Finance experience OR\nDiploma and 7 to 9 years of Finance experience\nConsistent record of launching new finance capabilities\nProficiency in data analytics and business intelligence tools.\nExperience with finance reporting and planning system technologies\nExperience with technical support of financial platforms\nKnowledge of financial management and accounting principles.\nExperience with ERP systems\nResourceful individual who can connect the dots across matrixed organization\nPreferred Qualifications:\nExperience in pharmaceutical and/or biotechnology industry.\nExperience in financial planning, analysis, and reporting.\nExperience with global finance operations.\nKnowledge of advanced financial modeling techniques.\nBusiness performance management\nFinance transformation experience involving recent technology advancements\nPrior multinational capability center experience\nExperience with Oracle Hyperion/EPM, S4/SAP, Anaplan, Tableau/PowerBI, DataBricks, Alteryx, data lakes, data structures\nSoft Skills:\nExcellent project management abilities.\nStrong communication and interpersonal skills.\nHigh level of integrity and ethical standards.\nProblem-solving and critical thinking capabilities.\nAbility to influence and motivate change.\nAdaptability to a dynamic and fast-paced environment.\nStrong organizational and time management skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Next Gen Forecasting', 'Oracle Hyperion', 'ERP', 'SAP', 'Finance', 'financial management', 'financial reporting', 'Anaplan', 'financial planning', 'Tableau']",2025-06-12 06:43:34
Senior Secondary Computer Teacher -Informatics Practices (IP)/AI,VIBGYOR Group of Schools,2 - 7 years,Not Disclosed,['Lucknow'],"Interested candidates can share their resume on vandita.pandey@vgos.org\n\nUrgent Requirement for IP (Informatics Practices)/AI (Artificial Intelligence)-Senior Secondary Teacher(8-12) @ Vibgyor School Lucknow\nDesired Qualification- Post Graduate Degree with B. Ed\nExperience: 3-10 Years\nLesson Delivery:\nEnsure the lesson plan prepared is followed along with the mentioned resources and activities.\nEnsure all students are learning in a safe and productive environment.\nShould make use of effective pedagogical styles to suit different aptitudes, learning styles and interests of the students.\nStudent Administration:\nEnsure discipline is maintained in accordance with the rules and disciplinary systems of the school\nPromote maximum student participation and assist students in improving study habits.\nShould keep a check on basic hygiene and pay attention to health matters seriously and diligently for each child.\nClassroom Functioning:\nCreate an effective learning environment through functional and attractive displays, bulletin boards, and interest centers\nEnsure a positive and professional relationship with parents is maintained & provide feedback to parents.\nSecondary Responsibility: Administration / School Policies:\nMust compile, maintain, and ensure confidentiality of school records.\nShould adhere to all the policies in force/ introduced from time to time and actively implement the same.\nShould do any similar work not specified in this job description at the coordinator's request.\nShould conduct quarterly stock check of the teaching aids along with the coordinator.\nShould participate in professional development through internal and external courses, seminars, conferences, and events.\nAttending all meetings convened by the principal and coordinators.\nEnsure liaising and collaborating with resource person and others.\nWork Relations:\nInterfacing with Principal for academic related issues.\nInterfacing with Co- teachers and other staff members as and when required.\nInterfacing with Admin, Finance, HR, Technology for any people for any operational issues\n\nInterested candidates can share their resume on vandita.pandey@vgos.org",Industry Type: Education / Training,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Computer', 'Computer Science', 'IP', 'informatics practices']",2025-06-12 06:43:36
Optimization Specialist,Ltimindtree,6 - 11 years,Not Disclosed,['Navi Mumbai'],"JD Optimization Specialist\n\nJob Summary: We are seeking an experienced Data Scientist with a strong background in optimization to join our team. The ideal candidate will have 12-17 years of experience in data science, machine learning, optimization techniques and Gen AI. This role involves leading complex data science and Gen AI projects ( with a focus in solving optimization problems), mentoring junior data scientists, and driving data-driven decision-making.\n\nRoles and Responsibilities:\n\n12-17 years of overall experience in the design, implementation, or consulting within the data science and AI space.\nOversee the design, development, and implementation of advanced optimization models to solve complex business problems, across domains ( manufacturing, hitech, retail , oil & gas, etc.)\nApply optimization techniques such as linear programming, integer programming, mixed integer linear programming, nonlinear optimization, and heuristic and meta heuristic algorithms ( like Genetic Algorithms ) to solve business problems.\nAnalyzing and understanding use cases to verify their fitment and to determine the best solution approach for data science and generative AI applications.\nWork closely with cross-functional teams including pre-sales, sales, hyper scalar platforms, to integrate the AI solutions and drive business outcomes\nDocumenting comprehensive technical artifacts and establishing best practices for implementing and deploying AI models on various cloud platforms.\nLeading a team of leads and developers in building Proof of Concepts (POCs) for various customers.\nProvide guidance and mentorship to junior data scientists, and sharing knowledge in data science, optimization and AI technologies, fostering a culture of continuous learning and improvements\nEnsuring AI solutions adhere to quality and ethical standards while optimizing their performance in production for reliability and efficiency.\n\nTechnical Skills\n\nProficiency in optimization tools, libraries & products such as CPLEX, Gurobi, PuLP, Llamasoft, etc.\nExperience with building and implementing optimization techniques like linear programming, Mixed Integer Linear Programming, nonlinear optimization, Genetic Algorithms, and heuristic and meta – heuristic algorithms.\nProficiency in programming languages like Python, R, and SQL.\nExpertise in data manipulation and analysis using libraries such as Pandas, NumPy, and Scikit-learn, SciPy\nStrong experience with machine learning frameworks like TensorFlow, Keras, and PyTorch\nProficiency in using LLM, and LLM – based frameworks like RAG, agentic framework to develop AI solutions\nStrong communication skills and experience in managing various stakeholder relationships to gain consensus on complex technical solutions.\nDeep experience in architecting, designing, and implementing solutions on-premises, in the cloud, and using hybrid models, and mastery of the latest AI frameworks.\nIn-depth experience in fine-tuning and customizing pretrained LLMs and AI models, with good understanding of various patterns and practices in AI, data engineering, and large data processing.\nProficiency with a variety of tools and platforms, including but not limited to Amazon SageMaker, Azure ML Studio, Azure Data Lake, Google BigQuery, Vertex AI, AWS S3, Databricks and Snowflake.\nExperience with relational and non-relational databases (e.g., MySQL, MongoDB).\nRelevant certifications in data science, optimization, operations research, Gen AI at the Architect/Lead level will be an advantage.\n\nBehavioral Skills:\n\nExcellent verbal and written communication skills to articulate complex data insights to non-technical stakeholders.\nProblem-Solving: Strong analytical and problem-solving abilities to tackle challenging data and optimization issues.\nCollaboration: Ability to work effectively in a collaborative environment and build strong relationships with cross-functional teams.\nAdaptability: Flexibility to adapt to changing business needs and technological advancements.\nAttention to Detail: High level of attention to detail and commitment to delivering high-quality work.\n\nOther Skills:\nProject Management: Experience in managing large-scale data science, optimization and Gen AI projects and ensuring timely delivery.\nBusiness Acumen: Understanding of business processes and the ability to align data science, optimization and AI initiatives with organizational goals.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Optimization Techniques', 'Data Science', 'Aiml']",2025-06-12 06:43:39
Generative AI Trainer,Zeominds It Solutions,2 - 7 years,8-12 Lacs P.A.,['Hyderabad'],"Were hiring a Generative AI Trainer (Full-time & Freelance) to lead engaging training sessions and guide learners through real-world AI applications. Youll be teaching the latest in Gen AI tools like LLMs, Prompt Engineering, Lang Chain, and more.\n\nKey Responsibilities:\nDeliver structured offline and online training on Generative AI topics\nTeach concepts including LLMs, Prompt Engineering, Lang Chain, Hugging Face, etc.\nSupport learners with project work, queries, and assessments\nCreate and update training material, hands-on exercises, and case studies\nEnsure high engagement and learner satisfaction\nStay up-to-date with latest AI research and industry practices\n\nKey Skills Required:\nStrong expertise in Python, Machine Learning, and Deep Learning\nPractical experience with Large Language Models (GPT, Llama, etc.), NLP, and RAG\nKnowledge of Lang Chain, Hugging Face, Transformers, and Prompt Engineering\nFamiliarity with Flask/Django, SQL, and Tableau is a plus\nHands-on experience with real-time AI/ML/Gen AI projects is a must\nStrong communication skills and a passion for teaching",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Freelance/Homebased","['Data Science', 'Generative Ai', 'Artificial Intelligence', 'Machine Learning', 'Deep Learning']",2025-06-12 06:43:41
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Surat'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI', 'AI Strategy', 'data science', 'AI Adoption', 'AI Ethics', 'AI Governance', 'AI Implementation', 'machine learning']",2025-06-12 06:43:43
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Jaipur'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI adoption', 'AI-driven business models', 'data science', 'AI research', 'regulatory compliance', 'innovation strategies']",2025-06-12 06:43:45
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Vadodara'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI adoption', 'AI-driven business models', 'data science', 'AI research', 'regulatory compliance', 'innovation strategies']",2025-06-12 06:43:47
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Patna'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI', 'AI Strategy', 'data science', 'AI Adoption', 'AI Ethics', 'AI Governance', 'AI Implementation', 'machine learning']",2025-06-12 06:43:50
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Guwahati'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: Education / Training,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI adoption', 'AI-driven business models', 'data science', 'AI research', 'regulatory compliance', 'innovation strategies']",2025-06-12 06:43:52
Advisory Board Members-AI,Benovymed Healthcare,20 - 30 years,Not Disclosed,['Mysuru'],"Key Responsibilities:\nProvide strategic guidance on AI adoption, ethics, and governance within the organization.\nAdvise on AI-driven business models, innovation strategies, and regulatory compliance.\nEvaluate AI research, development, and deployment strategies to ensure ethical and sustainable growth.\nMentor and collaborate with internal teams on best practices in AI, data science, and machine learning.\nAssess AI risks, biases, and challenges, providing solutions for responsible AI implementation.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI', 'AI Strategy', 'data science', 'AI Adoption', 'AI Ethics', 'AI Governance', 'AI Implementation', 'machine learning']",2025-06-12 06:43:54
AI Python Developer,Fractional Chro,2 - 7 years,Not Disclosed,[],"AI Python Developer: Job Description\n\nAbout US\nWe're a brand-new company with a bold vision to revolutionize through innovative AI solutions in globally serving niche customers. As a startup, we're building our team from the ground up, and that means you'll have an unparalleled opportunity to make a significant impact from day one.\nYou won't find layers of bureaucracy here, just a passionate and agile environment where your ideas are valued and your contributions directly shape our product's development. We're looking for a talented and driven AI Python Developer who thrives in a dynamic, remote setting and is excited to be a foundational member of our team.\nThis is your chance to not just build a chatbot, but to help build a company. If you're eager to take ownership, embrace challenges, and contribute to something truly impactful, we encourage you to apply.\n\nWhat will you do?\nDesigning and developing software applications using Python and C#.\nIntegrating AI and machine learning models into applications using Python and performing integrations with C#.\nDeveloping back-end components using Python and potentially interacting with front-end UI/UX using C#.\nCollaborating with product manager, onsite client coordinator and if need with the client as well.\nDebugging, testing, and optimizing application performance and code quality.\nDocumenting technical specifications and best practices.\nWorking with cloud platforms and services (e.g., AWS, Azure) for deployment and scaling.\n\nWho are you?\nAn experienced programmer with strong knowledge of programming preferably in Python including frameworks like Django or Flask, and libraries like Pandas and NumPy.\nExperience with AI and machine learning models, algorithms, and frameworks.\nKnowledge of C# programming language, including .NET Framework or .NET Core (Nice to have but not mandatory)\nExperience with testing and debugging tools and techniques.\nKnowledge of database systems, including SQL and NoSQL databases.\nFamiliarity with cloud platforms and services and experience with version control systems like Github.\nStrong problem-solving and analytical skills. Excellent communication and collaboration skills.\n\nLocation: Remote",Industry Type: Emerging Technologies (AI/ML),Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Chatbot Development', 'Machine Learning', 'Python']",2025-06-12 06:43:56
AI Linguistic/ Languge Research ( Tamil / Marathi / Gujarati/ Hindi ),Transsion,2 - 7 years,Not Disclosed,['Noida'],"Department - AI and Research Department\n\nVacancies - Multiple Vacancies (In different Language - Gujarati , Marathi , Tamil )\n\nFreshers profile also welcomed with good language expertise in either Gujarati , Marathi , Tamil and have knowledge of translation, text to speech , AI technology , Conversational technology , virtual assistant , Speech Recognition , Intent Recognition, Entity Extraction ,Language Generation\n\nWork Model - Work from Office - 5 days a week\n\nWork Location - Noida , Sector 142\n\nFuture Scope- Be a part of the AI Research team, driving technological revolution in the mobile industry and working on future technologies.\n\n\nPURPOSE OF THE POSITION:\n\nAs an AI Linguistic Engineer, you will develop linguistic rules, collect and annotate language data, and ensure high-quality inputs for AI models. Responsibilities include data labeling, quality checks, and model evaluation You'll collaborate closely with the team to optimize models and support related tasks.\n\nA) Key Responsibilities:\n\nAs an AI linguistic Expert in AI language research and development, and data production related positions, you will participate in the research and development of language rules, data collection, sorting and labeling, etc., to provide high-quality data support You will work closely with our team and be responsible for completing the following main tasks:\n\n1. Participated in the research and development of linguistic rules.\n2. Collect, organize, and annotate language data for AI model training and optimization.\n3. Focus on the learning and auxiliary formulation of specific link standards in data production; data labeling, quality inspection, model effect evaluation; and training of labeling personnel.\n4. Learn to understand AI-related business processes and algorithmic processes, including but not limited to automatic speech recognition , natural language processing, and Text To Speech. 5. Other business related work\n\nB) Desired Candidate Profile\n\nA) ELIGIBILTY CRITERIA\n\na) Preferred be BA , MA , PHD\nb) Must have an Excellent Communication Skills and expertise with language in translation, transcription,\nc) Person with Scholar articles/Publications is preferred\nB) SKILLS REQUIRED\n1. Bachelor degree or above, majoring in language or linguistics is preferred.\n2. Solid foundation in theoretical linguistics, with a strong interest and passion for linguistic research, and a strong interest in applying linguistic knowledge to the industrial Transsion Holdings, Inc. field.\n3. Proficient in the target languages, with good listening, speaking, reading and writing skills, able to accurately understand and express language characteristics.\n4. Able to communicate in English for internal communication with team.\n5. Proficient in using Product for audio analysis and annotation is preferred.",Industry Type: Consumer Electronics & Appliances,Department: Research & Development,"Employment Type: Full Time, Permanent","['Translation', 'Linguistic Research', 'marathi', 'Gujarati', 'Localization', 'Speech Recognition', 'Transcription', 'Artificial Intelligence', 'Interpretation', 'Tamil', 'Language trainer', 'Language Expert', 'Linguistics', 'Data Annotation']",2025-06-12 06:43:59
ITAC Assurance Manager (SOX),Shell,12 - 15 years,Not Disclosed,['Chennai'],"The role of CTE ITAC Assurance Manager contributes to ensuring that Shell maintains a fit for purpose and design effective control framework, with specific focus on the system and technical elements of financial controls including configurations, system reports, interfaces, and workflows.\nThe successful candidate will be responsible for driving the centralised delivery of 2nd Line SOX assurance over Application Embedded Controls, ensuring high-quality testing in accordance with relevant standards and methodologies, and aligning with the agreed SOX attestation timeframes.\nWhere do you fit in?\nCentral Testing Excellence Team (CTE Team) is the centralized 2nd Line function providing independent and objective assurance over Shell SOX financial control framework. Covering over 90% of all Shell SOX controls globally, the assurance provided by CTE Team significantly contributes to Shells SOX compliance. The Team evaluates effectiveness of manual, IT Application financial controls (ITACs) and IT General Controls (ITGC).\nIT Application Controls (ITACs), also known as Application Embedded Controls, are an important part of the SOX controls landscape, with approx. 800 ITDMs and 200 system controls at Shell, across variety of applications. Due to technical nature and evolving IT landscape, ITACs are complex to construct & manage, and require involvement of multiple stakeholders.\nWhats the role?\nCTE ITAC Assurance Manager is expected to lead and manage a team of technical assurance professionals within the ITAC Testing Team.\nThis role will drive the centralised delivery of independent 2nd Line assurance over Application Embedded Controls and ensure that testing is performed with high quality and in line with relevant methodology and guidelines. The successful candidate will be a Subject Matter Expert for independent evaluation of technical elements utilised in financial controls.\nThis global position will give the successful candidate visibility of senior stakeholders across both Finance and IT organizations. As a member of the CTE Leadership Team, this position also offers the opportunity to serve as a community leader, overseeing activities such as communications, learning and development, people matters, and operational excellence.\nKey accountabilities include:\nEnd-to-end coordination and management of the annual 2nd Line ITAC testing across various systems (SAP & non-SAP), in line with SOX reporting cycle. Quality assurance to ensure all ITAC testing is delivered with consistently high quality and in line with the established methodology. Robust monitoring & reporting of delivery status; impact assessment of control deficiencies, timely reporting of testing outcomes and value adding insights to senior stakeholders.\nActing as an owner of the global ITAC testing methodology and ensuring it is fit for purpose and sufficiently robust to provide reasonable assurance. Develop 2nd Line assurance approach for emerging technologies and concepts, addressing advancements in digital transformation of Shell (S4/CFIN, Machine Learning/AI, etc.). Keep up to date with regulatory changes and industry best practices related to ITAC controls assurance and its digital transformation and applying these best practices in CTE assurance.\nLeading a team of risk and assurance specialists with expertise in both finance and IT, focusing on enhancing team skills and fostering continuous capability growth. Developing others is a key aspect of this role, as CTE ITAC Assurance Manager will oversee the learning and development program for the team, covering both technical (IT) & financial risk aspects.\nTransformational leadership. Encouraging innovation and driving the continuous improvement and automation initiatives within ITAC Testing Team. Partnering with key stakeholders to transform 2nd Line assurance through continuous control monitoring, data analytics, and other innovative approaches. Demonstrating strategic mindset to form future of assurance.\nCollaborating with Controls Design Team, IT, external audit and other relevant stakeholders to assess ITAC control deficiencies. Serving as single point of contact for external audits on the ITAC framework. Collaborating with other CTE Managers to jointly oversee the resource pool, ensuring optimal allocation of assurance deliverables.\nUtilize network of Shell contacts to identify the appropriate focal points to support 2nd Line controls assessment. Support the team in find effective solutions to challenges encountered during controls testing.\nWhat we need from you?\nThis global role would suit an experienced individual who has previous experience of 12-15 years, including minimum 10 years in IT and/or financial audit, risk management, SOX controls assurance, or SAP process architecture.\nExperience in IT application controls and reports assurance in major audit/accounting firm.\nDue to highly complex nature of Shell's IT landscape and ITAC controls framework, the successful candidate is required to possess combined expertise in both IT application assurance and finance controls & risks.\nThe successful candidate should have a degree in Information Technology, Computer Science, or Finance/Accounting. Professional certifications in internal audit (e.g. CIA), IT audit (e.g. CISA, CISSP), SAP, and/or finance (ACCA, CPA, or equivalent) are highly desirable.\nThe candidate must be able to demonstrate very strong understanding of risk management, SOX compliance requirements, governance models and assurance frameworks.\nStrong technical expertise in SAP is required, including good understanding of configurations within SAP Project Reference Object and basic SAP ABAP. Strong grasp of IT architectures and concepts, including cloud-based software distribution models, interfaces, and middleware. This technical knowledge should be paired with solid understanding of accounting principles, business processes (such as R&A, PGS, HM, manage close, Trading, group reporting, master data) & and the key financial risks associated with those processes. Solid understanding of trading process & system landscape at Shell would be a plus.\nThe successful candidate should have a strong track record of team leadership and relationship management. Excellent analytical, problem-solving, and communication skills are required, the candidate should be able to convey complex technical issues in non-technical and business terms.\nThe candidate should have ability to cut through complexity in unstructured environment, work independently and manage multiple priorities in a fast-paced environment.",Industry Type: Power,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['SAP', 'ITAC controls framework', 'risk management', 'SOX controls assurance', 'financial audit', 'SAP process architecture']",2025-06-12 06:44:02
Product Architect,Global Investment management Firm,10 - 15 years,Not Disclosed,['Hyderabad'],"Role & responsibilities\nAs an AI Solution Architect, you will be responsible for designing, developing, and implementing AI solutions that address complex business challenges. You will work closely with cross-functional teams to ensure the successful integration of AI technologies into our products and services.\n\nPreferred candidate profile\n\nBachelors degree in computer science, Engineering, Data Science, or a related field or equivalent experience. Advanced degrees and certifications in AI, Machine Learning, or related areas are preferred.\n7+ years of experience in Product, Artificial Intelligence (AI).\nDemonstrated experience in AI consulting, AI solution design, implementation, and deployment. Familiarity with AI industry trends and use cases. Experience in a client-facing role is necessary. 5+ years of experience.\nUnderstanding business processes related to Asset Management, Retail, Advisory, Retirement, Wealth, Insurance.\nExperience in product lifecycle processes, including product research, market research, competitive analysis, planning positioning, roadmap development, requirements definition, and product launches and go-to-market strategies.\nExperience in project management, with the ability to manage multiple projects simultaneously and deliver results within deadlines.\nComprehensive knowledge of AI technologies, including machine learning algorithms, data analytics, natural language processing, and computer vision. Proficiency in programming languages such as Python, R, or Java.\nStrong analytical and problem-solving abilities to evaluate client requirements and develop effective AI strategies.\nExcellent written and verbal communication skills, with the ability to convey business needs to technical solutions and articulate to stakeholders.\nJob Level - Individual Contributor\nWork Shift Timings - 2:00 PM - 11:00 PM IST",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Strong GEN AI project experience', 'Aiml', 'Python', 'Data Science']",2025-06-12 06:44:04
"Sr Manager - Digital Technology (renewable industry)- IT, Mumbai",client of talent leads,10 - 20 years,25-40 Lacs P.A.,['Mumbai'],"1) Job Dimensions\nWe are looking for an experienced Digital Leader with around 6-8 years experience to work on various Digital initiatives of Renewables. This person is expected to deliver a variety of projects and solutions for the business to improve business outcomes such as increased power generation, better power generation prediction, reduce losses, construction monitoring, performance monitoring, improve productivity of the internal and external staff. He/she should leverage cutting edge technologies available in AI/ML, domain, Analytics and Robotics and Robotics Process Automations. Utilize Digital Technologies to optimize impact on the environment and support ESG\ngoals. He/she will be working very closely with the Engineering and Innovation Departments to drive and execute the projects.\nInnovation\nAbility to think out of the box and leverage technology\nAbility to challenge the status quo\nBuild prototypes/proof of concepts quicky and build solutions\nTeam Player\nWork with a cross functional team of Information Technology (ERP Systems),\nEngineering/Technology, Innovation Dept, Power Generation Dept, Innovation Cell of the Group and Central Analytics team.\nWork with cyber security team to align the project goals within the cybersecurity framework\nTechnical Skills\nExpert in AL/ML and Algorithmic models\nExpertise in IoT and Cloud computing\nExpert in Data Analytics and various platforms available in cloud\nShould be a hands-on person\nRenewal business is in growth phase and has ambitious plans to grow. One of the critical factor to enable the growth is ability to generate more power from the available resources, optimized use of existing Assets (Solar Panels and Wind Turbines.\nChallenges:\n1. Manage trade-offs between long term impact technologies and short term solutions\n2. Existing Assets and their digital infra range from 10 years to 1 Years old, which will require calibration of solutioning\n4) Principal Accountabilities",Industry Type: Power (Solar),Department: Project & Program Management,"Employment Type: Full Time, Permanent","['digital', 'ai', 'ml', 'Digital Transformation', 'technology', 'machine learning', 'artificial intellihence']",2025-06-12 06:44:06
Senior Manager Information Systems,Amgen Inc,8 - 13 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will develop an insight driven sensing capability with a focus on revolutionizing decision making. In this role you will lead the technical delivery for this capability as part of a team data engineers and software engineers. The team will rely on your leadership to own and refine the vision, feature prioritization, partner alignment, and experience leading solution delivery while building this ground-breaking new capability for Amgen. You will drive the software engineering side of the product release and will deliver for the outcomes.\nRoles & Responsibilities:\nLead delivery of overall product and product features from concept to end of life management of the product team comprising of technical engineers, product owners and data scientists to ensure that business, quality, and functional goals are met with each product release\nDrives excellence and quality for the respective product releases, collaborating with Partner teams.\nImpacts quality, efficiency and effectiveness of own team. Has significant input into priorities.\nIncorporate and prioritize feature requests into product roadmap; Able to translate roadmap into execution\nDesign and implement usability, quality, and delivery of a product or feature\nPlan releases and upgrades with no impacts to business\nHands on expertise in driving quality and best in class Agile engineering practices\nEncourage and motivate the product team to deliver innovative and exciting solutions with an appropriate sense of urgency\nManages progress of work and addresses production issues during sprints\nCommunication with partners to make sure goals are clear and the vision is aligned with business objectives\nDirect management and staff development of team members\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nBasic Qualifications:\nMasters degree and 8 to 10 years of Information Systems experience OR\nBachelors degree and 10 to 14 years ofInformation Systems experience OR\nDiploma and 14 to 18 years of Information Systems experience\nThorough understanding of modern web application development and delivery, Gen AI applications development, Data integration and enterprise data fabric concepts, methodologies, and technologies e.g. AWS technologies, Databricks\nDemonstrated experience in building strong teams with consistent practices.\nDemonstrated experience in navigating matrix organization and leading change.\nPrior experience writing business case documents and securing funding for product team delivery; Financial/Spend management for small to medium product teams is a plus.\nIn-depth knowledge of Agile process and principles.\nDefine success metrics for developer productivity metrics; on a monthly/quarterly basis analyze how the product team is performing against established KPIs.\nFunctional Skills:\nLeadership:\nInfluences through Collaboration: Builds direct and behind-the-scenes support for ideas by working collaboratively with others.\nStrategic Thinking: Anticipates downstream consequences and tailors influencing strategies to achieve positive outcomes.\nTransparent Decision-Making: Clearly articulates the rationale behind decisions and their potential implications, continuously reflecting on successes and failures to enhance performance and decision-making.\nAdaptive Leadership: Recognizes the need for change and actively participates in technical strategy planning.\nPreferred Qualifications:\nStrong influencing skills, influence stakeholders and be able to balance priorities.\nPrior experience in vendor management.\nPrior hands-on experience leading full stack development using infrastructure cloud services (AWS preferred) and cloud-native tools and design patterns (Containers, Serverless, Docker, etc.)\nExperience with developing solutions on AWS technologies such as S3, EMR, Spark,\nAthena, Redshift and others\nFamiliarity with cloud security (AWS /Azure/ GCP)\nConceptual understanding of DevOps tools (Ansible/ Chef / Puppet / Docker /Jenkins)\nProfessional Certifications\nAWS Certified Solutions Architect (preferred)\nCertified DevOps Engineer (preferred)\nCertified Agile Leader or similar (preferred)\nSoft Skills:\nStrong desire for continuous learning to pick new tools/technologies.\nHigh attention to detail is essential with critical thinking ability.\nShould be an active contributor on technological communities/forums\nProactively engages with cross-functional teams to resolve issues and design solutions using critical thinking and analysis skills and best practices.\nInfluences and energizes others toward the common vision and goal. Maintains excitement for a process and drives to new directions of meeting the goal even when odds and setbacks render one path impassable\nEstablished habit of proactive thinking and behavior and the desire and ability to self-start/learn and apply new technologies\nExcellent organizational and time-management skills\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills.\nShift Information:\nThis position requires you to work a later shift and may be assigned a second or third shift schedule. Candidates must be willing and able to work during evening or night shifts, as required based on business requirements.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Information Systems', 'Azure', 'DevOps', 'Gen AI application development', 'GCP', 'Data integration', 'AWS', 'web application development']",2025-06-12 06:44:09
Sr Manager Information Security,Amgen Inc,8 - 10 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role As a Data Security Senior Manager, you will responsible to lead, operate, manage and improve Amgens Data Loss Prevention (DLP) , Cloud Access Security Broker (CASB), and Data Classification services. This position will be responsible for delivering data protection services across Amgens global enterprise. The role will work with architects, engineers and business units to help design, build, and implement critical preventive and detective security controls. This role will lead the team responsible for the protection of Amgen data in a rapidly changing security sector.\nRoles & Responsibilities:\nMaintain the service delivery and working order of Amgen Data Protection solutions across Amgens global enterprise by leading the distributed team of data security analysts and engineers\nExecute Amgen service management processes such as Incident Management, Organisational Change, Service Requests, etc. for Amgens DLP / CASB solutions\nAdvise and consult to business domain experts to collect, analyze, create, tune and automate DLP /CASB policy sets\nTrain and manage the team, including other leaders to analyze events and logs for opportunities to improve SaaS, Classification, and DLP policies\nSynthesize evolving business ecosystem changes to proactively identify new controls to and opportunities to improve data protection practices\nAs needed, support Legal, Human Resources, and Incident Response teams in investigations related to data usage incidents\nMaintain the needed subject matter expertise to keep current, make recommendations, and lead or participate in the implementation and continuous improvement of technologies and services in assigned information security domains\nAct as main contact in audits covering information security services and technologies\nAdvise on cryptographic services to protect the confidentiality and integrity of data at rest and in transit\nCollaborates multi-functionally with analysts, engineers, data scientists to deliver continuous improvement in cyber defense/resilience.\n\nBasic Qualifications:\nMasters degree and 8 to 10 years of experience OR\nBachelors degree and 10 to 14 years of experience OR\nDiploma and 14 to 18 years of experience\n\nFunctional Skills:\nMust-Have Skills:\nTrack record of leading multi-level and matrixed teams in the operations of security services at a large enterprise.\nKnowledge of Cloud Access Security Platforms (Elastica, Netskope, SkyHigh,etc)\nUnderstanding of cloud environment (AWS, O365, Box, Salesforce, etc)\nExperience with Data Protection Technologies for a global enterprise\nSolid knowledge of core cryptographic services (Confidentiality, Data Integrity Verification, Authentication, Non-repudiation) and their applications\nCompetent understanding on how security technologies and data flows (on-prem / cloud) integrate\n\nGood-to-Have Skills:\nExperience and ability to mentor and train others\nService delivery experience including headcount and budgetary planning\nStrong effective verbal and written communication skills including a mastery of Standard American Business English and experience with both technical and persuasive writing\nBasic experience with ITIL processes such as Incident/Problem/Configuration/Change management with a focus on metric-driven delivery\nProfessional Certifications (please mention if the certification is preferred or mandatory for the role):\nCISSP or equivalent preferred\n\nSoft Skills:\nEstablished analytical and gap/fit assessment skills.\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals\nEffective presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Information Security', 'Change management', 'Configuration', 'service delivery', 'SaaS', 'Problem management', 'Incident management', 'ITIL processes']",2025-06-12 06:44:11
MDM Testing - Associate Analyst,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"Role Description:\nWe are looking for a skilled MDM Testing Associate Analyst who will responsible for ensuring the quality and integrity of Master Data Management (MDM) applications through rigorous testing processes. This role involves collaborating with cross-functional teams to define testing objectives, scope, and deliverables, and to ensure that master data is accurate, consistent, and reliable. and comply with Amgens standard operating procedures, policies, and guidelines. Your expertise will be instrumental in ensuring quality and adherence to required standards so that the engineering teams can build and deploy products that are compliant.\nRoles & Responsibilities:\nTest Planning: Develop and implement comprehensive testing strategies for MDM applications, including defining test objectives, scope, and deliverables. This includes creating detailed test plans, test cases, and test scripts.\nTest Execution: Execute test cases, report defects, and ensure that all issues are resolved before deployment. This involves performing functional, integration, regression, and performance testing.\nData Analysis: Analyze data to identify trends, patterns, and insights that can be used to improve business processes and decision-making. This includes validating data accuracy, completeness, and consistency.\nCollaboration: Work closely with the MDM, RefData and DQDG team and other departments to ensure that the organizations data needs are met. This includes coordinating with data stewards, data architects, and business analysts.\nDocumentation: Maintain detailed documentation of test cases, test results, and any issues encountered during testing. This includes creating test summary reports and defect logs.\nQuality Assurance: Develop and implement data quality metrics to ensure the accuracy and consistency of master data. This includes conducting regular data audits and implementing data cleansing processes.\nCompliance: Ensure that all master data is compliant with data privacy and protection regulations. This includes adhering to industry standards and best practices for data management.\nTraining and Support: Provide training and support to end-users to ensure proper use of MDM systems. This includes creating user manuals and conducting training sessions\nStay current on new technologies, validation trends, and industry best practices to improve validation efficiencies.\nCollaborate and communicate effectively with the product teams.\nBasic Qualifications and Experience:\nMasters degree with 1 - 3 years of experience in Business, Engineering, IT or related field OR\nBachelors degree with 2 - 5 years of experience in Business, Engineering, IT or related field OR\nDiploma with 6 - 8 years of experience in Business, Engineering, IT or related field\nFunctional Skills:\nMust-Have Skills:\n2+ years of experience in MDM implementations, primarily with testing (pharmaceutical, biotech, medical devices, etc.)\nExtensive experience on ETL/ELT and MDM testing (Creating test plan, test scripts and execution of test scripts and bugs tracking/reporting in JIRA)\nInformatica MDM: Proficiency in Informatica MDM Hub console, configuration, IDD (Informatica Data Director), IDQ, and data modeling\nor\nReltio MDM: Experience with Reltio components, including data modeling, integration, validation, cleansing, and unification.\nAdvanced SQL: Ability to write and optimize complex SQL queries, including subqueries, joins, and window functions.\nData Manipulation: Skills in data transformation techniques like pivoting and unpivoting.\nStored Procedures and Triggers: Proficiency in creating and managing stored procedures and triggers for automation.\nPython: Strong skills in using Python for data analysis, including libraries like Pandas and NumPy etc.\nAutomation: Experience in automating tasks using Python scripts.\nMachine Learning: Basic understanding of machine learning concepts and libraries like scikit-learn.\nStrong problem-solving and analytical skills\nExcellent communication and teamwork skills\nGood-to-Have Skills:\nETL Processes: Knowledge of ETL processes for extracting, transforming, and loading data from various sources.\nData Quality Management: Skills in data profiling and cleansing using tools like Informatica.\nData Governance: Understanding of data governance frameworks and implementation.\nData Stewardship: Ability to work with data stewards to enforce data policies and standards.\nSelenium: Experience with Selenium for automated testing of web applications.\nJIRA: Familiarity with JIRA for issue tracking and test case management.\nPostman: Skills in using Postman for API testing.\nUnderstanding of compliance and regulatory considerations in master data.\nIn depth knowledge of GDPR and HIPPA guidelines.\nProfessional Certifications:\nMDM certification (Informatica or Reltio)\nSQL Certified\nAgile or SAFe certified\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MDM Testing', 'ETL Processes', 'Data Stewardship', 'MDM', 'Agile', 'Data Quality Management', 'Data Governance', 'SQL']",2025-06-12 06:44:14
Job Architecture & Job Leveling Manager,Amgen Inc,5 - 7 years,Not Disclosed,['Hyderabad'],"ABOUT THE ROLE\n\n\nRole Description:\n\nWe are seeking a seasoned and strategic Job Architecture & Job leveling Expert to join our Total Rewards team in India. This role will serve as the global subject matter expert (SME) on job architecture and leveling, responsible for the execution, governance, and continuous enhancement of the organization's job leveling, functional and global career frameworks.\n\nThe role will actively ensure seamless execution, consistency, fairness, and transparency in how roles are placed in the external and internal career frameworks across the enterprise, and will partner closely with the compensation partners, enabling effective talent management, compensation design, and career progression. This role will also focus on process optimization and partner closely with internal technology and automation teams to enhance efficiency and simplify the delivery of job architecture initiatives.\n\nRoles & Responsibilities:\nProvide strategic oversight and operational management of the global job leveling framework, ensuring consistent application across functions, geographies, and organizational levels.\nAct as the primary authority on job leveling and architecture, leveraging AI-supported job analysis tools, offering expert guidance and support to Compensation partners and Total Rewards senior leadership.\nActively support the develop and maintenance of functional career progression frameworks, in partnership with Compensation partners, business and functional leaders, to support internal mobility and employee development, incorporating AI-based insights to tailor frameworks to evolving workforce skills and career patterns.\nLead the end-to-end execution of global job mapping and leveling exercises, ensuring alignment with internal equity and market competitiveness by supporting the integration of AI, and machine learning algorithms and technology to enhance consistency and detect outliers or anomalies.\nIdentify and implement AI & technology improvements to simplify, standardize, and enhance job architecture processes, consistency, user experience, and tools to better support business and HR stakeholders leveraging\nCollaborate closely with the Total Rewards Technology Manager and Compensation partners to explore and implement AI, technology and scalable solutions that automate and streamline job architecture processes and related processes, like benchmarking.\nMonitor industry best practices and trends related to AI, Technology, tools, job architecture, career frameworks, and job evaluation methodologies, applying relevant insights to enhance the companys framework, efficiency and consistency\nLeveraging generative AI tools to develop and maintain SOPs, knowledge bases, and training materials for scalable and up-to-date service delivery\nBasic Qualifications and Experience:\nBachelors or Masters degree in Human Resources, Business Administration, Industrial/Organizational Psychology, or a related field\n5+ years of progressive experience in Total Rewards, Compensation, or Talent Management, with a specific focus on job architecture or career framework design\nProven experience in the development and governance of global job leveling frameworks and career path models.\nExperience with AI-driven analytics tools to evaluate workforce data for job leveling decisions\nStrong understanding of job evaluation methodologies and principles of internal equity and external market alignment (e.g., Mercer, AON Radford, WillisTowersWatson Global Grading)\n\n\nSkills:\nDemonstrated ability to manage cross-functional projects with a high degree of accuracy, influence, and confidentiality.\nAnalytical proficiency, with the ability to interpret and combine complex organizational data to drive strategic recommendations and decisions.\nExcellent stakeholder management and collaboration skills.\nExperience operating in a matrixed, global environment and navigating across diverse cultural and business landscapes.\nCuriosity for new technologies and solutions to drive continuous improvement\nBackground in organizational design, change management, or workforce planning is a plus.",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Job Architecture', 'talent management', 'total rewards', 'workforce planning', 'stakeholder management', 'job evaluation', 'compensation', 'change management']",2025-06-12 06:44:17
Digital Solution Architect,Prodapt Solutions,6 - 11 years,Not Disclosed,['Chennai'],"Overview\n\n Responsibilities:-  \n\nDesigning and architecting for web solutions that delivers a seamless omni channel experience.\n\nEvaluating and selecting the most suitable technologies and tools to improves omni channel experience and conversions with latest techniques such as Micro Frontends, AEM AEP, AI, Machine Learning and Cloud Native platforms.\n\n\n\n Must have skills :-  \nStrong experience in Java/J2EE, Micro Services architecture & development, NextJS, Micro frontend with ReactJS, NoSQL databases(Cassandra), Session cache(Redis) and ElasticSearch.\nExperience in designing & development for large enterprise applications.\nAbility to translate business requirements into innovative and effective solutions/designs and ensure the successful implementation.\nAbility to analyze and report on project delivery metrics (planned vs. actual) to identify performance trends, risks, and opportunities for improvement.\nStrong communication and collaboration skills, with a talent for explaining complex concepts simply.\nLead the requirement, design & development with Agile implementation methodology, And should work hand in hand with product area stakeholders.\nCollaborate with cross-functional teams to design, build, and act as the primary point of contact.\nExcellent problem-solving skills and troubleshooting skills w.r.t real time challenges of customers.\nAbility to design complex conversation flows and create engaging user experiences.\nAble to Drive process improvement initiatives by partnering with cross-functional teams to implement best practices and resolve strategic and organizational issues.\nStay updated and keep the team updated with the latest advancements in web technologies, AI and integrating innovative approaches for sustained competitive advantage.\n\n\n\n Good to have :-  \nHands on experience in PEGA(Case Management, NBX) and GenAI & Personalization capabilities.\nHands on experience on AWS & Google Clouds.\nExperience on ForgeRock access gateway & identity management platforms.\n\nResponsibilities\n\n Responsibilities:-  \n\nDesigning and architecting for web solutions that delivers a seamless omni channel experience.\n\nEvaluating and selecting the most suitable technologies and tools to improves omni channel experience and conversions with latest techniques such as Micro Frontends, AEM AEP, AI, Machine Learning and Cloud Native platforms.\n\n\n\n Must have skills :-  \nStrong experience in Java/J2EE, Micro Services architecture & development, NextJS, Micro frontend with ReactJS, NoSQL databases(Cassandra), Session cache(Redis) and ElasticSearch.\nExperience in designing & development for large enterprise applications.\nAbility to translate business requirements into innovative and effective solutions/designs and ensure the successful implementation.\nAbility to analyze and report on project delivery metrics (planned vs. actual) to identify performance trends, risks, and opportunities for improvement.\nStrong communication and collaboration skills, with a talent for explaining complex concepts simply.\nLead the requirement, design & development with Agile implementation methodology, And should work hand in hand with product area stakeholders.\nCollaborate with cross-functional teams to design, build, and act as the primary point of contact.\nExcellent problem-solving skills and troubleshooting skills w.r.t real time challenges of customers.\nAbility to design complex conversation flows and create engaging user experiences.\nAble to Drive process improvement initiatives by partnering with cross-functional teams to implement best practices and resolve strategic and organizational issues.\nStay updated and keep the team updated with the latest advancements in web technologies, AI and integrating innovative approaches for sustained competitive advantage.\n\n\n\n Good to have :-  \nHands on experience in PEGA(Case Management, NBX) and GenAI & Personalization capabilities.\nHands on experience on AWS & Google Clouds.\nExperience on ForgeRock access gateway & identity management platforms.\n\n\n Responsibilities:-  \n\nDesigning and architecting for web solutions that delivers a seamless omni channel experience.\n\nEvaluating and selecting the most suitable technologies and tools to improves omni channel experience and conversions with latest techniques such as Micro Frontends, AEM AEP, AI, Machine Learning and Cloud Native platforms.\n\n\n\n Must have skills :-  \nStrong experience in Java/J2EE, Micro Services architecture & development, NextJS, Micro frontend with ReactJS, NoSQL databases(Cassandra), Session cache(Redis) and ElasticSearch.\nExperience in designing & development for large enterprise applications.\nAbility to translate business requirements into innovative and effective solutions/designs and ensure the successful implementation.\nAbility to analyze and report on project delivery metrics (planned vs. actual) to identify performance trends, risks, and opportunities for improvement.\nStrong communication and collaboration skills, with a talent for explaining complex concepts simply.\nLead the requirement, design & development with Agile implementation methodology, And should work hand in hand with product area stakeholders.\nCollaborate with cross-functional teams to design, build, and act as the primary point of contact.\nExcellent problem-solving skills and troubleshooting skills w.r.t real time challenges of customers.\nAbility to design complex conversation flows and create engaging user experiences.\nAble to Drive process improvement initiatives by partnering with cross-functional teams to implement best practices and resolve strategic and organizational issues.\nStay updated and keep the team updated with the latest advancements in web technologies, AI and integrating innovative approaches for sustained competitive advantage.\n\n\n\n Good to have :-  \nHands on experience in PEGA(Case Management, NBX) and GenAI & Personalization capabilities.\nHands on experience on AWS & Google Clouds.\nExperience on ForgeRock access gateway & identity management platforms.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['nextjs', 'microservices', 'react.js', 'java', 'j2ee', 'architecting', 'aem', 'aep', 'redis', 'elastic search', 'gcp', 'avaya', 'html', 'mysql', 'sip', 'mongodb', 'cache', 'python', 'machine learning', 'javascript', 'nosql', 'cassandra', 'web technologies', 'forgerock', 'troubleshooting', 'agile', 'pega', 'aws', 'nosql databases']",2025-06-12 06:44:20
"Manager, CSAR – Custom Function Programming",Amgen Inc,9 - 12 years,Not Disclosed,['Hyderabad'],"We are looking for a talented individual to join us as a Study Designer and Edit Check Programmer, reporting directly to the Sr. Manager, Clinical Systems and Analytical Reporting.\nThe successful candidate will play a crucial role in adhering to Amgen standards, procedures, and best practices to build and program studies in our clinical trial database. This position will require effective partnership with other CSAR Operations and cross-functional staff to ensure seamless, high-quality deliverables and activities related to the use of electronic data capture technology.\nWe are seeking a strong leader who can confidently influence stakeholders and contribute individually to study-specific and general CSAR/GDO projects or operational work. The ideal candidate will have proven experience in partnering effectively with cross-functional teams to deliver systems support and study deliverables. Additionally, they should have operational experience with clinical database management systems and allied technologies (e.g., Rave EDC, Veeva EDC).\nResponsibilities include, but are not limited to, the following:\nSupport of clinical trial platform technologies\nSupport decision-making by acting as a data scientist bringing awareness to patterns and analytical insight.\nCoordinating and providing programming support to Clinical Study Teams\nEnsure efficient and consistent use of EDC system and ensure the use is complied with the established procedures or standards.\nActing as a technical point of contact for systems deliverables on defined programs\nIdentify, recommend or implement system enhancements, new tools or emerging technologies to decrease database development cycle times and foster a collaborative working environment.\nProviding technical and business process input / expertise on new and emerging technologies\nDevelop, review and implement policies, SOPs and associated documents\nEnsure documentation supports CSAR operational or technical activities is in a complete manner and consistent with regulatory and the established processes.\nAssist in preparing for and responding to audit findings (internal or external).\nKnowledge\nGood Clinical Practice\nStrong understanding and experience in the use of performance management techniques, measures, problem-solving and analytical thinking\nDrug development and clinical trials processes\nData management processes\nClinical trial databases and applications\nEdit check development and Custom function programing\nProgramming Languages\nSystems development lifecycle\nProject planning and management\nCollaborating with global cross-functional teams (team/matrix environment)\nQuality management and Risk Analysis\nRegulatory filings and inspections\nProcess improvement methodologies\nPreferred Qualifications\nAdvanced degree or equivalent in life science, computer science, math, statistics, business administration or related discipline\nBroad knowledge / work experience in data management / programming in the Pharmaceutical or Biotech arena\nGeneral project management and planning experience\nExperience in oversight of outside vendors (CROs, central labs, imaging vendors, IRT vendors, etc.)\nBasic Qualifications\nBachelors degree or equivalent in life science, computer science, business administration or related discipline with 9 to 12 years of experience\nSpecialist knowledge / experience in life sciences or a medically related field\nGeneral biopharmaceutical clinical research experience (clinical research experience obtained working on clinical trials at a biotech, pharmaceutical or CRO company)",Industry Type: Pharmaceutical & Life Sciences,Department: Research & Development,"Employment Type: Full Time, Permanent","['Programming', 'documentation', 'Clinical trial databases', 'performance management', 'Data management processes', 'Systems development lifecycle', 'Quality management']",2025-06-12 06:44:22
Finance Manager,Amgen Inc,4 - 6 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will play a key role in enhancing and managing finance-related technology solutions to support Amgens Operations Finance team. This role requires strong expertise in corporate finance and accounting principles, combined with a deep understanding of financial systems, data analytics tools, and process automation.\nThe individual will collaborate with cross-functional teams to implement, optimize, and maintain financial technology platforms, ensuring they align with business needs and strategic goals.\nRoles & Responsibilities:\nLead/Support the implementation, integration, and optimization of financial technology systems, including SAP, Hyperion, Tableau, Smartsheet, Anaplan, and other finance and data tools.\nCollaborate with Operations Finance to streamline financial processes, automate reporting, and enhance data accuracy.\nSupport financial planning, forecasting, and data modeling through advanced technology solutions.\nEnsure data integrity, security, and compliance across all finance-related systems.\nIdentify opportunities for process improvements using automation and analytics.\nProvide guidance on system enhancements, data governance, and financial system integrations.\nSupport financial reporting and analytics to improve decision-making.\nPartner with IT and Finance teams to troubleshoot issues and implement solutions.\nStay updated on emerging financial technologies and best practices.\nDevelop business cases and presentations on finance technology enhancements.\n\nBasic Qualifications:\nMaster's degree and 4 to 6 years of Finance and Technology experience OR\nBachelor's degree and 6 to 8 years of Finance and Technology experience OR\nPreferred Qualifications:\nMust-Have Skills:\nStrong understanding of corporate finance and accounting principles.\nExperience working with finance systems, including SAP, Hyperion, Tableau, Smartsheet, and Anaplan.\nExpertise in financial data analytics, reporting, and forecasting tools.\nExperience in automation and process optimization within finance functions.\nAbility to support and improve data governance, financial controls, and compliance.\nKnowledge of ERP, FP&A, and BI tools relevant to finance.\n\n\nGood-to-Have Skills:\nFamiliarity with cloud-based finance solutions (AWS, Azure, Google Cloud, Databricks).\nExposure to data visualization and dashboarding tools.\nExperience with SQL, Python, or other programming languages (preferred but not required).\nUnderstanding of RPA (Robotic Process Automation) tools for finance processes.\nKnowledge of machine learning and AI applications in finance.\n\n\nProfessional Certifications:\nSAP Certified Application Associate\nHyperion or Anaplan certification\nData analytics certifications (e.g., Tableau, Power BI, SQL, Python)\n\n\nSoft Skills:\nStrong problem-solving and analytical skills.\nExcellent verbal and written communication skills.\nAbility to work cross-functionally and influence stakeholders.\nStrong attention to detail and ability to handle complex financial data.\nAbility to handle several priorities and drive projects to completion.\nStrong leadership and mentorship capabilities.",Industry Type: Pharmaceutical & Life Sciences,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Finance', 'ERP', 'SAP', 'Hyperion', 'forecasting', 'Anaplan', 'Tableau', 'financial planning', 'Robotic Process Automation']",2025-06-12 06:44:25
"Technical Systems Developer - Automation, Airtable, AI, Python, N8N",Hot Print Co,3 - 8 years,Not Disclosed,[],"Were looking for a sharp, self-directed, and versatile technical generalist/builder who can help us automate operations, reduce costs, and build scalable tools across two fast-moving businesses. Someone with a developer skillset that is ready to take on a variety of challenges.\nThis is a full-time, project-based role where youll go deep on one project at a time — usually focused on automation, backend logic, AI integration, or internal tools.\nYou won’t be handed perfect specs. You’ll collaborate with the founder to understand the current workflows and goals, then be expected to execute independently.\nThis role is ideal for someone who’s excited about using technology to drive real business ROI — not just cool experiments, but tangible results like lower costs, higher margins, more revenue, and fewer people needed to run the company. This is not a job for someone who only wants to code for fun — but if you're the kind of person who loves solving real-world problems with technology and seeing your work directly impact business growth and drive clear results, this is for you.\nWHAT YOU'LL DO\nYou’ll work directly with the founder to tackle high-impact projects that reduce costs, improve margins, and boost revenue — all through tech.\nThis is a full time role, but it is project-driven. You’ll take ownership of one project at a time, execute independently, and then move on to the next. Projects vary from quick wins to longer-term builds. You’ll help scope the best tool or approach for each job — no fixed tech stack.\nFirst few projects:\n-Set up a self-hosted n8n server and migrate Make.com automations.\n-Audit and reduce Google Workspace subscription costs.\n-Learn, document, and manage our Airtable setup.\n-Build automations for lead gen and Instagram scraping.\n-Integrate Airtable with Missive to sync and manage contact data.\nDown the line, you may help us:\n-Build a custom AI-powered SMS sales agent.\n-Automate follow-ups, customer service, and content repurposing.\n-Audit our SaaS tools to cut unnecessary spending.\nSKILLS AND TOOLS YOU NEED\nWe don’t expect one person to know every tool on earth. But the more of this you’ve done before, the faster you’ll ramp up:\n-Automation tools (especially n8n)\n-Airtable (advanced base design and scripting)\n-Twilio (SMS integrations and logic)\n-Missive (email/SMS support integration)\n-CRM (HighLevel)\n-Strong backend experience (Node.js or Python)\n-Solid understanding of APIs, webhooks, and data flow logic\n-Basic scraping and browser automation (any framework)\n-AI tooling (prompt engineering, OpenAI APIs, etc.)\n-Great communication, collaboration, and planning skills\nWHAT WE EXPECT\n-You can translate messy business problems into clear technical solutions.\n-You thrive without daily check-ins. We’ll sync up to plan — you take full ownership of projects and take it from there.\n-You’re comfortable documenting systems so they’re maintainable long-term.\n-You’re results-focused. It's about ROI. You care more about the business impact than the tech used to get there.\nYOUR IMPACT\nThe goal of this role is simple: make the company more profitable, more scalable, and less reliant on human labor.\nTech is the tool we’re using to do that — whether it’s automation, AI, backend logic, or all of the above. Every project we give you should tie back to reducing costs, increasing margins, or helping us scale with fewer people.\nThis is a key hire that touches all departments — sales, operations, marketing, and more — by solving bottlenecks with smart technical solutions.\nYou’ll be building a lot of cool stuff. But it all has to work. It all has to matter.\nWORK STYLE\nThis is a role for someone who works well independently. You’ll usually collaborate closely with the founder during project kickoffs — especially when we’re mapping out a process that isn’t documented. After that, you’ll be expected to work solo, with periodic check-ins and access to support when needed.\nEach project may have its own “ramp-up time,” but we expect you to begin executing within the first couple of days. Over time, your only ongoing responsibility will be to maintain the systems you’ve built (e.g., fixing Airtable issues when they pop up or resetting things for new sales cycles).\nWORK HOURS\nOur core team works from 10 a.m. to 6 p.m. Eastern Time, and we’d like at least 4–6 hours of overlap so you can collaborate and troubleshoot live when needed.\nSALARY\nThis is a long term role that has a lot of potential for growth. Estimated starting salary is between $1200-$2600 depending on experience, qualification, and skill set, but we are looking for a strong candidate and will pay more than fairly. There is also the opportunity to earn more over time based on execution, speed, and impact.\nTHIS ROLE IS NOT FOR YOU IF:\n-You’re still learning how to build automations or write production-ready code.\n-You are a no code expert ( We need someone that can code when needed)\n-You require close supervision or detailed step-by-step instructions.\n-You want a fixed tech stack or expect to only use one set of tools / aren't willing to adapt\n-This isn’t for someone who wants to work at totally random hours. You’ll need some overlap with our working day.\nABOUT US\nWe run two growing companies — a high-volume custom apparel business and a newer software venture in the same space. We're building a lean, profitable operation where systems and automation let us scale with fewer people. — all by building better systems. You'll play a key role in that.\nHere’s a short Loom video to learn more about our team and the role:\nwww.loom.com/share/fc6eef39101a4b85b3302ffd89f44cc5?sid=5995cbc4-4da0-4c44-a0a4-447f063f7622",Industry Type: Textile & Apparel (Fashion),Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Automating', 'Artificial Intelligence', 'Creative Solutions', 'Communication Skills', 'Large Language Model', 'Ai Solutions', 'Creative Thinking', 'PHP', 'API', 'Design Thinking', 'Python']",2025-06-12 06:44:27
It Trainer,Itvedant,2 - 7 years,4-9 Lacs P.A.,['Mumbai (All Areas)'],"Conducting classroom Training on programming skills\nCreating a positive and engaging learning environment\nA passion for teaching and helping students achieve their career goals\nStrong knowledge of SQL.\nPython, Data Science, ML, DL, NLP, Power Bi",Industry Type: Education / Training,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Data Science', 'Trainer', 'Python', 'Tutoring', 'Power Bi', 'Coaching', 'Data Analytics', 'Mentoring', 'Machine Learning', 'Teaching']",2025-06-12 06:44:29
Software Developer (Python),Virtual Galaxy Infotech,2 - 4 years,Not Disclosed,['Nagpur'],"Design, develop, and maintain Python applications focused on video processing and AI-based features and Web Application.\nBuild and optimize machine learning models for tasks such as object detection, tracking, activity recognition.\n\n\n\nRequired Candidate profile\nProficient in Python and familiar with object-oriented and functional programming principles.\nSolid understanding of machine learning concepts and hands-on experience with frameworks.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'algorithms', 'Software Developer', 'machine learning', 'video processing']",2025-06-12 06:44:32
AI/ML Associate Architect,Resources Valley,8 - 13 years,Not Disclosed,"['Indore', 'Gurugram', 'Jaipur']","experience in Designing and architecting solutions with artifacts and technical documents using LLM, Generative AI, RAG, and Agentic AI applications\nStrong understanding of LLM, Generative AI, RAG, and Agentic AI app.\nExp working with large datasets\n\nRequired Candidate profile\nWorking with data scientists, engineers, and other stakeholders to understand and implement ml algorithms such as regression, classification, and clustering.\nLeading teams on the latest AI tools .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Aiml', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-12 06:44:34
Hiring For Senior Group Manager (Transformational Quality) For Vizag,WNS Holdings,12 - 20 years,15-25 Lacs P.A.,['Visakhapatnam'],"Role & responsibilities\nOverall work experience of minimum 10 yrs.; minimum 8 yrs. experience in Quality\nLean Six sigma Black belt certified (Master black belt preferred)\nExperience in automation of aspects of Quality function\nKnowledge & experience of Agile methodology & demonstrate a digital mindset\nStrong work ethic with a will-to-win attitude, demonstrates personal excellence, lives the growth mindset\nLead Lean Six Sigma culture, applying DMAIC, DMADV and DFSS methodologies to eliminate waste and enhance efficiency. Implement holistic BPR projects, integrating advanced technologies such as Robotic Process Automation (RPA) and Artificial Intelligence (AI) to streamline operations.\nProcess Redesign: Lead process redesign initiatives using Agile and Scrum methodologies, ensuring alignment with organizational goals and user needs.\nStakeholder Management: Maintain strong client relationships through proactive communication, understanding client needs, and tailoring quality strategies accordingly.\nBusiness Intelligence: Utilize Business Intelligence tools like Power BI and Tableau to analyze data and provide actionable insights for decision-making.\nLead Transactional Monitor to analyze transactional quality metrics using Six Sigma methodologies to identify trends and areas for improvement.\nQuality Assurance: Guide teams that will implement, and maintain SOPs; conduct regular internal and external audits to ensure compliance and high standards.\nSLA Management: Define, monitor, and manage Service Level Agreements (SLAs) with clients to ensure performance targets are met.\nTeam Leadership: Empower and mentor the quality team, providing training, guidance, and support to achieve departmental objectives.\n\n\n\nPreferred candidate profile",Industry Type: BPM / BPO,Department: Quality Assurance,"Employment Type: Full Time, Permanent","['Quality Improvement', 'Process Quality', 'Process Enhancement', 'Continuous Improvement', 'Transformational quality', 'Quality Management', 'Process Excellence', 'Process Improvements', 'Lean Six Sigma', 'Quality Assurance', 'Black Belt', 'Stakeholder Management']",2025-06-12 06:44:36
Snowflake Developer | HYD | Walkin | TCS-C2H | 14th June | 6+,Coventine digital Pvt Ltd,6 - 8 years,6-12 Lacs P.A.,['Hyderabad'],"Key Responsibilities:\n\nDesign, develop, and maintain scalable data pipelines using Snowflake.\nDevelop and optimize complex SQL queries, views, and stored procedures.\nMigrate data from legacy systems to Snowflake using ETL tools like Informatica, Talend, dbt, or Matillion.\nImplement data modeling techniques (Star, Snowflake schemas) and maintain data dictionary.\nEnsure performance tuning, data quality, and security across all Snowflake objects.\nIntegrate Snowflake with BI tools like Tableau, Power BI, or Looker.\nCollaborate with data analysts, data scientists, and business teams to understand requirements and deliver solutions.\nMonitor and manage Snowflake environments using tools like SnowSight, Snowsql, or CloudWatch.\nParticipate in code reviews and enforce best practices for data governance and security.\nDevelop automation scripts using Python, Shell, or Airflow for data workflows.\nRequired Skills:\n\n6+ years of experience in data engineering / data warehousing.\n3+ years hands-on experience with Snowflake Cloud Data Platform.\nStrong expertise in SQL, performance tuning, data modeling, and query optimization.\nExperience with ETL tools like Informatica, Talend, Apache NiFi, or dbt.\nProficient in cloud platforms: AWS / Azure / GCP (preferably AWS).\nGood understanding of DevOps/CI-CD principles for Snowflake deployments.\nHands-on experience with scripting languages: Python, Bash, etc.\nKnowledge of RBAC, masking policies, row access policies in Snowflake.",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['performance tuning', 'SQL queries', 'Snowflake', 'AWS / Azure / GCP', 'Python', 'masking policies', 'Informatica', 'Bash', 'Apache NiFi', 'DevOps/CI-CD', 'and query optimization', 'data modeling', 'RBAC', 'row access policies', 'Talend']",2025-06-12 06:44:39
Business Development Research Analyst,Hexolt Life Solutions,2 - 5 years,2-4.5 Lacs P.A.,['Nagpur'],Execute strategic business plans for software product adoption and market expansion.\nConduct in-depth market and competitor research for software products.\nAnalyze industry trends and emerging technologies to inform strategic decisions.,Industry Type: IT Services & Consulting,Department: Research & Development,"Employment Type: Full Time, Permanent","['Negotiation', 'SAAS', 'Artificial Intelligence', 'Strong Analytical Skills', 'Market Research And Analysis', 'Fintech', 'Cloud Solution Sales', 'Crm Tool']",2025-06-12 06:44:41
Robotic Trainer,Techvein It Solutions,1 - 5 years,Not Disclosed,"['Katihar', 'Bhagalpur', 'Kalimpong']","Job Title: Robotics & AI Instructor STEM Education\nLocation: Siliguri & Bihar\nEmployment Type: Full-Time\nExperience Required: Minimum 2 years in EdTech/STEM education\nSalary: As per industry norms\nJoining: Immediate joiners preferred\n\nJob Summary:\nWe are looking for a passionate and skilled Robotics & AI Instructor to join our STEM education team. The role involves delivering hands-on training sessions in schools, setting up Robotics and AI labs, and supporting the implementation of STEM programs aligned with CBSE and ICSE curricula.\n\nKey Responsibilities:\nConduct engaging and practical Robotics, AI, and STEM sessions for school students\nFacilitate the setup and management of Robotics & AI labs at partner schools\nGuide students through project-based learning using tools such as Arduino, sensors, Scratch, Python, etc.\nSupport teachers and school staff in understanding and running STEM programs\nCoordinate with the academic and technical teams to improve curriculum delivery\nTravel to school locations as required in Siliguri and Bihar\nRequired Qualifications and Skills:\nMinimum 2 years of experience in EdTech, STEM, or Robotics instruction\nStrong knowledge of Robotics kits, programming (basic level), electronics, and AI concepts\nExcellent communication and classroom engagement skills\nAbility to work independently and as part of a team\nWillingness to travel and conduct on-site training sessions\nBenefits:\nCompetitive salary as per industry standards\nOpportunity to work in a fast-growing, innovation-driven EdTech environment\nContinuous learning and development in Robotics and AI education\nCareer advancement opportunities based on performance\nHow to Apply:\nInterested candidates may send their updated CV to rahul.kumar@techvein.com with the subject line:\n""Application for Robotics & AI Instructor Siliguri/Bihar""",Industry Type: Emerging Technologies (Drones/Robotics),Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Arduino', 'Raspberry Pi', 'Robot Operating System', 'Arduino Uno', 'Electronics Engineering', 'Arduino Ide', 'Drone', 'Robotics', 'IOT', '3D Printing', 'Robot Programming', 'Sensors']",2025-06-12 06:44:43
Assistant Manager Biostatistician - Hyderabad,Hetero,4 - 9 years,Not Disclosed,['Hyderabad( Sanath Nagar )'],"Role & responsibilities :\n\nCollaborating with cross-functional teams (e.g., clinical researchers, medical experts, data scientists) to design clinical studies and research protocols.\nDeveloping statistical analysis plans (SAP), including the identification of primary and secondary endpoints, sample size calculations, and statistical methodologies.\nEnsuring statistical methods are aligned with regulatory requirements and industry standards, especially in clinical trials.",,,,"['Biostatistician', 'SAS', 'STATA', 'Statistical Programming', 'Biostatistics', 'R', 'Clinical SAS Programming', 'Clinical Trials']",2025-06-12 06:44:46
Professor/Assistant Professor - Supply Chain / Logistics/Port,Symbiosis Skills and Professional University (SSPU),3 - 7 years,4-9 Lacs P.A.,['Pune'],"Symbiosis Skills and Professional University, Pune is looking for suitable candidates for the post of Professor & Assistant Professor at its School of Port, Terminal Management & Logistics. Details of qualification, experience and responsibilities are as under.\n\nProfessor/Assistant Professor - Supply Chain & Logistics\nPreferred Skills & Experience:\nQualifications: Ph.D.\nMasters Degree in Supply Chain Management/ Logistics Management/Operations\n7-9 years of Teaching experience post PhD for Professor\n0-2 years of Teaching experience post PhD for Assistant Professor\nIndustry collaboration or consultancy experience in Supply Chain Management/ Logistics Management/Operations.\nShall have teaching experience preferably at the University or reputed education institution.\nRelevant Experience/ Subject Expertise in :\nIntroduction to E-Commerce\nPower BI / Tableau for Data Visualization\nSupply Chain Risk Management\nERP Risk Modules\nRisk, Disaster, and Insurance Management\nApplication of Machine Learning in Supply Chain Management\nPython Programming for Supply Chain Applications\nSupply Chain Analytics\nERP and AI Tools in Supply Chain Management\nSupply Chain Planning and Optimization\n\n2. Assistant Professor - BBA Ports & Terminal Management:\nPreferred Skills & Experience:\nQualifications: PhD\nMasters Degree in Port and Shipping Management / Maritime Management / Logistics and Supply Chain Management / International Business / Transport Management / Maritime Studies / Maritime Logistics / Export and Import Management with First Class.\nExperience - 0-2 Years teaching experience post PhD.\nSubject Expertise in: Basics of Economics, Minor & Non-Major Ports of India, Ports Accounting, Financial Management in Ports, Marketing in Port and Shipping and Maritime Logistics.\nSupervise student projects, internships, and dissertations.\nEngage in academic research and publish in peer-reviewed journals.\nCollaborate with industry partners for live projects, consultancy, and research.\nParticipate in departmental activities, committees, and academic planning.",Industry Type: Education / Training,Department: Procurement & Supply Chain,"Employment Type: Full Time, Permanent","['Professor Activities', 'assistant professor', 'Lecturer Activities', 'Education', 'Port', 'Teaching']",2025-06-12 06:44:48
UI/UX Designer,Career Foresight Hr Solution,4 - 7 years,10-13 Lacs P.A.,['Kochi'],"Proficiency in UX design tools such as Figma, Sketch, or Adobe XD.\nDeep understanding of UX principles, heuristics, and accessibility standards.\nStrong portfolio demonstrating expertise in wireframing, information architecture\n\nRequired Candidate profile\n5+ years of experience in UX design, preferably for AI, machine learning, or data-driven\nproducts.",Industry Type: IT Services & Consulting,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent","['Figma', 'Adobe Xd', 'Sketching']",2025-06-12 06:44:50
Sr. Manager Enterprise Sales Cyber Security,Leaders in delivering transformative sol...,8 - 12 years,15-25 Lacs P.A.,"['Mumbai', 'Navi Mumbai']","Drive enterprise sales of Cybersecurity, Blockchain, AI & IT solutions to corporate/ PSUs.\nDevelop sales plans, manage OEM relationships, execute account mining, upselling & receivables.\nEnsure seamless client engagement and solution delivery\n\nRequired Candidate profile\nB.Tech/ MBA 10+ Yrs exp in enterprise sales.\nProven record in achieving sales targets in Cybersecurity, Blockchain, or AI fields.\nStrong knowledge & C-Level contacts in corporate & PSU Sectors.",Industry Type: Emerging Technologies (Cybersecurity),Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Sales Strategy', 'Cybersecurity', 'Develop ODC', 'Solution Sales', 'Account Management', 'Cross-Selling', 'CRM Tools', 'OEM Relationships & Partnerships', 'Bidding', 'Pre-Sales', 'Artificial Intelligence', 'Tender Mgt.', 'Blockchain', 'AI', 'GeM', 'Upselling', 'Software Sales', 'Post-Sales', 'Client Relationship', 'IT trends']",2025-06-12 06:44:53
