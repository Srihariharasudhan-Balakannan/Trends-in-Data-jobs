job_title,company,experience,salary,locations,description,industry,department,employment_type,skills,scraped_at
Data Scientist,Dwplacesolutions,3 - 5 years,Not Disclosed,['Bengaluru'],We are seeking an experienced Data Scientist to join our team.\nThe ideal candidate will have a strong background in developing and deploying\nconversational AI solutions using Large Language Models (LLMs) and RASA\nframework.,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Machine Learning', 'Tensorflow', 'R', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Chatbot', 'Deep Learning', 'Python']",2025-06-11 06:04:41
Data Scientist - L3,Wipro,3 - 5 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions.\n\n\n\nDo\n1. Demand generation through support in Solution development\na. Support Go-To-Market strategy\ni. Contribute to development solutions, proof of concepts aligned to key offerings to enable solution led sales\nb. Collaborate with different colleges and institutes for research initiatives and provide data science courses\n2. Revenue generation through Building & operationalizing Machine Learning, Deep Learning solutions\na. Develop Machine Learning / Deep learning models for decision augmentation or for automation solutions\nb. Collaborate with ML Engineers, Data engineers and IT to evaluate ML deployment options\n3. Team Management\na. Talent Management\ni. Support on boarding and training to enhance capability & effectiveness\n\n\n\nDeliver\n\nNo.Performance ParameterMeasure\n1.Demand generation# PoC supported\n2.Revenue generation through deliveryTimeliness, customer success stories, customer use cases\n3.Capability Building & Team Management# Skills acquired\n\n\n\n\n\n\nMandatory Skills: Data Analysis.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'ML deployment', 'Deep learning models', 'Solution development', 'Talent Management', 'Machine Learning']",2025-06-11 06:04:42
Data Scientist - L3,Wipro,3 - 5 years,Not Disclosed,['Ramdurg'],"Role Purpose\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions.\nDo\n1. Demand generation through support in Solution development\na. Support Go-To-Market strategy\ni. Contribute to development solutions, proof of concepts aligned to key offerings to enable solution led sales\nb. Collaborate with different colleges and institutes for research initiatives and provide data science courses\n2. Revenue generation through Building & operationalizing Machine Learning, Deep Learning solutions\na. Develop Machine Learning / Deep learning models for decision augmentation or for automation solutions\nb. Collaborate with ML Engineers, Data engineers and IT to evaluate ML deployment options\n3. Team Management\na. Talent Management\ni. Support on boarding and training to enhance capability & effectiveness\nDeliver\n\nNo.Performance ParameterMeasure\n1.Demand generation# PoC supported\n2.Revenue generation through deliveryTimeliness, customer success stories, customer use cases\n3.Capability Building & Team Management# Skills acquired\n\n\nMandatory Skills: Data Analysis.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'python', 'team management', 'natural language processing', 'scikit-learn', 'ml deployment', 'machine learning', 'data engineering', 'artificial intelligence', 'sql', 'deep learning', 'tensorflow', 'data science', 'predictive modeling', 'statistical modeling', 'ml']",2025-06-11 06:04:44
Data Scientist,THERMAX,2 - 3 years,Not Disclosed,['Pune'],Job Details:\nWe are seeking a highly motivated and enthusiastic Junior Data Scientist with 2-3 years of experience to join our data science team. This role offers an exciting opportunity to contribute to both traditional Machine Learning projects for our commercial IoT platform and cutting-edge Generative AI initiatives.\n\nExperience,,,,"['Tensorflow', 'Manufacturing', 'Machine Learning', 'IOT', 'Python', 'Pytorch', 'Data Science', 'Aiml', 'Scikit-Learn', 'Ml']",2025-06-11 06:04:45
Machine Learning Engineer,Whats On India Media,3 - 8 years,Not Disclosed,"['Mumbai', 'Gurugram', 'Bengaluru']","Nielsen is seeking an organized, detail oriented, team player, to join the Engineering team in the role of Software Machine Learning Engineer. Nielsen's Audience Measurement Engineering platforms support the measurement of television viewing in more than 30 countries around the world. The Software Engineer will be responsible to define, develop, test, analyze, and deliver technology solutions within Nielsen's Collections platforms.\nRequired Skills\nBachelor's degree in Computer Science or equivalent degree.\n3+ years of software experience\nExperience with Machine learning frameworks and models. Pytorch experience preferred\nStrong understanding of statistical analysis and mathematical data manipulation\nWork with web technology including Java, Python, JavaScript, React/Redux, Kotlin.\nFollow best practices for software development and deployment\nUnderstanding of relational database, big data, and experience in SQL\nProficient at using GIT, GitFlow, JIRA, Gitlab and Confluence.\nStrong analytical and problem solving skills.\nOpen-minded and passionate to learn and grow technology skills\nStrong sense of accountability\nSolution-focused and ability to drive change within the organization\nExperience in writing unit/integration tests including test automation.\nStrong testing and debugging abilities, functional, analytical and technical abilities, ability to find bugs, attention to detail, troubleshooting\nAdditional Useful Skills\nA fundamental understanding of the AWS ecosystem (EC2, S3, EMR, Lambda, etc)\nExperienced in building RESTful APIs.\nExperience in writing unit/integration tests including test automation.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Ml Algorithms', 'Python', 'Pytorch']",2025-06-11 06:04:47
Data Scientist,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Data Scientist is an advanced subject matter expert, tasked with taking accountability in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nResponsible for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources\nProvides meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nDirects scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualizes the output of the models.\nResponsible for ensuring that industry standards best practices are applied to development activities.\nKnowledge and Attributes:\nAdvanced understanding of data modelling, statistical methods and machine learning techniques.\nStrong ability to thrive in a dynamic, fast-paced environment.\nStrong quantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nAdvanced understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nStrong ability to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nStrong ability to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming certification preferred.\nAgile certification preferred.\nRequired Experience:\nAdvanced demonstrated experience in a data science position in a corporate environment and/or related industry.\nAdvanced demonstrated experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nAdvanced demonstrated experience in programming languages (R, Python, etc.).\nAdvanced demonstrated experience working with and creating data architectures.\nAdvanced demonstrated experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nAdvanced demonstrated experience visualizing and/or presenting data for stakeholder use and reuse across the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'R', 'data modelling', 'data mining', 'statistical modelling', 'machine learning', 'Python', 'SQL']",2025-06-11 06:04:48
Data Scientist - ML,Client Of EDGE,8 - 13 years,Not Disclosed,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","Our client is a India's marquee global technology company. They are an international flag-bearer of technical and managerial excellence. With offices around the globe, the company has a comprehensive presence across multiple segments of the IT product and service industries.\nWe are Seeking to identify a Data Scientist Engineer role, responsible for Leading the design, development, and deployment of advanced machine learning models and algorithms. Software engineering experience with Strong knowledge of machine learning frameworks (e.g., TensorFlow, PyTorch) and generative AI libraries., Understanding of C++ programming principles.\nLead the design, development, and deployment of advanced machine learning models and algorithms.\nTrain and fine-tune generative models on large datasets, optimizing model performance and efficiency.\nExperience of developing and deploying solutions on Nvidia or Intel software stacks will be an added advantage.\nExcellent problem-solving skills and the ability to work on complex, unstructured challenges.\nProficient Understanding of distributed Computing Principles. Working knowledge of frameworks such as accelerate, deepspeed, etc.\nExperience with hiring, mentoring and leading teams of ML engineers, data engineers, etc.\nConduct in-depth data analysis, feature engineering, and data pre-processing to extract meaningful insights.\nDevelop and execute data strategies to collect, process, and store data effectively.\nWork closely with data engineers and architects to ensure data availability and quality.\nCollaborate with cross-functional teams to develop AI-powered solutions that address business challenges and opportunities.\nEnsure the successful integration of AI models into production systems.\nStay up-to-date with the latest trends and advancements in data science and AI.\nDrive research initiatives to explore and implement innovative techniques and technologies.\nLead research initiatives to develop novel AI techniques and technologies.\nCommunicate findings, insights, and project progress to non-technical stakeholders in a clear and understandable manner.\nPublications or contributions to the field of CV, NLP or generative AI are a plus.\nYour Profile:\nAn Engineer with 5+ years of experience in Leading the design, development, and deployment of advanced machine learning models and algorithms.\nUnderstanding of C++ programming.\nStrong knowledge of machine learning frameworks (e.g., TensorFlow, PyTorch) and generative AI libraries.",Industry Type: Management Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['C++', 'Machine Learning', 'Data Scientist', 'AI', 'Development', 'Deployment']",2025-06-11 06:04:50
Data Scientist (Immediate To 15 days NP),Sais It Services,5 - 8 years,10-18 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Role & responsibilities :\n\nRequirements:\nStrong expertise in NLP, text summarization, semantic search, and LLM APIs.\nPractical experience with Amazon Bedrock, OpenAI, or Hugging Face transformers.\nFamiliar with prompt tuning and few-shot learning.\nPython (pandas, langchain, boto3, NumPy, etc.)",,,,"['Open AI', 'NLP', 'Design and Development', 'LLM APIs', 'Python', 'call transcripts', 'Amazon Bedrock']",2025-06-11 06:04:52
Staff Data Engineer - Machine Learning,Netradyne,5 - 8 years,22.5-35 Lacs P.A.,['Bengaluru'],"Role and Responsibilities:\n\nYou will be embedded within a team of machine learning engineers and data scientists; responsible for building and productizing generative AI and deep learning solutions. You will:\nDesign, develop and deploy production ready scalable solutions that utilizes GenAI, Traditional ML models, Data science and ETL pipelines\nCollaborate with cross-functional teams to integrate AI-driven solutions into business operations.\nBuild and enhance frameworks for automation, data processing, and model deployment.\nUtilize Gen-AI tools and workflows to improve the efficiency and effectiveness of AI solutions.\nConduct research and stay updated with the latest advancements in generative AI and related technologies.\nDeliver key product features within cloud analytics.\n\nRequirements:\n\nB. Tech, M. Tech or PhD in Computer Science, Data Science, Electrical Engineering, Statistics, Maths, Operations Research or related domain.\nStrong programming skills in Python, SQL and solid fundamentals in computer science, particularly in algorithms, data structures, and OOP.\nExperience with building end-to-end solutions on AWS cloud infra.\nGood understanding of internals and schema design for various data stores (RDBMS, Vector databases and NoSQL).\nExperience with Gen-AI tools and workflows, and large language models (LLMs).\nExperience with cloud platforms and deploying models at scale.\nStrong analytical and problem-solving skills with a keen attention to detail.\nStrong knowledge of statistics, probability, and estimation theory.\n\nDesired Skills:\n\nFamiliarity with frameworks such as PyTorch, TensorFlow and Hugging Face.\nExperience with data visualization tools like Tableau, Graphana, Plotly-Dash.\nExposure to AWS services like Kinesis, SQS, EKS, ASG, lambda etc.\nExpertise in at least one popular Python web-framework (like FastAPI, Django or Flask).\nExposure to quick prototyping using Streamlit, Gradio, Dash etc.\nExposure to Big Data processing (Snowflake, Redshift, HDFS, EMR)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'AWS', 'Generative Artificial Intelligence', 'Python', 'Big Data Technologies']",2025-06-11 06:04:53
Specialist Data Scientist,NICE,8 - 11 years,Not Disclosed,['Pune'],"So, what’s the role all about?\nNICE provides state-of-the-art enterprise level AI and analytics for all forms of business communications between speech and digital.   We are a world class research team developing new algorithms and approaches to help companies with solving critical issues such as identifying their best performing agents, preventing fraud, categorizing customer issues, and determining overall customer satisfaction.  If you have interacted with a major contact center in the last decade, it is very likely we have processed your call. \nThe research group partners with all areas of NICE’s business to scale out the delivery of new technology and AI models to customers around the world that are tailored to their company, industry, and language needs.",,,,"['python', 'confluence', 'natural language processing', 'presentation skills', 'big data technologies', 'pyspark', 'microsoft azure', 'bert', 'machine learning', 'sql', 'tensorflow', 'data science', 'gcp', 'pytorch', 'machine learning algorithms', 'aws', 'big data', 'communication skills', 'statistics', 'jira']",2025-06-11 06:04:55
Hdfc Bank - Digital Banking - Data Scientist - Generative AI,Hdfc Bank,4 - 9 years,Not Disclosed,['Mumbai (All Areas)'],"Role - Digital Banking-Data Scientist-Digital Experience Analytics\n\nLocation - Mumbai\nGrade - Deputy Manager to Senior Manager\nMinimum 4 years experience\n\nJob Purpose:\nThe Data Scientist will design, develop and deploy advanced AI models to drive digital transformation, enhance customer experience, optimize operations and mitigate risks. This role requires a sound understanding of AI/ML techniques and their application to challenges such as customer engagement and process automation.",,,,"['Data Science', 'Artificial Intelligence', 'Machine Learning', 'Generative AI', 'Risk Analytics', 'Data Analytics']",2025-06-11 06:04:56
Data Scientist(0217),A Reputed Organization,5 - 10 years,Not Disclosed,"['Kolkata', 'Pune', 'Bengaluru']","Lead the design, development, and deployment of advanced machine learning models and algorithms.\nTrain and fine-tune generative models on large datasets, optimizing model performance and efficiency.\nStrong knowledge of machine learning frameworks (e.g., TensorFlow, PyTorch) and generative AI libraries., Understanding of C++ programming principles.\nExperience of developing and deploying solutions on Nvidia or Intel software stacks will be an added advantage.\nExcellent problem-solving skills and the ability to work on complex, unstructured challenges.\nProficient Understanding of distributed Computing Principles. Working knowledge of frameworks such as accelerate, deepspeed, etc.\nExperience with hiring, mentoring and leading teams of ML engineers, data engineers, etc.\nConduct in-depth data analysis, feature engineering, and data preprocessing to extract meaningful insights.\nDevelop and execute data strategies to collect, process, and store data effectively.\nWork closely with data engineers and architects to ensure data availability and quality.\nCollaborate with cross-functional teams to develop AI-powered solutions that address business challenges and opportunities.\nEnsure the successful integration of AI models into production systems.\nStay up-to-date with the latest trends and advancements in data science and AI.\nDrive research initiatives to explore and implement innovative techniques and technologies.\nLead research initiatives to develop novel AI techniques and technologies.\nCommunicate findings, insights, and project progress to non-technical stakeholders in a clear and understandable manner.\nPublications or contributions to the field of CV, NLP or generative AI are a plus.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'C++', 'Data Scientist', 'AI']",2025-06-11 06:04:58
Engineer,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Bengaluru'],"Req ID: 327976\n\nWe are currently seeking a Engineer to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n Key Responsibilities: \n\nServe as the primary technical expert on DataRobot""™s AI platform, providing deep technical guidance and support.\n\nCollaborate with data scientists, AI engineers, and business stakeholders to implement and optimize DataRobot solutions.\n\nTroubleshoot and resolve complex issues related to DataRobot configuration, deployment, and monitoring.\n\nOnboard and configure existing SAS-based and DataRobot Prime v6 Python models into DataRobot v8.0.21.\n\nIngest LST report files from SAS and upload metrics into DataRobot.\n\nExecute onboarded models with historical data and generate monitoring outputs within DataRobot.\n\nCompare current Power BI dashboard metrics with DataRobot outputs and develop equivalent visualizations within the platform.\n\nLead the upgrade of DataRobot from version 8 to version 11 on Azure, working closely with technology partners.\n\nUnderstand and configure necessary Azure services (e.g., AKS, storage, networking) to support DataRobot deployment.\n\nDebug and resolve AKS container setup/configuration issues and propose scalable solutions.\n\nProvide training and support to internal teams on DataRobot functionalities and best practices.\n\nDevelop and maintain comprehensive documentation including user guides, technical manuals, and best practice guidelines.\n\nStay current with advancements in AI/ML and integrate relevant innovations into DataRobot solutions.\n\nWork through the Shield process and manage Jira stories for PreDev, PostDev, Prod, and RTx environments.\n\n Required Skills & Qualifications: \n\nProven experience with DataRobot platform, especially in enterprise-scale deployments.\n\nStrong understanding of Azure cloud services, including AKS, networking, and storage.\n\nHands-on experience with containerized deployments and Kubernetes troubleshooting.\n\nProficiency in Python and familiarity with SAS model structures.\n\nExperience with model monitoring, performance metrics, and visualization tools like Power BI.\n\nExcellent problem-solving skills and ability to work independently in a fast-paced environment.\n\nStrong communication skills for cross-functional collaboration and training delivery.\n\nFamiliarity with enterprise deployment processes, including Jira-based workflow management.\n\n\nPreferred Qualifications:\n\nExperience working in regulated environments such as banking or finance.\n\nKnowledge of U.S. Bank""™s Shield process or similar enterprise governance frameworks.\n\nPrior involvement in AI/ML model lifecycle management and MLOps practices",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure cloud services', 'kubernetes', 'artificial intelligence', 'ml', 'python', 'aks', 'networking', 'jquery', 'providing training', 'asp.net', 'debugging', 'web api', 'html', 'mvc', 'wcf', 'jira', 'c#', 'sas', 'entity framework', 'power bi', 'microsoft azure', 'javascript', 'sql server', 'linq', 'troubleshooting', '.net']",2025-06-11 06:05:00
Opening For Senior Machine Learning Engineer with Fareportal,Fareportal,2 - 5 years,Not Disclosed,['Gurugram'],"Title: Senior Machine Learning Engineer\nLocation: Gurgaon, IN\nType: (Hybrid, In-Office)\nJob Description\n\nWho We Are:\nFareportal is a travel technology company powering a next-generation travel concierge service. Utilizing its innovative technology and company owned and operated global contact centres, Fareportal has built strong industry partnerships providing customers access to over 500 airlines, a million lodgings, and hundreds of car rental companies around the globe. With a portfolio of consumer travel brands including CheapOair and OneTravel, Fareportal enables consumers to book-online, on mobile apps for iOS and Android, by phone, or live chat. Fareportal provides its airline partners with access to a broad customer base that books high-yielding international travel and add-on ancillaries.",,,,"['Containerization', 'Machine Learning', 'Python', 'azure', 'sql', 'api', 'nosql', 'deployment']",2025-06-11 06:05:01
Senior Machine Learning Engineer,"Technology, Information and Internet",5 - 10 years,30-35 Lacs P.A.,['Gurugram'],"We are seeking a highly skilled Senior Machine Learning Engineer to join our dynamic team. The ideal candidate will have a deep understanding of Machine Learning, AI, and cloud platforms like Azure. You will play a key role in designing, developing, and deploying ML models and Generative AI solutions to solve complex business problems.\n\nRole overview\nEngineering Masters degree or PhD in Data Science, Statistics, Mathematics, or related fields\n5 years+ experience in a Machine Learning Engineer role into large corporate organizations\nExperience of working with ML models in a cloud ecosystem.\nStatistics & amp; Machine Learning\nStatistics: Strong understanding of statistical analysis and modelling techniques (e.g., regression analysis, hypothesis testing, time series analysis)\nClassical ML: Very strong knowledge in classical ML algorithms for regression & classification, supervised and unsupervised machine learning, both theoretical and practical (e.g. using scikit-learn, xgboost)\nML niche: Expertise in at least one of the following ML specialisations: Timeseries forecasting / Natural Language Processing / Computer Vision\nDeep Learning: Good knowledge of Deep Learning fundamentals (CNN, RNN, transformer architecture, attention mechanism, ) and one of the deep learning frameworks (pytorch, tensorflow, keras)\nGenerative AI: Good understanding of Generative AI specificities and previous experience in working with Large Language Models is a plus (e.g. with openai, langchain).\nMLOps\nModel strategy: Expertise in designing, implementing, and testing machine learning strategies.\nModel integration: Very strong skills in integrating a machine learning algorithm in a data science application in production.\nModel performance: Deep understanding of model performance evaluation metrics and existing libraries (e.g., scikit-learn, evidently)\nModel deployment: Experience in deploying and managing machine learning models in production either using specific cloud platform, model serving frameworks, or containerization.\nModel monitoring: Experience with model performance monitoring tools is a plus (Grafana, Prometheus).\nSoftware Engineering\nPython: Very strong coding skills in Python including modularity, OOP, data & config manipulation frameworks (e.g., pandas, pydantic) etc.\nPython ecosystem: Strong knowledge of tooling in Python ecosystem such as dependency management tooling (venv, poetry), documentation frameworks (e.g. sphinx, mkdocs, jupyter-book), testing frameworks (unittest,pytest)\nSoftware engineering practices: Experience in putting in place good software engineering practices such as design patterns, testing (unit, integration), clean code, code formatting etc.\nDebugging: Ability to troubleshoot and debug issues within machine learning pipelines.\nData Science Experimentation and Analytics\nData Visualization: Knowledge of data visualization tools such as plotly, seaborn, matplotlib, etc. to visualise, interpret and communicate the results of machine learning models to stakeholders. Basic knowledge of PowerBI is a plus.\nData Cleaning: Experience with data cleaning and preprocessing techniques such as feature scaling, dimensionality reduction, and outlier detection (e.g. with pandas, scikit-learn).\nData Science Experiments: Understanding of experimental design and A/B testing methodologies.\nData Processing:\nDatabricks/Spark: Basic knowledge of PySpark for big data processing\nDatabases: Basic knowledge of SQL to query data in internal systems\nData Formats: Familiarity with different data storage formats such as Parquet and Delta.\nDevOps\nAzure DevOps: Experience using a DevOps platform such as Azure DevOps for using Boards, Repositories, Pipelines\nGit: Experience working with code versioning (git), branch strategies, and collaborative work with pull requests. Proficient with the most basic git commands.\nCI / CD: Experience in implementing/maintaining pipelines for continuous integration (including execution of testing strategy) and continuous deployment is preferable.\nCloud Platform:\nAzure Cloud: Previous experience with services like Azure Machine Learning Services and/or Azure Databricks on Azure is preferable.\nSoft skills:\nStrong analytical and problem-solving skills, with attention to detail\nExcellent verbal and written communication and pedagogical skills with technical and non-technical teams\nExcellent teamwork and collaboration skills\nAdaptability and reactivity to new technologies, tools, and techniques\nFluent in English.\nWhat would you do here:\nManaging the lifecycle of machine learning models\nDevelop and implement machine learning models to solve complex business problems.\nEnsure that models are accurate, efficient, reliable, and scalable.\nDeploy machine learning models to production environments, ensuring that models are integrated with software systems.\nMonitor machine learning models in production, ensuring that models are performing as expected and that any errors or performance issues are identified and resolved quickly.\nMaintain machine learning models over time. This includes updating models as new data becomes available, retraining models to improve performance, and retiring models that are no longer effective.\nDevelop and implement policies and procedures for ensuring the ethical and responsible use of machine learning models. This includes addressing issues related to bias, fairness, transparency, and accountability.\nContinuous Improvements:\nStay up to date with the latest developments in the field: read research papers, attend conferences, and participate in trainings to expand their knowledge and skills.\nIdentify and evaluate new technologies and tools that can improve the efficiency and effectiveness of machine learning projects.\nPropose and implement optimizations for current machine learning workflows and systems.\nProactively identify areas of improvement within the pipelines.\nMake sure that created code is compliant with our set of engineering standards.\nCollaboration with other data experts (Data Engineers, Platform Engineers, and Data Analysts)\nParticipate to pull requests reviews coming from other team members.\nAsk for review and comments when submitting their own work.\nActively participate to the day-to-day life of the project (Agile rituals), the data science team (DS meeting) and the rest of the Global Engineering team.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure', 'Generative AI', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-11 06:05:03
Machine Learning Engineer,SRS Infoway,5 - 7 years,16-17 Lacs P.A.,"['Pune', 'Bengaluru']","ML Engineer with 8+ yrs in Data & Analytics, 5+ in ML. Skilled in Python, FastAPI, Azure, APIs, and deployment. Agile team player, handles multiple projects, values diversity, inclusion, and flexibility.\nMail:kowsalya.k@srsinfoway.com",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Temporary/Contractual","['Power BI', 'Analytics modeling', 'Python', 'ML']",2025-06-11 06:05:04
"Data Scientist with EDA, Python, SQL and Business Analysis",Cognizant,8 - 11 years,Not Disclosed,['Hyderabad'],"Job Summary\nWe are seeking a highly skilled Data Scientist with Business analysis with good hands on in Python , SQL , EDA Data Visualization with 3 to 12+ years of experience\nKey Responsibilities:\nPerform exploratory data analysis (EDA) to uncover trends, patterns, and insights.\nDevelop and maintain dashboards and reports to visualize key business metrics.\nCollaborate with cross-functional teams to gather requirements and deliver data-driven solutions.",,,,"['python', 'eda', 'data analysis', 'data management', 'modeling', 'analytical', 'data manipulation', 'query', 'predictive analytics', 'microsoft azure', 'business analysis', 'cloud platforms', 'business analytics', 'machine learning', 'dashboards', 'sql', 'analytics', 'gcp', 'statistical modeling', 'data visualization', 'aws']",2025-06-11 06:05:06
Principal Machine Learning Engineer,Amgen Inc,2 - 7 years,Not Disclosed,['Hyderabad'],"What you will do\nWe are seeking a highly skilled Machine Learning Engineer with a strong MLOps background to join our team. You will play a pivotal role in building and scaling our machine learning models from development to production. Your expertise in both machine learning and operations will be essential in creating efficient and reliable ML pipelines.\nRoles & Responsibilities:\nCollaborate with data scientists to develop, train, and evaluate machine learning models.\nBuild and maintain MLOps pipelines, including data ingestion, feature engineering, model training, deployment, and monitoring.\nLeverage cloud platforms (AWS, GCP, Azure) for ML model development, training, and deployment.\nImplement DevOps/MLOps best practices to automate ML workflows and improve efficiency.\nDevelop and implement monitoring systems to track model performance and identify issues.\nConduct A/B testing and experimentation to optimize model performance.\nWork closely with data scientists, engineers, and product teams to deliver ML solutions.\nGuide and mentor junior engineers in the team\nStay updated with the latest trends and advancements\n\nBasic Qualifications:\nDoctorate degree and 2 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nMasters degree and 8 to 10 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nBachelors degree and 10 to 14 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nDiploma and 14 to 18 years of years of Computer Science, Statistics, and Data Science, Machine Learning experience\nPreferred Qualifications:\nMust-Have Skills:\nStrong foundation in machine learning algorithms and techniques\nExperience in MLOps practices and tools (e.g., MLflow, Kubeflow, Airflow); Experience in DevOps tools (e.g., Docker, Kubernetes, CI/CD)\nProficiency in Python and relevant ML libraries (e.g., TensorFlow, PyTorch, Scikit-learn)\nOutstanding analytical and problem-solving skills; Ability to learn quickly; Excellent communication and interpersonal skills\nGood-to-Have Skills:\nExperience with big data technologies (e.g., Spark), and performance tuning in query and data processing\nExperience with data engineering and pipeline development\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification\nKnowledge of NLP techniques for text analysis and sentiment analysis\nExperience in analyzing time-series data for forecasting and trend analysis\nFamiliar with AWS, Azure, or Google Cloud;\nFamiliar with Databricks platform for data analytics and MLOps\nProfessional Certifications\nCloud Computing and Databricks certificate preferred\nSoft Skills:\nExcellent analytical and fixing skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Azure', 'NLP', 'MLOps', 'Databricks', 'AWS', 'Google Cloud']",2025-06-11 06:05:07
"Mid Data Science & AIML, GenAI Lead/Engineer","NTT DATA, Inc.",3 - 6 years,Not Disclosed,['Bengaluru'],"Req ID: 312501\n\nWe are currently seeking a Mid Data Science & AIML, GenAI Lead/Engineer to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nJob DutiesJob TitleData Science & AIML, GenAI Lead/Engineer\n\nKey Responsibilities:\n""¢ Develop and implement traditional machine learning algorithms.\n""¢ Deploy at least one model in a production environment.\n""¢ Write and maintain Python code for data science and machine learning projects.\n\nMinimum Skills RequiredPreferred Qualifications:\n""¢ Knowledge of Deep Learning (DL) techniques.\n""¢ Experience working with Generative AI (GenAI) and Large Language Models (LLM).\n""¢ Exposure to Langchain.\n\n""‹""‹""‹""‹""‹""‹""‹",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'artificial intelligence', 'deep learning', 'data science', 'algorithms', 'natural language processing', 'scikit-learn', 'dl', 'aiml', 'numpy', 'sql', 'tensorflow', 'r', 'predictive modeling', 'statistical modeling', 'machine learning algorithms', 'statistics']",2025-06-11 06:05:09
Senior Machine Learning Engineer - NLP,Avalara Technologies,5 - 8 years,Not Disclosed,[],"What You'll Do\nWe are looking for experienced Machine Learning Engineers with a background in software development and a deep enthusiasm for solving complex problems. You will lead a dynamic team dedicated to designing and implementing a large language model framework to power diverse applications across Avalara. Your responsibilities will span the entire development lifecycle, including conceptualization, prototyping and delivery of the LLM platform features.\nYou will have a blend of technical skills in the fields of AI & Machine Learning especially with LLMs and a deep-seated understanding of software development practices where you'll work with a team to ensure our systems are scalable, performant and accurate. You will be reporting to Senior Manager, AI/ML.",,,,"['Machine Learning', 'LLMs', 'Prometheus', 'Grafana', 'NLP', 'Docker', 'Terraform', 'MLFlow', 'Postgres', 'AWS', 'GitLab', 'Python', 'Kubernetes']",2025-06-11 06:05:11
Data Scientist - 25 To 30 lacs. Remote,Markelytics Limited,1 - 3 years,25-30 Lacs P.A.,[],"We only hire from Top Tier Universities including IITs, BITS, DCE/NSIT, ISI, Top NITs etc.\n\nThis role is only suitable for candidates with between 1 to 4 years experience. People with more than 4 years of experience need not apply.\n\nThis is an URGENT requirement. We are hiring for a UK based Fintech company (name is kept confidential). The company is seeking an early stage Data Scientist to join the team and support the design, development, and Machine Learning and AI use-cases. Your work will directly support strategic initiatives and improve business outcomes.\n\n\nJob Summary:\n\nWe are seeking a motivated Data Scientist to join our Data and AI team. The ideal candidate will assist in analysing complex datasets, building predictive models, and contributing to data-driven decision-making. This entry-level role is perfect for someone eager to apply their technical skills and grow in a collaborative, innovative environment.\n\n\nKey Responsibilities:\n\nCollect, clean, and preprocess structured and unstructured data from various sources\nPerform exploratory data analysis (EDA) to identify trends, patterns, and insights\nDevelop, test, and deploy basic machine learning models under senior team guidance\nCreate visualisations and dashboards to communicate findings to stakeholders\nCollaborate with cross-functional teams (e.g., product, engineering) to support business objectives\nAssist in maintaining data pipelines and ensuring data quality\nStay updated on industry trends and emerging tools in data science\n\n\nQualifications:\n\nBachelors degree in data science, Computer Science, Statistics, Mathematics, or a related field\n1-3 years of experience in data science or a related role (internships or academic projects count)\nProficiency in Python for data analysis (e.g., pandas, NumPy, scikit-learn)\nStrong analytical and problem-solving skills\nExcellent communication skills to explain technical concepts to non-technical audiences.\nUnderstanding of machine learning algorithms (e.g., regression, classification, clustering).\n\n\nNice to Have:\n\nInternship or project experience in data science or analytics\nExposure to Gen AI architectures (RAG, MCP etc.)\nExperience working with cloud platforms (e.g., AWS, GCP, Azure)\nExperience with SQL for data querying\nKnowledge of version control (e.g., Git)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Python', 'Algebra', 'Data Wrangling', 'Probability', 'Data Analysis', 'Mathematics', 'Data Processing', 'machine learning', 'Statistics']",2025-06-11 06:05:12
Machine Learning Scientist,Glynac,2 - 7 years,6-12 Lacs P.A.,['Bengaluru'],Responsibilities:\n* Develop machine learning models using PyTorch.\n* Optimize model performance through data analysis and experimentation.\n* Collaborate with cross-functional teams on product development.\n\n\nWork from home,Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Pytorch', 'Artificial Intelligence', 'Natural Language Processing']",2025-06-11 06:05:14
Data/ML Ops Engineer,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Additional Career Level Description:\n\n\nKnowledge and application:\nSeasoned, experienced professional; has complete knowledge and understanding of area of specialization.\nUses evaluation, judgment, and interpretation to select right course of action.\n\n\n\nProblem solving:\nWorks on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\nResolves and assesses a wide range of issues in creative ways and suggests variations in approach.\n\n\n\nInteraction:\nEnhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\nWorks with others outside of own area of expertise, with the ability to adapt style to differing audiences and often advises others on difficult matters.\n\n\n\nImpact:\nImpacts short to medium term goals through personal effort or influence over team members.\n\n\n\nAccountability:\nAccountable for own targets with work reviewed at critical points.\nWork is done independently and is reviewed at critical points.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ML Ops', 'python', 'spark', 'big data', 'data engineering', 'artificial intelligence', 'ml', 'sql']",2025-06-11 06:05:15
Lead Data Scientist,Tothr,8 - 12 years,20-22.5 Lacs P.A.,"['Chennai', 'Bengaluru']","Experience working closely with other data scientists, data engineers' software engineers, data managers and business partners.\n7+ years in designing, planning, prototyping, productionizing, maintaining\nknowledge in Python, Go, Java,\nSQL knowledge",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Statistical Modeling', 'Python Development', 'Machine Learning', 'Deep Learning', 'Generative Ai', 'Advance Sql']",2025-06-11 06:05:17
GenAI Engineer,Xebia It Architects,5 - 10 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","About Xebia\nXebia is a trusted advisor in the modern era of digital transformation, serving hundreds of leading brands worldwide with end-to-end IT solutions. The company has experts specializing in technology consulting, software engineering, AI, digital products and platforms, data, cloud, intelligent automation, agile transformation, and industry digitization. In addition to providing high-quality digital consulting and state-of-the-art software development, Xebia has a host of standardized solutions that substantially reduce the time-to-market for businesses.\nXebia also offers a diverse portfolio of training courses to help support forward-thinking organizations as they look to upskill and educate their workforce to capitalize on the latest digital capabilities. The company has a strong presence across 16 countries with development centres across the US, Latin America, Western Europe, Poland, the Nordics, the Middle East, and Asia Pacific.\n\nJob Title: Generative AI Engineer\nExp: 5 9 yrs\nLocation: Bengaluru, Chennai, Gurgaon & Pune\nJob Summary:\nWe are seeking a highly skilled Generative AI Engineer with hands-on experience in developing and deploying cutting-edge AI solutions using AWS, Amazon Bedrock, and agentic AI frameworks. The ideal candidate will have a strong background in machine learning and prompt engineering, with a passion for building intelligent, scalable, and secure GenAI applications.\nKey Responsibilities:\n\nDesign, develop, and deploy Generative AI models and pipelines for real-world use cases.\nBuild and optimize solutions using AWS AI/ML services, including Amazon Bedrock, SageMaker, and related cloud-native tools.\nDevelop and orchestrate Agentic AI systems, integrating autonomous agents with structured workflows and dynamic decision-making.\nCollaborate with cross-functional teams including data scientists, cloud engineers, and product managers to translate business needs into GenAI solutions.\nImplement prompt engineering, fine-tuning, and retrieval-augmented generation (RAG) techniques to optimize model performance.\nEnsure robustness, scalability, and compliance in GenAI workloads deployed in production environments.\nRequired Skills & Qualifications:\n\nStrong experience with Generative AI models (e.g., GPT, Claude, Mistral, etc.)\nHands-on experience with Amazon Bedrock and other AWS AI/ML services.\nProficiency in building and managing Agentic AI systems using frameworks like LangChain, AutoGen, or similar.\nSolid understanding of cloud-native architectures and ML Ops on AWS.\nProficiency in Python and relevant GenAI/ML libraries (Transformers, PyTorch, LangChain, etc.)\nFamiliarity with security, cost, and governance best practices for GenAI on cloud.\nPreferred Qualifications:\n\nAWS certifications (e.g., AWS Certified Machine Learning Specialty)\nExperience with LLMOps tools and vector databases (e.g., Pinecone, FAISS, Weaviate)\nBackground in NLP, knowledge graphs, or conversational AI.\nWhy Join Us?\nWork on cutting-edge AI technologies that are transforming industries.\nCollaborative and innovative environment.\nOpportunities for continuous learning and growth.",Industry Type: IT Services & Consulting,"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['GenAI', 'Agentic Ai', 'Ml']",2025-06-11 06:05:18
Associate Data Engineer,"NTT DATA, Inc.",1 - 3 years,Not Disclosed,"['New Delhi', 'Chennai', 'Bengaluru']","Your day at NTT DATA\nWe are seeking an experienced Data Engineer to join our team in delivering cutting-edge Generative AI (GenAI) solutions to clients. The successful candidate will be responsible for designing, developing, and deploying data pipelines and architectures that support the training, fine-tuning, and deployment of LLMs for various industries. This role requires strong technical expertise in data engineering, problem-solving skills, and the ability to work effectively with clients and internal teams.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesign, develop, and manage data pipelines and architectures to support GenAI model training, fine-tuning, and deployment\nData Ingestion and Integration: Develop data ingestion frameworks to collect data from various sources, transform, and integrate it into a unified data platform for GenAI model training and deployment.\nGenAI Model Integration: Collaborate with data scientists to integrate GenAI models into production-ready applications, ensuring seamless model deployment, monitoring, and maintenance.\nCloud Infrastructure Management: Design, implement, and manage cloud-based data infrastructure (e.g., AWS, GCP, Azure) to support large-scale GenAI workloads, ensuring cost-effectiveness, security, and compliance.\nWrite scalable, readable, and maintainable code using object-oriented programming concepts in languages like Python, and utilize libraries like Hugging Face Transformers, PyTorch, or TensorFlow\nPerformance Optimization: Optimize data pipelines, GenAI model performance, and infrastructure for scalability, efficiency, and cost-effectiveness.\nData Security and Compliance: Ensure data security, privacy, and compliance with regulatory requirements (e.g., GDPR, HIPAA) across data pipelines and GenAI applications.\nClient Collaboration: Collaborate with clients to understand their GenAI needs, design solutions, and deliver high-quality data engineering services.\nInnovation and R&D: Stay up to date with the latest GenAI trends, technologies, and innovations, applying research and development skills to improve data engineering services.\nKnowledge Sharing: Share knowledge, best practices, and expertise with team members, contributing to the growth and development of the team.\n\nBachelors degree in computer science, Engineering, or related fields (Masters recommended)\nExperience with vector databases (e.g., Pinecone, Weaviate, Faiss, Annoy) for efficient similarity search and storage of dense vectors in GenAI applications\n5+ years of experience in data engineering, with a strong emphasis on cloud environments (AWS, GCP, Azure, or Cloud Native platforms)\nProficiency in programming languages like SQL, Python, and PySpark\nStrong data architecture, data modeling, and data governance skills\nExperience with Big Data Platforms (Hadoop, Databricks, Hive, Kafka, Apache Iceberg), Data Warehouses (Teradata, Snowflake, BigQuery), and lakehouses (Delta Lake, Apache Hudi)\nKnowledge of DevOps practices, including Git workflows and CI/CD pipelines (Azure DevOps, Jenkins, GitHub Actions)\nExperience with GenAI frameworks and tools (e.g., TensorFlow, PyTorch, Keras)\nNice to have:\nExperience with containerization and orchestration tools like Docker and Kubernetes\nIntegrate vector databases and implement similarity search techniques, with a focus on GraphRAG is a plus\nFamiliarity with API gateway and service mesh architectures\nExperience with low latency/streaming, batch, and micro-batch processing\nFamiliarity with Linux-based operating systems and REST APIs",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Apache Iceberg', 'Faiss', 'PySpark', 'Kafka', 'Pinecone', 'GitHub Actions', 'Snowflake', 'Apache Hudi', 'AWS', 'Azure DevOps', 'Python', 'Azure', 'BigQuery', 'Hadoop', 'Annoy', 'Teradata', 'SQL', 'Jenkins', 'Hive', 'Cloud Native platforms', 'GCP', 'Delta Lake', 'Databricks', 'Weaviate']",2025-06-11 06:05:20
Lead Data Scientist,R Systems International,8 - 10 years,Not Disclosed,"['Noida', 'Pune', 'Chennai']","Job Title: Lead Data Scientist\n\nWe are seeking a highly skilled and experienced Lead Data Scientist to join our dynamic team. In this role, you will be responsible for leading data-driven projects, mentoring junior data scientists, and guiding the organization in making strategic decisions based on data insights.\n\nKey Responsibilities:\n- Develop and implement advanced statistical models and algorithms to analyze complex data sets.\n- Collaborate with cross-functional teams to identify business opportunities and translate them into data-driven solutions.\n- Mentor and oversee a team of data scientists, providing guidance on best practices and techniques in data analysis and modeling.\n- Communicate findings and insights to stakeholders through presentations, reports, and visualizations.\n- Stay current with industry trends and emerging technologies in data science and analytics.\n- Design and implement experiments to validate models and hypotheses.\n- Ensure the quality and integrity of data throughout the analytic process.\n\nQualifications:\n- Master's. in Computer Science, Statistics, Mathematics, or a related field.\n- Proven experience as a Data Scientist, with a strong portfolio of successful projects.\n- Expertise in programming languages such as Python or R, as well as experience with machine learning frameworks.\n- Strong knowledge of statistical analysis and modeling techniques.\n- Excellent problem-solving skills and the ability to work with large and complex data sets.\n- Strong communication skills, with the ability to convey technical concepts to non-technical stakeholders.\n- Experience in leading and managing teams is a plus.\n\nWe offer a competitive salary, comprehensive benefits, and the opportunity to work in a collaborative and innovative environment. If you are passionate about data science and eager to make a significant impact, we would love to hear from you.",,,,"['algorithms', 'python', 'modeling', 'data analysis', 'mathematics', 'data processing', 'data pipeline', 'machine learning', 'data collection', 'analytics', 'r', 'data science', 'computer science', 'predictive modeling', 'science', 'machine learning algorithms', 'programming', 'reporting', 'statistics', 'communication skills']",2025-06-11 06:05:21
Sr. Executive Data Engineering Analytics,IndiGo,5 - 10 years,Not Disclosed,['Gurugram'],"Role & responsibilities\nDevelop in Python, create responsive dashboards, and manage large datasets.\nDesign and deploy Power BI reports based on business needs.\nApply machine learning, deep learning, and statistical analysis (e.g., classification, regression, sentiment analysis, time series).\nTranslate technical concepts for non-technical stakeholders.\nDesign and implement Big Data platform components (batch/stream processing, memory cache, SQL query layer, rule engine).\nBuild scalable data solutions.\nConduct root cause analysis, troubleshoot applications, and support configurations.\nAutomate processes and reporting within the Operations Control Center (OCC).\nCollaborate with leadership to solve business problems and define objectives.\nRecommend and implement automated solutions.\nPerform data analysis and apply statistical methods for decision-making.\n\nPreferred candidate profile\n\nEducation: Bachelors or Master’s in Computer Science, Engineering, or related field. (Mathematics/Statistics)\nExperience: 5–10 years in data engineering & analytics.\nSkills:\nPython (hands-on)\nPower BI (dashboarding)\nSQL/SSMS (data storage and extraction)\nPower Automate / Power Apps (nice to have)",Industry Type: Travel & Tourism,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'SQL', 'SSMS', 'Power Bi', 'Power Automate']",2025-06-11 06:05:23
Data Analyst-Having Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Analyst\n\nLocation: Bangalore\nExperience: 8 - 15 Yrs\nType: Full-time\n\nRole Overview\n\nWe are seeking a skilled Data Analyst to support our platform powering operational intelligence across airports and similar sectors. The ideal candidate will have experience working with time-series datasets and operational information to uncover trends, anomalies, and actionable insights. This role will work closely with data engineers, ML teams, and domain experts to turn raw data into meaningful intelligence for business and operations stakeholders.\n\nKey Responsibilities\n\nAnalyze time-series and sensor data from various sources\nDevelop and maintain dashboards, reports, and visualizations to communicate key metrics and trends.\nCorrelate data from multiple systems (vision, weather, flight schedules, etc) to provide holistic insights.\nCollaborate with AI/ML teams to support model validation and interpret AI-driven alerts (e.g., anomalies, intrusion detection).\nPrepare and clean datasets for analysis and modeling; ensure data quality and consistency.\nWork with stakeholders to understand reporting needs and deliver business-oriented outputs.\n\n\nQualifications & Required Skills\n\nBachelors or Masters degree in Data Science, Statistics, Computer Science, Engineering, or a related field.\n5+ years of experience in a data analyst role, ideally in a technical/industrial domain.\nStrong SQL skills and proficiency with BI/reporting tools (e.g., Power BI, Tableau, Grafana).\nHands-on experience analyzing structured and semi-structured data (JSON, CSV, time-series).\nProficiency in Python or R for data manipulation and exploratory analysis.\nUnderstanding of time-series databases or streaming data (e.g., InfluxDB, Kafka, Kinesis).\nSolid grasp of statistical analysis and anomaly detection methods.\nExperience working with data from industrial systems or large-scale physical infrastructure.\n\n\nGood-to-Have Skills\n\nDomain experience in airports, smart infrastructure, transportation, or logistics.\nFamiliarity with data platforms (Snowflake, BigQuery, Custom-built using open-source).\nExposure to tools like Airflow, Jupyter Notebooks and data quality frameworks.\nBasic understanding of AI/ML workflows and data preparation requirements.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Kafka', 'SQL', 'airports', 'InfluxDB', 'Airflow', 'structured Data', 'time-series', 'JSON', 'Tableau', 'Grafana', 'R', 'AI/ML', 'Kinesis', 'Snowflake', 'time-series databases', 'Data Preparation', 'Python', 'smart infrastructure', 'BigQuery', 'streaming data', 'Power BI', 'CSV', 'transportation', 'logistic', 'reporting tools']",2025-06-11 06:05:24
Hiring - Data Scientist Lead,AGS Health,6 - 10 years,13-23 Lacs P.A.,['Ahmedabad'],Hi\n\nImmediate opening for Data Scientist Lead\n\nLocation : Ahmedabad ( Onsite only )\n\nExperience : 6 + years,,,,"['Tensorflow', 'Deep Learning', 'Pytorch', 'Data Science', 'NLP', 'Natural Language Processing', 'LLM', 'Machine Learning', 'Scikit-Learn', 'Nltk', 'Keras', 'Spacy', 'Python']",2025-06-11 06:05:26
BFSI Data and Analytics Project Lead - CITI Bank,"NTT DATA, Inc.",12 - 17 years,Not Disclosed,['Bengaluru'],"Req ID: 326459\n\nWe are currently seeking a BFSI Data and Analytics Project Lead - CITI Bank to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesData & Analytics Project Lead with over 12+ years of experience in BFSI Domain\nThe Data and Analytics Delivery Manager will oversee the successful delivery of the Client's data and analytics projects, ensuring our clients derive maximum value from their data assets. This leadership role involves setting strategy, managing delivery teams, collaborating across functions, and upholding data governance and quality standards. The ideal candidate brings strong technical and business acumen to build and execute data-driven strategies aligned with the Client's mission of transforming their business with data-driven insights.\nThe core responsibilities for the job include the following:\nProject and Program Oversight:\n""¢ Oversee end-to-end delivery of complex data and analytics projects, ensuring timely, high-quality, and cost-effective outcomes.\n""¢ Establish project governance, risk management, and quality assurance standards for effective project delivery.\n""¢ Monitor project portfolios and allocate resources to optimize productivity across multiple client engagements.\n\nStakeholder Collaboration and Engagement:\n""¢ Serve as the primary liaison between data delivery teams, sales, product, and client-facing teams to ensure client needs are met.\n""¢ Present data strategies, project status, and insights effectively to both technical and non-technical stakeholders, fostering alignment.\n""¢ Drive collaboration with product management and engineering teams to align on data needs and operational goals.\n\nInnovation and Technology Adoption:\n""¢ Stay abreast of the latest trends in GenAI, Agentic AI in data engineering, data science, machine learning, and AI to enhance the Client's data capabilities.\n""¢ Must have experience in Cloud Modernization, DWH, Datalake project execution\n""¢ Drive the adoption of advanced analytics tools and technologies to improve data delivery efficiency and solution impact.\n""¢ Assess and recommend new tools, platforms, and partners to continuously improve data solutions.\nTeam Development and Leadership:\n""¢ Recruit, mentor, and retain a high-performing data and analytics team, fostering a culture of collaboration and continuous improvement.\n""¢ Set performance goals, conduct regular evaluations, and provide ongoing feedback to support team growth.\n\nMinimum Skills Required:\n""¢ Educational BackgroundBachelor's or Master's degree in Data Science, Computer Science, Business Administration, or a related field.\n""¢ Experience15+ years of experience in data and analytics, including at least 5 years in a leadership role with a proven track record in delivery management.\n""¢ Technical ProficiencyDeep understanding of data warehousing, data visualization, data governance, data trust and big data tools (SQL, Python, R, Tableau, Power BI, and cloud platforms like AWS, Azure, or Google Cloud).\n""¢ Must have experience in Cloud Modernization, DWH, Datalake project execution\n""¢ BFSI KnowledgeMandatory to have worked in BFSI projects delivered Data & Analytics projects to BFSI clients\n""¢ Project Management ExpertiseStrong background in Agile, Scrum, or other project management methodologies.\n""¢ Leadership and CommunicationExcellent interpersonal and communication skills, with a demonstrated ability to lead, influence, and engage stakeholders at all levels.\n""¢ Analytical and Problem-Solving\n\nSkills:\nStrong analytical mindset with a track record of delivering actionable insights from complex data\nThe Data and Analytics Delivery Manager will oversee the successful delivery of the Client's data and analytics projects, ensuring our retail clients derive maximum value from their data assets. This leadership role involves setting strategy, managing delivery teams, collaborating across functions, and upholding data governance and quality standards. The ideal candidate brings strong technical and business acumen to build and execute data-driven strategies aligned with the Client's mission of transforming retail with data-driven insights.""",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data governance', 'scrum', 'agile', 'data visualization', 'big data', 'advanced analytics', 'python', 'data analytics', 'data warehousing', 'power bi', 'microsoft azure', 'project management process', 'machine learning', 'sql', 'tableau', 'r', 'bfsi', 'data science', 'gcp', 'project execution', 'aws']",2025-06-11 06:05:27
Data Analyst,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Pune'],"Req ID: 324676\n\nWe are currently seeking a Data Analyst to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nKey Responsibilities:\n\nExtract, transform, and load (ETL) data from various sources, ensuring data quality, integrity, and accuracy.\n\nPerform data cleansing, validation, and preprocessing to prepare structured and unstructured data for analysis.\n\nDevelop and execute queries, scripts, and data manipulation tasks using SQL, Python, or other relevant tools.\n\nAnalyze large datasets to identify trends, patterns, and correlations, drawing meaningful conclusions that inform business decisions.\n\nCreate clear and concise data visualizations, dashboards, and reports to communicate findings effectively to stakeholders.\n\nCollaborate with clients and cross-functional teams to gather and understand data requirements, translating them into actionable insights.\n\nWork closely with other departments to support their data needs.\n\nCollaborate with Data Scientists and other analysts to support predictive modeling, machine learning, and statistical analysis.\n\nContinuously monitor data quality and proactively identify anomalies or discrepancies, recommending corrective actions.\n\nStay up-to-date with industry trends, emerging technologies, and best practices to enhance analytical techniques.\n\nAssist in the identification and implementation of process improvements to streamline data workflows and analysis.\n\nBasic Qualifications:\n\n3 + years of proficiency in data analysis tools such as [Tools - e.g., Excel, SQL, R, Python].\n\n3+ years of experience supporting Software Engineering, Data Engineering, or Data Analytics projects.\n\n2+ years of experience leading a team supporting data related projects to develop end-to-end technical solutions.\n\nUndergraduate or Graduate degree preferred\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nStrong proficiency in data analysis tools such as Python, SQL, Talend (any ETL).\n\nExperience with data visualization tools like PowerBI.\n\nExperience with cloud data platforms .\n\nFamiliarity with ETL (Extract, Transform, Load) processes and tools.\n\nKnowledge of machine learning techniques and tools.\n\nExperience in a specific industry (e.g., financial services, healthcare, manufacturing) can be a plus.\n\nUnderstanding of data governance and data privacy regulations.\n\nAbility to query and manipulate databases and data warehouses.\n\nExcellent analytical and problem-solving skills.\n\nStrong communication skills with the ability to explain complex data insights to non-technical stakeholders.\n\nDetail-oriented with a commitment to accuracy.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'data analytics', 'data engineering', 'analysis tools', 'software engineering', 'python', 'data manipulation', 'talend', 'power bi', 'data warehousing', 'machine learning', 'dashboards', 'sql', 'data cleansing', 'data quality', 'r', 'predictive modeling', 'data visualization', 'etl']",2025-06-11 06:05:29
LLMOps Engineer,HCLTech,8 - 10 years,Not Disclosed,['Noida'],"Position Summary\nLLMOps(Large language model operations) Engineer will play a pivotal role in building and maintaining the infrastructure and pipelines for our cutting-edge Generative AI applications, establishing efficient and scalable systems for LLM research, evaluation, training, and fine-tuning. Engineer will be responsible for managing and optimizing large language models (LLMs) across various platforms This position is uniquely tailored for those who excel in crafting pipelines, cloud infrastructure, environments, and workflows. Your expertise in automating and streamlining the ML lifecycle will be instrumental in ensuring the efficiency, scalability, and reliability of our Generative AI models and associated platform. LLMOps engineers expertise will ensure the smooth deployment, maintenance, and performance of these AI platforms and powerful large language models.\n\nYou will follow Site Reliability Engineering & MLOps principles and will be encouraged to contribute your own best practices and ideas to our ways of working.\nReporting to the Head of Cloud Native operations, you will be an experienced thought leader, and comfortable engaging senior managers and technologists. You will engage with clients, display technical leadership, and guide the creation of efficient and complex products/solutions.\nKey Responsibilities\nTechnical & Architectural Leadership\n\nContribute to the technical delivery of projects, ensuring a high quality of work that adheres to best practices, brings innovative approaches and meets client expectations. Project types include following (but not limited to):\nSolution architecture, Proof of concepts (PoCs), MVP, design, develop, and implementation of ML/LLM pipelines for generative AI models, data management & preparation for fine tuning, training, deployment, and monitoring.\nAutomate ML tasks across the model lifecycle.\nContribute to HCL thought leadership across the Cloud Native domain with an expert understanding of advanced AI solutions using Large Language Models (LLM) & Natural Language Processing (NLP) techniques and partner technologies.\nCollaborate with cross-functional teams to integrate LLM and NLP technologies into existing systems.\nEnsure the highest levels of governance and compliance are maintained in all ML and LLM operations.\nStay abreast of the latest developments in ML and LLM technologies and methodologies, integrating these innovations to enhance operational efficiency and model effectiveness.\nCollaborate with global peers from partner ecosystems on joint technical projects. This partner ecosystem includes Google, Microsoft, Nvidia, AWS, IBM, Red Hat, Intel, Cisco, and Dell VMware etc.\nService Delivery\n\nProvide a technical hands-on contribution. Create scalable infra to support enterprise loads (distributed GPU compute, foundation models, orchestrating across multiple cloud vendors, etc.)\nEnsuring the reliable and efficient platform operations.\nApply data science, machine learning, deep learning, and natural language processing methods to analyse, process, and improve the models data and performance.\nUnderstanding of Explainability & Biased Detection concepts.\nCreate and optimize prompts and queries for retrieval augmented generation and prompt engineering techniques to enhance the models capabilities and user experience w.r.t Operations & associated platforms.\nClient-facing influence and guidance, engaging in consultative client discussions and performing a Trusted Advisor role.\nProvide effective support to HCL Sales and Delivery teams.\nSupport sales pursuits and enable HCL revenue growth.\nDefine the modernization strategy for client platform and associated IT practices, create solution architecture and provide oversight of the client journey.\nInnovation & Initiative\n\nAlways maintain hands-on technical credibility, keep in front of the industry, and be prepared to show and lead the way forward to others.\nEngage in technical innovation and support HCLs position as an industry leader.\nActively contribute to HCL sponsorship of leading industry bodies such as the CNCF and Linux Foundation.\nContribute to thought leadership by writing Whitepapers, blogs, and speaking at industry events.\nBe a trusted, knowledgeable internal innovator driving success across our global workforce.\nClient Relationships\n\nAdvise on best practices related to platform & Operations engineering and cloud native operations, run client briefings and workshops, and engage technical leaders in a strategic dialogue.\nDevelop and maintain strong relationships with client stakeholders.\nPerform a Trusted Advisor role.\nContribute to technical projects with a strong focus on technical excellence and on-time delivery.\nMandatory Skills & Experience\nExpertise in designing and optimizing machine-learning operations, with a preference for LLMOps.\nProficient in Data Science, Machine Learning, Python, SQL, Linux/Unix shell scripting.\nExperience on Large Language Models and Natural Language Processing (NLP), and experience with researching, training, and fine-tuning LLMs. Contribute towards fine-tune Transformer models for optimal performance in NLP tasks, if required.\nImplement and maintain automated testing and deployment processes for machine learning models w.r.t LLMOps.\nImplement version control, CI/CD pipelines, and containerization techniques to streamline ML and LLM workflows.\nDevelop and maintain robust monitoring and alerting systems for generative AI models ensuring proactive identification and resolution of issues.\nResearch or engineering experience in deep learning with one or more of the following: generative models, segmentation, object detection, classification, model optimisations.\nExperience implementing RAG frameworks as part of available-ready products.\nExperience in setting up the infrastructure for the latest technology such as Kubernetes, Serverless, Containers, Microservices etc.\nExperience in scripting programming to automate deployments and testing, worked on tools like Terraform and Ansible. Scripting languages like Python, bash, YAML etc.\nExperience on CI/CD opensource and enterprise tool sets such as Argo CD, Jenkins.\nExperience with the GitHub/DevOps Lifecycle\nExperience in at least one of the Observability solutions (Prometheus, EFK stacks, ELK stacks, Grafana, Dynatrace, AppDynamics)\nExperience in at-least one of the clouds for example - Azure/AWS/GCP\nSignificant experience on microservices-based, container-based or similar modern approaches of applications and workloads.\nYou have exemplary verbal and written communication skills (English). Able to interact and influence at the highest level, you will be a confident presenter and speaker, able to command the respect of your audience.\nDesired Skills & Experience\nBachelor level technical degree or equivalent experience; Computer Science, Data Science, or Engineering background preferred; masters degree desired.\nExperience in LLMOps or related areas, such as DevOps, data engineering, or ML infrastructure.\nHands-on experience in deploying and managing machine learning and large language model pipelines in cloud platforms (e.g., AWS, Azure) for ML workloads.\nFamiliar with data science, machine learning, deep learning, and natural language processing concepts, tools, and libraries such as Python, TensorFlow, PyTorch, NLTK etc.\nExperience in using retrieval augmented generation and prompt engineering techniques to improve the models quality and diversity to improve operations efficiency. Proven experience in developing and fine-tuning Language Models (LLMs).\nStay up-to-date with the latest advancements in Generative AI, conduct research, and explore innovative techniques to improve model quality and efficiency.\nThe perfect candidate will already be working within a System Integrator, Consulting or Enterprise organisation with 8+ years of experience in a technical role within the Cloud domain.\nDeep understanding of core practices including SRE, Agile, Scrum, XP and Domain Driven Design. Familiarity with the CNCF open-source community.\nEnjoy working in a fast-paced environment using the latest technologies, love Labs dynamic and high-energy atmosphere, and want to build your career with an industry leader.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['LLMOps', 'Architectural Leadership', 'Machine Learning', 'Unix shell scripting', 'SQL', 'Data Science', 'NLP', 'Linux', 'Terraform', 'Ansible', 'CI/CD', 'technical delivery', 'AWS', 'Python']",2025-06-11 06:05:30
Gen AI Lead Engineer,"NTT DATA, Inc.",2 - 7 years,Not Disclosed,['Bengaluru'],"Req ID: 323701\n\nWe are currently seeking a Gen AI Lead Engineer to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nJob DutiesExercise expertise in ideating and developing AI/ML applications on prediction, recommendation, text analytics, computer vision, bots, and content intelligence.\n\nApply statistical skills and advanced statistical techniques and concepts.\n\nDemonstrate deep knowledge of ML frameworks such as TensorFlow, PyTorch, Keras, Spacy, and scikit-learn.\n\nLeverage advanced knowledge of Python open-source software stack such as Django or Flask, Django Rest or FastAPI, etc.\n\nDeep knowledge in statistics and Machine Learning models, deep learning models, NLP, Generative Adversarial Networks (GAN), and other generative models.\n\nExperience working with RAG technologies and LLM frameworks, LLM model registries (Hugging Face), LLM APIs, embedding models, and vector databases\n\nEmploy technical knowledge and hands-on experience with Azure OpenAI, Google Vertex Gen AI, and AWS LLM foundational models, BERT, Transformers, PaLM, Bard, etc.\n\nDisplay proficiency in programming languages such as Python and understanding of various Python packages. Experience with TensorFlow, PyTorch, or Keras.\n\nDevelop and implement GenAI solutions, collaborating with cross-functional teams, and supporting the successful execution of AI projects for a diverse range of clients.\n\nAssist in the design and implementation of GenAI use cases, projects, and POCs across multiple industries.\n\nWork on RAG models and Agents Frameworks to enhance GenAI solutions by incorporating relevant information retrieval mechanisms and frameworks\n\nCreate and maintain data infrastructure to ingest, normalize, and combine datasets for actionable insights.\n\nWork closely with customers to understand their requirements and deliver customized AI solutions.\n\nInteract at appropriate levels to ensure client satisfaction and project success.\n\nCommunicate complex technical concepts clearly to non-technical audiences.\n\nConduct training sessions to enhance overall data science skills within the organization\n\nBuild solutions for Private AI and Smart Agentic Solutions\n\nMinimum Skills Required 2+ years of experience architecting high-impact GenAI solutions for diverse clients, preferably in Private AI and Smart Agentic Solutions\n\n8+ year(s) of experience participating in projects that focused on one or more of the following areas:\n\no Predictive Analytics\n\no Data Design\n\no Generative AI\n\no AI/ML\n\no ML Ops\n\n3+ years of experience using Python.\n\nAbility to travel at least 25%.\n\nBachelor""™s Degree required.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'deep learning', 'ml', 'architecting', 'rest', 'vertex', 'scikit-learn', 'predictive analytics', 'aiml', 'google', 'artificial intelligence', 'gen', 'tensorflow', 'spacy', 'ops', 'django', 'pytorch', 'keras', 'flask', 'aws', 'statistics']",2025-06-11 06:05:32
"Tcs is hiring For Azure Data Engineer (ADF, Python, Pyspark,DataBricks",Tata Consultancy Services,5 - 10 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Role & responsibilities\nStrong understanding of Azure environment (PaaS, IaaS) and experience in working with Hybrid model\nAt least 1 project experience in Azure Data Stack that involves components like Azure Data Lake, Azure Synapse Analytics, Azure Data Factory, Azure Data Bricks, Azure Analysis Service, Azure SQL DWH\nStrong hands-on SQL/T-SQL/Spark SQL and database concepts",,,,"['Azure Databricks', 'Azure Data Factory', 'Pyspark', 'Python Data', 'Microsoft Azure', 'Devops', 'Python', 'SQL']",2025-06-11 06:05:34
Senior Associate Data Scientist,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Data Scientist is a seasoned subject matter expert, tasked with participating in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nAccountable for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources.\nAccountable for providing meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nAccountable for performing analysis using programming languages or statistical packages such as Python, pandas etc.\nDesigns scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualize the output of the models.\nCreates documentation around processes and procedures and manages code reviews.\nAccountable for ensuring that industry standards best practices are applied to development activities.\nKnowledge and Attributes:\nSeasoned in data modelling, statistical methods and machine learning techniques.\nAbility to thrive in a dynamic, fast-paced environment.\nQuantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nGood understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nAbility to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nAbility to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\nAble to apply data science principles through a business lens.\nDesire to create strategies and solutions that challenge and expand the thinking of peers and business stakeholders.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming (Python) certification preferred.\nAgile certification preferred.\nRequired Experience:\nSeasoned experience in a data science position in a corporate environment and/or related industry.\nSeasoned experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nSeasoned experience in programming languages (Python, etc.).\nSeasoned experience working in databases (MySQL, Microsoft SQL Server, Azure Synapse, MongoDB)\nSeasoned experience working with and creating data architectures.\nSeasoned experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nSeasoned experience visualizing and/or presenting data for stakeholder use and reuse across the business.\nSeasoned experience on working with API (creating and using APIs)\nAutomation experience using Python scripting, UIPath, Selenium, PowerAutomate.\nSeasoned experience working on Linux operating system (Ubuntu)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure Synapse', 'Microsoft SQL Server', 'MySQL', 'Python scripting', 'PowerAutomate', 'Linux operating system', 'MongoDB', 'Selenium', 'Python', 'UIPath']",2025-06-11 06:05:35
Data Engineer _Technology Lead,Broadridge,6 - 10 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nAnalyzes and solve problems using technical experience, judgment and precedents\nProvides informal guidance to new team members\nExplains complex information to others in straightforward situations\n1. Data Engineering and Modelling:\nDesign & Develop Scalable Data Pipelines: Leverage AWS technologies to design, develop, and manage end-to-end data pipelines with services like .",,,,"['Star Schema', 'Snowflake', 'AWS', 'Apache Airflow']",2025-06-11 06:05:37
Senior Data Scientist,"NTT DATA, Inc.",2 - 6 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Data Scientist is an advanced subject matter expert, tasked with taking accountability in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nKey responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nResponsible for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources\nProvides meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nDirects scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualizes the output of the models.\nResponsible for ensuring that industry standards best practices are applied to development activities.\n\nTo thrive in this role, you need to have:\nAdvanced understanding of data modelling, statistical methods and machine learning techniques.\nStrong ability to thrive in a dynamic, fast-paced environment.\nStrong quantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nAdvanced understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nStrong ability to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nStrong ability to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\n\nAcademic qualifications and certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming certification preferred.\nAgile certification preferred.\n\nRequired experience:\nAdvanced demonstrated experience in a data science position in a corporate environment and/or related industry.\nAdvanced demonstrated experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nAdvanced demonstrated experience in programming languages (R, Python, etc.).\nAdvanced demonstrated experience working with and creating data architectures.\nAdvanced demonstrated experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nAdvanced demonstrated experience visualizing and/or presenting data for stakeholder use and reuse across the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'data analytics', 'natural language processing', 'data modeling', 'data mining', 'statistical modeling', 'data architecture', 'machine learning']",2025-06-11 06:05:38
Lead Data Architect,"NTT DATA, Inc.",7 - 12 years,Not Disclosed,['Bengaluru'],"We are currently seeking a Lead Data Architect to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n Position Overview  We are seeking a highly skilled and experienced Data Architect to join our dynamic team. The ideal candidate will have a strong background in designing and implementing data solutions using AWS infrastructure and a variety of core and supplementary technologies. This role requires a deep understanding of data architecture, cloud services, and the ability to drive innovative solutions to meet business needs.\n\n\n\n Key Responsibilities  \n\n- Architect end-to-end data solutions using AWS services, including Lambda, SNS, S3, and EKS, Kafka and Confluent, all within a larger and overarching programme ecosystem\n\n- Architect data processing applications using Python, Kafka, Confluent Cloud and AWS\n\n- Ensure data security and compliance throughout the architecture\n\n- Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions\n\n- Optimize data flows for performance, cost-efficiency, and scalability\n\n- Implement data governance and quality control measures\n\n- Ensure delivery of CI, CD and IaC for NTT tooling, and as templates for downstream teams\n\n- Provide technical leadership and mentorship to development teams and lead engineers\n\n- Stay current with emerging technologies and industry trends\n\n\n\n Required Skills and Qualifications  \n\n\n\n- Bachelor's degree in Computer Science, Engineering, or related field\n\n- 7+ years of experience in data architecture and engineering\n\n- Strong expertise in AWS cloud services, particularly Lambda, SNS, S3, and EKS\n\n- Strong experience with Confluent\n\n- Strong experience in Kafka\n\n- Solid understanding of data streaming architectures and best practices\n\n- Strong problem-solving skills and ability to think critically\n\n- Excellent communication skills to convey complex technical concepts to both technical and non-technical stakeholders\n\n- Knowledge of Apache Airflow for data orchestration\n\n\n\n Preferred Qualifications  \n\n\n\n- An understanding of cloud networking patterns and practises\n\n- Experience with working on a library or other long term product\n\n- Knowledge of the Flink ecosystem\n\n- Experience with Terraform\n\n- Deep experience with CI/CD pipelines\n\n- Strong understanding of the JVM language family\n\n- Understanding of GDPR and the correct handling of PII\n\n- Expertise with technical interface design\n\n- Use of Docker\n\n\n\n Responsibilities  \n\n- Design and implement scalable data architectures using AWS services, Confluent and Kafka\n\n- Develop data ingestion, processing, and storage solutions using Python and AWS Lambda, Confluent and Kafka\n\n- Ensure data security and implement best practices using tools like Synk\n\n- Optimize data pipelines for performance and cost-efficiency\n\n- Collaborate with data scientists and analysts to enable efficient data access and analysis\n\n- Implement data governance policies and procedures\n\n- Provide technical guidance and mentorship to junior team members\n\n- Evaluate and recommend new technologies to improve data architecture",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'cloud services', 'data architecture', 'kafka', 'ci cd pipeline', 'jvm', 'python', 'confluent', 'aws iam', 'airflow', 'ci/cd', 'eks', 'aws lambda', 'apache flink', 'docker', 'apache', 'lambda expressions', 'aws cloud', 'data governance', 'sns', 'terraform', 'aws', 'interface design']",2025-06-11 06:05:40
Senior GenAI Data Engineer,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,"['New Delhi', 'Chennai', 'Bengaluru']","Your day at NTT DATA\nSenior GenAI Data Engineer\nWe are seeking an experienced Senior Data Engineer to join our team in delivering cutting-edge Generative AI (GenAI) solutions to clients. The successful candidate will be responsible for designing, developing, and deploying data pipelines and architectures that support the training, fine-tuning, and deployment of LLMs for various industries. This role requires strong technical expertise in data engineering, problem-solving skills, and the ability to work effectively with clients and internal teams.\nWhat you'll be doing\nKey Responsibilities:\nDesign, develop, and manage data pipelines and architectures to support GenAI model training, fine-tuning, and deployment\nData Ingestion and Integration: Develop data ingestion frameworks to collect data from various sources, transform, and integrate it into a unified data platform for GenAI model training and deployment.\nGenAI Model Integration: Collaborate with data scientists to integrate GenAI models into production-ready applications, ensuring seamless model deployment, monitoring, and maintenance.\nCloud Infrastructure Management: Design, implement, and manage cloud-based data infrastructure (e.g., AWS, GCP, Azure) to support large-scale GenAI workloads, ensuring cost-effectiveness, security, and compliance.\nWrite scalable, readable, and maintainable code using object-oriented programming concepts in languages like Python, and utilize libraries like Hugging Face Transformers, PyTorch, or TensorFlow\nPerformance Optimization: Optimize data pipelines, GenAI model performance, and infrastructure for scalability, efficiency, and cost-effectiveness.\nData Security and Compliance: Ensure data security, privacy, and compliance with regulatory requirements (e.g., GDPR, HIPAA) across data pipelines and GenAI applications.\nClient Collaboration: Collaborate with clients to understand their GenAI needs, design solutions, and deliver high-quality data engineering services.\nInnovation and R&D: Stay up to date with the latest GenAI trends, technologies, and innovations, applying research and development skills to improve data engineering services.\nKnowledge Sharing: Share knowledge, best practices, and expertise with team members, contributing to the growth and development of the team.\nRequirements:\nBachelors degree in computer science, Engineering, or related fields (Master's recommended)\nExperience with vector databases (e.g., Pinecone, Weaviate, Faiss, Annoy) for efficient similarity search and storage of dense vectors in GenAI applications\n5+ years of experience in data engineering, with a strong emphasis on cloud environments (AWS, GCP, Azure, or Cloud Native platforms)\nProficiency in programming languages like SQL, Python, and PySpark\nStrong data architecture, data modeling, and data governance skills\nExperience with Big Data Platforms (Hadoop, Databricks, Hive, Kafka, Apache Iceberg), Data Warehouses (Teradata, Snowflake, BigQuery), and lakehouses (Delta Lake, Apache Hudi)\nKnowledge of DevOps practices, including Git workflows and CI/CD pipelines (Azure DevOps, Jenkins, GitHub Actions)\nExperience with GenAI frameworks and tools (e.g., TensorFlow, PyTorch, Keras)\nNice to have:\nExperience with containerization and orchestration tools like Docker and Kubernetes\nIntegrate vector databases and implement similarity search techniques, with a focus on GraphRAG is a plus\nFamiliarity with API gateway and service mesh architectures\nExperience with low latency/streaming, batch, and micro-batch processing\nFamiliarity with Linux-based operating systems and REST APIs\nLocation: Delhi or Bangalore\nWorkplace type:\nHybrid Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['GenAI', 'hive', 'continuous integration', 'kubernetes', 'ci/cd', 'pyspark', 'data architecture', 'sql', 'docker', 'tensorflow', 'git', 'data modeling', 'gcp', 'devops', 'linux', 'jenkins', 'pytorch', 'keras', 'hadoop', 'bigquery', 'python', 'microsoft azure', 'data engineering', 'data bricks', 'data governance', 'aws']",2025-06-11 06:05:41
Software Development Engineer - Trainee,Meesho,0 - 1 years,20-25 Lacs P.A.,['Bengaluru'],"Join us for an exciting SDE Traineeship at Meesho.\nBased on the performance at Meesho, successful candidates will be considered for a full-time opportunity (FTE). The FTE salary offered will be INR 20,00,000 p.a. fixed + Benefits.\nPosition: Software Development Engineer - Trainee\nLocation : Bengaluru\nAPPLY HERE: https://p.hck.re/6TcJ\n\nAbout the role:\nAs an SDE Trainee , we expect you to be motivated in solving real-life complex problems and creating compelling experiences for our resellers. Being a small company we have a culture of creative problem- solving, intellectual design, fast-paced development, and passionate product delivery. The pace of our growth is incredible. If you want to tackle hard, interesting and UNIQUE problems, and create an impact within an entrepreneurial environment, JOIN US!\nKey Responsibilities:\nCollaborate with teams to develop new features for Meesho customers and suppliers\nLeverage state-of-the-art technologies and write highly performant code\nTake end-to-end ownership of features, from ideation to production\n\nTechnical Requirements:\n0-1 years of experience\nStrong problem-solving skills\nExcellent understanding of data structures and algorithms, and their space & time complexities\nStrong hands-on and practical working experience with at least one programming language: Java/Python/Javascript\nExcellent coding skills should be able to convert design into code fluently.",Industry Type: Internet (E-Commerce),Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Generative Ai', 'Gen AI', 'java', 'Artificial Intelligence', 'Data Structures', 'Javascript', 'Python']",2025-06-11 06:05:43
Data Scientist - Computational Scientist / Applied Mathematician,Gitcs India,5 - 7 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Role: Data Scientists - Computational Scientist / Applied Mathematician\nLocation: Bangalore\nMust Have:\nMSc/PhD in Physics, Stats, Math, Comp Bio, CS, etc.\nStrong Python + Jupyter skills\nExperience with real-world biological data\nEager to learn biology & make real patient impact\nBonus: Genomics, sequencing tech, cloud (AWS/GCP), Rust/C++, Snakemake, ML models\nWork with biologists, chemists & ML scientists to analyze experiments & build predictive tools.\n\nAbout Role\nYou have strong mathematical foundations and a passion for understanding & analyzing data. You have a solid understanding of how to analyze noisy, real-world, data. In addition to a strong background in statistics, you are also capable of programming a computer to perform data analysis tasks. You want to impact people by treating genetic diseases and are capable of learning biology that is crucial to the data analysis task.\nYou enjoy close-knit teamwork and a highly interdisciplinary intellectual environment where you will work side-by-side with both computational and bench scientists. You continually learn and challenge yourself with scientific pursuits. You take pride in rigorous pursuit of science.\n\nRequired Qualifications\nMSc or PhD in a quantitative discipline such as physics, statistics, economics, applied mathematics, computer science, computation genomics / biology or related field\nFamiliarity with analyzing real world data and quantifying uncertainty\nGood understanding of Python is a required, knowledge of Rust / C++ are nice to have\nVery comfortable with Juptyer ecosystem\nAbility to independently master unfamiliar topics, especially in biological sciences and data analysis\nDesire to make a difference to patients with rare disease\n\nHelpful Qualifications\nStrong foundation in algorithms of scientific computing: steepest descent, Metropolis-Hastings, Runge-Kutta, Krylov space methods, etc\nFluent and comfortable working across local and cloud environments and tools (AWS, GCP, kubernetes, docker)\nUnderstanding of sequencing technologies (Illumina, PacBio, Oxford Nanopore)\nKnowledge of standard software tools in transcriptomics, genomics, NGS assays & biological data analysis\nUnderstanding of Linux, make, snakemake, git, etc.\nExposure in distributed computing (Spark, Dask etc.)",Industry Type: Biotechnology,Department: Research & Development,"Employment Type: Full Time, Permanent","['Cloud Platforms', 'Research Analysis', 'Python', 'C++', 'Rust', 'Docker', 'Jupyter Ecosystem', 'GCP', 'Statistical Analysis Software', 'Bioinformatics', 'AWS', 'Machine Learning']",2025-06-11 06:05:45
"Lead Data Scientist, Operations || Mumbai || Max 38 LPA",Argus India Price Reporting Services,5 - 10 years,20-35 Lacs P.A.,"['Mumbai Suburban', 'Navi Mumbai', 'Mumbai (All Areas)']","Lead Data Scientist, Operations\nMumbai, India\n\nAbout Argus:\n\nArgus is the leading independent provider of market intelligence to the global energy and commodity markets. We offer essential price assessments, news, analytics, consulting services, data science tools and industry conferences to illuminate complex and opaque commodity markets.\nHeadquartered in London with 1,500 staff, Argus is an independent media organisation with 30 offices in the worlds principal commodity trading hubs.\nCompanies, trading firms and governments in 160 countries around the world trust Argus data to make decisions, analyse situations, manage risk, facilitate trading and for long-term planning. Argus prices are used as trusted benchmarks around the world for pricing transportation, commodities and energy.\nFounded in 1970, Argus remains a privately held UK-registered company owned by employee shareholders and global growth equity firm General Atlantic.\nWhat were looking for:\nJoin our Generative AI team to lead a new group in India, focused on creating and maintaining AI-ready data. As the point of contact in Mumbai, you will guide the local team and ensure seamless collaboration with our global counterparts. Your contributions will directly impact the development of innovative solutions used by industry leaders worldwide, supporting text and numerical data extraction, curation, and metadata enhancements to accelerate development and ensure rapid response times. You will play a pivotal role in transforming how our data are seamlessly integrated with AI systems, paving the way for the next generation of customer interactions.\n\nWhat will you be doing:\n\nLead and Develop the Team: Oversee a team of data scientists in Mumbai. Mentoring and guiding junior team members, fostering their professional growth and development.\nStrategic Planning: Develop and implement strategic plans for data science projects, ensuring alignment with the company's goals and objectives.\nAI-Ready Data Development: Design, develop, and maintain high-quality AI-ready datasets, ensuring data integrity, usability, and scalability to support advanced Generative AI models.\nAdvanced Data Processing: Drive hands-on efforts in complex data extraction, cleansing, and curation for diverse text and numerical datasets. Implement sophisticated metadata enrichment strategies to enhance data utility and accessibility for AI systems.\nAlgorithm Implementation & Optimization: Implement and optimize state-of-the-art algorithms and pipelines for efficient data processing, feature engineering, and data transformation tailored for LLM and GenAI applications.\nGenAI Application Development: Apply and integrate frameworks like LangChain and Hugging Face Transformers to build modular, scalable, and robust Generative AI data pipelines and applications.\nPrompt Engineering Application: Apply advanced prompt engineering techniques to optimize LLM performance for specific data extraction, summarization, and generation tasks, working closely with the Lead's guidance.\nLLM Evaluation Support: Contribute to the systematic evaluation of Large Language Models (LLMs) outputs, analysing quality, relevance, and accuracy, and supporting the implementation of LLM-as-a-judge frameworks.\nRetrieval-Augmented Generation (RAG) Contribution: Actively contribute to the implementation and optimization of RAG systems, including working with embedding models, vector databases, and, where applicable, knowledge graphs, to enhance data retrieval for GenAI.\nTechnical Leadership: Act as a technical leader and subject matter expert for junior data scientists, providing guidance on best practices in coding and PR reviews, data handling, and GenAI methodologies.\nCross-Functional Collaboration: Collaborate effectively with global data science teams, engineering, and product stakeholders to integrate data solutions and ensure alignment with broader company objectives.\nOperational Excellence: Troubleshoot and resolve data-related issues promptly to minimize potential disruptions, ensuring high operational efficiency and responsiveness.\nDocumentation & Code Quality: Produce clean, well-documented, production-grade code, adhering to best practices for version control and software engineering.\n\nSkills and Experience:\n\nLeadership Experience: Proven track record in leading and mentoring data science teams, with a focus on strategic planning and operational excellence.\nAcademic Background: Advanced degree in AI, statistics, mathematics, computer science, or a related field.\nProgramming and Frameworks: 5+ years of hands-on experience with Python, TensorFlow or PyTorch, and NLP libraries such as spaCy and Hugging Face.\nGenAI Tools: 2+ years of Practical experience with LangChain, Hugging Face Transformers, and embedding models for building GenAI applications.\nPrompt Engineering: Deep expertise in prompt engineering, including prompt tuning, chaining, and optimization techniques.\nLLM Evaluation: Experience evaluating LLM outputs, including using LLM-as-a-judge methodologies to assess quality and alignment.\nRAG and Knowledge Graphs: Practical understanding and experience using vector databases. In addition, familiarity with graph-based RAG architectures and the use of knowledge graphs to enhance retrieval and reasoning would be a strong plus.\nCloud: 2+ years of experience with Gemini/OpenAI models and cloud platforms such as AWS, Google Cloud, or Azure. Proficient with Docker for containerization.\nData Engineering: Strong understanding of data extraction, curation, metadata enrichment, and AI-ready dataset creation.\nCollaboration and Communication: Excellent communication skills and a collaborative mindset, with experience working across global teams.\n\nWhats in it for you:\n\nCompetitive salary\nHybrid Working Policy (3 days in Mumbai office/ 2 days WFH once fully inducted)\nGroup healthcare scheme\n18 days annual leave\n8 days of casual leave\nExtensive internal and external training\n\nHours:\n\nThis is a full-time position operating under a hybrid model, with three days in the office and up to two days working remotely.\nThe team supports Argus key business processes every day, as such you will be required to work on a shift-based rota with other members of the team supporting the business until 8pm. Typically support hours run from 11am to 8pm with each member of the team participating up to 2/3 times a week.\n\nFor more details about the company and to apply please make sure you send your CV and cover letter via our website: www.argusmedia.com/en/careers/open-positions\nBy submitting your job application, you automatically acknowledge and consent to the collection, use and/or disclosure of your personal data to the Company. Argus is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Huggingface', 'Langchain', 'Spacy', 'Python', 'TensorFlow', 'Pytorch']",2025-06-11 06:05:46
GenAI Data Scientist,EXL,2 - 5 years,Not Disclosed,"['Noida', 'Gurugram', 'Bengaluru']","Job Summary\nWe are seeking a highly skilled Generative AI Data Scientist to design, develop, and deploy generative AI applications and models that can generate meaningful insights, creative business domain content, or solve domain-specific challenges. The ideal candidate will combine expertise in data science, machine learning, AI and natural language processing (NLP) with a passion for innovation and real-world applications.\nAs part of the EXL Digital AI R&D Innovation team, you will work as a Data Scientist in the Innovation unit supporting all EXL Business Units. You will be exposed to hundreds of different enterprise GenAI business use cases and help our clients create value architecting GenAI applications and solutions.",,,,"['GenAI', 'NLP', 'LLM', 'Natural Language Processing']",2025-06-11 06:05:48
Data Science Lead,Wipro,8 - 10 years,Not Disclosed,['Chennai'],"Role Purpose\n\nThe purpose of the role is to create exceptional architectural solution design and thought leadership and enable delivery teams to provide exceptional client engagement and satisfaction.\n\n\n\n\n\nDo\n\n\n1.Develop architectural solutions for the new deals/ major change requests in existing deals\nCreates an enterprise-wide architecture that ensures systems are scalable, reliable, and manageable.\nProvide solutioning of RFPs received from clients and ensure overall design assurance\nDevelop a direction to manage the portfolio of to-be-solutions including systems, shared infrastructure services, applications in order to better match business outcome objectives\nAnalyse technology environment, enterprise specifics, client requirements to set a collaboration solution design framework/ architecture\nProvide technical leadership to the design, development and implementation of custom solutions through thoughtful use of modern technology\nDefine and understand current state solutions and identify improvements, options & tradeoffs to define target state solutions\nClearly articulate, document and sell architectural targets, recommendations and reusable patterns and accordingly propose investment roadmaps\nEvaluate and recommend solutions to integrate with overall technology ecosystem\nWorks closely with various IT groups to transition tasks, ensure performance and manage issues through to resolution\nPerform detailed documentation (App view, multiple sections & views) of the architectural design and solution mentioning all the artefacts in detail\nValidate the solution/ prototype from technology, cost structure and customer differentiation point of view\nIdentify problem areas and perform root cause analysis of architectural design and solutions and provide relevant solutions to the problem\nCollaborating with sales, program/project, consulting teams to reconcile solutions to architecture\nTracks industry and application trends and relates these to planning current and future IT needs\nProvides technical and strategic input during the project planning phase in the form of technical architectural designs and recommendation\nCollaborates with all relevant parties in order to review the objectives and constraints of solutions and determine conformance with the Enterprise Architecture\nIdentifies implementation risks and potential impacts\n2.Enable Delivery Teams by providing optimal delivery solutions/ frameworks\nBuild and maintain relationships with executives, technical leaders, product owners, peer architects and other stakeholders to become a trusted advisor\nDevelops and establishes relevant technical, business process and overall support metrics (KPI/SLA) to drive results\nManages multiple projects and accurately reports the status of all major assignments while adhering to all project management standards\nIdentify technical, process, structural risks and prepare a risk mitigation plan for all the projects\nEnsure quality assurance of all the architecture or design decisions and provides technical mitigation support to the delivery teams\nRecommend tools for reuse, automation for improved productivity and reduced cycle times\nLeads the development and maintenance of enterprise framework and related artefacts\nDevelops trust and builds effective working relationships through respectful, collaborative engagement across individual product teams\nEnsures architecture principles and standards are consistently applied to all the projects\nEnsure optimal Client Engagement\nSupport pre-sales team while presenting the entire solution design and its principles to the client\nNegotiate, manage and coordinate with the client teams to ensure all requirements are met and create an impact of solution proposed\nDemonstrate thought leadership with strong technical capability in front of the client to win the confidence and act as a trusted advisor\n\n\n\n\n3.Competency Building and Branding\nEnsure completion of necessary trainings and certifications\nDevelop Proof of Concepts (POCs),case studies, demos etc. for new growth areas based on market and customer research\nDevelop and present a point of view of Wipro on solution design and architect by writing white papers, blogs etc.\nAttain market referencability and recognition through highest analyst rankings, client testimonials and partner credits\nBe the voice of Wipros Thought Leadership by speaking in forums (internal and external)\nMentor developers, designers and Junior architects in the project for their further career development and enhancement\nContribute to the architecture practice by conducting selection interviews etc\n\n\n\n\n4.Team Management\nResourcing\nAnticipating new talent requirements as per the market/ industry trends or client requirements\nHire adequate and right resources for the team\nTalent Management\nEnsure adequate onboarding and training for the team members to enhance capability & effectiveness\nBuild an internal talent pool and ensure their career progression within the organization\nManage team attrition\nDrive diversity in leadership positions\nPerformance Management\nSet goals for the team, conduct timely performance reviews and provide constructive feedback to own direct reports\nEnsure that the Performance Nxt is followed for the entire team\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nMandatory\n\nSkills:\nAI Cognitive.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'rpa', 'AI Cognitive', 'statistical modeling', 'robotic process automation', 'artificial intelligence', 'sql']",2025-06-11 06:05:49
Sr. Data Scientist-Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Senior Data Scientist\n\nLocation: Onsite Bangalore\nExperience: 8+ years\n\nRole Overview\n\nWe are seeking a Senior Data Scientist with a strong foundation in machine learning, deep learning, and statistical modeling, with the ability to translate complex operational problems into scalable AI/ML solutions. In addition to core data science responsibilities, the role involves building production-ready backends in Python and contributing to end-to-end model lifecycle management. Exposure to computer vision is a plus, especially for industrial use cases like identification, intrusion detection, and anomaly detection.\n\nKey Responsibilities\n\nDevelop, validate, and deploy machine learning and deep learning models for forecasting, classification, anomaly detection, and operational optimization\nBuild backend APIs using Python (FastAPI, Flask) to serve ML/DL models in production environments\nApply advanced computer vision models (e.g., YOLO, Faster R-CNN) to object detection, intrusion detection, and visual monitoring tasks\nTranslate business problems into analytical frameworks and data science solutions\nWork with data engineering and DevOps teams to operationalize and monitor models at scale\nCollaborate with product, domain experts, and engineering teams to iterate on solution design\nContribute to technical documentation, model explainability, and reproducibility practices\n\n\nRequired Skills\n\nStrong proficiency in Python for data science and backend development\nExperience with ML/DL libraries such as scikit-learn, TensorFlow, or PyTorch\nSolid knowledge of time-series modeling, forecasting techniques, and anomaly detection\nExperience building and deploying APIs for model serving (FastAPI, Flask)\nFamiliarity with real-time data pipelines using Kafka, Spark, or similar tools\nStrong understanding of model validation, feature engineering, and performance tuning\nAbility to work with SQL and NoSQL databases, and large-scale datasets\nGood communication skills and stakeholder engagement experience\n\n\nGood to Have\n\nExperience with ML model deployment tools (MLflow, Docker, Airflow)\nUnderstanding of MLOps and continuous model delivery practices\nBackground in aviation, logistics, manufacturing, or other industrial domains\nFamiliarity with edge deployment and optimization of vision models\n\n\nQualifications\n\nMasters or PhD in Data Science, Computer Science, Applied Mathematics, or related field\n7+ years of experience in machine learning and data science, including end-to-end deployment of models in production",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['scikit-learn', 'time-series modeling', 'ML/DL libraries', 'data science', 'Python', 'Airflow', 'Kafka', 'MLflow', 'logistics', 'anomaly detection', 'aviation', 'SQL', 'PyTorch', 'NoSQL', 'MLOps', 'forecasting techniques', 'Docker', 'manufacturing', 'FastAPI', 'Spark', 'TensorFlow', 'Flask']",2025-06-11 06:05:51
Associate Lead / Lead Data Scientist,Ignitho,6 - 10 years,Not Disclosed,['Chennai( Sholinganallur )'],"Job Title: Lead Data Scientist\nLocation: Chennai\nReports To: CEO\nJob Summary:\nWe are seeking a highly skilled and experienced Data Scientist with 6+ years of hands-on experience in data science, analytics, and stakeholder engagement. The ideal candidate should have strong expertise in Python, Tableau, Snowflake, Machine Learning, Statistical testing and should be comfortable driving business insights through storytelling and daily interactions with stakeholders.\nKey Responsibilities:\nDesign, build, and deploy scalable machine learning models to solve complex business problems\nWrite and optimize complex SQL queries, particularly on the Snowflake platform\nDevelop insightful dashboards and visualizations using Tableau\nConduct data exploration, cleaning, and transformation using Python & R and relevant libraries (Pandas, NumPy, Scikit-learn, etc.)\nPerform A/B testing & other statistical techniques\nTranslate analytical insights into clear, compelling stories and recommendations for stakeholders\nCollaborate cross-functionally with product, engineering, and business teams to understand data needs and deliver solutions\nPresent findings and recommendations to both technical and non-technical stakeholders regularly\nRequirements:\n6+ years of professional experience in data science or advanced analytics\nStrong proficiency in Python for data manipulation, analysis, and modelling\nProven experience in building dashboards and reports using Tableau\nExpertise in writing complex SQL queries, especially on Snowflake\nSolid understanding of machine learning techniques, statistical tests and model deployment best practices\nExcellent communication and storytelling skills to convey data-driven insights\nComfortable working closely with stakeholders daily to gather requirements and present findings",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Tableau', 'Machine Learning', 'Python', 'SQL', 'Pandas', 'Scikit-Learn', 'Numpy', 'Ml']",2025-06-11 06:05:52
Senior Data Scientist,Fastenal,4 - 9 years,Not Disclosed,['Bengaluru'],"Job Description:\nWe are seeking a highly skilled and experienced Senior Data Scientist to join our team. The ideal candidate will have a strong background in data science, machine learning, and statistical analysis. As a Senior Data Scientist, you will be responsible for leading data-driven projects, developing predictive models, and providing actionable insights to drive business decisions.\n\nKey Responsibilities:",,,,"['Data Science', 'SQL', 'Pyspark', 'R', 'Python']",2025-06-11 06:05:54
Job opening For Manager Data Science @ GlobalData-Bengaluru,Globaldata,8 - 12 years,Not Disclosed,['Bengaluru( Koramangala )'],"Hello,\n\nGreetings from GlobalData!!!\n\nJob opening for Data Science Manager role @ GD-Bengaluru\nJob Criteria :-\nQualification: B.Tech/BE/MCA/M.Tech/M.Sc-(Computers)",,,,"['Natural Language Processing', 'Machine Learning', 'Generative Ai Tools', 'Large Language Model', 'Python', 'Tensorflow', 'Artificial Intelligence', 'Statistics', 'Deep Learning', 'Data Science', 'Agentic AI', 'Pytorch', 'Pandas']",2025-06-11 06:05:55
Data Engineer,Talent Aspire,2 - 7 years,Not Disclosed,"['Chandigarh', 'Bengaluru', 'Remote']","As the Data Engineer, you will play a pivotal role in shaping our data infrastructure and\nexecuting against our strategy. You will ideate alongside engineering, data and our clients to\ndeploy data products with an innovative and meaningful impact to clients. You will design, build,\nand maintain scalable data pipelines and workflows on AWS. Additionally, your expertise in AI\nand machine learning will enhance our ability to deliver smarter, more predictive solutions.\nKey Responsibilities\nCollaborate with other engineers, customers to brainstorm and develop impactful data\nproducts tailored to our clients.\nLeverage AI and machine learning techniques to integrate intelligent features into our\nofferings.\nDevelop, and optimize end-to-end data pipelines on AWS\nFollow best practices in software architecture and development.\nImplement effective cost management and performance optimization strategies.\nDevelop and maintain systems using Python, SQL, PySpark, and Django for front-end\ndevelopment.\nWork directly with clients and end-users and address their data needs\nUtilize databases and tools including and not limited to, Postgres, Redshift, Airflow, and\nMongoDB to support our data ecosystem.\nLeverage AI frameworks and libraries to integrate advanced analytics into our solutions.\nQualifications\n\nExperience:\nMinimum of 3 years of experience in data engineering, software development, or\nrelated roles.\nProven track record in designing and deploying AWS cloud infrastructure\nsolutions\nAt least 2 years in data analysis and mining techniques to aid in descriptive and\ndiagnostic insights\nExtensive hands-on experience with Postgres, Redshift, Airflow, MongoDB, and\nreal-time data workflows.\n\nTechnical Skills:\nExpertise in Python, SQL, and PySpark\nStrong background in software architecture and scalable development practices.\nTableau, Metabase or similar viz tools experience\nWorking knowledge of AI frameworks and libraries is a plus.\nLeadership & Communication:\nDemonstrates ownership and accountability for delivery with a strong\ncommitment to quality.\nExcellent communication skills with a history of effective client and end-user\nengagement.\nStartup & Fintech Mindset:\nAdaptability and agility to thrive in a fast-paced, early-stage startup environment.\nPassion for fintech innovation and a strong desire to make a meaningful impact\non the future of finance.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'and PySpark', 'Django', 'AI frameworks', 'Python', 'SQL']",2025-06-11 06:05:57
Data Engineer 2,Uplers,3 - 8 years,Not Disclosed,['Bengaluru'],"About the Role:\nAs a Data Engineer, you will be part of the Data Engineering team with this role being inherently multi-functional, and the ideal candidate will work with Data Scientist, Analysts, Application teams across the company, as well as all other Data Engineering squads at Wayfair. We are looking for someone with a love for data, understanding requirements clearly and the ability to iterate quickly. Successful candidates will have strong engineering skills and communication and a belief that data-driven processes lead to phenomenal products.\n\nWhat you'll do:\nBuild and launch data pipelines, and data products focussed on SMART Org.\nHelping teams push the boundaries of insights, creating new product features using data, and powering machine learning models.\nBuild cross-functional relationships to understand data needs, build key metrics and standardize their usage across the organization.\nUtilize current and leading edge technologies in software engineering, big data, streaming, and cloud infrastructure\n\nWhat You'll Need:\nBachelor/Master degree in Computer Science or related technical subject area or equivalent combination of education and experience 3+ years relevant work experience in the Data Engineering field with web scale data sets.\nDemonstrated strength in data modeling, ETL development and data lake architecture.\nData Warehousing Experience with Big Data Technologies (Hadoop, Spark, Hive, Presto, Airflow etc.).\nCoding proficiency in at least one modern programming language (Python, Scala, etc)\nExperience building/operating highly available, distributed systems of data extraction, ingestion, and processing and query performance tuning skills of large data sets.\nIndustry experience as a Big Data Engineer and working along cross functional teams such as Software Engineering, Analytics, Data Science with a track record of manipulating, processing, and extracting value from large datasets.\nStrong business acumen. Experience leading large-scale data warehousing and analytics projects, including using GCP technologies Big Query, Dataproc, GCS, Cloud Composer, Dataflow or related big data technologies in other cloud platforms like AWS, Azure etc.\nBe a team player and introduce/follow the best practices on the data engineering space.\nAbility to effectively communicate (both written and verbally) technical information and the results of engineering design at all levels of the organization.\n\nGood to have :\nUnderstanding of NoSQL Database exposure and Pub-Sub architecture setup.\nFamiliarity with Bl tools like Looker, Tableau, AtScale, PowerBI, or any similar tools.\n\nPS: This role is with one of our clients who is a leading name in Retail Industry.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Java', 'Data Engineering', 'Cloud Platform', 'Hive', 'GCP', 'Bigquery', 'Hadoop', 'SCALA', 'Big Data Technologies', 'Etl Development', 'Spark', 'Python']",2025-06-11 06:05:59
Senior Data Engineer,Impetus Technologies,5 - 10 years,Not Disclosed,['United Arab Emirates'],"The Opportunity:We are seeking a highly motivated and technically strong Module Lead Software Engineer with significant expertise in Python, PySpark, and Palantir Foundry. In this role, you will be responsible for the end-to-end technical ownership, design, and delivery of a specific module or component within our enterprise data platform. You will combine hands-on development with technical leadership, ensuring the highest standards of code quality, performance, and reliability.\n\nKey Responsibilities:\n\nModule Technical Leadership & Ownership: Take full technical ownership of a specific module or component within the data platform on Palantir Foundry. This includes defining its technical roadmap, architecture, design patterns, and ensuring its integration into the broader data ecosystem.\nHands-on Development and Complex Problem Solving: Act as a lead individual contributor, developing sophisticated data pipelines, transformations, and applications using Python and PySpark within Palantir Foundry's various tools (e.g., Code Workbook, Pipeline Builder). Tackle the most challenging technical problems and implement core functionalities for the module.\nQuality Assurance and Best Practices Advocacy: Drive and enforce high standards for code quality, test coverage, documentation, and operational excellence within your module. Conduct rigorous code reviews, provide constructive feedback, and mentor engineers within your immediate scope to elevate their technical skills.\nCross-Functional Collaboration and Module Integration: Collaborate extensively with other module leads, architects, data scientists, and business stakeholders to ensure seamless integration of your module's deliverables. Proactively identify and manage technical dependencies and ensure the module aligns with overall project goals and architectural vision.\n• Performance Optimization and Troubleshooting: Continuously monitor and optimize the performance of your module's data pipelines and applications. Efficiently troubleshoot and resolve complex technical issues, data quality concerns, and system failures specific to your module.\n\nRequired Qualifications:\n\nExperience: 6-8 years of progressive experience in software development with a strong focus on data engineering.\nPython Proficiency: Expert-level proficiency in Python, including advanced programming concepts, data structures, and performance optimization techniques.\nPySpark Expertise: Strong experience with PySpark for large-scale distributed data processing, transformations, and analytics.\nPalantir Foundry: Proven, hands-on experience designing, developing, and deploying solutions within Palantir Foundry is essential.\nDeep familiarity with Foundry's data integration capabilities, Code Workbook, Pipeline Builder, Data Health checks, and Ontology modeling.\nExperience with Foundry's approach to data governance and versioning.\nSQL Skills: Excellent SQL skills for complex data querying, manipulation, and optimization.\nData Warehousing/Lakes: Solid understanding of data warehousing concepts, data lake architectures, and ETL/ELT principles.\nCloud Platforms: Experience with at least one major cloud platform (AWS, Azure, GCP), particularly with data-related services.\nVersion Control: Strong experience with Git and collaborative development workflows.\n\nPreferred Qualifications (Nice-to-Have):\n\nExperience mentoring or leading small technical teams/pods.\nFamiliarity with containerization technologies (Docker, Kubernetes).\nExperience with streaming data technologies (e.g., Kafka, Kinesis).\nUnderstanding of CI/CD pipelines for data solutions.\nKnowledge of data governance, data quality, and metadata management best practices.\nExperience in [specific industry, e.g., Financial Services, Manufacturing, Healthcare].",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Engineering', 'Palantir Foundry', 'Python', 'Spark', 'Data Warehousing', 'SQL']",2025-06-11 06:06:00
Digital Engineering Lead Engineer,"NTT DATA, Inc.",3 - 6 years,Not Disclosed,['Bengaluru'],"Req ID: 312505\n\nWe are currently seeking a Digital Engineering Lead Engineer to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nJob DutiesJob TitleData Science & AIML, GenAI Lead/Engineer\n\nKey Responsibilities:\n""¢ Develop and implement traditional machine learning algorithms.\n""¢ Deploy at least one model in a production environment.\n""¢ Write and maintain Python code for data science and machine learning projects.\n\nMinimum Skills RequiredPreferred Qualifications:\n""¢ Knowledge of Deep Learning (DL) techniques.\n""¢ Experience working with Generative AI (GenAI) and Large Language Models (LLM).\n""¢ Exposure to Langchain.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'artificial intelligence', 'deep learning', 'data science', 'digital marketing', 'project management', 'data analysis', 'natural language processing', 'neural networks', 'sql', 'marketing', 'r', 'java', 'predictive modeling', 'social media marketing', 'agile']",2025-06-11 06:06:04
Principal Engineer - .Net Full Stack,Wells Fargo,7 - 9 years,Not Disclosed,['Bengaluru'],"About this role:\nWells Fargo is seeking a Principal Engineer\n\nIn this role, you will:\nAct as an advisor to leadership to develop or influence applications, network, information security, database, operating systems, or web technologies for highly complex business and technical needs across multiple groups\nLead the strategy and resolution of highly complex and unique challenges requiring in-depth evaluation across multiple areas or the enterprise, delivering solutions that are long-term, large-scale and require vision, creativity, innovation, advanced analytical and inductive thinking\nTranslate advanced technology experience, an in-depth knowledge of the organizations tactical and strategic business objectives, the enterprise technological environment, the organization structure, and strategic technological opportunities and requirements into technical engineering solutions\nProvide vision, direction and expertise to leadership on implementing innovative and significant business solutions\nMaintain knowledge of industry best practices and new technologies and recommends innovations that enhance operations or provide a competitive advantage to the organization\nStrategically engage with all levels of professionals and managers across the enterprise and serve as an expert advisor to leadership\n\nRequired Qualifications:\n7+ years of Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education\n\nDesired Qualifications:\nExperience in building new apps, and major enhancements and transformation to large application suite.\nExperience in automating manual process using state of the art methodologies and techniques\nAble to own the roadmap for a large and critical SDLC domain application and interacts with CI/CD, DevOps and IDP teams\n\nJob Expectations:\nFull stack developer in .net and react is preferred\nAdditional skills in Java, Python, ETL and database technologies are expected.\nApplication modernization, micro services architecture are required skills.\nUser experience, business process simplification and automation are desired.\nExperience and knowledge in Gen AI / Agentic AI is a added plus.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['.Net', 'Java', 'Gen AI', 'DevOps', 'CI/CD', 'micro services architecture', 'Full Stack', 'ETL', 'SDLC', 'Python']",2025-06-11 06:06:06
Data & AI Technical Solution Architects,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 323775\n\nWe are currently seeking a Data & AI Technical Solution Architects to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'solution design', 'gcp', 'gcp cloud', 'ml']",2025-06-11 06:06:08
Data Architect Sr. Advisor,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 323777\n\nWe are currently seeking a Data Architect Sr. Advisor to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works""",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'python', 'client engagement', 'ai solutions', 'aiml', 'data architecture', 'machine learning', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'gcp cloud', 'ml']",2025-06-11 06:06:10
BFSI Data and Analytics Delivery Manager,"NTT DATA, Inc.",18 - 23 years,Not Disclosed,['Bengaluru'],"Req ID: 326457\n\nWe are currently seeking a BFSI Data and Analytics Delivery Manager to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesData & Analytics Delivery Manager with over 18+ years of experience in BFSI Domain\nThe Data and Analytics Delivery Manager will oversee the successful delivery of the Client's data and analytics projects, ensuring our clients derive maximum value from their data assets. This leadership role involves setting strategy, managing delivery teams, collaborating across functions, and upholding data governance and quality standards. The ideal candidate brings strong technical and business acumen to build and execute data-driven strategies aligned with the Client's mission of transforming their business with data-driven insights.\nThe core responsibilities for the job include the following:\nProject and Program Oversight:\n""¢ Oversee end-to-end delivery of complex data and analytics projects, ensuring timely, high-quality, and cost-effective outcomes.\n""¢ Establish project governance, risk management, and quality assurance standards for effective project delivery.\n""¢ Monitor project portfolios and allocate resources to optimize productivity across multiple client engagements.\n\nStakeholder Collaboration and Engagement:\n""¢ Serve as the primary liaison between data delivery teams, sales, product, and client-facing teams to ensure client needs are met.\n""¢ Present data strategies, project status, and insights effectively to both technical and non-technical stakeholders, fostering alignment.\n""¢ Drive collaboration with product management and engineering teams to align on data needs and operational goals.\n\nInnovation and Technology Adoption:\n""¢ Stay abreast of the latest trends in GenAI, Agentic AI in data engineering, data science, machine learning, and AI to enhance the Client's data capabilities.\n""¢ Must have experience in Cloud Modernization, DWH, Datalake project execution\n""¢ Drive the adoption of advanced analytics tools and technologies to improve data delivery efficiency and solution impact.\n""¢ Assess and recommend new tools, platforms, and partners to continuously improve data solutions.\nTeam Development and Leadership:\n""¢ Recruit, mentor, and retain a high-performing data and analytics team, fostering a culture of collaboration and continuous improvement.\n""¢ Set performance goals, conduct regular evaluations, and provide ongoing feedback to support team growth.\n\nMinimum Skills Required:\n""¢ Educational BackgroundBachelor's or Master's degree in Data Science, Computer Science, Business Administration, or a related field.\n""¢ Experience15+ years of experience in data and analytics, including at least 5 years in a leadership role with a proven track record in delivery management.\n""¢ Technical ProficiencyDeep understanding of data warehousing, data visualization, data governance, data trust and big data tools (SQL, Python, R, Tableau, Power BI, and cloud platforms like AWS, Azure, or Google Cloud).\n""¢ Must have experience in Cloud Modernization, DWH, Datalake project execution\n""¢ BFSI KnowledgeMandatory to have worked in BFSI projects delivered Data & Analytics projects to BFSI clients\n""¢ Project Management ExpertiseStrong background in Agile, Scrum, or other project management methodologies.\n""¢ Leadership and CommunicationExcellent interpersonal and communication skills, with a demonstrated ability to lead, influence, and engage stakeholders at all levels.\n""¢ Analytical and Problem-Solving\n\nSkills:\nStrong analytical mindset with a track record of delivering actionable insights from complex data\nThe Data and Analytics Delivery Manager will oversee the successful delivery of the Client's data and analytics projects, ensuring our retail clients derive maximum value from their data assets. This leadership role involves setting strategy, managing delivery teams, collaborating across functions, and upholding data governance and quality standards. The ideal candidate brings strong technical and business acumen to build and execute data-driven strategies aligned with the Client's mission of transforming retail with data-driven insig""",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data governance', 'scrum', 'agile', 'data visualization', 'big data', 'advanced analytics', 'python', 'data analytics', 'data warehousing', 'power bi', 'microsoft azure', 'project management process', 'machine learning', 'sql', 'tableau', 'r', 'bfsi', 'data science', 'gcp', 'project execution', 'aws']",2025-06-11 06:06:11
Data Architect,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,['Bengaluru'],"Additional Career Level Description\n\n\nKnowledge and application\nApplies advanced wide-ranging experience and in-depth professional knowledge to develop and resolve complex models and procedures in creative way .\nDirects the application of existing principles and guides development of new policies and ideas.\nDetermines own methods and procedures on new assignments .\n\n\n\nProblem solving\nUnderstands and works on complex issues where analysis of situation or data requires an in-depth evaluation of variable factors, solutions may need to be devised from limited informatio n.\nExercises judgment in selecting methods, evaluating, adapting of complex techniques and evaluation criteria for obtaining results.\n\n\n\nInteraction\nFrequently advises key people outside own area of expertise on complex matters, using persuasion in delivering messages.\n\n\n\nImpact\nDevelops and manages operational initiatives to deliver tactical results and achieve medium-term goals.\n\n\n\nAccountability\nMay be accountable through team for delivery of tactical business targets .\nWork is reviewed upon completion and is consistent with departmental objectives.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Architecture', 'data modeling', 'Data Architect', 'artificial intelligence', 'sql']",2025-06-11 06:06:13
"Google Cloud Platform Data Engineer -GCP,BigQuery,SQL, Cloud Function",Tredence,5 - 10 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","Role - GCP Data Engineer\nExperience:4+ years\nPreferred - Data Engineering Background\nLocation - Bangalore, Chennai, Pune, Gurgaon, Kolkata\nRequired Skills - GCP DE Experience, Big query, SQL, Cloud compressor/Python, Cloud functions, Dataproc+pyspark, Python injection, Dataflow+PUB/SUB\n\nHere is the job description for the same -\nJob Requirement:\nHave Implemented and Architected solutions on Google Cloud Platform using the components of GCP\nExperience with Apache Beam/Google Dataflow/Apache Spark in creating end to end data pipelines.\nExperience in some of the following: Python, Hadoop, Spark, SQL, Big Query, Big Table Cloud Storage, Datastore, Spanner, Cloud SQL, Machine Learning.\nExperience programming in Java, Python, etc.\nExpertise in at least two of these technologies: Relational Databases, Analytical Databases, NoSQL databases.\nCertified in Google Professional Data Engineer/ Solution Architect is a major Advantage",,,,"['Pubsub', 'GCP', 'Bigquery', 'Google Cloud Platforms', 'SQL', 'Data Flow', 'Dataproc']",2025-06-11 06:06:15
Principal Engineer (VoIP Platform),Sprinklr,11 - 15 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Sprinklr is a leading enterprise software company for all customer-facing functions. With advanced AI, Sprinklr's unified customer experience management (Unified-CXM) platform helps companies deliver human experiences to every customer, every time, across any modern channel. Headquartered in New York City with employees around the world, Sprinklr works with more than 1,000 of the worlds most valuable enterprises - global brands like Microsoft, P&G, Samsung and more than 50% of the Fortune 100.\nWhat Does Success Look Like?\nWe are looking for a Principal VOIP Engineer to lead the architecture and technical direction of our next-gen voice infrastructure. You’ll be responsible for building carrier- grade systems with high availability, low latency, and global scalability- powering mission-critical voice communication in our CCaaS platform. This is a hands-on leadership role where you will influence architecture, establish best practices, and work cross-functionally across Engineering, DevOps, Product, and QA teams.\nSeniority Level: Principal / Individual Contributor with technical leadership scope.\n\nWhat You’ll Do:\nDesign and implement VOIP (signaling and media) infrastructure using FreeSWITCH, Kamailio/OpenSIPs, and RTPEngine.\nArchitect session border controllers (SBC), NAT traversal, load balancing, and failover strategies.\nDefine standards for call routing and audio quality optimization (codecs, jitter, etc.)\nLead initiatives for scalability, observability, security, and resiliency of our voice infrastructure.\nTroubleshoot live trac and provide technical leadership during major incidents.\nCollaborate with Backend and API teams to design provisioning, billing, and call analytics APIs.\nEvaluate and onboard open-source tools or commercial carriers as needed.\nCoach and mentor junior/lead engineers in VoIP best practices.\n\nWhat Makes You Qualified?\n12+ years of hands-on experience in the Telephony / VoIP / CPaaS domain.\nStrong knowledge of VoIP Protocols (SIP/SDP, RTP/RTCP), Networking fundamentals (UDP/TCP/IP, DNS, MPLS), QoS (latency, jitter, packet loss mitigation).\nHands-on experience with Session Border Controller (SBC), Media Servers and WebRTC.\nExpert-level understanding of SIP, RTP, NAT traversal (ICE/STUN/TURN), and VoIP security (TLS, SRTP, fraud prevention).\nHands-on development experience with FreeSWITCH, Kamailio/OpenSIPs, and RTPEngine.\nExperience in designing carrier-grade telephony plaforms serving millions of calls.\nStrong systems programming and debugging skills in C/C++\nStrong troubleshooting skills, with experience using network monitoring and debugging tools.\nFamiliarity with distributed systems and cloud-based deployments (AWS, GCP, Azure)\nExcellent problem-solving, debugging, and performance tuning skills",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['C++', 'Freeswitch', 'C Programming Language', 'Kamailio', 'Sbc', 'Telephony', 'RTPEngine']",2025-06-11 06:06:17
Automation & Data Engineer,Vyometra Global Llp,2 - 3 years,3.6-3.96 Lacs P.A.,['Bengaluru'],"Work with ops teams to digitize manual processes.\nCapture data via PLCs/IoT, build backend (Python, Flask/Django), SQL DB & frontend dashboard.\nTrack OEE, downtime, rejections. Deploy, maintain & contribute to future product roadmap.",Industry Type: Advertising & Marketing,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Automation', 'Automation', 'Machine Learning', 'Javascript', 'Python', 'Ai Techniques', 'Artificial Intelligence', 'Software Testing', 'Flask Web Framework', 'Numpy', 'Scikit-Learn', 'English', 'Pandas', 'Data Analysis', 'SQL Database', 'Ai Builder', 'Flask']",2025-06-11 06:06:18
Data Bricks,PwC India,7 - 12 years,Not Disclosed,['Bengaluru'],"Job Summary:\n\nWe are seeking a talented Data Engineer with strong expertise in Databricks, specifically in Unity Catalog, PySpark, and SQL, to join our data team. Youll play a key role in building secure, scalable data pipelines and implementing robust data governance strategies using Unity Catalog.\n\nKey Responsibilities:",,,,"['DataBricks', 'Data Bricks', 'Pyspark', 'Delta Lake', 'Databricks Engineer', 'Unity Catalog', 'SQL']",2025-06-11 06:06:20
Artificial Intelligence Developer,Infosys,5 - 10 years,Not Disclosed,"['Hyderabad', 'Bengaluru', 'Thiruvananthapuram']","Role & responsibilities\nArchitect and implement AI/ML solutions tailored to client-specific business problems using Gen AI (e.g., LLMs like GPT, Gemini, Mistral) and traditional ML models (e.g., scikit-learn, XGBoost).\nCollaborate with client stakeholders to understand requirements, define problem statements, and translate them into scalable AI/ML solutions.\nPresent demos and proof-of-concepts (POCs) to clients, showcasing the value of AI/ML in real-world scenarios\nMentor and guide a cross-functional team of data scientists, ML engineers, and developers\nDrive best practices in model development, deployment, and monitoring\nStay abreast of the latest advancements in Gen AI and ML, and evaluate their applicability to client use cases\nContribute to internal knowledge bases and reusable solution accelerators\nPreferred candidate profile\nStrong programming skills in Python and experience with ML libraries (e.g., TensorFlow, PyTorch, scikit-learn).\nHands-on experience with Gen AI platforms and LLMs (e.g., OpenAI, Gemini, LLaMA, Mistral).\nProven track record of deploying ML models in production environments (cloud/on-prem).\nExperience with API development, data pipelines, and dashboarding tools like Streamlit.\nFamiliarity with DevOps and MLOps practices for model lifecycle management.\nExcellent communication and stakeholder management skills.\nTools:\nLLM, SLM, Vector DB, Graph DB, Airflow, MLFlow, MLOps tools, NLP, KG, ML models (Regression, Clustering, Classification etc), LangChain, LangGraph, AutoGen",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Agentic Ai', 'Knowledge Graphs', 'Generative Ai', 'Machine Learning', 'Deep Learning', 'RAG', 'Multimodal models', 'Computer Vision']",2025-06-11 06:06:22
Artificial Intelligence Engineer,Grasko Solutions,2 - 5 years,10-20 Lacs P.A.,['Bengaluru'],"Lead AI Engineer Job Description\n\nEducational Qualifications:\nMaster's or Ph.D. in Computer Science, Artificial Intelligence, Machine Learning, or a related field.\nStrong academic background with a focus on deep learning, natural language processing, and/or computer vision.\nExperience Requirements:\n2+ years of experience in AI/ML research and development, with a proven track record of delivering innovative solutions.\nExtensive experience in working with and customizing Large Language Models (LLMs).\nProficiency in popular AI development frameworks (e.g., TensorFlow, PyTorch, Keras).\nStrong programming skills in Python and/or other relevant languages.\nExperience in leading and mentoring AI/ML teams.\nKey Responsibilities:\nLead the development and deployment of AI-powered solutions for the project.\nInteract with and customize LLMs to meet specific project requirements.\nUtilize popular AI development frameworks to build and optimize AI models.\nCollaborate with cross-functional teams (e.g., product, engineering, data science) to deliver AI solutions.\nStay abreast of the latest advancements in AI/ML and incorporate them into the project.\nDesired Skills:\nStrong problem-solving and analytical skills.\nExcellent communication and interpersonal skills.\nAbility to work independently and as part of a team.\nPassion for AI and its potential to transform industries.\nAdditional Considerations:\nExperience in cloud computing platforms (e.g., AWS, Azure, GCP) is a plus.\nContributions to open-source AI/ML projects are highly valued.\nPublications in top-tier AI/ML conferences or journals are a plus.\nNote: This job description is intended to provide a general outline of the position's requirements. The specific responsibilities and qualifications may vary depending on the project and company needs.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['LLM', 'Python', 'Artificial Intelligence', 'Natural Language Processing']",2025-06-11 06:06:23
"Senior Data Scientist, Operations || Mumbai || 29 LPA",Argus India Price Reporting Services,5 - 10 years,20-25 Lacs P.A.,"['Mumbai Suburban', 'Navi Mumbai', 'Mumbai (All Areas)']","Senior Data Scientist, Operations\nMumbai, India\nAbout Argus:\n\nArgus is the leading independent provider of market intelligence to the global energy and commodity markets. We offer essential price assessments, news, analytics, consulting services, data science tools and industry conferences to illuminate complex and opaque commodity markets.\nHeadquartered in London with 1,500 staff, Argus is an independent media organisation with 30 offices in the worlds principal commodity trading hubs.\nCompanies, trading firms and governments in 160 countries around the world trust Argus data to make decisions, analyse situations, manage risk, facilitate trading and for long-term planning. Argus prices are used as trusted benchmarks around the world for pricing transportation, commodities and energy.\nFounded in 1970, Argus remains a privately held UK-registered company owned by employee shareholders and global growth equity firm General Atlantic.\n\nWhat were looking for:\nJoin our Generative AI team as a Senior Data Scientist, reporting directly to the Lead Data Scientist in India. You will play a crucial role in building, optimizing, and maintaining AI-ready data infrastructure for advanced Generative AI applications. Your focus will be on hands-on implementation of cutting-edge data extraction, curation, and metadata enhancement techniques for both text and numerical data. You will be a key contributor to the development of innovative solutions, ensuring rapid iteration and deployment, and supporting the Lead in achieving the team's strategic goals.\n\nWhat will you be doing:\nAI-Ready Data Development: Design, develop, and maintain high-quality AI-ready datasets, ensuring data integrity, usability, and scalability to support advanced Generative AI models.\nAdvanced Data Processing: Drive hands-on efforts in complex data extraction, cleansing, and curation for diverse text and numerical datasets. Implement sophisticated metadata enrichment strategies to enhance data utility and accessibility for AI systems.\nAlgorithm Implementation & Optimization: Implement and optimize state-of-the-art algorithms and pipelines for efficient data processing, feature engineering, and data transformation tailored for LLM and GenAI applications.\nGenAI Application Development: Apply and integrate frameworks like LangChain and Hugging Face Transformers to build modular, scalable, and robust Generative AI data pipelines and applications.\nPrompt Engineering Application: Apply advanced prompt engineering techniques to optimize LLM performance for specific data extraction, summarization, and generation tasks, working closely with the Lead's guidance.\nLLM Evaluation Support: Contribute to the systematic evaluation of Large Language Models (LLMs) outputs, analysing quality, relevance, and accuracy, and supporting the implementation of LLM-as-a-judge frameworks.\nRetrieval-Augmented Generation (RAG) Contribution: Actively contribute to the implementation and optimization of RAG systems, including working with embedding models, vector databases, and, where applicable, knowledge graphs, to enhance data retrieval for GenAI.\nTechnical Mentorship: Act as a technical mentor and subject matter expert for junior data scientists, providing guidance on best practices in coding and PR reviews, data handling, and GenAI methodologies.\nCross-Functional Collaboration: Collaborate effectively with global data science teams, engineering, and product stakeholders to integrate data solutions and ensure alignment with broader company objectives.\nOperational Excellence: Troubleshoot and resolve data-related issues promptly to minimize potential disruptions, ensuring high operational efficiency and responsiveness.\nDocumentation & Code Quality: Produce clean, well-documented, production-grade code, adhering to best practices for version control and software engineering.\n\nSkills and Experience:\nAcademic Background: Advanced degree in AI, statistics, mathematics, computer science, or a related field.\nProgramming and Frameworks: 2+ years of hands-on experience with Python, TensorFlow or PyTorch, and NLP libraries such as spaCy and Hugging Face.\nGenAI Tools: 1+ years Practical experience with LangChain, Hugging Face Transformers, and embedding models for building GenAI applications.\nPrompt Engineering: Deep expertise in prompt engineering, including prompt tuning, chaining, and optimization techniques.\nLLM Evaluation: Experience evaluating LLM outputs, including using LLM-as-a-judge methodologies to assess quality and alignment.\nRAG and Knowledge Graphs: Practical understanding and experience using vector databases. In addition, familiarity with graph-based RAG architectures and the use of knowledge graphs to enhance retrieval and reasoning would be a strong plus.\nCloud: 2+ years of experience with Gemini/OpenAI models and cloud platforms such as AWS, Google Cloud, or Azure. Proficient with Docker for containerization.\nData Engineering: Strong understanding of data extraction, curation, metadata enrichment, and AI-ready dataset creation.\nCollaboration and Communication: Excellent communication skills and a collaborative mindset, with experience working across global teams.\n\nWhats in it for you:\nCompetitive salary\nHybrid Working Policy (3 days in Mumbai office/ 2 days WFH once fully inducted)\nGroup healthcare scheme\n18 days annual leave\n8 days of casual leave\nExtensive internal and external training\n\nHours:\nThis is a full-time position operating under a hybrid model, with three days in the office and up to two days working remotely.\nThe team supports Argus key business processes every day, as such you will be required to work on a shift-based rota with other members of the team supporting the business until 8pm. Typically support hours run from 11am to 8pm with each member of the team participating up to 2/3 times a week.\n\nFor more details about the company and to apply please make sure you send your CV and cover letter via our website: www.argusmedia.com/en/careers/open-positions\nBy submitting your job application, you automatically acknowledge and consent to the collection, use and/or disclosure of your personal data to the Company. Argus is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pytorch', 'Artificial Intelligence', 'LangChain', 'hugging face', 'Spacy', 'Tensorflow']",2025-06-11 06:06:24
Associate Data Scientist,ZIGRAM,3 - 6 years,Not Disclosed,['Gurugram'],"Role & responsibilities\n\nHighly focused individual with self-driven attitude\nProblem solving and logical thinking to automate and improve internal processes\nUsing various tools such as SQL and Python for managing the various requirements for different data asset projects.\nAbility to diligently involve in activities like Data Cleaning, Retrieval, Manipulation, Analytics and Reporting\nUsing data science and statistical techniques to build machine learning models and deal with textual data.\nKeep up-to-date knowledge of the industry and related markets\nAbility to multitask, prioritize, and manage time efficiently\nUnderstand needs of the hiring organization or client in order to target solutions to their benefit\nAdvanced speaking and writing skills for effective communication\nAbility to work in cross functional teams demonstrating high level of commitment and coordination\nAttention to details and commitment to accuracy for the desired deliverable\nShould demonstrate and develop a sense of ownership towards the assigned task\nAbility to keep sensitive business information confidential\nContribute, positively and extensively towards building the organizational reputation, brand and\noperational excellence\n\nPreferred candidate profile\n\n3-6 years of relevant experience in data science\nAdvanced knowledge of statistics and basics of machine learning\nExperienced in dealing with textual data and using natural language processing techniques\nAbility to conduct analysis to extract actionable insights\nTechnical skills in Python (Numpy, Pandas, NLTK, transformers, Spacy), SQL and other programming languages for dealing with large datasets\nExperienced in data cleaning, manipulation, feature engineering and building models\nExperienced in the end-to-end development of a data science project\nStrong interpersonal skills and extremely resourceful\nProven ability to complete assigned task according to the outlined scope and timeline\nGood language, communication and writing skills in English\nExpertise in using tools like MS Office, PowerPoint, Excel and Word\nGraduate or Post-graduate from a reputed college or university",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Natural Language Processing', 'Machine Learning', 'Statistics', 'Random Forest', 'Data Science', 'Logistic Regression', 'Word', 'Mathematics', 'Powerpoint', 'MS Office', 'Deep Learning', 'Numpy', 'Analytics', 'SQL', 'Nltk', 'data base', 'English', 'Excel', 'Pandas', 'Transformers', 'Spacy', 'Python']",2025-06-11 06:06:26
Data Scientist @ bangalore,MKS Vision,7 - 12 years,Not Disclosed,"['Hyderabad', 'Coimbatore']","MKS Vision Pvt Ltd\n\nAbout us:\nMKS Vision is a full spectrum of Information Technology and engineering service provider. We exist to provide increased efficiencies and flexibility that accelerate business performance by adapting the latest cutting-edge technologies for our customers. Our services bring tangible benefits to our customers. MKS Vision will assist you in adopting global services.\nWebsite: https://www.mksvision.com/\nJob Location: Coimbatore/Hyderabad\nRisk Data Scientist\nKnowledge of lending industry analytical processes related to (credit underwriting, collections, etc.)\nExperienced in the data science lifecycle (model specification, development, deployment, and validation)\nProficient in the use of modeling and machine learning techniques (logistic regression, gradient boosting, etc.), in SAS, Python or R\nStrong working exp in Power BI.\nProficient in SQL for data extraction, manipulation and cleanup, and the development of modeling datasets for development\nExperience in conducting data studies and retro studies using internal and external data for model validation\nExperience in developing project presentations across the project lifecycle (project specification, development, conclusions, and recommendations)\nExperience in development and maintenance of model documentation\nKnowledge of lending data systems and data structures (credit applications, loan origination, collections, payments, dialers, credit bureau data)\nAbility to generate analytical insights form model data, including identification of candidate variables, and development of new features.\nPreferred minimum 7+ years of experience, BS degree on computer science, management information systems, statistics, data science, etc., or similar experience.",Industry Type: FinTech / Payments,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'SAS', 'Credit Risk Modelling', 'Python', 'SQL', 'R', 'Power Bi', 'Risk Analytics', 'ETL', 'Data Standards', 'Risk Modeling', 'Credit Risk Analysis']",2025-06-11 06:06:28
Gen AI Engineer,"NTT DATA, Inc.",2 - 7 years,Not Disclosed,['Bengaluru'],"Req ID: 323767\n\nWe are currently seeking a Gen AI Engineer to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nJob DutiesExercise expertise in ideating and developing AI/ML applications on prediction, recommendation, text analytics, computer vision, bots, content intelligence\n\nApply statistical skills and advanced statistical techniques and concepts.\n\nDemonstrate deep knowledge of ML frameworks such as TensorFlow, PyTorch, Keras, Spacy, and scikit-learn.\n\nLeverage advanced knowledge of Python open-source software stack such as Django or Flask, Django Rest or FastAPI, etc.\n\nDeep knowledge in statistics and Machine Learning models, deep learning models, NLP, Generative Adversarial Networks (GAN), and other generative models.\n\nExperience working with RAG technologies and LLM frameworks (Langchain and LlamaIndex), LLM model registries (Hugging Face), LLM APIs, embedding models, and vector databases (FAISS, Milvus, etc.).\n\nEmploy technical knowledge and hands-on experience with Azure OpenAI, Google Vertex Gen AI, and AWS LLM foundational models, BERT, Transformers, PaLM, Bard, etc.\n\nDisplay proficiency in programming languages such as Python and understanding of various Python packages. Experience with TensorFlow, PyTorch, or Keras.\n\nDevelop and implement GenAI solutions, collaborating with cross-functional teams, and supporting the successful execution of AI projects for a diverse range of clients.\n\nAssist in the design and implementation of GenAI use cases, projects, and POCs across multiple industries.\n\nContribute to the development of frameworks, capabilities, and features for NTT DATA""™s global GenAI platform and TechHub.\n\nWork on RAG models to enhance AI solutions by incorporating relevant information retrieval mechanisms.\n\nCreate and maintain data infrastructure to ingest, normalize, and combine datasets for actionable insights.\n\nCollaborate with data science teams to build, tune, and iterate on machine learning models and prompts.\n\nWork closely with customers to understand their requirements and deliver customized AI solutions.\n\nInteract at appropriate levels to ensure client satisfaction and project success.\n\nCommunicate complex technical concepts clearly to non-technical audiences.\n\nPreferred experience in Private AI and Smart Agent Solutions\n\nMinimum Skills Required 2+ years of experience architecting high-impact GenAI solutions for diverse clients, preferably in Private AI and Smart Agentic Solutions\n\n5+ year(s) of experience participating in projects that focused on one or more of the following areas:\n\no Predictive Analytics\n\no Data Design\n\no Generative AI\n\no AI/ML\n\no ML Ops\n\n3+ years of experience using Python.\n\nAbility to travel at least 25%.\n\nBachelor""™s Degree required.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'deep learning', 'ml', 'architecting', 'rest', 'vertex', 'scikit-learn', 'predictive analytics', 'aiml', 'google', 'artificial intelligence', 'gen', 'tensorflow', 'spacy', 'ops', 'django', 'pytorch', 'keras', 'flask', 'aws', 'statistics']",2025-06-11 06:06:29
Senior Data Science Engineer - Computer Vision,Uplers,6 - 7 years,25-35 Lacs P.A.,['Bengaluru'],"Senior Data Science Engineer - Computer Vision\n\nExperience: 6 - 7 Years Exp\nSalary : INR 25-35 Lacs per annum\nPreferred Notice Period: Within 30 Days\nShift: 09:00AM to 6:00PM IST\nOpportunity Type: Onsite (Bengaluru)\nPlacement Type: Contractual\nContract Duration: Full-Time, Indefinite Period\n\n(*Note: This is a requirement for one of Uplers' Clients)\n\nMust have skills required :\nComputer Vision, Deep Learning, Large scale Visual Datasets, MLFlow or DVC, Prometheus Or Grafana Or Sentry, Pytorch, Cloud Server (Google / AWS), Python\nGood to have skills :\nCV/AI Research, Healthcare, or surveillance/IoT-based CV applications., Publications in CVPR/NeurIPS/ICCU, Stakeholder Communication, TensorRT, Work in domains such as retail analytics\n\nRadius AI (One of Uplers' Clients) is Looking for:\nSenior Data Science Engineer - Computer Vision who is passionate about their work, eager to learn and grow, and who is committed to delivering exceptional results. If you are a team player, with a positive attitude and a desire to make a difference, then we want to hear from you.\n\nRole Overview Description\nSenior Data Science Engineer Computer Vision\nJob Summary\nWe are seeking a highly skilled and forward-thinking Senior Data Science Engineer to lead the development of advanced computer vision models and systems. You will play a pivotal role in designing, training, and deploying deep learning models, with a strong focus on real-time inference and edge deployment.\nThe ideal candidate will bring hands-on experience with state-of-the-art architectures and have a deep understanding of the complete ML lifecycle from data acquisition to deployment at scale.\n\nKey Responsibilities\nLead the development and implementation of computer vision models for tasks such as object detection, tracking, image retrieval, and scene understanding.\nDesign and execute end-to-end pipelines for data preparation, model training, evaluation, and deployment.\n¢ Perform fine-tuning and transfer learning on large-scale vision-language models to meet application-specific needs.\n¢ Optimize deep learning models for edge inference (NVIDIA Jetson, TensorRT, OpenVINO) and real-time performance.\n¢ Develop scalable and maintainable ML pipelines using tools such as MLflow, DVC, and Kubeflow.\n¢ Automate experimentation and deployment processes using CI/CD workflows.\n¢ Collaborate cross-functionally with MLOps, backend, and product teams to align technical efforts with business needs.\n¢ Monitor, debug, and enhance model performance in production environments.\n¢ Stay up-to-date with the latest trends in CV/AI research and rapidly prototype new ideas for real-world use.\n\nRequired Qualifications\n¢ 67+ years of hands-on experience in data science and machine learning, with at least 4 years focused on computer vision.\n¢ Strong experience with deep learning frameworks: PyTorch (preferred), TensorFlow, Hugging Face Transformers.\n¢ In-depth understanding and practical experience with Class-incremental learning and lifelong learning systems\n¢ Proficient in Python, including data processing libraries like NumPy, Pandas, and OpenCV.\n¢ Strong command of version control and reproducibility tools (e.g., MLflow, DVC, Weights & Biases).\n¢ Experience with training and optimizing models for GPU inference and edge deployment (Jetson, Coral, etc.).\n¢ Familiarity with ONNX, TensorRT, and model quantization/conversion techniques.\n¢ Demonstrated ability to analyze and work with large-scale visual datasets in real-time or near-real-time systems.\n\nPreferred Qualifications\n¢ Experience working in fast-paced startup environments with ownership of production AI systems.\n¢ Exposure to cloud platforms such as AWS (SageMaker, Lambda), GCP, or Azure for ML workflows.\n¢ Experience with video analytics, real-time inference, and event-based vision systems. ¢ Familiarity with monitoring tools for ML systems (e.g., Prometheus, Grafana, Sentry).\n\nEasy 3-Step Process:\n1. Click On Apply! And Register or log in on our portal\n2. Upload updated Resume & Complete the Screening Form\n3. Increase your chances to get shortlisted & meet the client for the Interview!\n\nAbout Our Client:\nRadiusAI is a pioneering computer vision analytics company revolutionizing retail operations with advanced, human-centric AI solutions. We offer the world's most advanced VisionAI checkout and we provide real-time data to improve operational efficiency across the entire retail industry, focusing on enterprise-level customers and secure edge integration\n\nAbout Uplers:\nOur goal is to make hiring and getting hired reliable, simple, and fast. Our role will be to help all our talents find and apply for relevant product and engineering job opportunities and progress in their career.\n\n(Note: There are many more opportunities apart from this on the portal.)\n\nSo, if you are ready for a new challenge, a great work environment, and an opportunity to take your career to the next level, don't hesitate to apply today. We are waiting for you!",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer Vision', 'Deep Learning', 'Pytorch', 'Large scale Visual Datasets', 'MLFlow or DVC', 'Prometheus Or Grafana Or Sentry']",2025-06-11 06:06:31
Senior Data Scientist,IDS Infotech,5 - 6 years,Not Disclosed,['Chandigarh'],"We are seeking a highly skilled and motivated Senior Data Scientist with 56 years of experience to drive the development of intelligent AI systems.\nThis role requires extensive hands-on experience with Large Language Models (LLMs), strong background in Agentic AI, Machine Learning, and Python programming.\nYou will work on designing autonomous agents, building scalable ML pipelines, and integrating advanced LLM-powered solutions into real-world products.\nKey Responsibilities:\nArchitect and implement agentic AI systems that use LLMs for autonomous reasoning, planning, and multi-step task execution.\nLead the development, fine-tuning, evaluation, and deployment of Large Language Models (LLMs) using frameworks like Hugging Face Transformers, LangChain, LLM orchestration tools, and vector databases.\nDevelop ML models using supervised, unsupervised, and reinforcement learning techniques, and integrate them into production environments.\nDesign and build end-to-end machine learning pipelines, including data ingestion, feature engineering, training, and deployment.\nOptimize model performance and latency in real-world applications and implement model monitoring and retraining strategies.\nCollaborate with cross-functional teams including product, engineering, and business to translate AI capabilities into product features.\nMentor junior data scientists and contribute to the team's technical excellence and innovation.\nRequired Skills & Experience:\n56 years of professional and relevant experience in data science, AI, or machine learning roles.\nProven hands-on experience with LLMs, including fine-tuning, prompt engineering, and RAG (Retrieval-Augmented Generation) pipelines.\nDeep expertise in Python and ML libraries such as scikit-learn, PyTorch, TensorFlow, and transformers.\nStrong understanding of agentic AI principles, autonomous agents, and task orchestration.\nExperience with cloud platforms (AWS, GCP, or Azure) and scalable infrastructure for deploying AI models.\nExposure to API development, ML model serving, and integration with real-time systems.\nExcellent communication and collaboration skills in cross-functional environments.\nEducational Qualification:\nBachelor of Technology (B.Tech) in Computer Science, Data Science, Artificial Intelligence, or a related field from a recognized institution.\nPreferred Qualifications:\nContributions to open-source AI/ML projects or research publications related to LLMs or agent-based systems.\nFamiliarity with LangChain, AutoGPT, CrewAI, or other agent orchestration frameworks.\nExperience with vector databases (e.g., FAISS, Pinecone) and knowledge of semantic search.\nUnderstanding of multi-agent collaboration, goal decomposition, and planning architectures.",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'ML model serving', 'Azure', 'PyTorch', 'CrewAI', 'GCP', 'LLM orchestration', 'AWS', 'Machine Learning', 'Python', 'TensorFlow']",2025-06-11 06:06:32
Data Engineer-Having Stratup-Mid-Size company Exp.@ Bangalore_Urgent,"As a leader in this space, we deliver wo...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Engineer\n\nLocation: Bangalore - Onsite\nExperience: 8 - 15 years\nType: Full-time\n\nRole Overview\n\nWe are seeking an experienced Data Engineer to build and maintain scalable, high-performance data pipelines and infrastructure for our next-generation data platform. The platform ingests and processes real-time and historical data from diverse industrial sources such as airport systems, sensors, cameras, and APIs. You will work closely with AI/ML engineers, data scientists, and DevOps to enable reliable analytics, forecasting, and anomaly detection use cases.\nKey Responsibilities\nDesign and implement real-time (Kafka, Spark/Flink) and batch (Airflow, Spark) pipelines for high-throughput data ingestion, processing, and transformation.\nDevelop data models and manage data lakes and warehouses (Delta Lake, Iceberg, etc) to support both analytical and ML workloads.\nIntegrate data from diverse sources: IoT sensors, databases (SQL/NoSQL), REST APIs, and flat files.\nEnsure pipeline scalability, observability, and data quality through monitoring, alerting, validation, and lineage tracking.\nCollaborate with AI/ML teams to provision clean and ML-ready datasets for training and inference.\nDeploy, optimize, and manage pipelines and data infrastructure across on-premise and hybrid environments.\nParticipate in architectural decisions to ensure resilient, cost-effective, and secure data flows.\nContribute to infrastructure-as-code and automation for data deployment using Terraform, Ansible, or similar tools.\n\n\nQualifications & Required Skills\n\nBachelors or Master’s in Computer Science, Engineering, or related field.\n6+ years in data engineering roles, with at least 2 years handling real-time or streaming pipelines.\nStrong programming skills in Python/Java and SQL.\nExperience with Apache Kafka, Apache Spark, or Apache Flink for real-time and batch processing.\nHands-on with Airflow, dbt, or other orchestration tools.\nFamiliarity with data modeling (OLAP/OLTP), schema evolution, and format handling (Parquet, Avro, ORC).\nExperience with hybrid/on-prem and cloud platforms (AWS/GCP/Azure) deployments.\nProficient in working with data lakes/warehouses like Snowflake, BigQuery, Redshift, or Delta Lake.\nKnowledge of DevOps practices, Docker/Kubernetes, Terraform or Ansible.\nExposure to data observability, data cataloging, and quality tools (e.g., Great Expectations, OpenMetadata).\nGood-to-Have\nExperience with time-series databases (e.g., InfluxDB, TimescaleDB) and sensor data.\nPrior experience in domains such as aviation, manufacturing, or logistics is a plus.\n\nRole & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['aviation', 'Data Modeling', 'Python', 'OLAP', 'Cloud', 'ORC', 'logistics', 'Avro', 'Terraform', 'Snowflake', 'manufacturing', 'AWS', 'Parquet', 'Java', 'Azure', 'BigQuery', 'Data', 'Redshift', 'SQL', 'TimescaleDB', 'GCP', 'InfluxDB', 'dbt', 'Ansible', 'OLTP', 'Kubernetes']",2025-06-11 06:06:35
Data Engineer,7dxperts,5 - 8 years,15-20 Lacs P.A.,['Bengaluru'],"Role & responsibilities\n3+ years of experience in Spark, Databricks, Hadoop, Data and ML Engineering.\n3+ Years on experience in designing architectures using AWS cloud services & Databricks.\nArchitecture, design and build Big Data Platform (Data Lake / Data Warehouse / Lake house) using Databricks services and integrating with wider AWS cloud services.\nKnowledge & experience in infrastructure as code and CI/CD pipeline to build and deploy data platform tech stack and solution.\nHands-on spark experience in supporting and developing Data Engineering (ETL/ELT) and Machine learning (ML) solutions using Python, Spark, Scala or R languages.\nDistributed system fundamentals and optimising Spark distributed computing.\nExperience in setting up batch and streams data pipeline using Databricks DLT, jobs and streams.\nUnderstand the concepts and principles of data modelling, Database, tables and can produce, maintain, and update relevant data models across multiple subject areas.\nDesign, build and test medium to complex or large-scale data pipelines (ETL/ELT) based on feeds from multiple systems using a range of different storage technologies and/or access methods, implement data quality validation and to create repeatable and reusable pipelines\nExperience in designing metadata repositories, understanding range of metadata tools and technologies to implement metadata repositories and working with metadata.\nUnderstand the concepts of build automation, implementing automation pipelines to build, test and deploy changes to higher environments.\nDefine and execute test cases, scripts and understand the role of testing and how it works.\n\nPreferred candidate profile\nBig Data technologies Databricks, Spark, Hadoop, EMR or Hortonworks.\nSolid hands-on experience in programming languages Python, Spark, SQL, Spark SQL, Spark Streaming, Hive and Presto\nExperience in different Databricks components and API like notebooks, jobs, DLT, interactive and jobs cluster, SQL warehouse, policies, secrets, dbfs, Hive Metastore, Glue Metastore, Unity Catalog and ML Flow.\nKnowledge and experience in AWS Lambda, VPC, S3, EC2, API Gateway, IAM users, roles & policies, Cognito, Application Load Balancer, Glue, Redshift, Spectrum, Athena and Kinesis.\nExperience in using source control tools like git, bit bucket or AWS code commit and automation tools like Jenkins, AWS Code build and Code deploy.\nHands-on experience in terraform and Databricks API to automate infrastructure stack.\nExperience in implementing CI/CD pipeline and ML Ops pipeline using Git, Git actions or Jenkins.\nExperience in delivering project artifacts like design documents, test cases, traceability matrix and low-level design documents.\nBuild references architectures, how-tos, and demo applications for customers.\nReady to complete certifications",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'Data Bricks', 'Python', 'ML', 'ML Engineering', 'Pyspark', 'MLops', 'Ci Cd Pipeline', 'GIT', 'Machine Learning', 'SQL']",2025-06-11 06:06:36
Data Science Manager job opening at GlobalData(Hyd),Globaldata,10 - 15 years,Not Disclosed,['Hyderabad( Kondapur )'],"Hello,\n\nUrgent job openings for Data Science Manager role @ GlobalData(Hyd).\n\nJob Description given below please go through to understand the requirement.\nif requirement is matching to your profile & interested to apply please share your updated resume @ mail id (m.salim@globaldata.com).",,,,"['Artificial Intelligence', 'Natural Language Processing', 'Machine Learning', 'Deep Learning', 'Data Science', 'Tensorflow', 'Predictive Modeling', 'Azure', 'Power Bi', 'Tableau', 'NLP', 'Hadoop Spark', 'AWS', 'Python']",2025-06-11 06:06:38
Data Engineer,Bebo Technologies,4 - 9 years,Not Disclosed,['Chandigarh'],"Design, build, and maintain scalable and reliable data pipelines on Databricks, Snowflake, or equivalent cloud platforms.\nIngest and process structured, semi-structured, and unstructured data from a variety of sources including APIs, RDBMS, and file systems.\nPerform data wrangling, cleansing, transformation, and enrichment using PySpark, Pandas, NumPy, or similar libraries.\nOptimize and manage large-scale data workflows for performance, scalability, and cost-efficiency.\nWrite and optimize complex SQL queries for transformation, extraction, and reporting.\nDesign and implement efficient data models and database schemas with appropriate partitioning and indexing strategies for Data Warehouse or Data Mart.\nLeverage cloud services (e.g., AWS S3, Glue, Kinesis, Lambda) for storage, processing, and orchestration.\nUse orchestration tools like Airflow, Temporal, or AWS Step Functions to manage end-to-end workflows.\nBuild containerized solutions using Docker and manage deployment pipelines via CI/CD tools such as Azure DevOps, GitHub Actions, or Jenkins.\nCollaborate closely with data scientists, analysts, and business stakeholders to understand requirements and deliver data solutions.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Pyspark', 'python', 'Snowflake', 'Data Bricks', 'sql']",2025-06-11 06:06:39
"Machine Learning, Technical Lead - NLP / LLM",Avalara Technologies,6 - 10 years,Not Disclosed,[],"What You'll Do\nWe are looking for experienced Machine Learning Engineers with a background in software development and a deep enthusiasm for solving complex problems. You will lead a dynamic team dedicated to designing and implementing a large language model framework to power diverse applications across Avalara.\nYour responsibilities will span the entire development lifecycle, including conceptualization, prototyping and delivery of the LLM platform features. You will build core agent infrastructureA2A orchestration and MCP-driven tool discoveryso teams can launch secure, scalable agent workflows. You will be reporting to Senior Manager, Machine Learning",,,,"['Machine Learning', 'NLP', 'Docker', 'Terraform', 'MLFlow', 'Prometheus', 'LLM', 'AWS', 'Grafana', 'GitLab', 'Kubernetes']",2025-06-11 06:06:41
Data Analyst -Python,Sopra Steria,3 - 5 years,Not Disclosed,['Chennai'],"Experience working in large Software Development Teams\nKnowledge and experience in Agile Delivery mechanisms \nWork with business stakeholders, SCRUM masters, Designers and testers in SCRUM team.\nProficient in English language with ability to lead stakeholder conversations.\nExperience in generating insights through data and articulating stories addressing business problems.\nTotal Experience Expected: 6-8 years\n",,,,"['data mining', 'vlookup', 'sql', 'analytics', 'data science', 'advanced excel', 'data visualization', 'technical skills', 'python', 'macros', 'data analysis', 'data analytics', 'sas', 'insights', 'predictive analytics', 'business analysis', 'machine learning', 'excel', 'tableau', 'r', 'vba', 'predictive modeling', 'scrum', 'agile', 'statistics']",2025-06-11 06:06:42
Lead Data Analyst-Business Intelligence,Tresvista Financial Services,6 - 10 years,Not Disclosed,['Bengaluru'],"Roles and Responsibilities\nArchitect and incorporate an effective Data framework enabling end to end Data Solution.\nUnderstand business needs, use cases and drivers for insights and translate them into detailed technical specifications.\nCreate epics, features and user stories with clear acceptance criteria for execution and delivery by the data engineering team.\nCreate scalable and robust data solution designs that incorporate governance, security and compliance aspects.\nDevelop and maintain logical and physical data models and work closely with data engineers, data analysts and data testers for successful implementation of them.\nAnalyze, assess and design data integration strategies across various sources and platforms.\nCreate project plans and timelines while monitoring and mitigating risks and controlling progress of the project.\nConduct daily scrum with the team with a clear focus on meeting sprint goals and timely resolution of impediments.\nAct as a liaison between technical teams and business stakeholders and ensure.\nGuide and mentor the team for best practices on Data solutions and delivery frameworks.\nActively work, facilitate and support the stakeholders/ clients to complete User Acceptance Testing ensure there is strong adoption of the data products after the launch.\nDefining and measuring KPIs/KRA for feature(s) and ensuring the Data roadmap is verified through measurable outcomes\n\nPrerequisites\n5 to 8 years of professional, hands on experience building end to end Data Solution on Cloud based Data Platforms including 2+ years working in a Data Architect role.\nProven hands on experience in building pipelines for Data Lakes, Data Lake Houses, Data Warehouses and Data Visualization solutions\nSound understanding of modern Data technologies like Databricks, Snowflake, Data Mesh and Data Fabric.\nExperience in managing Data Life Cycle in a fast-paced, Agile / Scrum environment.\nExcellent spoken and written communication, receptive listening skills, and ability to convey complex ideas in a clear, concise fashion to technical and non-technical audiences\nAbility to collaborate and work effectively with cross functional teams, project stakeholders and end users for quality deliverables withing stipulated timelines\nAbility to manage, coach and mentor a team of Data Engineers, Data Testers and Data Analysts. Strong process driver with expertise in Agile/Scrum framework on tools like Azure DevOps, Jira or Confluence\nExposure to Machine Learning, Gen AI and modern AI based solutions.\n\nExperience\nTechnical Lead Data Analytics with 6+ years of overall experience out of which 2+ years is on Data architecture.\n\nEducation\nEngineering degree from a Tier 1 institute preferred.\n\nCompensation\nThe compensation structure will be as per industry standards",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'Data Bricks', 'Data Lake', 'Data Warehousing', 'Python', 'Business Intelligence', 'Databricks Engineer', 'Machine Learning', 'Redshift Aws', 'Snowflake', 'Data Visualization', 'ETL', 'Data Mesh']",2025-06-11 06:06:44
Senior Data Scientist,Straive,5 - 10 years,Not Disclosed,"['Hyderabad', 'Gurugram', 'Bengaluru']","Role & responsibilities\nRequires 5-8 years of proven experience in banking/payments/other domains\nStrong experience in developing Machine Learning models, Python & SQL\nExperience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases\nDetailed oriented with a proactive mindset towards problem-solving\nExcellent communication and presentation skills with the ability to convey complex information clearly and concisely",,,,"['Machine Learning', 'Python', 'SQL', 'Xgboost', 'Neural Networks', 'Random Forest']",2025-06-11 06:06:46
DevOps Engineer Senior Specialist,"NTT DATA, Inc.",2 - 6 years,Not Disclosed,['Bengaluru'],"Req ID: 318941\n\nWe are currently seeking a DevOps Engineer Senior Specialist to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nExpert in terraform coding knowledge.\n\nExpert in Azure DevOps.\nProficient in designing, deploying and maintaining Azure infrastructure using version-controlled infrastructure as code deployments.\nExpertise in writing and troubleshooting CICD pipelines defined in source control. Knowledge of Azure DevOps and Git.\nExcellent communication, analytical and problem-solving skills.\nProven ability to efficiently manage multiple initiatives simultaneously.\nCollaborative team player, keen to learn and share ideas.\nExperience with one or more of the following would be a benefitPowerShell, Azure OpenAI, Azure Machine Learning, Databricks.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure devops', 'azure infrastructure', 'troubleshooting', 'terraform', 'ci cd pipeline', 'python', 'natural language processing', 'azure machine learning', 'microsoft azure', 'ci/cd', 'machine learning', 'sql', 'ansible', 'docker', 'data bricks', 'code deploy', 'git', 'devops', 'jenkins', 'aws']",2025-06-11 06:06:47
Hiring Team Lead / Manager - Master Data- Finance and Accounts,"NTT DATA, Inc.",7 - 11 years,Not Disclosed,['Gurugram'],"""NTT DATA- Hiring for Master Data Management (MDM) Finance & Accounting- Looking for Immediate Joiners ""\nWork Location- Gurgaon\nWork Mode- Hybrid\n\nMaster Data Management (MDM) Finance & Accounting""\nAbout NTT DATANTT DATA is a $30+ billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long-term success. As a Global Top Employer, we have experts in more than 50 countries and a robust partner ecosystem of established and startup companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are also one of the leading providers of digital and AI infrastructure in the world. NTT DATA is part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at nttdata.com\n\nJob brief We seek a competent Specialist to perform Master Data Management (MDM) in ERP system. This process consists of very tight timelines and multiple source systems and end systems. Our Specialist should exhibit professionalism, dedication and commitment towards timely delivery of services.\n\nJob Responsibilities\nEnd-to-end ownership of master data management\nAnalyze and triage missing master data issues and work with respective teams to fix the issues. This job involves MDM with respect to:\nProduct Master creation and Maintenance\nClient Master creation and Maintenance\nVendor Master creation and Maintenance\nService Master creation and Maintenance\nData Governance Review each incoming request for duplication and completeness of data\nData Quality Review each record for correctness and completeness\n\nMinimum Experience, Education and Certifications\nM.Com / B.Com /CA/ICWA\nRequires 7- 11 years relevant experience\n\nTechnical Skill Must have\nVery good knowledge of relevant usage of Master Data\nVery good data analysis skills\nProblem resolving skills and should be a team player\nWorking knowledge of MS Office and databases\nSAP ERP\n\nSoft Skills\nGood communication skills (verbal and written).\nGood interpersonal skills and ability to self-manage.\nDisplay good planning and organizing abilities.\nDemonstrate good attention to detail and deadline driven.\nAble to cope with stressful situations.\nAble to deal with different individuals at various levels in the organization.\nTakes own initiative and has a solutions-orientated approach.\nMaintains a high standard of accuracy and quality.\nAbility to work independently and be a knowledge expert\nComfortable working with targets\nPatience and ability to manage stress",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['SAP', 'MDM', 'Master Data Management', 'Customer creation', 'Vendor Master', 'Vendor Master Data', 'Material Master Data', 'Data Governance', 'Product Master', 'Client master']",2025-06-11 06:06:48
Data Science - Director job opening at GlobalData(Hyderabad),Globaldata,15 - 20 years,Not Disclosed,['Hyderabad( Kondapur )'],"R\nHello,\n\nUrgent job openings for Data Science - Director @ GlobalData(Hyderebad)\n\nJob Description given below please go through to understand the requirement.\n\nif requirement is matching to your profile & interested to apply please share your updated resume @ mail id (m.salim@globaldata.com).",,,,"['Data Science', 'Pytorch', 'Generative Ai Tools', 'Large Language Model', 'Python', 'Tensorflow', 'Natural Language Processing', 'Deep Learning']",2025-06-11 06:06:50
Sr. Data Scientist - Chennai,Teamplus Staffing Solution,10 - 17 years,25-40 Lacs P.A.,['Chennai( T Nagar )'],"LLMs - OpenAI, Gemini, CoPilot etc.\nGood Knowledge of RAG Pipeline Architectures\nFine/Prompt/Instruction Tuning of LLMs\nmachine learning frameworks (like Keras or PyTorch) and libraries (like scikit-learn).\ncloud services (GCP, Azure, AWS).",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Data Scientist', 'Azure', 'Artificial Intelligence', 'CoPilot', 'LLM', 'Machine Learning', 'Deep Learning', 'Pytorch', 'GCP', 'RAG', 'OpenAI', 'Keras', 'AWS', 'Gemini']",2025-06-11 06:06:51
Hiring | Display Support| Naukri| Noida,Info Edge,0 - 4 years,3-4 Lacs P.A.,['Noida'],"Hi,\nAs discussed, Please find the below mentioned JD for the role of Display Support-Naukri.com\nAbout Info Edge\nInfoEdges mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['freshers', 'Customer Service', 'Customer Support', 'operations', 'Non Voice Process', 'graduate', 'Back Office', 'Customer Care', 'backend', 'Non Voice', 'Bpo Non Voice']",2025-06-11 06:06:53
Data Engineer,Tekskills India pvt ltd,7 - 9 years,8-15 Lacs P.A.,['Hyderabad'],"Role & Responsibilities Role Overview: We are seeking a talented and forward-thinking Data Engineer for one of the large financial services GCC based in Hyderabad with responsibilities that include designing and constructing data pipelines, integrating data from multiple sources, developing scalable data solutions, optimizing data workflows, collaborating with cross-functional teams, implementing data governance practices, and ensuring data security and compliance.\n\nTechnical Requirements: • Proficiency in ETL, Batch, and Streaming Process • Experience with BigQuery, Cloud Storage, and CloudSQL • Strong programming skills in Python, SQL, and Apache Beam for data processing • Understanding of data modeling and schema design for analytics • Knowledge of data governance, security, and compliance in GCP • Familiarity with machine learning workflows and integration with GCP ML tools • Ability to optimize performance within data pipelines\n\nFunctional Requirements: • Ability to collaborate with Data Operations, Software Engineers, Data Scientists, and Business SMEs to develop Data Product Features • Experience in leading and mentoring peers within an existing development team • Strong communication skills to craft and communicate robust solutions • Proficient in working with Engineering Leads, Enterprise and Data Architects, and Business Architects to build appropriate data foundations • Willingness to work on contemporary data architecture in Public and Private Cloud environments This role offers a compelling opportunity for a seasoned Data Engineering to drive transformative cloud initiatives within the financial sector, leveraging unparalleled experience and expertise to deliver innovative cloud solutions that align with business imperatives and regulatory requirements. Qualification o Engineering Grad / Postgraduate CRITERIA o Proficient in ETL, Python, and Apache Beam for data processing efficiency. o Demonstrated expertise in BigQuery, Cloud Storage, and CloudSQL utilization. o Strong collaboration skills with cross-functional teams for data product development. o Comprehensive knowledge of data governance, security, and compliance in GCP. o Experienced in optimizing performance within data pipelines for efficiency.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['ETL', 'GCP', 'Apache beam', 'Bigquery', 'Cloud sql', 'Cloudstorage', 'Python']",2025-06-11 06:06:54
NLP Data Engineer - Risk Insights & Monitoring,MNC IT,10 - 12 years,25-30 Lacs P.A.,"['Pune', 'Mumbai (All Areas)']","Design and implement state-of-the-art NLP models, including but not limited to text classification, semantic search, sentiment analysis, named entity recognition, and summary generation.\nconduct data preprocessing, and feature engineering to improve model accuracy and performance.\nStay updated with the latest developments in NLP and ML, and integrate cutting-edge techniques into our solutions.\ncollaborate with Cross-Functional Teams: Work closely with data scientists, software engineers, and product managers to align NLP projects with business objectives.\ndeploy models into production environments and monitor their performance to ensure robustness and reliability.\nmaintain comprehensive documentation of processes, models, and experiments, and report findings to stakeholders.\nimplement and deliver high quality software solutions / components for the Credit Risk monitoring platform.\nleverage his/her expertise to mentor developers; review code and ensure adherence to standards.\napply a broad range of software engineering practices, from analyzing user needs and developing new features to automated testing and deployment\nensure the quality, security, reliability, and compliance of our solutions by applying our digital principles and implementing both functional and non-functional requirements\nbuild observability into our solutions, monitor production health, help to resolve incidents, and remediate the root cause of risks and issues\nunderstand, represent, and advocate for client needs\nshare knowledge and expertise with colleagues , help with hiring, and contribute regularly to our engineering culture and internal communities.\nExpertise -\nBachelor of Engineering or equivalent.\nIdeally 8-10Yrs years of experience in NLP based applications focused on Banking / Finance sector.\nPreference for experience in financial data extraction and classification.\nInterested in learning new technologies and practices, reuse strategic platforms and standards, evaluate options, and make decisions with long-term sustainability in mind.\nProficiency in programming languages such as Python & Java. Experience with frameworks like TensorFlow, PyTorch, or Keras.\nIn-depth knowledge of NLP techniques and tools, including spaCy, NLTK, and Hugging Face.\nExperience with data handling and processing tools like Pandas, NumPy, and SQL.\nPrior experience in agentic AI, LLMs ,prompt engineering and generative AI is a plus.\nBackend development and microservices using Java Spring Boot, J2EE, REST for implementing projects with high SLA of data availability and data quality.\nExperience of building cloud ready and migrating applications using Azure and understanding of the Azure Native Cloud services, software design and enterprise integration patterns.\nKnowledge of SQL and PL/SQL (Oracle) and UNIX, writing queries, packages, working with joins, partitions, looking at execution plans, and tuning queries.\nA real passion for and experience of Agile working practices, with a strong desire to work with baked in quality subject areas such as TDD, BDD, test automation and DevOps principles\nExperience in Azure development including Databricks , Azure Services , ADLS etc.\nExperience using DevOps toolsets like GitLab, Jenkins",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['data engineer', 'Natural Language Processing', 'Python', 'Java']",2025-06-11 06:06:56
Walkin| Operations Executive | Naukri| Noida,Info Edge,0 - 4 years,3-4 Lacs P.A.,['Noida'],"Hi,\nAs discussed, Please find the below mentioned JD for the role of Display Support-Naukri.com\nAbout Info Edge\n\nInfoEdges mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['freshers', 'Customer Service', 'Customer Support', 'operations', 'Non Voice Process', 'Mba Operations', 'graduate', 'Back Office', 'Customer Care', 'backend', 'Non Voice', 'Bpo Non Voice']",2025-06-11 06:06:57
Data Engineer Graph – Research Data and Analytics,Amgen Inc,2 - 4 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will be part Researchs Semantic Graph Team is seeking a qualified individual to design, build, and maintain solutions for scientific data that drive business decisions for Research. The successful candidate will construct scalable and high-performance data engineering solutions for extensive scientific datasets and collaborate with Research partners to address their data requirements. The ideal candidate should have experience in the pharmaceutical or biotech industry, leveraging their expertise in semantics, taxonomies, and linked data principles to ensure data harmonization and interoperability. Additionally, this individual should demonstrate robust technical skills, proficiency with data engineering technologies, and a thorough understanding of data architecture and ETL processes.\nRoles & Responsibilities:\nDesign, develop, and implement data pipelines, ETL/ELT processes, and data integration solutions\nTake ownership of data pipeline projects from inception to deployment, manage scope, timelines, and risks\nDevelop and maintain semantic data models for biopharma scientific data, data dictionaries, and other documentation to ensure data accuracy and consistency\nOptimize large datasets for query performance\nCollaborate with global multi-functional teams including research scientists to understand data requirements and design solutions that meet business needs\nImplement data security and privacy measures to protect sensitive data\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions\nCollaborate with Data Architects, Business SMEs, Software Engineers and Data Scientists to design and develop end-to-end data pipelines to meet fast paced business needs across geographic regions\nIdentify and resolve [complex] data-related challenges\nAdhere to standard processes for coding, testing, and designing reusable code/component\nExplore new tools and technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation\nMaintain comprehensive documentation of processes, systems, and solutions\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. T\nBasic Qualifications and Experience:\nDoctorate Degree OR Masters degree with 2- 4years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 4- 6years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 7- 9 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\n\n\nPreferred Qualifications and Experience:\n4+ years of experience in designing and supporting biopharma scientific research data analytics (software platforms)\n\n\nFunctional Skills:\nMust-Have Skills:\nProficiency in SQL and Python for data engineering, test automation frameworks (pytest), and scripting tasks\nHands on experience with data technologies and platforms, such as Databricks, workflow orchestration, performance tuning on big data processing.\nExcellent problem-solving skills and the ability to work with large, complex datasets\n\n\nGood-to-Have Skills:\nA passion for tackling complex challenges in drug discovery with technology and data\nExperience with system administration skills, such as managing Linux and Windows servers, configuring network infrastructure, and automating tasks with shell scripting. Examples include setting up and maintaining virtual machines, troubleshooting server issues, and ensuring data security through regular updates and backups.\nSolid understanding of data modeling, data warehousing, and data integration concepts\nSolid experience using RDBMS (e.g. Oracle, MySQL, SQL server, PostgreSQL)\nKnowledge of cloud data platforms (AWS preferred)\nExperience with data visualization tools (e.g. Dash, Plotly, Spotfire)\nExperience with diagramming and collaboration tools such as Miro, Lucidchart or similar tools for process mapping and brainstorming\nExperience writing and maintaining user documentation in Confluence\nUnderstanding of data governance frameworks, tools, and standard processes\n\n\nProfessional Certifications:\nDatabricks Certified Data Engineer Professional preferred\n\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nDemonstrated presentation skills",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'PostgreSQL', 'MySQL', 'ETL', 'ELT', 'Oracle', 'SQL server', 'AWS']",2025-06-11 06:06:59
Data Engineer,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will responsible for designing, building, maintaining, analyzing, and interpreting data to provide actionable insights that drive business decisions. This role involves working with large datasets, developing reports, supporting and executing data governance initiatives, and visualizing data to ensure data is accessible, reliable, and efficiently managed. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture and ETL processes.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in the design and development of the data pipeline.\nCreate data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nContribute to the design, development, and implementation of data pipelines, ETL/ELT processes, and data integration solutions.\nTake ownership of data pipeline projects from inception to deployment, manage scope, timelines, and risks.\nCollaborate with cross-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nBasic Qualifications and Experience\nMasters degree and 1 to 3 years of experience in Computer Science, IT, or related field OR\nBachelors degree and 3 to 5 years of experience in Computer Science, IT, or related field OR\nDiploma and 7 to 9 years of experience in Computer Science, IT, or related field\nMust-Have Skills:\nHands-on experience with big data technologies and platforms, such as Databricks, Apache Spark (PySpark, SparkSQL), workflow orchestration, performance tuning on big data processing.\nProficiency in data analysis tools (e.g., SQL) and experience with data visualization tools.\nExcellent problem-solving skills and the ability to work with large, complex datasets.\nPreferred Qualifications:\nGood-to-Have Skills:\nExperience with ETL tools such as Apache Spark, and various Python packages related to data processing, machine learning model development.\nStrong understanding of data modeling, data warehousing, and data integration concepts.\nKnowledge of Python/R, Databricks, SageMaker, cloud data platforms.\nProfessional Certifications:\nCertified Data Engineer / Data Analyst (preferred on Databricks or cloud environments).\nCertified Data Scientist (preferred on Databricks or Cloud environments).\nMachine Learning Certification (preferred on Databricks or Cloud environments).\nSoft Skills:\nExcellent critical-thinking and problem-solving skills.\nStrong communication and collaboration skills.\nDemonstrated awareness of how to function in a team setting.\nDemonstrated presentation skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'SageMaker', 'R', 'data modeling', 'data warehousing', 'cloud data platforms', 'Databricks', 'ETL', 'data integration', 'Python']",2025-06-11 06:07:00
Data & AI Technical Solution ArchitectsData & AI Technical Solution,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Pune'],"Title : Data & AI Technical Solution ArchitectsData & AI Technical Solution Architects\n\nReq ID: 323749\n\nWe are currently seeking a Data & AI Technical Solution ArchitectsData & AI Technical Solution Architects to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nJob DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'needs assessment', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'gcp', 'gcp cloud', 'ml']",2025-06-11 06:07:02
Walk-in Interview | Inside Sales | Naukri.com,Info Edge,0 - 5 years,4.25-5.5 Lacs P.A.,['Noida'],"Dear [Candidate Name],\nYou have been invited for a face to face interview with Naukri.com. Please find below the details.\n\nDate - 14th June 2025 (Saturday)\nTime - 10 AM to 2 PM\nAddress - D-13, Sector - 2, Noida (near sector - 15 metro station)\n\nAbout Info Edge",,,,"['telesales', 'inside sales', 'b2b sales', 'Lead Generation', 'Telecalling', 'Insurance Sales', 'outbound sales', 'Bpo Sales', 'b2c sales', 'Telemarketing', 'sales']",2025-06-11 06:07:04
Senior Data Engineer,Atidiv,5 - 8 years,10-17 Lacs P.A.,[],"Were Hiring! | Senior Data Engineer (Remote)\n\nLocation: Remote |\nShift: US - CST Time |\nDepartment: Data Engineering\n\nAre you a data powerhouse who thrives on solving complex data challenges? Do you love working with Python, AWS, and cutting-edge data tools? If yes, Atidiv wants YOU!",,,,"['SQL', 'Snowflake', 'Python', 'Airflow', 'Pyspark', 'Kafka', 'Lamda', 'Ci/Cd', 'EMR', 'Aws Glue', 'Lambda Aws', 'Cd Tools', 'Glue', 'Kinesis', 'Redshift Aws', 'DBT', 'aws']",2025-06-11 06:07:06
Data & AI Technical Solution Architects,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Pune'],"Req ID: 323754\n\nWe are currently seeking a Data & AI Technical Solution Architects to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nJob DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'solution design', 'gcp', 'gcp cloud', 'ml']",2025-06-11 06:07:07
Data & AI Technical Solution Architects,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Hyderabad'],"Req ID: 323774\n\nWe are currently seeking a Data & AI Technical Solution Architects to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n""Job DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'solution design', 'gcp', 'gcp cloud', 'ml']",2025-06-11 06:07:09
Senior Data Engineer,A leading Bank of India,8 - 13 years,Not Disclosed,['Mumbai (All Areas)'],"Role & responsibilities:\nDesign, optimize, and manage complex SQL queries across large Oracle databases.\nBuild and maintain metadata layers (table schema, DDL, column descriptions, relationships).\nDevelop and fine-tune solutions for converting natural language to SQL using various python libraries or other solutions.\nBuild and integrate chatbot interfaces using Python (Streamlit, FastAPI, Flask). Preferred is Flask.\nHave handled feature building for creating dynamic query agents.\nImplement user query handling, ambiguity detection, and feedback loops.\nDesign and test proof-of-concept (PoC) solutions to solve business queries using Python.\nBuild modular components (e.g., SQL generators, data sanitizers, security layers).\nCollaborate with business and business analysts to convert ideas into working prototypes.\nImplement query safety checks to prevent injection and unauthorized data access.\nMaintain logs and audit trails for executed queries and system usage.\n\nPreferred candidate profile:\n\nStrong experience in data engineering, analytics, or backend systems.\nExpert-level SQL skills (especially Oracle SQL).\nStrong Python programming skills, including libraries like pandas, sqlalchemy,strea, flask, etc.\nExperience with one or more NLP libraries: OpenAI GPT (function calling), LangChain, HuggingFace Transformers.\nKnowledge of database metadata modeling and handling DDL for large-scale systems.\nExperience with REST APIs and building microservices in Python.\nExposure to modern LLM tools like DSPy, sqlcoder, Text2SQL, or LangChain SQL Agent.\nFamiliarity with RDBMS performance tuning and optimization strategies.\nKnowledge of visualization tools like Plotly, Dash, or Streamlit for result rendering.\nUnderstanding of RBAC and secure data access practices.",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Banking domain', 'Natural Language Processing', 'Large Language Model', 'Chatbot Development', 'Python', 'Tensorflow', 'Oracle SQL', 'Artificial Intelligence', 'FASTapi', 'Machine Learning', 'Deep Learning', 'Numpy', 'Scikit-Learn', 'Pytorch', 'Django', 'Pandas', 'Aiml', 'Flask']",2025-06-11 06:07:10
"Data engineer with Gen AI- Balewadi, pune- hybrid",Indian MNC,5 - 10 years,15-30 Lacs P.A.,['Pune( Balewadi )'],"Role & responsibilities\nWe are seeking a skilled Data Engineer with advanced expertise in Python, PySpark, Databricks, and Machine Learning, along with a working knowledge of Generative and Agentic AI. This role is critical in ensuring data integrity and driving innovation across enterprise systems. You will design and implement ML-driven solutions to enhance Data Governance & Data Privacy initiatives through automation, self-service capabilities, and scalable, AI-enabled innovation.\nKey Responsibilities:\nImplement ML and Generative/Agentic AI solutions to optimize Data Governance processes.\nDesign, develop, and maintain scalable data pipelines using Python, PySpark, and Databricks.\nDevelop automation frameworks to support data quality, lineage, classification, and access control.\nDevelop and deploy machine learning models to uncover data patterns, detect anomalies, and enhance data governance and privacy compliance\nCollaborate with data stewards, analysts, and governance teams to build self-service data capabilities.\nWork with Databricks, Azure Data Lake, AWS, and other cloud-based data platforms for data engineering.\nBuild, configure, and integrate APIs for seamless system interoperability.\nEnsure data integrity, consistency, and compliance across systems and workflows.\nIntegrate AI models to support data discovery, metadata enrichment, and intelligent recommendations.\nOptimize data architecture to support analytics, reporting, and governance use cases.\nMonitor and improve the performance of ML/AI components in production environments.\nStay updated with emerging AI and data engineering technologies to drive continuous innovation.\nTechnical Skills:\nStrong programming skills in Python, PySpark, SQL for data processing and automation.\nExperience with Databricks and Snowflake (preferred) for building and maintaining data pipelines.\nExperience with Machine Learning model development and Generative/Agentic AI frameworks (e.g. LLMs, Transformers, LangChain) especially in the Data Management space\nExperience working with REST APIs & JSON for service integration\nExperience working with cloud-based platforms such as Azure, AWS, or GCP\nPower BI dashboard development experience is a plus.\nSoft Skills:\nStrong problem-solving skills and attention to detail.\nExcellent communication and collaboration abilities, with experience working across technical and business teams",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pyspark', 'Generative Ai', 'Azure Databricks', 'Ml']",2025-06-11 06:07:12
Senior Web Crawler & Data Extraction Engineer,Netgraph Networking,5 - 10 years,Not Disclosed,[],"Summary\n\nTo enhance user profiling and risk assessment, we are building web crawlers to collect relevant user data from third-party sources, forums, and the dark web. We are seeking a Senior Web Crawler & Data Extraction Engineer to design and implement these data collection solutions.\n\nJob Responsibilities\n\nDesign, develop, and maintain web crawlers and scrapers to extract data from open web sources, forums, marketplaces, and the dark web.\nImplement data extraction pipelines that aggregate, clean, and structure data for fraud detection and risk profiling.\nUse Tor, VPNs, and other anonymization techniques to safely crawl the dark web while avoiding detection.\nDevelop real-time monitoring solutions for tracking fraudulent activities, data breaches, and cybercrime discussions.\nOptimize crawling speed and ensure compliance with website terms of service, ethical standards, and legal frameworks.\nIntegrate extracted data with fraud detection models, risk scoring algorithms, and cybersecurity intelligence tools.\nWork with data scientists and security analysts to develop threat intelligence dashboards from collected data.\nImplement anti-bot detection evasion techniques and handle CAPTCHAs using AI-driven solvers where necessary.\nStay updated on OSINT (Open-Source Intelligence) techniques, web scraping best practices, and cybersecurity trends.\n\nRequirements\n5+ years of experience in web crawling, data scraping, or cybersecurity data extraction.\nStrong proficiency in Python, Scrapy, Selenium, BeautifulSoup, Puppeteer, or similar frameworks.\nExperience working with Tor, proxies, and VPNs for anonymous web scraping.\nDeep understanding of HTTP protocols, web security, and bot detection mechanisms.\nExperience parsing structured and unstructured data from JSON, XML, and web pages.\nStrong knowledge of database management (SQL, NoSQL) for storing large-scale crawled data.\nFamiliarity with AI/ML-based fraud detection techniques and data classification methods.\nExperience working with cybersecurity intelligence sources, dark web monitoring, and OSINT tools.\nAbility to implement scalable, distributed web crawling architectures.\nKnowledge of data privacy regulations (GDPR, CCPA) and ethical data collection practices.\n\nNice to Have\nExperience in fintech, fraud detection, or threat intelligence.\nKnowledge of natural language processing (NLP) for analyzing cybercrime discussions.\nFamiliarity with machine learning-driven anomaly detection for fraud prevention.\nHands-on experience with cloud-based big data solutions (AWS, GCP, Azure, Elasticsearch, Kafka).",Industry Type: FinTech / Payments,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Scrapy', 'Web Crawling', 'Data Extraction', 'Web Scraping', 'Python', 'Automation', 'BeautifulSoup', 'Data Scraping', 'Selenium', 'Python Development']",2025-06-11 06:07:13
Data Engineer,DATA ENGINEER,5 - 10 years,Not Disclosed,['Hyderabad'],"Job Title: Data Engineer\nExperience: 5+ Years\nLocation: Hyderabad (Onsite)\nAvailability: Immediate Joiners Preferred\nJob Description:\nWe are seeking an experienced Data Engineer with a strong background in Java, Spark, and Scala to join our dynamic team in Hyderabad. The ideal candidate will be responsible for building scalable data pipelines, optimizing data processing workflows, and supporting data-driven solutions for enterprise-grade applications. This is a full-time onsite role.\nKey Responsibilities:\nDesign, develop, and maintain robust and scalable data processing pipelines.\nWork with large-scale data using distributed computing technologies like Apache Spark.\nDevelop applications and data integration workflows using Java and Scala.\nCollaborate with cross-functional teams including Data Scientists, Analysts, and Product Managers.\nEnsure data quality, integrity, and security in all data engineering solutions.\nMonitor and troubleshoot performance and data issues in production systems.\nMust-Have Skills:\nStrong hands-on experience with Java, Apache Spark, and Scala.\nProven experience working on large-scale data processing systems.\nSolid understanding of distributed systems and performance tuning.\nGood-to-Have Skills:\nExperience with Hadoop, Hive, and HDFS.\nFamiliarity with data warehousing concepts and ETL processes.\nExposure to cloud data platforms is a plus.\nDesired Candidate Profile:\n5+ years of relevant experience in data engineering or big data technologies.\nStrong problem-solving and analytical skills.\nExcellent communication and collaboration skills.\nAbility to work independently in a fast-paced environment.\nAdditional Details:\nWork Mode: Onsite (Hyderabad)\nEmployment Type: Full-time\nNotice Period: Immediate joiners highly preferred, candidates serving notice period.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Java', 'SCALA', 'Spark', 'Hive', 'Hadoop', 'Kafka']",2025-06-11 06:07:15
Data Engineer with GCP,Egen (Formerly SpringML),4 - 6 years,Not Disclosed,['Hyderabad( Nanakramguda )'],"Job Overview:\n\nWe are looking for a skilled and motivated Data Engineer with strong experience in Python programming and Google Cloud Platform (GCP) to join our data engineering team. The ideal candidate will be responsible for designing, developing, and maintaining robust and scalable ETL (Extract, Transform, Load) data pipelines. The role involves working with various GCP services, implementing data ingestion and transformation logic, and ensuring data quality and consistency across systems.",,,,"['GCP', 'Python', 'Azure Data Factory', 'Cloud Functions', 'IAM', 'Bigquery', 'Snowflake', 'Google Cloud Storage', 'SQL Server', 'Oracle', 'Data Integration']",2025-06-11 06:07:16
Senior Data Engineer,Parkar Global Technologies,6 - 10 years,Not Disclosed,['Pune'],"About Position:\nWe are looking for a Senior Data Engineer to play a key role in building, optimizing, and maintaining our Azure-based data platform, which supports IoT data processing, analytics, and AI/ML applications. As part of our Data Platform Team, you will design and develop scalable data pipelines, implement data governance frameworks, and ensure high-performance data processing to drive digital transformation across our business.\n\nResponsibilities:\nData Pipeline Development: Design, build, and maintain high-performance, scalable ETL/ELT pipelines using Azure Data Factory, Databricks, and ADLS.\nData Platform Enhancement: Contribute to the development and optimization of our Azure-based data platform, ensuring efficiency, reliability, and security.\nIoT & High-Volume Data Processing: Work with large-scale IoT and operational datasets, optimizing data ingestion, transformation, and storage.\nData Governance & Quality: Implement data governance best practices, ensuring data integrity, consistency, and compliance.\nPerformance Optimization: Improve query performance and storage efficiency for analytics and reporting use cases.\nCollaboration: Work closely with data scientists, architects, and business teams to ensure data availability and usability.\nInnovation & Automation: Identify opportunities for automation and process improvements, leveraging modern tools and technologies.\n\nRequirement:\n6+ years of experience in data engineering with a focus on Azure cloud technologies.\nStrong expertise in Azure Data Factory, Databricks, ADLS, and Power BI.\nProficiency in SQL, Python, and Spark for data processing and transformation.\nExperience with IoT data ingestion and processing, handling high-volume, real-time data streams.\nStrong understanding of data modeling, lakehouse architectures, and medallion frameworks.\nExperience in building and optimizing scalable ETL/ELT processes.\nKnowledge of data governance, security, and compliance frameworks.\nExperience with monitoring, logging, and performance tuning of data workflows.\nStrong problem-solving and analytical skills with a platform-first mindset.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Data Factory', 'Pyspark', 'Azure Databricks', 'Azure Data Lake', 'Azure Devops', 'SQL']",2025-06-11 06:07:18
Senior Data Engineer,Tredence,4 - 8 years,Not Disclosed,['Pune'],"About Tredence:\nTredence is a global data science solutions provider founded in 2013 by Shub Bhowmick, Sumit Mehra, and Shashank Dubey focused on solving the last-mile problem in AI. Headquartered in San Jose, California, the company embraces a vertical-first approach and an outcome-driven mindset to help clients win and accelerate value realization from their analytics investments. The aim is to bridge the gap between insight delivery and value realization by providing customers with a differentiated approach to data and analytics through tailor-made solutions. Tredence is 1,800-plus employees strong with offices in San Jose, Foster City, Chicago, London, Toranto, and Bangalore, with the largest companies in retail, CPG, hi-tech, telecom, healthcare, travel, and industrials as clients.",,,,"['azure databricks', 'python', 'azure data lake', 'rdbms', 'data management', 'performance tuning', 'analytical', 'data', 'pyspark', 'data warehousing', 'azure data factory', 'data engineering', 'tools', 'artificial intelligence', 'sql', 'plsql', 'unix shell scripting', 'spark', 'etl', 'communication skills', 'agile methodology']",2025-06-11 06:07:20
Software Developer,Tetcos,0 - 2 years,4-7.5 Lacs P.A.,['Bangalore/Bengaluru'],"Job Vacancy: Software Developer (5G and Wireless)\nTETCOS is looking to recruiting candidates on a for the role of Software Developer\nEligibility for applying:\nCandidates with the following educational background\nEducational\nB.E (CSE) from IIT, BITS, NIT, IIIT or other top universities\nS.S.L.C / Xth Std -- 80% and above\nP.U.C / XII Std -- 80% and above\nMust be good in C programing, data structures and algorithms.\nKnowledge of wireless protocols is a plus.\nPrior work on NetSim a plus\nProcess of Selection: Aptitude Test, followed by Technical and HR interviews.\nDesignation: Software Engineer\nJob Description:\nDevelopment of C libraries for protocols in the NetSim framework\nProtocol development in 5G, IOT, and Mobile Adhoc Networks\nEnhancement of the protocol stack, simulation kernel and post processing engine\nSimulation trace data analysis and machine learning\nCompensation: 5L to 8L per annum depending on skills and experience\nOur website www.tetcos.com has more information on our company and our products.\nInterested candidates can email their resumes with a short cover letter, to humanresources@tetcos.com",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['C#', 'Multi Treading', 'C Coding', 'Networking Protocols', 'Network Programming']",2025-06-11 06:07:21
Artificial Intelligence Engineer,Arocom It Solutions,2 - 5 years,6.5-15 Lacs P.A.,[],"Location: Any / Remote / Work From Home\nEmployment Type: Full-time\n\nJob Summary:\nWe are seeking skilled and innovative AI Engineers with a minimum 2-4 years of experience in developing and deploying AI solutions. The ideal candidate should have practical knowledge in AWS, Amazon Bedrock, LLMs, Claude AI, and Custom AI Development. You will contribute to the design and implementation of cutting-edge Generative AI (GenAI) and Mainstream AI applications across diverse business domains.\n\nThis is an excellent opportunity to work with emerging technologies in an agile, fast-paced environment with full ownership of AI engineering pipelines.\n\n\nKey Responsibilities:\nDevelop custom machine learning models and fine-tune foundation models for enterprise use\nDesign and implement LLM-based and Generative AI solutions tailored to client use cases\nWork with OpenAI, Anthropic, HuggingFace models and their APIs to build secure, scalable AI systems\nPerform prompt engineering and experiment with parameter tuning and context optimization\nBuild APIs and backend services to integrate AI models into product workflows\nCollaborate with product, data, and DevOps teams to deliver end-to-end AI-powered solutions\nEnsure best practices for AI model governance, security, performance, and ethical use\nStay current with advancements in LLMs, vector databases (e.g., Pinecone, FAISS), and GenAI tooling\nDocument architecture, experiments, and processes clearly and effectively\nParticipate in peer reviews, client meetings, and cross-functional planning discussions\n\nRequired Qualifications:\nMinimum 2-4 years of professional experience in AI/ML, with specific focus on LLMs and GenAI\nStrong experience working on AWS Bedrock, Lambda, and related services\nProficiency in Python, including experience with libraries like HuggingFace, LangChain, etc.\nFamiliarity with Anthropic, OpenAI, or other foundation models in production settings\nExperience with custom AI model development and model fine-tuning\nGood understanding of cloud-native AI deployments and API integrations\nAbility to apply prompt engineering techniques to optimize LLM responses\nExposure to vector databases and RAG pipelines\nStrong problem-solving, communication, and team collaboration skills\n\nPreferred Qualifications (STRONG PLUS):\nHands-on experience with LangChain, RAG pipelines, or agent frameworks\nFamiliarity with AWS Sagemaker, DynamoDB, Lambda, or other AI tooling in AWS\nKnowledge of Docker or Kubernetes for containerizing AI workloads\nUnderstanding of MLOps principles and tools (MLflow, SageMaker Pipelines, etc.)\nContributions to open-source AI projects or published GenAI applications\nAI/ML certifications\nFamiliarity with enterprise use cases in biotech, healthcare, or manufacturing\n\nWhat We Offer:\nRemote work option\nCompetitive salary package\nExciting projects in the field of LLMs, AI, and cloud-native development\nContinuous learning opportunities in Generative AI and cloud AI tools\nA collaborative and fast-paced environment with a forward-thinking team\nAccess to state-of-the-art tools and flexible project ownership\n\nHow to Apply:\nPlease submit your resume and cover letter outlining your relevant experience and why you'd be a great fit for Arocom. We differentiate candidates based on professionalism.\nWe admire the new age methods like a video resume. If you have one please share the URL along with your resume.\nYour privacy is important to us, so we will not be contacting candidates by phone. If your application is selected, we will email you a link to schedule your interview at your convenient time. Please check your emails regularly, including your SPAM folder.\n\nArocom encourages work from home and has a Bring Your Own Device (BYOD) policy.\nEmployees / Consultants working from home are expected to use their personal\nlaptops/desktops for work-related tasks.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Freelance/Homebased","['Aws Bedrock', 'Generative Ai', 'Artificial Intelligence', 'Machine Learning', 'Data Science', 'Problem Solving', 'Deep Learning', 'Agentic Ai', 'Communication Skills', 'MLOPS', 'Statistical Modeling', 'Aws Sagemaker', 'Python']",2025-06-11 06:07:23
Test Engineer - L3,Wipro,3 - 5 years,Not Disclosed,['Chennai'],"Role Purpose\nThe purpose of this role is to prepare test cases and perform testing of the product/ platform/ solution to be deployed at a client end and ensure its meet 100% quality assurance parameters.\n\n\n\nDo\nInstrumental in understanding the test requirements and test case design of the product\nAuthoring test planning with appropriate knowledge on business requirements and corresponding testable requirements\nImplementation of Wipro's way of testing using Model based testing and achieving efficient way of test generation\nEnsuring the test cases are peer reviewed and achieving less rework\nWork with development team to identify and capture test cases, ensure version\nSetting the criteria, parameters, scope/out-scope of testing and involve in UAT (User Acceptance Testing)\nAutomate the test life cycle process at the appropriate stages through vb macros, scheduling, GUI automation etc\nTo design and execute the automation framework and reporting\nDevelop and automate tests for software validation by setting up of test environments, designing test plans, developing test cases/scenarios/usage cases, and executing these cases\nEnsure the test defects raised are as per the norm defined for project / program / account with clear description and replication patterns\nDetect bug issues and prepare file defect reports and report test progress\nNo instances of rejection / slippage of delivered work items and they are within the Wipro / Customer SLA's and norms\nDesign and timely release of test status dashboard at the end of every cycle test execution to the stake holders\nProviding feedback on usability and serviceability, trace the result to quality risk and report it to concerned stakeholders\n\n\n\nStatus Reporting and Customer Focus on an ongoing basis with respect to testing and its execution\nEnsure good quality of interaction with customer w.r.t. e-mail content, fault report tracking, voice calls, business etiquette etc\nOn time deliveries - WSRs, Test execution report and relevant dashboard updates in Test management repository\nUpdates of accurate efforts in eCube, TMS and other project related trackers\nTimely Response to customer requests and no instances of complaints either internally or externally\n\nNoPerformance ParameterMeasure1Understanding the test requirements and test case design of the productEnsure error free testing solutions, minimum process exceptions, 100% SLA compliance, # of automation done using VB, macros2Execute test cases and reportingTesting efficiency & quality, On-Time Delivery, Troubleshoot queries within TAT, CSAT score\n\nMandatory Skills: AI assisted RPA.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Test Engineering', 'RPA', 'user acceptance testing', 'test cases', 'test planning', 'gui automation', 'test case design', 'artificial intelligence']",2025-06-11 06:07:25
Artificial Intelligence Engineer,Qiskitq Technology,5 - 10 years,12-18 Lacs P.A.,[],"Key Responsibilities:\n\nDesign, develop, and implement AI-driven chatbots and IVAs to streamline customer interactions.\nWork on conversational AI platforms to create a seamless customer experience, with a focus on natural language processing (NLP), intent recognition, and sentiment analysis.\nCollaborate with cross-functional teams, including product managers and customer support, to translate business requirements into technical solutions.\nBuild, train, and fine-tune machine learning models to enhance IVA capabilities and ensure high accuracy in responses.\nContinuously optimize models based on user feedback and data-driven insights to improve performance.\nIntegrate IVA/chat solutions with internal systems such as CRM and backend databases.\nEnsure scalability, robustness, and security of IVA/chat solutions in compliance with industry standards.\nParticipate in code reviews, testing, and deployment of AI solutions to ensure high quality and reliability.\nRequired Skills and Qualifications:\n\nBachelors or master’s degree in computer science, Data Science, AI/ML, or a related field.\n3+ years of experience in developing IVA/chatbots, conversational AI, or similar AI-driven systems using AWS services\nExpert in using Amazon Lex, Amazon Polly, AWS lambda, AWS connect\nAWS Bedrock experience with Sage maker will have added advantage\nSolid understanding of API integration and experience working with RESTful services.\nStrong problem-solving skills, attention to detail, and ability to work independently and in a team.\nExcellent communication skills in English, both written and verbal.\nPreferred Qualifications:\n\nExperience in financial services or fintech projects.\nKnowledge of data security best practices and compliance requirements in the financial sector.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['Aws Bedrock', 'Aws Connect', 'Aws Lambda', 'Aws Sagemaker', 'Amazon Lex', 'Aws Cloudformation', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-11 06:07:26
Technology Lead,Infosys,5 - 8 years,Not Disclosed,['Bengaluru'],"Responsibilities\nJob Responsibilities:\n* Lead the development of Gen AI solutions, including design, implementation, and deployment of AI models and systems\n* Collaborate with cross-functional teams to identify business problems and develop AI-powered solutions to drive growth and efficiency\n* Design and implement scalable and efficient AI solutions, leveraging technologies such as LangChain, Agentic AI, RAG, Event driven architecture using Kafka etc.\n* Develop and maintain large-scale AI systems, ensuring high performance, reliability, and security\n* Lead and mentor a team of AI developers, providing guidance and expertise to ensure high-quality deliverables\n* Stay up-to-date with the latest advancements in Gen AI, Prompt Engineering, and related technologies, applying this knowledge to drive innovation and improvement\n* Develop and maintain technical documentation, including architecture diagrams, design documents, and technical guides\n* Participate in code reviews, ensuring high-quality code and adherence to coding standards and best practices\nTechnical and Professional Requirements:\nPreferred Qualifications:* Experience with Agentic Frameworks such LangGraph, AutoGen, CrewAI* Experience with cloud-based AI platforms, such as AWS or Azure* Knowledge of containerization technologies, such as Docker* Familiarity with agile development methodologies, such as Scrum or Kanban* Experience with AI-related tools and frameworks, such as TensorFlow or PyTorch* Strong understanding of software design patterns, principles, and best practices* Experience with DevOps practices, including continuous integration and continuous deployment (CI/CD)* Certification in AI, machine learning, or related fields, such as Certified Data Scientist or Certified AI Engineer\nPreferred Skills:\nTechnology->Artificial Intelligence->Artificial Intelligence - ALL\nTechnology->Machine Learning->GoLearn\nTechnology->Machine Learning->Generative AI\nAdditional Responsibilities:\nRequired Qualifications:* Bachelor's or Master's degree in Computer Science, Engineering, or related field (B.E/B.Tech/M.E/M.Tech/MCA)* At least 5-8 years of experience in software development, with a minimum of 2 years of experience in Gen AI* Strong proficiency in LangChain, Python, Gen AI, Agentic AI, and Prompt Engineering* Excellent communication, teamwork, problem-solving, and leadership skillsTech Skill: LangChain, Python, Fast/Flask API, Gen AI, Agentic AI, Advanced Prompt Engineering, Machine Learning, SQL, KafkaSoft Skill: Communication, Team Work, Problem Solving\nEducational Requirements\nBachelor of Engineering\nService Line\nInformation Systems\n* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['AI models', 'coding', 'Kanban', 'Azure', 'PyTorch', 'Docker', 'Kafka', 'CI/CD', 'Scrum', 'machine learning', 'AWS', 'TensorFlow']",2025-06-11 06:07:28
Staff Engineer (Generative-AI),Nagarro,7 - 10 years,Not Disclosed,['India'],"We're Nagarro.\n\nWe are a Digital Product Engineering company that is scaling in a big way! We build products, services, and experiences that inspire, excite, and delight. We work at scale across all devices and digital mediums, and our people exist everywhere in the world (18000+ experts across 38 countries, to be exact). Our work culture is dynamic and non-hierarchical. We are looking for great new colleagues. That's where you come in!\n\nREQUIREMENTS:\nTotal experience 7+ Years.\nDeep understanding of Generative AI fundamentals and transformer-based architectures.\nStrong experience in Cloud Architecture (e.g., AWS, Azure, GCP) for deploying scalable AI systems.\nProven experience with BERT, GPT, LLaMA, and similar LLMs.\nStrong hands-on experience in prompt engineering and RAG techniques.\nExperience in fine-tuning and deploying models using frameworks like Hugging Face Transformers, LangChain, or equivalent.\nFamiliarity with multi-agent AI systems and collaborative model workflows.\nProficient in Python and machine learning libraries (e.g., PyTorch, TensorFlow).\nStrong problem-solving skills and a passion for AI innovation and ethical development.\nExperience integrating models into enterprise platforms and APIs.\nUnderstanding of ML Ops practices and CI/CD pipelines for AI deployment.\nBackground in Natural Language Processing (NLP) and Knowledge Engineering.\nExcellent communication skills, with the ability to articulate solutions effectively.\n\nRESPONSIBILITIES:\nUnderstanding the clients business use cases and technical requirements and be able to convert them into technical design which elegantly meets the requirements.\nMapping decisions with requirements and be able to translate the same to developers.\nIdentifying different solutions and being able to narrow down the best option that meets the clients requirements.\nDefining guidelines and benchmarks for NFR considerations during project implementation\nWriting and reviewing design document explaining overall architecture, framework, and high-level design of the application for the developers\nReviewing architecture and design on various aspects like extensibility, scalability, security, design patterns, user experience, NFRs, etc., and ensure that all relevant best practices are followed.\nDeveloping and designing the overall solution for defined functional and non-functional requirements; and defining technologies, patterns, and frameworks to materialize it\nUnderstanding and relating technology integration scenarios and applying these learnings in projects\nResolving issues that are raised during code/review, through exhaustive systematic analysis of the root cause, and being able to justify the decision taken.\nCarrying out POCs to make sure that suggested design/technologies meet the requirements.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Generative Ai', 'Cloud Architecture', 'Python', 'Natural Language Processing', 'Transformers', 'Bert', 'Machine Learning', 'Deep Learning']",2025-06-11 06:07:29
Gen AI Lead,Wipro,6 - 11 years,Not Disclosed,"['Chennai', 'Coimbatore', 'Bengaluru']","Mandatory Skills\n\nGen AI, LLM, ML/DL/NLP, RAG, Lang chain, Llama, Hugging Face, Python, Tensorflow, Pytorch, Django, Vector DB,\nPreferred Skills\n\nAzure/AWS, MLOps, Kubernetes, GitHub/Bitbucket, GPT-4, Banking exposure\nJob Description / Roles",,,,"['Gen AI', 'RAG', 'Hugging Face', 'LLM', 'Python', 'Tensorflow', 'Pytorch', 'Lang chain', 'Llama', 'Vector DB', 'Django', 'ML/DL/NLP']",2025-06-11 06:07:31
Python Developer Lead {ENG - Infosys @ Pan India - G },Infosys,4 - 9 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Process->Testing processes->Test Automation Process,Technology->Machine Learning->Python\n\nPreferred Skills: Process->Testing processes->Test Automation Process\nTechnology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BE,BSc,BTech Role & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Django Framework', 'Python Development', 'Python']",2025-06-11 06:07:33
Azure Data Engineers For Pune IT Companies urgent,International IT Companies,3 - 8 years,9-16 Lacs P.A.,['Pune'],"We are looking for a skilled Azure Data Engineer to design, develop, optimize data pipelines for following\n1, SQL+ETL+AZURE+Python+Pyspark+Databricks\n2, SQL+ADF+ Azure\n3, SQL+Python+Pyspark\n- Strong proficiency in SQL for data manipulation querying\n\nRequired Candidate profile\n- Python and PySpark for data engineering tasks.\n- Exp with Databricks for big data processing analytics.\n- Knowledge of data modeling, warehousing, governance.\n- CI/CD pipelines for data deployment.\n\nPerks and benefits\nPerks and Benefits",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure', 'PySpark', 'SQL', 'ETL', 'Python', 'Data Transformation', 'Business Intelligence', 'ADF', 'Data Engineering', 'Data Pipelines', 'Big Data', 'AI', 'Machine Learning', 'Analytics', 'Cloud Computing', 'Data Security', 'Databricks', 'Data Governance']",2025-06-11 06:07:35
AI Engineer,HCLTech,10 - 14 years,Not Disclosed,['Noida'],"Seniority: Senior\nDescription & Requirements\nPosition Summary\nThe Senior AI Engineer with GenAI expertise is responsible for developing advanced technical solutions, integrating cutting-edge generative AI technologies. This role requires a deep understanding of modern technical and cloud-native practices, AI, DevOps, and machine learning technologies, particularly in generative models. You will support a wide range of customers through the Ideation to MVP journey, showcasing leadership and decision-making abilities while tackling complex challenges.\nKey Responsibilities\nTechnical & Engineering Leadership\nDevelop solutions leveraging GenAI technologies, integrating advanced AI capabilities into cloud-native architectures to enhance system functionality and scalability.\nLead the design and implementation of GenAI-driven applications, ensuring seamless integration with microservices and container-based environments.\nCreate solutions that fully leverage the capabilities of modern microservice and container-based environments running in public, private, and hybrid clouds.\nContribute to HCL thought leadership across the Cloud Native domain with an expert understanding of open-source technologies (e.g., Kubernetes/CNCF) and partner technologies.\nCollaborate on joint technical projects with partners, including Google, Microsoft, AWS, IBM, Red Hat, Intel, Cisco, and Dell/VMware.\nService Delivery\nEngineer innovative GenAI solutions from ideation to MVP, ensuring high performance and reliability within cloud-native frameworks.\nOptimize AI models for deployment in cloud environments, balancing efficiency and effectiveness to meet client requirements and industry standards.\nAssess existing complex solutions and recommend appropriate technical treatments to transform applications with cloud-native/12-factor characteristics.\nRefactor existing solutions to implement a microservices-based architecture.\nInnovation & Initiative\nDrive the adoption of cutting-edge GenAI technologies within cloud-native projects, spearheading initiatives that push the boundaries of AI integration in cloud services.\nEngage in technical innovation and support HCLs position as an industry leader.\nAuthor whitepapers, blogs, and speak at industry events.\nMaintain hands-on technical credibility, stay ahead of industry trends, and mentor others.\nClient Relationships\nProvide expert guidance to clients on incorporating GenAI and machine learning into their cloud-native systems, ensuring best practices and strategic alignment with business goals.\nConduct workshops and briefings to educate clients on the benefits and applications of GenAI, establishing strong, trust-based relationships.\nPerform a trusted advisor role, contributing to technical projects (PoCs and MVPs) with a strong focus on technical excellence and on-time delivery.\nMandatory Skills & Experience\nA passionate developer with 10+ years of experience in Java, Python, Node.js, and Spring programming, comfortable working as part of a paired/balanced team.\nExtensive experience in software development, with significant exposure to AI/ML technologies.\nExpertise in GenAI frameworks: Proficient in using GenAI frameworks and libraries such as LangChain, OpenAI API, Gemini, and Hugging Face Transformers.\nPrompt engineering: Experience in designing and optimizing prompts for various AI models to achieve desired outputs and improve model performance.\nStrong understanding of NLP techniques and tools, including tokenization, embeddings, transformers, and language models.\nProven experience developing complex solutions that leverage cloud-native technologiesfeaturing container-based, microservices-based approaches; based on applying 12-factor principles to application engineering.\nExemplary verbal and written communication skills (English).\nPositive and solution-oriented mindset.\nSolid experience delivering Agile and Scrum projects in a Jira-based project management environment.\nProven leadership skills and the ability to inspire and manage teams.\nDesired Skills & Experience\nMachine Learning Operations (MLOps): Experience in deploying, monitoring, and maintaining AI models in production environments using MLOps practices.\nData engineering for AI: Skilled in data preprocessing, feature engineering, and creating pipelines to feed AI models with high-quality data.\nAI model fine-tuning: Proficiency in fine-tuning pre-trained models on specific datasets to improve performance for specialized tasks.\nAI ethics and bias mitigation: Knowledgeable about ethical considerations in AI and experienced in implementing strategies to mitigate bias in AI models.\nKnowledgeable about vector databases, LLMs, and SMLs, and integrating with such models.\nProficient with Kubernetes and other cloud-native technologies, including experience with commercial Kubernetes distributions (e.g., Red Hat OpenShift, VMware Tanzu, Google Anthos, Azure AKS, Amazon EKS, Google GKE).\nDeep understanding of core practices including DevOps, SRE, Agile, Scrum, XP, Domain-Driven Design, and familiarity with the CNCF open-source community.\nRecognized with multiple cloud and technical certifications at a professional level, ideally including AI/ML specializations from providers like Google, Microsoft, AWS, Linux Foundation, IBM, or Red Hat.\nVerifiable Certification\nAt least one recognized cloud professional / developer certification (AWS/Google/Microsoft)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI engineering', 'VMware', 'Java', 'Azure', 'Data engineering', 'AI models', 'Node.js', 'NLP', 'Azure AKS', 'Machine Learning Operations', 'AWS', 'Kubernetes', 'Python']",2025-06-11 06:07:36
Principal AI Architect,Wabtec,10 - 15 years,Not Disclosed,['Bengaluru'],"How will you make a difference?\n\nWe are seeking a collaborative and highly motivated Principal AI Architect to lead our AI team, drive innovation, and enhance customer experiences through impactful artificial intelligence solutions. As a member of the Wabtec IT Data & Analytics (DnA) Team, you will be responsible for:\n\nProviding strategic leadership and direction in the development, articulation and implementation, of a comprehensive AI/ML/ Data Transformation Roadmap for Wabtec aligned with the overall business objectives.\nWorking with other AI champions in Wabtec evaluating AI tools/ technologies/ frameworks, champion adoption in different projects and demonstrate value for business and customers.\nActively collaborating with various stakeholders to align AI initiatives in Cloud Computing environments (e.g., AWS, Azure, OCI) with business goals.\nProviding technical oversight on AI projects to drive performance output to meet KPI metrics in Productivity and Quality.\nServing as contact and interface with external partners and industry leaders for collaborations in AI/LLM/ Generative AI.\nArchitecting and deploying scalable AI solutions that integrate seamlessly with existing business and IT infrastructure.\nDesign and architect AI as a service, to enable collaboration btw multiple teams in delivering AI solutions\nOptimizing state-of-the-art algorithms in distributed environments\nCreate clear and concise communications/recommendations for senior leadership review related to AI strategic business plans and initiatives.\nStaying abreast of advancements in AI, machine learning, and data science to continuously innovate and improve solutions and bring the external best practices for adoption in Wabtec\nImplementing best practices for AI designing, testing, deployment, and maintenance\nDiving deep into complex business problems and immerse yourself in Wabtec data & outcomes.\nMentoring a team of data scientists, fostering growth and performance.\nDeveloping AI governance frameworks with ethical AI practices and ensuring compliance with data protection regulations and ensuring responsible AI development.\n\nWhat do we want to know about you?\n\nYou must have:\nThe minimum qualifications for this role include:\n\nPh.D., M.S., or Bachelor's degree in Statistics, Machine Learning, Operations Research, Computer Science, Economics, or a related quantitative field\n5+ years of experience developing and supporting AI products in a production environment with 12+ years of proven relevant experience\n8+ years of experience managing and leading data science teams initiatives at enterprise level\nProfound knowledge of modern AI and Generative AI technologies\nExtensive experience in designing, implementing, and maintaining AI systems\nEnd-to-end expertise in AI/ML project lifecycle, from conception to large-scale production deployment\nProven track record as an Architect with cloud computing environments (e.g., AWS, Azure, OCI) and distributed computing platforms, including containerized deployments using technologies such as Amazon EKS (Elastic Kubernetes Service)\nExpertise with Hands-On experience into Python, AWS AI tech-stack (Bedrock Services, Foundation models, Textract, Kendra, Knowledge Bases, Guard rails, Agents etc.), ML Flow, Image Processing, NLP/Deep Learning, PyTorch /TensorFlow, LLMs integration with applications.\n\nPreferred qualifications for this role include:\nProven track record in building and leading high-performance AI teams, with expertise in hiring, coaching, and developing engineering leaders, data scientists, and ML engineers\nDemonstrated ability to align team vision with strategic business goals, driving impactful outcomes across complex product suites for diverse, global customers\nStrong stakeholder management skills, adept at influencing and unifying cross-functional teams to achieve successful project outcomes\nExtensive hands-on experience with enterprise-level Python development, PyData stack, Big Data technologies, and machine learning model deployment at scale\nProficiency in cutting-edge AI technologies, including generative AI, open-source frameworks, and third-party solutions (e.g., OpenAI)\nMastery of data science infrastructure and tools, including code versioning (Git), containerization (Docker), and modern AI/ML tech stacks\nPreferred: AWS with AWS AI services.\n\nWe would love it if you had:\n\nFluent with experimental design and the ability to identify, compute and validate the appropriate metrics to measure success\nDemonstrated success working in a highly collaborative technical environment (e.g., code sharing, using revision control, contributing to team discussions/workshops, and collaborative documentation)\nPassion and aptitude for turning complex business problems into concrete hypotheses that can be answered through rigorous data analysis and experimentation\nDeep expertise in analytical storytelling and stellar communications skills\nDemonstrated success mentoring junior teammates & helping develop peers\n\nWhat will your typical day look like?\n\nStakeholder Engagement: Collaborate with our Internal stakeholders to understand their needs, update on a specific project progress, and align our AI initiatives with business goals.\nUse Generative AI and machine learning techniques and build LLM Models & fine-tuning, Image processing, NLP, model integration with new/existing applications, and improve model performance/accuracy along with cost effective solutions.\nSupport AI Team: Guide and mentor the AI team, resolving technical issues and provide suggestions.\nReporting & Strategy: Generate and present reports to senior leadership, develop strategic insights, and stay updated on industry trends.\nBuilding AI roadmap for Wabtec and discussion with senior leadership\nTraining, Development & Compliance: Organize training sessions, manage resources efficiently, ensure data accuracy, security, and compliance with best practices.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Cloud Architecture', 'Eks', 'Machine Learning', 'Aiml']",2025-06-11 06:07:38
Java Tech Lead,Applied Materials,7 - 12 years,Not Disclosed,['Bengaluru'],"Who We Are\n\nApplied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips- the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world- like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of""science and engineering to make possible""the next generations of technology, join us to Make Possible® a Better Future.\n\nWhat We Offer\n\nLocation:\nBangalore,IND\nAt Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. Were committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits .\n\nYoull also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers.""We empower our team to push the boundaries of what is possible""”while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied.\n\n \n\nJob TitleJava-Technical Lead \n \n\nLocationITPL Bangalore  \n As a Tech lead your primary responsibility will be to participate in the creation of new products and enhancements to existing products from concept to launch as part of a cross functional team. In this role you will utilize your experience to provide Software solutions which involves System understanding of the Product. You will also be required to work with various interfaces to ensure the completeness of the solution. \n  \n \n\nKey Responsibilities \n\n Execute the design, analysis, or evaluation of assigned projects using sound engineering principles and adhering to business standards, practices, procedures, and product / program requirements \n\n Design & code a variety of complex software features with adequate documentation \n\n Write automation for new/existing features. \n\n Customer Support & troubleshoot/fix a variety of difficult software problems. Proactively communicate on development status & delays in agreed upon timelines \n\n Interface with global teams for requirements analysis and schedule. \n\n Interface with external customers regarding software issues. \n\n Be willing to travel to onsite locations for Short Term Assignments like Feature Integrations & Version Installations. \n\n  \n \n\nQualification and  \n\n Bachelors Degree / masters degree in engineering with Computer Science/Electronics/Electrical background and 7-14 years of experience \n\n Minimum of 6 years experience in software development with exposure to maintenance, continuous integration & releases \n\n Minimum of 3 years experience in core product software development \n\n Strong Object Oriented Design & Programming Experience \n\n Professional experience of Core Java Technologies (Design Pattern/Multi-threading/Data Structures/Algorithm) \n\n Exposure to Agile methodologies and tool chain (like JIRA) \n\n Has knowledge of best practices and how own area integrates with others \n\n\nAdditional Information\n\nTime Type:\nFull time\n\nEmployee Type:\nAssignee / Regular\n\nTravel:\nYes, 20% of the Time\n\nRelocation Eligible:\nYes\nApplied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software development', 'java', 'oops', 'data structures', 'multithreading', 'algorithms', 'continuous integration', 'java technologies', 'hibernate', 'artificial intelligence', 'iot', 'spring', 'spring boot', 'computer science', 'design patterns', 'troubleshooting', 'agile', 'agile methodology', 'jira']",2025-06-11 06:07:40
"Senior Team Lead, Software Applications Development","NTT DATA, Inc.",3 - 7 years,Not Disclosed,['Bengaluru'],"Knowledge and application:\nApplies professional knowledge and provides direction to employees according to established policies and management guidance.\nProblem solving:\nWorks on issues requiring the analysis of data and application of sophisticated problem-solving techniques.\nExercises judgment and interpretation to help define procedures and policies to determine appropriate action.\nInteraction:\nInteraction with subordinates/peers requires interpreting and explaining information to audiences not familiar with the subject.\nGains cooperation of others, conducting presentations of technical information concerning specific projects or programs.\nImpact:\nMistakes or failure to achieve results will cause delays in schedules, typically against a monthly plan.\nDevelops and manages routine operational plans.\nAccountability:\nAdministers company policies that directly affect subordinate employees.\nTakes actions to monitor and manage costs related to a section.\nWorkplace type:\nHybrid Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Software Applications Development', 'c#', 'project management', 'program management', 'business analysis', 'artificial intelligence', 'sql server', 'application development', 'sql', 'plsql', 'strategy consulting', 'application management', 'technology consulting']",2025-06-11 06:07:41
Virtual Walk-in | Telesales | Naukri.com,Info Edge,0 - 5 years,Not Disclosed,"['Noida', 'Pune']","Dear [Candidate Name],\n\nYou have been invited for a virtual walk-in for Naukri.com. Please find below the details.\n\nDate - 11th June' 25 (Wednesday)\nTime - 1 PM\n\nLink - https://teams.microsoft.com/l/meetup-join/19:meeting_ZTYwM2U5ZGYtYzk1ZC00YWRkLTgwYzAtZjkzY2I1Y2FkYWE5@thread.v2/0?context={""Tid"":""0ee9b5f9-52b3-4351-8198-c4804cd66b68"",""Oid"":""2ba02286-eee6-4b0e-a395-b8757bd4c96d""}",,,,"['sales', 'inside sales', 'Lead Generation', 'Credit Card Sales', 'telesales', 'outbound sales', 'telecalling', 'bpo sales', 'Online Sales', 'Business Development', 'Telemarketing']",2025-06-11 06:07:43
Java Tech Lead,Applied Materials,5 - 8 years,Not Disclosed,['Bengaluru'],"Who We Are\n\nApplied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips- the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world- like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of""science and engineering to make possible""the next generations of technology, join us to Make Possible® a Better Future.\n\nWhat We Offer\n\nLocation:\nBangalore,IND\nAt Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. Were committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits .\n\nYoull also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers.""We empower our team to push the boundaries of what is possible""”while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied.\n\nKey Responsibilities\nDevelops code for moderately difficult software projects. Design and implement bug fixes.\nDesigns moderately difficult software projects.\nDevelops software documentation.\nTroubleshoots a variety of moderately difficult software problems. Performs software tests on code and enhancements. Defines software specifications.\nInterfaces with external customers regarding software issues\nInterfaces with internal customers for requirements analysis and schedule.\nCompiles data for regularly scheduled or special reports, analysis and statements.\n\n\nFunctional Knowledge\nDemonstrates expanded conceptual knowledge in own discipline and broadens capabilities\n\n\nBusiness Expertise\nUnderstands key business drivers; uses this understanding to accomplish own work\n\n\nLeadership\nNo supervisory responsibilities but provides informal guidance to new team members\n\n\nProblem Solving\nSolves problems in straightforward situations; analyzes possible solutions using technical experience and judgment and precedents\n\n\nImpact\nImpacts quality of own work and the work of others on the team; works within guidelines and policies\n\n\nInterpersonal Skills\nExplains complex information to others in straightforward situations\n\n\nAdditional Information\n\nTime Type:\nFull time\n\nEmployee Type:\nAssignee / Regular\n\nTravel:\nNo\n\nRelocation Eligible:\nYes\nApplied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['project management', 'artificial intelligence', 'iot', 'java', 'sap abap', 'data dictionary', 'budgeting', 'sql', 'spring', 'estimation', 'alv reports', 'construction', 'smartforms', 'oo abap', 'project planning']",2025-06-11 06:07:45
Java Tech Lead,Applied Materials,6 - 11 years,Not Disclosed,['Bengaluru'],"Who We Are\n\nApplied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips- the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world- like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of""science and engineering to make possible""the next generations of technology, join us to Make Possible® a Better Future.\n\nWhat We Offer\n\nLocation:\nBangalore,IND\nAt Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. Were committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits .\n\nYoull also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers.""We empower our team to push the boundaries of what is possible""”while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied.\n\nAbout Applied\n\nApplied Materials is the leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. Our expertise in modifying materials at atomic levels and on an industrial scale enables customers to transform possibilities into reality. At Applied Materials, our innovations make possible the technology shaping the future.\n\nKey Responsibilities\nDevelops code and documentation for a variety of difficult software projects, and design and implement bug fixes.\nDesigns a variety of difficult software projects.\nDefines software specifications.\nInterfaces with internal customers for requirements analysis and schedule.\nTroubleshoots a variety of difficult software problems. Performs software tests on code and enhancements.\nInterfaces with external customers regarding software issues.\nCompiles data for regularly scheduled or special reports, analysis and statements.\n\n\nRelevant Work experience 6- 14 years\n\nQualifications Information Technology, Engineering, Computer Science\n\nWork LocationITPL, Whitefield - Bangalore (Onsite)\n\nFunctional Knowledge\nDemonstrates conceptual and practical expertise in own discipline and basic knowledge of related disciplines\n\n\nBusiness Expertise\nHas knowledge of best practices and how own area integrates with others; is aware of the competition and the factors that differentiate them in the market\n\n\nLeadership\nActs as a resource for colleagues with less experience; may lead small projects with manageable risks and resource requirements\n\n\nProblem Solving\nSolves complex problems; takes a new perspective on existing solutions; exercises judgment based on the analysis of multiple sources of information\n\n\nImpact\nImpacts a range of customer, operational, project or service activities within own team and other related teams; works within broad guidelines and policies\n\n\nInterpersonal Skills\nExplains difficult or sensitive information; works to build consensus.\n\n\nApplied Materials is committed to diversity in its workforce including Equal Employment Opportunity for Minorities, Females, Protected Veterans and Individuals with Disabilities.\n\nAdditional Information\n\nTime Type:\nFull time\n\nEmployee Type:\nAssignee / Regular\n\nTravel:\nYes, 20% of the Time\n\nRelocation Eligible:\nYes\nApplied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['information technology', 'artificial intelligence', 'iot', 'java', 'computer science', 'project management', 'data dictionary', 'budgeting', 'alv reports', 'construction', 'smartforms', 'sap abap', 'project planning', 'oo abap']",2025-06-11 06:07:47
Security Managed Services Engineer (L2),"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Security Managed Services Engineer (L2) is a developing engineering role, responsible for providing a managed service to clients to ensure that their Security Infrastructures and systems remain operational.\n\nThrough the proactive monitoring, identifying, investigating, and resolving of technical incidents and problems, this role is able to restore service to clients.\n\nThe primary objective of this role is to proactively review client requests or tickets and apply technical/process knowledge to resolve them without breaching service level agreement (SLA) and focuses on second-line support for incidents and requests with a medium level of complexity.\n\nThe Security Managed Services Engineer (L2) may also contribute to support on project work as and when required.\nWhat you'll be doing\nKey Responsibilities:\nMin 5 Years exp\nCollaborate with Company to address challenging issues in cyber, analytics, machine learning, optimization, and computer networking to research solutions.\nPropose new research projects to tackle complex cyber, analytics, machine learning, optimization, and networking problems.\nPossess expertise in comprehending advanced persistent threats, emerging threats, and malware within a corporate environment.\nUnderstand attacks, attack vectors, and kill chain methodology.\nDemonstrate proficiency in working with big data and executing complex queries across multiple platforms.\nExhibit a strong grasp of malware analysis, threat taxonomy, and threat indicators.\nCompetently engage with various security technologies.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCTIA/CEH/CSA certification in must.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Security engineering', 'malware analysis', 'networking', 'Security monitoring', 'Security analysis']",2025-06-11 06:07:49
Inside Sales || Jeevansathi.com || Noida,Info Edge,0 - 5 years,4.5-6 Lacs P.A. (Including Variable: 30%),[],"About Info Edge\nInfoEdges mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['Sales', 'Outbound', 'Upselling', 'Customer Support', 'Cross Selling', 'Telesales', 'Inside Sales', 'Business Development', 'Inbound', 'Customer Acquisition']",2025-06-11 06:07:50
Digital Solution Architect Lead Advisor,"NTT DATA, Inc.",4 - 9 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nLead AI/ML/GenAI-driven solution design and integration.\nArchitect intelligent workflows using RPA, low-code/no-code platforms, and cognitive services.\nIdentify opportunities for automation and transformation in client environments.\nDefine governance, ethics, and performance monitoring for AI implementations.\n\n\nRequired\n\nSkills:\n\nDeep knowledge of AI/ML frameworks, GenAI models, and automation tools (UiPath, Power Automate, etc.).\nExperience in business process optimization and intelligent workflows.\nAbility to translate business needs into AI use cases and value.\nFamiliarity with ethical AI, MLOps, and prompt engineering.\nExpertise in technical solutions writing and presenting using tools such as Word, PowerPoint, Excel, Visio etc.\nHigh level of executive presence to be able to articulate the solutions to CXO level executives.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['artificial intelligence', 'automation tools', 'visio', 'uipath', 'ml', 'cognitive services', 'c#', 'css', 'python', 'business process optimization', 'performance monitoring', 'presentation skills', 'microsoft azure', 'javascript', 'sql server', 'solution design', 'asp.net', '.net', 'html', 'web api', 'wcf']",2025-06-11 06:07:52
Senior Software Applications Development Engineer,"NTT DATA, Inc.",4 - 6 years,Not Disclosed,['Hyderabad'],"Your day at NTT DATA\nThis role is for fullstack developer\nYrs of exp 4 6\nClient Name Gainwell\n\n\n\nWhat youll be doing\n\nDesign, Develop, and Operate solutions for a cloud computing platform with baked in attributes of security, auditability and observability. Define and build value-add services on the platform using cloud-native principles. Expert level proficiency with at least one programming language such as Java or NodeJS. Experience in writing automated tests using industry frameworks. Experience in programming frameworks (e.g. Spring Boot, Spring Cloud, 15 factor app principles) . Experience in Kubernetes is essential. Demonstrated knowledge of software applications and technical processes within a technical discipline (e.g., cloud, artificial intelligence, machine learning, mobile, etc.) with cloud native data management capabilities (e.g. relational db, no-sql db, graph db and object storage). Experince in developing high performance RESTful and GraphQL APIs. Experience building custom annotations in Springboot to enable better tooling, code analysis, and code generation to standardize API invocation, OAuth token generation etc.Are familiar with modern development stack, e.g. Kotlin or Java 8+, TypeScript, React or Angular 2+, GraphQL, PostgreSQL Worked with source control like Git Understanding of CI/CD, rapid delivery on production Experience with one of the cloud platform like AWS, Azure etc. Understanding different Agile methodologies Ability to write quality unit and endtoend tests; debug and optimize existing and new code. Yrs of exp 4 6Client Name Gainwell",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Software Applications Development', 'REST', 'GraphQL', 'APIs', 'Spring Boot', 'Spring Cloud', 'Kubernetes']",2025-06-11 06:07:54
Applied Scientist I at Fintech Platform,Talent 24/7,2 - 4 years,22.5-27.5 Lacs P.A.,[],"Preferred candidate profile\nProficient in Java, C++, Python, or similar languages.\nExperience with SQL and relational databases (e.g., Oracle, Data Warehouse).\nHands-on in building ML models or algorithms for real-world use.\nBackground in ML, deep learning, NLP, computer vision, or data science.\nKnowledge of deep learning architecture, training optimization, and model pruning.",Industry Type: FinTech / Payments,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Computer Vision', 'Python']",2025-06-11 06:07:55
AI Lead - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\nThe purpose of this role is to develop minimum viable product (MVP) and comprehensive AI solutions that meet and exceed clients expectations and add value to business.\nDo\nManage the product/ solution development using the desired AI techniques\nLead development and implementation of custom solutions through thoughtful use of modern AI technology\nReview and evaluate the use cases and decide whether a product can be developed to add business value\nCreate the overall product development strategy and integrating with the larger interfaces\nCreate AI models and framework and implement them to cater to a business problem\nDraft the desired user Interface and create AI models as per business problem\nAnalyze technology environment and client requirements to define product solutions using AI framework/ architecture\nImplement the necessary security features as per products requirements\nReview the used case and see the latest AI that can be used in products development\nIdentify problem areas and perform root cause analysis and provide relevant solutions to the problem\nTracks industry and application trends and relates these to planning current and future AI needs\nCreate and delegate work plans to the programming team for product development\nInteract with Holmes advisory board for knowledge sharing and best practices\nResponsible for developing and maintaining client relationships with the key strategic partners and decision makers\nDrive discussions and provide consultation around product design as per customer needs\nParticipate in client interactions and gather insights regarding product development\nInteract with vertical delivery and business teams and provide and correct responses to RFP/ client requirements\nAssist in products demonstration and receive feedback from the client\nDesign presentations for seminars, meetings and enclave primarily focused over product\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTalent Management\nEnsure adequate onboarding and training for the team members to enhance capability & effectiveness\nBuild an internal talent pool and ensure their career progression within the organization\nManage team attrition\nDrive diversity in leadership positions\nPerformance Management\nSet goals for the team, conduct timely performance reviews and provide constructive feedback to own direct reports\nEnsure that the Performance Nxt is followed for the entire team\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\n\nDeliver\nNo.Performance ParameterMeasure\n1.Continuous technical project management & deliveryAdoption of new technologies, IP creation, MVP creation, Number of patents filed, Research papers created\n2.Client CentricityNo. of automation done, On-Time Delivery, cost of delivery, optimal resource allocation\n3.Capability Building & Team Management% trained on new age skills, Team attrition %, Number of webinars conducted (internal/external)\n\n\n\n\nMandatory\n\nSkills:\nGenerative AI.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['solution development', 'project management', 'attrition', 'team management', 'performance management', 'artificial intelligence']",2025-06-11 06:07:57
Director Data Science,Astar Data,10 - 17 years,Not Disclosed,['Bengaluru'],"Sigmoid enables business transformation using data and analytics, leveraging real-time insights to make accurate and fast business decisions, by building modern data architectures using cloud and open source. Some of the worlds largest data producers engage with Sigmoid to solve complex business problems. Sigmoid brings deep expertise in data engineering, predictive analytics, artificial intelligence, and DataOps. Sigmoid has been recognized as one of the fastest growing technology companies in North America, 2021, by Financial Times, Inc. 5000, and Deloitte Technology Fast 500.\nOffices: New York | Dallas | San Francisco | Lima | Bengaluru\nThe below role is for our Bengaluru office.\n\nWhy Join Sigmoid?\n• Sigmoid provides the opportunity to push the boundaries of what is possible by seamlessly\ncombining technical expertise and creativity to tackle intrinsically complex business\nproblems and convert them into straight-forward data solutions.\n• Despite being continuously challenged, you are not alone. You will be part of a fast-paced\ndiverse environment as a member of a high-performing team that works together to\nenergize and inspire each other by challenging the status quo\n• Vibrant inclusive culture of mutual respect and fun through both work and play\nRoles and Responsibilities:\n• Convert broad vision and concepts into a structured data science roadmap, and guide a\nteam to successfully execute on it.\n• Handling end-to-end client AI & analytics programs in a fluid environment. Your role will be a\ncombination of hands-on contribution, technical team management, and client interaction.\n• Proven ability to discover solutions hidden in large datasets and to drive business results\nwith their data-based insights\n• Contribute to internal product development initiatives related to data science.\n• Drive excellent project management required to deliver complex projects, including\neffort/time estimation.\n• Be proactive, with full ownership of the engagement. Build scalable client engagement level\nprocesses for faster turnaround & higher accuracy\n• Define Technology/ Strategy and Roadmap for client accounts, and guides implementation\nof that strategy within projects\n• Manage the team-members, to ensure that the project plan is being adhered to over the\ncourse of the project\n• Build a trusted advisor relationship with the IT management at clients and internal accounts\nleadership.\nMandated Skills:\n• A B-Tech/M-Tech/MBA from a top tier Institutepreferably in a quantitativesubject\n• 10+ years of hands-onexperience in applied Machine Learning, AI and analytics\n• Experience of scientific programming in scripting languages like Python, R, SQL, NoSQL,\nSpark with ML tools & Cloud Technology (AWS, Azure, GCP)\n• Experience in Python libraries such as numpy, pandas, scikit-learn, tensor-flow, scrapy, BERT\netc. Strong grasp of depth and breadth of machine learning, deep learning, data mining, and\nstatistical concepts and experience in developing models and solutions in these areas\n• Expertise with client engagement, understanding complex problem statements, and offering\nsolutions in the domains of Supply Chain, Manufacturing, CPG, Marketing etc.\nDesired Skills:\nDeep understanding of ML algorithms for common use cases in both structured and\nunstructured data ecosystems.\nComfortable with large scale data processing and distributed computing\nProviding required inputs to sales, and pre-sales activities\nA self-starter who can work well with minimalguidance\nExcellent written and verbal communication skills",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Machine Learning', 'Algorithm Development', 'Pattern Recognition', 'Opencv', 'Image Processing', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Computer Vision', 'Deep Learning']",2025-06-11 06:07:58
Senior Artificial Intelligence Engineer,Ignitho,4 - 6 years,Not Disclosed,['Chennai( Sholinganallur )'],"Job Title: Senior AI Engineer\nLocation: Chennai\nReports To: Data Architect\n\nAbout the Company:\nIgnitho Inc. is a leading AI and data engineering company with a global presence, including US, UK, India, and Costa Rica offices.\nVisit our website to learn more about our work and culture: www.ignitho.com.\nIgnitho is a portfolio company of Nuivio Ventures Inc., a venture builder dedicated to developing Enterprise AI product companies across various domains, including AI, Data Engineering, and IoT.\nLearn more about Nuivio at: www.nuivio.com.\n\nJob Summary:\nAs a Senior AI Engineer, the candidate will lead the design, development, and deployment of cutting-edge machine learning and artificial intelligence solutions. The candidate will work closely with cross-functional teams to understand business needs and translate them into scalable AI-driven applications.\n\nKey Responsibilities:\nDesign and implement machine learning models and AI agents/LLMs.\nDevelop and optimize AI pipelines (LLM, RAG, fine-tuning)\nCollaborate with product, engineering, and data teams to define and implement AI-driven features.\nEvaluate model performance and iterate to improve accuracy and efficiency.\nMentor junior engineers and contribute to team best practices.\nStay up to date with state-of-the-art AI technologies and research.\n\nRequired Qualifications:\nBachelors or master’s in computer science, AI, or related field.\n5+ years of experience in AI/ML development.\nExperience working with LLMs, Agentic AI, RAG, and model fine-tuning\nStrong programming skills in Python and familiarity with frameworks such as TensorFlow, PyTorch, and Scikit-learn.\nExperience with cloud platforms (Azure preferred).\nSolid understanding of data preprocessing, model training, validation, and deployment.",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Pytorch', 'Azure Cloud', 'RAG', 'LLM', 'Ai Platform', 'AWS', 'Scikit-Learn', 'TensorFlow']",2025-06-11 06:08:00
Data Architect / Engagement Lead,Ignitho,7 - 10 years,Not Disclosed,['Chennai( Sholinganallur )'],"Job Title: Data Architect / Engagement Lead\nLocation: Chennai\nReports To: CEO\n\nAbout the Company:\nIgnitho Inc. is a leading AI and data engineering company with a global presence, including US, UK, India, and Costa Rica offices.\nVisit our website to learn more about our work and culture: www.ignitho.com.\nIgnitho is a portfolio company of Nuivio Ventures Inc., a venture builder dedicated to developing Enterprise AI product companies across various domains, including AI, Data Engineering, and IoT.\nLearn more about Nuivio at: www.nuivio.com.\n\nJob Summary:\nAs the Data Architect and Engagement Lead, you will define the data architecture strategy and lead client engagements, ensuring alignment between data solutions and business goals. This dual role blends technical leadership with client-facing responsibilities.\n\nKey Responsibilities:\nDesign scalable data architectures, including storage, processing, and integration layers.\nLead technical discovery and requirements gathering sessions with clients.\nProvide architectural oversight for data and AI solutions.\nAct as a liaison between technical teams and business stakeholders.\nDefine data governance, security, and compliance standards.\n\nRequired Qualifications:\nBachelors or Masters in computer science, Information Systems, or similar.\n7+ years of experience in data architecture, with client-facing experience.\nDeep knowledge of data modelling, cloud data platforms (Snowflake / BigQuery/ Redshift / Azure), and orchestration tools.\nExcellent communication, stakeholder management, and technical leadership skills.\nFamiliarity with AI/ML systems and their data requirements is a strong plus.",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Aiml', 'Data Modeling', 'Azure Cloud', 'Bigquery', 'Redshift Aws', 'Artificial Intelligence', 'Snowflake', 'Machine Learning']",2025-06-11 06:08:01
Digital Project Manager Lead Consultant,"NTT DATA, Inc.",3 - 4 years,Not Disclosed,['Pune'],"Req ID: 303766\n\nWe are currently seeking a Digital Project Manager Lead Consultant to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nRESPONSIBILITIES\n\n\nLead and manage AI projects from inception to completion, ensuring successful delivery within scope, timeline, and budget.\n\n\nDevelop comprehensive project plans, including timelines, resource allocation, and risk management strategies for AI and machine learning initiatives.\n\n\nCollaborate with a diverse range of stakeholders, including data scientists, engineers, and business leaders, to align project objectives with organizational goals.\n\n\nOversee the development and deployment of AI models, ensuring alignment with project requirements and performance metrics.\n\n\nIdentify, analyze, and address project issues and risks, implementing corrective actions as needed to keep projects on track.\n\n\nDrive process improvements by integrating new technologies and best practices into project management processes.\n\n\nFacilitate clear and effective communication across project teams and stakeholders, providing regular updates and ensuring transparency throughout the project lifecycle.\n\n\nEnsure AI projects adhere to data privacy regulations, ethical guidelines, and industry standards.\n\n\nHandle project operations ""“ Resource Rampup, People Management, Trainings\n\n\nWorking with COE to create new GenAI accelerators\n\n\nLocationPune\n\n\nSkills, Knowledge, and Experience\n\n\nTechnical Handson skills in GenAI is must. Should be able to provide technical guidance to the team when required\n\n\nMinimum 3-4 years of experience managing AI or technology projects, with a proven track record of delivering complex projects on time and within budget.\n\n\nBachelor""™s degree in Computer Science, Data Science, or a related field; advanced certification (e.g., PMP, Agile) is a plus.\n\n\nStrong portfolio demonstrating successful AI projects, showcasing ability to manage project scope, resources, and stakeholder expectations effectively.\n\n\nFamiliarity with AI and machine learning concepts, technologies, and tools, with the ability to understand and manage technical aspects of projects.\n\n\nProficiency in project management methodologies (e.g., Agile, Scrum) and tools (e.g., Jira, MS Project).\n\n\nExperience with data analytics and performance monitoring tools relevant to AI projects.\n\n\n\nUnderstanding of how AI solutions can drive business value and impact organizational strategy.\n\n\nKnowledge of ethical considerations and compliance requirements related to AI and data privacy.\n\n\nStrong understanding of programming or data science tools (e.g., Python, R) for better communication with technical teams & Azure GENAI\n\n\nExceptional communication skills, with the ability to convey complex AI concepts and project details to both technical and non-technical stakeholders.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['python', 'project management process', 'machine learning', 'artificial intelligence', 'data science', 'project operations', 'risk management', 'project management', 'data analytics', 'ms project', 'microsoft azure', 'budgeting', 'r', 'pmp', 'resource allocation', 'scrum', 'agile', 'jira']",2025-06-11 06:08:03
Data Architect,.,7 - 12 years,20-35 Lacs P.A.,"['Hyderabad', 'Bengaluru']","Job Description\nWe are seeking a highly skilled Azure Data Engineer with strong expertise in Data Architecture, PySpark/Python, Azure Databricks, and data streaming solutions. The ideal candidate will have hands-on experience in designing and implementing large-scale data pipelines, along with solid knowledge of data governance and data modeling.\nKey Responsibilities\nDesign, develop, and optimize PySpark/Python-based data streaming jobs on Azure Databricks.\nBuild scalable and efficient data pipelines for batch and real-time processing.\nImplement data governance policies, ensuring data quality, security, and compliance.\nDevelop and maintain data models (dimensional, relational, NoSQL) to support analytics and reporting.\nCollaborate with cross-functional teams (data scientists, analysts, and business stakeholders) to deliver data solutions.\nTroubleshoot performance bottlenecks and optimize Spark jobs for efficiency.\nEnsure best practices in CI/CD, automation, and monitoring of data workflows.\nMentor junior engineers and lead technical discussions (for senior/managerial roles).\nMandatory Skills & Experience\n5+ years of relevant experience as a Data Engineer/Analyst/Architect (8+ years for Manager/Lead positions).\nExpert-level proficiency in PySpark/Python and Azure Databricks (must have worked on real production projects).\nStrong experience in building and optimizing streaming data pipelines (Kafka, Event Hubs, Delta Lake, etc.).\n4+ years of hands-on experience in data governance & data modeling (ER, star schema, data vault, etc.).\nIn-depth knowledge of Azure Data Factory, Synapse, ADLS, and SQL/NoSQL databases.\nExperience with Delta Lake, Databricks Workflows, and performance tuning.\nFamiliarity with data security, metadata management, and lineage tracking.\nExcellent communication skills (must be able to articulate technical concepts clearly).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Azure Databricks', 'Data Modeling', 'Data Governance', 'Python', 'ETL']",2025-06-11 06:08:05
Senior Principal Engineer - Pavement,Aecom,10 - 15 years,Not Disclosed,['Bengaluru'],"\n\nOur team is seeking an experienced Pavement Engineer to join our Bangalore or Gurgaon office.\n\nOur pavement team has several long-term State Government Road upgrade projects, which provide solid base workload. In addition, they internally support our other teams with pavement designs for infrastructure-related projects, commercial and industrial developments, as well as for airside and ports-related projects.\n\nAs valued members of the pavement team, opportunities exist to be involved in projects from the earliest stages of planning, ground investigation, design, and all the way through to construction and operational management phases. You will assist with the business development by preparation of bids and proposals and attend meetings with contractors and clients (both external and internal). You will be expected to promote the implementation of innovations and sustainable technologies within AECOM and the industry.\n\nYour demonstrated experience will enable you to immediately contribute to the team. However, ongoing personal development is a major driver of the AECOM business.\n\n About You \n\nYour role will include new pavement design, rehabilitation design, testing and pavement management advisory services. As part of this role you will be given the opportunity to work on a range of assignments to aid in your professional development.\n\nYou will also assist in preparation of bids and proposals and attend meetings with contractors and clients, both external and internal and work on multi-disciplinary project design teams.\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Civil Engineers, UK)\n10 to 15 years of Pavement Design experience.\nRelevant tertiary qualification\nRelevant postgraduate qualifications would be advantageous.\nExtensive knowledge and understanding of pavement engineering and earthworks.\nExperienced in the provision and management of project design services, including managing pavement assessment (destructive and non-destructive methods), design of new pavements and rehabilitation of existing pavements (flexible mandatory, rigid advantageous).\nExperience across highways, industrial, maritime and airfields sectors would be advantageous.\nDemonstrated experience in using pavement design software such as linear elastic pavement modelling and back-calculation software.\nExperience in pavement management systems such as dTims will be preferred.\nExperience with Australian standards for pavement design will be preferred\n\n\n Skills \nDemonstrated experience in complex projects and meeting delivery requirements.\nStrong oral and written communication skills.\nDemonstrated time management and organizational skills.\nDemonstrated commercial acumen\n\n Essential Performance Criteria \nStrong team player with excellent interpersonal skills who is able to work independently and collaboratively with international teams.\nHigh level attention to detail and accuracy.\nDiligent and able to work consistently to deadlines under tight timeframes.\nHigh-level problem-solving skills & judgment capability.\nTakes accountability for assigned work.\nAble to maintain confidentiality.\nWellpresented, with a professional attitude.\nClient focused (both internal and external clients).\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['earthworks', 'customer service', 'construction management', 'highways', 'maritime', 'site execution', 'non voice process', 'pqc', 'logistics', 'dbm', 'shipping', 'civil engineering', 'wmm', 'gsb', 'semi voice', 'site engineering', 'dlc', 'port operations']",2025-06-11 06:08:06
Senior Principal Engineer-Dry Utility(Infrastructure),Aecom,10 - 13 years,Not Disclosed,['Bengaluru'],"\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation and operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\nAECOM is seeking for a candidate to be based inBengaluru or Gurgaon. Candidate will be responsible for the following activities:\n10 - 13Years (Exposure to outside India projects preferably Middle East,UK, USA, Canada & ANZ region )\nPreparation, Review and production of Electrical (EHV, HV, MV, LV), Street Lighting, Telecom, ELV, ICT Network, Pump station,Water Treatment Plant, EV charging Station, Substation, Power Transmission & Distribution network\nDesign CalculationStreet lighting, High Mast Area Lighting, Cable sizing & Voltage drop, Earthing, Fault level, Corridor sizing\nSoftwareDialux, AGI, Lighting Reality, Amtech, ETAP\n\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nGood communication skills, and ability to work well independently at times.\nAble to see the bigger picture and take a birds-eye view of projects\nConfident, with the ability to work either independently or as part of a team.\nAbility to work to deadlines and under pressure.\nAccountability for assigned work.\nAccuracy & precision of work.\nWillingness to learn and develop.\nExcellent written and verbal communication skills\nStrong problem-solving skills\nEnthusiastic and Self-motivated.\nWork well within a multidisciplinary team\n\n\n",Industry Type: Building Material (Cement),"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['kubernetes', 'infrastructure architecture', 'docker', 'devops', 'aws', 'vmware', 'enterprise architecture', 'microsoft azure', 'ansible', 'sccm', 'data center', 'active directory', 'solution design', 'linux', 'microsoft windows', 'cloud computing', 'it infrastructure']",2025-06-11 06:08:08
Sr. Principal /Principal Engineer,Aecom,12 - 17 years,Not Disclosed,['Bengaluru'],"\n\nAECOM is seeking a Principal/Senior Principal Engineer - Water Infrastructure to be based in Bengaluru/Gurgaon/Mumbai, India. Candidates will be responsible for the following activities:\n\n12+ Years (Exposure to outside India projects preferably UK, USA, Canada, MER & ANZ region )\nHaving hands on experience for Design of wet utilities - Potable Water, Storm Water Drainage, Highway Drainage, Treated Sewage Effluent & Sewerage network (pressure plus gravity design experience with the help of AutoCAD 2D, AutoCAD Civil3D, Open Roads & MicroStation)\nCapable of designing the pumping stations, general arrangement, road/bridge crossing structures, typical valve chambers etc.\nHaving experience with any Hydraulic modeling tools like Water Hammer, Sewer GEMS/Infoworks ICM, Infoworks WS Pro/ WaterGEMS, Info Drainage, HEC-RAS would be advantage.\nProvide technical support to designers for relocation/shifting of assets, asset tagging, connection drawings, standard drawings etc.\nClash Analysis experience using Navisworks\nExperience in working in Common Data Environment (ProjectWise, BIM 360, ACC)\nCapable for leading the project, coordinating with Lead Office, mentoring juniors and ensuring quality checks\nShould be capable of leading multiple projects with different geographical locations same time.\nProvides training and technical support to Engineers, designers on understanding design standards, adopting digital tools\nAdditional skills like team management, project management, resource planning, project budget planning, estimation is must\n\n\n Qualifications \n\nThe successful candidate will have the following Qualifications:\nMasters in civil / water resources / Environment / PHE\nPreferable to have or working towards Professional Qualification such as C.Eng. (ICE) or C.Eng. (IET) or C. CIWEM.\nGood communication skills, and ability to work well independently at times.\nAble to see the bigger picture and take a birds-eye view of projects\nConfident, with the ability to work either independently or as part of a team.\nAbility to work to deadlines and under pressure.\nAccountability for assigned work.\nAccuracy & precision of work.\n\n\n",Industry Type: Building Material (Cement),Department: Project & Program Management,"Employment Type: Full Time, Permanent","['bim', 'resource planning', 'project management', 'team management', 'estimation', 'autocad', 'sql', 'plsql', 'autocad 2d', '3d', 'icm', 'technical support', 'java', 'modeling tools', 'drawing', 'construction', 'mer', 'ws', 'c', 'autocad civil 3d', 'water', 'microstation', '2d', 'quality check', 'sewergems']",2025-06-11 06:08:10
Principal Engineer - EMC and Earthing and Bonding,Aecom,12 - 17 years,Not Disclosed,['Bengaluru'],"\n\nUnderstand and align the team's contributions with project goals, recognizing their impact within the project management framework\nOperate within financial and program constraints while considering budgetary implications in design options\nDevelops construction cost estimates and estimates of technical efforts/ fee proposal for projects\nWork within the financial and programme constraints and consider financial implications in producing design options\nPerforms quality control review of design documentation, calculations and drawing\nLead EMI and E&B activities, offering guidance, support, and performance management\nParticipates in development of technical proposals.\nProvides input to the development of engineering budget and schedule to meet requirements.\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Civil Engineers, UK)\n12+ Years of experience\nContribute to design development, design risk and mitigation, and value engineering with a focus on electromagnetic compatibility (EMC) and electromagnetic interference (EMI)\nProvide expert technical guidance and ensure adherence to earthing and bonding (E&B) standards throughout the design process\nPresent EMC/EMI and E&B strategies effectively to stakeholders and non-technical leads\nDevelop and deliver Earthing (Grounding) and Bonding Control Strategy reports\nProduce detailed design documentation, including calculations, design sketches, and technical specifications\nParticipate in interdisciplinary design team meetings and coordinate with sub-consultants and equipment suppliers for accurate design information\nReview and verify design drawings and ensure they align with project requirements and standards\nPrepare technical reports and assess project specifications for construction compliance\nProvide input to E&B strategy and conduct power quality compatibility assessments\nWorking with design engineers to advise on EMC test specifications and production of test procedures and reports as required\nAdvise appropriate EMC solutions through design analysis to identify required control techniques and good design practice\nEarthing (Grounding) & Bonding Design:\nProduce comprehensive reports detailing solutions for each facility\nProduce calculation reports to justify results and ensure compliance with required values.\nDevelop and mark up drawings, including grounding grid layouts, cross-sections, riser diagrams, and bonding drawings.\nTechnical specifications of the elements\nLightning Protection Design:\nProduce reports outlining solutions for each facility.\nCreate calculation reports to validate results and meet compliance requirements\nDevelop and Mark up drawings for lightning protection layouts and connections to main grounding grids.\nDefine technical specifications for lightning protection elements.\nEnsure that technical and safety standards are maintained across all design activities tin order that successful project implementation and future reliability is achieved.\nCarry out risk assessments and provision of design information for Health and Safety file.\n\n\n",Industry Type: Building Material (Cement),Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['emi', 'san', 'project management', 'vmax', 'emc', 'emc design', 'emi / emc', 'software testing', 'brocade', 'spi', 'power electronics', 'microcontroller', 'orcad', 'signal integrity', 'hardware design', 'emc testing', 'pcb designing', 'emc storage', 'i2c', 'netapp']",2025-06-11 06:08:11
Principal Engineer - Track (ANZ Projects),Aecom,12 - 17 years,Not Disclosed,['Bengaluru'],"\n\nThis position requires leading track designs by example primarily in Australia and New Zealand region and will need a combination of hands-on track design, design checking, mentoring, and training other team members. Primary KPI is to increase repeat work from ANZ through sustained high-quality deliverables.\nLead in the production of track designs and provision of technical support throughout to support all stages of the design process (Feasibility through to Construction) in both Plain Line and S&C, especially in the ANZ region.\nIndependently deliver / manage the production of design deliverables in accordance with client requirements\nActs as a Senior technical resource and serve as technical advisor and/or mentor for lesser experienced team members.\nProvides specialized technical input to studies and design for staff's specific area of expertise.\nDevelops study and design procedures to facilitate high-quality cost-effective work by others.\nParticipates in interdisciplinary review of project deliverables.\nDevelops construction cost estimates and estimates of technical efforts for projects.\nUses expertise in all steps of completing discipline component.\nPerforms quality control review of design calculations, Models, or drawings.\nPrepares technical specification sections.\nProvides input to the development of engineering budget and schedule to meet requirements.\nAgility in the face of dynamic project stages. This position may also be leading similar designs in other global regions if required.\n\n\n Qualifications \nMaster of Engineering degree or Bachelor degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university. Washington Accord accredited preferred.\nRegistered Practicing Engineer - Victoria (RPEV), (RPEQ), or eligible for qualification or working towards.\n12+ Years of Track Design experience in both greenfield and brownfield projects with substantial experience in Australian or New Zealand Projects.\nPrior or current experience in gauging as per ESC215 in New South Wales is mandatory.\nProficiency in Power Rail Track, Microstation mandatory. Open Rail Designer preferred.\nExtensive experience and Technical Proficiency in Plain Line and Switches & Crossings mandatory, preferably in ANZ region.\nExperience with earthworks, including cut and fill modelling and quantity estimation.\nSolid understanding of Australian Track Design including interpretation of Standards and application of SiD, HSE regulations.\nSolid understanding of track construction methods, stageworks of projects, Way components and surveys in Australian region.\nWorking knowledge of AMB standards and requirements\nDemonstrated ability to author technical reports.\nDemonstrated ability to present their work and represent their colleagues on the project in presentations and meetings.\nTechnical quality of deliverables undertaking checks of design deliverables completed by team members in accordance with company procedures.\nTimely delivery in accordance with design programmes.\nExperience of Attendance at technical design reviews including Design and Construction Interface meetings and Interdisciplinary Design Checks to present Track design.\nKeep up to date with industry best practices and where appropriate apply best practices within the project team environment.\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['switching', 'microstation', 'construction management', 'construction', 'project engineering', 'earthworks', 'project management', 'quality control', 'brownfield', 'design calculations', 'water', 'estimation', 'oil', 'quantity estimation', 'drawing', 'brownfield project', 'petrochemical']",2025-06-11 06:08:13
Principal Engineer- Electrical(Primary Substation),Aecom,8 - 13 years,Not Disclosed,['Bengaluru'],"\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation, operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\n Duties and Responsibilities \n\nSenior technical resource may serve as technical advisor for team\n\nProvides specialized technical input to studies and design for staff's specific area of expertise.\n\nDevelops study and design procedures to facilitate high quality cost effective work by others.\n\nParticipates in interdisciplinary review of project deliverables.\n\nDevelops construction cost estimates and estimates of technical efforts for projects.\n\nUses expertise in all steps of completing discipline component of PS&E package.\n\nPerforms quality control review of design calculations or drawings.\n\nPrepares technical specification sections.\n\nProvides input to the development of engineering budget and schedule to meet requirements.\n\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Electrical Engineers, UK)\n\n Minimum  \nOverall 8+ years of work experience is preferred.\nPrior experience in leading large design engineering teams performing Grid Substation design in a global consultancy firm is preferred.\nExperience on HV Plant Design for large EHV Grid Substations is mandatory.\nPrevious experience in design teams working for Grid Utilities (for e.g., National Grid, Transgrid, Powergrid etc.,) is highly desirable\nExpsoure to International standards (IEC, IEEE, ANSI, Australian Standards and Middle East region codes and standards) is preferred\nPrevious design experience working with GIS and AIS EHV substation HV Plant Primary design is preferable\nChartership or Fellowship with IET or equivalent is highly preferable\nVery good communication skills (Oral and Written) in English language is mandatory\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['ais', 'substation design', 'design engineering', 'hv', 'plant design', 'circuit', 'power system', 'electrical engineering', 'power transmission', 'design calculations', 'gis', 'electricals', 'construction management', 'transmission', 'drawing', 'construction', 'electrical installation']",2025-06-11 06:08:15
Principal Engineer- Electrical(Secondary Substation),Aecom,8 - 13 years,Not Disclosed,['Bengaluru'],"\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation, operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\n Duties and Responsibilities \n\nSenior technical resource may serve as technical advisor for team\n\nProvides specialized technical input to studies and design for staff's specific area of expertise.\n\nDevelops study and design procedures to facilitate high quality cost effective work by others.\n\nParticipates in interdisciplinary review of project deliverables.\n\nDevelops construction cost estimates and estimates of technical efforts for projects.\n\nUses expertise in all steps of completing discipline component of PS&E package.\n\nPerforms quality control review of design calculations or drawings.\n\nPrepares technical specification sections.\n\nProvides input to the development of engineering budget and schedule to meet requirements.\n\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Electrical Engineers, UK)\n\n Minimum  \nOverall 8+ years of work experience is preferred.\nPrevious experience in design teams working for Grid Utilities (for e.g., National Grid, Transgrid, Powergrid etc.,) for Transmission Line Electrical design is highly desirable\nExposure to International standards (IEC, IEEE, ANSI, Australian Standards and Middle East region codes and standards) is preferred\nPrevious design experience working with Secondary Design for HV, MV Substations and Transmission Lines is preferable.\nChartership or Fellowship with IET or equivalent is desirable\nVery good communication skills (Oral and Written) in English language is mandatory\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['electrical design', 'transmission lines', 'hv', 'transmission line', 'electricals', 'circuit', 'power system', 'electrical engineering', 'power transmission', 'design calculations', 'motor control', 'construction management', 'transmission', 'drawing', 'construction', 'electrical installation']",2025-06-11 06:08:17
Principal Engineer - Electrical Design,Aecom,10 - 14 years,Not Disclosed,['Bengaluru'],"\n\n Duties and Responsibilities \n\nSenior technical resource may serve as technical advisor for team\nProvides specialized technical input to studies and design for staff's specific area of expertise\nDevelops study and design procedures to facilitate high quality cost effective work by others\nParticipates in interdisciplinary review of project deliverables\nDevelops construction cost estimates and estimates of technical efforts for projects\nUses expertise in all steps of completing discipline component of PS&E package\nPerforms quality control review of design calculations or drawings\nPrepares technical specification sections\nProvides input to the development of engineering budget and schedule to meet requirements\nLeads and mentors junior engineers and technicians in electrical design principles and best practices\nCollaborates with cross-functional teams to integrate electrical systems with other engineering disciplines\nDevelops and implements innovative solutions to complex electrical engineering challenges\nEnsures compliance with relevant electrical codes, standards, and regulations\nConducts feasibility studies and risk assessments for new electrical design projects\nRepresents the company in technical forums and industry conferences related to electrical engineering\n\n\n\n Qualifications \n\n Minimum  \nBA/BS in Electrical Engineering + 10YORE or demonstrated equivalency of experience and/or education\nProfessional Engineering (PE) license in Electrical Engineering\nExtensive experience in electrical system design, including power distribution, lighting, and control systems\nProficiency in electrical design software such as AutoCAD Electrical, ETAP, or similar tools\nStrong knowledge of National Electrical Code (NEC) and other relevant industry standards\nDemonstrated leadership experience in managing complex electrical engineering projects\nExcellent problem-solving and analytical skills\nStrong communication and interpersonal skills, with the ability to work effectively in cross-functional teams\nExperience in developing and reviewing technical specifications and construction documents\nFamiliarity with energy-efficient design principles and sustainable engineering practices\nAbility to mentor and guide junior engineers and technicians\n\n Preferred Qualifications \nMaster's degree in Electrical Engineering or related field\nAdditional certifications such as LEED AP, CEM, or PMP\nExperience with Building Information Modeling (BIM) software\nKnowledge of emerging technologies in electrical engineering, such as smart grid systems or renewable energy integration\n\n\n",Industry Type: Building Material (Cement),"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['electrical design', 'bim', 'system design', 'etap', 'autocad electrical', 'quality control', 'electrical engineering', 'design calculations', 'distribution', 'autocad', 'electricals', 'renewable energy', 'drawing', 'construction', 'power distribution', 'engineering projects']",2025-06-11 06:08:19
Principal Engineer - HVAC Design (Energy Modelling),Aecom,10 - 15 years,Not Disclosed,['Bengaluru'],"\n\nResponsible for engineering, design, and modification activities related to mechanical equipment, vessels and tanks and piping systems including equipment and piping specifications and procurement. May be involved with the support of installation and operation & maintenance of equipment.\n\nDiscipline concerning air conditioning, refrigeration, ventilation, combustion, heat transfer, energy, power, fuels, propulsion, machinery, tools, manufacturing, fluids, plumbing, fire suppression systems and devices, water supplies and pumping systems for fire protection.\n\nDiscipline covers the ability to solve problems that deliver and optimise safe, sustainable and ethical solutions for the design, production and operation of devices, machines, structures, processes and systems involving mechanical elements.\n\n Duties and Responsibilities \n\nSenior technical resource may serve as technical advisor for team\nProvides specialized technical input to studies and design for staff's specific area of expertise.\nDevelops study and design procedures to facilitate high quality cost effective work by others.\nParticipates in interdisciplinary review of project deliverables.\nDevelops construction cost estimates and estimates of technical efforts for projects.\nUses expertise in all steps of completing discipline component of PS&E package.\nPerforms quality control review of design calculations or drawings.\nPrepares technical specification sections.\nProvides input to the development of engineering budget and schedule to meet requirements.\n\nTechnical Excellence\nIdentifies incremental improvements to existing procedures or processes that increase efficiency or work quality\nPerforms a self-check of work products prior to submitting them to others.\n\nLeadership\nWorks independently and collaboratively with a lesser level of guidance needed for unfamiliar tasks\nProvides regular updates to the manager on project/assignment status\nMay assist more junior staff members with aspects of their job and may coordinate activities of a small team.\n\n\n Qualifications \n\n Minimum  \nMinimum Bachelor's Degree in Mechanical Engineering (with minimum 10years experience) or Equivalent and specialising in HVAC Design.\nHe/She should be well versed with ASHRAE/CIBSE/NFPA.\nHe/She should have experience in commercial, residential, datacentre, and infrastructure projects from different geographies - USA, Canada, ANZ Region.\nExperienced Senior Mechanical Engineer - Specialized in HVAC Design.\nShould be capable of leading the discussions with the Client and lead projects for the HVAC Disciplines.\nShould be able to take Design decisions independently.\nEnergy Modelling , Building Performance analysis & IES Software skills listed in detail below.\nUtilize the energy modelling software like IES VE to simulate the building performance and energy consumption\nAnalyze the data received from client and data from energy results and provide the best energy efficient solutions to tam\nCollaborate with the multidisciplinary teams for various inputs and outputs to do the efficient design process\nAbility to work on Cooling/Heating loads, Energy consumption and building performance in IES VE or any other modelling software\nFamiliarity with ASHRAE 90.1, 62.1, 55 and CIBSE requirement\nKnowledge of Mechanical system architecture and components\n\n\n",Industry Type: Building Material (Cement),"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['hvac', 'mechanical engineering', 'ashrae', 'hvac design', 'performance analysis', 'ventilation', 'water supply', 'design calculations', 'plumbing', 'autocad', 'design engineering', 'piping', 'refrigeration', 'manufacturing', 'drawing', 'construction', 'mep', 'fire protection', 'machinery']",2025-06-11 06:08:20
Principal Engineer - HV Cables,Aecom,8 - 13 years,Not Disclosed,['Gurugram'],"\n\nAECOM is seeking for a candidate to be based in Bengaluru or Gurgaon. Candidate will be responsible for the following activities:\n\nSenior technical resource may serve as technical advisor for team\nProvides specialized technical input to studies and design for staff's specific area of expertise.\nDevelops study and design procedures to facilitate high quality cost effective work by others.\nParticipates in interdisciplinary review of project deliverables.\nDevelops construction cost estimates and estimates of technical efforts for projects.\nUses expertise in all steps of completing discipline component of PS&E package.\nPerforms quality control review of design calculations or drawings.\nPrepares technical specification sections.\nProvides input to the development of engineering budget and schedule to meet requirements.\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation and operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\n\n Minimum  \n\nOverall 8+ years of work experience is preferred.\n\nPrevious experience in HV Cable OEM design teams working for Grid Utilities (for e.g., National Grid, Transgrid, Powergrid etc.,) for Underground HV Cables design is highly desirable\n\nExpsoure to International standards (IEC, IEEE, ANSI, Australian Standards and Middle East region codes and standards) is preferred\n\nPrevious design experience working with CYMCAP or other similar software tools for EHV/HV AC and DC Cable Ampacity calculations, EMTP Calculations and modelling expertise is highly desirable\n\nChartership with IET-UK or equivalent is desirable\n\nVery good communication skills (Oral and Written) in English language is mandatory\n\n\n",Industry Type: Building Material (Cement),"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['hvac', 'cables', 'elv', 'hv', 'dc', 'matlab', 'python', 'transformers', 'pscad', 'power system', 'digsilent', 'electrical engineering', 'emtp', 'design engineering', 'autocad', 'comsol', 'etap', 'system study', 'renewable energy', 'power system studies', 'cable sizing', 'power plant', 'cabling']",2025-06-11 06:08:22
Principal Engineer - HV Cables,Aecom,8 - 13 years,Not Disclosed,['Bengaluru'],"\n\nAECOM is seeking for a candidate to be based in Bengaluru or Gurgaon. Candidate will be responsible for the following activities:\n\nSenior technical resource may serve as technical advisor for team\nProvides specialized technical input to studies and design for staff's specific area of expertise.\nDevelops study and design procedures to facilitate high quality cost effective work by others.\nParticipates in interdisciplinary review of project deliverables.\nDevelops construction cost estimates and estimates of technical efforts for projects.\nUses expertise in all steps of completing discipline component of PS&E package.\nPerforms quality control review of design calculations or drawings.\nPrepares technical specification sections.\nProvides input to the development of engineering budget and schedule to meet requirements.\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation and operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\n\n Minimum  \n\nOverall 8+ years of work experience is preferred.\n\nPrevious experience in HV Cable OEM design teams working for Grid Utilities (for e.g., National Grid, Transgrid, Powergrid etc.,) for Underground HV Cables design is highly desirable\n\nExpsoure to International standards (IEC, IEEE, ANSI, Australian Standards and Middle East region codes and standards) is preferred\n\nPrevious design experience working with CYMCAP or other similar software tools for EHV/HV AC and DC Cable Ampacity calculations, EMTP Calculations and modelling expertise is highly desirable\n\nChartership with IET-UK or equivalent is desirable\n\nVery good communication skills (Oral and Written) in English language is mandatory\n\n\n",Industry Type: Building Material (Cement),"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['hvac', 'cables', 'elv', 'hv', 'dc', 'matlab', 'python', 'transformers', 'pscad', 'power system', 'digsilent', 'electrical engineering', 'emtp', 'design engineering', 'autocad', 'comsol', 'etap', 'system study', 'renewable energy', 'power system studies', 'cable sizing', 'power plant', 'cabling']",2025-06-11 06:08:23
Principal Engineer - Rail E&P,Aecom,12 - 17 years,Not Disclosed,['Bengaluru'],"\n\nPerforms specific and moderate portions of a broader assignment of an experienced engineer.\n\nGathers and correlates basic engineering data using established and well-defined procedures.\n\nWorks on detailed or routine engineering assignments involving calculations and relatively simple tests.\n\nProposes approach to solve new problems encountered using modifications of standard procedures or methods developed in previous assignments.\n\nIdentifies discrepancies in results.\n\nProvides guidance to entry level engineers.\n\nPerforms work in accordance with agreed upon budget and schedule with little supervision.\n\nIndependently performs all the tasks necessary to complete primary design\n\nelements for engineering works.\n\nPerformance at this level requires developmental experience in a professional position,\n\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Civil Engineers, UK)\n12+ Years experience.\nExperienced in Points Heating, Signalling Power, Power system analysis, ETAP, AMTECH etc.\nExperienced in the use of UK Network Rail, and Railway Group Standards as well as the relevant British Standards and Eurocodes.\nUnderstanding of Health and Safety including CDM\nGood standard of written English and communication.\nStrong Electrical Engineering background with Rail industry experience.\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['power system', 'electrical engineering', 'system analysis', 'etap', 'signalling', 'navisworks', 'cable tray', 'c++', 'c', 'electrical design', 'bim', 'revit mep', 'single line diagram', 'dialux', 'autocad', 'microstation', 'cable schedule', 'lighting design', 'cable sizing', 'revit', 'construction', 'amtech']",2025-06-11 06:08:25
Principal Engineer - Bridges,Aecom,9 - 12 years,Not Disclosed,['Bengaluru'],"\n\nAECOM is seeking for a candidate to be based in Bangalore or Gurgaon with the following skill sets.\n\nExperience working on US/ME projects with good understanding of AASHTO/AREMA codes\n\nExperience on design of all types of Bridge structures, PSC, Concrete, Steel and Composite with good knowledge of Midas/LUSAS/SOFiSTiK\n\nSenior technical resource may serve as technical advisor for the team\n\nSenior technical resource may serve as technical advisor for team\nProvides specialized technical input to studies and design for staff's specific area of expertise.\nDevelops study and design procedures to facilitate high quality cost effective work by others.\nParticipates in interdisciplinary review of project deliverables.\nDevelops construction cost estimates and estimates of technical efforts for projects.\nUses expertise in all steps of completing discipline component of PS&E package.\nPerforms quality control review of design calculations or drawings.\nPrepares technical specification sections.\nProvides input to the development of engineering budget and schedule to meet requirements.\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Civil Engineers, UK).\n9-12years experience in Bridges\nUndertake rail and road bridges and associated structural engineering schemes from inspection and assessment, feasibility through to detailed design.\nExperience of Eurocodes, British Standards and assessment codes.\nProject management of schemes including client reporting, programming, resource planning and commercial management\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['project management', 'structural engineering', 'lusas', 'construction', 'bridge engineering', 'site execution', 'bridge design', 'flyovers', 'staad pro', 'autocad', 'construction management', 'site supervision', 'civil engineering', 'site engineering', 'highways', 'structural design']",2025-06-11 06:08:27
Hiring For Gen AI !!,HCLTech,5 - 10 years,Not Disclosed,"['Noida', 'Chennai', 'Bengaluru']","RESPONSIBILITIES:\nDevelop and contribute to end-to-end architecture of highly scalable, distributed machine learning solutions for AI/ML/DL/NLP platforms.\nContribute to the research and development of advanced generative AI models such as LLMs, SLM’s including GANs, VAEs, autoregressive models, and novel architectures.\nDeployment of generative AI models, frameworks, and algorithms into scalable REST API services.",,,,"['Generative Ai', 'Artificial Intelligence', 'Natural Language Processing', 'Machine Learning', 'Deep Learning']",2025-06-11 06:08:29
"Python Developer Ab-Bengaluru, Chennai, Pune",Infosys,3 - 5 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities\nWrite clean, maintainable, and efficient Python code for backend services or applications. Develop RESTful APIs or work on web applications using frameworks like Django or Flask. Implement data extraction, transformation, and loading (ETL) processes using Python. Collaborate with front-end developers and other team members to ensure seamless integration. Test and debug applications to ensure they meet quality and performance standards.\nParticipate in code reviews and contribute to the development of coding standards.\nKeep up-to-date with Python libraries and tools relevant to the project.\n\nTechnical and Professional Requirements:\nPrimary skills: Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities:\nSkills Required:\nStrong proficiency in Python 3.x.\nExperience with at least one Python web framework (Django, Flask, etc.).\nKnowledge of database technologies, including SQL and ORM (e.g., SQLAlchemy).\nFamiliarity with version control systems like Git.\nBasic understanding of front-end technologies (HTML, CSS, JavaScript).\nExperience with unit testing frameworks like pytest or unittest.\nKnowledge of REST API design principles.\n\nEducational Requirements\nBCA/MCA/B.Tech/BE/M.Tech/ME/BSC/MSC",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Python', 'Flask']",2025-06-11 06:08:30
Python Developer -AB-Pan India,Infosys,3 - 5 years,3.25-8.25 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities\nWrite clean, maintainable, and efficient Python code for backend services or applications. Develop RESTful APIs or work on web applications using frameworks like Django or Flask. Implement data extraction, transformation, and loading (ETL) processes using Python. Collaborate with front-end developers and other team members to ensure seamless integration. Test and debug applications to ensure they meet quality and performance standards.\nParticipate in code reviews and contribute to the development of coding standards.\nKeep up-to-date with Python libraries and tools relevant to the project.\n\nTechnical and Professional Requirements:\nPrimary skills: Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities:\nSkills Required:\nStrong proficiency in Python 3.x.\nExperience with at least one Python web framework (Django, Flask, etc.).\nKnowledge of database technologies, including SQL and ORM (e.g., SQLAlchemy).\nFamiliarity with version control systems like Git.\nBasic understanding of front-end technologies (HTML, CSS, JavaScript).\nExperience with unit testing frameworks like pytest or unittest.\nKnowledge of REST API design principles.\n\nEducational Requirements\nBCA/MCA/B.Tech/BE/M.Tech/ME/BSC/MSC",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Python', 'Flask']",2025-06-11 06:08:32
Proactive Hiring For AI/ML/DL !!,HCLTech,5 - 10 years,Not Disclosed,"['Noida', 'Chennai', 'Bengaluru']","Senior Technical Lead (AI-DLML)\nJob Role & responsibilities\nUnderstand operational needs by collaborating with client specialized teams\nFormalize needs into mathematical models and problems\nExplore databases (including very big databases, in tables or unstructured, including open ones) to mine patterns\nChoose relevant techniques and create data processing solutions for the identified needs",,,,"['Artificial Intelligence', 'Natural Language Processing', 'Machine Learning', 'Deep Learning', 'Tensorflow', 'Cnn', 'Rnn', 'Opencv', 'pytorch', 'Keras', 'Computer Vision', 'AWS']",2025-06-11 06:08:34
Developer - L4,Wipro,5 - 8 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of this role is to design, test and maintain software programs for operating systems or applications which needs to be deployed at a client end and ensure its meet 100% quality assurance parameters\n\n\n\nDo\n1. Instrumental in understanding the requirements and design of the product/ software\nDevelop software solutions by studying information needs, studying systems flow, data usage and work processes\nInvestigating problem areas followed by the software development life cycle\nFacilitate root cause analysis of the system issues and problem statement\nIdentify ideas to improve system performance and impact availability\nAnalyze client requirements and convert requirements to feasible design\nCollaborate with functional teams or systems analysts who carry out the detailed investigation into software requirements\nConferring with project managers to obtain information on software capabilities\n\n\n\n2. Perform coding and ensure optimal software/ module development\nDetermine operational feasibility by evaluating analysis, problem definition, requirements, software development and proposed software\nDevelop and automate processes for software validation by setting up and designing test cases/scenarios/usage cases, and executing these cases\nModifying software to fix errors, adapt it to new hardware, improve its performance, or upgrade interfaces.\nAnalyzing information to recommend and plan the installation of new systems or modifications of an existing system\nEnsuring that code is error free or has no bugs and test failure\nPreparing reports on programming project specifications, activities and status\nEnsure all the codes are raised as per the norm defined for project / program / account with clear description and replication patterns\nCompile timely, comprehensive and accurate documentation and reports as requested\nCoordinating with the team on daily project status and progress and documenting it\nProviding feedback on usability and serviceability, trace the result to quality risk and report it to concerned stakeholders\n\n\n\n3. Status Reporting and Customer Focus on an ongoing basis with respect to project and its execution\nCapturing all the requirements and clarifications from the client for better quality work\nTaking feedback on the regular basis to ensure smooth and on time delivery\nParticipating in continuing education and training to remain current on best practices, learn new programming languages, and better assist other team members.\nConsulting with engineering staff to evaluate software-hardware interfaces and develop specifications and performance requirements\nDocument and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code\nDocumenting very necessary details and reports in a formal way for proper understanding of software from client proposal to implementation\nEnsure good quality of interaction with customer w.r.t. e-mail content, fault report tracking, voice calls, business etiquette etc\nTimely Response to customer requests and no instances of complaints either internally or externally\n\n\n\nDeliver\n\nNo.Performance ParameterMeasure\n1.Continuous Integration, Deployment & Monitoring of Software100% error free on boarding & implementation, throughput %, Adherence to the schedule/ release plan\n2.Quality & CSATOn-Time Delivery, Manage software, Troubleshoot queries,Customer experience, completion of assigned certifications for skill upgradation\n3.MIS & Reporting100% on time MIS & report generation\nMandatory Skills: Machine Learning.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Machine Learning', 'module development', 'software development', 'report generation', 'MIS', 'CI/CD', 'SDLC']",2025-06-11 06:08:35
Python Developer Lead @ Infosys- PAN INDIA,Infosys,3 - 8 years,Not Disclosed,"['Kolkata', 'Pune', 'Delhi / NCR']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Process->Testing processes->Test Automation Process,Technology->Machine Learning->Python\n\nPreferred Skills: Process->Testing processes->Test Automation Process Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BE,BSc,BTech",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Python Development', 'Flask']",2025-06-11 06:08:36
Python Lead,Infosys,5 - 8 years,Not Disclosed,['Chennai'],"Responsibilities\nA day in the life of an Infoscion\nAs part of the Infosys delivery team, your primary role would be to interface with the client for quality assurance, issue resolution and ensuring high customer satisfaction.\nYou will understand requirements, create and review designs, validate the architecture and ensure high levels of service offerings to clients in the technology domain.\nYou will participate in project estimation, provide inputs for solution delivery, conduct technical risk planning, perform code reviews and unit test plan reviews.\nYou will lead and guide your teams towards developing optimized high quality code deliverables, continual knowledge management and adherence to the organizational guidelines and processes.\nYou would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\nTechnical and Professional Requirements:\nPrimary skills:Technology->Machine Learning->Python,Technology->OpenSystem->Python - OpenSystem\nPreferred Skills:\nTechnology->OpenSystem->Python - OpenSystem->Python\nTechnology->Machine Learning->Python\nAdditional Responsibilities:\nKnowledge of more than one technology\nBasics of Architecture and Design fundamentals\nKnowledge of Testing tools\nKnowledge of agile methodologies\nUnderstanding of Project life cycle activities on development and maintenance projects\nUnderstanding of one or more Estimation methodologies, Knowledge of Quality processes\nBasics of business domain to understand the business requirements\nAnalytical abilities, Strong Technical Skills, Good communication skills\nGood understanding of the technology and domain\nAbility to demonstrate a sound understanding of software quality assurance principles, SOLID design principles and modelling methods\nAwareness of latest technologies and trends\nExcellent problem solving, analytical and debugging skills\nEducational Requirements\nMCA,MSc,MTech,Bachelor of Engineering,Bachelor Of Technology\nService Line\nApplication Development and Maintenance\n* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'technical risk planning', 'test plan', 'debugging', 'code reviews', 'Machine Learning', 'project estimation']",2025-06-11 06:08:38
Director - Algorithm Development,Applied Materials,15 - 20 years,Not Disclosed,['Bengaluru'],"Who We Are\n\nApplied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips- the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world- like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of""science and engineering to make possible""the next generations of technology, join us to Make Possible® a Better Future.\n\nWhat We Offer\n\nLocation:\nBangalore,IND\nAt Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. Were committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits .\n\nYoull also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers.""We empower our team to push the boundaries of what is possible""”while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied.\n\nJob Expectations\n\nThe candidate will be responsible for leading a team of data scientists who provide analytics services for Applied Materials installed base. The deliverables include developing new service capabilities, piloting them, and commercializing them in partnership with Engineering and Service Product Managers. The team will work with field engineers and product engineering teams to understand the requirements, bring forward creative ideas, develop proofs-of-concept, architect, design, develop, and modify algorithms into production code, provide production support, and train end-users. The skill sets in the team include descriptive statistical analysis, predictive statistical analysis using AI/ML, data visualization and analytics process automation, data cleansing, complex image processing, and text processing. Candidate should be willing to learn and adopt semiconductor industry as their career domain.\n\nKey Responsibilities\n\nResponsible for managing completion of assignments, projects and programs to support Applieds service business. Scope of algorithm development includes research, design, code development, implementation, and proliferation. Execute projects as needed to support the business. Review and monitor progress to milestones on development programs. Develop roadmaps for algorithmic development programs. Oversee algorithmic concept and feasibility for algorithmic modules, including problem statement definition, data gathering, literature review, concept selection, risks, and implementation constraints. Oversee documentation of algorithmic development and deployment, including integration into required systems, user testing, and user training. Oversee software and hardware implementation. Interact with internal and external customers to define gaps, identify opportunities, define program scope and deliverables, and proliferate solutions to the user base. Present to management for project reviews, interact with project stakeholders, run regular cadence meetings and work in alignment with team and organization goals. Responsible for technical development of team, objective setting, and performance management. Develop growth plan for the team, including identification of new areas of impact.\n\n\n\nPreferred programming and data science skills includePython, C++, Unix, Image Processing, Deep Learning, AI/ML, NLP, GenAI, Text Mining, Database Design and Management, Web Scraping, GPU Optimization. Proficient in business processes and software such as Microsoft Word/ Excel/ Powerpoint/ Teams, Atlassian JIRA and Confluence. Highly organized and detail-oriented. Ability to build and maintain positive and productive inter-departmental working relationships. Ability to work in a cross-functional organization and multitask on multiple projects. Drive team members to deliver programs on time and on budget. Excellent oral and written communication, organizational, analytical, and interpersonal skills. Interest in building a career in the semiconductor industry.\n\nFunctional Knowledge\n\nDemonstrates comprehensive understanding of concepts and principles within own job family and knowledge of other related job families.\n\nBusiness Expertise\n\nApplies in-depth understanding of how own discipline integrates within the segment/function.\n\nLeadership\n\nManages multiple related teams, sets organizational priorities and allocates resources.\n\nProblem Solving\n\nIdentifies and resolves complex technical, operational and organizational problems.\n\nImpact\n\nImpacts the business results of a team or area by supporting and funding of projects, products, services and/or technologies and developing policies and plans.\n\nGuided by business unit, department or sub-functional business plans.\n\nInterpersonal Skills\n\nInfluences others internally and externally, including senior management.\n\nPosition requires understanding of Applied Materials global Standards of Business Conduct and compliance with these standards at all times. This includes demonstrating the highest level of ethical conduct reflecting Applied Materials core values.\n\nEducation\n\nBachelors, Masters, or Ph.D. Degree in Computer Science, Mathematics, or Engineering with a concentration in data science or AI/ML.\n\nExperience\n\n15 years of experience\n\nComputer Science/ Mathematics/ Engineering background with\n\n15 years of experience in performing statistical analysis, designing and developing Image Processing/ Computer Vision Algorithms, handling and analyzing large volumes of data. Semiconductor background is an added advantage. Prior team leadership experience is required.\n\nAdditional Information\n\nTime Type:\nFull time\n\nEmployee Type:\nAssignee / Regular\n\nTravel:\nYes, 20% of the Time\n\nRelocation Eligible:\nYes\nApplied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",Industry Type: Electronic Components / Semiconductors,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['natural language processing', 'artificial intelligence', 'deep learning', 'statistics', 'jira', 'image processing', 'web scraping', 'algorithms', 'c++', 'python', 'confluence', 'atlassian', 'iot', 'java', 'data science', 'computer vision', 'jenkins', 'text mining', 'performance management', 'unix', 'ml']",2025-06-11 06:08:40
Java Developer,Applied Materials,5 - 10 years,Not Disclosed,['Bengaluru'],"Who We Are\n\nApplied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips- the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world- like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of""science and engineering to make possible""the next generations of technology, join us to Make Possible® a Better Future.\n\nWhat We Offer\n\nLocation:\nBangalore,IND\nAt Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. Were committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits .\n\nYoull also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers.""We empower our team to push the boundaries of what is possible""”while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied.\n\nThe primary responsibility will be to participate in the creation of new products and enhancements to existing products from concept to launch as part of a cross functional team. In this role you will utilize your experience to provide Software solutions which involves System understanding of the Product. You will also be required to work with various interfaces to ensure the completeness of the solution.\n\nKey Responsibilities\nExecute the design, analysis, or evaluation of assigned projects using sound engineering principles and adhering to business standards, practices, procedures, and product / program requirements\nDesign & code a variety of complex software features with adequate documentation\nWrite automation for new/existing features.\nCustomer Support & troubleshoot/fix a variety of difficult software problems.\nProactively communicate on development status & delays in agreed upon timelines\nInterface with global teams for requirements analysis and schedule.\nInterface with external customers regarding software issues.\nBe willing to travel to onsite locations for Short Term Assignments like Feature Integrations & Version Installations.\n\n\nQualification and\nBachelors Degree / masters degree in engineering with Computer Science/Electronics/Electrical background and\n\n5 - 10 years of experience\nMinimum of 3 years experience in software development with exposure to maintenance, continuous integration & releases\nMinimum of 2 years experience in core product software development, Docker and Kubernetes\nStrong Object Oriented Design & Programming Experience\nProfessional experience of Core Java Technologies (Design Pattern/Multi-threading/Data Structures/Algorithm)\nExposure to Agile methodologies and tool chain (like JIRA)\nHas knowledge of best practices and how own area integrates with others\nExperience with porting of application to container based application\nExperience with docker and Kubernetes\n\n\n\nApplied Materials is committed to diversity in its workforce including Equal Employment Opportunity for Minorities, Females, Protected Veterans and Individuals with Disabilities.\n\nAdditional Information\n\nTime Type:\nFull time\n\nEmployee Type:\nAssignee / Regular\n\nTravel:\nNot Specified\n\nRelocation Eligible:\nYes\nApplied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",Industry Type: Electronic Components / Semiconductors,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['kubernetes', 'software development', 'docker', 'java', 'oops', 'algorithms', 'continuous integration', 'java development', 'java technologies', 'artificial intelligence', 'iot', 'computer science', 'design patterns', 'data structures', 'multithreading', 'agile', 'agile methodology', 'jira']",2025-06-11 06:08:41
Technical Trainer,Applied Materials,3 - 7 years,Not Disclosed,['Bengaluru'],"Who We Are\n\nApplied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips- the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world- like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of""science and engineering to make possible""the next generations of technology, join us to Make Possible® a Better Future.\n\nWhat We Offer\n\nLocation:\nBangalore,IND\nAt Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. Were committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits .\n\nYoull also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers.""We empower our team to push the boundaries of what is possible""”while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied.\n\nKey Responsibilities\nPresents technical training in house and at customer sites, focusing on specialized / customized courses; requires both domestic and international travel; manages classroom/lab activities to assure fulfillment of course objectives; presents and practices safety per procedure; may train during off shift and/or weekends as assigned.\nProject manage university partnership.\nHas general industry knowledge.\nMaintains product technical knowledge sufficient to prepare and present defined product courses; disseminates new information to staff; may complete certification on multiple platforms and/or processes to include safety modules; actively certifies others; establishes new certification requirements.\nUtilizes Technical Publications and System Business Units to improve technical documentation efficiencies; creates and augments documentation to fill gaps in released materials; evaluates instructor performance; trains others in standard course development process/Instructional System Design (ISD); responsible for course design approval.\nProvides technical expertise and troubleshooting skills to assist with system repairs; ensures system functionality can support course objectives; ensures all safety retrofits are installed on the training systems.\nDemonstrates knowledge and understanding of the technical training organization and operations and the AGS organization; informs customers of additional technical training courses/products available; assists in building customer relationships and selling technical training related products; provides input on customer issues/needs to determine future training opportunities.\nProvides coaching and leadership to other instructors; serves as mentor to less senior instructors for class delivery, technical development and certification; anticipates, prevents and resolves customer satisfaction issues.\nManages multiple projects of diverse scope and complexity; directs project team members.\nAlpha Site support to Engineering in house or on an engineering tool provides review of ECOs; communication to the field.\nSupports GPS in the generation of docs.\nDevelop new procedures and Best Known Methods.\nFirst chamber Build. Work with Engineering and Manufacturing; participate on New Product final test.\nDevelop technical materials.\nObserve technical activities to determine operating procedure and detail.\nInterview personnel to become familiar with products & methods.\nStudy tech docs to integrate a technology, operating procedure, production sequence and detail.\nReview published materials and recommends revisions.\nCommunicates with BUs to obtain current product information for courses updates; represents technical training organization at divisional meetings.\n\n\nFunctional Knowledge\nDemonstrates conceptual and practical expertise in own discipline and basic knowledge of related disciplines\n\n\nBusiness Expertise\nHas knowledge of best practices and how own area integrates with others; is aware of the competition and the factors that differentiate them in the market\n\n\nLeadership\nActs as a resource for colleagues with less experience; may lead small projects with manageable risks and resource requirements\n\n\nProblem Solving\nSolves complex problems; takes a new perspective on existing solutions; exercises judgment based on the analysis of multiple sources of information\n\n\nImpact\nImpacts a range of customer, operational, project or service activities within own team and other related teams; works within broad guidelines and policies\n\n\nInterpersonal Skills\nExplains difficult or sensitive information; works to build consensus\n\n\nThis role can teach PW(Precision workmanship) and general industry classes. The load for CE training will be very light initially, but the demand for university partnerships will be strong. This position should be able to do project manage university partnership.\n\nAdditional Information\n\nTime Type:\nFull time\n\nEmployee Type:\nAssignee / Regular\n\nTravel:\nYes, 20% of the Time\n\nRelocation Eligible:\nYes\nApplied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",Industry Type: Electronic Components / Semiconductors,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['orientation', 'presentation skills', 'iot', 'technical training', 'troubleshooting', 'process training', 'documentation', 'training management', 'training', 'product training', 'artificial intelligence', 'induction', 'recruitment', 'fitness', 'wellness', 'onboarding', 'coaching', 'gym']",2025-06-11 06:08:43
"Sr Software Eng: Generative AI, Go/Python, AWS, Kubernetes 7-12 Yrs",Cisco,7 - 12 years,Not Disclosed,['Bengaluru'],"Meet The Team\nThe Cisco AI Software & Platform Group drives the development of groundbreaking generative AI applications. We empower Cisco's diverse product portfolio, spanning networking and security, with intelligent assistants and agents. We work on pioneering technologies that proactively defend against threats, safeguard critical business assets, and simplify security operations. Fueled by a passion for AI/ML, we strive to create a secure future for businesses. Our collaborative and passionate team thrives with tackling sophisticated challenges and delivering innovative solutions.",,,,"['Golang', 'Generative Ai', 'AWS', 'Python', 'Kubernetes', 'Java']",2025-06-11 06:08:45
Director of Strategy and Chief of Staff To President Applied Materials,Applied Materials,17 - 22 years,Not Disclosed,['Bengaluru'],"Title : Director of Strategy and Chief of Staff to President Applied Materials India\n\nWho We Are\n\nApplied Materials is the global leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. We design, build and service cutting-edge equipment that helps our customers manufacture display and semiconductor chips- the brains of devices we use every day. As the foundation of the global electronics industry, Applied enables the exciting technologies that literally connect our world- like AI and IoT. If you want to work beyond the cutting-edge, continuously pushing the boundaries of""science and engineering to make possible""the next generations of technology, join us to Make Possible® a Better Future.\n\nWhat We Offer\n\nLocation:\nBangalore,IND\nAt Applied, we prioritize the well-being of you and your family and encourage you to bring your best self to work. Your happiness, health, and resiliency are at the core of our benefits and wellness programs. Our robust total rewards package makes it easier to take care of your whole self and your whole family. Were committed to providing programs and support that encourage personal and professional growth and care for you at work, at home, or wherever you may go. Learn more about our benefits .\n\nYoull also benefit from a supportive work culture that encourages you to learn, develop and grow your career as you take on challenges and drive innovative solutions for our customers.""We empower our team to push the boundaries of what is possible""”while learning every day in a supportive leading global company. Visit our Careers website to learn more about careers at Applied.\n\nAre you ready to take your career to the next levelJoin our dynamic team as a Strategy Leader at Applied Materials India and be a part of an innovative company that is revolutionising the industry! We are looking for a passionate and driven individual who is eager to make a significant impact and contribute to our continued success.\n\nApplied Materials is the leader in materials engineering solutions used to produce virtually every new chip and advanced display in the world. Our expertise in modifying materials at atomic levels and on an industrial scale enables customers to transform possibilities into reality. At Applied Materials, our innovations make possible the technology shaping the future..\n\nAs a Head of Strategy and Chief of Staff to President, Applied Materials India, you will play a crucial role in steering the companys growth, development, and attainment of strategic goals. Applied Materials is poised to make significant stides in going our capability and business presence in India as the semiconductor ecosystem evolves. We are looking for a high potential strategy leader who can partner closely with the President and senior leadership team to develop and execute our plans.\n\nYour role will be pivotal in shaping our multiyear journey to transform new product development and commercial growth to support our business interests locally, regionally and globally, while also helping to build a robust semiconductor ecosystem in India. Demonstrated success in this role will position you to take up senior leadership roles within the business as the Company grows.\n\nKey Responsibilities:\nBe a thought partner on strategy formulation and support local and corporate strategic initiatives.\nPartner with local and global BU leaders to execute strategy.\nConduct research and analysis, identify opportunities and threats, evaluate options and trade-offs, and develop strategic frameworks and models.\nDrive and oversee the progress of multiple strategic programs.\nSupport the preparation of strategic business cases and position Applied Materials internal and external ecosystem.\nBuild and nurture strong advisory relationships with key external and internal senior stakeholders, including influencing executives.\nDefine problems and strategic solutions - scope, analyze, prepare, and present strategy checks.\nAnalyze competitive dynamics, identify potential opportunities, and develop effective strategies\nEffectively translate strategic requirements into operational frameworks that can be deployed via the business and functional teams.\nLead engagements with technology and business partners as needed to execute strategic agenda.\nOpportunity for visibility with senior global leadership and possible travel to the US and Asia as needed to drive business results.\n\n\nQualifications:\nMinimum 4+ years tenure in a recognised strategy consulting business with an engineering background. Prior experience in engineering role in product oriented company will be preferred.\nDemonstrated experience and knowledge of strategic problem-solving frameworks and project management skills.\nWork experience in Electronics or Hardware engineering company.\nAbility to liaise with stakeholders and influence people from diverse backgrounds.\nExperience in applying strategic frameworks and tools for analyzing strategic problems and developing strategies.\nExcellent written and verbal communication skills with the ability to establish credibility and strong relationships with senior stakeholder..\nImpressive performance across a broad range of strategic engagements.\nStrong academic record, MBA Degree qualified, and bachelors degree in engineering from premier institutes will be given preference.\n\n\nWhy Join Us\n\n\nExciting OpportunitiesBe a part of groundbreaking projects that challenge and inspire you.\n\n\nCollaborative CultureWork alongside talented professionals who are passionate about what they do.\n\n\nGrowth and DevelopmentWe invest in your career growth and provide ample opportunities for advancement.\n\n\nPositive ImpactMake a difference and contribute to our mission of shaping the future of technology.\n\nApplied Materials is committed to diversity in its workforce, including Equal Employment Opportunity for Minorities, Females, Protected Veterans, and Individuals with Disabilities 19.\n\nAdditional Information\n\nTime Type:\nFull time\n\nEmployee Type:\nAssignee / Regular\n\nTravel:\n\nRelocation Eligible:\nNo\nApplied Materials is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, national origin, citizenship, ancestry, religion, creed, sex, sexual orientation, gender identity, age, disability, veteran or military status, or any other basis prohibited by law.",Industry Type: Electronic Components / Semiconductors,Department: Strategic & Top Management,"Employment Type: Full Time, Permanent","['operational framework', 'strategy development', 'opportunity identification', 'artificial intelligence', 'new product development', 'marketing', 'project management', 'strategic initiatives', 'hardware engineering', 'business development', 'strategy formulation', 'sales']",2025-06-11 06:08:46
Solutions Architect Cloud AI,"NTT DATA, Inc.",8 - 12 years,Not Disclosed,"['Chennai', 'Delhi / NCR', 'Bengaluru']","Your day at NTT DATA\nWe are seeking an exceptional Solution Architect/BDM specializing in Hyperscalers. This role requires deep expertise in cloud-based AI services and Large Language Models (LLMs) offered by major cloud providers. As our Cloud AI SME, you will assess client needs, recommend appropriate cloud AI technologies, size opportunities and cloud infrastructure requirements, and collaborate with delivery teams to create end-to-end solutions with accurate costing. This pivotal role demands a strategic thinker with strong technical knowledge and business acumen who can drive innovation and deliver exceptional value to our clients through cloud-based AI solutions.\nWhat you'll be doing\nKey Roles and Responsibilities:\nSolution Architecture & Technical Leadership\nDemonstrate deep expertise in cloud-based AI services and LLMs such as AWS Bedrock, Azure OpenAI Service, Google Vertex AI, and their supported models\nAssess client business requirements and translate them into detailed technical specifications leveraging hyperscaler AI capabilities\nRecommend appropriate cloud AI solutions based on specific business outcomes and use cases\nSize cloud infrastructure requirements and optimize cost models for AI workloads\nDesign scalable and secure Private AI architectures\nCreate technical POCs and prototypes on hyperscaler platforms to demonstrate solution capabilities\nExpertise in fine-tuning, query caching, and optimizing vector embeddings for efficient similarity searches\nBusiness Development\nSize and qualify opportunities in the Cloud AI space\nDevelop compelling proposals and solution presentations for cloud-based AI implementations\nBuild and nurture client relationships at technical and executive levels\nCollaborate with sales teams to create competitive go-to-market strategies\nIdentify new business opportunities through technical consultation on cloud AI solutions\nProject & Delivery Leadership\nWork with delivery teams to develop end-to-end solution approaches and accurate costing\nLead technical discovery sessions with clients\nGuide implementation teams during solution delivery\nEnsure technical solutions meet client requirements and business outcomes\nDevelop reusable solution components and frameworks to accelerate delivery\nAI Agent Development\nArchitect multi-agent systems that leverage cloud platform capabilities\nDevelop frameworks for agent orchestration, evaluation, and governance on cloud platforms\nDesign cloud-native agent solutions that integrate with existing enterprise systems\nImplement agent-based solutions using Cloud tools and services\n\n\nKnowledge, Skills, and Attributes:\nBasic Qualifications:\n8+ years of experience in solution architecture or technical consulting roles\n3+ years of specialized experience working with LLMs and Private AI solutions\nDemonstrated expertise with AWS or Azure or GCP AI/ML services\nStrong understanding of cloud infrastructure sizing, optimization, and cost management for AI workloads\nProven experience converting business requirements into technical specifications\nExperience working with delivery teams to create end-to-end solutions with accurate costing\nStrong understanding of agentic AI systems and orchestration frameworks\nBachelors degree in computer science, AI, or related field\nAbility to travel up to 25%\nPreferred Qualifications:\nMaster's degree or PhD in Computer Science or related technical field.\nCloud certifications such as:\nAWS: AWS Certified Solutions Architect, AWS Certified Machine Learning Specialty\nAzure: Microsoft Certified: Azure Solutions Architect Expert, Azure AI Engineer Associate\nGCP: Google Cloud Professional Cloud Architect, Professional Machine Learning Engineer\nExperience with autonomous agent development using cloud-based AI services\nExperience with deploying and fine-tuning LLMs on cloud platforms\nHands-on experience with prompt engineering and LLM optimization techniques\nUnderstanding of AI governance, security, and compliance requirements\nPrior experience in business development or pre-sales for AI solutions\nExcellent verbal and written communication skills, with the ability to explain complex technical concepts to non-technical stakeholders\nStrong problem-solving abilities and analytical mindset.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Solutions Architecture', 'Azure', 'GCP', 'Artificial Intelligence', 'cloud infrastructure', 'Technical Leadership', 'AWS', 'Machine Learning']",2025-06-11 06:08:48
Systems Integration Advisor -Technical Architecture-Cloud Services-AWS,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,['Bengaluru'],"Req ID: 284544\n\nWe are currently seeking a Systems Integration Advisor -Technical Architecture-Cloud Services-AWS to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n:\n\nWe are seeking a highly skilled and motivated Mid-Level AI/DS Specialist to join our dynamic team at NTT Data. The ideal candidate will have a strong background in artificial intelligence and data science, with expertise in natural language processing (NLP), generative AI (Gen-AI), and conversational AI. The candidate should be well-versed with the Microsoft AI platform, OpenAI, Databricks, Python, and common data science libraries and tools. Additionally, the candidate should be capable of fine-tuning large language models (LLMs) and familiar with AI/ML engineering and prompt engineering.\n\nKey Responsibilities:\nDevelop and implement AI/DS solutions to enhance business processes and customer experiences.\nUtilize NLP, Gen-AI, and conversational AI techniques to build and optimize AI models.\nWork with the Microsoft AI platform, OpenAI, and Databricks to develop and deploy AI solutions.\nWrite efficient and scalable code in Python, leveraging common data science libraries and tools.\nFine-tune LLM models to meet specific project requirements.\nCollaborate with cross-functional teams to integrate AI/DS solutions into existing systems.\nStay updated with the latest advancements in AI/DS and apply them to ongoing projects.\nConduct prompt engineering to improve the performance and accuracy of AI models.\n\n\nQualifications:\nBachelor's or Master's degree in Computer Science, Data Science, AI, or a related field.\nProven experience in AI/DS, with a focus on NLP, Gen-AI, and conversational AI.\nProficiency in the Microsoft AI platform, OpenAI, Databricks, and Python.\nStrong knowledge of common data science libraries and tools.\nExperience in fine-tuning LLM models.\nFamiliarity with AI/ML engineering and prompt engineering.\nExcellent problem-solving skills and attention to detail.\nStrong communication and collaboration skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'artificial intelligence', 'data bricks', 'data science', 'scala', 'numpy', 'machine learning', 'hibernate', 'sql', 'dataproc', 'pandas', 'gen', 'tensorflow', 'system integration', 'java', 'gcp', 'spark', 'computer vision', 'j2ee', 'ai platform', 'bigquery', 'data flow']",2025-06-11 06:08:50
APAC Presales Solution Architect,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 328244\n\nWe are currently seeking a APAC Presales Solution Architect to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesSenior Data and AI Architect ""“ Presales\nGrade 11\n\nSeeking a senior data solution architect to closely work with India and APAC sales teams for technical solutioning and presales work.\n\nThe Consultant is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n\nMinimum Skills Required""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\n""¢ Academic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\n""¢ Required Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop On-prem, Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n\n""¢ Additional\n""¢ Knowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\n""¢ Problem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\n""¢ Interaction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject m""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['client engagement', 'data architecture', 'change management', 'artificial intelligence', 'service orientation', 'needs assessment', 'architecting', 'python', 'project management', 'rfqs', 'togaf', 'aiml', 'market research', 'presales', 'solution architecting', 'gen', 'solution design', 'aws', 'rfp', 'ml']",2025-06-11 06:08:51
Automation Anywhere Senior Developer,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['Bengaluru'],"Req ID: 318719\n\nWe are currently seeking a Automation Anywhere Senior Developer to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nRoles & Responsibilities:\n5+ years of Automation Anywhere development in the enterprise software space, agile methodologies\nWork independently or under the direction of Architect/Leadership.\nDesign and develop solutions utilizing Automation Anywhere Tool and maintain technical responsibility for project delivery as the sole technical resource on a project\nStrong technical leadership skills in evaluating Software Solutions, and following best practices in architectural design and applying design patterns\nExperience in RPA infrastructure setup is a plus\nGood understanding of attended vs unattended robotics implementations\nKnowledge of Citrix environment with RPA Tools\nKnowledge of OCR libraries or tools (eg., ABBYY..).\nExcellent interpersonal and relationship building skills to deliver proposals; provide user support and interact with team members and other departments\nFlexible and agile attitude in respect to responsibilities and change that may be outside your control\nFlexible and adaptable, the individual will be open to learning new methodologies, tools, platforms and systems\n\n\n\nMinimum Skills RequiredAutomation Anywhere - 5+",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['rpa', 'technical leadership', 'relationship building', 'automation anywhere', 'agile methodology', 'c#', 'python', 'abbyy', 'robotics', 'rpa tool', 'machine learning', 'blue prism', 'sql server', 'sql', 'java', 'infrastructure setup', 'vba', 'asp.net', '.net', 'uipath', 'robotic process automation', 'citrix']",2025-06-11 06:08:53
Digital Solution Arch. Strategic Advisor,"NTT DATA, Inc.",2 - 6 years,Not Disclosed,['Bengaluru'],"Req ID: 324078\n\nWe are currently seeking a Digital Solution Arch. Strategic Advisor to join our team in Bengaluru, India, Karntaka (IN-KA), India (IN).\n\nMandatory Qualifications\nDeep understanding of manufacturing processes, retail supply chains, CPG go-to-market models, and telecom operations.\nExperience in ecommerce platforms (Magento, Salesforce Commerce, SAP Commerce), and Manufacturing IT (MES, PLM, IoT).\nPresales leadership for multi-million-dollar digital and cloud transformation deals.\nExcellent executive engagement, solution storytelling, and value proposition articulation skills.\n\n\n\nPreferred Qualifications\nCertifications like AWS Manufacturing and Industrial Specialization, Salesforce B2B Commerce Specialist, or similar.\nFamiliarity with supply chain planning platforms, OMS (Order Management Systems), and Edge AI solutions.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['manufacturing processes', 'order management system', 'cpg', 'retail supply chain', 'ocs', 'chatbot', 'risk management', 'risk assessment', 'sap', 'ai solutions', 'presales', 'machine learning', 'salesforce', 'solution consulting', 'supply chain planning', 'digital transformation', 'magento']",2025-06-11 06:08:55
MS Technical Specialist - Wireless,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Networking Managed Services Engineer (L3) is a seasoned engineering role, responsible for providing a managed service to clients by proactively identifying and resolving technical incidents and problems.\n\nThrough pre-emptive service incident and resolution activities, as well as product reviews, operational improvements, operational practices, and quality assurance this role maintains a high level of service to clients.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and is responsible for managing tickets of high complexity, conducts advanced and complicated tasks, and provides resolution to a diverse range of complex problems.\n\nThis position uses considerable judgment and independent analysis within defined policies and practices and applies analytical thinking and deep technical expertise in achieving client outcomes, while coaching and mentoring junior team members across functions.\n\nThe Networking Managed Services Engineer (L3) may also contribute to support on project work as and when required.\nWhat you'll be doing\nKey Responsibilities:\nEnsures that assigned infrastructure at the client site is configured, installed, tested, and operational\nPerforms necessary checks, apply monitoring tools and respond to alerts.\nIdentifies problems and errors prior to or when it occurs and log all such incidents in a timely manner with the required level of detail.\nAssists in analyzing, assigning, and escalating support calls.\nInvestigates third line support calls assigned and identify the root cause of incidents and problems\nReports and escalates issues to 3rd party vendors if necessary.\nProvides onsite technical support to clients and provide field engineering services to clients.\nConducts a monthly random review of incidents and service requests, analyze and recommend improvement in quality.\nProvides continuous feedback to clients and affected parties and update all systems and/or portals as prescribed by the company.\nProactively identifies opportunities for work optimization including opportunities for automation of work.\nMay manage and implement projects within technology domain, delivering effectively and promptly per client agreed upon requirements and timelines.\nMay work on implementing and delivering Disaster Recovery functions and tests.\nPerforms any other related task as required.\n\nKnowledge and Attributes:\nAbility to communicate and work across different cultures and social groups.\nAbility to plan activities and projects well in advance, and takes into account possible changing circumstances.\nAbility to maintain a positive outlook at work.\nAbility to work well in a pressurized environment.\nAbility to work hard and put in longer hours when it is necessary.\nAbility to apply active listening techniques such as paraphrasing the message to confirm understanding, probing for further relevant information, and refraining from interrupting.\nAbility to adapt to changing circumstances.\nAbility to place clients at the forefront of all interactions, understanding their requirements, and creating a positive client experience throughout the total client journey.\nAdditional skills proficiency such as (but not limited to) -\nPulse Secure SSL VPN Virtual Juniper, Palo Alto, Fortinet Firewalls Cisco Nexus switches, ASR and ISR routers Cisco ACS, ISE Meraki switches and access points Enterprise network architecture Common routing protocols: BGP,OSPF, EIGRP Network address translation Configuring, monitoring and troubleshooting uplinks to ISPs for DIA, MPLS and P2P circuits Familiarity with common network management and monitoring tools such as SecureCRT, Logic Monitor.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCCNP or equivalent certification.\nCertifications relevant to the services provided (certifications carry additional weightage on a candidates qualification for the role).\n\nRequired Experience:\nSeasoned experience required in Engineering function within a medium to large ICT organization.\nSeasoned experience of Managed Services.\nSeasoned working knowledge of ITIL processes.\nSeasoned experience working with vendors and/or 3rd parties.\nWorkplace type:\nHybrid Working",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Networking', 'eigrp', 'software testing', 'bgp', 'mentoring', 'ospf', 'artificial intelligence', 'cisco acs', 'fortigate firewall', 'technical support', 'cisco nexus switches', 'technology consulting', 'troubleshooting', 'wireless', 'itil']",2025-06-11 06:08:56
Digital Solution Architect Sr. Advisor,"NTT DATA, Inc.",10 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 323226\n\nWe are currently seeking a Digital Solution Architect Sr. Advisor to join our team in Bengaluru, India, Karntaka (IN-KA), India (IN).\n\nKey Responsibilities:\nDesign data platform architectures (data lakes, lakehouses, DWH) using modern cloud-native tools (e.g., Databricks, Snowflake, BigQuery, Synapse, Redshift).\nArchitect data ingestion, transformation, and consumption pipelines using batch and streaming methods.\nEnable real-time analytics and machine learning through scalable and modular data frameworks.\nDefine data governance models, metadata management, lineage tracking, and access controls.\nCollaborate with AI/ML, application, and business teams to identify high-impact use cases and optimize data usage.\nLead modernization initiatives from legacy data warehouses to cloud-native and distributed architectures.\nEnforce data quality and observability practices for mission-critical workloads.\n\nRequired\n\nSkills:\n\n10+ years in data architecture, with strong grounding in modern data platforms and pipelines.\nDeep knowledge of SQL/NoSQL, Spark, Delta Lake, Kafka, ETL/ELT frameworks.\nHands-on experience with cloud data platforms (AWS, Azure, GCP).\nUnderstanding of data privacy, security, lineage, and compliance (GDPR, HIPAA, etc.).\nExperience implementing data mesh/data fabric concepts is a plus.\nExpertise in technical solutions writing and presenting using tools such as Word, PowerPoint, Excel, Visio etc.\nHigh level of executive presence to be able to articulate the solutions to CXO level executives.\n\nPreferred Qualifications:\nCertifications in Snowflake, Databricks, or cloud-native data platforms.\nExposure to AI/ML data pipelines, MLOps, and real-time data applications.\nFamiliarity with data visualization and BI tools (Power BI, Tableau, Looker, etc.).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'nosql', 'spark', 'kafka', 'etl', 'metadata management', 'microsoft azure', 'power bi', 'data warehousing', 'data architecture', 'elt', 'machine learning', 'distributed architecture', 'tableau', 'gcp', 'visio', 'data governance', 'platform architecture', 'data visualization', 'aws']",2025-06-11 06:08:58
Digital Solution Architect Sr. Advisor,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Bengaluru'],"Req ID: 324311\n\nWe are currently seeking a Digital Solution Architect Sr. Advisor to join our team in Bengaluru, India, Karntaka (IN-KA), India (IN).\n\nWe are seeking an experienced solution architect specializing in technology based business process solutions to join our dynamic Digital BPS team at NTT DATA. As an SME (subject matter expert), you will closely work with NTT DATA""™s customers to understand their business problems and engage with them to provide consulting and solutioning for solving their business problems using AI and Automation related technologies. Design and implement effective AI technologies and methods to address clients' business problems and needs, while complying with company's strategies, business goals, and key ethical considerations. Your engagement with the customer should give the customer confidence that NTT DATA is the right business and technology partner for their operation.\n\n\n\nExperience Requirement\n10+Experience in solution architecture with an emphasis on business process services\n7+ Experience in north America healthcare insurance and provider industry.\n3+ years of experience with automation and machine learning solutions.\n5+ Years in financial cost modelling.\nExperience with creating and communicating business value prop to executive in both oral and written format.\n\nResponsibilities\nBe a solution architecture/designer for business process service.\nIndependently able to solution and respond to RFP""™s.\nProvide solution and technology consulting and drive opportunities for leveraging GenAI, AI based solutions on various platforms\nDrive close discussions with client and draw technical and functional requirements through workshops with stakeholders\nDevelop Point of Views that provide details of scope, due-diligence, approach and business/cost benefit.\nCollaborate with NTT DATA Global business and stakeholders\n\nQualifications\nBachelors / Masters / PhD degree in Computer Science or related field\nCertification or Degree with AI and machine learning.\n\nSkills\nExcellent communication and articulation in English language\nStrong excel and math acumen.\nExcellent problem-solving and analytical skills.\nEnthusiasm for AI/ML technologies and a proactive attitude towards learning and staying updated.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['healthcare insurance', 'machine learning', 'artificial intelligence', 'english language', 'technology consulting', 'project management', 'due diligence', 'us healthcare', 'technical drawing', 'autocad', 'ehr', 'construction management', 'claims processing', 'civil engineering']",2025-06-11 06:09:00
Ml Engineer,Ltimindtree,6 - 9 years,Not Disclosed,"['Pune', 'Bengaluru', 'Mumbai (All Areas)']","Job Title: Data Scientist\n\nLooking for someone with 5-8 years of experience manipulating data sets and building statistical models\n\nDesired Skills:\n\nExperience using statistical computer languages (R, Python, etc.) to manage data and draw insights from large data sets.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, XGBoost, KNN, SVM, ANN, etc.).\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modelling, clustering, decision trees, neural networks, etc.\nExperience visualizing/presenting data for stakeholders.\nExperience with Snowflake will be an added advantage.\nExperience in deployment of machine learning models using cloud technologies.\n\nRoles and responsibilities:\n\n1. Work with stakeholders to identify opportunities for leveraging data to drive business solutions.\n2. Mine and analyse data from databases to drive optimization and improvement of product development and business strategies.\n3. Assess the effectiveness and accuracy of new data sources and data gathering techniques.\n4. Develop custom models and algorithms to apply to data sets.\n5. Use predictive modelling to increase and optimize customer experiences.\n6. Coordinate with different functional teams to implement models and monitor outcomes.\n7. Analyse large amounts of information to discover trends and patterns.\n8. Build predictive models and machine-learning algorithms.\n9. Present information using data visualization techniques .\n10. Good to have a knowledge of ML lifecycle and model governance.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'R', 'Python']",2025-06-11 06:09:01
Python developer - Infosys @ Pan India,Infosys,2 - 7 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTech",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Python Development']",2025-06-11 06:09:03
Python Software Developer-AB Pan India,Infosys,3 - 8 years,Not Disclosed,"['Kolkata', 'Pune', 'Bengaluru']","Responsibilities\n\nA day in the life of an Infoscion\n• As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain.\n• You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers.\n• You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements:\n\n• Primary skills: Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities:\n• Knowledge of design principles and fundamentals of architecture\n• Understanding of performance engineering\n• Knowledge of quality processes and estimation techniques\n• Basic understanding of project domain\n• Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs\n• Ability to write test cases and scenarios based on the specifications\n• Good understanding of SDLC and agile methodologies\n• Awareness of latest technologies and trends\n• Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational Requirements MCA, MSc, MTech, Bachelor of Engineering, BCA, BSc, BTech\nLocation- PAN INDIA",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Python', 'Flask']",2025-06-11 06:09:05
Senior AI Scientist,Confidential,4 - 9 years,40-80 Lacs P.A.,"['Bengaluru', 'Mumbai (All Areas)']","Design & develop end-to-end machine learning models & GenAI workflows\nFetch & process data from BigQuery & various sources for model development\nBuild & deploy models using Python & frameworks like Scikit Learn, XGBoost/CatBoost, TensorFlow & Gemini\n\nRequired Candidate profile\n4+ years of experience in the Data Science domain and should have hands on exp in Python, Machine Learning and/or Generative AI (Artificial Intelligence)\nThis is an Individual contributor role",Industry Type: NBFC,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Generative Ai', 'Artificial Intelligence', 'data scientist', 'Machine Learning', 'Python']",2025-06-11 06:09:06
Python Developer -ENG - Infosys@ PAN India,Infosys,3 - 8 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills:Technology->Machine Learning->Python\n\nPreferred Skills: Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\nEducational RequirementsMCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTech responsibilities",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Django', 'Python Development', 'Python', 'Django Framework']",2025-06-11 06:09:08
Proactive Hiring For Databricks,HCLTech,5 - 10 years,Not Disclosed,"['Noida', 'Chennai', 'Bengaluru']","Responsibilities\nLead the design, development, and implementation of big data solutions using Apache Spark and Databricks.\nArchitect and optimize data pipelines and workflows to process large volumes of data efficiently.\nUtilize Databricks features such as Delta Lake, Databricks SQL, and Databricks Workflows to enhance data processing and analytics capabilities.",,,,"['apache spark', 'Databricks Engineer', 'SQL']",2025-06-11 06:09:09
A reputed FMCG company hiring software Engineer Bangalore location,ontimesolutions,3 - 5 years,4-9 Lacs P.A.,['Bengaluru'],"Greetings\n\nWe are currently hiring software engineers for our FMCG client\n\nPermanent position\n\nQualification: Btech Computers - from Tier 1/Tier 2 Engineering colleges\n\nKnowledge/experience with web development frameworks (e.g., React, Angular, or Vue.js) and back-end technologies (e.g., Node.js, .NET, Django) is an added advantage.\nFamiliarity with database management systems (e.g., SQL, NoSQL) is important.\nKnowledge of cloud platforms (e.g., AWS, Azure, Google Cloud) & Data Engineering technology is important\nStrong problem-solving skills and the ability to work both independently and collaboratively in a team environment.\nExcellent communication skills to effectively convey technical concepts to non-technical stakeholders.\nBachelors degree in Computer Science, Engineering, or a related field, from a leading engineering college in India.\nProficiency in one or more programming languages, such as Python. • Medium to high proficiency in AI tech stack (TensorFlow, LLMs, conversational AI etc.) as well as data processing frameworks.\nExperience with AI and ML platforms such as Google AI Platform, AWS SageMaker, or Microsoft Azure AI services.\nFamiliarity with tools and libraries specifically designed for generative AI, such as GPT/Gemini/Claude etc. WHAT WE EXPECT\n\nKindly share cv to susmitha@ontimesolutions.in",Industry Type: FMCG,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Machine Learning', 'Python', 'SQL', 'Artificial Intelligence']",2025-06-11 06:09:11
Generative AI Engineer,Bebo Technologies,3 - 8 years,Not Disclosed,"['Chandigarh', 'Delhi / NCR']","Key Responsibilities:\nDesign and development of AI-driven applications using frameworks such as LangChain, LangGraph, CrewAI, AutoGPT, and Autogen.\nBuild and maintain RESTful APIs, GraphQL endpoints, and gRPC services to support scalable AI features.\nSupport the development of intelligent agents and multi-agent collaboration mechanisms.\nImplement reasoning techniques including ReAct, Chain-of-Thought (CoT), and Tree-of-Thought (ToT) as part of AI workflows.\nContribute to retrieval-augmented generation (RAG) pipelines using vector stores like Weaviate, Pinecone, FAISS, or ChromaDB.\nIntegrate tool-use APIs, function calling, MCP, and external workflows via tools like Zapier or N8N.\nWork with orchestration tools such as Airflow, Ray, or Temporal to manage agent workflows and data pipelines.\nCollaborate with AI/ML engineers, product managers, and other developers in building intelligent, production-grade applications.\nRequired Qualifications:\n3-5 years of backend or full-stack development experience, with working on Generative or Agentic AI solutions.\nProficiency in Python (preferred), with working knowledge of TypeScript/Node.js, Go, or Java.\nHands-on experience developing REST APIs, GraphQL endpoints, and/or gRPC-based services.\nFamiliarity with integrating LLMs like GPT-4, Claude, Gemini, Mistral, or LLaMA.\nExposure to frameworks such as LangChain, LlamaIndex, or CrewAI.\nBasic understanding of vector databases and semantic search tools (e.g., FAISS, Pinecone).\nExperience working in cloud environments (AWS, GCP, Azure) and with containerization tools (Docker, Kubernetes).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['langchain', 'Crewai', 'Langgraph', 'Python']",2025-06-11 06:09:13
Back Office- Sector Fifty Nine Noida- Walk in-10th-14th June,Cogito Tech,0 - 1 years,Not Disclosed,['Noida'],"Cogito is currently working on Artificial Intelligence applications in Annotation work and is looking to engage with candidates to participate in ongoing projects.\n\nTotal Openings: 80\n\nWork Type: Back Office\n\n\nDesignation: Data Annotator/Back Office Executive\nGender: Male/Female\nCTC:\nDAY: Rs, 13,900 Per Month\nNIGHT: Rs, 15,900 Per Month\nExtra Benefit: Yearly bonus\n\n\nNOTE:\n\nFreshers are eligible.\n\nDirect Walk in Interview dates: 10th -14th June\nInterview Time: 9:00 am to 5:00 pm\n\nInterview Venue -\nCogito\nC-40, C Block\nSector- 59\nNoida-UP- 201307\n\nOld Landmark: R Systems (Red Building)\n\nContact @ HR Department (Basement Area)\n\n-----\nRegards\nTeam HR",Industry Type: BPM / BPO,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Bpo Operations', 'Artificial Intelligence', 'Back Office', 'Back Office Support', 'Non Voice', 'Backend', 'Bpo Backoffice', 'Back Office Processing', 'Back Office Operations', 'Backend Operations', 'Bpo Non Voice', 'Data Entry']",2025-06-11 06:09:14
Scrum Master,"NTT DATA, Inc.",2 - 6 years,Not Disclosed,['Bengaluru'],"Knowledge and application:\nSeasoned, experienced professional; has complete knowledge and understanding of area of specialization.\nUses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\nWorks on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\nResolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\nEnhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\nWorks with others outside of own area of expertise, with the ability to adapt style to differing audiences and often advises others on difficult matters.\nImpact:\nImpacts short to medium term goals through personal effort or influence over team members.\nAccountability:\nAccountable for own targets with work reviewed at critical points.\nWork is done independently and is reviewed at critical points.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Scrum Master', 'project management', 'program management', 'business analysis', 'artificial intelligence', 'jira']",2025-06-11 06:09:16
Technical Lead-Analytics,3i Infotech,5 - 10 years,Not Disclosed,"['Navi Mumbai', 'Bengaluru', 'Greater Noida']","Analytics Tech Lead Job Description\nAnalytics Tech Lead with a 6 years of relevant experience, who will be responsible for designing, developing, and maintaining Machine Learning use cases, data visualization solutions. Experience in Banking Industry and a good understanding of Core Banking systems/flow is preferred.\nResponsibilities\n•         Experienced in develop Machine Learning Model use cases using Python and other ML tools. \n•         Enabling clients with AI/ML solutions that seamlessly cater their business needs of data-driven decision results. I\nExperienced in designing data exploration & storyline-based analytics dashboard/wireframes/prototypes using Tableau\nAdvanced Tableau development skills, including experience with Tableau Desktop and Server latest version and expert knowledge of Tableau software optimization and configuration.\nExperience working with Tableau server and user management, performance tuning, security in Tableau server.\nImplemented data modelling, data blending, and custom query joins to enhance dashboard interactivity and functionality. \nExperience with Structured Query Language,  data analysis, data profiling, data validation.\nWork with cross-functional teams, including business analysts and data engineers to understand requirements and develop solutions.\nPrepare technical documentation on the deliverables.\nSkills and Qualifications\nBachelors degree in computer science or Master of Computer Applications with 6+ years of relevant experience.\nAI/ML tool  Certification \nExcellent written, verbal and presentation skills to foster clarity and predictability.\nExperience working with a global team in different time zones.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Machine Learning', 'Analytics', 'Python', 'Ml']",2025-06-11 06:09:18
Solutions Architect AI/ML,"NTT DATA, Inc.",10 - 14 years,Not Disclosed,"['Chennai', 'Delhi / NCR', 'Bengaluru']","Your day at NTT DATA\nWe are seeking an experienced Solution Architect/Business Development Manager with expertise in AI/ML to drive business growth and deliver innovative solutions. The successful candidate will be responsible for assessing client business requirements, designing technical solutions, recommending AI/ML approaches, and collaborating with delivery organizations to implement end-to-end solutions.\nWhat you'll be doing\nKey Responsibilities:\nBusiness Requirement Analysis: Assess client's business requirements and convert them into technical specifications that meet business outcomes. AI/ML Solution Design: Recommend the right AI/ML approaches to meet business requirements and design solutions that drive business value. Opportunity Sizing: Size the opportunity and develop business cases to secure new projects and grow existing relationships. Solution Delivery: Collaborate with delivery organizations to design end-to-end AI/ML solutions, ensuring timely and within-budget delivery.\nCosting and Pricing: Develop costing and pricing strategies for AI/ML solutions, ensuring competitiveness and profitability. Client Relationship Management: Build and maintain strong relationships with clients, understanding their business needs and identifying new opportunities.\nTechnical Leadership: Provide technical leadership and guidance to delivery teams, ensuring solutions meet technical and business requirements.\nKnowledge Sharing: Share knowledge and expertise with the team, contributing to the development of best practices and staying up-to-date with industry trends. Collaboration: Work closely with cross-functional teams, including data science, engineering, and product management, to ensure successful project delivery.\nRequirements:\nEducation: Master's degree in Computer Science, Engineering, or related field Experience: 10+ years of experience in AI/ML solution architecture, business development, or a related field\nTechnical Skills: Strong technical expertise in AI/ML, including machine learning algorithms, deep learning, and natural language processing.\nTechnical Skills: Solid grasp of data munging techniques, including data cleaning, transformation, and normalization to ensure data quality and integrity\nTechnical Skills: Hands-on implementing various machine learning algorithms such as linear regression, logistic regression, decision trees, and clustering algorithms\nHyperscaler: Experience with cloud-based AI/ML platforms and tools (e.g., AWS SageMaker, Azure Machine Learning, Google Cloud AI Platform)\nSoftskill: Excellent business acumen and understanding of business requirements and outcomes Softskill: Strong communication and interpersonal skills, with ability to work with clients and delivery teams Business Acumen: Experience with solution costing and pricing strategies with\nStrong analytical and problem-solving skills, with ability to think creatively and drive innovation\nNice to Have:\nExperience with Agile development methodologies\nKnowledge of industry-specific AI/ML applications (e.g., healthcare, finance, retail)\nCertification in AI/ML or related field (e.g., AWS Certified Machine Learning Specialty)",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Solutions Architecture', 'algorithms', 'deep learning', 'Azure', 'natural language processing', 'AWS SageMaker', 'business development', 'Machine Learning']",2025-06-11 06:09:19
Senior Software Engineer,Magnit Global,3 - 8 years,Not Disclosed,['Bengaluru'],"Senior AI & ML Platform Engineer\nLocation: Bengaluru\nExperience Level: 3 to 10 Years\n\nAbout the Role\nWe are building next-generation AI-powered platforms that leverage Large Language Models (LLMs), advanced Machine Learning (ML), NLP, and agentic workflows to automate critical business processes across multiple domains.\nWe are looking for experienced AI/ML Engineers who are passionate about building real-world AI productsnot just experimenting. You will help design, prototype, and deploy intelligent systems integrating LLMs, agents, APIs, and robust ML models for classification, prediction, and optimization.\n\nResponsibilities\nBuild and integrate agentic AI workflows using LangChain or similar frameworks.\nDevelop APIs and backend services to support LLM and ML-driven platforms.\nImplement, train, and optimize lightweight and scalable ML models for classification, prediction, and anomaly detection.\nWork with LLMs (OpenAI, Claude, Gemini) to fine-tune prompts, create retrieval-augmented generation (RAG) systems, and chain multi-step tasks.\nDesign and optimize vector search implementations for LLM-driven applications.\nIntegrate AI models with external systems (VMS platforms, ERP systems) using APIs.\nImplement document processing pipelines combining OCR with LLM/ML validation.\nApply ML techniques for supply-demand forecasting, fraud detection, and optimization.\nParticipate in design discussions, brainstorming sessions, and agile sprints.\nCollaborate with senior AI architects and SMEs to refine platform capabilities.\nRequired Skills\nStrong experience in Python for ML and AI development.\nExpertise in ML frameworks such as TensorFlow, PyTorch, scikit-learn.\nKnowledge of NLP tasks (text extraction, classification, summarization).\nExperience building and optimizing RAG workflows with vector databases.\nSolid understanding of API development (FastAPI, Flask, or similar frameworks).\nFamiliarity with prompt engineering and agent orchestration concepts.\nAbility to build scalable ML models for classification, forecasting, and anomaly detection.\nExperience integrating ML solutions with cloud services (AWS, Azure, GCP).\nKnowledge of OCR tools and techniques for document processing.\nExposure to multi-agent architectures and reinforcement learning is a plus.\nUnderstanding of feature engineering, model evaluation, and optimization techniques.\nMindset We Are Looking For\nBuilders mindset: You love turning ideas into working solutions fast.\nCuriosity: Passionate about keeping up with the latest in GenAI and ML.\nProblem-solver: Comfortable working in ambiguous environments where solutions need discovery, not just execution.\nCollaboration: Open to learning from senior architects and iterating based on feedback.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Agentic Ai', 'ML Modeling', 'Generative Ai', 'LLM', 'Python']",2025-06-11 06:09:21
Cloud Engineer,NetApp,3 - 5 years,Not Disclosed,['Bengaluru'],"Job Summary\nWe are seeking a skilled and innovative Cloud Engineer to join our team. As a Cloud Engineer, you will be responsible for developing and maintaining cloud-based solutions, with a focus on coding complex problems, automation using Golang and Python, and collaborating with the Site Reliability Engineering (SRE) team for feature deployment in production. Additionally, the ideal candidate should be proficient in utilizing AI tools like Copilot to enhance productivity in the areas of automation, documentation, and unit test writing.\n",,,,"['continuous integration', 'kubernetes', 'golang', 'interpersonal skills', 'ci/cd', 'artificial intelligence', 'microservices', 'docker', 'sql', 'cloud', 'java', 'gcp', 'devops', 'design', 'jenkins', 'programming', 'communication skills', 'rest', 'cd', 'python', 'ai solutions', 'elk', 'microsoft azure', 'aws cloudformation', 'terraform', 'agile', 'aws']",2025-06-11 06:09:23
Security Consultant ( Operational Technology Security ),"NTT DATA, Inc.",3 - 6 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Security Consultant is a seasoned level role, responsible for translating clients cybersecurity requirements and customizing and implementing security solutions into specific systems, applications and product designs.\n\nThis role identifies and develops the security solutions for clients using company products, outsourced technology solutions and technical tools.\n\nThis role consults with clients regarding secure product configuration, deployment, and security patches to minimize security vulnerabilities and provides comprehensive scanning, penetration testing, vulnerability assessments, monitoring services and source code analysis and delivers detailed results to clients.\n\nThis role guides and supports clients in the development and implementation of product security controls.\nWhat you'll be doing\nKey Responsibilities:\nWorks on strategic projects that ensure the efficient and effective reaction to security breaches to mitigate immediate and potential threats.\nUses mitigation, preparedness, response and recovery approaches to minimize business disruptions and commercial consequences.\nOffers detailed technical support investigation and analysis response activities and evaluate the effectiveness of and improvements to existing practices.\nConducts regular threat and vulnerability assessments and determine deviations from acceptable configurations or policies.\nParticipates in the assessment of the level of risk and support the development of appropriate mitigation countermeasures in operational and non-operational situations.\nAnalyzes evidence to support network vulnerability mitigation.\nSupports peers in the management and implementation of the information security management system.\nParticipates in the implementation of policies, processes and guidelines to ensure the standardization of security management throughout the organization.\nApplies tactics, techniques, and procedures to a full range of tools and processes related to administrative, criminal, and counterintelligence gathering (e.g., in-depth case analyses, continuous monitoring, malware analysis, clear documentation).\nProactively searches through our critical infrastructure, systems and networks to detect and isolate advanced threats that may cause harm to our organization.\nUse both manual approaches and automated tools to identify, analyze, and report events and support the development of countermeasures to proactively protect against these threats in the future.\n\nKnowledge and Attributes:\nStrong understanding of information technology and information security\nSolid understanding of security risks and preventative controls\nExcellent understanding of security operational processes and controls\nService consulting aptitude, focusing on the business, service and sales aspects\nExcellent verbal and written communication skills\nDemonstrate impeccable attention to detail are able to translate internal customer requirements into solutions\nMaintain up-to-date knowledge of security threats, countermeasures, security tools, and network technologies\nHigh level of drive and ability to work under pressure\nAbility to build and maintain cross-functional relationships with a variety of stakeholders\nUnderstanding of relevant laws, regulations, and compliance frameworks affecting the technology sector.\nGood ability to assess and manage cybersecurity risks at both organizational and project levels.\nGood knowledge of security frameworks and standards like NIST, ISO/IEC 27001, CIS, etc.\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent in Information Technology or Computer Science or Engineering or related field.\nIndustry relevant certifications such as CISSP, CISM, CEH, GSEC or CompTIA Security+ essential.\n\nRequired Experience:\nSeasoned demonstrable experience in the Information Technology Security Industry or relevant experience in similar role within a related environment.\nSeasoned experience with security architecture design principles.\nSeasoned experience with industry compliance and standards such as ISO 27000, PCI DSS, NIST, HIPAA or others.\nSeasoned experience with security tools and techniques to cover SANS Top 25, OWASP or others.\nSeasoned experience working in a multi-team environment across multiple geographies.\nWorkplace type:\nHybrid Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Operational Technology Security', 'security compliance', 'information technology', 'hipaa', 'owasp', 'information security', 'vulnerability assessment', 'cissp', 'technology solutions', 'artificial intelligence', 'nist', 'application management', 'technology consulting', 'penetration testing', 'pci dss']",2025-06-11 06:09:24
Solutions Architect,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,"['New Delhi', 'Chennai', 'Bengaluru']","Your day at NTT DATA\nWe are seeking an experienced Data Architect to join our team in designing and delivering innovative data solutions to clients. The successful candidate will be responsible for architecting, developing, and implementing data management solutions and data architectures for various industries. This role requires strong technical expertise, excellent problem-solving skills, and the ability to work effectively with clients and internal teams to design and deploy scalable, secure, and efficient data solutions.\nWhat you'll be doing\nWe are seeking an experienced Data Architect to join our team in designing and delivering innovative data solutions to clients. The successful candidate will be responsible for architecting, developing, and implementing data management solutions and data architectures for various industries. This role requires strong technical expertise, excellent problem-solving skills, and the ability to work effectively with clients and internal teams to design and deploy scalable, secure, and efficient data solutions.\nExperience and Leadership:\nProven experience in data architecture, with a recent role as a Lead Data Solutions Architect, or a similar senior position in the field.\nProven experience in leading architectural design and strategy for complex data solutions and then overseeing their delivery.\nExperience in consulting roles, delivering custom data architecture solutions across various industries.\nArchitectural Expertise:\nStrong expertise in designing and overseeing delivery of data streaming and event-driven architectures, with a focus on Kafka and Confluent platforms.\nIn-depth knowledge in architecting and implementing data lakes and lakehouse platforms, including experience with Databricks and Unity Catalog.\nProficiency in conceptualising and applying Data Mesh and Data Fabric architectural patterns.\nExperience in developing data product strategies, with a strong inclination towards a product-led approach in data solution architecture.\nExtensive familiarity with cloud data architecture on platforms such as AWS, Azure, GCP, and Snowflake.\nUnderstanding of cloud platform infrastructure and its impact on data architecture.\nData Technology Skills:\nA solid understanding of big data technologies such as Apache Spark, and knowledge of Hadoop ecosystems.\nKnowledge of programming languages such as Python or R is beneficial.\nExposure to ETL/ ELT processes, SQL, NoSQL databases is a nice-to-have, providing a well-rounded background.\nExperience with data visualization tools and DevOps principles/tools is advantageous.\nFamiliarity with machine learning and AI concepts, particularly in how they integrate into data architectures.\nDesign and Lifecycle Management:\nProven background in designing modern, scalable, and robust data architectures.\nComprehensive grasp of the data architecture lifecycle, from concept to deployment and consumption.\nData Management and Governance:\nStrong knowledge of data management principles and best practices, including data governance frameworks.\nExperience with data security and compliance regulations (GDPR, CCPA, HIPAA, etc.)\nLeadership and Communication:\nExceptional leadership skills to manage and guide a team of architects and technical experts.\nExcellent communication and interpersonal skills, with a proven ability to influence architectural decisions with clients and guide best practices\nProject and Stakeholder Management:\nExperience with agile methodologies (e.g. SAFe, Scrum, Kanban) in the context of architectural projects.\nAbility to manage project budgets, timelines, and resources, maintaining focus on architectural deliverables.\nLocation: Delhi or Bangalore\nWorkplace type:\nHybrid Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Solution architecture', 'snowflake', 'python', 'data management', 'big data technologies', 'microsoft azure', 'data architecture', 'sql', 'data bricks', 'spark', 'gcp', 'devops', 'kanban', 'kafka', 'architectural patterns', 'scrum', 'agile', 'hadoop', 'conceptualization', 'aws', 'etl', 'data lake']",2025-06-11 06:09:26
Senior Services Architect,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,['Bengaluru'],"Key Responsibilities:\nGuides a virtual team of domain experts to orchestrate the development of secure, multiple year, services solutions.\nDesigns complex service solutions to meet client requirements by integrating technology and service design across multiple domains.\nWorks across multiple teams in the design of the Support & Technical Services offering.\nTests and validates new designs features and delivery models or recommend improving existing service offers that is being taken to market.\nResponsible for the service design deliverables of the solution and interfacing with multiple teams and partners to ensure supportability.\nDirects the validation processes by obtaining sign-off from technical, service and costing stakeholders.\nLeads the service design of solutions for the client that will be commercially competitive whilst mitigating risk.\nMaps the client's requirements against proposed set of service elements and architectures and leads the end-to-end solution development (Technology Consulting, Technical Services, Support Services and Managed Services).\nDevelops and executes a consulting approach that results in a consolidated statement of requirements, scope, transition documents and costing based need for change, role of IT, definition of the AS-IS versus desired state (Future Mode of operation defined), gap analysis and roadmap, highlighted impacts, consequences and benefits of the intended transformation (people, process, technology).\nSupports the sales teams in presenting an architecture solution to clients with a focus on cost savings or uncovering other client growth opportunities using the ability to discover and analyze the clients current architecture, platforms and operating models.\nShares client outcomes and market conditions with other stakeholders so that the global offering leads, and Services Solutions community can evolve strategies and develop innovative solutions for the future.\nProvides coaching and mentoring and acts as advisor and decision maker in service design situations.\nSupport the sales teams to have a commercial model discussion with the client.\nIdentifies all service costs and populating cost models accurately to ensure a full visibility of costs related to the delivery of the service over the contract term.\nCreates and gets sign-off from relevant stakeholders on the solution design that will form part of the commercial model.\nResponsible for vendor management depending on the service offers and ensures that the transition to service delivery teams are well coordinated to ensure a smooth transition.\n\nKnowledge and Attributes:\nAdvanced knowledge of IT Management Services service and delivery models, including cloud, global, and distributed delivery models.\nAbility to work with costing models in partnership with sales and finance stakeholders.\nAdvanced proficiency in Key Technology Vendor Services (namely, Cisco, Palo Alto, F5, Checkpoint, HP Aruba, Dell, Genesys, NICE)\nAbility to communicate potential improvements and value of our solutions to all levels of stakeholders.\nAbility to facilitate workshops with clients and internal teams to discover requirements, present solutions and obtain client buy-in.\nAbility to work within a team, contributing to the success of the team while making a personal contribution, especially in a matrixed organization.\nAdvanced knowledge on emerging trends in technology, Managed Services Integration, Application Development DevSecOps, Cloud Native Service Applications, Microsoft Development platforms, and Open-Source Software, Cloud platforms like Azure, AWS and GCP, Data Analytics, Containers, RPA, IoT, and Intelligent Automation.\nAnalytical abilities to discover and analyze all input and data.\nPassion for staying abreast of related industry trends and best practices.\n\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Information technology/systems or a related field.\nCertification and working knowledge of ITIL, Service Management and Integration, Automation Artificial Intelligence and Analytics preferred.\nScaled Agile certification or equivalent is desirable.\nAdditional desirable vendor certifications (Cisco, Palo Alto, Checkpoint, Cloud Hyperscaler) or any relevant latest technology trend equivalent.\n\nRequired Experience:\nAdvanced demonstratable track record of designing IT Management services solutions to large enterprise accounts.\nAdvanced experience in structuring large, multi-year profitable contracts.\nAdvanced solution planning and deal shaping expertise, with the ability to create compelling value propositions as part of the solution design.\nAdvanced experience working in an environment with global delivery and in multiple geographies and industries.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Service Management', 'Checkpoint', 'Palo Alto', 'Cloud Hyperscale', 'Cisco', 'IT Management services', 'ITIL']",2025-06-11 06:09:28
Senior Services Architect,"NTT DATA, Inc.",7 - 12 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Services Architect is an advanced subject matter expert and is also a pre-sales persona working with clients and sales/delivery teams in a value co-creation process resulting in the design of Managed Services solutions across multiple technology domains.\n\nThis role is responsible for the development of competitive, innovative, secure, multi-year, viable Managed Services solutions and associated costing inputs to commercial models.\n\nThe Senior Services Architect applies both solution design and sales skills to engage and help close opportunities with decision-makers.\n\nThis role has the opportunity to design solutions with some of the most innovative global organizations, technologies, accelerating the digital transformation business objectives and outcomes.\n\nIn some instances, the Senior Services Architect will remain engaged during and post the implementation of services designed and may be required to participate in renewals.\nWhat you'll be doing\nKey Responsibilities:\nGuides a virtual team of domain experts to orchestrate the development of secure, multiple year, services solutions.\nDesigns complex managed service solutions to meet client requirements by integrating technology and service design across multiple domains.\nWorks across multiple teams in the design of the Managed Service offering.\nTests and validates new designs features and delivery models or recommend improving existing service offers that is being taken to market.\nResponsible for the service design deliverables of the solution and interfacing with multiple teams and partners to ensure supportability.\nDirects the validation processes by obtaining sign-off from technical, service and costing stakeholders.\nLeads the service design of solutions for the client that will be commercially competitive whilst mitigating risk.\nMaps the client's requirements against proposed set of service elements and architectures and leads the end-to-end solution development (Cloud Services, Technology Architectures, SIAM, SLA, ITSM leading practices).\nDevelops and executes a consulting approach that results in a consolidated statement of requirements, scope, transition documents and costing based need for change, role of IT, definition of the AS-IS versus desired state (Future Mode of operation defined), gap analysis and roadmap, highlighted impacts, consequences and benefits of the intended transformation (people, process, technology).\nSupports the sales teams in presenting an architecture solution to clients with a focus on cost savings or uncovering other client growth opportunities using the ability to discover and analyze the clients current architecture, platforms and operating models.\nShares client outcomes and market conditions with other stakeholders so that the global offering leads, and Managed Services community can evolve strategies and develop innovative solutions for the future.\nProvides coaching and mentoring and acts as advisor and decision maker in service design situations.\nSupport the sales teams to have a commercial model discussion with the client.\nIdentifies all service costs and populating cost models accurately to ensure a full visibility of costs related to the delivery of the service over the contract term.\nCreates and gets sign-off from relevant stakeholders on the solution design that will form part of the commercial model.\nResponsible for vendor management depending on the service offers and ensures that the transition to service delivery teams are well coordinated to ensure a smooth transition.\n\nKnowledge and Attributes:\nAdvanced knowledge of Managed Services service and delivery models, including cloud, global, and distributed delivery models.\nAbility to work with costing models in partnership with sales and finance stakeholders.\nAdvanced proficiency in Application and Cloud/Infrastructure Managed Services.\nAbility to communicate potential improvements and value of our solutions to all levels of stakeholders.\nAbility to facilitate workshops with clients and internal teams to discover requirements, present solutions and obtain client buy-in.\nAbility to work within a team, contributing to the success of the team while making a personal contribution, especially in a matrixed organization.\nAdvanced knowledge on emerging trends in technology, Managed Services Integration, Application Development DevSecOps, Cloud Native Service Applications, Microsoft Development platforms, and Open-Source Software, Cloud platforms like Azure, AWS and GCP, Data Analytics, Containers, RPA, IoT, and Intelligent Automation.\nAnalytical abilities to discover and analyze all input and data.\nPassion for staying abreast of related industry trends and best practices.\n\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Information technology/systems or a related field.\nCertification and working knowledge of ITIL, Service Management and Integration, Automation Artificial Intelligence and Analytics preferred.\nScaled Agile certification or equivalent is desirable.\nAdditional desirable technology vendor certifications are AWS Cloud Practitioner Essentials Training, MS Azure Fundamentals Training, or the latest equivalent.\n\nRequired Experience:\nAdvanced demonstratable track record of designing managed services solutions to large enterprise accounts.\nAdvanced experience in structuring large, multi-year profitable contracts.\nAdvanced solution planning and deal shaping expertise, with the ability to create compelling value propositions as part of the solution design.\nAdvanced experience working in an environment with global delivery and in multiple geographies and industries.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['design solutions', 'Azure', 'solution design', 'GCP', 'Agile', 'Data Analytics', 'ITIL', 'AWS', 'Service Management']",2025-06-11 06:09:29
Hr And Administration Associate,Prym Solutions,0 - 2 years,2.5-3.5 Lacs P.A.,['Mumbai (All Areas)( Nariman Point )'],"About Us\nSalam Kisan is a tech-enabled end-to-end agriculture platform that provides data-driven insights to increase productivity and profitability for farmers.\nVision: Driving rural communities towards resilience and sustainability. Mission: Transcending agriculture by bridging the fragmented agriculture value chain with data-driven insights, artificial intelligence, and end-to-end products and services.\n\nLocation\nMumbai, Maharashtra\n\nJob Title\nHR/Admin Associate\n\nPosition Overview\nWe are looking for a motivated and detail-oriented HR/Admin Associate to join our growing team. This role will support the Human Resources and Administration functions, ensuring smooth internal operations, compliance, and employee support across the organization. This is an excellent opportunity for a candidate looking to build a career in HR and office management within an impact-driven organization.\n\nResponsibilities\nHuman Resources Support\nAssist with end-to-end recruitment activities including job postings, resume screening, interview coordination, and onboarding.\nMaintain employee records, attendance, and leave data.\nSupport payroll input processes and employee benefits administration.\nHelp coordinate performance review cycles and maintain related documentation.\nAssist in organizing employee engagement initiatives and internal communications.\nAdministrative Support\nManage daily office operations including vendor coordination, supplies procurement, and facility management.\nSupport travel and logistics arrangements for employees and visitors.\nMaintain proper filing and documentation systems for HR and admin functions.\nEnsure general office upkeep and act as a point of contact for office-related needs.\nQualifications\nEducation: Bachelors degree in Human Resources, Business Administration, or a related field.\nExperience: 0-2 years of experience in an HR or administrative roles. Internship experience will be considered.\nSkills:\nStrong communication and interpersonal skills.\nBasic understanding of HR practices and labor laws.\nGood organizational and time management skills.\nProficiency in MS Office (Word, Excel, PowerPoint); familiarity with HR software is a plus.\n\nSalary\nCompetitive salary and benefits package, commensurate with experience.\nTo Apply\nQualified candidates can send their resumes and cover letter to hrdesk@salamkisan.com.",Industry Type: Agriculture / Forestry / Fishing (Agri-tech),Department: Human Resources,"Employment Type: Full Time, Permanent","['Payroll Administration', 'Organization Skills', 'Administrative Skills', 'Hr Software', 'Interpersonal Skills', 'Communication Skills', 'Management Skills']",2025-06-11 06:09:31
Senior Engineer - Structures,WSP,9 - 14 years,Not Disclosed,['Bengaluru'],"Role Summary\nThis role is to work as part of engineering team, focus on project delivery, production and liaison with the WSP in India Netherland team and mentoring. Role will be working under the supervision of an Principal Engineer or Associate.\n  Responsibilities:\nCore Functions\nPrepare feasibility study reports to meet brief requirements in the agreed format and review with the Local CRC Head of Structures\nWork with the team to assemble a design specification compliant with the employers’ requirements, agree its format and content, and monitor and review its preparation ensuring delivery by the due date\nExpertise in Concept design to Detailed design stage for Steel and Concrete buildings\nAgree and monitor scope of works with the local CRC Head of Structures\nCarry out detailed design as per client requirements in accordance with standard codes, QA and technical review and sign off by the local CRC Head of Structures, including complex calculations and co-ordination issues\nReview and monitor the production of calculations including QA, technical reviews and sign off\nCo-ordinate project contract documents (drawings and specifications) and reviews input from team members\nDeal with the day to day queries from the team, ensuring that relevant information is available on time for construction activity\nLead the design process and encourage the rest of the team to deliver appropriate and cost effective solutions to the agreed programme.\nManagement of a team of engineers and BIM technicians.\n  Technical and Project Management\nRaise the level of technical competence within the teams\nImplement delivery and quality measurement processes\nPromote technical excellence in all our projects\nUndertake technical reviews and contribute to the concept design\nDevelop positive professional relationship with the WSP Netherlands team, communicating openly about project progress\nParticipate in team meetings, disseminate information within the team, and communicate with other teams in WSP\nIdentify and act on, or refer, potential risk issues and follow in full the company commercial and contracting processes\nManage delegated tasks to ensure that deadlines are met and flag resourcing concerns to team leader \nComplete timesheet accurately ahead of weekly deadlines\nKey Competencies / Skills\nThe applicant will have proven experience in the design of Building Structures, Concrete and Streel building designs, Seismic design with significant experience in a similar role or demonstration of a good track record\nGood presentation skills are also required\nMust be fully conversant with technical structural software, such as RFEM, FEM Design, ROBOT, ETABS, SAFE, RAM and STAAD Pro\nExperience with International design codes viz., Eurocode, ACI etc., is required\nA sound understanding of Microsoft Outlook, Word, Excel, Powerpoint is essential\nMust be fluent in English with an excellent understanding of technical terminology\nDemonstrate good management, communication and technical skills and be capable of working both within the team and independently, as dictated by work load\nQualifications\nThe candidate should possess a Bachelor’s degree in Civil or Structural Engineering and possess membership to an accredited engineering body. Master’s degree is preferred.\nIt is desirable that the candidate has obtained UK Chartered Engineer status or pursuing the same.\nExperience: 8 to 14 years",Industry Type: Engineering & Construction,Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['concrete', 'structural engineering', 'technical', 'aci', 'concept design', 'staad', 'staad pro', 'ms outlook', 'fem', 'robot', 'design', 'civil', 'construction', 'international', 'structural design', 'powerpoint', 'communication skills', 'ram', 'etabs', 'presentation skills', 'analysis', 'excel', 'management', 'civil engineering', 'safe', 'word']",2025-06-11 06:09:33
Project Intern,Here2help,0 - 1 years,"36,000-60,000 P.A.",['Delhi / NCR'],Responsibilities:\n* Collaborate with cross-functional teams on AI/ML projects\n* Assist in full stack development using MERN tech stack\n* Contribute to cybersecurity initiatives within the organization\n\n\nWork from home\nPerformance bonus\nReferral bonus\nJob/soft skill training,Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Mern Stack', 'Cyber Security', 'Artificial Intelligence', 'Full Stack', 'Machine Learning', 'English']",2025-06-11 06:09:34
Robotics Trainer & Operational Executive,PHN Technology,0 - 2 years,5-6 Lacs P.A.,[],"Job Description Technology Educator & Operational Executive\nCompany: PHN Technology Pvt. Ltd.\nJob Type: Full-Time\nLocation: PAN India (On-site)\nExperience: 0 to 2 Years\nCTC Offered: 5.6 LPA\n\nEligibility Criteria\nPass-out Years: 2020 to 2025\nAny Graduate / Postgraduate from the following streams:\n- BE / BTech, ME / MTech\n\nRegistration Link: https://forms.gle/8D2JZoxnABapQKzx9\nWebsite & LinkedIn Registration Link: https://forms.gle/PjkqqFUvfNh9RUET8\n\nAbout the Company\nPHN Technology Pvt. Ltd. is on a mission to revolutionize industries through product development, R&D, and innovation powered by cutting-edge technologies. We work with schools, colleges, and communities across India to bridge the digital divide and foster 21st-century skills such as robotics, AI, coding, and critical thinking.\nWe proudly collaborate with premier institutions like IITs, NITs, IIITs, and esteemed government bodies including ISRO, Bharat Electronics Limited, TCIL, and ITI Limited. Additionally, we are associated with educational regulators such as AICTE and MSBTE, reinforcing our commitment to minimizing the gap between real industry challenges and the education system.\nRole Overview\nWe are looking for passionate and self-driven individuals to join us as Technology Educators & Operational Executives. This role combines technology education, regional operational management, and innovation in domains like Artificial Intelligence, IoT, Embedded Systems, and Drones.\nAs a Technology Educator & Operational Executive, you will empower students and educators by delivering hands-on training in cutting-edge technologies while ensuring the smooth execution of our educational initiatives on the ground.\nThis opportunity is ideal for individuals passionate about education, innovation, and creating social impact.\n\nKey Responsibilities\nDeliver interactive training sessions on AI, Robotics, IoT, and Embedded Systems to students and teachers.\nProactively visit and engage with schools and colleges in your assigned territory to implement training programs and ensure effective execution.\nCustomize learning experiences based on the institutions needs.\nConduct workshops to promote 21st-century skills among students.\nOversee and manage operational activities within your region.\nCoordinate with school and college authorities, report program progress, and support lab setups.\nInnovate new ideas for training delivery and curriculum engagement.\nIdentify real-life problems and actively participate in solution development.\nNote: Selected candidates will undergo comprehensive technical training by PHN Technology across all associated domains.\n\nRequired Skills & Qualities\nStrong communication, presentation, and public speaking abilities.\nLeadership and decision-making skills; ability to coordinate at the regional level.\nAdaptive thinking and the ability to work independently.\nProficiency in MS Office and Google tools (Docs, Sheets, Forms).\nFluency in English and local language (spoken and written).\nWell-groomed, confident, dynamic, and people oriented.",Industry Type: IT Services & Consulting,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Training', 'Training Management', 'Machine Learning', 'IOT', 'Operations Management']",2025-06-11 06:09:36
Gen AI Experts,Axtria,5 - 10 years,Not Disclosed,"['Noida', 'Hyderabad', 'Bengaluru']","Axtria: -Axtria is a global provider of award-winning cloud software and data analytics to the life sciences industry. Axtria enables life sciences organizations to transform the product commercialization journey and deliver much-improved healthcare outcomes for patients worldwide. We are acutely aware that our work impacts millions of people and are incredibly passionate about the improvement we can bring to patients lives.\nOur focus is on delivering solutions that help pharmaceutical, medical device, and diagnostics companies complete the journey from data to insights to action and get superior returns from their investments. As a participant of the United Nations Global Compact, Axtria is committed to aligning strategies and operations with universal principles on human rights, labor, environment, and anti-corruption and taking actions that advance societal goals.\nOur people are our core strength, and they make us proud of our work; this has helped us grow exponentially and make tremendous strides toward developing great products. It is for the grit, thinking of an entrepreneur, and a family-like environment where each member is valued and treasured that we are growing rapidly. For more information, visit www.axtria.com.\n\n\nJob Title: - Gen AI Experts ( Open across levels – Senior Associate to Associate Director)\n\nJob Location: -Gurgaon/Bangalore/Pune/Hyderabad\n\nJob Responsibilities: -\nBe an Individual Contributor in the Analytics and Development team and solve real-world problems using cutting-edge capabilities and emerging technologies based on LLM/GenAI/GPT\nSoftware development experience in python is needed as backend for UI based applications\nBe a part of large delivery teams working on advanced projects when expert assistance is required.\nDeliver advanced Data Science capabilities to businesses in a meaningful manner through successful proof-of-concept solutions, and later smoothly transition the proof-of-concept into production.\nCreate Technical documents, develop, test, and deploy data analytics processes using Python, SQL on Azure/AWS platforms\nCan interact with client on GenAI related capabilities and use cases\n\nQualification: -\n- B-Tech or BE in Computer Science / Computer Applications from Tier 1-2 college\nOR\n- Master’s degree in Machine Learning / Statistics / Econometrics, or related discipline from Tier 1-2 college\n\nMust have Skills: -\nRequire 3-15 years experience to develop, test, and deploy Python based applications on Azure/AWS platforms\nMust have basic knowledge on concepts of Generative AI / LLMs / GPT\nDeep understanding of architecture and work experience on Web Technologies\nPython, SQL hands-on experience\nExpertise in any popular python web frameworks e.g. flask, Django etc.\nFamiliarity with frontend technologies like HTML, JavaScript, REACT\nSkills that give you an edge: -\nStrong analytical skills to solve and model complex business requirements are a plus. With life sciences or pharma background.\nWe will provide– (Employee Value Proposition)\nOffer an inclusive environment that encourages diverse perspectives and ideas\nDeliver challenging and unique opportunities to contribute to the success of a transforming organization\nOpportunity to work on technical challenges that may impact across geographies\nVast opportunities for self-development: online Axtria Institute, knowledge sharing opportunities globally, learning opportunities through external certifications\nSponsored Tech Talks & Hackathons\nPossibility to relocate to any Axtria office for short and long-term projects\nBenefit package:\n-Health benefits\n-Retirement benefits\n-Paid time off\n-Flexible Benefits\n-Hybrid /FT Office/Remote\nAxtria is an equal-opportunity employer that values diversity and inclusiveness in the workplace.\nWho we are\nAxtria 14 years journey\nAxtria, Great Place to Work\nLife at Axtria\nAxtria Diversity",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'Model Building', 'Python', 'SQL', 'Modeling Tools']",2025-06-11 06:09:38
Application Architect - L1,Wipro,8 - 10 years,Not Disclosed,['Chennai'],"Role Purpose\n\nThe purpose of the role is to create exceptional and detailed architectural application design and provide thought leadership and enable delivery teams to provide exceptional client engagement and satisfaction.\nDo\n\n1. Develop architectural application for the new deals/ major change requests in existing deals\n\na. Creates an enterprise-wide architecture that ensures systems are scalable, reliable, and manageable.\n\nb. Manages application assets and directs the development efforts within an enterprise to improve solution delivery and agility\n\nc. Guides how to construct and assemble application components and services to support solution architecture and application development\n\nd. Maintains the frameworks and artefacts used in the implementation of an application, with reference to the systematic architecture of the overall application portfolio\n\ne. Responsible for application architecture paradigms such as service-oriented architecture (SOA) and, more specifically, microservices, ensuring business achieve agility and scalability for a faster time to market\n\n\n\nf. Provide solution of RFPs received from clients and ensure overall design assurance\nDevelop a direction to manage the portfolio of to-be-solutions including systems, shared infrastructure services, applications in order to better match business outcome objectives\nAnalyse technology environment, enterprise specifics, client requirements to set a collaboration design framework/ architecture\nDepending on the clients need with particular standards and technology stacks create complete RFPs\nProvide technical leadership to the design, development and implementation of custom solutions through thoughtful use of modern technology\nDefine and understand current state solutions and identify improvements, options & tradeoffs to define target state solutions\nClearly articulate and sell architectural targets, recommendations and reusable patterns and accordingly propose investment roadmaps\nEvaluate and recommend solutions to integrate with overall technology ecosystem\nTracks industry and application trends and relates these to planning current and future IT needs\n\ng. Provides technical and strategic inputs during the project planning phase in the form of technical architectural designs and recommendations\n\nh. Account mining to find opportunities in the existing clients\n\ni. Collaborates with all relevant parties in order to review the objectives and constraints of solutions and determine conformance with the Enterprise Architecture.\n\nj. Identifies implementation risks and potential impacts.\n\nk. Create new revenue streams within applications as APIs that can be leveraged by clients\n\nl. Bring knowledge of automation in application by embracing Agile and dev-ops principles to reduce manual part\n\n\n\n2.Understanding application requirements and design a standardize application\n\na. Creating Intellectual Property in forms of services, patterns, models and organizational approaches\n\nb. Designing patterns, best practices and reusable applications that can be used for future references\n\nc. Ensure system capabilities are consumed by system components and set criteria for evaluating technical and business value in terms of Tolerate, Invest, Migrate and Eliminate\n\nd. Provide platform to create standardize tools, uniform design and techniques are maintained to reduce costs of maintenance\n\ne. Coordinating input on risks, costs and opportunities for concepts\n\nf. Developing customised applications for the customers aligned with their needs\n\ng. Perform design and code reviews thoroughly on regular basis, keeping in mind the security measures\n\nh. Understanding design and production procedures and standards to create prototypes and finished products\n\ni. Work closely with systems analysts, software developers, data managers and other team members to ensure successful production of application software\n\nj. Offer viable solutions for various systems and architectures to different types of businesses\n\nk. Seamless integration of new and existing systems to eliminate potential problems and maintain data structure and bring value in terms of development\n\nl. Transforming all applications into digital form and implement and evolve around mesh app and service architecture that support new technologies like IOT, blockchain, machine learning, automation, BOTS etc\n\n\n\nm.Cloud Transformation(Migration)\nUnderstanding non-functional requirements\nProducing artefacts such as deployment architecture, interface catalogue\nIdentify internal and external dependency, vendor and internal IT management\nSupport build and testing team\n\nn.Cloud Transformation(Modernization)\nUnderstanding and Defining target architecture in Integration space\nAssessing project pipeline / demand and align to target architecture\nTechnical support of delivery team in terms and POC and technical guidance\n\no.Keep Up-to-date with the latest technologies in the market\nMandatory\n\nSkills:\nSpring Boot.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['architectural design', 'software development', 'design patterns', 'enterprise architecture', 'agile']",2025-06-11 06:09:39
Human Resource Intern,Angel One,4 months duration,"15,000/month",['Mumbai (All Areas)'],"About Angel one :\nAngel One Limited is a Fintech company providing broking services, margin trading facility, research services, depository services, investment education and distributes third party financial products to its clients, on a mission to become the No. 1 fintech organization in India. With over 2 crore+ registered clients, we are onboarding an average of over 800k new clients every month in the current financial year. We are working to build personalized financial journeys for our clients via a single app, powered by new-age tech, AI, Machine Learning and Data Science.\nWe have a flat structure, with ample opportunity to showcase your talent and a growth path for you to the very top. We are aggressively hiring for various non-tech and tech roles across India. Join our team and experience the best of both worlds at Angel One! Check out our careers section!",,,,"['Intern HR', 'Human Resource Management', 'Hr Internship', 'MBA HR', 'Pursuing MBA HR', 'HRBP']",2025-06-11 06:09:41
AI/ML Lead Engineer (Senior AI Engineer),Conversehr Business Solutions,7 - 12 years,30-45 Lacs P.A.,['Hyderabad'],"What is AI Engineer team responsible for?\nAs a Senior AI Engineer, youll be a key member of the Data & AI team. This team is responsible for designing and delivering data engineering, analytics, and generative AI solutions that drive meaningful business impact. Were looking for a pragmatic, results-driven problem solver who thrives in a fast-paced environment and is passionate about building solutions at scale.\nThe ideal candidate has a strong technical foundation, a collaborative mindset, and the ability to navigate complex challenges. You should be comfortable working in a fast-moving, startup-like environment within an established enterprise, and should bring strong skill sets to adapt new solutions fast. You will play a crucial role in integrating AI solutions in our existing digital solutions, optimizing our data infrastructure, and enabling insights through data #MID_SENIOR_LEVEL\nWhat is a Digital & AI/ML Lead Engineer (Senior AI Engineer) responsible for?\nServe as a hands-on technical lead, driving project execution and delivery in our growing AI team based in the Hyderabad office.\nCollaborate closely with the U.S.-based team and cross-functional stakeholders to understand business needs and deliver scalable, AI-powered solutions.\nDesign and build AI applications leveraging best smart solutions.\nProvide quick prototype and evaluation AI/ML solutions aligned with business objectives.\nStay current with emerging trends in AI, and machine learning and help implement best practices within the team.\nMentor and support junior engineers, fostering a culture of learning and technical excellence.\nManage unstructured data and generate embeddings that can further be leveraged into AI products.\nWhat ideal qualifications, skills & experience would help someone to be successful?\nBachelors or master’s degree in computer science, data science, engineering, or a related field from a premium institute.\n7+ years of experience in engineering, software engineering, data science, or machine learning, including 3+ years in a technical leadership role.\nStrong understanding with data pipelines, Snowflake ecosystem and master data management.\nProficiency in Python.\nExperience working with unstructured data, large language models (LLMs), embeddings, and building generative AI prototypes.\nSelf-starter with a passion for learning new tools and technologies.\nStrong communication skills and a collaborative, ownership-driven mindset.\nWork Shift Timings - 2:00 PM - 11:00 PM IST",Industry Type: Investment Banking / Venture Capital / Private Equity,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Aiml', 'Python', 'ai/ml', 'genAI', 'Generative Ai', 'Large Language Model', 'Snowflake', 'Master Data Management', 'llm']",2025-06-11 06:09:42
Senior Principal Engineer - IT Business Analysis,Mercer,5 - 8 years,11-16 Lacs P.A.,['Mumbai (All Areas)'],"Job Description For Posting\nWe are seeking a talented individual to join our team at Marsh .This role will be based in Mumbai .This is a hybrid role that has a requirement of working at least three days a week in the office.\n\nSenior Principal Engineer - IT Business Analysis\n\nWe will count on you to:\nBe a highly motivated team player working within MMC Agile culture, within a specified Agile framework of Scrum or KANBAN and maintain a willingness for continuously improving your agile mindset. \nWork with the Product Owner to communicate the product vision, roadmap, value, and MVP to the Agile team to enable empathy and a shared understanding thereby helping the team to formulate an appropriate solution. \nCollaborate with the Pod Leadership and Product Owner to create Personas, Story Maps, and a Release Plan for the project.\nWork with the Product Owner to communicate the product vision, roadmap, value, and MVP to the agile teams to enable empathy and a shared understanding thereby helping the team to formulate an appropriate solution.\nWork in partnership with the Product Owner and agile teams in the creation and maintenance of Product Backlog Items ensuring that Epics and User Stories are continuously prioritized and aligned to the Product Roadmap and MVP.\nFacilitate refinement sessions with the Agile Teams and Business to sufficiently detail out User Stories, to include dependencies.\nFacilitate the Sprint Review ceremony by working with the agile teams, Product Owner, Business and Customer to review, assess and adapt the latest product increment by incorporating customer insights and feedback into the Product Backlog.\nActively work with Pod Leadership by running assessments processes for the POD and provide constructive feedback towards continuously improving the Systems Analyst function, standards and processes in Global Technology.\nFacilitate discussions and collaborate with data engineers, data architects, technical experts and AI engineers to integrate AI solutions into application design.\nDemonstrate an awareness of MMC and Mercer Technical, Security and Process Standards and work with the team to incorporate them in product delivery through the software development life cycle. \n\nWhat you need to have:\nHighly motivated candidate who is inquisitive, a rapid learner that is comfortable working as part of a remote team. \nPossess strong communication skills with the capability of working collaboratively within the organization, regardless of boundaries.\nAn effective communicator for both technical and business-oriented audiences.  \nDemonstrated requirements gathering skills showcasing the capture of customer needs and business drivers using a variety of techniques into product backlog items such as Epics and User Stories.\nProven quantitative, analytical, and problem-solving skills.\nAbility to find resolutions regarding own work methods requiring minimal direction.  \nBe willing to respond to emergent changes rather than focused on existing plans. \nFamiliarity with AI concepts and technologies, including machine learning, natural language processing, and data analytics, while ensuring compliance with AI governance frameworks. Leverage these technologies to enhance user experiences and improve decision-making processes within applications.\n\nWhat makes you stand out?\nAbility to craft effective prompts that optimize AI responses, enhancing the functionality of AI-driven applications for problem-solving, analysis, and content generation.\nStay open to learning about emerging AI tools and methodologies.\nAn Agile Mindset with an in-depth understanding of Agile Principles.\nPrior experience as an IT Systems Analyst or IT Business Analyst working as part of an agile team using an Agile Workflow tool such as JIRA or TFS. \nAgile Certification, such as CSM, PSM, CSPO, PSPO, PMI-ACP, Certified SAFe Practitioner, Azure AI Fundamentals is desirable.\n\n\nMarsh McLennan (NYSE: MMC) is a global leader in risk, strategy and people, advising clients in 130 countries across four businesses: Marsh, Guy Carpenter, Mercer and Oliver Wyman. With annual revenue of $24 billion and more than 90,000 colleagues, Marsh McLennan helps build the confidence to thrive through the power of perspective. For more information, visit marshmclennan.com, or follow on LinkedIn and X.\n\nMarsh McLennan is committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age, background, caste, disability, ethnic origin, family duties, gender orientation or expression, gender reassignment, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, or any other characteristic protected by applicable law.\n\nMarsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local office or working onsite with clients at least three days per week. Office-based teams will identify at least one anchor day” per week on which their full team will be together in person.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analysis', 'Use Cases', 'Requirement Gathering']",2025-06-11 06:09:44
Senior Data Science,IDS Infotech,4 - 8 years,Not Disclosed,['Chandigarh'],"About the Role:\nWe are seeking a highly skilled and motivated Senior Data Scientist with 56 years of experience to drive the development of intelligent AI systems. This role requires extensive hands-on experience with Large Language Models (LLMs), strong background in Agentic AI, Machine Learning, and Python programming.\nYou will work on designing autonomous agents, building scalable ML pipelines, and integrating advanced LLM-powered solutions into real-world products.\nKey Responsibilities:",,,,"['GEN AI', 'Natural Language Processing', 'Aiml', 'LLM', 'Deep Learning', 'Artificial Intelligence', 'Machine Learning']",2025-06-11 06:09:45
Retainer,Info Edge,1 - 5 years,Not Disclosed,['Bengaluru'],"About Info Edge\nInfoEdge?s mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behavior, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['data management', 'verbal communication', 'business solutions', 'customer engagement', 'interpersonal skills', 'machine learning', 'artificial intelligence', 'target achievement', 'customer centric', 'education counseling', 'writing', 'career counselling', 'student counseling', 'communication skills']",2025-06-11 06:09:47
MDM Data Science Manager,Amgen Inc,10 - 14 years,Not Disclosed,['Hyderabad'],"We are seeking an accomplished and visionary Data Scientist/ GenAI Lead to join Amgens Enterprise Data Management team.\nAs MDM Data Science/Manager, you will lead the design, development, and deployment of Generative AI and ML models to power data-driven decisions across business domains.\nThis role is ideal for an AI practitioner who thrives in a collaborative environment and brings a strategic mindset to applying advanced AI techniques to solve real-world problems.To succeed in this role, the candidate must have strong AI/ML, Data Science, GenAI experience along with MDM knowledge, hence the candidates having only MDM experience are not eligible for this role. Candidate must have AI/ML, data science and GenAI experience on technologies like (PySpark/PyTorch, TensorFlow, LLM, Autogen, Hugging FaceVectorDB,Embeddings, RAGsetc), along with knowledge of MDM (Master Data Management)\nRoles & Responsibilities:\nDrive development of enterprise-level GenAI applications using LLM frameworks such as Langchain, Autogen, and Hugging Face.\nArchitect intelligent pipelines using PySpark, TensorFlow, and PyTorch within Databricks and AWS environments.\nImplement embedding models andmanage VectorStores for retrieval-augmented generation (RAG) solutions.\nIntegrate and leverage MDM platforms like Informatica and Reltio to supply high-quality structured data to ML systems.\nUtilize SQL and Python for data engineering, data wrangling, and pipeline automation.\nBuild scalable APIs and services to serve GenAI models in production.\nLead cross-functional collaboration with data scientists, engineers, and product teams to scope, design, and deploy AI-powered systems.\nEnsure model governance, version control, and auditability aligned with regulatory and compliance expectations.\nBasic Qualifications and Experience:\nMasters degree with 8 - 10 years of experience in Data Science, Artificial Intelligence, Computer Science, or related fields OR\nBachelors degree with 10 - 14 years of experience in Data Science, Artificial Intelligence, Computer Science, or related fields OR\nDiploma with 14 - 16 years of hands-on experience in Data Science, AI/ML technologies, or related technical domains\nFunctional Skills:\nMust-Have Skills:\n10+ years of experience working in AI/ML or Data Science roles, including designing and implementing GenAI solutions.\nExtensive hands-on experience with LLM frameworks and tools such as Langchain, Autogen, Hugging Face, OpenAI APIs, and embedding models.\nStrong programming background with Python, PySpark, and experience in building scalable solutions using TensorFlow, PyTorch, and SK-Learn.\nProven track record of building and deploying AI/ML applications in cloud environments such as AWS.\nExpertise in developing APIs, automation pipelines, and serving GenAI models using frameworks like Django, FastAPI, and DataBricks.\nSolid experience integrating and managing MDM tools (Informatica/Reltio) and applying data governance best practices.\nGuide the team on development activities and lead the solution discussions\nMust have core technical capabilities in GenAI, Data Science space\nGood-to-Have Skills:\nPrior experience in Data Modeling, ETL development, and data profiling to support AI/ML workflows.\nWorking knowledge of Life Sciences or Pharma industry standards and regulatory considerations.\nProficiency in tools like JIRA and Confluence for Agile delivery and project collaboration.\nFamiliarity with MongoDB, VectorStores, and modern architecture principles for scalable GenAI applications.\nProfessional Certifications:\nAny ETL certification (e.g. Informatica)\nAny Data Analysis certification (SQL)\nAny cloud certification (AWS or AZURE)\nData Science and ML Certification\nSoft Skills:\nStrong analytical abilities to assess and improve master data processes and solutions.\nExcellent verbal and written communication skills, with the ability to convey complex data concepts clearly to technical and non-technical stakeholders.\nEffective problem-solving skills to address data-related issues and implement scalable solutions.\nAbility to work effectively with global, virtual teams",Industry Type: Pharmaceutical & Life Sciences,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Science', 'AZURE', 'AI/ML', 'PyTorch', 'Data Analysis', 'ETL', 'AWS', 'SQL', 'TensorFlow']",2025-06-11 06:09:49
EDR Analyst - L1,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Security Managed Services Engineer (L1) is an entry level engineering role, responsible for providing a managed service to clients to ensure that their Firewall infrastructure remain operational through proactively identifying, investigating, and routing the incidents to correct resolver group.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and focuses on first-line support for standard and low complexity incidents and service requests.\n\nThe Security Managed Services Engineer (L1) may also contribute to support on project work as and when required.\nWhat you'll be doing\nKey Responsibilities:\nMin 3 Years exp in EDR and Trend Micro.\nThe vendor should assess the existing endpoint security infrastructure and identify any gaps or vulnerabilities.\nThe vendor should deploy EDR agents on endpoints, servers, and critical systems within the organization's network.\nThe vendor should configure EDR agents to collect and analyze security events and activities on endpoints.\nThe solution should monitor endpoints for suspicious activities, such as malware infections, unauthorized access attempts, and unusual user behavior.\nThe solution should use behavioral analysis and machine learning to detect advanced threats and zero-day attacks.\nThe solution should generate real-time alerts for potential security incidents and provide guidance for incident response and remediation.\nThe vendor should enable endpoint forensics capabilities to investigate security incidents and identify the root cause of attacks.\nThe solution should capture and store detailed endpoint activity logs and artifacts for further analysis.\nThe vendor should integrate the tool with vulnerability management systems to assess the endpoint's security posture.\nThe EDR solution should be able to rollout patches or upgrades from the EDR management console for agents onboarded on the platforms.\nThe solution should alert and remediate endpoints with outdated or vulnerable software configurations.\nThe solution should provide real-time alerts for anomalies that could indicate potential threats.\nThe vendor should ensure the compatibility with other security systems, such as (but not limited to) SIEM, incident response tools, etc.\nThe solution should correlate network anomalies with potential threats, aiding in early threat detection.\nThe vendor is expected to deliver reports at periodic intervals as per Clients requirements.\nThe vendor should re-deploy the agent as and when there is a change in the infrastructure or the operating systems.\n\nKnowledge and Attributes:\nAbility to communicate and work across different cultures and social groups.\nAbility to plan activities and projects well in advance, and takes into account possible changing circumstances.\nAbility to maintain a positive outlook at work.\nAbility to work well in a pressurized environment.\nAbility to work hard and put in longer hours when it is necessary.\nAbility to apply active listening techniques such as paraphrasing the message to confirm understanding, probing for further relevant information, and refraining from interrupting.\nAbility to adapt to changing circumstances.\nAbility to place clients at the forefront of all interactions, understanding their requirements, and creating a positive client experience throughout the total client journey.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCEH certification is must.\n\nRequired Experience:\nEntry-level experience with troubleshooting and providing the support required in security network/ data center/ systems/ storage administration and monitoring Services within a medium to large ICT organization.\nBasic knowledge of management agents, redundancy concepts, and products within the supported technical domain (such as Security, Network, Data Centre, Telephony, etc.).\nWorking knowledge of ITIL processes.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['EDR', 'cyber security', 'soc', 'information security', 'networking', 'siem', 'machine learning', 'vulnerability assessment', 'artificial intelligence', 'trend micro', 'vendor', 'technology consulting', 'troubleshooting', 'itil']",2025-06-11 06:09:50
Senior AI Developer,S&P Global Market Intelligence,5 - 8 years,Not Disclosed,['Bengaluru'],"\n\nAbout the Role: \n\nGrade Level (for internal use):\n10\n\nJob TitleSenior AI Developer\n\nSummary\n\nWe seek a skilled Senior Developer to join the Editorial, Design & Publishing team. You will contribute to the development and maintenance of tools and technology for editing and designing news, research articles, images, maps and data visualizations published and distributed on S&P Global websites and client-only subscription platforms. The role will also involve exploring and integrating Generative AI solutions to enhance content creation, automation, and efficiency in editorial and design workflows.\n\n\n\nWe are looking for a skilled Senior Developer to join our team and contribute to the development and maintenance of tools and technology for editing and designing news, research articles, images, maps and data visualizations published and distributed on S&P Global websites and client-only subscription platforms. The role will also involve exploring and integrating Generative AI solutions to enhance content creation, automation, and efficiency in editorial and design workflows.\n\nRoles and responsibilities:\n\nDevelop and maintain tools and solutions for editorial and publishing processes.\n\nCollaborate with internal teams to understand requirements and deliver high-quality solutions.\n\nEnsure the scalability, security, and performance of the developed tools.\n\nTroubleshoot and resolve technical issues.\n\nDevelop and integrate GenAI solutions to enhance editorial and design workflows, improving content generation and efficiency, while ensuring compliance with data security, ethical guidelines, and company standards for AI-assisted content creation.\n\nCollaborate with internal teams to identify opportunities where GenAI can streamline processes and provide efficiencies.\n\nStay updated with the latest technologies and industry trends.\n\nProvide technical guidance and mentorship to junior developers\n\n\nAbout the team:\n\nYou will be part of a dynamic and innovative team dedicated to enhancing the efficiency and effectiveness of our editorial and publishing processes. The team works closely with various internal departments to deliver high-quality content to our audience.\n\nWhat's in it for you:\n\nOpportunity to work on cutting-edge technology solutions for a global leader in financial information and analytics.\n\nCollaborate with a talented and diverse team.\n\nCompetitive salary and benefits package.\n\nProfessional growth and development opportunities.\n\n\nMinimum qualifications:\n\nBachelors degree in computer science or a related field.\n\n5-8 years of experience in software development\n\nProficiency in programming languages such as Python and JavaScript (including React and Typescript experience)\n\nExperience with content management systems (CMS) such as AWS or Azure Cloud Services, APIs, and cloud platforms.\n\nStrong problem-solving abilities.\n\nExperience working with globally distributed teams.\n\nExcellent communication skills.\n\n\nPreferred qualifications:\n\nExperience in the financial information and analytics industry.\n\nFamiliarity with the latest trends and technologies in digital publishing.\n\nExperience with data analytics/visualization tools (e.g., Power BI, Tableau, Flourish, Infogram, Plotly)\n\nProven track record of successfully delivering complex software projects.\n\nStrong analytical and decision-making skills.\n\n\n#LI-USA\n\nWhats In It For\n\nYou\n\nOur Purpose:\n\nProgress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technologythe right combination can unlock possibility and change the world.Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence, pinpointing risks and opening possibilities. We Accelerate Progress.\n\nOur People:\n\nOur Values:\n\nIntegrity, Discovery, Partnership\n\nAt S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of\n\nintegrity in all we do, bring a spirit of\n\ndiscovery to our work, and collaborate in close\n\npartnership with each other and our customers to achieve shared goals.\n\nBenefits:\n\nWe take care of you, so you cantake care of business. We care about our people. Thats why we provide everything youand your careerneed to thrive at S&P Global.\n\nHealth & WellnessHealth care coverage designed for the mind and body.\n\n\n\nContinuous LearningAccess a wealth of resources to grow your career and learn valuable new skills.\n\nInvest in Your FutureSecure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.\n\nFamily Friendly PerksIts not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.\n\nBeyond the BasicsFrom retail discounts to referral incentive awardssmall perks can make a big difference.\n\nFor more information on benefits by country visithttps://spgbenefits.com/benefit-summaries",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['react.js', 'typescript', 'python', 'software development', 'javascript', 'azure cloud services', 'artificial intelligence', 'jquery', 'asp.net', 'web api', 'html', 'api', 'mvc', 'wcf', 'c#', 'data analytics', 'entity framework', 'power bi', 'sql server', 'angular', 'tableau', 'linq', '.net core', '.net', 'aws']",2025-06-11 06:09:52
Principal Engineer-Dry Utility(Infrastructure),Aecom,10 - 13 years,Not Disclosed,['Gurugram'],"\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation and operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\nAECOM is seeking for a candidate to be based inBengaluru or Gurgaon. Candidate will be responsible for the following activities:\n10 - 13Years (Exposure to outside India projects preferably Middle East,UK, USA, Canada & ANZ region )\nPreparation, Review and production of Electrical (EHV, HV, MV, LV), Street Lighting, Telecom, ELV, ICT Network, Pump station,Water Treatment Plant, EV charging Station, Substation, Power Transmission & Distribution network\nDesign CalculationStreet lighting, High Mast Area Lighting, Cable sizing & Voltage drop, Earthing, Fault level, Corridor sizing\nSoftwareDialux, AGI, Lighting Reality, Amtech, ETAP\n\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nGood communication skills, and ability to work well independently at times.\nAble to see the bigger picture and take a birds-eye view of projects\nConfident, with the ability to work either independently or as part of a team.\nAbility to work to deadlines and under pressure.\nAccountability for assigned work.\nAccuracy & precision of work.\nWillingness to learn and develop.\nExcellent written and verbal communication skills\nStrong problem-solving skills\nEnthusiastic and Self-motivated.\nWork well within a multidisciplinary team\n\n\n",Industry Type: Building Material (Cement),"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['microsoft azure', 'infrastructure architecture', 'docker', 'linux', 'aws', 'kubernetes', 'vmware', 'redhat linux', 'ansible', 'amazon ec2', 'windows system administration', 'active directory', 'linux administration', 'microsoft windows', 'powershell', 'windows server', 'cloud computing', 'unix']",2025-06-11 06:09:54
Principal Engineer- Electrical(Secondary Substation),Aecom,10 - 15 years,Not Disclosed,['Gurugram'],"\nPerforms specific and moderate portions of a broader assignment of an experienced engineer.\nGathers and correlates basic engineering data using established and well-defined procedures.\nWorks on detailed or routine engineering assignments involving calculations and relatively simple tests.\nProposes approach to solve new problems encountered using modifications of standard procedures or methods developed in previous assignments.\nIdentifies discrepancies in results.\nProvides guidance to entry level engineers.\nPerforms work in accordance with agreed upon budget and schedule with little supervision.\nIndependently performs all the tasks necessary to complete primary design elements for engineering works.\nPerformance at this level requires developmental experience in a professional position.\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation and operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Electrical Engineers, UK)\n\n Minimum  \nOverall 10+ years of work experience is preferred.\nPrevious experience in design teams working for Grid Utilities (for e.g., National Grid, Transgrid, Powergrid etc.,) for Transmission Line Electrical design is highly desirable\nExposure to International standards (IEC, IEEE, ANSI, Australian Standards and Middle East region codes and standards) is preferred\nPrevious design experience working with Secondary Design for HV, MV Substations and Transmission Lines is preferable.\nChartership or Fellowship with IET or equivalent is desirable\nVery good communication skills (Oral and Written) in English language is mandatory\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['electrical design', 'transmission lines', 'hv', 'transmission line', 'electricals', 'matlab', 'simulink', 'circuit', 'c', 'power system', 'plc', 'electrical engineering', 'power transmission', 'motor control', 'scada', 'construction management', 'transmission', 'construction', 'electrical installation']",2025-06-11 06:09:55
Master Data Management Data Architect,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will be responsible for designing, building, maintaining, analyzing, and interpreting data deliver actionable insights that drive business decisions. This role involves working with large datasets, developing reports, supporting and driving data governance initiatives, and visualizing data to ensure data is accessible, reliable, and efficiently managed. The ideal candidate has deep technical skills and provides administration support for Master Data Management (MDM) and Data Quality platform, including solution architecture, inbound/outbound data integration (ETL), Data Quality (DQ), and maintenance/tuning of match rules.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing\nCollaborate and communicate with MDM Developers, Data Architects, Product teams, Business SMEs, and Data Scientists to design and develop end-to-end data pipelines to meet fast paced business needs across geographic regions\nIdentify and resolve complex data-related challenges\nAdhere to standard processes for coding, testing, and designing reusable code/component\nParticipate in sprint planning meetings and provide estimations on technical implementation\nAs a SME, work with the team on MDM related product installation, configuration, customization and optimization\nResponsible for the understanding, documentation, maintenance, and additional creation of master data related data-models (conceptual, logical, and physical) and database structures\nReview technical model specifications and participate in data quality testing\nCollaborate with Data Quality & Governance Analyst and Data Governance Organization to monitor and preserve the master data quality\nCreate and maintain system specific master data data-dictionaries for domains in scope\nArchitect MDM Solutions, including data modeling and data source integrations from proof-of-concept through development and delivery\nDevelop the architectural design for Master Data Management domain development, base object integration to other systems and general solutions as related to Master Data Management\nDevelop and deliver solutions individually or as part of a development team\nApproves code reviews and technical work\nMaintains compliance with change control, SDLC and development standards\nContribute to the design, development, and implementation of data pipelines, ETL/ELT processes, and data integration solutions\nCollaborate with multi-functional teams to understand data requirements and design solutions that meet business needs\nImplement data security and privacy measures to protect sensitive data\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience.\nPreferred Qualifications:\nExpertise in architecting and designing Master Data Management (MDM) solutions.\nPractical experience with AWS Cloud, Databricks, Apache Spark, workflow orchestration, and optimizing big data processing performance.\nFamiliarity with enterprise source systems and consumer systems for master and reference data, such as CRM, ERP, and Data Warehouse/Business Intelligence.\nAt least 2 to 3 years of experience as an MDM developer using Informatica MDM or Reltio MDM, along with strong proficiency in SQL.\n\n\nGood-to-Have Skills:\nExperience with ETL tools such as Apache Spark, and various Python packages related to data processing, machine learning model development.\nGood understanding of data modeling, data warehousing, and data integration concepts.\nExperience with development using Python, React JS, cloud data platforms.\nCertified Data Engineer / Data Analyst (preferred on Databricks or cloud environments).\n\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Business Intelligence', 'Data Warehouse', 'cloud data platforms', 'Databricks', 'ETL', 'React JS', 'Python']",2025-06-11 06:09:57
Principal Engineer- Transmission Lines,Aecom,10 - 15 years,Not Disclosed,['Gurugram'],"\nSenior technical resource may serve as technical advisor for team\nProvides specialized technical input to studies and design for staff's specific area of expertise.\nDevelops study and design procedures to facilitate high quality cost effective work by others.\nParticipates in interdisciplinary review of project deliverables.\nDevelops construction cost estimates and estimates of technical efforts for projects.\nUses expertise in all steps of completing discipline component of PS&E package.\nPerforms quality control review of design calculations or drawings.\nPrepares technical specification sections.\nProvides input to the development of engineering budget and schedule to meet requirements.\n\n\nRefers to the field of engineering dealing with the analysis and design of structures that support or resist loads. Commonly involved in the design of buildings and large nonbuilding structures, but can also be involved in the design of machinery, medical equipment, vehicles or any item where structural integrity affects the function or safety of an item. Discipline concerning force resisting and load bearing members and their connections for structures such as foundations, bridges, walls, columns, slabs, beams, trusses or similar members used singly or as part of a larger structure.""\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\n\n Minimum  \nOverall 10+ years of work experience is preferred.\nPrevious experience in design teams working for Grid Utilities (for e.g., National Grid, Transgrid, Powergrid etc.,) for Transmission Line Structural design is highly desirable\nExposure to International standards (IEC, IEEE, ANSI, Australian Standards and Middle East region codes and standards) is preferred\nPrevious design experience working with PLS CADD, PLS TOWER, PLS POLE, Staad Pro, Microstran or other similar software tools is highly desirable\nChartership or Fellowship with IStructE / ICE or equivalent is desirable\nVery good communication skills (Oral and Written) in English language is mandatory\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['staad pro', 'pls tower', 'transmission line', 'pls cadd', 'structural design', 'steel structures', 'structural engineering', 'etabs', 'staad', 'transmission lines', 'autocad', 'design engineering', 'sql', 'plsql', 'construction management', 'transmission', 'civil engineering', 'pls', 'construction']",2025-06-11 06:09:59
Principal Engineer-Highways,Aecom,8 - 12 years,Not Disclosed,['Gurugram'],"\nShould have previously worked on UK/US projects /NA -Canada/ME/ANZ regional projects using different codes standards and guidelines software proficiency in ORD/ Civil 3D is a must for design coordination, mentoring juniors in Design and Design software applications ability to learn and challenge the designs, understanding Technical subjects and propose alternatives as per site requirements, BIM and CDE awareness and working in a collaborative environment involving multi-technical teams, leading BIM levels of Design and co-ordination communication skills, ability to explain and ask questions, co-ordinate teams for projects success quality process, procedures, implementation for delivery of projects Training, mentoring, guiding the engineers for technical skills and delivery of projects-schemes through collaboration\n\n\n Qualifications \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Civil Engineers, UK)\n8-12+ years of exp in the Design of Roads, Streets, Highways, and motorways using ORD software and Civil 3D software.\nShould have worked on international projects on the GDC platform.\nGood communication skills, and able to work well independently at times.\nAble to see the bigger picture and take a birds-eye view of projects\nConfident, with the ability to work either independently or as part of a team.\nAbility to work to deadlines and under pressure.\nAccountability for assigned work.\nAccuracy & precision of work.\nWillingness to learn and develop.\nExcellent written and verbal communication skills\nStrong problem-solving skills\nEnthusiastic and Self-motivated.\nWork well within a multidisciplinary team.\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['civil 3d', 'highway engineering', 'construction management', 'construction', 'highways', 'site execution', 'bim', 'flyovers', 'water', 'autocad', 'mx road', 'building construction', '3d', 'construction engineering', 'site supervision', 'civil engineering', 'wmm', 'site engineering', 'highway design']",2025-06-11 06:10:00
Principal Engineer- Building Structure,Aecom,8 - 12 years,Not Disclosed,['Gurugram'],"\n\nAECOM is seeking a Principal Engineer - Building Structures be based inBengaluru/Gurgaon India. Candidates will be responsible for the following activities:\nDevelops technical solutions to a wide range of difficult problems. Works under only general direction. Independently determines and develops approach to solutions.\nExperience in retail and hospitality medium to large projects.\nExperience in UK, UAE, US, Canada, ANZ(preferred).\nExperience in delivering projects in BIM and relevant discipline software.\nReceives instructions on specific assignment objectives, complex features, and possible solutions.\nShould be knowledgeable in building design services, associated regulations and technical standards.\nCapable of working on as own initiative, as an overall responsibility and accountability for assigned work.\nEffective communication skills.\nGood attention to details.\nMust be a team player and possess strong interpersonal skills.\nMust be able to make decisions, act on own initiative and operate in a pro-active way.\nConfident, with the ability to work either independently or as part of a team.\nAbility to work to deadlines and under pressure.\nMaintains affiliation with professional societies to keep abreast of current technologies.\nAccountability for assigned work.\nAccuracy & precision of work.\n\n\n Qualifications \n\nThe successful candidate will have the following Qualifications:\nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nApplicants must have between 8-12years of experience in CivilEngineering, Middle East/US/UK experience, which would be desirable but are not essential.\nGood communication skills, and ability to work well independently at times.\nAble to see the bigger picture and take a birds-eye view of projects\nConfident, and able to work independently or as part of a team.\nAbility to work to deadlines and under pressure.\nAccountability for assigned work.\nAccuracy & precision of work.\nWillingness to learn and develop.\nExcellent written and verbal communication skills\nStrong problem-solving skills\nEnthusiastic and Self-motivated.\nWork well within a multidisciplinary team.\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['oil', 'civil engineering', 'gcc', 'nursing', 'ent', 'construction', 'autocad', 'customer support']",2025-06-11 06:10:02
Principal Engineer Electrical - Healthcare experience,Aecom,13 - 18 years,Not Disclosed,['Gurugram'],"\n\nResponsible for engineering design and modification activities related to electrical & electronic circuits, systems, and equipment. May involve the installation and operation & maintenance of electrical systems and equipment.\n\nDiscipline concerning power systems, electronic and transmission equipment, electric service and supply systems, lighting systems, communication service and supply systems, fire alarm and detection systems, control systems or electrical installations.\n\nAn electrical engineer focuses on designing, maintaining and improving products that are powered by or produce electricity. Electrical engineering deals with electricity, electro-magnetism and electronics. It also covers power, control systems, telecommunications and signal processing. These engineers are usually concerned with large-scale electrical systems such as motor control and power transmission, as well as utilizing electricity to transmit energy.\n\n Duties and Responsibilities  \n\nSenior technical resource may serve as technical advisor for team\nProvides specialized technical input to studies and design for staff's specific area of expertise.\nDevelops study and design procedures to facilitate high quality cost effective work by others.\nParticipates in interdisciplinary review of project deliverables.\nDevelops construction cost estimates and estimates of technical efforts for projects.\nUses expertise in all steps of completing discipline component of PS&E package.\nPerforms quality control review of design calculations or drawings.\nPrepares technical specification sections.\nProvides input to the development of engineering budget and schedule to meet requirements.\n\n Qualifications \n\n Minimum  \nMaster of Engineering degree (or equivalent education) in an appropriate engineering discipline from an accredited college or university.\nChartered Engineer (CEng), or Professional Engineer (PE) license or equivalent in the relevant field from any global organization (e.g., Institution of Electrical Engineers, UK)\nHealthcare design experience required\n\nOverall 13+ years of work experience is preferred.\n\n\n",Industry Type: Building Material (Cement),Department: Construction & Site Engineering,"Employment Type: Full Time, Permanent","['circuit', 'electrical engineering', 'electricity', 'power transmission', 'electrical installation', 'quality control', 'power system', 'equipment', 'design calculations', 'telecommunication', 'construction management', 'transmission', 'construction', 'engineering design', 'control system']",2025-06-11 06:10:04
SAP MM Consultant,NTT DATA Business Solutions,6 - 10 years,Not Disclosed,['Hyderabad'],"Job Title: SAP MM Consultant\nExperience: 6 to 8 Years\nNotice Period: Immediate joiners - preferred\nJob Location : Hyderabad\n\nJob Description:\nCore Functional competency & Project Deliverables Strong configuration hands on experience in the following MM areas: Material Master, Purchasing, Inventory Management, Account Determination, Invoice Verifications, knowledge of inbound and outbound supply chain involving Purchase Requisitions, Quotation, Contacts, Purchase Orders, Stock Transport Order, STO Delivery, Inventory Management including Physical Inventory and Invoice Verifications",,,,"['Material Master', 'SAP MM', 'Invoice Verification', 'S4HANA', 'Implementation', 'MM', 'Mm Module', 'Material Requirement Planning', 'Private Cloud', 'Master Data', 'SAP MM Module', 'SAP WM', 'Material Management', 'Inventory Management', 'Public Cloud', 'Warehouse Management', 'Sap Mm Wm', 'SAP MM Implementation']",2025-06-11 06:10:05
SQL My SQL L1,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nSQL My SQL L1\nWhat you'll be doing\nDegree BE/B.Tech/MCA in IT/Computer Science/ Electronics & Communication/Electronics or higher/Diploma in Computer Science\nGood understanding of the Oracle/SQL database, Related utilities and tools\nGood understanding of the underlying operating system\nGood knowledge of the physical database design\nOracle/SQL certified professional\nAbility to perform both Oracle/SQL and operating system performance tuning and monitoring\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SQL', 'database design', 'oracle', 'performance tuning', 'application management', 'technology consulting', 'system performance', 'troubleshooting', 'database administration', 'artificial intelligence', 'sql database']",2025-06-11 06:10:07
SQL My SQL L1,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Chennai'],"Your day at NTT DATA\nSQL My SQL L1\nWhat you'll be doing\nDegree BE/B.Tech/MCA in IT/Computer Science/ Electronics & Communication/Electronics or higher/Diploma in Computer Science\nGood understanding of the Oracle/SQL database, Related utilities and tools\nGood understanding of the underlying operating system\nGood knowledge of the physical database design\nOracle/SQL certified professional\nAbility to perform both Oracle/SQL and operating system performance tuning and monitoring\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['SQL', 'database design', 'oracle', 'performance tuning', 'application management', 'technology consulting', 'microsoft windows', 'system performance', 'troubleshooting', 'windows vista', 'networking', 'artificial intelligence']",2025-06-11 06:10:09
Application Architect - L1,Wipro,8 - 10 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of the role is to create exceptional and detailed architectural application design and provide thought leadership and enable delivery teams to provide exceptional client engagement and satisfaction.\nDo\n\n1. Develop architectural application for the new deals/ major change requests in existing deals\n\na. Creates an enterprise-wide architecture that ensures systems are scalable, reliable, and manageable.\n\nb. Manages application assets and directs the development efforts within an enterprise to improve solution delivery and agility\n\nc. Guides how to construct and assemble application components and services to support solution architecture and application development\n\nd. Maintains the frameworks and artefacts used in the implementation of an application, with reference to the systematic architecture of the overall application portfolio\n\ne. Responsible for application architecture paradigms such as service-oriented architecture (SOA) and, more specifically, microservices, ensuring business achieve agility and scalability for a faster time to market\n\n\n\nf. Provide solution of RFPs received from clients and ensure overall design assurance\nDevelop a direction to manage the portfolio of to-be-solutions including systems, shared infrastructure services, applications in order to better match business outcome objectives\nAnalyse technology environment, enterprise specifics, client requirements to set a collaboration design framework/ architecture\nDepending on the clients need with particular standards and technology stacks create complete RFPs\nProvide technical leadership to the design, development and implementation of custom solutions through thoughtful use of modern technology\nDefine and understand current state solutions and identify improvements, options & tradeoffs to define target state solutions\nClearly articulate and sell architectural targets, recommendations and reusable patterns and accordingly propose investment roadmaps\nEvaluate and recommend solutions to integrate with overall technology ecosystem\nTracks industry and application trends and relates these to planning current and future IT needs\n\ng. Provides technical and strategic inputs during the project planning phase in the form of technical architectural designs and recommendations\n\nh. Account mining to find opportunities in the existing clients\n\ni. Collaborates with all relevant parties in order to review the objectives and constraints of solutions and determine conformance with the Enterprise Architecture.\n\nj. Identifies implementation risks and potential impacts.\n\nk. Create new revenue streams within applications as APIs that can be leveraged by clients\n\nl. Bring knowledge of automation in application by embracing Agile and dev-ops principles to reduce manual part\n\n\n\n2.Understanding application requirements and design a standardize application\n\na. Creating Intellectual Property in forms of services, patterns, models and organizational approaches\n\nb. Designing patterns, best practices and reusable applications that can be used for future references\n\nc. Ensure system capabilities are consumed by system components and set criteria for evaluating technical and business value in terms of Tolerate, Invest, Migrate and Eliminate\n\nd. Provide platform to create standardize tools, uniform design and techniques are maintained to reduce costs of maintenance\n\ne. Coordinating input on risks, costs and opportunities for concepts\n\nf. Developing customised applications for the customers aligned with their needs\n\ng. Perform design and code reviews thoroughly on regular basis, keeping in mind the security measures\n\nh. Understanding design and production procedures and standards to create prototypes and finished products\n\ni. Work closely with systems analysts, software developers, data managers and other team members to ensure successful production of application software\n\nj. Offer viable solutions for various systems and architectures to different types of businesses\n\nk. Seamless integration of new and existing systems to eliminate potential problems and maintain data structure and bring value in terms of development\n\nl. Transforming all applications into digital form and implement and evolve around mesh app and service architecture that support new technologies like IOT, blockchain, machine learning, automation, BOTS etc\n\n\n\nm.Cloud Transformation(Migration)\nUnderstanding non-functional requirements\nProducing artefacts such as deployment architecture, interface catalogue\nIdentify internal and external dependency, vendor and internal IT management\nSupport build and testing team\n\nn.Cloud Transformation(Modernization)\nUnderstanding and Defining target architecture in Integration space\nAssessing project pipeline / demand and align to target architecture\nTechnical support of delivery team in terms and POC and technical guidance\n\no.Keep Up-to-date with the latest technologies in the market\nMandatory\n\nSkills:\nFullstack Java Enterprise.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Application architectural', 'architectural design', 'software development', 'design patterns', 'enterprise architecture', 'application development']",2025-06-11 06:10:10
Application Architect - L1,Wipro,8 - 10 years,Not Disclosed,['Hyderabad'],"Role Purpose\nThe purpose of the role is to create exceptional and detailed architectural application design and provide thought leadership and enable delivery teams to provide exceptional client engagement and satisfaction.\nDo\n1. Develop architectural application for the new deals/ major change requests in existing deals\na. Creates an enterprise-wide architecture that ensures systems are scalable, reliable, and manageable.\nb. Manages application assets and directs the development efforts within an enterprise to improve solution delivery and agility\nc. Guides how to construct and assemble application components and services to support solution architecture and application development\nd. Maintains the frameworks and artefacts used in the implementation of an application, with reference to the systematic architecture of the overall application portfolio\ne. Responsible for application architecture paradigms such as service-oriented architecture (SOA) and, more specifically, microservices, ensuring business achieve agility and scalability for a faster time to market\n\n\n\nf. Provide solution of RFPs received from clients and ensure overall design assurance\nDevelop a direction to manage the portfolio of to-be-solutions including systems, shared infrastructure services, applications in order to better match business outcome objectives\nAnalyse technology environment, enterprise specifics, client requirements to set a collaboration design framework/ architecture\nDepending on the clients need with particular standards and technology stacks create complete RFPs\nProvide technical leadership to the design, development and implementation of custom solutions through thoughtful use of modern technology\nDefine and understand current state solutions and identify improvements, options & tradeoffs to define target state solutions\nClearly articulate and sell architectural targets, recommendations and reusable patterns and accordingly propose investment roadmaps\nEvaluate and recommend solutions to integrate with overall technology ecosystem\nTracks industry and application trends and relates these to planning current and future IT needs\ng. Provides technical and strategic inputs during the project planning phase in the form of technical architectural designs and recommendations\nh. Account mining to find opportunities in the existing clients\ni. Collaborates with all relevant parties in order to review the objectives and constraints of solutions and determine conformance with the Enterprise Architecture.\nj. Identifies implementation risks and potential impacts.\nk. Create new revenue streams within applications as APIs that can be leveraged by clients\nl. Bring knowledge of automation in application by embracing Agile and dev-ops principles to reduce manual part\n2.Understanding application requirements and design a standardize application\na. Creating Intellectual Property in forms of services, patterns, models and organizational approaches\nb. Designing patterns, best practices and reusable applications that can be used for future references\nc. Ensure system capabilities are consumed by system components and set criteria for evaluating technical and business value in terms of Tolerate, Invest, Migrate and Eliminate\nd. Provide platform to create standardize tools, uniform design and techniques are maintained to reduce costs of maintenance\ne. Coordinating input on risks, costs and opportunities for concepts\nf. Developing customised applications for the customers aligned with their needs\ng. Perform design and code reviews thoroughly on regular basis, keeping in mind the security measures\nh. Understanding design and production procedures and standards to create prototypes and finished products\ni. Work closely with systems analysts, software developers, data managers and other team members to ensure successful production of application software\nj. Offer viable solutions for various systems and architectures to different types of businesses\nk. Seamless integration of new and existing systems to eliminate potential problems and maintain data structure and bring value in terms of development\nl. Transforming all applications into digital form and implement and evolve around mesh app and service architecture that support new technologies like IOT, blockchain, machine learning, automation, BOTS etc\n\n\n\nm.Cloud Transformation: (Migration)\nUnderstanding non-functional requirements\nProducing artefacts such as deployment architecture, interface catalogue\nIdentify internal and external dependency, vendor and internal IT management\nSupport build and testing team\nn.Cloud Transformation: (Modernization)\nUnderstanding and Defining target architecture in Integration space\nAssessing project pipeline / demand and align to target architecture\nTechnical support of delivery team in terms and POC and technical guidance\no.Keep Up-to-date with the latest technologies in the market\nMandatory Skills: Microsoft Power Platform for M365.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Microsoft 365', 'SOA', 'application design', 'Cloud Transformation', 'IT management', 'microservices']",2025-06-11 06:10:11
IT consulting Professional,Infosys,3 - 7 years,Not Disclosed,['Coimbatore'],"Responsibilities\nlA day in the life of an Infoscion\nAs part of the Infosys consulting team, your primary role would be to get to the heart of customer issues, diagnose problem areas, design innovative solutions and facilitate deployment resulting in client delight.\nYou will develop a proposal by owning parts of the proposal document and by giving inputs in solution design based on areas of expertise.\nYou will plan the activities of configuration, configure the product as per the design, conduct conference room pilots and will assist in resolving any queries related to requirements and solution design\nYou will conduct solution/product demonstrations, POC/Proof of Technology workshops and prepare effort estimates which suit the customer budgetary requirements and are in line with organizations financial guidelines\nActively lead small projects and contribute to unit-level and organizational initiatives with an objective of providing high quality value adding solutions to customers. If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\nTechnical and Professional : Primary skills Test Automation using Selenium/Playwright Python RPA\nPreferred Skills:\nTechnology-Automated Testing-Automated Testing - ALL-RPA\nTechnology-Automated Testing-Test automation framework design\nTechnology-Machine Learning-Python Educational Bachelor of Engineering Service LineInfosys Quality Engineering* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['IT consulting', 'python', 'RPA', 'selenium', 'automation testing', 'test automation framework', 'framework design']",2025-06-11 06:10:13
Technical Specialist,"NTT DATA, Inc.",1 - 4 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Networking Managed Services Engineer (L3) is a seasoned engineering role, responsible for providing a managed service to clients by proactively identifying and resolving technical incidents and problems.\n\nThrough pre-emptive service incident and resolution activities, as well as product reviews, operational improvements, operational practices, and quality assurance this role maintains a high level of service to clients.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and is responsible for managing tickets of high complexity, conducts advanced and complicated tasks, and provides resolution to a diverse range of complex problems.\n\nThis position uses considerable judgment and independent analysis within defined policies and practices and applies analytical thinking and deep technical expertise in achieving client outcomes, while coaching and mentoring junior team members across functions.\n\nThe Networking Managed Services Engineer (L3) may also contribute to support on project work as and when required.\nWhat you'll be doing\nKey Responsibilities:\nAdvanced Troubleshooting: Resolve complex network issues that L1 and L2 engineers cannot handle, using deep knowledge of SD-WAN technologies and protocols.\nNetwork Design and Architecture: Design and implement advanced network architectures, ensuring scalability, reliability, and security.\nPerformance Optimization: Analyze network performance data to identify bottlenecks and optimize the network for better performance and efficiency.\nSecurity Management: Implement and manage advanced security measures within the SD-WAN environment, including firewalls, VPNs, and intrusion detection systems.\nPolicy Management: Develop and enforce network policies, including QoS (Quality of Service) and traffic management policies.\nCollaboration and Leadership: Work closely with other IT teams, provide guidance to L1 and L2 engineers, and lead network projects.\nVendor Management: Coordinate with SD-WAN vendors for support, updates, and new implementations.\nDocumentation and Reporting: Maintain detailed documentation of network configurations, changes, and performance reports.\nThese responsibilities ensure that the SD-WAN infrastructure is robust, secure, and capable of meeting the demands of modern network environments.\nInventory , SOP creation, Diagram Inventory and Audit and compliance\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Network Design', 'algorithms', 'python', 'project management', 'wan', 'distribution system', 'microsoft azure', 'mentoring', 'artificial intelligence', 'microservices', 'nosql', 'spring', 'sd', 'java', 'technology consulting', 'troubleshooting', 'coaching', 'data structures', 'mysql', 'agile', 'aws', 'cloud computing', 'mongodb']",2025-06-11 06:10:15
EDR Analyst - L1,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Security Managed Services Engineer (L1) is an entry level engineering role, responsible for providing a managed service to clients to ensure that their Firewall infrastructure remain operational through proactively identifying, investigating, and routing the incidents to correct resolver group.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and focuses on first-line support for standard and low complexity incidents and service requests.\n\nThe Security Managed Services Engineer (L1) may also contribute to support on project work as and when required.\nWhat you'll be doing\nKey Responsibilities:\nMin 3 Years exp in EDR and Trend Micro.\nThe vendor should assess the existing endpoint security infrastructure and identify any gaps or vulnerabilities.\nThe vendor should deploy EDR agents on endpoints, servers, and critical systems within the organization's network.\nThe vendor should configure EDR agents to collect and analyze security events and activities on endpoints.\nThe solution should monitor endpoints for suspicious activities, such as malware infections, unauthorized access attempts, and unusual user behavior.\nThe solution should use behavioral analysis and machine learning to detect advanced threats and zero-day attacks.\nThe solution should generate real-time alerts for potential security incidents and provide guidance for incident response and remediation.\nThe vendor should enable endpoint forensics capabilities to investigate security incidents and identify the root cause of attacks.\nThe solution should capture and store detailed endpoint activity logs and artifacts for further analysis.\nThe vendor should integrate the tool with vulnerability management systems to assess the endpoint's security posture.\nThe EDR solution should be able to rollout patches or upgrades from the EDR management console for agents onboarded on the platforms.\nThe solution should alert and remediate endpoints with outdated or vulnerable software configurations.\nThe solution should provide real-time alerts for anomalies that could indicate potential threats.\nThe vendor should ensure the compatibility with other security systems, such as (but not limited to) SIEM, incident response tools, etc.\nThe solution should correlate network anomalies with potential threats, aiding in early threat detection.\nThe vendor is expected to deliver reports at periodic intervals as per Clients requirements.\nThe vendor should re-deploy the agent as and when there is a change in the infrastructure or the operating systems.\n\nKnowledge and Attributes:\nAbility to communicate and work across different cultures and social groups.\nAbility to plan activities and projects well in advance, and takes into account possible changing circumstances.\nAbility to maintain a positive outlook at work.\nAbility to work well in a pressurized environment.\nAbility to work hard and put in longer hours when it is necessary.\nAbility to apply active listening techniques such as paraphrasing the message to confirm understanding, probing for further relevant information, and refraining from interrupting.\nAbility to adapt to changing circumstances.\nAbility to place clients at the forefront of all interactions, understanding their requirements, and creating a positive client experience throughout the total client journey.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCEH certification is must.\n\nRequired Experience:\nEntry-level experience with troubleshooting and providing the support required in security network/ data center/ systems/ storage administration and monitoring Services within a medium to large ICT organization.\nBasic knowledge of management agents, redundancy concepts, and products within the supported technical domain (such as Security, Network, Data Centre, Telephony, etc.).\nWorking knowledge of ITIL processes.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['EDR', 'troubleshooting', 'networking', 'siem', 'data center operations', 'ITIL', 'storage administration']",2025-06-11 06:10:17
Software Development Senior Specialist,"NTT DATA, Inc.",5 - 7 years,Not Disclosed,['Chennai'],"Python Software Development Sr.specialist  \n\n  \n\n In these roles, you will   be responsible for \nDesign, implement, and test generative AI models using python and various frameworks such as Pandas, TensorFlow, PyTorch, and OpenAI.\nResearch and explore new techniques and applications of generative AI, such as text, image, audio, and video synthesis, style transfer, data augmentation, and anomaly detection.\nCollaborate with other developers, researchers, and stakeholders to deliver high-quality and innovative solutions.\nDocument and communicate the results and challenges of generative AI projects.\n\n Required Skills for this role include: \n\n\n\nTechnical skills\n5 to 7 years""™ Experience in developing Python frameworks such DL, ML, Flask\nAt least 2 years of experience in developing generative AI models using python and relevant frameworks.\nStrong knowledge of machine learning, deep learning, and generative AI concepts and algorithms.\nProficient in python and common libraries such as numpy, pandas, matplotlib, and scikit-learn.\nFamiliar with version control, testing, debugging, and deployment tools.\nExcellent communication and problem-solving skills.\nCurious and eager to learn new technologies and domains.\n\nDesired\n\nSkills:\n\nKnowledge of Django, Web API\nProficient exposure on MVC.\n\n   \n\n Preferences:  \nGraduate degree in Computer Science with 4 years of   Python based development.\nGen AI Framework Professional Certification",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['algorithms', 'deep learning', 'mvc', 'python', 'machine learning', 'css', 'scikit-learn', 'dl', 'numpy', 'tensorflow', 'pytorch', 'debugging', 'web api', 'html', 'api', 'ml', 'software development', 'software testing', 'version control', 'javascript', 'pandas', 'django', 'matplotlib', 'flask', 'python framework']",2025-06-11 06:10:18
Software Development Advisor,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Chennai'],"In these roles, you will be responsible for:\nAnalyzes business needs and Responsible for development of AI & Robotic process automation (RPA) with the given specification and requirement.\nIdentify tasks with automation potential together with production teams and customers and implement automation with RPA and other applicable technologies.\nPerform architecture, design and review of development policies for adherence to standards and best practices\nManage day-to-day system development and maintenance activities for RPA deployment in global regions\nProvide software solutions to customer issues and responds to suggestions for improvements and enhancements / new tools.\nDrives engineering processes for the project such as build automation, unit testing, software configuration management and packaging.\nInteracts with business users, I/T, vendors and customers to Identify potential tasks with production teams, customers and implement Robotic Process Automation including other applicable technologies for current and future application requirements\nExecute assigned activities of Project(s) in accordance with established work processes\nPrepare /maintain/ update project execution plan, MS Project schedule and quality plan for assigned Project(s)\n\n\n\nRequired Skills for this role include:\n12 to 15 years of relevant experience as Lead developer (expertise using Python, Microsoft technologies, C",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'rpa', 'c', 'microsoft technologies', 'robotic process automation', 'c#', 'software development', 'entity framework', 'unit testing', 'artificial intelligence', 'software configuration management', 'sql server', 'jquery', 'system development', 'asp.net', '.net', 'scrum', 'mvc', 'wcf', 'agile']",2025-06-11 06:10:20
Offshore Program Manager,"NTT DATA, Inc.",12 - 14 years,Not Disclosed,['Pune'],"Req ID: 326837\n\nWe are currently seeking a Offshore Program Manager to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nJob DutiesOffshore BA / PM\nGrade 10/11\nSeeking an offshore program manager for managing data projects for Australia, India, and APAC region.\n\nThe individual must be able to guide the offshore project team located in different locations across India. The role involves planning, executing, and overseeing data related projects ensuring on time and within budget delivery.\n\nKey roles and responsibilities ""“\n""¢ Requirement Analysis ""“ Act as a bridge between technical development team and onshore team to understand and document the project requirements\n""¢ Project / Program Management ""“\no Project planning, timelines, and resource allocation / management\no Managing project risks related to quality, budget, and resources\no Team Management ""“ Lead and motivate offshore teams including data engineers, QA team, and data SMEs resolving potential issues that may arise during execution\no Budget management ""“ Manage project financials and budgets\no Compliance and standards management\no Risk management ""“ Identify and mitigate potential risks like scope creep, timelines etc.\no Ability to track and monitor project KPIs like defect density, Project health index etc.\n""¢ Stakeholder communication ""“\no Excellent communication and interpersonal skills with onshore / offshore / nearshore teams\no Client communication with F2F client meetings and presentations\no Ability to communicate with senior management within NTTDATA\n\nPreferred Skills and Qualifications ""“\n""¢ Overall, 12-14 years of work experience\n""¢ 7+ years of enterprise Technical Program Management experience supporting data projects.\n""¢ Data lifecycle management ""“ Understanding of data lifecycle management principles including data acquisition, ingestion, data quality, data consumption, and data visualization\n""¢ Exposure to AI and Gen AI fundamental concepts\n""¢ 7+ years of experience with Agile and Waterfall methodologies\n""¢ Ability to travel at least 25%\n""¢ Graduate degree or equivalent combination of education and work experience.\n""¢ Undergraduate or Graduate degree preferred\n\nMinimum Skills RequiredOffshore BA / PM\nGrade 10/11\nSeeking an offshore program manager for managing data projects for Australia, India, and APAC region.\n\nThe individual must be able to guide the offshore project team located in different locations across India. The role involves planning, executing, and overseeing data related projects ensuring on time and within budget delivery.\n\nKey roles and responsibilities ""“\n""¢ Requirement Analysis ""“ Act as a bridge between technical development team and onshore team to understand and document the project requirements\n""¢ Project / Program Management ""“\no Project planning, timelines, and resource allocation / management\no Managing project risks related to quality, budget, and resources\no Team Management ""“ Lead and motivate offshore teams including data engineers, QA team, and data SMEs resolving potential issues that may arise during execution\no Budget management ""“ Manage project financials and budgets\no Compliance and standards management\no Risk management ""“ Identify and mitigate potential risks like scope creep, timelines etc.\no Ability to track and monitor project KPIs like defect density, Project health index etc.\n""¢ Stakeholder communication ""“\no Excellent communication and interpersonal skills with onshore / offshore / nearshore teams\no Client communication with F2F client meetings and presentations\no Ability to communicate with senior management within NTTDATA\n\nPreferred Skills and Qualifications ""“\n""¢ Overall, 12-14 years of work experience\n""¢ 7+ years of enterprise Technical Program Management experience supporting data projects.\n""¢ Data lifecycle management ""“ Understanding of data lifecycle management principles including data acquisition, ingestion, data quality, data consumption, and data visualization\n""¢ Exposure to AI and Gen AI fundamental concepts\n""¢ 7+ years of experience with Agile and Waterfall methodologies\n""¢ Ability to travel at least 25%\n""¢ Graduate degree or equivalent combi",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['artificial intelligence', 'data quality', 'technical program management', 'waterfall', 'agile', 'data life cycle management', 'risk management', 'consumables', 'program management', 'budgeting', 'resource allocation', 'data acquisition', 'data visualization', 'project planning']",2025-06-11 06:10:22
EDR Analyst - L1,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Mumbai'],"Key Responsibilities:\nMin 3 Years exo in EDR and Trend Micro.\nThe vendor should assess the existing endpoint security infrastructure and identify any gaps or vulnerabilities.\nThe vendor should deploy EDR agents on endpoints, servers, and critical systems within the organization's network.\nThe vendor should configure EDR agents to collect and analyze security events and activities on endpoints.\nThe solution should monitor endpoints for suspicious activities, such as malware infections, unauthorized access attempts, and unusual user behavior.\nThe solution should use behavioral analysis and machine learning to detect advanced threats and zero-day attacks.\nThe solution should generate real-time alerts for potential security incidents and provide guidance for incident response and remediation.\nThe vendor should enable endpoint forensics capabilities to investigate security incidents and identify the root cause of attacks.\nThe solution should capture and store detailed endpoint activity logs and artifacts for further analysis.\nThe vendor should integrate the tool with vulnerability management systems to assess the endpoint's security posture.\nThe EDR solution should be able to rollout patches or upgrades from the EDR management console for agents onboarded on the platforms.\nThe solution should alert and remediate endpoints with outdated or vulnerable software configurations.\nThe solution should provide real-time alerts for anomalies that could indicate potential threats.\nThe vendor should ensure the compatibility with other security systems, such as (but not limited to) SIEM, incident response tools, etc.\nThe solution should correlate network anomalies with potential threats, aiding in early threat detection.\nThe vendor is expected to deliver reports at periodic intervals as per Clients requirements.\nThe vendor should re-deploy the agent as and when there is a change in the infrastructure or the operating systems.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCEH certification is must.\n\nRequired Experience:\nEntry-level experience with troubleshooting and providing the support required in security network/ data center/ systems/ storage administration and monitoring Services within a medium to large ICT organization.\nBasic knowledge of management agents, redundancy concepts, and products within the supported technical domain (such as Security, Network, Data Centre, Telephony, etc.).\nWorking knowledge of EDR processes.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['EDR Analysis', 'EDR', 'CEH', 'SIEM', 'Trend Micro', 'vulnerability management systems']",2025-06-11 06:10:23
Microsoft Fabric Specialist,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['Hyderabad'],"Req ID: 326727\n\nWe are currently seeking a Microsoft Fabric Specialist to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n\n\n:\n\nWe are seeking a Mid-Level Microsoft Fabric Support Specialist to join our IT team. The ideal candidate will be responsible for providing technical support, troubleshooting, and ensuring the smooth operation of Microsoft Fabric services.\n\nThis role requires a deep understanding of Microsoft Fabric, data integration, and analytics solutions, along with strong problem-solving skills.\n\nKey Responsibilities:\n\n""¢ Provide technical support and troubleshooting for Microsoft Fabric services.\n\n""¢ Assist in the implementation, configuration, and maintenance of Microsoft Fabric environments.\n\n""¢ Monitor system performance and resolve issues proactively.\n\n""¢ Collaborate with cross-functional teams to optimize data workflows and analytics solutions.\n\n""¢ Document support procedures, best practices, and troubleshooting steps.\n\n""¢ Assist in user training and onboarding for Microsoft Fabric-related tools and applications.\n\n""¢ Stay up to date with the latest Microsoft Fabric updates and best practices.\n\n\n\nRequired Qualifications:\n\n""¢ 5+ years of experience in IT support, with a focus on Microsoft Fabric or related technologies.\n\n""¢ Strong knowledge of Microsoft Fabric, Power BI, Azure Synapse, and data integration tools.\n\n""¢ Experience with troubleshooting and resolving issues in a cloud-based environment.\n\n""¢ Familiarity with SQL, data pipelines, and ETL processes.\n\n""¢ Excellent problem-solving and communication skills.\n\n""¢ Ability to work independently and collaboratively in a team environment. Preferred Qualifications:\n\n""¢ Microsoft certifications related to Fabric, Azure, or Power BI.\n\n""¢ Experience with automation and scripting (PowerShell, Python, etc.).\n\n""¢ Understanding of security and compliance considerations in cloud-based data platforms.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['analytics services', 'azure synapse', 'power bi', 'troubleshooting', 'data integration', 'python', 'it support', 'oracle', 'data analytics', 'data warehousing', 'machine learning', 'jquery', 'sql server', 'sql', 'r', 'java', 'data science', 'data integration tools', 'powershell', 'html', 'agile', 'etl', 'unix']",2025-06-11 06:10:25
Digital Consultant - Innovation Group,"NTT DATA, Inc.",18 - 23 years,Not Disclosed,['Pune'],"Req ID: 317103\n\nWe are currently seeking a Digital Consultant - Innovation Group to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nJob DutiesWe are seeking a highly skilled and experienced Digital Consultant to join our Innovation Group. The ideal candidate will have a strong background in Big Data, Cloud, and AI/ML projects, with a focus on the health insurance or retail domains or manufacturing domains. This role involves engaging with clients for architecture and design, building accelerators for cloud migration, and developing innovative solutions using GenAI technologies.\nKey Responsibilities:\n""¢ Engage with clients to understand their requirements and provide architectural and design solutions.\n""¢ Develop and implement accelerators to facilitate faster cloud migration.\n""¢ Create innovative use cases or solutions to solve day to day data engineering problems using AI and GenAI tools.\n""¢ Develop reference architectures for various use cases using modern cloud data platforms.\n""¢ Understanding of Legacy toolsets, be it ETL, reporting etc is needed.\n""¢ Create migration suites for cataloging, migrating, and verifying data from legacy systems to modern platforms like Databricks and Snowflake.\n\nMinimum Skills RequiredQualifications:\n""¢ EducationB.E. in Electronics & Telecommunication or related field.\n""¢ Experience18+ years in IT, with significant experience in Big Data, Cloud, and AI/ML projects.\n""¢ Technical\n\nSkills:\nProficiency in Databricks, Snowflake, AWS, GenAI (RAG and GANs), Python, C/C++/C",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'big data', 'snowflake', 'python', 'aws', 'legacy', 'web services', 'soa', 'as400', 'data migration', 'artificial intelligence', 'retail', 'java', 'ms office outlook', 'etl', 'ml', 'mainframes', 'project management', 'erp', 'c', 'sap', 'sql server', 'data bricks', 'as', 'cobol', 'web technologies']",2025-06-11 06:10:27
EDR Analyst - L1,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Security Managed Services Engineer (L1) is an entry level engineering role, responsible for providing a managed service to clients to ensure that their Firewall infrastructure remain operational through proactively identifying, investigating, and routing the incidents to correct resolver group.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and focuses on first-line support for standard and low complexity incidents and service requests.\n\nThe Security Managed Services Engineer (L1) may also contribute to / support on project work as and when required.\n\nWhat youll be doing\n\nKey Responsibilities:\nMin 3 Years exp in EDR and Trend Micro.\nThe vendor should assess the existing endpoint security infrastructure and identify any gaps or vulnerabilities.\nThe vendor should deploy EDR agents on endpoints, servers, and critical systems within the organizations network.\nThe vendor should configure EDR agents to collect and analyze security events and activities on endpoints.\nThe solution should monitor endpoints for suspicious activities, such as malware infections, unauthorized access attempts, and unusual user behavior.\nThe solution should use behavioral analysis and machine learning to detect advanced threats and zero-day attacks.\nThe solution should generate real-time alerts for potential security incidents and provide guidance for incident response and remediation.\nThe vendor should enable endpoint forensics capabilities to investigate security incidents and identify the root cause of attacks.\nThe solution should capture and store detailed endpoint activity logs and artifacts for further analysis.\nThe vendor should integrate the tool with vulnerability management systems to assess the endpoints security posture.\nThe EDR solution should be able to rollout patches or upgrades from the EDR management console for agents onboarded on the platforms.\nThe solution should alert and remediate endpoints with outdated or vulnerable software configurations.\nThe solution should provide real-time alerts for anomalies that could indicate potential threats.\nThe vendor should ensure the compatibility with other security systems, such as (but not limited to) SIEM, incident response tools, etc.\nThe solution should correlate network anomalies with potential threats, aiding in early threat detection.\nThe vendor is expected to deliver reports at periodic intervals as per Clients requirements.\nThe vendor should re-deploy the agent as and when there is a change in the infrastructure or the operating systems.\nKnowledge and Attributes:\nAbility to communicate and work across different cultures and social groups.\nAbility to plan activities and projects well in advance, and takes into account possible changing circumstances.\nAbility to maintain a positive outlook at work.\nAbility to work well in a pressurized environment.\nAbility to work hard and put in longer hours when it is necessary.\nAbility to apply active listening techniques such as paraphrasing the message to confirm understanding, probing for further relevant information, and refraining from interrupting.\nAbility to adapt to changing circumstances.\nAbility to place clients at the forefront of all interactions, understanding their requirements, and creating a positive client experience throughout the total client journey.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCEH certification is must.\nRequired Experience:\nEntry-level experience with troubleshooting and providing the support required in security / network/ data center/ systems/ storage administration and monitoring Services within a medium to large ICT organization.\nBasic knowledge of management agents, redundancy concepts, and products within the supported technical domain (such as Security, Network, Data Centre, Telephony, etc.).\nWorking knowledge of ITIL processes.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['EDR Analysis', 'Security management', 'Data Centre', 'ITIL processes', 'vulnerability management systems', 'storage administration']",2025-06-11 06:10:28
"Technical Specialist - MS, Cloud","NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Cloud Managed Services Engineer (L3) is a seasoned engineering role, responsible for providing a managed service to clients by proactively identifying and resolving cloud-based incident and problems.\n\nThrough pre-emptive service incident and resolution activities, as well as product reviews, operational improvements, operational practices, and quality assurance this role maintains a high level of service to clients.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and is responsible for managing tickets of high complexity, conducts advanced and complicated tasks, and provides resolution to a diverse range of complex problems.\n\nThis position uses considerable judgment and independent analysis within defined policies and practices and applies analytical thinking and deep technical expertise in achieving client outcomes, while coaching and mentoring junior team members across functions.\n\nThe Cloud Managed Services Engineer (L3) may also contribute to support on project work as and when required.\nWhat you'll be doing\nJob Description:\nExperience of 7+ years with relevant experience of 4+ years in GCP.\nGood understanding of cloud architecture.\nDeployment of cloud services using Terraform\nDefining and configuring the alert thresholds as directed by the Cloud CoE.\nMonitoring Incident triggered and responding to the relevant team basis the RCA.\nReport Generation and Data Submission basis the requirement raised by various teams.\nImplementation of Cloud Security controls as directed by Info-Sec team.\nFollow-up for audit and compliance point closure post implementation.\nCloud Process Automation and Standardization\nGolden AMI creation and patching of the golden images.\nUpdating the AMI access across accounts for latest image deployment.\nDetailed understanding of the Cloud (IaaS and PaaS) industry and associated various technologies.\nDeep understanding of Service Management best practices frameworks such as ITIL.\nEffective troubleshooting and analytical skills and ability to manage complex and technical projects.\nGood communication skills and an ability to develop relationships with customer external\nstakeholders levels.\nBasic understanding of network & security, data center architecture\nProfessional cloud certifications preferred\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Cloud Managed Services', 'kubernetes', 'cloud services', 'python', 'cloud security', 'service management', 'microsoft azure', 'mentoring', 'artificial intelligence', 'docker', 'ansible', 'data center', 'cloud architecture', 'gcp', 'devops', 'paas', 'jenkins', 'troubleshooting', 'terraform', 'coaching', 'iaas', 'aws', 'itil']",2025-06-11 06:10:30
EDR Analyst - L1,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Mumbai'],"Join a company that is pushing the boundaries of what is possible. We are renowned for our technical excellence and leading innovations, and for making a difference to our clients and society. Our workplace embraces diversity and inclusion its a place where you can grow, belong and thrive.\n\nYour day at NTT DATA\nThe Security Managed Services Engineer (L1) is an entry level engineering role, responsible for providing a managed service to clients to ensure that their Firewall infrastructure remain operational through proactively identifying, investigating, and routing the incidents to correct resolver group.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and focuses on first-line support for standard and low complexity incidents and service requests.\n\nThe Security Managed Services Engineer (L1) may also contribute to / support on project work as and when required.\n\nWhat youll be doing\n\nKey Responsibilities:\nMin 3 Years exo in EDR and Trend Micro.\nThe vendor should assess the existing endpoint security infrastructure and identify any gaps or vulnerabilities.\nThe vendor should deploy EDR agents on endpoints, servers, and critical systems within the organizations network.\nThe vendor should configure EDR agents to collect and analyze security events and activities on endpoints.\nThe solution should monitor endpoints for suspicious activities, such as malware infections, unauthorized access attempts, and unusual user behavior.\nThe solution should use behavioral analysis and machine learning to detect advanced threats and zero-day attacks.\nThe solution should generate real-time alerts for potential security incidents and provide guidance for incident response and remediation.\nThe vendor should enable endpoint forensics capabilities to investigate security incidents and identify the root cause of attacks.\nThe solution should capture and store detailed endpoint activity logs and artifacts for further analysis.\nThe vendor should integrate the tool with vulnerability management systems to assess the endpoints security posture.\nThe EDR solution should be able to rollout patches or upgrades from the EDR management console for agents onboarded on the platforms.\nThe solution should alert and remediate endpoints with outdated or vulnerable software configurations.\nThe solution should provide real-time alerts for anomalies that could indicate potential threats.\nThe vendor should ensure the compatibility with other security systems, such as (but not limited to) SIEM, incident response tools, etc.\nThe solution should correlate network anomalies with potential threats, aiding in early threat detection.\nThe vendor is expected to deliver reports at periodic intervals as per Clients requirements.\nThe vendor should re-deploy the agent as and when there is a change in the infrastructure or the operating systems.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCEH certification is Must",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['EDR', 'malware infections', 'SIEM', 'Trend Micro', 'incident response tools']",2025-06-11 06:10:31
"Technical Specialist - Cisco SDWAN, CCNP","NTT DATA, Inc.",4 - 8 years,Not Disclosed,['Hyderabad'],"Your day at NTT DATA\nThe Networking Managed Services Engineer (L3) is a seasoned engineering role, responsible for providing a managed service to clients by proactively identifying and resolving technical incidents and problems.\n\nThrough pre-emptive service incident and resolution activities, as well as product reviews, operational improvements, operational practices, and quality assurance this role maintains a high level of service to clients.\n\nThe primary objective of this role is to ensure zero missed service level agreement (SLA) conditions and is responsible for managing tickets of high complexity, conducts advanced and complicated tasks, and provides resolution to a diverse range of complex problems.\n\nThis position uses considerable judgment and independent analysis within defined policies and practices and applies analytical thinking and deep technical expertise in achieving client outcomes, while coaching and mentoring junior team members across functions.\n\nThe Networking Managed Services Engineer (L3) may also contribute to support on project work as and when required.\nWhat you'll be doing\nKey Responsibilities:\nEnsures that assigned infrastructure at the client site is configured, installed, tested, and operational.\nHas to maintain the NMC Operations i.e string in Routing and Switching with some experience in SDWAN/ACI.\nPerforms necessary checks, apply monitoring tools and respond to alerts.\nIdentifies problems and errors prior to or when it occurs and log all such incidents in a timely manner with the required level of detail.\nAssists in analyzing, assigning, and escalating support calls.\nInvestigates third line support calls assigned and identify the root cause of incidents and problems\nReports and escalates issues to 3rd party vendors if necessary.\nProvides onsite technical support to clients and provide field engineering services to clients.\nKnowledge and Attributes:\nAbility to communicate and work across different cultures and social groups.\nAbility to plan activities and projects well in advance, and takes into account possible changing circumstances.\nAbility to maintain a positive outlook at work.\nAbility to work well in a pressurized environment.\nAbility to work hard and put in longer hours when it is necessary.\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCCNP or equivalent certification.\nCertifications relevant to the services provided (certifications carry additional weightage on a candidates qualification for the role).\n\nRequired Experience:\nSeasoned experience required in Engineering function within a medium to large ICT organization.\nSeasoned experience of Managed Services.\nSeasoned working knowledge of ITIL processes.\nSeasoned experience working with vendors and/or 3rd parties.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Cisco SDWAN', 'switching', 'project management', 'software testing', 'program management', 'networking', 'artificial intelligence', 'routing', 'technical support', 'strategy consulting', 'technology consulting', 'hsrp', 'itil']",2025-06-11 06:10:33
Senior Cloud Services Architect,"NTT DATA, Inc.",4 - 8 years,Not Disclosed,['Mumbai'],"Key Responsibilities:\nGuides a virtual team of domain experts to orchestrate the development of secure, multiple year, services solutions.\nDesigns complex managed service solutions to meet client requirements by integrating technology and service design the cloud domain.\nWorks across multiple teams in the design of the Managed Service offering.\nTests and validates new designs features and delivery models or recommend improving existing service offers that is being taken to market.\nResponsible for the service design deliverables of the solution and interfacing with multiple teams and partners to ensure supportability.\nDirects the validation processes by obtaining sign-off from technical, service and costing stakeholders.\nLeads the service design of solutions for the client that will be commercially competitive whilst mitigating risk.\nMaps the client's requirements against proposed set of service elements and architectures and leads the end-to-end solution development (Cloud Services, Technology Architectures, SIAM, SLA, ITSM leading practices).\nDevelops and executes a consulting approach that results in a consolidated statement of requirements, scope, transition documents and costing based need for change, role of IT, definition of the AS-IS versus desired state (Future Mode of operation defined), gap analysis and roadmap, highlighted impacts, consequences and benefits of the intended transformation (people, process, technology).\nSupports the sales teams in presenting an architecture solution to clients with a focus on cost savings or uncovering other client growth opportunities using the ability to discover and analyze the clients current architecture, platforms and operating models.\nShares client outcomes and market conditions with other stakeholders so that the global offering leads, and Managed Services community can evolve strategies and develop innovative solutions for the future.\nProvides coaching and mentoring and acts as advisor and decision maker in service design situations.\nSupport the sales teams to have a commercial model discussion with the client.\nIdentifies all service costs and populating cost models accurately to ensure a full visibility of costs related to the delivery of the service over the contract term.\nCreates and gets sign-off from relevant stakeholders on the solution design that will form part of the commercial model.\nResponsible for vendor management depending on the service offers and ensures that the transition to service delivery teams are well coordinated to ensure a smooth transition.\nKnowledge and Attributes:\nAdvanced understanding of cloud technologies, networking, security, and system administration\nAdvanced demonstratable knowledge and value of multi cloud technologies especially cloud native application workflows, understanding of architecture transformation, observability and legacy to cloud migrations.\nApplied Azure and/or GCP and/or AWS infrastructure architect and presales skills.\nAdvanced understanding of virtualization, hybrid computing environments, storage technology and cloud native technologies.\nAdvanced knowledge of Managed Services service and delivery models, including cloud, global, and distributed delivery models.\nAbility to work with costing models in partnership with sales and finance stakeholders.\nAbility to communicate potential improvements and value of our solutions to all levels of stakeholders, including C-suite decision-makers.\nAbility to facilitate workshops with clients and internal teams to discover requirements, present solutions and obtain client buy-in.\nAbility to work within a team, contributing to the success of the team while making a personal contribution, especially in a matrixed organization.\nUp to date knowledge on emerging trends in Cloud technology, Managed Services Integration, etc.\nAnalytical abilities to discover and analyze all input and data.\nPassion for staying abreast of related industry trends and best practices.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Information technology/systems or a related field.\nCertification and working knowledge of ITIL, Service Management and Integration, Automation Artificial Intelligence and Analytics preferred.\nScaled Agile certification or equivalent is desirable.\nAdditional technology vendor certifications are desirable, such as\n(any one or more) - Azure AZ900 Azure Fundamentals, AWS Cloud Practitioner, VMWare: VTSP or VTSP for AWS/Azure.\n\nRequired Experience:\nAdvanced prior experience in managed service provider, or cloud services provider.\nTrack record of designing cloud infrastructure managed services solutions to medium/large enterprise accounts.\nProof of structuring medium/large, multi-year profitable contracts.\nSolution planning and deal shaping technical specialist, with the ability to create compelling value propositions as part of the solution design.\nAdvanced experience working in an environment with global delivery and in multiple geographies and industries",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Cloud', 'Azure', 'VTSP', 'SIAM', 'ITSM', 'Technology Architectures', 'SLA', 'AWS']",2025-06-11 06:10:35
Tableau Admin with AWS Experience,"NTT DATA, Inc.",2 - 6 years,Not Disclosed,['Noida'],"Req ID: 324014\n\nWe are currently seeking a Tableau Admin with AWS Experience to join our team in NOIDA, Uttar Pradesh (IN-UP), India (IN).\n\nTableau Admin with AWS Experience\n\n\n\nWe are seeking a skilled Tableau Administrator with experience in AWS to join our team. The ideal candidate will be responsible for managing and optimizing our Tableau Server environment hosted on AWS, ensuring efficient operation, data security, and seamless integration with other data sources and analytics tools.\n\n\n\nKey Responsibilities\n\n\n\n- Manage, configure, and administer Tableau Server on AWS, including setting up sites and managing user access and permissions.\n\n- Monitor server activity/performance, conduct regular system maintenance, and troubleshoot issues to ensure optimal performance and minimal downtime.\n\n- Collaborate with data engineers and analysts to optimize data sources and dashboard performance.\n\n- Implement and manage security protocols, ensuring compliance with data governance and privacy policies.\n\n- Automate monitoring and server management tasks using AWS and Tableau APIs.\n\n- Assist in the design and development of complex Tableau dashboards.\nProvide technical support and training to Tableau users.\n\n- Stay updated on the latest Tableau and AWS features and best practices, recommending and implementing improvements.\n\n\n\nQualifications -\n\n- Proven experience as a Tableau Administrator, with strong skills in Tableau Server and Tableau Desktop.\n\n- Experience with AWS, particularly with services relevant to hosting and managing Tableau Server (e.g., EC2, S3, RDS).\n\n- Familiarity with SQL and experience working with various databases.\nKnowledge of data integration, ETL processes, and data warehousing principles.\n\n- Strong problem-solving skills and the ability to work in a fast-paced environment.\n\n- Excellent communication and collaboration skills.\n\n- Relevant certifications in Tableau and AWS are a plus.\n\n\n\n\n\nA Tableau Administrator, also known as a Tableau Server Administrator, is responsible for managing and maintaining Tableau Server, a platform that enables organizations to create, share, and collaborate on data visualizations and dashboards. Here's a typical job description for a Tableau Admin\n\n1.\n\nServer AdministrationInstall, configure, and maintain Tableau Server to ensure its reliability, performance, and security.\n\n2.\n\nUser ManagementManage user accounts, roles, and permissions on Tableau Server, ensuring appropriate access control.\n\n3.\n\nSecurityImplement security measures, including authentication, encryption, and access controls, to protect sensitive data and dashboards.\n\n4.\n\nData Source ConnectionsSet up and manage connections to various data sources, databases, and data warehouses for data extraction.\n\n5. L\n\nicense Management: Monitor Tableau licensing, allocate licenses as needed, and ensure compliance with licensing agreements.\n\n6.\n\nBackup and RecoveryEstablish backup and disaster recovery plans to safeguard Tableau Server data and configurations.\n\n7.\n\nPerformance OptimizationMonitor server performance, identify bottlenecks, and optimize configurations to ensure smooth dashboard loading and efficient data processing.\n\n8.\n\nScalingScale Tableau Server resources to accommodate increasing user demand and data volume.\n\n9.\n\nTroubleshootingDiagnose and resolve issues related to Tableau Server, data sources, and dashboards.\n\n10.\n\nVersion UpgradesPlan and execute server upgrades, apply patches, and stay current with Tableau releases.\n\n11.\n\nMonitoring and LoggingSet up monitoring tools and logs to track server health, user activity, and performance metrics.\n\n12.\n\nTraining and SupportProvide training and support to Tableau users, helping them with dashboard development and troubleshooting.\n\n13.\n\nCollaborationCollaborate with data analysts, data scientists, and business users to understand their requirements and assist with dashboard development.\n\n14.\n\nDocumentationMaintain documentation for server configurations, procedures, and best practices.\n\n15.\n\nGovernanceImplement data governance policies and practices to maintain data quality and consistency across Tableau dashboards.\n\n16.\n\nIntegrationCollaborate with IT teams to integrate Tableau with other data management systems and tools.\n\n17.\n\nUsage AnalyticsGenerate reports and insights on Tableau usage and adoption to inform decision-making.\n\n18.\n\nStay CurrentKeep up-to-date with Tableau updates, new features, and best practices in server administration. A Tableau Administrator plays a vital role in ensuring that Tableau is effectively utilized within an organization, allowing users to harness the power of data visualization and analytics for informed decision-making.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data warehousing', 'sql', 'tableau', 'etl', 'data integration', 'python', 'aws iam', 'amazon redshift', 'aws administration', 'amazon rds', 'aws cloudformation', 'aws lambda', 'ansible', 'docker', 'amazon ec2', 'git', 'devops', 'server administration', 'linux', 'jenkins', 'terraform', 'aws', 'amazon cloudwatch']",2025-06-11 06:10:36
Business Operations Senior Analyst,"NTT DATA, Inc.",5 - 6 years,Not Disclosed,['Gurugram'],"Job Responsibilities:The incumbent may be required to perform all or a combination of the following essential functions as determined by business necessity\nResource who has strong process/business knowledge and experience with E2E of Order-to-Cash processes and functional knowledge of each of the sub-streams of Order to Cash.\nAs part of daily production activities: -\nUnderstanding and setting up newly received contracts/projects in the system (SAP, Peoplesoft etc.) and performing their maintenance activities as and when required. This requires accurately understanding and interpreting supporting documents.\nCo-ordinate with all O2C sub streams to ensure accurate and timely invoicing to the customer\nConstant reduction of unbilled items\nDelivering upon the SLAs and KPIs of the team from production standpoint.\nGetting on calls, discussions and meetings with Delivery managers, Project Managers, Vertical CFOs, Financial analysts and other key stake holders to maintain smooth communication of operational activities on a daily basis.\nResponsible for account operations tracking, process compliance activities and repeatable administrative actions with minimal coordination or ambiguity related to the process areas\nSomeone with analytical bent of mind who can work on providing continuous improvement ideas and has a considerable knowledge of revenue recognition methods from an accounting standpoint.\nWorks with leadership team to provide feedback, identifying training needs and perform root cause analysis for iterations/escalations\nWorks closely with different teams like resource mgmt., revenue, finance to ensure smooth month, quarter & year end closing process\nTechnical Skills\nProficient with MS office suite (MS Excel, MS outlook etc)\nAbility to use systems effectively for Projects/Time/Resource management and other functions\nExperience / Exposure on with SAP and Saleforce.com will be an added advantage\nFunctional Skills\n5 to 6 plus years of experience in at least one of the process areas Project/Time, Contracts/Invoicing/AR is preferred, Order management and master data management will be preferred\nResource who has strong process/Business knowledge and experience with Order-to-Cash process\nConducting UAT and securing Sign Offs for new requirements under supervision of Technical team/Lead\n1+ years of Operations or Back-office Support Services experience is preferred\nStrong communication (verbal and written) & analytical skills and the ability to understand complex business problems and propose solutions.\nManagement Skills\nSelf-managed individual who can effectively organize and manage activities, drive attention to detail, ensure quality of deliverables and optimize results\nFlexible to business requirements\nCoordinate with internal resources and stakeholders for the flawless execution of work\nEffectively communicating your insights and plans to cross-functional team members and management\nMonitoring deliverables and ensuring timely completion of change requests/requirements\nMaintaining SLAs and resolving issues within SLA\nCore Competencies\nEffective People Management skills with experience of independent team handling for at least 1-3 years.\nDrive strong performance management within the team for achieving team targets, maintaining optimum production standards and driving efficiency within the team\nUsing Leadership skills and change management for advocacy of organisational objectives\nStrong business acumen with ability to drive zero surprise operations and un-interrupted production.\nUsing innovation and initiative as tools for driving process improvements .\nDriving a strong channel of communication for effective stakeholder management.\nLocation Gurgaon/Bangalore\nNTT DATA is a $30 billion trusted global innovator of business and technology services. We serve 75% of the Fortune Global 100 and are committed to helping clients innovate, optimize and transform for long term success. As a Global Top Employer, we have diverse experts in more than 50 countries and a robust partner ecosystem of established and start-up companies. Our services include business and technology consulting, data and artificial intelligence, industry solutions, as well as the development, implementation and management of applications, infrastructure and connectivity. We are one of the leading providers of digital and AI infrastructure in the world. NTT DATA is a part of NTT Group, which invests over $3.6 billion each year in R&D to help organizations and society move confidently and sustainably into the digital future. Visit us at\nNTT DATA endeavors to make accessible to any and all users. If you would like to contact us regarding the accessibility of our website or need assistance completing the application process, please contact us at . This contact information is for accommodation requests only and cannot be used to inquire about the status of applications. NTT DATA is an equal opportunity employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status. For our EEO Policy Statement, please click . If you'd like more information on your EEO rights under the law, please click . For Pay Transparency information, please click.",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Business Operations', 'Order management', 'O2C', 'SAP', 'Order-to-Cash processes', 'Saleforce.com', 'Peoplesoft', 'process compliance activities', 'master data management']",2025-06-11 06:10:38
Jr.AI Engineer,Tekone It Services,1 - 3 years,1.5-6.5 Lacs P.A.,['Hyderabad'],"Position Overview\nWe are hiring five AI Engineers with 12 years of experience to join our dynamic team in Hyderabad. The ideal candidates will have a solid foundation in Large Language Models (LLMs), LangChain, and Generative AI (GenAI) frameworks. This is a great opportunity to work on innovative AI solutions, contributing to projects that integrate LLMs, prompt engineering, RAG pipelines, and cloud-based deployments.\nKey Responsibilities\nContribute to the design and development of AI-powered applications utilizing LLMs (GPT-3.5, GPT-4, Gemini).\nAssist in building LangChain-based pipelines and workflows, including LangSmith and LangGraph.\nSupport the implementation of Retrieval-Augmented Generation (RAG) frameworks using vector databases such as ChromaDB.\nApply prompt engineering techniques to optimize model responses and improve contextual accuracy.\nDevelop RESTful APIs using Flask or FastAPI to enable model consumption in production environments.\nWrite and manage data workflows using SQL, PySpark, and Spark SQL.\nDeploy and monitor models on Azure Machine Learning or AWS Bedrock platforms.\nCollaborate with cross-functional teams, including data scientists, engineers, and business stakeholders.\nRequired Skills\nProficiency in Python, SQL, PySpark, and Spark SQL\nHands-on experience with LLMs: GPT-3.5, GPT-4, Gemini\nKnowledge of LangChain, LangSmith, LangGraph\nFamiliarity with Vector Databases (e.g., ChromaDB) and embeddings\nExperience with prompt engineering and RAG-based architectures\nExposure to cloud platforms such as Azure ML or AWS Bedrock\nStrong understanding of REST APIs and version control systems (Git/GitHub)\nPreferred Qualifications\nBachelor's degree in Computer Science, Artificial Intelligence, Data Science, or a related field\nInternship or academic project experience in NLP, LLMs, or GenAI technologies\nFamiliarity with MLOps tools and practices (e.g., CI/CD, Airflow)\nStrong problem-solving abilities, attention to detail, and a collaborative mindset",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'Prompt Engineering', 'Artificial Intelligence', 'llm']",2025-06-11 06:10:40
AI Ml Engineer,Fulcrum Worldwide Software,4 - 8 years,15-30 Lacs P.A.,['Pune'],"The Role\nMachine learning and data science are interdisciplinary fields that require a combination of skills in mathematics, statistics, programming, and domain-specific knowledge to extract meaningful insights from data and develop predictive models.\nSkills Requirements\nMandatory Skillset - ML Techniques, any ML Framework, Gen AI COncepts, Azure, Python\nSecondary Skillset - AWS, or Google Cloud\n\nRequirements\nWork closely with cross-functional teams to understand business requirements and translate them into machine learning solutions.\nCollect, clean, and pre-process large datasets to prepare them for machine learning models.\nDevelop and implement machine learning algorithms and models for solving specific business problems.\nCollaborate with data engineers to ensure seamless integration of machine learning models into production systems.\nFine-tune models for optimal performance and conduct thorough testing and validation.\nStay updated on the latest advancements in machine learning and artificial intelligence and assess their potential impact on our projects.\nEffectively communicate complex technical concepts and findings to non-technical stakeholders.\nMonitor and maintain deployed models and update them as needed to adapt to changes in data or business requirements.\nAdhere to ethical standards and ensure that machine learning solutions comply with relevant regulations.\nProficiency in Python with hands-on experience in cloud platforms including GCP, AWS, and Azure; strong skills in API integration.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['NLP', 'Generative ai', 'Machine Learning', 'Deep Learning']",2025-06-11 06:10:41
Python Developer @ Infosys- Pan India,Infosys,4 - 9 years,Not Disclosed,"['Pune', 'Delhi / NCR', 'Mumbai (All Areas)']","Responsibilities A day in the life of an Infoscion • As part of the Infosys delivery team, your primary role would be to ensure effective Design, Development, Validation and Support activities, to assure that our clients are satisfied with the high levels of service in the technology domain. • You will gather the requirements and specifications to understand the client requirements in a detailed manner and translate the same into system requirements. • You will play a key role in the overall estimation of work requirements to provide the right information on project estimations to Technology Leads and Project Managers. • You would be a key contributor to building efficient programs/ systems and if you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you! If you think you fit right in to help our clients navigate their next in their digital transformation journey, this is the place for you!\n\nTechnical and Professional Requirements: • Primary skills: Process->Testing processes->Test Automation Process, Technology->Machine Learning->Python\n\nPreferred Skills: Process->Testing processes->Test Automation Process Technology->Machine Learning->Python\n\nAdditional Responsibilities: • Knowledge of design principles and fundamentals of architecture • Understanding of performance engineering • Knowledge of quality processes and estimation techniques • Basic understanding of project domain • Ability to translate functional / nonfunctional requirements to systems requirements • Ability to design and code complex programs • Ability to write test cases and scenarios based on the specifications • Good understanding of SDLC and agile methodologies • Awareness of latest technologies and trends • Logical thinking and problem solving skills along with an ability to collaborate\n\nEducational Requirements MCA,MSc,MTech,Bachelor of Engineering,BCA,BE,BSc,BTech",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Python', 'Django', 'Python Development', 'Flask']",2025-06-11 06:10:43
Ml Engineer/,Orcapod,3 - 5 years,Not Disclosed,['Pune'],"Dear Candidate,\n\n\nWe are currently hiring for our client in Pune location.\nKey Responsibilities\n\n• •Extraction, Transformation, and Loading (ETL) data from source systems and bringing into the desired format for better decision-making.\n• •Identify, analyze, and interpret trends or patterns in complex data sets (Sensor/Machine Data)\n• •Understand Data warehouses and Enterprise Data Lakes  (EDL) and how they work.\n• •Build and refine machine learning models to solve complex problems.\n• •Develop data pipelines for optimal model training and deployment.\n• •Explore new/advanced Data Science techniques/methodologies.\n• •Monitor and optimize model performance post-deployment.\n• •Building and testing the hypothesis using data.\n• •Maintain thorough documentation and communicate technical insights effectively.\n\nRequired Skills\n\n• •Strong knowledge in SQL & PySpark\n• •Hands-on experience in productionizing the ML models.\n• •Experience in working with cloud technologies will be an added advantage (Databricks)\n• •Hands-on experience on any visualization tool (Tableau Preferred)\n• •Strong knowledge of statistical techniques for data analysis\n• •Experience with data mining, machine learning and deep learning for analytical insights\n• •Good communication skills",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ETL', 'EDL', 'Machine Learning', 'SQL']",2025-06-11 06:10:45
AI Engineer,Fission Labs,3 - 8 years,15-25 Lacs P.A.,['Hyderabad'],"Company Name - Fission Labs\n\nApply Here - https://app.fabrichq.ai/jobs/0e46cebe-8b91-4a96-9061-950b66dc4d54\n\nAbout Us:\nHeadquartered in Sunnyvale, with offices in Dallas & Hyderabad, Fission Labs is a leading\nsoftware development company, specializing in crafting flexible, agile, and scalable solutions\nthat propel businesses forward.With a comprehensive range of services, including product development, cloud engineering, big data analytics, QA, DevOps consulting, and AI/ML solutions, we empower clients to achieve sustainable digital transformation that aligns seamlessly with their business goals.\n\nKey Responsibilities\nDesign and architect complex Generative AI solutions using AWS technologies\nDevelop advanced AI architectures incorporating state-of-the-art GenAI technologies\nCreate and implement Retrieval Augmented Generation (RAG) and GraphRAG solutions\nArchitect scalable AI systems using AWS Bedrock and SageMaker\nDesign and implement agentic AI systems with advanced reasoning capabilities\nDevelop custom AI solutions leveraging vector databases and advanced machine learning techniques\nEvaluate and integrate emerging GenAI technologies and methodologies\n\nTechnical Expertise Requirements\n\nGenerative AI Technologies\nExpert-level understanding of:\nRetrieval Augmented Generation (RAG)\nVector Database architectures\nAgentic AI design principles\n\nAWS AI Services\nComprehensive expertise in:\nAWS Bedrock\nAmazon SageMaker\nAWS AI/ML services ecosystem\nCloud-native AI solution design\n\nTechnical Skills\nAdvanced Python programming for AI/ML applications",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['LoRA', 'Vector Database', 'RAG', 'LLM', 'Python', 'GraphRag']",2025-06-11 06:10:46
AI / ML Engineer,Ecotech,3 - 5 years,15-20 Lacs P.A.,['Pune'],"Check full JD and apply here - https://app.fabrichq.ai/jobs/520384e9-7af4-4614-a7b7-9f14e98c183d\n\nRole & responsibilities\nEcotech is seeking an AI Engineer with 3-5 years of experience in developing and deploying ML, DL, and NLP solutions. The role involves building scalable AI models for business intelligence, process automation, and predictive analytics. The ideal candidate will lead end-to-end AI project lifecycles and collaborate with cross-functional teams.\n\nKey Responsibilities\nDesign, develop, and deploy Machine Learning and Deep Learning models for applications such as object detection, image processing, predictive analytics, and NLP-based applications\nLead the end-to-end lifecycle of AI projects from data collection to model deployment and optimization\nCollaborate with cross-functional teams to integrate AI solutions into existing business systems\nEnhance operational efficiency and automate processes through intelligent solutions\nMaintain high standards of quality, compliance, and scalability in AI models",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['RAG', 'Machine Learning', 'Python']",2025-06-11 06:10:48
Ml Engineer,Solix Technologies,5 - 10 years,15-25 Lacs P.A.,['Hyderabad'],"Solix Technologies Inc. is a leading provider of big data applications for enterprise archiving, data privacy, and advanced analytics. We are on a mission to help organizations manage and leverage their data for maximum value, efficiency, and compliance.\nJob Summary:\nWe are seeking a highly skilled and motivated Machine Learning Engineer with hands-on experience in Natural Language Processing (NLP) and Large Language Models (LLMs). You will play a key role in designing, developing, and deploying scalable ML/NLP solutions that drive intelligent automation and data insight across our platforms.\nKey Responsibilities:\nDesign and develop machine learning models, particularly in the domain of NLP and LLMs.\nFine-tune, evaluate, and deploy transformer-based models (e.g., BERT, GPT, T5, LLaMA, etc.).\nApply techniques such as named entity recognition (NER), text classification, semantic search, summarization, and question answering.\nWork with large-scale datasets to extract insights and build data pipelines.\nCollaborate with cross-functional teams including data engineers, product managers, and software developers.\nConduct experiments, model training, and optimization to improve accuracy and performance.\nStay up-to-date with the latest research in NLP, LLMs, and machine learning.\nRequired Skills and Experience:\nBachelor's or Masters degree in Computer Science, Data Science, AI/ML, or a related field.\nMinimum 5+ years of hands-on experience with NLP and LLMs\nProficient in Python and ML frameworks like TensorFlow, PyTorch, Hugging Face Transformers.\nStrong understanding of modern NLP techniques (tokenization, embeddings, attention mechanisms, etc.).\nExperience with ML lifecycle including model development, evaluation, and deployment (MLOps).\nFamiliarity with data handling libraries (Pandas, NumPy) and cloud platforms (AWS, GCP, or Azure).\nGood understanding of data preprocessing, feature engineering, and model validation techniques.\nExperience with open-source LLM fine-tuning and deployment.\nKnowledge of vector databases (e.g., FAISS, Pinecone) and retrieval-augmented generation (RAG).\nPrior experience with large-scale data systems or enterprise data environments.\nPublished papers or open-source contributions in the ML/NLP space.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['LLm', 'Large Language Model', 'Natural Language Processing', 'Ml Algorithms']",2025-06-11 06:10:50
AI Product Engineer,Tekone It Services,1 - 2 years,1-6 Lacs P.A.,['Hyderabad'],"Position Overview\nWe are seeking AI Product Engineers with 12 years of experience who can bridge the gap between product development and advanced AI technologies. This role involves working closely with AI models, APIs, and data pipelines, while also contributing to product design, user experience, and deployment strategies. You will work at the intersection of technology, user experience, and business outcomes.\nKey Responsibilities\nCollaborate with product managers and AI teams to design and develop AI-driven products leveraging LLMs (GPT-3.5, GPT-4, Gemini).\nTranslate business requirements into AI product features and work on building functional prototypes.\nDevelop and integrate LangChain-based workflows, including LangSmith and LangGraph, to enable intelligent app interactions.\nImplement Retrieval-Augmented Generation (RAG) pipelines and integrate vector databases (e.g., ChromaDB) to enhance AI performance.\nApply prompt engineering to customize model outputs based on product needs and use cases.\nBuild REST APIs and microservices using Flask or FastAPI to support model integration.\nWork with SQL, PySpark, and Spark SQL to manage and process structured and unstructured data.\nCollaborate with UI/UX teams to ensure seamless user interaction with AI components.\nSupport product deployment and monitoring on Azure ML or AWS Bedrock.\nRequired Skills\nStrong programming skills in Python, SQL, PySpark, Spark SQL\nUnderstanding of Generative AI, LLMs, and prompt engineering\nExperience with LangChain, LangGraph, LangSmith\nFamiliarity with vector databases and embedding techniques\nExposure to cloud platforms: Azure ML or AWS Bedrock\nREST API development using Flask or FastAPI\nExcellent problem-solving skills and product-oriented mindset\nPreferred Qualifications\nBachelor’s degree in Computer Science, AI/ML, Data Science, or related field\nInternship or academic experience in AI product development or applied NLP\nFamiliarity with MLOps concepts and product lifecycle best practices\nBasic understanding of UI/UX principles and user-centric design",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Langchain', 'Lang graph', 'Python', 'SQL']",2025-06-11 06:10:51
AIML Engineer,Throughbit Technologies,1 - 6 years,2-7 Lacs P.A.,['Coimbatore'],"Education:\nBachelor's degree in Computer Science, Data Science, Artificial Intelligence, or a related certifications or experience in NLP & CV.\n\nYears of Experience:\nMinimum 2 years of experience in Deep Learning, NLP,CV, MLOps and its related technologies.\n\nResponsibilities:\n- Design, develop, and deploy state-of-the-art NLP and CV models and algorithm\n- Collaborate with cross-functional teams to understand requirements and develop customised NLP & CV solutions and have experience in building the python backend using Flask / Django.\n- Database integration preferably using MongoDB or any other vector databases.\n- Maintain and improve the performance, accuracy, and efficiency of existing AI/ML models and their deployment on Cloud platforms (AWS) and monitor their performance using MLOps tools such as MLFlow, DVC.\n- Experience in building End to End data pipelines\n- Stay updated with emerging AI/ML technologies, LLMs ,RAG\n- Conduct regular performance evaluations of AI/ML models using production grade MLOps solutions.\n- Troubleshoot and resolve any issues arising from the implementation of NLP & CV models.\n- Develop and monitor the code that runs in production environments using MLOps practices.\n\nRequirements:\n- Strong experience with Deep learning and NLP frameworks such as TensorFlow or other open-source machine learning frameworks.\n- Experience of using both tensorflow and pytorch frameworks\n- Proficient in programming languages, such as Python or Java, and experience with AI/ML libraries.\n- Familiarity with the integration of APIs, such as REST API, OpenAI API, for implementing advanced AI-driven features.\n- Solid understanding of Machine learning and Deep learning algorithms, concepts, and best practices in a production environment using MLOps.\n- Experience with big data technologies, such as Hadoop and Spark, is a plus.\n- Strong problem-solving skills.\n- Excellent communication and teamwork skills, with the ability to collaborate effectively with team members from various disciplines.\n- Eagerness to learn and adapt to new technologies and industry trends.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Natural Language Processing', 'Py', 'Deep Learning', 'Java', 'Deep', 'Python']",2025-06-11 06:10:53
Gen AI Senior Lead,Client of Edge,11 - 15 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","The Company\nIndia's marquee global technology & consulting company. They are an international flag-bearer of technical and managerial excellence. With offices around the globe, the company has a comprehensive presence across multiple segments of the technology product and service industries as well as a blue-chip roster of clients for their Consulting engagements. They are a respected career company and a long-term wealth creator.\nThe Job\nWe are seeking a highly skilled Generative AI Senior Lead with 11+ Years of IT industry experience in which 5/6 years should be in AI/ML/DS domain, including Gen AI technologies to lead the design and deployment of cutting-edge AI solutions. The ideal candidate will possess deep expertise in Generative AI, strong analytical skills, and excellent communication abilities to engage with clients and internal teams. This role involves designing AI architectures, implementing scalable models, and ensuring solutions align with business objectives.\nRoles & Responsibilities:\nClient Interaction: Collaborate with clients to understand business needs and define AI solutions.\nSolution Design: Develop AI architectures addressing client objectives and technical requirements.\nMetrics Definition: Define success criteria and measurable KPIs with stakeholders.\nTechnical Implementation: Guide teams in deploying AI solutions efficiently.\nPerformance Monitoring: Ensure AI model accuracy and recommend improvements as needed.\nClient Collaboration: Act as the main point of contact between clients and internal teams.\nKnowledge Sharing: Keep up with Generative AI advancements and contribute insights.\nDocumentation: Maintain detailed technical reports and project records.\nSolution Design & Communication:\nAbility to design end-to-end AI solutions, from requirement elicitation to deployment strategy.\nExperience in architecting systems including data preprocessing, model integration, and optimization.\nExcellent verbal and written communication skills for client engagement and stakeholder\nYour Profile\nTechnical Proficiency:\nMachine Learning Algorithms: Linear/logistic regression, decision trees, random forests, SVMs, neural networks.\nData Science Tools: NumPy, SciPy, Pandas, Matplotlib, TensorFlow, Keras.\nCloud Platforms: AWS, Azure, GCP.\nNatural Language Processing (NLP): Transformer models, attention mechanisms, word embeddings.\nComputer Vision: CNNs, RNNs, object detection.\nRobotics: Reinforcement learning, motion planning, control systems.\nData Ethics & Responsible AI: Strong understanding of bias in ML, algorithmic fairness, ethical data handling, and transparency.\nSolution Design & Communication:\nAbility to design end-to-end AI solutions, from requirement elicitation to deployment strategy.\nExperience in architecting systems including data preprocessing, model integration, and optimization.\nExcellent verbal and written communication skills for client engagement and stakeholder presentations.\nSecondary Skill Set:\nDomain Knowledge: Understanding of industry applications (healthcare, finance, manufacturing).\nProject Management: Ability to oversee timelines, milestones, and deliverables, coordinating cross-functional teams.\nData Understanding: Strong grasp of feature engineering, preprocessing, and quality assurance.",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Generative Ai', 'Computer Vision', 'Machine Learning', 'Python', 'Tensorflow', 'Artificial Intelligence', 'Natural Language Processing', 'Solution Design']",2025-06-11 06:10:54
ML engineering expert,Winjit Technologies,5 - 7 years,Not Disclosed,['Hyderabad'],"5+ years of experience in Python programing and performance tuning and optimization.\nExperience on ML engineering, Knowledge on Feast, Kubeflow and MLFlow.\nDeep understanding on NumPy , Pandas, data frames etc.\nWorking knowledge on bigdata environment and data science model added advantage.\nStrong analytical and problem-solving skills, with attention to detail and ability to work in a fast-paced environment\nExcellent communication and collaboration skills, with ability to work with cross-functional teams\nKnowledge of machine learning and data science concepts",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Kubeflow', 'MLflow', 'Feast', 'Python', 'Data Science', 'Machine Learning']",2025-06-11 06:10:56
AI Tech Lead,Avaali Solutions,8 - 13 years,Not Disclosed,['Bengaluru'],"Job Title: AI Technical Lead\nLocation: Bengaluru, work from Avaali office\nEmployment Type: Full-time\nReports to: CTO\n\nKey Responsibilities\n1. Develop and Execute AI Initiatives\nCollaborate closely with business stakeholders at all levels to identify and implement AI-driven solutions that address key pain points and deliver measurable outcomes.\nActively participate in multidisciplinary and cross-functional (fusion) teams to support the entire lifecycle of AI projectsfrom ideation to execution.\nStay on top of cutting-edge AI trends, innovations, and best practices in the industry while leveraging these insights to deliver impactful solutions.\n2. Design and Implement AI Solutions\nArchitect AI-based solutions that align with Avaali's vision of operational cost optimization and margin improvement for clients.\nEnsure that all AI solutions are scalable, secure, governed, and adhere to applicable regulations and compliance standards.\nCreate personalized solutions aligned with specific business requirements and ensure the delivery of high-quality outcomes.\n3. Build and Scale the AI Practice in collaboration with the CTO\nDevelop and implement standardized methodologies, frameworks, and best practices to drive consistency and excellence across AI initiatives.\nCreate knowledge-sharing forums, training modules, and certifications to upskill internal teams and establish Avaali as a center of excellence for AI.\nThis person would support the CTO in this area (he/she will be an important team member in this activity)\n\nRequired Skills and Competencies\nDeep knowledge of AI/ML technologies, frameworks, and platforms, including hands-on experience with AI-based tools and cloud ecosystems.\nStrong expertise in designing enterprise-class AI systems that balance innovation with security, governance, and compliance needs.\nProven track record of managing large-scale AI initiatives across industries, including successful implementation of impactful solutions.\nOutstanding analytical and problem-solving skills combined with a strategic mindset that embraces emerging opportunities.\nQualifications\nBachelor’s or Master’s degree in Computer Science, Data Science, Engineering, or a related field. Advanced degrees preferred.\nMinimum 8 years of experience including in AI leadership roles, ideally including consultancy or enterprise environments.\nDemonstrated success in building and scaling AI capabilities and teams.\nExperience defining and managing budgets for AI initiatives while delivering cost-effective outcomes.\nBenefits of Joining Avaali\nBe a key player in driving transformational change in cutting-edge industries.\nWork with a highly skilled and innovative team eager to push the boundaries of what AI can achieve.\nOpportunity to develop AI solutions with real-world impact, empowering businesses to thrive in a digital-first era.\nIf you are ready to shape the future of AI at scale, we invite you to apply for this role.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Design', 'Generative Ai', 'Development', 'Artificial frameworks', 'Machine Learning', 'Tensorflow', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Deep Learning', 'SQL']",2025-06-11 06:10:57
AI Engineer,Channel Fusion,2 - 5 years,Not Disclosed,['Chandigarh'],"Job Title: AI Engineer\nRequired Experience :-2 to 5 years\n\nResponsibilities:\nArchitect, develop, and deploy advanced AI solutions, encompassing Machine Learning, Generative AI, NLP, and LLMs.\nRemain abreast of the latest AI advancements, actively researching and integrating emerging trends and technologies such as LLMOps, Large Model Deployments, LLM Security, Vector Databases, etc.\nStreamline data modeling processes to automate tasks, enhance data preparation, and facilitate data exploration to optimize business outcomes.\nCollaborate closely with cross-functional teams, including business units, accounts teams, researchers, and engineers, to translate business requirements into actionable AI solutions.\nExhibit expertise in responsible AI practices, ensuring fairness, transparency, and interpretability in all models.\nIdentify and mitigate potential risks related to AI and LLM development and deployment, emphasizing data trust and security.\nContribute to the professional development of the AI team by mentoring engineers, fostering knowledge sharing, and promoting a culture of continuous learning.\nThis role is based in a lab environment and involves hands-on, fast-paced, and high-intensity work. The ideal candidate should be proactive, adaptable, and comfortable working in a dynamic and demanding setting.\nQualifications:\nMinimum of 2+ years of hands-on experience in developing and deploying AI solutions, with a proven track record of success.\nMasters degree in Computer Science, Artificial Intelligence, or a related field (or equivalent\nexperience).\nProficiency in Machine Learning, NLP, Generative AI, and LLMs, including their architectures, algorithms, and training methodologies.\nUnderstanding of LLMOps principles, Prompt Engineering, In-Context Training, LangChain, and Reinforcement Learning.\nFamiliarity with best practices for large model deployment, monitoring, management, and scalability.\nExperience with Azure Cloud services.\nStrong communication, collaboration, and problem-solving abilities.\nCommitment to ethical AI practices and security standards.\nProficiency in deep learning frameworks and languages such as Azure ML platform, Python, PyTorch, etc.\nHands-on experience with ML frameworks, libraries, and third-party ML models.\nExpertise in building solutions using AI/ML/DL open-source tools and libraries.\nStrong analytical and problem-solving skills.\nAbility to write optimized and clear code, and address complex technical challenges effectively.\nSelf-motivated and fast learner, with a proactive approach to learning new technologies.\nProficiency in data analysis and troubleshooting skills.\nExperience in building AI/ML/DL solutions for NLP/text applications, with familiarity in reinforcement learning being advantageous.\nMinimum of 2 years of experience on AI/ML/DL projects, with specialization or certification in Artificial Intelligence being a plus.\nGood knowledge of Azure AI/Cognitive Services tools.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Azure Cloud Services', 'Machine Learning', 'Ai Solutions', 'Ai Platform']",2025-06-11 06:10:59
Full Stack Developer : AI Integration & Prompt Engineering Full Stack,Thydream Tech,1 - 4 years,Not Disclosed,['Coimbatore'],"Job Title: Full Stack Developer AI Integration & Prompt Engineering\n\nEmployment type: Full Time\n\nAbout the Role:\nWere looking for a talented Full Stack Developer with strong JavaScript skills and hands-on experience integrating AI models like ChatGPT into web applications. If you’re passionate about AI, prompt engineering, and building intelligent, responsive web apps, this is the perfect opportunity.\n\nKey Responsibilities\nBuild and maintain web applications using JavaScript frameworks (React.js, Node.js, Vue.js).\nIntegrate AI/ML models and APIs (e.g., OpenAI) into scalable web applications.\nDesign, test, and refine effective prompts to drive accurate and meaningful AI responses.\nCreate smooth and responsive AI-driven user experiences, including chat interfaces.\nOptimize application performance, ensuring high responsiveness and scalability.\nExperiment with different prompting strategies to improve AI performance and user interaction.\nCollaborate closely with AI engineers, UI/UX designers, and backend developers to deliver cohesive features.\nStay updated on the latest trends in AI/ML, NLP, and JavaScript frameworks.\n\nWhat We’re Looking For\nStrong experience with JavaScript, React, Redux, and TypeScript\nProven ability to integrate AI APIs (e.g., OpenAI, GPT models)\nHands-on experience in prompt engineering and AI model tuning\nGood understanding of Vector Search and AI application workflows\nExcellent English communication skills, both verbal and written\nFamiliarity with frontend and backend web development best practices\n\nWhy Join Us?\nBe at the forefront of AI innovation in real-world applications\nWork on exciting projects that merge web technology and artificial intelligence\nCollaborate with a passionate, forward-thinking teamRole & responsibilities",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['AI/ML', 'AI-driven user experiences', 'Redux', 'avaScript', 'React', 'TypeScript', 'NLP', 'and JavaScript frameworks']",2025-06-11 06:11:01
BI Engineering Sr Manager,Amgen Inc,4 - 8 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will be a Senior Manager BI & Visualization to lead and drive enterprise-wide business intelligence (BI) and data visualization initiatives. This role will be responsible for strategic planning, governance, and execution of BI and analytics solutions, ensuring that business leaders have access to actionable insights through advanced reporting and visualization platforms. The ideal candidate will have a deep understanding of BI tools, data visualization best practices, self-service BI enablement, and enterprise analytics strategy, working closely with business executives, data teams, and technology leaders to foster a data-driven culture.\nDevelop and execute a strategic BI & visualization roadmap, aligning with business goals, analytics objectives, and digital transformation strategies.\nLead and mentor BI, analytics, and visualization teams, fostering a culture of innovation, collaboration, and continuous learning.\nOwn the end-to-end BI lifecycle, including data modeling, dashboard development, analytics governance, and self-service BI adoption.\nOversee the implementation of modern BI solutions, leveraging tools like Power BI, Tableau, Looker, Qlik Sense, or similar to deliver high-impact visual insights.\nDefine and enforce data visualization best practices, ensuring dashboards are intuitive, user-friendly, and business-focused.\nDrive self-service BI enablement, empowering business users to explore, analyze, and act on data independently while maintaining data security and governance.\nCollaborate with business leaders, data scientists, and engineering teams to identify and prioritize high-value analytics use cases.\nOptimize BI infrastructure and reporting architecture, ensuring scalability, performance, and cost efficiency.\nEstablish BI governance frameworks, defining data access controls, security policies, KPI standardization, and metadata management.\nChampion the use of AI/ML-powered BI solutions, enabling predictive analytics, anomaly detection, and natural language-driven insights.\nMonitor BI performance metrics, ensuring reporting solutions meet business SLAs, operational efficiency, and data accuracy.\nStay ahead of emerging trends in BI, data visualization, and analytics automation, ensuring the company remains competitive in its data strategy.\nWhat we expect of you\nMasters degree and 8 to 10 years of experience in Computer Science, IT or related field OR\nBachelors degree and 10 to 14 years of experience in Computer Science, IT or related field OR\nDiploma and 14 to 18 years of experience in Computer Science, IT or related field.\nCertifications on PowerBI / Any other visualization tools\nBasic Qualifications:\n10-14 + years of experience in BI, analytics, and data visualization, with at least 5 years in a leadership role.\nExpertise in BI tools, including Power BI, Tableau, Looker, Qlik Sense similar enterprise BI platforms.\nStrong proficiency in data visualization principles, storytelling with data, and dashboard usability best practices.\nExperience in leading large-scale BI transformation initiatives, driving self-service analytics adoption across an enterprise.\nStrong knowledge of data modeling, dimensional modeling (star/snowflake schema), and data warehousing concepts.\nHands-on experience with SQL, DAX, Power Query (M), or other analytics scripting languages.\nStrong background in BI governance, data security, compliance, and metadata management.\nAbility to influence senior leadership, communicate insights effectively, and drive business impact through BI.\nExcellent problem-solving skills, with a track record of driving efficiency, automation, and data-driven decision-making.\nPreferred Qualifications:\nExperience in Biotechnology or pharma industry is a big plus\nExperience with Data Mesh, Data Fabric, or Federated Data Governance models.\nExperience with AI/ML-driven BI solutions, predictive analytics, and NLP-based BI capabilities.\nKnowledge infrastructure & deploayment automation for visualization platforms.\nExperience integrating BI with ERP, CRM, and operational systems (SAP, Salesforce, Oracle, Workday, etc.).\nFamiliarity with Agile methodologies and Scaled Agile Framework (SAFe) for BI project delivery.\nSoft Skills:\nExcellent analytical and troubleshooting skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals.\nAbility to learn quickly, be organized and detail oriented.\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['business intelligence', 'NLP', 'SAP', 'DAX', 'Workday', 'Oracle', 'Data Governance', 'Power Query', 'SQL', 'Salesforce']",2025-06-11 06:11:02
Finance Associate,"NTT DATA, Inc.",1 - 3 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nTo help analyzing and processing telecom invoices for NTT Global Networks\nWhat you'll be doing\nKEY RESPONSIBILITY\nUnderstanding the Telecom Expense Management\nValidating the Invoices of 200+ service providers from 100+ countries.\nEnsuring accuracy and timeliness in payments\nAny additional task given to the incumbent from time to time based on business needs\nKEY CONTACTS\nManager Finance\nSr. Manager Finance\nDIMENSION OF THE JOB\nTelecom Expense Management\nData management\nReport generation.\nDocumentation\nKEY ACCOUNTABILITY\nAccountability Statement\nTelecom Expense Management\nObjectives\nValidation of charges on Invoices from 200+ Service providers\nAssist with weekly monthly reporting requirements\nAssist with reconciliation of accounts with vendors\nAssist with cleaning up and structuring the database\nAssist with resolving the disputes on invalid charges with service providers\nMeans of Measurements\nTimely payment of Invoices for all valid charges\nAccountability Statement\nData Management & Report Generation\nObjectives\nGetting data from different sources and compiling in reports\nCreating weekly, monthly, quarterly reports in as per requirements for management review\nDesign reporting formats to provide accurate information in a clear and concise manner\nAd Hoc data collection, analysis and reporting as required. (i.e., Data/ Field Formatting, Data Storage, and report Generation)\nMeans of Measurements\nMIS review\nAccountability Statement\nDocumentation\nObjectives\nPreparing and maintaining documentation related to various processes and practice.\nMeans of Measurements\nDocumentation Audit Report\nEDUCATIONAL QUALIFICATIONS\nBachelors Degree in Commerce, MBA.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Finance analysis', 'project management', 'data management', 'data analysis', 'report generation', 'program management', 'business analysis', 'vlookup', 'data collection', 'artificial intelligence', 'mis', 'vendor', 'advanced excel', 'business consulting', 'technology consulting']",2025-06-11 06:11:04
Senior Backend Engineer,Welocalize,5 - 8 years,Not Disclosed,['Noida'],"Role Summary\nThe Senior Backend Engineer (Python & Node.js) is responsible for leading the design, implementation, and optimization of scalable machine learning infrastructure. This role ensures that AI/ML models are efficiently deployed, managed, and monitored in production environments while providing mentorship and technical leadership to junior engineers.\n\nYou can apply using the link below.",,,,"['Node.Js', 'Python', 'Cloud Development', 'GCP', 'Azure Cloud', 'Microservice Based Architecture', 'AWS']",2025-06-11 06:11:05
EDR Analyst - L1,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Mumbai'],"Key Responsibilities:\nMin 3 Years exp in EDR and Trend Micro.\nThe vendor should assess the existing endpoint security infrastructure and identify any gaps or vulnerabilities.\nThe vendor should deploy EDR agents on endpoints, servers, and critical systems within the organization's network.\nThe vendor should configure EDR agents to collect and analyze security events and activities on endpoints.\nThe solution should monitor endpoints for suspicious activities, such as malware infections, unauthorized access attempts, and unusual user behavior.\nThe solution should use behavioral analysis and machine learning to detect advanced threats and zero-day attacks.\nThe solution should generate real-time alerts for potential security incidents and provide guidance for incident response and remediation.\nThe vendor should enable endpoint forensics capabilities to investigate security incidents and identify the root cause of attacks.\nThe solution should capture and store detailed endpoint activity logs and artifacts for further analysis.\nThe vendor should integrate the tool with vulnerability management systems to assess the endpoint's security posture.\nThe EDR solution should be able to rollout patches or upgrades from the EDR management console for agents onboarded on the platforms.\nThe solution should alert and remediate endpoints with outdated or vulnerable software configurations.\nThe solution should provide real-time alerts for anomalies that could indicate potential threats.\nThe vendor should ensure the compatibility with other security systems, such as (but not limited to) SIEM, incident response tools, etc.\nThe solution should correlate network anomalies with potential threats, aiding in early threat detection.\nThe vendor is expected to deliver reports at periodic intervals as per Clients requirements.\nThe vendor should re-deploy the agent as and when there is a change in the infrastructure or the operating systems.\n\nKnowledge and Attributes:\nAbility to communicate and work across different cultures and social groups.\nAbility to plan activities and projects well in advance, and takes into account possible changing circumstances.\nAbility to maintain a positive outlook at work.\nAbility to work well in a pressurized environment.\nAbility to work hard and put in longer hours when it is necessary.\nAbility to apply active listening techniques such as paraphrasing the message to confirm understanding, probing for further relevant information, and refraining from interrupting.\nAbility to adapt to changing circumstances.\nAbility to place clients at the forefront of all interactions, understanding their requirements, and creating a positive client experience throughout the total client journey.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent qualification in IT/Computing (or demonstrated equivalent work experience).\nCEH certification is must.\n\nRequired Experience:\nEntry-level experience with troubleshooting and providing the support required in security network/ data center/ systems/ storage administration and monitoring Services within a medium to large ICT organization.\nBasic knowledge of management agents, redundancy concepts, and products within the supported technical domain (such as Security, Network, Data Centre, Telephony, etc.).\nWorking knowledge of ITIL processes.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['EDR Analysis', 'CEH', 'SIEM', 'troubleshooting', 'ITIL']",2025-06-11 06:11:07
Senior AI/ML Engineer - Blackstraw - Work from Office- Chennai,Blackstraw Technologies,4 - 9 years,Not Disclosed,"['Chennai', 'Mumbai (All Areas)']","Job Summary:\nWe are looking for a passionate and skilled AI/ML Engineer to join our team, focusing on cutting edge solutions in vector search, embeddings, and semantic similarity. In this role, you will design, develop, and optimize intelligent search systems that leverage state-of-the-art machine learning and deep learning techniques. You will collaborate with cross-functional teams to build scalable and efficient solutions that transform how we retrieve and process information.",,,,"['Artificial Intelligence', 'Machine Learning', 'Object Detection', 'Algorithm Development', 'Natural Language Processing', 'Image Recognition', 'Deep Learning', 'Pytorch', 'Huggingface', 'Video Processing', 'Opencv', 'Image Processing', 'Computer Vision', 'Optimize Vector Search Systems', 'Python', 'OCR']",2025-06-11 06:11:08
EUS Professional L2,"NTT DATA, Inc.",5 - 6 years,Not Disclosed,['Mumbai'],"What you'll be doing\nDiploma Degree/PG Diploma in IT/Computer Science from recognized institution.\nEngineer should have 5-6 years of experience/ expertise in areas Like trouble shooting and handling of various IT hardware's like PC, Printers, Laptops and other IT equipment.\nConfigure Desktops, Laptops. Should have expertise in Windows, Linux, client operating systems and related applications, Support Services for Software Application Mailing (webmail/MS outlook express/Outlook express), O365 and other system software.\nFollowing are the requirement for Desktop Engineers:\na. Hands-on experience troubleshooting desktop/ laptop/ peripheral\nb. At least 2 years of work experience as support executive preferably in Government/ PSU/Corporate sector\nc. Strong End User IT Infrastructure Domain knowledge\nd. Good communication skills and can converse in Hindi/ English",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Linux', 'active directory', 'DNS', 'troubleshooting', 'it infrastructure', 'artificial intelligence']",2025-06-11 06:11:10
Python + Gen AI Resources,"""Exciting Opportunity with a Leading IT ...",8 - 10 years,11-20 Lacs P.A.,"['Pune', 'Bengaluru', 'Mumbai (All Areas)']","Detailed JD *(Roles and Responsibilities)\nBachelors degree or higher in Machine Learning, Computer Science, Computational Linguistics, Mathematics or other relevant technical field from premier institute.\n•Strong foundation in Probability, Statistics, Linear Algebra, Calculus, Machine Learning and Generative AI/LLM.\n•Expertise in Deep Learning techniques and applications.\n•Strong understanding of Generative AI (GenAI) including math behind the models and its practical implementations.\n•Hands-on experience working with Large Language Model APIs like Azure OpenAI, Anthropic etc.. and cloud ecosystems like Azure, AWS, GCP, Databricks\n•Proficiency in LangChain, LangGraph, and working with Vector Databases for advanced data retrieval and AI workflows.\n•Proficiency in Python or similar programming languages, with experience in AI/ML libraries and frameworks such as TensorFlow, PyTorch, or Hugging Face.\n•Knowledge of financial products, including mutual funds, ETFs, and client segmentation, is a plus.\n•Excellent problem-solving and analytical skills.\n•Strong communication skills to explain complex models and insights effectively.\nMandatory skills*\nPython + Gen AI",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Machine Learning', 'GEN AI', 'Artificial Intelligence', 'Aiml', 'Al', 'Python', 'Ml']",2025-06-11 06:11:12
Data Science Instructor,TransOrg,1 - 4 years,Not Disclosed,['Gurugram'],"Pickl.AI (TransOrgs education brand) is looking for an instructor who is technically immersed in data science/data engineering as subjects. We are looking for a creative instructor who wants to accelerate their exposure to many areas in Machine Learning, loves wearing multiple hats and can take full ownership of their work.\n\nResponsibilities:\n• Design and deliver data science and data engineering training programs to students at Pickl.AI partner institutions\n• Teach and mentor students on topics such as data analysis, machine learning, statistics, data visualisation, and other relevant topics\n• Create and develop instructional materials, including lesson plans, presentations, assignments, and assessments\n• Keep up-to-date with the latest developments in data science and incorporate new and emerging trends into the curriculum\n• Include hands-on and relevant case studies in the topics that you are teaching\n• Provide guidance and support to students throughout their learning journey, including answering questions and providing feedback on assignments and projects\n• Collaborate with other instructors and team members to continuously improve the curriculum and training programs\n• Participate in meetings and training sessions to enhance instructional skills and techniques\n• Maintain accurate and up-to-date records of student attendance, progress, and grades\n\nRequirements:\n• Master's degree or Ph.D. in Computer Science, Data Science, Statistics, or a related field would be preferred\n• Excellent knowledge and understanding of data science concepts, techniques, and tools\n• Strong presentation and communication skills\n• Ability to work independently and in a team environment\n• Experience in teaching or mentoring students in a classroom or online setting is a plus\n• Passion for teaching and helping others learn.\n\nAbout the company: TransOrg Analytics has over a decade of specialization in machine learning and data science consulting. Pickl.AI is the education brand of TransOrg Analytics. Visit us at https://pickl.ai and www.transorg,com for details",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'tutoring', 'Education', 'Statistics', 'Machine Learning']",2025-06-11 06:11:13
Ai Ml Engineer,Confidential,7 - 10 years,8.4-14.4 Lacs P.A.,['Indore'],"Design, develop, and deploy ML models using Python, NLP, CV, RAG.\nOptimize model performance through DevOps practices with Kafka, REST APIs.\nPractical experience in building applications based on Large Language Models (LLMs)\n\n\nWork from home\nFlexi working",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'Artificial Intelligence', 'Natural Language Processing', 'Retrieval Augmented Generation', 'Machine Learning', 'Kafka', 'Computer Vision', 'Devops', 'Deep Learning', 'Restful Web Api Development', 'Python']",2025-06-11 06:11:15
Gen AI Consultant,Client of Edge,9 - 12 years,Not Disclosed,"['Hyderabad', 'Bengaluru', 'Delhi / NCR']","The Company\nIndia's marquee global technology & consulting company. They are an international flag-bearer of technical and managerial excellence. With offices around the globe, the company has a comprehensive presence across multiple segments of the technology product and service industries as well as a blue-chip roster of clients for their Consulting engagements. They are a respected career company and a long-term wealth creator.\nThe Job\nWe are seeking a highly skilled Generative AI Consultant with 9+ Years of IT industry experience in which 2/3 years should be in AI/ML/DS domain, including Gen AI technologies to lead the design and deployment of cutting-edge AI solutions. The ideal candidate will possess deep expertise in Generative AI, strong analytical skills, and excellent communication abilities to engage with clients and internal teams. This role involves designing AI architectures, implementing scalable models, and ensuring solutions align with business objectives.\nKey Responsibilities\nCollaborate with clients to understand AI project needs and define measurable success metrics\nDesign end-to-end Generative AI solutions with a focus on performance, security, and ethical AI\nDevelop models using GANs, VAEs, NLP transformers, and other generative techniques\nImplement AI solutions utilizing cloud platforms (AWS, Azure, GCP) and ML frameworks (TensorFlow, PyTorch, LangChain, Semantic Kernels)\nEnsure compliance with Responsible AI and Data Privacy principles, mitigating bias and ensuring ethical AI practices\nWork alongside engineers and data scientists to integrate and optimize AI models into real-world applications\nConduct performance monitoring, troubleshooting, and continuous improvements for AI systems\nStay updated with AI advancements and share knowledge with internal teams\nYour Profile\nPrimary Skills\nExpertise in Generative AI techniques, including image generation, text synthesis, and function calling\nStrong understanding of AI/ML algorithms, cloud computing, NLP, and computer vision\nProficiency in data science tools (NumPy, SciPy, Pandas, Matplotlib, TensorFlow, Keras)\nSolid grasp of Responsible AI, fairness in algorithms, and bias mitigation strategies\nExcellent communication and solution design skills, capable of translating business needs into technical AI architectures.\nSecondary Skills\nKnowledge of industry-specific AI applications (healthcare, finance, manufacturing, etc.)\nBasic project management abilities to oversee timelines and deliverables\nFoundational data preprocessing and quality assurance expertise",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Genrative Ai', 'Natural Language Processing', 'Computer Vision', 'Solution Design', 'Ml', 'Python']",2025-06-11 06:11:17
Hiring| IT-Recruiter| Naukri-Ehire| Noida,Info Edge,3 - 8 years,Not Disclosed,['Noida'],"Hi,\n\nKindly find the Job Description below.\n\nAbout Info Edge\nInfoEdge mission is to create world-class platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behaviour and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['IT Recruitment', 'Sourcing Profiles', 'IT Staffing', 'HR Consulting', 'Consultancy', 'Screening Resumes', 'Technical Recruitment', 'Consultancy Services', 'Recruitment Consulting']",2025-06-11 06:11:18
Scrum Lead- Project Management,Metlife,8 - 12 years,Not Disclosed,['Hyderabad'],"Position Summary\n\nMetLife established a Global capability center (MGCC) in India to scale and mature Data & Analytics, technology capabilities in a cost-effective manner and make MetLife future ready. The center is integral to Global Technology and Operations with a with a focus to protect & build MetLife IP, promote reusability and drive experimentation and innovation. The Data & Analytics team in India mirrors the Global D&A team with an objective to drive business value through trusted data, scaled capabilities, and actionable insights. The operating models consists of business aligned data officers- US, Japan and LatAm & Corporate functions enabled by enterprise COEs- data engineering, data governance and data science.\n\nRole Value Proposition:\nDriven by passion and a zeal to succeed, we are looking for accomplished Program Manager to structure, plan and handle multiple projects with minimum supervision and will be responsible for successful completion of projects supporting MGCC and US D&A leadership with various strategic initiatives in development and successful implementation of governance and process excellence practices.\nThis position would be responsible for complete adherence of the projects and its objectives and support all aspects of project management. This role will support development of best practices, processes and framework to achieve standardization and streamlining across various initiatives.\n\nJob Responsibilities\nServe as analytics program manager on data, analytics projects and POCs working with data engineers, business analysts, data scientists, IT teams, vendors, executive leaders, and business stakeholders\nDrive transparency leveraging tech stack and data, own progress reporting and proactively communicate status\nDrive delivery of projects using Agile methodology for data and analytics programs\nFacilitate scrum ceremonies including Sprint planning, Daily stand ups, sprint reviews and retrospectives\nResponsible for defining relevant program metrics, status reports and continuous measurement of program portfolio best practices\nLead, coach, support and mentor junior team members\nInteract with senior leadership teams across Data and analytics, IT and business teams.\n\nKnowledge, Skills and Abilities\nBachelors degree. Technology/IT specialization is preferred.\nMBA is a preferred qualification\n8-12+ years of progressive experience in project/program management role with proven people influencing experience including with virtual and global teams\nAgile project management/delivery experience is a must preferably with Data and Analytics background\nProficient in MS Office suite: Excel, PowerPoint, Project.\nUnderstanding of analytical tool stack, Azure Devboards, Jira, SharePoint is a plus\nCSM, SAFe Agilist certifications are preferred\nAbility to identify risks to project success and recommend course of action to prevent risk from negatively impacting the project; Effectively recognize when to escalate issues and options to senior management for resolution\nSuperior solutioning techniques, organizational skills and ability to manage multiple ongoing projects.\nExcellent collaboration and communication skills, both written and verbal\nDemonstrated competency with cross-group collaboration, organizational agility, and analytical planning\nStrong leadership & negotiation skills.",Industry Type: Insurance,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Agile Methodology', 'Sprint Planning', 'scrum', 'Azure Devops', 'Agile Framework', 'Backlog Refinement', 'Scrum Development', 'Sprint Review', 'Retrospective']",2025-06-11 06:11:20
LLM Developer,Turnberry Solutions,2 - 5 years,Not Disclosed,['Bengaluru'],"Job Description: As an LLM Evaluation Expert specializing in Coding, you will play a crucial role in assessing and improving our language models' coding capabilities. Your expertise will be instrumental in evaluating LLM-generated code responses, making high-level judgments, and setting the standard for what constitutes excellent AI-assisted coding.\nKey Responsibilities:\n• Critically analyze and evaluate code responses generated by our LLMs across various programming languages and paradigms\n• Exercise expert judgment to select the most appropriate and efficient code solutions from multiple LLM-generated options\n• Make informed decisions on behalf of our customers, ensuring that selected code meets industry standards, best practices, and specific client needs\n• Develop and write coding demonstrations to illustrate ""what good looks like"" in AI-generated code, setting benchmarks for quality and efficiency\n• Provide detailed feedback and explanations for your evaluations, helping to refine and improve the LLM's understanding and output\n• Collaborate with the AI research team to identify areas for improvement in the LLM's coding capabilities\n• Stay abreast of the latest developments in software engineering, coding standards, and AI to ensure our evaluations remain cutting-edge",,,,"['GenAI', 'Generative Ai Tools', 'Large Language Model', 'Artificial Intelligence', 'Machine Learning', 'LLM']",2025-06-11 06:11:21
AI Engineer/Architect,Transnational Ai,7 - 12 years,Not Disclosed,['Hyderabad'],"We are seeking a highly motivated AI Engineer with extensive experience in Python, Fast API, and event-driven microservice architecture. The position requires a strong technical background paired with a product-focused mindset.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Fast Api', 'Python', 'AWS', 'Machine Learning']",2025-06-11 06:11:23
Gen AI Developer,A Edge Client,3 - 5 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","The Company\nIndia's marquee global technology & consulting company. They are an international flag-bearer of technical and managerial excellence. With offices around the globe, the company has a comprehensive presence across multiple segments of the technology product and service industries as well as a blue-chip roster of clients for their Consulting engagements. They are a respected career company and a long-term wealth creator.\nThe Job\nWe are seeking an experienced  3+ years of IT experience ( 2 Years in AI/ML/DS Domain).\nGen AI  Development :\nData collection and preparation: Collect and prepare data for training and evaluating LLMs. This may involve cleaning and processing text data, or creating synthetic data.\nModel development: Design and implement LLM models. This may involve choosing the right architecture, training the model, and tuning the hyperparameters.\nModel evaluation: Evaluate the performance of LLM models. This may involve measuring the accuracy of the model on a held-out dataset, or assessing the quality of the generated text.\nModel deployment: Deploy LLM models to production. This may involve packaging the model, creating a REST API, and deploying the model to a cloud computing platform.\nResponsible AI: Should have proficient knowledge in Responsible AI and Data Privacy principles to ensure ethical data handling, transparency, and accountability in all stages of AI development. Must demonstrate a commitment to upholding privacy standards, mitigating bias, and fostering trust within data-driven initiatives.\nExperience in working with ML toolkit like R, NumPy, MatLab etc..\nExperience in data mining, statistical analysis and data visualization\nYour Profile\nRoles and Responsibility:\nLLM Development/Deployment Pipeline creation, workflows\nStudy and transform Gen AI PoCs to production grade deployment\nDesign machine learning systems, Run machine learning tests and experiments\nResearch and implement appropriate ML algorithms and tools\nDevelop machine learning applications according to requirements\nSelect appropriate datasets and data representation methods\nPerform statistical analysis and fine-tuning using test results\nTrain and retrain systems when necessary",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Gen AI', 'Gen AI Developer', 'Generative Ai', 'Artificial Intelligence', 'Computer Vision', 'Machine Learning', 'Generative Artificial Intelligence', 'Deep Learning', 'Python']",2025-06-11 06:11:24
Gen AI Developer - Lead,A Edge Client,5 - 9 years,Not Disclosed,"['Pune', 'Chennai', 'Delhi / NCR']","The Company\nIndia's marquee global technology & consulting company. They are an international flag-bearer of technical and managerial excellence. With offices around the globe, the company has a comprehensive presence across multiple segments of the technology product and service industries as well as a blue-chip roster of clients for their Consulting engagements. They are a respected career company and a long-term wealth creator.\nThe Job\nWe are seeking an 6 Years of IT industry experience in which 2/3 years should be in AI/ML/DS domain, including Gen AI technologies.\nWe are seeking an accomplished Generative AI Technical Lead to spearhead the development, implementation, and optimization of Generative AI solutions. As the Lead Developer, you will play a pivotal role in prompt engineering, pipeline creation, workflow establishment, and ensuring the quality of the technical outputs generated by the team. This role requires strong technical expertise in Generative AI, hands-on experience in development, and the ability to lead and guide a team effectively.\nPrimary Skill Set:\nGenerative AI Expertise: Good understanding of various Generative AI techniques, including GANs, VAEs, and other relevant architectures. Proven experience in applying these techniques to real-world problems for tasks such as image and text generation. Conversant with Gen AI development tools like Prompt engineering, Langchain, Semantic Kernels, Function calling. Exposure to both API based and opens source LLMs based solution design.\nTechnical Proficiency:\nMachine learning algorithms: Linear regression, logistic regression, decision trees, random forests, support vector machines, neural networks\nData science tools: NumPy, SciPy, Pandas, Matplotlib, TensorFlow, Keras\nCloud computing platforms: AWS, Azure, GCP\nNatural language processing (NLP): Transformer models, attention mechanisms, word embeddings\nComputer vision: Convolutional neural networks, recurrent neural networks, object detection\nRobotics: Reinforcement learning, motion planning, control systems\nData ethics: Bias in machine learning, fairness in algorithms\nYour Profile\nRoles & Responsibilities:\nTechnical Leadership: Lead a team of developers in the creation, implementation, and optimization of Generative AI solutions. Provide technical guidance, resolve challenges, and foster a collaborative environment.\nPrompt Engineering: Spearhead the design and development of prompt engineering strategies to influence and control the output of Generative AI models. Optimize prompts for desired results.\nPipeline Design: Design end-to-end data pipelines that encompass data preprocessing, feature engineering, model training, and deployment. Ensure pipelines are efficient, scalable, and well-documented.\nTechnical Review: Review the technical outputs generated by the team, including code, models, and pipelines. Ensure high-quality and maintainable solutions that adhere to best practices.\nTesting and Validation: Implement testing methodologies to validate the performance and accuracy of Generative AI models. Develop and execute unit tests, integration tests, and validation strategies.\nDeployment Strategy: Collaborate with DevOps and deployment teams to deploy trained models into production environments. Ensure smooth integration and monitor performance post-deployment.\nWorkflow Optimization: Identify opportunities to optimize development workflows, enhance productivity, and streamline processes. Implement tools and practices to improve efficiency.\nCollaboration: Interface with cross-functional teams, including data scientists, architects, and business stakeholders. Collaborate on solution design, implementation, and project milestones.\nDocumentation: Maintain comprehensive documentation of technical designs, code, and workflows. Ensure documentation is up-to-date, accessible, and understandable for team members.",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Gen AI', 'Gen AI Lead', 'Computer Vision', 'Open Source', 'Generative Ai', 'Artificial Intelligence', 'Machine Learning', 'Generative Artificial Intelligence', 'Robotics', 'Python']",2025-06-11 06:11:26
Python Technical Architect,Valuelabs,10 - 20 years,Not Disclosed,"['Bangalore Rural', 'Bengaluru']",Role: Python Full-Stack Architect\nLocation: Bangalore\nShift: 2:00 PM to 11:00 PM\n\n\nPreferred candidate profile\n8-10 years in full stack development and architecture.\n3-4 years in developing AI-based solutions.,,,,"['fastapi', 'DevOps', 'Pytest', 'React', 'Python', 'AI Tools', 'Postgresql', 'GraphQL', 'ORM', 'Machine Learning']",2025-06-11 06:11:27
Senior Manager - Change Management,Fidelity International,3 - 5 years,Not Disclosed,"['Bengaluru', 'Bengalure']","Title Senior Change Manager, Service Management\n\nDepartment Enterprise Service Management\n\nLocation Bangalore\n\nReports To Associate Director, Service Management\n\nLevel 6\n\nWe re proud to have been helping our clients build better financial futures for over 50 years. How have we achieved thisBy working together - and supporting each other - all over the world. So, join our Service Operations team, part of the Enterprise Service Management function and feel like you re part of something bigger.\n\nAbout your team\n\nThe Change Management function owns the centralised Change Management process for Technology and ensures a standardised implementation across all systems for efficient and prompt Change request handling to minimise risks to the Production environment. The team also administers change control over non-production environments. The team works in close coordination with other Technology and Business teams across Asia Pacific, Canada, India, and EMEA regions.\n\nAbout your role\nThe Senior Change Manager ensures that day to day the team functions effectively and we deliver a service of high quality that delights our users. Deep knowledge is required across the Change Management Practice, ServiceNow, PowerBI, OKRs, KPIs, AI/ML, Stakeholder Management, Risk, Audit, Compliance in order to act as our authority in this space. Comfortable with managing multiple stakeholders and competing demands, this role has a strong eye on improving what we do, with a focus on machine learning, deeper trending, industry standard metrics and AI so that the team is at the forefront of innovative solutions in a cost and time effective way. That said, you are also happy to roll up your sleeves and get involved in day to day activities if the need arises.",Industry Type: Banking,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['aiml', 'artificial intelligence', 'change management', 'stakeholder management', 'ml', 'project management', 'service management', 'program management', 'power bi', 'okrs', 'product roadmap', 'change request', 'user stories', 'change control', 'servicenow', 'product management', 'agile', 'jira']",2025-06-11 06:11:29
Snowflake - Senior Technical Lead,Sopra Steria,6 - 10 years,Not Disclosed,['Noida'],"Position: Snowflake - Senior Technical Lead\nExperience: 8-11 years\nLocation: Noida/ Bangalore\nEducation: B.E./ B.Tech./ MCA\nPrimary Skills: Snowflake, Snowpipe, SQL, Data Modelling, DV 2.0, Data Quality, AWS, Snowflake Security\nGood to have Skills: Snowpark, Data Build Tool, Finance Domain  \nPreferred Skills",,,,"['data', 'scala', 'administration', 'data warehousing', 'snowpipe', 'sql', 'star schema', 'cloud', 'scripting', 'security', 'java', 'data modeling', 'gcp', 'data vault', 'etl', 'architecture', 'snowflake', 'python', 'performance tuning', 'talend', 'microsoft azure', 'cloud platforms', 'javascript', 'data quality', 'build', 'aws', 'informatica']",2025-06-11 06:11:31
Learning Counselor - Inside Sales,Analytics Vidhya,1 - 5 years,Not Disclosed,['Gurugram'],"About Analytics Vidhya\nAnalytics Vidhya is on a mission to build next-generation AI Professionals across the globe. We aim to build the best community knowledge platform to learn, teach, apply and evaluate their data skills (data science, data engineering, data analysis, machine learning, Artificial Intelligence and more).\nThe AVians (our community members) seamlessly learn through our high quality AI programs, apply these skills to solve real life industry problems and find career defining jobs through Analytics Vidhya.\n\nWhy join Analytics Vidhya?\nAnalytics Vidhya is in the growth stage and while we are at it, we also ensure growth of our employees! Join us if you want to be the sales leader of tomorrow, join us for learning, join us for ownership - and get rewarded handsomely for your performance. \n\nResponsibilities\nBuild Relationships: Engage and follow up with prospects to nurture trust and long-term connections.\nManage Complete Customer Lifecycle: Oversee the sales process from lead engagement to program enrollment.\nCounsel Professionals: Recommend courses aligned with career goals via calls and emails.\nMaintain Records: Use CRM tools to track sales activities and manage pipelines.\n\nRequirements\nProven experience as B2C sales representative \nExcellent communication and interpersonal skills\nOutstanding negotiation skills to close sales with the ability to resolve issues and address complaints\nHigh customer empathy\n\nPerks and Benefits\nAt Analytics Vidhya, we believe in rewarding excellence and fostering a vibrant, success-driven team culture. Heres what you can look forward to as part of our dynamic sales team:\nDream Destinations: Pack your bags for international trips to exciting destinations as part of our celebrations for top-performing teams!\nExciting Prizes: Join an exceptional sales team and win incredible rewards like the latest iPhones, gift vouchers, and more.\nTeam Competitions: Participate in fun sales challenges to win cash prizes and uplift team spirit.\nQuarterly Reward Challenges: Achieve greatness with exclusive individual and team challenges, earning cash rewards for outstanding performance.\n\nCriteria\nShould have worked in B2C sales role in for at-least one year\nMin Qualification: Graduate/Diploma\nYour success is our success, and we cant wait to celebrate it with you—on stage, on trips, and with incredible rewards!\n***Analytics Vidhya holds the right to change/update any perks and benefits at its sole discretion***",Industry Type: E-Learning / EdTech,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['sales', 'Edtech', 'Admission Counselling', 'B2C Sales', 'Edtech Sales', 'Inside Sales', 'Business Development', 'Career Counselling']",2025-06-11 06:11:32
Business Manager - Corporate Sales (Key accounts),Info Edge,4 - 8 years,10-15 Lacs P.A.,['Chandigarh'],"Role: Manager Corporate Sales Naukri.com\n\nAbout Organization : Info Edge India Ltd\nInfo Edge is Indias leading consumer internet company known for its strong brands in recruitment (naukri.com, naukrigulf.com, iimjobs.com, firstnaukri.com), real estate (99acres.com), matrimony (Jeevansathi.com) and education (shiksha.com).\n\nStarting with a classified recruitment online business, naukri.com, the company has grown and diversified rapidly, setting benchmarks as a pioneer for others to follow either through setting up of in-house brands or through the route of strategic investments and acquisitions. along with large portfolio of our investee companies position our strong presence to consumer internet space.",,,,"['Media Sales', 'Enterprise Sales', 'Corporate Sales', 'B2B', 'Solution Sales', 'Key Account Management', 'Saas Sales']",2025-06-11 06:11:34
Jeevansathi II Noida II WFH after 3 months,Info Edge,1 - 5 years,Not Disclosed,"['Noida', 'New Delhi', 'Greater Noida']","About Info Edge\nInfo Edges mission is to create excellent platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behavior, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['Sales Closure', 'Inside Sales', 'Subscription Sales', 'Outbound Sales', 'Target Achievement', 'Sales Pitch', 'B2C Sales', 'Telesales', 'Deal Closure', 'Sales Strategy', 'Convincing Power', 'B2B Sales', 'sales executive', 'Sales Process', 'Selling Skills', 'Telecalling', 'Closing Deals', 'End To End Sales']",2025-06-11 06:11:36
Senior Product Manager,S&P Global Market Intelligence,6 - 11 years,Not Disclosed,"['Hyderabad', 'Gurugram', 'Ahmedabad']","\n\nAbout the Role: \n\nGrade Level (for internal use):\n11\n\nThe Team:-\n\nCI Pricing and Packaging is a pivotal pillar of Commercial Strategy - Commercial Models Implementation group that focuses on supporting and evolving existing commercial models (CSM 1.0, CSM+, Market Basics, Legacy products and ancillary services), designing new commercial models, partnering with product management and content functions on portfolio optimization, supporting our pricing and packaging efforts. In addition, this function partners with our technology teams on implementation and support of commercial models, and workflow optimization and automation through solutions like CI Subscription manager.\n\nResponsibilities and Impact:-\n\nWe are looking for a\n\nSenior Product Managerwith a unique blend of\n\ncommercial acumen, technical expertise, and cross-functional leadershipto drive the execution of scalable commercial models and go-to-market (GTM) strategies. This role is ideal for someone who thrives in a fast-paced environment and is passionate about solving customer problems through data, analytics, domain expertise, automation, and collaboration.\n\n\nCommercial Model ImplementationLead the build and execution of existing and upcoming commercial models and digital selling aligning them with business objectives and customer needs.\n\n\nCross-Functional ExecutionPartner with\n\nOperations, Marketing, Finance, and Productteams to drive tactical execution of GTM processes, including\n\nOrder-to-Cash and Enterprise system integrations.\n\n\nStrategic ExpansionExpand the scope of product management by combining\n\ntechnical depthwith\n\nbusiness strategyto identify new growth opportunities, improve operational efficiencies in sales processes, and take ownership of technology execution of various projects' lifecycles\n\n\nCustomer-Centric Problem SolvingApply an\n\noutside-in approachto understand customer pain points and translate insights into actionable product and process improvements.\n\n\nData & InsightsUtilize\n\nTableauand other analytics tools to present insights, track KPIs in operational efficiencies, and support data-driven decision-making.\n\n\nAI & AutomationLeverage\n\nAI toolsto build\n\nrepeatable, scalable processesand drive automation across Sales and operational workflows\n\n\nClient facing Lead the roll-out of CI Subscription Manager (client self-fulfillment system) to all of CI customer base\n\n\nWhat we are looking for:-\n\nRequired\n\nSkills:\n\n\n6+ years of experience in product management, with a strong track record in Product Management and project execution.\n\nProven ability to implement and scale commercial models.\n\nExperience working across multiple functions including operations, marketing, finance, and engineering.\n\nStrong technical and business acumen; ability to translate complex technical concepts into business value.\n\nProficiency in\n\nTableau/PowerBI or similar BI tools; excellent presentation and storytelling skills.\n\nFamiliarity with\n\nAI/ML toolsand their application in process automation and product development.\n\nExcellent communication, collaboration, and stakeholder management skills.\n\nBachelors degree in Business, Engineering, Computer Science, or a related field; MBA or equivalent is a plus.\n\n\nPreferred\n\nSkills:\n\n\nExperience with Order-to-Cash systems and enterprise integrations.\n\nBackground in SaaS, B2B, or enterprise technology environments.\n\nKnowledge of Agile/SAFe methodology and project lifecycle management.\n\n\nAbout S&P Global Commodity InsightsAt S&P Global Commodity Insights, our complete view of global energy and commodities markets enables our customers to make decisions with conviction and create long-term, sustainable value.\n\nWere a trusted connector that brings together thought leaders, market participants, governments, and regulators to co-create solutions that lead to progress. Vital to navigating Energy Transition, S&P Global Commodity Insights coverage includes oil and gas, power, chemicals, metals, agriculture and shipping.\n\nS&P Global Commodity Insights is a division of S&P Global (NYSESPGI). S&P Global is the worlds foremost provider of credit ratings, benchmarks, analytics and workflow solutions in the global capital, commodity and automotive markets. With every one of our offerings, we help many of the worlds leading organizations navigate the economic landscape so they can plan for tomorrow, today.For more information, visit http://www.spglobal.com/commodity-insights .\n\nWhats In It For\n\nYou\n\nOur Purpose:\n\nProgress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technologythe right combination can unlock possibility and change the world.Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P Global we transform data into Essential Intelligence, pinpointing risks and opening possibilities. We Accelerate Progress.\n\nOur People:\n\nOur Values:\n\nIntegrity, Discovery, Partnership\n\nAt S&P Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of\n\nintegrity in all we do, bring a spirit of\n\ndiscovery to our work, and collaborate in close\n\npartnership with each other and our customers to achieve shared goals.\n\nBenefits:\n\nWe take care of you, so you cantake care of business. We care about our people. Thats why we provide everything youand your careerneed to thrive at S&P Global.\n\nHealth & WellnessHealth care coverage designed for the mind and body.\n\n\n\nContinuous LearningAccess a wealth of resources to grow your career and learn valuable new skills.\n\nInvest in Your FutureSecure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.\n\nFamily Friendly PerksIts not just about you. S&P Global has perks for your partners and little ones, too, with some best-in class benefits for families.\n\nBeyond the BasicsFrom retail discounts to referral incentive awardssmall perks can make a big difference.\n\nFor more information on benefits by country visithttps://spgbenefits.com/benefit-summaries",Industry Type: Banking,Department: Product Management,"Employment Type: Full Time, Permanent","['bi', 'presentation skills', 'power bi', 'tableau', 'product management', 'management skills', 'order fulfillment', 'artificial intelligence', 'sales', 'marketing', 'story writing', 'stakeholder management', 'saas', 'go-to-market strategy', 'project execution', 'selling', 'agile', 'ml']",2025-06-11 06:11:37
Service Assurance Engineer,Techf Solutions,7 - 12 years,20-25 Lacs P.A.,['Indore'],"Required Experience – 7+yrs\nSkills - TSOM (TrueSight Operations Management), BHOM (BMC Helix Operations Management) and AIOps (Artificial Intelligence for IT Operations) OR APM tools such as Dynatrace, New Relic, AppDynamics, etc",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Appdynamics', 'Apm Tools', 'Artificial Intelligence', 'New Relic', 'Bmc Helix', 'Dynatrace', 'Service Assurance', 'BHOM', 'Truesight', 'IT Operations']",2025-06-11 06:11:39
Lead Designer,Aironic Artificial Intelligence,2 - 5 years,6-12 Lacs P.A.,['Bhopal'],"Responsibilities:\nDesign graphics for social media, websites, presentations, and marketing materials\nWork with the team to understand what the design needs to do and who its for\nMake sure all your designs match our brand style and message\nTake feedback positively and edit your work based on suggestions\nStay updated with new design trends and tools, especially AI-based design tools\nHelp turn complex ideas into simple, attractive visuals\nRequirements:\nAt least 2 years of experience as a graphic designer\nA professional portfolio showing your best work (this is a must)\nExpert in Adobe Photoshop and Adobe Illustrator• Experience using AI design tools like Midjourney, Adobe Firefly, or similar\nGood understanding of fonts, colors, layout, and visual storytelling\nPositive attitude, open to feedback, and good communication skills.",Industry Type: Software Product,"Department: UX, Design & Architecture","Employment Type: Full Time, Permanent","['Ux Design', 'Graphic Designing', 'UI Design', 'User Experience Design', 'Visual Design']",2025-06-11 06:11:40
Inside Sales II Noida II Jeevansathi,Info Edge,1 - 5 years,Not Disclosed,"['Noida', 'New Delhi', 'Greater Noida']","About Info Edge\nInfo Edges mission is to create excellent platforms that transform lives by continuously innovating. Our products and services are built keeping our customers in mind. We always delight our customers by delivering superior value through enhanced offerings on the internet and other platforms. Through our continuous investment across various businesses, especially in cutting-edge technology, machine learning and artificial intelligence (AI), we have built a robust system that constantly increases our predictive powers on customer behavior, and optimizes and improves our systems. Our various teams tirelessly work together to solve problems, innovate, and create something to empower our customers.",,,,"['Inside Sales', 'Communication Skills', 'Outbound Sales', 'Target Achievement', 'Sales Activities', 'Pressure Handling', 'B2C Sales', 'Telesales', 'Sales Closure', 'Sales Strategy', 'Convincing Power', 'B2B Sales', 'sales executive', 'Sales Initiatives', 'Selling Skills', 'Telecalling', 'Cold Calling']",2025-06-11 06:11:42
Project Manager (Non Technical),Eclinicalworks,1 - 5 years,Not Disclosed,['Bengaluru'],"Position Overview:\nSeeking highly skilled and motivated healow Project Manager to join the team. This role involves implementation of healow Genie, an AI powered virtual assistant for customers to enhance practice and patient efficiency. Strong background in implementation process, training and troubleshooting coupled with excellent communication, problem solving skills and comprehensive grasp of contact centre operations.\n\nJob Functions/Responsibilities",,,,"['Project Coordination', 'International Voice Process', 'Contact Center Operations', 'Computer Skills']",2025-06-11 06:11:44
AI ML Architect,Datametica,10 - 15 years,27.5-35 Lacs P.A. (Including Variable: 10%),"['Pune( Mundhwa )', 'Bengaluru( Hoodi )']","We are seeking an experienced AI/ML Architect to lead the design, development, and deployment of Generative AI solutions. This role requires a deep understanding of AI/ML architectures, technical leadership, and the ability to design robust, scalable, and production-ready systems. The ideal candidate will have extensive experience in cloud platforms like GCP and optionally AWS, Azure, or equivalent tools, combined with hands-on expertise in MLOps, containerization, data processing, and advanced model optimization. You will work closely with cross-functional teams, technical leadership, and stakeholders to implement state-of-the-art AI solutions that solve real-world challenges and drive business value.\n\nRoles & Responsibilities\n\n1) Technical Leadership\nLead the technical design and architecture of complex Generative AI systems.\nEnsure solutions align with business objectives, scalability requirements, and technical feasibility.\nGuide development teams through best practices, architecture reviews, and technical decision-making processes.\n\n2) Solution Architecture\nDesign and develop end-to-end Generative AI solutions, including data pipelines, model training, deployment, and real-time monitoring.\nUtilize MLOps tools and frameworks to automate workflows, ensuring scalable and repeatable deployments.\nArchitect robust solutions using GCP and optionally AWS, Azure, or open-source frameworks.\nDesign, train, and fine-tune AI/ML models, especially Generative AI and Large Language Models (LLMs), to address specific use cases.\nBuild conversational AI solutions and chatbots using frameworks such as LangChain, RAG (Retrieval-Augmented Generation), and Chain-of-Thought (COT) prompting.\n\n3) Production Deployment\nLead the deployment of Generative AI models into production environments.\nOptimize deployment pipelines leveraging tools like Docker, Kubernetes, and cloud-native services for orchestration.\nEnsure seamless integration of GenAI solutions into existing CI/CD pipelines.\n4) Data Processing & Feature Engineering\nBuild scalable ETL workflows for managing structured, semi-structured, and unstructured data.\nImplement data wrangling, preprocessing, and feature engineering pipelines to prepare data for Generative AI applications.\nOptimize workflows to extract meaningful insights from large datasets.\n\n5) Model Optimization\nIdentify and implement optimization strategies such as hyperparameter tuning, feature engineering, and model selection for performance enhancement.\nFocus on computational efficiency and scaling models to production-level performance.\n\n6) Pilot/POCs Development\nDrive the design and development of Proof of Concepts (POCs) and pilot projects to address customer requirements.\nCollaborate with delivery and product teams to scale successful pilots to production-grade solutions.\n\n7) Evangelization\nPromote and drive the adoption of Generative AI solutions across customer and delivery teams.\nProvide technical leadership and mentorship to teams working on GenAI projects.\nConduct workshops, training sessions, and knowledge-sharing initiatives to enable stakeholders.\n\n8) Continuous Improvement\nStay at the forefront of AI advancements, frameworks, and tools, including emerging concepts in Generative AI.\nExplore and evaluate techniques like Reinforcement Learning from Human Feedback (RLHF) and REACT (Retrieve, Extract, Adapt, Construct, Think) frameworks to enhance GenAI applications.\nRequired Skills & Qualifications\n10+ years of experience in AI/ML architecture, model development, and production deployment\nProven expertise in designing, implementing, and scaling Generative AI and LLM-based solutions\nHands-on experience with frameworks like LangChain, Retrieval-Augmented Generation (RAG), and advanced prompting techniques\nProficiency in advanced techniques such as embeddings and Chain-of-Thought (COT) prompting\nExperience working with cloud platforms, primarily GCP, with optional experience in AWS or Azure\nStrong understanding of MLOps tools, pipelines, and model monitoring in production\nProficiency in Python and SQL for model development and data processing\nExperience with data preprocessing, ETL workflows, and feature engineering for AI applications\nStrong knowledge of containerization tools like Docker and orchestration platforms like Kubernetes\nSolid understanding of CI/CD pipelines for continuous deployment and integration of AI solutions\nExperience working with large datasets for structured and unstructured AI applications\nDeep experience in model optimization, including hyperparameter tuning and computational efficiency strategies\nProven track record of leading POCs/pilots and scaling them to production-grade deployments\nPreferred Skills\nFamiliarity with Reinforcement Learning from Human Feedback (RLHF).\nExperience with REACT (Retrieve, Extract, Adapt, Construct, Think) frameworks.\nStrong understanding of orchestration for large-scale production environments.\nKey Attributes\nStrong technical leadership and mentorship abilities.\nExcellent communication and stakeholder management skills.\nStrategic thinking with the ability to architect scalable and future-ready AI systems.\nPassion for solving business challenges using state-of-the-art AI techniques.\nCommitment to staying updated with the latest advancements in AI/ML technologies.\nWhy Join Us?\nLead the development of cutting-edge Generative AI solutions for real-world applications.\nBe part of a collaborative, innovative, and technology-driven team.\nOpportunity to work with advanced AI/ML tools and frameworks.\nDrive innovation through technical leadership, mentorship, and solution evangelization.\nContinuous professional growth with access to the latest AI/ML technologies and frameworks.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Generative AI', 'Artificial Intelligence', 'Machine Learning', 'ML Ops', 'Large Language Model', 'Azure', 'Langchain', 'Natural Language Processing', 'CoT', 'Cloud Platform', 'LLM', 'Deep Learning', 'SQL', 'GCP', 'RAG', 'AWS', 'Python']",2025-06-11 06:11:45
Technical Recruiter - IT(Contractual),Eteam,3 - 8 years,3-7.5 Lacs P.A.,['Bengaluru( Kothanur )'],"Role Details:\nLocation : Onsite Kothanur Office, Bangalore\nPayroll Company : eTeam Infoservices Pvt. Ltd.\nMode : Onsite.\nType : Contract\nTenure : 1 year\nExtension/ Permanent Conversion : Yes, Basis on performance\nInterview Mode : Face 2 face on Monday, 02 June 2025\nNotice Period : Immediate to 15days Only\nRole Requirements:\nProven experience in end-to-end IT recruitment\nMust have handled niche and volume hiring (10+ closures/month)\nStrong market insights and ability to work under pressure\nExcellent stakeholder management\nWork Location:\nOnsite Kothanur Office, Bangalore\nAssignment:\nDuration: 6 months to 1 year and extendable (with potential for extension or permanent role)\nImmediate joiners preferred\nDeep Technical expertise in the below skills:\nProgramming Languages - Python / SQL - Data extraction\nMachine Learning & AI - Specially using Tensorflow / Pytorch.\nData Visualization - Power BIs (No Tableau)\nBig Data Technologies - Spark, Hadoop, Databricks\nCloud Engineers - GCP, AWS, Azure\nML - CI / CD - Docker & Kubernetes\nDatabase Management - MySQL, Mongo DB\nPrompt Engineers\nSnowflake Engineers\nFull stack - Node & React JS\nDataware & Application Architects",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Temporary/Contractual","['IT Recruitment', 'Technical Hiring', 'Internal Hiring', 'Niche Hiring', 'End To End Recruitment', 'Technology Hiring', 'Leadership Hiring', 'core it', 'Technical Recruitment', 'Talent Acquisition']",2025-06-11 06:11:47
"Senior ML Manager, Notifications Intel Science",Uplers,9 - 14 years,Not Disclosed,['Bengaluru'],"What Youll do:\nOwn the strategy, roadmap, and execution of notification intelligence and automation solutions.\nLead the development of GenAI-powered content generation, send-time optimization, and cross-channel orchestration systems.\nBuild intelligent systems that drive significant incremental revenue while minimizing customer fatigue and unsubscribes.\nDevelop and grow technical leadership within the team, modeling a culture of continuous research and innovation.\nCollaborate with Engineering and Product teams to scale decisioning systems to millions of notifications daily.\nAct as a subject matter expert, providing mentorship and technical guidance across the broader Data Science and Engineering organization.\n\nWe Are a Match Because You Have:\nBachelor's or Masters degree in Computer Science, Mathematics, Statistics, or related field.\n9+ years of industry experience, with at least 12 years of experience managing teams, and 5+ years as an individual contributor working on production ML systems.\nStrategic thinker with a customer-centric mindset and a desire for creative problem-solving, looking to make a big impact in a growing organization.\nDemonstrated success influencing senior-level stakeholders on strategic direction, based on recommendations backed by in-depth analysis, and excellent written and verbal communication skills.\nAbility to partner cross-functionally to own and shape technical roadmaps and the organizations required to drive them.\nProficient in one or more programming languages, e.g., Python, Golang, or Rust.\n\nNice to have:\nExperience with GCP, Airflow, and containerization (Docker).\nExperience building scalable data processing pipelines with big data tools such as Hadoop, Hive, SQL, Spark, etc.\nExperience in Bayesian Learning, Multi-armed Bandits, or Reinforcement Learning.\nFamiliarity with Generative AI and agentic workflows.\n\nPS: This role is with one of our clients who is a leading name in the Retail Industry.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Jvm', 'Cloud Platform', 'Machine Learning', 'Golang', 'Airflow', 'Java', 'Rust', 'GCP', 'AWS', 'Python']",2025-06-11 06:11:49
Senior AI/ML,Voxai,6 - 10 years,Not Disclosed,['Hyderabad'],"Voxai IT Solution Pvt. Ltd.\nhttp://www.voxai.com/\n\nJob Description\nAs a Senior AI/ML Engineer, you will play a key role in the design, development, and continuous improvement of our AI and machine learning solutions. Your primary responsibilities will include ensuring the scalability, accuracy, and reliability of our models, while collaborating with team members and providing technical expertise to drive success.\nJob Title: - Senior AI/ML Engineer Work Location: Hyderabad\n\nKey Responsibilities:\nModel Development: Design, develop, and deploy machine learning models and algorithms to address complex business problems.\nData Analysis: Analyze datasets to uncover trends, patterns, and insights, and ensure data quality and integrity for model training.\nAlgorithm Optimization: Continuously optimize machine learning models for performance, scalability, and efficiency, ensuring that they meet business and technical requirements.\nCollaboration: Work closely with cross-functional teams, including data scientists, engineers, and product managers, to integrate machine learning models into production systems.\nResearch & Innovation: Stay updated with the latest AI/ML trends and research, applying innovative approaches and solutions to improve models and processes.\nModel Evaluation & Tuning: Perform rigorous model validation, hyperparameter tuning, and evaluation to ensure model accuracy and generalization.\nAutomation: Develop and implement tools to automate and streamline ML workflows, including data preprocessing, feature engineering, and model retraining.\nMentorship: Provide guidance and technical leadership to junior team members, helping them with best practices, problem-solving, and professional growth.\nDocumentation: Document model development processes, experiments, and results for internal use and knowledge sharing.\nPerformance Monitoring: Monitor the performance of deployed models in production environments and troubleshoot issues as they arise.\nEthical AI Development: Ensuring AI solutions are ethical, fair, and unbiased while adhering to privacy and security standards.\nQualifications:\nBachelors or Masters degree in Computer Science or a related field.\n8+ years of experience in software development\nMachine Learning (Supervised, Unsupervised, and Reinforcement Learning)\nProgramming: Python, TensorFlow, PyTorch\nCloud Platforms: AWS/Azure/GCP\nModel Deployment (Docker/ Kubernetes)\n\nExperience with SQL / NoSQL databases (e.g.SQL Server, Dynamo DB, MongoDB, Cassandra).\nExperience in Natural language processing (NLP)\nExperience with various Design patterns(eg Pipeline, Ensemble, Transfer Learning) and Metrics (eg Precision, Recall, F1-Score ROC-AUC, MSE, RMSE, Confusion Matrix)\nExperience in evaluating Model Deployment metrics\nKnowledge of ML OPS is a plus\nStrong problem-solving and debugging skills.\nFamiliarity with Agile/Scrum methodologies.\nExcellent communication and interpersonal skills.\nAbility to work effectively in a collaborative team environment.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Python or pytorch or Tensorflow', 'Machine Learning', 'Docker or Kubernetes', 'AWS or Azure or GCP', 'SQL']",2025-06-11 06:11:51
IT Technical Recruiter,Eteam,3 - 7 years,5-7 Lacs P.A.,['Bengaluru'],"Role\nRole Details:\nLocation : Onsite Flatworld Solutions Pvt. Ltd. • Survey No.11, 3rd Floor, Indraprastha, Gubbi Cross, 81, Hennur Bagalur Main Rd, Kuvempu Layout, Kothanur, Bengaluru, Karnataka 560077, India.\nPayroll Company : eTeam Infoservices Pvt. Ltd.\nMode : Onsite.\nType : Contract\nTenure : 1 year\nExtension/ Permanent Conversion : Yes, Basis on performance\nInterview Mode : Face to face\nNotice Period : Immediate to 15days Only\nRole Requirements:\nProven experience in end-to-end IT recruitment\nMust have handled niche and volume hiring (10+ closures/month)\nStrong market insights and ability to work under pressure\nExcellent stakeholder management\nWork Location:\nOnsite Kothanur Office, Bangalore\nAssignment:\nDuration: 3 to 6 months (with potential for extension or permanent role)\nImmediate joiners preferred\nDeep Technical expertise in the below skills:\nProgramming Languages - Python / SQL - Data extraction\nMachine Learning & AI - Specially using Tensorflow / Pytorch.\nData Visualization - Power BIs (No Tableau)\nBig Data Technologies - Spark, Hadoop, Databricks\nCloud Engineers - GCP, AWS, Azure\nML - CI / CD - Docker & Kubernetes\nDatabase Management - MySQL, Mongo DB\nPrompt Engineers\nSnowflake Engineers\nFull stack - Node & React JS\nDataware & Application Architects. & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['It Hiring', 'Lateral Hiring', 'Niche Hiring', 'End To End Recruitment', 'C2H', 'h', 'Mass Hiring', 'Talent Acquisition']",2025-06-11 06:11:52
Corporate Development - M&A Analyst,Aspire Systems,1 - 3 years,Not Disclosed,"['Kochi', 'Chennai', 'Bengaluru']","Role Overview:\nWe are seeking a highly motivated and detail-oriented M&A & Fundraise Analyst with a strong interest and exposure to the IT Services and Artificial Intelligence domains to join our Corporate Development team. The ideal candidate will play a pivotal role in driving our growth strategy by working on M&A origination and execution in the Technology/IT Services space and fundraising activities for a cutting-edge Artificial Intelligence product. This role requires a strong blend of financial acumen, market research expertise, and a deep understanding of the Technology/IT Services and AI sectors",,,,"['Mergers And Acquisitions', 'Corporate Development', 'Financial Analysis', 'Financial Due Diligence', 'Fund Raising', 'M&A', 'Due Diligence', 'Finance Modelling']",2025-06-11 06:11:54
Sr. Project Manager,Useready,15 - 18 years,30-40 Lacs P.A.,"['Mohali', 'Bengaluru']","Job Summary:\nWe are seeking an experienced and detail-oriented Technical Project Manager, with strong interpersonal skills to lead and manage Data, Business Intelligence (BI), and Analytics initiatives across single and multiple client engagements. The ideal candidate will have a solid background in data project delivery, knowledge of modern cloud platforms, and familiarity with tools like Snowflake, Tableau, and Power BI. Understanding of AI and machine learning projects is a strong plus.\nThis role requires strong communication and leadership skills, with the ability to translate complex technical requirements into actionable plans and ensure successful, timely, and high-quality delivery with attention to details.\nKey Responsibilities:\nProject & Program Delivery\nManage end-to-end, the full lifecycle of data engineering and analytics, projects including data platform migrations, dashboard/report development, and advanced analytics initiatives.\nDefine project scope, timelines, milestones, resource needs, and deliverables in alignment with stakeholder objectives.\nManage budgets, resource allocation, and risk mitigation strategies to ensure successful program delivery.\nUse Agile, Scrum, or hybrid methodologies to ensure iterative delivery and continuous improvement.\nMonitor performance, track KPIs, and adjust plans to maintain scope, schedule, and quality.\nExcellence in execution and ensure client satisfaction\nClient & Stakeholder Engagement\nServe as the primary point of contact for clients and internal teams across all data initiatives.\nTranslate business needs into actionable technical requirements and facilitate alignment across teams.\nConduct regular status meetings, monthly and quarterly reviews, executive updates, and retrospectives.\nManage Large teams\nAbility to manage up to 50+ resources working on different projects for different clients.\nWork with practice and talent acquisition teams for resourcing needs\nManage P & L\nManage allocation, gross margin, utilization etc effectively\nTeam Coordination\nLead and coordinate cross-functional teams including data engineers, BI developers, analysts, and QA testers.\nEnsure appropriate allocation of resources across concurrent projects and clients.\nFoster collaboration, accountability, and a results-oriented team culture.\n  Data, AI and BI Technology Oversight\nManage project delivery using modern cloud data platforms\nOversee BI development using Tableau and/or Power BI, ensuring dashboards meet user needs and follow visualization best practices. Conduct UATs\nManage initiatives involving ETL/ELT processes, data modeling, and real-time analytics pipelines.\nEnsure compatibility with data governance, security, and privacy requirements.\nManage AL ML projects\nData & Cloud Understanding\nOversee delivery of solutions involving cloud data platforms (e.g., Azure, AWS, GCP), data lakes, and modern data stacks.\nSupport planning for data migrations, ETL processes, data modeling, and analytics pipelines.\nBe conversant in tools such as Power BI, Tableau, Snowflake, Databricks, Azure Synapse, or BigQuery.\nRisk, Quality & Governance\nIdentify and mitigate risks related to data quality, project timelines, and resource availability.\nEnsure adherence to governance, compliance, and data privacy standards (e.g., GDPR, HIPAA).\nMaintain thorough project documentation including charters, RACI matrices, RAID logs, and retrospectives.\nQualifications:\n  Bachelor’s degree in Computer Science, Information Systems, Business, or a related field.\nCertifications (Preferred):\nPMP, PRINCE2, or Certified ScrumMaster (CSM)\nCloud certifications (e.g., AWS Cloud Practitioner, Azure Fundamentals, Google Cloud Certified)\nBI/analytics certifications (e.g., Tableau Desktop Specialist, Power BI Data Analyst Associate, DA-100)\nMust Have Skills:\nStrong communication skills\nStrong interpersonal\nAbility to work collaboratively\nExcellent Organizing skills\nStakeholder Management\nCustomer Management\nPeople Management\nContract Management\nRisk & Compliance Management\nC-suite reporting\nTeam Management\nResourcing\nExperience using tools like JIRA, MS Plan etc.\nDesirable Skills:\n15 years of IT experience with 8+ years of proven project management experience, in delivering data, AI Ml, BI / analytics-focused environments.\nExperience delivering projects with cloud platforms (e.g., Azure, AWS, GCP) and data platforms like Snowflake.\nProficiency in managing BI projects preferably Tableau and/or Power BI.\nKnowledge or hands on experience on legacy tools is a plus.\nSolid understanding of the data lifecycle including ingestion, transformation, visualization, and reporting.\nComfortable using PM tools like Jira, Azure DevOps, Monday.com, or Smartsheet.\nExperience managing projects involving data governance, metadata management, or master data management (MDM).",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['delivery', 'bi projects', 'project management', 'data', 'interpersonal skills', 'microsoft azure', 'power bi', 'aiml', 'machine learning', 'business intelligence', 'artificial intelligence', 'tableau', 'stakeholder management', 'gcp', 'leadership', 'project delivery', 'scrum', 'agile', 'organizing', 'aws', 'communication skills']",2025-06-11 06:11:55
AWS Quicksight Developer,Wavicle Data Solutions,6 - 11 years,12-20 Lacs P.A.,"['Chennai', 'Coimbatore', 'Bengaluru']","Job Summary:\nWe are seeking an experienced Amazon QuickSight Developer to design and develop interactive dashboards, business intelligence (BI) reports, and data visualizations. The ideal candidate will have hands-on experience with Amazon QuickSight, a strong background in data analytics, and the ability to work closely with stakeholders to transform business requirements into actionable insights.\nKey Responsibilities:\nDesign, develop, and maintain BI dashboards, reports, and visualizations using Amazon QuickSight.\nIntegrate QuickSight with AWS data services like Amazon Redshift, Athena, S3, and RDS.\nOptimize dashboards and visualizations for performance, usability, and scalability.\nGather, analyze, and translate business requirements into technical specifications for BI solutions.\nImplement security settings, row-level security, and user access controls in QuickSight.\nCollaborate with cross-functional teams including data engineers, data scientists, and business analysts.\n\n\nInterested can send your resume to gowtham.veerasamy@wavicledata.com.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Quicksight', 'AWS', 'SQL']",2025-06-11 06:11:57
Executive - IOT,PGP Glass,5 - 10 years,5-8 Lacs P.A.,['Surat'],"DigIT Team\n\n\nPlant Digital & IOT Engineer\n\nExperience\n\n5-10 yrs\n\nSalary Range\n\nup-to 10L\n\nLocation\n\nKosamba (Preferrable)\n\nLanguages Known\n\nGujarati (Preferrable)\n\nEducation (min)\n\nB.E. (Electrical, Electronics, Mechanical, Computer, IT etc.)\n\nBasic Requrirement\n\n1\n\nWork ex in Manufacturing Plant\n2\n\nExperience of working in Digital / IOT / IIOT / OT technologies\n3\n\nGood communication skills\n4\n\nHigh level of confidence\n5\n\nReady to work in Plant\n6\n\nReady for daily travel to Plant locations\n7\n\nKnowledge / Information about PGP Glass\n\nAdditional Requirement\n1\n\nAbility to relocate to Other Plants within Gujarat\n2\n\nGood multi-tasking ability\n3\n\nProject Management skills\n4\n\nExposure to Digital / OT platforms - MES, EMS, Computer Vision, AI-ML\n5\n\nUnderstanding of SDLC (Software Development Life Cycle)\n6\n\nDocumentation skills\n\n7\n\nExposure to Data Analytics\n8\n\nWorked on Industry 4.0 technologies\n9\n\nDigital Protocols and devices\n10\n\nCloud Technologies exposure\n11\n\nAbility to drive projects\n12\n\nAbility to manage operations\n13\n\nAbility to work with partners / vendora\n14\n\nStakeholder management skills\n15\n\nAbility to conduct training\n16\n\nCross-function teams (CFT)\n17\n\nExposure to Six Sigma, Lean, Kaizen\n\nStrong Keywords\n\n\nOT\n\n\nIOT\n\n\nIIOT\n\n\nDigital\n\n\nManufacturing\n\n\nIndustry 4.0\n\n\nOther Keywords\n\n\nInnovation\n\n\nAnalytics\n\n\nOperations\n\n\nProtocols - RS485, RS232, MQTT, OPC UA, DDS\n\nBasic Software Skills - SQL,Database, HTML, CSS, Javascript / JS\n\nRobotics\n\n\nComputer Vision / CV\n\n\nAugmented Reality / AR\n\nVirtual Reality / VR\n\n\nMixed Reality / MR\n\n\nXR\n\n\nPredictive Maintenance\n\nCBM (Condition Based Monitoring)\n\nEMS (Energy Management System)\n\nMES (Manufacturing Execution System)\n\nAutomation\n\n\nBig Data\n\n\nSix Sigma\n\n\nKaizen\n\n\nLean Principles",Industry Type: Packaging & Containers,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Factory Automation', 'Industry 4.0', 'Digital Transformation', 'IOT', 'Cloud Computing', 'Artificial Intelligence', 'Machine Learning']",2025-06-11 06:11:59
Technical Architect,Talentship,15 - 22 years,Not Disclosed,"['Chennai', 'Bengaluru']","Job Overview\nWe are seeking an experienced Technical Architect to join our team. This role demands a highly skilled professional with deep expertise in software development, cloud operations, and modern web technologies. The Technical Architect will lead the design and delivery of scalable, secure, and high-performing solutions, leveraging their proficiency in JavaScript, Node.js, React, Angular, and cloud platforms. You will collaborate with cross-functional teams to architect innovative systems that align with business objectives.\nKey Responsibilities\nSolution Design & Architecture:\nDesign end-to-end technical architectures for complex applications, ensuring scalability, reliability, and performance.\nDefine system components, integration patterns, and data flows to meet business requirements.\nCreate architecture blueprints, technical roadmaps, and documentation for development teams.\nSoftware Development Leadership:\nProvide technical guidance to development teams, ensuring best practices in coding, testing, and deployment with a focus on JavaScript-based frameworks.\nLead the implementation of front-end and back-end solutions using React, Angular, Node.js, and related technologies.\nParticipate in code reviews and mentor developers to maintain high-quality standards.\nCloud Operations & Strategy:\nArchitect and optimize cloud-based solutions using platforms such as AWS, Azure, or Google Cloud.\nImplement cloud-native designs, including microservices, serverless architectures, and containerization (e.g., Docker, Kubernetes).\nOversee cloud infrastructure management, including cost optimization, security, and performance monitoring.\nCollaboration & Stakeholder Management:\nWork closely with product managers, business analysts, and stakeholders to translate business goals into technical solutions.\nCommunicate architectural decisions and trade-offs effectively to both technical and non-technical audiences.\nCollaborate with DevOps teams to ensure seamless CI/CD pipelines and infrastructure-as-code practices.\nInnovation & Problem Solving:\nStay updated on emerging technologies and evaluate their applicability to organizational needs.\nTroubleshoot complex technical issues and provide innovative solutions to enhance system performance and reliability.\nEnsure systems are secure, compliant with industry standards, and resilient to failures.\nRequired Skills & Qualifications\nExperience:\n12+ years of experience in software development, with at least 4+ years in a Technical Architect or similar role.\nProven track record of designing and implementing large-scale software systems with JavaScript-based technologies.\nExtensive hands-on experience with cloud platforms (AWS, Azure, GCP) and cloud operations.\nTechnical Expertise:\nMastery of JavaScript, including ES6+ syntax, asynchronous programming, and modern development practices.\nExpertise in Node.js for building scalable back-end services and APIs (REST, GraphQL).\nProficiency in front-end frameworks such as React and Angular, including state management (e.g., Redux, NgRx) and component-based architecture.\nStrong understanding of software design patterns, microservices architecture, and full-stack development.\nExperience with cloud technologies, including IAM, VPC, load balancing, auto-scaling, and serverless computing.\nFamiliarity with containerization tools (Docker, Kubernetes) and orchestration frameworks.\nKnowledge of database systems (SQL, NoSQL) and data modeling.\nSoft Skills:\nStrong problem-solving and analytical skills.\nExcellent communication and leadership abilities.\nAbility to work in a fast-paced, collaborative environment.\nEducation:\nBachelors degree in Computer Science, Engineering, or a related field (Master’s degree preferred).\nRelevant certifications (e.g., AWS Certified Solutions Architect, Microsoft Azure Architect, TOGAF) are a plus.\nPreferred Qualifications\nExperience with additional JavaScript frameworks or libraries (e.g., Vue.js, Express.js).\nProficiency with DevOps tools (e.g., Jenkins, Terraform, Ansible) and CI/CD pipelines tailored to Node.js and React/Angular projects.\nKnowledge of enterprise integration patterns and middleware technologies (e.g., Kafka, RabbitMQ).\nBackground in security best practices, including encryption, authentication, and compliance frameworks (e.g., GDPR, HIPAA).\nFamiliarity with AI/ML integration or big data technologies (e.g. Spark) is an advantage.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Mern Stack', 'Mean Stack', 'LLD', 'Artificial Intelligence', 'Javascript', 'Node.Js', 'High Level Design', 'React.Js', 'AWS', 'Technical Architecture', 'Microservices', 'ML']",2025-06-11 06:12:00
Azure Cloud Architect,Resolve Tech Solutions,8 - 13 years,25-40 Lacs P.A.,['Bengaluru'],"We're seeking an experienced Azure and AWS Architect with a strong background in designing and implementing cloud infrastructure and automation services. The ideal candidate will have hands-on experience with Azure and AWS, as well as a deep understanding of SAP technologies and integration points with cloud services. Additionally, the candidate should have experience in cloud migration and operations capabilities, with relevant Microsoft and AWS certifications.\nRequired Qualifications:\n- Bachelor's degree or higher in Computer Science, Information Systems, Engineering, Mathematics, or a related field",,,,"['Azure Cloud', 'Cloud Migration', 'Cloud Infrastructure']",2025-06-11 06:12:02
Technology Support Specialist Audit Function (RPA/AI/ML Solutions),T R Chadha,3 - 6 years,"50,000-90,000 P.A.","['Goregaon', 'Mumbai (All Areas)']","Job Title: Technology Support Specialist Audit Function (RPA/AI/ML Solutions)\nLocation: Mumbai\nEmployment Type: Full-Time\nJob Summary:\nWe are seeking a dynamic Technology Support Specialist to enhance the Audit function by developing and deploying RPA, AI, and ML solutions across various industries. The ideal candidate will work closely with clients to automate business processes, improve efficiency, and ensure compliance with industry standards.\nKey Responsibilities:\nCollaborate with Audit teams to identify opportunities for automation and technology integration.\nDevelop and implement RPA (Robotic Process Automation), AI (Artificial Intelligence), and ML (Machine Learning) solutions tailored to audit and compliance needs.\nAssess business processes across multiple industry verticals, identifying areas for automation and optimization.\nWork with clients to design and deploy automation strategies that enhance operational efficiency.\nProvide technical support, troubleshooting, and continuous improvement for deployed automation solutions.\nEnsure data security, compliance, and risk management within AI/ML-driven solutions.\nStay updated with the latest advancements in RPA, AI, and ML technologies and apply them effectively.\nPrepare detailed reports and documentation on automated audit processes and technology implementations.\nRequired Skills and Qualifications:\nBachelor’s or Master’s degree in Computer Science, IT, Engineering, or a related field.\n3+ years of experience in RPA, AI, and ML development, preferably within audit functions.\nStrong knowledge of automation tools such as UiPath, Automation Anywhere, Blue Prism, or similar.\nProficiency in AI/ML frameworks such as TensorFlow, PyTorch, Scikit-learn, or IBM Watson.\nExperience in data analytics, process optimization, and business process automation.\nStrong understanding of audit processes, compliance frameworks, and risk assessment.\nExcellent problem-solving skills with an analytical mindset.\nAbility to communicate effectively with both technical and non-technical stakeholders.\nExperience with cloud platforms (AWS, Azure, or Google Cloud) is a plus.\nPreferred Certifications:\nRPA Certifications (UiPath, Blue Prism, Automation Anywhere)\nAI/ML Certifications (Google AI, AWS ML, IBM Watson AI)\nAudit and Compliance Certifications (CISA)\nBenefits:\nCompetitive salary\nProfessional development and training opportunities\nExposure to cutting-edge automation technologies\nCollaborative work environment",Industry Type: Accounting / Auditing,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Machine Learning', 'Robotic Process Automation']",2025-06-11 06:12:03
Senior It Recruiter,Acesoft Labs.com,3 - 7 years,Not Disclosed,['Bengaluru'],"Job Summary:\nWe are seeking a highly motivated and experienced Senior IT Recruiter to join our dynamic talent acquisition team. In this role, you will be responsible for the full lifecycle recruitment for a variety of IT positions, with a primary focus on Contract-to-Hire engagements. You will leverage your deep understanding of the IT landscape and current industry trends to identify, attract, and secure top talent. This role requires a proactive individual with excellent communication and stakeholder management skills, capable of thriving in a fast-paced environment. You will also be expected to stay abreast of emerging technologies and their impact on talent acquisition.\nResponsibilities:\nManage the full recruitment lifecycle for IT positions, including sourcing, screening, interviewing, and offer management, with a strong emphasis on Contract-to-Hire roles.\nDevelop and implement effective sourcing strategies utilizing various channels such as job boards, professional networking sites (e.g., LinkedIn), employee referrals, and niche platforms.\nProactively build and maintain a strong pipeline of qualified IT candidates for current and future needs, particularly for C2H opportunities.\nConduct thorough and insightful interviews to assess candidates' technical skills, experience, and cultural fit.\nCollaborate closely with hiring managers to understand their specific requirements and provide regular updates on the recruitment progress.\nStay informed about current technology trends, including but not limited to Artificial Intelligence (AI) advancements such as ChatGPT, Grok AI, and AI Checkers, and understand their implications for talent acquisition and the required skill sets.\nUnderstand and effectively communicate the benefits and processes of Contract-to-Hire engagements to both candidates and hiring managers.\nManage candidate relationships throughout the recruitment process, ensuring a positive candidate experience.\nNegotiate offers and facilitate the onboarding process in collaboration with the HR team.\nMaintain accurate and up-to-date records of all recruitment activities within the Applicant Tracking System (ATS).\nContribute to employer branding initiatives to attract top IT talent.\nProvide market insights and competitive intelligence related to IT talent acquisition.\nAdhere to all company policies and legal requirements related to recruitment and hiring.\nQualifications:\nBachelor's degree in Human Resources, Business Administration, or a related field.2\nMinimum of 3 years of progressive IT recruitment experience, with a significant portion focused on Contract-to-Hire (C2H) roles.\nProven track record of successfully sourcing and placing IT professionals across various skill sets and levels.\nStrong understanding of the IT industry, including various technologies, roles, and skill demands.\nExposure to and understanding of current AI trends and their impact on the technology landscape, including familiarity with concepts related to ChatGPT, Grok AI, and AI Checkers, and the skills associated with these areas.\nExcellent sourcing skills, with proficiency in using LinkedIn Recruiter and other relevant sourcing tools.\nStrong interviewing and assessment skills, with the ability to evaluate both technical and soft skills.\nExceptional communication (both written and verbal) and interpersonal skills.\nAbility to build and maintain strong relationships with candidates and hiring managers.\nExcellent negotiation and problem-solving skills.\nStrong organizational skills and attention to detail.\nAbility to work independently and as part of a team in a fast-paced environment.\nFamiliarity with Applicant Tracking Systems (ATS).\nWork Schedule:\n5 Days Work from Office (Monday to Friday)\nLocation:\nMarathahalli, Bangalore\n\nInterested candidates, please share your updated resume to:\ndurgabhavani.b@acesoftlabs.com\nContact : 9701923036",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['C2H', 'It Hiring', 'Technical Hiring', 'Contract Staffing', 'Ai Techniques', 'Niche Hiring', 'Domestic Staffing']",2025-06-11 06:12:05
Senior Associate - Next Gen Forecasting,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will support an ambitious program to evolve how Amgen does forecasting, moving from batch processes (e.g., sales forecasting to COGS forecast, clinical study forecasting) to a more continuous process. The hardworking professional we seek is curious by nature, organizationally and data savvy, with a strong record of Finance transformation, partner management and accomplishments in Finance, Accounting, or Procurement. This role will help redesign existing processes to incorporate Artificial Intelligence and Machine Learning capabilities to significantly reduce time and resources needed to build forecasts. As the Next Gen Forecasting Senior Associate at Amgen India, you will drive innovation and continuous improvement in Finances planning, reporting and data processes with a focus on maximizing current technologies and adapting new technologies where relevant. This individual will collaborate with cross-functional teams and support business objectives. This role reports directly to the Next Gen Forecasting Manager in Hyderabad, India.\nRoles & Responsibilities:\nPriorities can often change in a fast-paced technology environment like Amgens, so this role includes, but is not limited to, the following:\nSupport implementation of real-time / continuous forecasting capabilities\nEstablish baseline analyses, define current and future state using traditional approaches and emerging digital technologies\nIdentify which areas would benefit most from automation / AI / ML\nIdentify additional process / governance changes to move from batch to continuous forecasting\nClosely partner with Business, Accounting, FP&A, Technology and other impacted functions to define and implement proposed changes\nPartners with Amgen Technology function to support both existing and new finance platforms\nPartners with local and global teams on use cases for Artificial Intelligence (AI), Machine Learning (ML) and Robotic Process Automation (RPA)\nCollaborate with cross-functional teams and Centers of Excellence globally to drive operational efficiency\nContributes to a learning environment and enhances learning methodologies of technical tools where applicable.\nServe as local financial systems and financial data subject matter expert, supporting local team with questions\nSupports global finance teams and business partners with centrally delivered financial reporting via tableau and other tools\nSupports local adoption of Anaplan for operating expense planning / tracking\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nBasic Qualifications:\nMasters degree and 1 to 3 years of Finance experience OR\nBachelors degree and 3 to 5 years of Finance experience OR\nDiploma and 7 to 9 years of Finance experience\nConsistent record of launching new finance capabilities\nProficiency in data analytics and business intelligence tools.\nExperience with finance reporting and planning system technologies\nExperience with technical support of financial platforms\nKnowledge of financial management and accounting principles.\nExperience with ERP systems\nResourceful individual who can connect the dots across matrixed organization\nPreferred Qualifications:\nExperience in pharmaceutical and/or biotechnology industry.\nExperience in financial planning, analysis, and reporting.\nExperience with global finance operations.\nKnowledge of advanced financial modeling techniques.\nBusiness performance management\nFinance transformation experience involving recent technology advancements\nPrior multinational capability center experience\nExperience with Oracle Hyperion/EPM, S4/SAP, Anaplan, Tableau/PowerBI, DataBricks, Alteryx, data lakes, data structures\nSoft Skills:\nExcellent project management abilities.\nStrong communication and interpersonal skills.\nHigh level of integrity and ethical standards.\nProblem-solving and critical thinking capabilities.\nAbility to influence and motivate change.\nAdaptability to a dynamic and fast-paced environment.\nStrong organizational and time management skills",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Next Gen Forecasting', 'DataBricks', 'Oracle Hyperion', 'data lakes', 'EPM', 'SAP', 'Alteryx', 'data structures']",2025-06-11 06:12:07
Salesforce Einstein+ AgentForce Developer,Ekloud Data Labs,5 - 10 years,Not Disclosed,[],"Key Responsibilities :\n1. Einstein Analytics : Develop and maintain Einstein Analytics solutions, including data preparation, data modeling, and dashboard creation.\n2. Einstein Prediction Builder : Develop and maintain predictive models using Einstein Prediction Builder, including data preparation, model training, and model deployment.\n3. Einstein Discovery : Develop and maintain Einstein Discovery solutions, including data preparation, insight generation, and recommendation engines.\n4. AI-Powered Solutions : Design and deploy AI-powered solutions using Salesforce Einstein, including chatbots, virtual assistants, and predictive maintenance.\n5. Integration : Integrate Salesforce Einstein with other Salesforce products, including Sales Cloud, Marketing Cloud, and Service Cloud.\n6. Data Preparation : Prepare and manage data for use in Einstein Analytics, Einstein Prediction Builder, and Einstein Discovery, including data cleansing, data transformation, and data loading.\n7. Model Training and Deployment : Train and deploy machine learning models using Einstein Prediction Builder, including model selection, hyperparameter tuning, and model evaluation.\n8. Solution Deployment : Deploy Einstein solutions to production environments, including configuration, testing, and validation.\nRequirements :\n1. Salesforce Experience : At least 6 years of experience with Salesforce, including Sales Cloud, Marketing Cloud, and Service Cloud.\n2. Agentforce Experience : At least 2 years of experience with Salesforce Agentforce, including Einstein Analytics, Einstein Prediction Builder, and Einstein Discovery.\n3. AI and Machine Learning Experience : At least 2 years of experience with AI and machine learning, including machine learning frameworks, deep learning, and natural language processing.\n4. Programming Skills : Strong proficiency in programming languages, such as Python, Java, and Apex.\n5. Data Analysis and Visualization : Strong skills in data analysis and visualization, including data preparation, data modeling, and data visualization.\n6. Communication and Collaboration : Excellent communication and collaboration skills, including the ability to work with cross-functional teams and stakeholders.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['agentforce', 'generative AI', 'Salesforce Einstein Analytics', 'Salesforce CRM']",2025-06-11 06:12:08
Regional Sales Manager,Innspark Solutions,7 - 12 years,10-14 Lacs P.A.,"['Kolkata', 'Chennai', 'Delhi / NCR']","Role: Regional Sales Manager\nJob Type: Full Time, Permanent\nLocation: Kolkata (East Region), Chennai (South Region), Delhi (North Region)\nNumber of Openings: 3\nExperience Required: Minimum 5 years experience in cyber security Field\nQualification: Bachelor’s degree in Business Administration, Marketing, Engineering, or a related field. MBA or equivalent postgraduate qualification is preferred.\n\n\nBrief Role Description\n\nWe are seeking a highly experienced and driven Sales Professional having 7–12 years of experience in B2B sales with minimum 5 years’ experience in cyber security field. The ideal candidate will take ownership of the complete sales cycle - from lead generation to deal closure - while building strong relationships with clients and driving business growth.\n\nResponsibilities:\n\nFormulate and implement strategic sales plans to meet revenue targets and drive customer base expansion within the East / South / North Indian region.\nProactively identify and pursue new business opportunities through market research, networking and cold callings.\nCoordinate with operations and technical teams and educate, empower the team to capture cybersecurity services opportunity at the end customer.\nFoster strong post-sales relationships to ensure customer satisfaction and identify opportunities for upselling and cross-selling.\nDeliver accurate sales forecasts and provide timely, detailed reports to Executive.\n\nSkills Required:\n\nAbility to handle complex sales cycles and decision-making units.\nSelf-motivated with a high level of accountability and initiative.\nExtensive professional network and comprehensive market knowledge of East / South / North India Corporate sector.\nThorough understanding of CRM systems with the ability to generate and analyze sales reports effectively.\nEngage with clients in strategic discussions to provide best in class cybersecurity.\nProficiency in delivering impactful presentations to clients, showcasing cybersecurity solutions with clarity and compelling manner.\nConduct market research and identify leads.\nProven track record in the sales of cybersecurity technologies or enterprise software solutions.\nExperience in engaging and collaborating with government entities and PSU clients.\n\nAbout Company\n\nInnspark is the fastest-growing Deep-tech Solutions company that provides next-generation products and services in Cybersecurity and Telematics. The Cybersecurity segment provides out-of-the-box solutions to detect and respond to sophisticated cyber incidents, threats, and attacks. The solutions are powered by advanced Threat Intelligence, Machine Learning, and Artificial Intelligence that provides deep visibility of the enterprise’s security.\n\nWe have developed and implemented solutions for a wide range of customers with highly complex environments including Government Organizations, Banks & Financial institutes, PSU, Healthcare Providers, Private Enterprises.\n\nWebsite: https://innspark.in/",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Cyber Security', 'Government Sales', 'Security Sales', 'Psu Sales', 'Cross Selling', 'Deal Closure', 'Ueba', 'OEM Sales', 'Soar', 'B2B Sales', 'Communication Skills', 'Upselling', 'Complex Sales', 'Lead Generation', 'Sales Forecasting', 'SIEM', 'Cyber Security Sales', 'Sales Planning', 'Sales Presentations']",2025-06-11 06:12:10
Palantir Developer,Algoleap Technologies,5 - 10 years,Not Disclosed,['Hyderabad'],"Work Responsibilities\n\nThe Palantir Developer will be responsible for designing and implementing modern data architecture solutions that facilitate enterprise-level transformation. Key responsibilities include:\n\nData Architecture Design: Create and optimize modern data architectures that support advanced analytics and operational requirements.\n\nPipelining: Develop and maintain efficient data pipelines using Palantir Foundry to ensure seamless data flow and accessibility for analytics.\n\nAdvanced Analytics: Create and deploy advanced analytics products that provide actionable insights to stakeholders, enhancing decision-making processes.\n\nArtificial Intelligence Integration: Collaborate with data scientists to incorporate AI and machine learning models into data pipelines and analytics products, enabling predictive capabilities.\n\nAgentic AI Exposure: Leverage knowledge of Agentic AI to develop systems that can autonomously make decisions and take actions based on data insights, enhancing operational capabilities.\n\nCollaboration: Work closely with cross-functional teams, including data scientists, engineers, and business analysts, to gather requirements and deliver tailored solutions.\n\nCloud Technologies: Utilize cloud-based tools and services to enhance scalability, security, and performance of data solutions.\n\nBest Practices: Implement best practices for data governance, quality, and security to maintain data integrity and compliance with relevant regulations.\n\nContinuous Improvement: Identify opportunities for process improvements and automation to enhance operational efficiency within data ecosystems.\n\nDocumentation: Maintain comprehensive documentation of data architecture designs, pipeline configurations, and analytics processes.\n\n\n\nArtificial Intelligence & Data Engineering: In this age of disruption, organizations need to embrace data-driven decision-making to\n\nDeliver Enterprise Value. Our Team Leverages Data, Analytics, Robotics, And Cognitive Technologies To Uncover Insights And Drive Transformation In Business. Key Initiatives Include\n\nData Ecosystem Implementation: Collaborate with clients to implement large-scale data ecosystems that integrate structured and unstructured data for comprehensive insights.\n\nPredictive Analytics: Utilize machine learning and predictive modeling techniques to derive actionable insights and predict future scenarios.\n\nAI Solutions Development: Work on developing AI-driven solutions that enhance data analytics capabilities, including natural language processing (NLP), computer vision, and recommendation systems.\n\nAgentic AI Development: Engage in projects that involve the development and deployment of Agentic AI systems capable of autonomous decision-making and action-taking based on real-time data.\n\nOperational Efficiency: Drive operational efficiency by utilizing automation and cognitive techniques for data management, ensuring timely and accurate reporting.\n\nClient Engagement: Engage with clients to understand their unique challenges and tailor solutions that align with their strategic objectives.\n\nInnovative Solutions: Research and implement innovative technologies and methodologies that enhance data analytics capabilities and drive business value.\n\nTraining and Support: Provide training and support to clients on data tools and platforms to ensure they can maximize the value of their data assets.\n\n\n\nRequired:\n\nEducation: Bachelors degree in Computer Science, Data Science, Engineering, or a related field.\n\n\n\n3+ years of hands-on experience in data extraction and manipulation using various tools and programming languages.\n\n3+ years of experience in engineering and developing Palantir pipelines, with a strong understanding of data integration techniques.\n\n3+ years of experience collaborating with Palantir Foundry data scientists and engineers on complex data projects.\n\n2+ years of experience working with AI and machine learning technologies, including model development, deployment, and performance tuning.\n\nFamiliarity with Agentic AI concepts and applications, including experience developing or working with autonomous systems is a plus.\n\nTechnical Skills: Proficiency in programming languages such as Python, SQL, or R, along with experience in statistical analysis and machine learning techniques.\n\nProblem-Solving: Strong analytical and problem-solving skills, with the ability to think critically and creatively.\n\nCommunication: Excellent interpersonal and communication skills to effectively convey technical concepts to non-technical stakeholders.",,,,"['Palantir Pipelines', 'Data Extraction', 'Agentic Ai', 'R', 'Artificial Intelligence', 'Palantir Foundry', 'Performance Tuning', 'manipulation', 'Machine Learning', 'Model Development', 'Python', 'SQL']",2025-06-11 06:12:11
Pega Senior Decision Architect,MNC IT,10 years,17-25 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Pega Senior Decision Architect (CDH)\nIf you want to be part of team destined to disrupt the market with fresh approach to MarTech\nimplementation, join us. We are looking for Pega CDH Senior System Architect who can work\nacross entire project lifecycle to help transition initiative from build to run. Candidate should\nhave good understanding of MarTech ecosystem to help organisation build and integrate Pega\nCDH platform with data and channels. He/she will be go-to expert for building healthy CDH\nplatform that is scalable and easy to use.\nExperience:\n4 - 8 years relevant experience delivering technology solutions with Pega platform with\nat least 4 years in CDH. Strong PRPC experience in past is added advantage.\nCertified Pega SA/SSA.\nAble to engage clients, gather business requirements, and translate them into platform\nbuild.\nGood understanding of Java, jQuery and other frameworks.\nAble to use APIs and other data ingestion frameworks.\nGood ability to work with multiple database solutions like snowflake, Hadoop,\nTeradata, databricks, etc.\nExperience working in agile squads and using tools like Jira/ADO/Confluence.\nExcellent oral and written communication skills with demonstrated ability to engage\nbusiness and technical stakeholders.\nAble to work with cloud platforms and artificial intelligence technologies.\nResponsibilities:\nDeliver best in class 1:1 customer engagement for our clients using Pega Customer\nDecision Hub.\nImplement integration with channels across digital, Mobile app, Outbound channels as\nwell as CRM.\nIntegrate CDH with other SaaS applications like Salesforce, Adobe including CDP like\nTealium.\nAble to ingest both real time and batch data into xCAR from on-prem and cloud data\nstores.\nGood understanding of simulation, scenario planner and BOE as well as decision\nstrategies, adaptive models, etc.\nAble to upgrade CDH versions.\nAble to add value to all phases of project lifecycle as well as support in presales work\non CDH.\nAble to conduct workshops, if needed.\nCollaborate with teams from engineering, data, channels, analytics, etc.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['Java', 'jQuery', 'SA/SSA']",2025-06-11 06:12:13
Digital Campaign Specialist,Torry Harris Business Solutions,6 - 7 years,9-10 Lacs P.A.,['Bengaluru'],"We are looking for a data-driven and creative Digital Campaign Specialist to lead the planning, execution, and optimization of performance-based digital campaigns across multiple channels. The primary focus of this role is to generate high-quality Marketing Qualified Leads (MQLs) that feed into the sales funnel and support pipeline growth. You will work closely with marketing, sales, content, and design teams to craft compelling, targeted campaigns that resonate with our audience and drive measurable business results.\n\nRoles and Responsibilities\nBuild a strong sales pipeline by generating leads/enquiries through sponsored updates and digital campaigns (LinkedIn, Twitter, YouTube, Google AdWords, etc.).\nDevelop, implement, and manage our social media and paid marketing strategy for webinars/events and thought leadership content.\nConduct LinkedIn Lives, Podcasts, Webinars to generate marketing qualified leads.\nLeverage tools such as Google Ads, LinkedIn Campaign Manager and HubSpot to execute and monitor campaigns.\nManage & measure the success of every social media & paid campaigns.\nMonitor and analyze MQL volume, cost per lead, and conversion rates across channels.\nEnsure seamless integration and tracking of leads via CRM and marketing automation platforms.\nPerform A/B testing on campaign elements to improve lead quality and performance.\nCollaborate with copywriters and designers to ensure content is informative and appealing.\nDeliver regular reports and insights to stakeholders with actionable recommendations.\nCollaborate with sales to ensure MQL handoff is timely and aligned with SLAs.\nCommunicate with industry professionals and influencers via social media to create a strong network.\nManage and facilitate social media communities by responding to social media posts and developing discussions.\n  Required Skills:\n  6-7 years of experience in digital marketing with a strong focus on lead generation and campaign management.\nProven record of achieving MQL and lead conversion targets.\nFamiliarity with ABM (Account-Based Marketing) strategies.\nStrong knowledge in diverse types of SMM techniques (ad campaigns, tools, etc.).\nGood Knowledge of marketing automation, analytics, and AI-based marketing tools.\nAbility to work both independently and in a collaborative environment.",Industry Type: IT Services & Consulting,Department: Marketing & Communication,"Employment Type: Full Time, Permanent","['digital marketing', 'digital', 'marketing strategy', 'adwords', 'digital campaigns', 'google adwords', 'mql', 'accounting', 'media', 'abm', 'artificial intelligence', 'sales', 'ad agency', 'marketing automation', 'campaign management', 'analytics', 'marketing', 'smm', 'campaigns', 'paid marketing', 'lead generation', 'social media']",2025-06-11 06:12:15
Python Developer,Numerator,6 - 11 years,Not Disclosed,[],"Numerator provides unparalleled consumer insights at a massive scale. Our technology harnesses data through the application of gamified mobile apps and sophisticated web crawling technology to deliver an unmatched view of consumer shopping and purchase experience.\nNumerator is looking for a passionate Senior Software Developer to join our Datasources Team. As part of our Receipt Processing and Attribution team, you will be responsible for our receipt processing pipeline, data attribution system, and internal tools that processes and adds attributes to over a billion receipts captured through our mobile panel app. This is a high growth and impactful role that will give you tons of opportunity to drive decisions for projects from inception through production.",,,,"['python', 'SQL', 'django', 'MySQL', 'Postgresql', 'Jenkins', 'Docker', 'Terraform', 'Ansible', 'MongoDB', 'Python Development', 'AWS', 'Elastic Search', 'Kubernetes']",2025-06-11 06:12:16
CTO / Technical Co-founder ( Equity Only | Remote),Kalythe Growth Studio,2 - 7 years,0 P.A.,['Delhi / NCR'],Equity-only role\nSeeking a CTO/Technical Co-founder to join us at idea-to-MVP stage for a startup building an AI-powered travel planning app. Looking for:\nStrong technical fundamentals\nEntrepreneurial mindset\nExcitement about building a product,Industry Type: Management Consulting,Department: Product Management,"Employment Type: Full Time, Permanent","['Fullstack Development', 'Application Development', 'QA Testing', 'Artificial Intelligence', 'Aiml', 'QA Automation', 'Ml Algorithms', 'Machine Learning']",2025-06-11 06:12:18
"Technical Systems Developer - Automation, Airtable, AI, Python, N8N",Hot Print Co,3 - 8 years,Not Disclosed,[],"Were looking for a sharp, self-directed, and versatile technical generalist/builder who can help us automate operations, reduce costs, and build scalable tools across two fast-moving businesses. Someone with a developer skillset that is ready to take on a variety of challenges.\nThis is a full-time, project-based role where youll go deep on one project at a time — usually focused on automation, backend logic, AI integration, or internal tools.\nYou won’t be handed perfect specs. You’ll collaborate with the founder to understand the current workflows and goals, then be expected to execute independently.\nThis role is ideal for someone who’s excited about using technology to drive real business ROI — not just cool experiments, but tangible results like lower costs, higher margins, more revenue, and fewer people needed to run the company. This is not a job for someone who only wants to code for fun — but if you're the kind of person who loves solving real-world problems with technology and seeing your work directly impact business growth and drive clear results, this is for you.\nWHAT YOU'LL DO\nYou’ll work directly with the founder to tackle high-impact projects that reduce costs, improve margins, and boost revenue — all through tech.\nThis is a full time role, but it is project-driven. You’ll take ownership of one project at a time, execute independently, and then move on to the next. Projects vary from quick wins to longer-term builds. You’ll help scope the best tool or approach for each job — no fixed tech stack.\nFirst few projects:\n-Set up a self-hosted n8n server and migrate Make.com automations.\n-Audit and reduce Google Workspace subscription costs.\n-Learn, document, and manage our Airtable setup.\n-Build automations for lead gen and Instagram scraping.\n-Integrate Airtable with Missive to sync and manage contact data.\nDown the line, you may help us:\n-Build a custom AI-powered SMS sales agent.\n-Automate follow-ups, customer service, and content repurposing.\n-Audit our SaaS tools to cut unnecessary spending.\nSKILLS AND TOOLS YOU NEED\nWe don’t expect one person to know every tool on earth. But the more of this you’ve done before, the faster you’ll ramp up:\n-Automation tools (especially n8n)\n-Airtable (advanced base design and scripting)\n-Twilio (SMS integrations and logic)\n-Missive (email/SMS support integration)\n-CRM (HighLevel)\n-Strong backend experience (Node.js or Python)\n-Solid understanding of APIs, webhooks, and data flow logic\n-Basic scraping and browser automation (any framework)\n-AI tooling (prompt engineering, OpenAI APIs, etc.)\n-Great communication, collaboration, and planning skills\nWHAT WE EXPECT\n-You can translate messy business problems into clear technical solutions.\n-You thrive without daily check-ins. We’ll sync up to plan — you take full ownership of projects and take it from there.\n-You’re comfortable documenting systems so they’re maintainable long-term.\n-You’re results-focused. It's about ROI. You care more about the business impact than the tech used to get there.\nYOUR IMPACT\nThe goal of this role is simple: make the company more profitable, more scalable, and less reliant on human labor.\nTech is the tool we’re using to do that — whether it’s automation, AI, backend logic, or all of the above. Every project we give you should tie back to reducing costs, increasing margins, or helping us scale with fewer people.\nThis is a key hire that touches all departments — sales, operations, marketing, and more — by solving bottlenecks with smart technical solutions.\nYou’ll be building a lot of cool stuff. But it all has to work. It all has to matter.\nWORK STYLE\nThis is a role for someone who works well independently. You’ll usually collaborate closely with the founder during project kickoffs — especially when we’re mapping out a process that isn’t documented. After that, you’ll be expected to work solo, with periodic check-ins and access to support when needed.\nEach project may have its own “ramp-up time,” but we expect you to begin executing within the first couple of days. Over time, your only ongoing responsibility will be to maintain the systems you’ve built (e.g., fixing Airtable issues when they pop up or resetting things for new sales cycles).\nWORK HOURS\nOur core team works from 10 a.m. to 6 p.m. Eastern Time, and we’d like at least 4–6 hours of overlap so you can collaborate and troubleshoot live when needed.\nSALARY\nThis is a long term role that has a lot of potential for growth. Estimated starting salary is between $1200-$2600 depending on experience, qualification, and skill set, but we are looking for a strong candidate and will pay more than fairly. There is also the opportunity to earn more over time based on execution, speed, and impact.\nTHIS ROLE IS NOT FOR YOU IF:\n-You’re still learning how to build automations or write production-ready code.\n-You are a no code expert ( We need someone that can code when needed)\n-You require close supervision or detailed step-by-step instructions.\n-You want a fixed tech stack or expect to only use one set of tools / aren't willing to adapt\n-This isn’t for someone who wants to work at totally random hours. You’ll need some overlap with our working day.\nABOUT US\nWe run two growing companies — a high-volume custom apparel business and a newer software venture in the same space. We're building a lean, profitable operation where systems and automation let us scale with fewer people. — all by building better systems. You'll play a key role in that.\nHere’s a short Loom video to learn more about our team and the role:\nwww.loom.com/share/fc6eef39101a4b85b3302ffd89f44cc5?sid=5995cbc4-4da0-4c44-a0a4-447f063f7622",Industry Type: Textile & Apparel (Fashion),Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Automation', 'Automating', 'Artificial Intelligence', 'Creative Solutions', 'Communication Skills', 'Large Language Model', 'Ai Solutions', 'Creative Thinking', 'PHP', 'API', 'Design Thinking', 'Python']",2025-06-11 06:12:20
AI Developer,Raymoon Enterprise,1 - 6 years,6-15 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","Qualifications and Experience:\nExp. : 1+ year\nSalary : Upto 15LPA\nLocation : Gurgaon\nSkills : AI, ML, Python, SQL, NOSQL, AWS, GCP, Tensorflow, Database Management, Language R",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Artificial Intelligence', 'Tensorflow', 'Pytorch', 'Data Science', 'NoSQL', 'Database Management', 'Aiml', 'Machine Learning', 'Deep Learning', 'SQL', 'LANGUAGE R', 'Ml']",2025-06-11 06:12:21
Python + Gen AI,MNC IT,10 - 12 years,20-30 Lacs P.A.,"['Pune', 'Mumbai (All Areas)']","Bachelors degree or higher in Machine Learning, Computer Science, Computational Linguistics, Mathematics or other relevant technical field from premier institute.\n•Strong foundation in Probability, Statistics, Linear Algebra, Calculus, Machine Learning and Generative AI/LLM.\n•Expertise in Deep Learning techniques and applications.\n•Strong understanding of Generative AI (GenAI) including math behind the models and its practical implementations.\n•Hands-on experience working with Large Language Model APIs like Azure OpenAI, Anthropic etc.. and cloud ecosystems like Azure, AWS, GCP, Databricks\n•Proficiency in LangChain, LangGraph, and working with Vector Databases for advanced data retrieval and AI workflows.\n•Proficiency in Python or similar programming languages, with experience in AI/ML libraries and frameworks such as TensorFlow, PyTorch, or Hugging Face.\n•Knowledge of financial products, including mutual funds, ETFs, and client segmentation, is a plus.\n•Excellent problem-solving and analytical skills.\n•Strong communication skills to explain complex models and insights effectively.",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['LangGraph', 'LangChain', 'TensorFlow', 'PyTorch']",2025-06-11 06:12:22
Assistant Professor,K L University,2 - 7 years,Not Disclosed,"['Vijayawada', 'Guntur']","Position Title: Assistant / Associate / Professor Department of Electronics and Communication Engineering (ECE)\nInstitution: K.L University.\nLocation: K L University Campus, Vaddeswaram, Guntur, Andhra Pradesh.\n\nJob Summary:\nThe Department of Electronics and Communication Engineering at K L University invites applications for the position of Assistant/Associate/ Professor. The ideal candidate should possess a strong academic background, a passion for teaching, and a solid research portfolio in one or more of the above specialization areas.\n\nRoles and Responsibilities:\nTeach undergraduate and postgraduate courses in ECE and related specialization subjects.\nSupervise B.Tech, M.Tech, and Ph.D. student projects and theses.\nConduct and publish high-quality research in reputed peer-reviewed journals and conferences.\nApply for funded research projects from national and international agencies.\nContribute to the development of laboratories and research infrastructure.\nActively participate in departmental, institutional, and academic development activities.\n\nEligibility Criteria:\nPh.D. in Electronics and Communication Engineering or a closely related field, preferably from IITs, NITs, or other reputed institutions.\nFirst-class (or equivalent CGPA) in both B.Tech and M.Tech degrees, preferably from IITs, NITs, or other reputed institutions.\nA strong research profile with publications in SCI and/or Scopus-indexed journals.\n\nAreas of Specialization (any one or more):\nMicroelectronics and VLSI Design\nEmbedded Systems and IoT\nGenerative AI and Machine Learning (Signal Processing)\nWireless Technologies and Communication Systems\n\nExperience:\n\nRelevant teaching experience in academia or research experience in reputed institutions/organizations is required.\n\nPay Scale: Salary is not a constraint for deserving candidates.\n\nApplication Process:\n\nInterested candidates kindly share your updated CV's to careers@kluniversity.in for any enquiries please reach us +91 83097 70116 / +91 9100054787.",Industry Type: Education / Training,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Wireless Communication', 'AI', 'Embedded Systems', 'VLSI Design', 'Signal Processing']",2025-06-11 06:12:24
CS/IT Technical Trainer Freelancer,Shri Ramswaroop Memorial University,4 - 8 years,Not Disclosed,['Lucknow'],"Training Modules & Expertise Required:\n\nFull-Stack Development (MERN / MEAN)\nHands-on with MongoDB, Express.js, React/Angular, Node.js\nFrontend-backend integration\nREST API development, Deployment (Heroku/Vercel)\n\nPython Programming with Additional Libraries\nCore Python + OOPs\nLibraries: Pandas, NumPy, Matplotlib, Flask, Django (as applicable)\nProject implementation focus\n\nCyber Security with Network Analysis\nNetwork protocols, penetration testing, ethical hacking\nTools like Wireshark, Kali Linux, Nmap\nReal-time threat detection techniques\n\nBasic Data Structures & Algorithms (DSA)\nArrays, Linked Lists, Stacks, Queues, Trees, Sorting, Searching\nTime complexity analysis\nProblem-solving via C/C++/Java/Python\n\nArtificial Intelligence with LLM (Large Language Models)\nBasics of AI, ML, NLP\nIntroduction to LLMs like GPT, BERT, etc.\nApplications of LLM in real-world domains\n\nAdvanced DSA\nGraphs, Dynamic Programming, Greedy Algorithms\nAdvanced problem-solving\nCompetitive programming approach",Industry Type: IT Services & Consulting,Department: Teaching & Training,"Employment Type: Full Time, Permanent","['Communication Skills', 'Subject Matter Expertise', 'Technical Training']",2025-06-11 06:12:25
Manager,NBC Bearings,1 - 2 years,3.5-6 Lacs P.A.,['Jaipur'],"Job Responsibilities:\n\n- Proficient in conceptualising, designing & prototyping Mechatronics systems adjacent to transmission & motive units.\n- Proficient in selecting, applying & configuring server for deployment of software, must able to implement algorithms for the artificial intelligence.\n- Proficient in developing full stack software development in JavaScript, SQL, Node.js, MySQL.\n- Must be conversant in DFMEA, QFD, FMEA, GD&T, NPD, APQP, RCA, SOI -RFQ Handling, Technical & Costing Proposal etc\n\nPreferred candidate profile\n\n- Customer Interaction, Program management, Sample Development & Testing\n- Must have exposure to Internal Engineering Standards like ISO, JIS, ASTM, SAE & IEC etc.\n- Programming Basic Python is must.\n- Problem-solving and troubleshooting\n- Proficiency in MS office",Industry Type: Electronic Components / Semiconductors,Department: Research & Development,"Employment Type: Full Time, Permanent","['Mechatronics', 'Rfq Management', 'NPD', 'Javascript', 'GD&t', 'Design Review']",2025-06-11 06:12:27
Business Analytics Trainer - Freelancer,ziphertech,8 - 13 years,Not Disclosed,"['Chennai', 'Delhi / NCR', 'Mumbai (All Areas)']","Freelance Trainers Required with hands on exp in\n\nAPI Integration Mastery\nDatabase Management System\nData Analytics & Visualization using Power BI\n6 D’s of Product Management\nCloud Computing Fundamentals (AWS preferred)\nAI/ML Applications for BA\n\nRequired Candidate profile\nPrior training exp preferred. Must bring in case studies, hands-on exercises, and live demos. Able to deliver engaging, outcome-driven sessions. Certification is a plus (for AWS, Power BI, etc.)",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Part Time, Freelance/Homebased","['Power Bi', 'Api Integration', 'Machine Learning', 'AWS', 'Freelance Training', 'Product Management', 'Artificial Intelligence', 'IT Training', 'Azure Certified', 'Part Time', 'Emerging Technologies', 'AI/ML', 'Aws Certified', 'Database Management', 'Corporate Training']",2025-06-11 06:12:28
Product manager (Solar),Renew,5 - 8 years,Not Disclosed,['Haryana'],"About Company\nJob Description\nResponsibilities\n•    Understand Business problems and identify constraints\n•    Design digital and advance analytics solutions to Business problems\n•    Implement the solution with an understanding of end-to-end architecture\n•    Identify opportunities for implementation of new use cases\n•    Keep updates of any policy changes in power markets\n•    Ensure ReD targets are met and delivered on time\n•    Ensure documentation of Use Cases\nOur Ideal Candidate\n•    Education - Engineering (Electrical/Electronics/IT) + MBA \n•    Experience Range – 4 to 7 years\n•    Experience in Renewable energy/ Storage/Hydro/RTC power/Power Trading\n•    Good program management, Project planning & coordination skills\n•    Good Experience of working in cross functional teams\n•    Good IT skills - understanding different solutions and matching solutions to problems\n•    Analytical approach to solving problems with focus on solution delivery\n•    Capable of extrapolating current situation to future scenarios\nFunctional/ Domain expertise\n•    Knowledge of Power markets is a must\n•    Should have experience in evaluating or implementing any of the new technologies (BESS/ Hybrids/ EV, Charging Infra/ Pumped Storage/ Hydrogen/Market procurement of RE - GTAM) \n•    Participated in some Digital transformation/enablement exercise in organisation\n•    Basic understanding of work of Data Scientists & Data engineering roles is a plus\n•    Experience in agile working methodology would be a plus\n•    Experience with tools like PowerBI, Tableau, JIRA would be a plus\nCommunication skills\n•    Ability to communicate with cross functional roles is a must\n•    Excellent written and verbal communication skills\n•    Good presentation skills\nTeamwork\n•    Ability to work as a self-motivated team player\n•    Has worked in large teams with an agile setup in the past\n•    Handle multiple projects across intra and inter-department teams\n",Industry Type: Power,Department: Product Management,"Employment Type: Full Time, Permanent","['power trading', 'analytical', 'program management', 'verbal communication', 'presentation skills', 'power bi', 'coordination', 'analytics', 'tableau', 'product management', 'use cases', 'writing', 'agile', 'rational team concert', 'digital transformation', 'project planning', 'communication skills', 'jira', 'architecture']",2025-06-11 06:12:30
Content Writer,Cognida,2 - 5 years,Not Disclosed,[],"Role Overview:\nWere seeking a creative and detail-oriented Content Writer with a passion for technology and a knack for turning complex ideas into clear, engaging content. In this role, you will be responsible for creating a wide range of written content that educates, engages, and converts our target audiencesfrom blog posts and white papers to website copy and product messaging.\n\nLocation : Remote/India",,,,['Content Writing'],2025-06-11 06:12:32
Power Bi Developer,IntelERA Inc,7 - 12 years,20-35 Lacs P.A.,[],"Job Title: Power BI Engineer\nLocation: Fully Remote (Preferred candidates in Pune, but open to all)\nWork Hours: 4:30 PM to 1:30 AM IST\nExperience Required: 7+ Years\n\nWe are seeking an experienced Power BI Engineer to join our team. The ideal candidate has a strong background in data analytics, visualization, and business intelligence, with a proven track record of designing and implementing impactful dashboards and reports. This role requires advanced skills in Power BI, data modeling, DAX, and ETL processes, as well as experience with large datasets and complex data transformations.\n\n\nKey Responsibilities:\n\nDesign, develop, and deploy Power BI dashboards and reports to provide insights that drive business decisions.\nWork closely with business stakeholders to gather and translate requirements into scalable, impactful data visualizations.\nImplement and optimize data models, using DAX to create robust calculations and complex measures.\nIntegrate and manage diverse data sources, including SQL databases, cloud services (e.g., Azure), APIs, and flat files.\nConduct data analysis and quality assurance to ensure data accuracy and report integrity.\nDevelop ETL processes using Power Query, SQL, and Azure Data Factory to extract, transform, and load data.\nImplement row-level security (RLS) and ensure adherence to data governance and security policies.\nPerform performance tuning on Power BI dashboards, ensuring efficient load times and smooth user experience.\nCollaborate with data engineers, data scientists, and other stakeholders to integrate advanced analytics and predictive insights.\nStay up-to-date with the latest Power BI features, best practices, and trends to continuously enhance BI solutions.\n\nRequired Skills and Qualifications:\n\n7+ years of experience in business intelligence and data analytics, with a strong focus on Power BI.\nProficient in Power BI Desktop, Power BI Service, and Power BI Report Server.\nExpertise in data modeling, DAX (Data Analysis Expressions), and M language.\nSolid understanding of relational databases and SQL, with experience in database management (SQL Server, Oracle, etc.).\nHands-on experience with ETL tools, such as Power Query, SQL Server Integration Services (SSIS), or Azure Data Factory.\nFamiliarity with cloud platforms, particularly Azure services like Azure SQL Database, Azure Data Lake, and Azure Analysis Services.\nStrong analytical skills, with a keen eye for detail and a commitment to data quality.\nExperience in implementing row-level security (RLS) and maintaining compliance with data governance standards.\nFamiliarity with scripting languages like Python or PowerShell for automation is a plus.\nExcellent communication and interpersonal skills, with the ability to effectively collaborate with both technical and non-technical stakeholders.\n\nSoft Skills:\n\nTakes ownership, is a proactive problem-solver with a positive, can-do attitude.\nPassionate about development.\nExcellent communication and teamwork skills.\nAbility to work effectively in a remote environment.\n\nNice to Have:\n\nKnowledge of Agile methodologies and familiarity with tools like Azure DevOps or JIRA.\nCertifications in Power BI, Microsoft Azure, or data engineering are advantageous.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Power Bi', 'Data Visualization', 'Dax', 'Data Modeling', 'Data Analytics', 'Azure Data Factory', 'Power Bi Dashboards', 'SSIS', 'Power Query', 'SQL']",2025-06-11 06:12:33
Life sciences - Sr.Project Manager,Agilisium,10 - 17 years,Not Disclosed,['Chennai( Perungudi )'],"Job Title: IT Project Manager (Life Sciences)\nLocation: OMR, Chennai\nWork Mode: On-site (Ready to work from office)\nExperience: 12+ Years\nJob Description:\nWe are looking for an IT Project Manager with deep expertise in Life Sciences (Pharma/Biotech/MedTech) and hands-on experience managing Data Engineering projects. The ideal candidate will have 12+ years of experience leading IT initiatives, including data pipelines, cloud-based analytics, and regulatory-compliant data solutions in the Life Sciences domain.",,,,"['Life Sciences', 'Project Management', 'Profit And Loss', 'Project Monitoring', 'Project Documentation', 'Project Planning', 'Project Scheduling', 'Salesforce']",2025-06-11 06:12:35
Cyber Security Specialist,Pharmaace Innovations,5 - 10 years,Not Disclosed,['Pune'],"Role & responsibilities\n• Monitor and respond to real-time cyber threats using SIEM tools and threat intelligence platforms.\nConduct regular vulnerability assessments and penetration testing.\nAnalyze security incidents and provide detailed incident reports with remediation plans.\nOversee firewall, antivirus, and intrusion detection/prevention systems (IDS/IPS).\nPerform security risk assessments for infrastructure, applications, and cloud environments.\nEnsure compliance with HIPAA, GDPR, ISO 27001, and other relevant regulations.\nDevelop and enforce information security policies, procedures, and standards.\nWork closely with the DevOps, Network, and Infrastructure teams to enforce security protocols. • Lead incident response drills and disaster recovery planning.\nPrepare security metrics and dashboards for internal reviews and audit support.\nStay current on evolving cyber threats and emerging security technologies\n\nPreferred candidate profile\n• Bachelor's degree in Computer Science, Information Security, or a related field.\n• Strong knowledge of threat intelligence, security monitoring tools (e.g., Splunk, IBM QRadar, or similar).\nExperience in cloud security (AWS/Azure/GCP) and endpoint security.\nFamiliarity with frameworks such as NIST, MITRE ATT&CK, OWASP.\nCertifications preferred: CISSP, CISM, CEH, or CompTIA Security+.\nStrong analytical skills and ability to handle security incidents independently.\nExcellent communication skills and ability to work with cross-functional teams.\n\nNice to Have\n• Experience working in healthcare or pharmaceutical industries.\n• Knowledge of data privacy regulations applicable to clinical or health data.\n• Exposure to machine learning applications in threat detection.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Incident Response', 'Siem Tools', 'Incident Reporting', 'Vulnerability Assessment', 'Security Risk Assessment', 'antivirus', 'firewall', 'HIPAA', 'ISO 27001', 'information security', 'intrusion detection/prevention system', 'GDPR']",2025-06-11 06:12:36
Trainer,S H Ev Motors,1 - 6 years,1.8-2.4 Lacs P.A.,['Bhubaneswar'],"Responsibilities:\nConduct engaging online technical sessions, design comprehensive course content, mentor learners, address technical queries, and ensure skill enhancement aligned with industry trends and best practices.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Teacher Training', 'Training', 'Training Programs', 'Soft Skills', 'English', 'Hindi', 'train']",2025-06-11 06:12:38
Senior Node Js Developer,Zentest Software,4 - 8 years,Not Disclosed,['Pune'],"Prerequisites and Qualifications\n4-8 years of overall experience, including at least 1 year of hands-on development using Node.js.\nKnowledge of AI model lifecycle: training, fine-tuning, inference, prompt engineering, Retrieval-Augmented Generation (RAG) architecture.\nSolid understanding of server-side technologies and asynchronous programming.\nExperience with frameworks such as Express.js.\nProficient in working with databases.\nStrong understanding of RESTful API design and implementation.\nFamiliarity with front-end technologies (HTML, CSS, JavaScript) and their integration with server-side logic.\nExcellent problem-solving and communication skills.\nAbility to work collaboratively in a team environment.\n\nJob Responsibilities\nServer-Side Design & Development:\nDesign, develop, and maintain server-side logic using Node.js.\nImplement RESTful APIs to support frontend applications and other system components.\nAI Solution Development:\nCollect and analyze functional and non-functional requirements for AI use cases and develop AI solutions leveraging Retrieval-Augmented Generation (RAG) architecture.\nBuild modular prompt templates (for GPT-like models) and support dynamic construction from user input.\nPlan how the AI model (or service) fits within the broader application ecosystem.\nDatabase Design & Integration:\nDesign & integrate with database to store and retrieve data efficiently.\nOptimize database queries for performance and scalability.\nMiddleware Development:\nBuild middleware components to handle communication between frontend and backend systems.\nImplement caching mechanisms to improve application performance.\nCode Quality and Testing:\nConduct code reviews to ensure adherence to coding standards.\nImplement and maintain unit tests to validate the functionality of server-side components.\nCollaboration and Communication:\nWork closely with frontend developers, designers, and other stakeholders to understand project requirements.\nCollaborate with cross-functional teams to deliver high-quality solutions.\nPerformance & Security:\nIdentify and address performance bottlenecks in server-side components.\nOptimize server-side code for maximum speed and scalability.\nImplement security best practices to protect against common web application vulnerabilities.\nEnsure the secure handling of sensitive data and user authentication.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Expresjs', 'Restfull Api', 'Artificial Intelligence', 'Node.Js']",2025-06-11 06:12:40
Manager - HRBP,Yubi,8 - 13 years,Not Disclosed,['Ahmedabad'],"Accumn - a Yubi company, is Indias most advanced AI-first credit decisioning platform, integrating machine learning (ML) and generative artificial intelligence (GenAI) to empower credit managers with precise, data-driven tools for fair and transparent lending decisions. Formed through the strategic consolidation of Corpository and FinFort, Accumn offers a comprehensive suite of solutions to support the entire credit lifecycle—from lead generation and risk management to post-disbursement monitoring. With over 1 lakh active banking and credit users, Accumn has achieved a 66% reduction in credit processing time and boasts an 85% success rate in predicting defaults. The platform has over 5 lakh entities under credit monitoring. The company has been recognized for “Best Use of AI & ML Models for Credit Default Prediction” by Banking Frontiers and “Best Use of AI in Risk Evaluation” by Dun & Bradstreet. Visit www.hello.accumn.ai and www.go-yubi.com to learn more.",,,,"['Employee Engagement', 'Employee Retention', 'PMS', 'Employee Welfare', 'Employee Grievances']",2025-06-11 06:12:41
Business Head - LAS & LAMF,Angel One,15 - 20 years,Not Disclosed,['Mumbai (All Areas)'],"About Angel One :\n\nAngel One Limited is a Fintech company providing broking services, margin trading facility, research services, depository services, investment education and distributes third party financial products to its clients, on a mission to become the No. 1 fintech organization in India.\nWith over 2 crore+ registered clients, we are onboarding an average of over 800k new clients every month in the current financial year. We are working to build personalized financial journeys for our clients via a single app, powered by new-age tech, AI, Machine Learning and Data Science.",,,,"['loan against mutual fund', 'Loan Against Shares']",2025-06-11 06:12:43
Scala developer (with Spark),Fortune India 500 IT Services Firm,5 - 8 years,Not Disclosed,"['Hyderabad', 'Pune']","We are looking for a highly skilled Scala Developer with solid experience in Apache Spark to join our data engineering team.\n\nExperience- 5 to 8yrs\nLocation- Pune, Hyderabad\nMandatory skills- Scala development, Spark\nKey Responsibilities:\nDesign, develop, and optimize batch and streaming data pipelines using Scala and Apache Spark.\nWrite efficient, reusable, and testable code following functional programming best practices.\nWork with large-scale datasets from a variety of sources (e.g., Kafka, Hive, S3, Parquet).\nCollaborate with data scientists, data analysts, and DevOps to ensure robust and scalable pipelines.\nTune Spark jobs for performance and resource efficiency.\nImplement data quality checks, logging, and error-handling mechanisms.\n\n\n\nInterested candidates share your CV at himani.girnar@alikethoughts.com with below details\n\nCandidate's name-\nEmail and Alternate Email ID-\nContact and Alternate Contact no-\nTotal exp-\nRelevant experience-\nCurrent Org-\nNotice period-\nCCTC-\nECTC-\nCurrent Location-\nPreferred Location-\nPancard No-",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Scala Programming', 'Spark', 'SCALA', 'Big Data Technologies', 'SQL']",2025-06-11 06:12:45
Manager - Payroll & HR Operations,Angel One,10 - 15 years,Not Disclosed,['Mumbai (All Areas)'],"About Angel one :\n\nAngel One Limited is a Fintech company providing broking services, margin trading facility, research services, depository services, investment education and distributes third party financial products to its clients, on a mission to become the No. 1 fintech organization in India. With over 2 crore+ registered clients, we are onboarding an average of over 800k new clients every month in the current financial year.",,,,"['Payroll Management', 'ESIC', 'Statutory Compliance', 'Wages', 'Payroll Processing', 'Salary Administration', 'PF Act', 'PF', 'LWF']",2025-06-11 06:12:47
