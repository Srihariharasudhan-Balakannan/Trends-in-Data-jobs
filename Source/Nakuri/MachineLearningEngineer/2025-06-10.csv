job_title,company,experience,salary,locations,description,industry,department,employment_type,skills,scraped_at
Machine Learning Engineer,CompIndia,0 - 1 years,Not Disclosed,"['Tirupati', 'Chennai( Aminjikarai )']",Value-Added Skills:\nCompleted Courses in Python & ML\nCompleted Academic projects involving ML\nParticipated in Kaggle competitions and Hackathons\nBuilt ML projects with real-world datasets,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Python', 'Kaggle', 'Hackathon']",2025-06-10 15:33:23
Machine Learning Engineer,goML,3 - 8 years,Not Disclosed,[],"Looking for a culture to thrive & build a rewarding career for yourself, join the core team of young hustlers building the next generation of Machine Learning platform & services. You will develop training and deployment pipelines for machine learning, implement model compression algorithms, and productionize machine learning research solving challenging business problems.\n\nWe are Hiring Machine Learning Engineers at goML!\n\nKey Responsibilities:\nDesign and develop generative AI models using techniques like RAG, transformers, and other relevant approaches.\nFine-tune pre-trained LLMs for specific tasks and domains.\nConduct research on new techniques for improving the performance and capabilities of generative AI models.\nApply software engineering rigor and best practices to machine learning /Generative AI pipelines.\nEvaluate and analyse the performance of ML/generative AI models.\nStay up to date on the latest advancements in generative AI research.\nFacilitate the development and deployment of proof-of-concept Generative AI systems.\n\nQualifications:\nBachelors/Masters degree in Computer Science, Machine Learning, Artificial Intelligence, or a related field.\n3-8 years of experience in generative AI or related fields.\nExperience in building data pipelines, deploying ML/GenAI models in production, and monitoring and maintaining their performance.\nStrong programming skills in Python.\nFamiliarity with RAG and other techniques for building generative models.\nExtensive experience with Git, Docker and a good understanding of Linux for managing servers.\nExperience with cloud-based ecosystems, especially AWS ML/GenAI services.\nExposure to ML/GenAI frameworks and tools.\nExcellent communication and collaboration skills.\nAbility to work independently and in a team-oriented environment.\nMethodical and meticulous towards work and planning.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative AI', 'Machine Learning', 'AWS', 'Natural Language Processing', 'Computer Vision', 'Deep Learning']",2025-06-10 15:33:26
Machine Learning Engineer - Recommender Systems,Thomson Reuters,3 - 8 years,Not Disclosed,['Bengaluru'],"Senior Machine Learning Engineer - Recommender Systems\n\nJoin our team at Thomson Reuters and contribute to the global knowledge economy. Our innovative technology influences global markets and supports professionals worldwide in making pivotal decisions. Collaborate with some of the brightest minds on diverse projects to craft next-generation solutions that have a significant impact. As a leader in providing intelligent information, we value the unique perspectives that foster the advancement of our business and your professional journey.\n\nAre you excited about the opportunity to leverage your extensive technical expertise to guide a development team through the complexities of full life cycle implementation at a top-tier companyOur Commercial Engineering team is eager to welcome a skilled Senior Machine Learning Engineer to our established global engineering group. Were looking for someone enthusiastic, an independent thinker, who excels in a collaborative environment across various disciplines, and is at ease interacting with a diverse range of individuals and technological stacks. This is your chance to make a lasting impact by transforming customer interactions as we develop the next generation of an enterprise-wide experience.\n\nAbout the Role:\n\nAs a Machine Learning Engineer, you will:\n\nSpearhead the development and technical implementation of machine learning solutions, including configuration and integration, to fulfill business, product, and recommender system objectives.\n\nCreate machine learning solutions that are scalable, dependable, and secure.\n\nCraft and sustain technical outputs such as design documentation and representative models.\n\nContribute to the establishment of machine learning best practices, technical standards, model designs, and quality control, including code reviews.\n\nProvide expert oversight, guidance on implementation, and solutions for technical challenges.\n\nCollaborate with an array of stakeholders, cross-functional and product teams, business units, technical specialists, and architects to grasp the project scope, requirements, solutions, data, and services.\n\nPromote a team-focused culture that values information sharing and diverse viewpoints.\n\nCultivate an environment of continual enhancement, learning, innovation, and deployment.\n\n\nAbout You:\n\nYou are an excellent candidate for the role of Machine Learning Engineer if you possess:\n\n\nAt least 3 years of experience in addressing practical machine learning challenges, particularly with Recommender Systems, to enhance user efficiency, reliability, and consistency.\n\nA profound comprehension of data processing, machine learning infrastructure, and DevOps/MLOps practices.\n\nA minimum of 2 years of experience with cloud technologies (AWS SageMaker, AWS is preferred), including services, networking, and security principles.\n\nDirect experience in machine learning and orchestration, developing intricate multi-tenant machine learning products.\n\nProficient Python programming skills, SQL, and data modeling expertise, with DBT considered a plus.\n\nFamiliarity with Spark, Airflow, PyTorch, Scikit-learn, Pandas, Keras, and other relevant ML libraries.\n\nExperience in leading and supporting engineering teams.\n\nRobust background in crafting data science and machine learning solutions.\n\nA creative, resourceful, and effective problem-solving approach.\n\n\n#LI-HG1\n\nWhat’s in it For You\n\n\n\nHybrid Work Model We’ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.\n\n\nFlexibility & Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.\n\n\nCareer Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow’s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.\n\n\nIndustry Competitive Benefits We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.\n\n\nCulture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our valuesObsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.\n\n\nSocial Impact Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives.\n\n\nMaking a Real-World Impact:We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.\n\n\nAbout Us\n\nThomson Reuters informs the way forward by bringing together the trusted content and technology that people and organizations need to make the right decisions. We serve professionals across legal, tax, accounting, compliance, government, and media. Our products combine highly specialized software and insights to empower professionals with the data, intelligence, and solutions needed to make informed decisions, and to help institutions in their pursuit of justice, truth, and transparency. Reuters, part of Thomson Reuters, is a world leading provider of trusted journalism and news.\n\nWe are powered by the talents of 26,000 employees across more than 70 countries, where everyone has a chance to contribute and grow professionally in flexible work environments. At a time when objectivity, accuracy, fairness, and transparency are under attack, we consider it our duty to pursue them. Sound excitingJoin us and help shape the industries that move society forward.\n\nAs a global business, we rely on the unique backgrounds, perspectives, and experiences of all employees to deliver on our business goals. To ensure we can do that, we seek talented, qualified employees in all our operations around the world regardless of race, color, sex/gender, including pregnancy, gender identity and expression, national origin, religion, sexual orientation, disability, age, marital status, citizen status, veteran status, or any other protected classification under applicable law. Thomson Reuters is proud to be an Equal Employment Opportunity Employer providing a drug-free workplace.\n\nWe also make reasonable accommodations for qualified individuals with disabilities and for sincerely held religious beliefs in accordance with applicable law. More information on requesting an accommodation here.\n\nLearn more on how to protect yourself from fraudulent job postings here.\n\nMore information about Thomson Reuters can be found on thomsonreuters.com.",Industry Type: Advertising & Marketing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'cloud technologies', 'sql', 'data modeling', 'natural language processing', 'scikit-learn', 'airflow', 'data processing', 'aws sagemaker', 'pandas', 'deep learning', 'recommender systems', 'data science', 'spark', 'devops', 'pytorch', 'keras', 'code review', 'aws', 'win', 'ml']",2025-06-10 15:33:29
Machine Learning Engineer (Search),Insider,2 - 5 years,Not Disclosed,[],"Before jumping in on all the information about the role and what you can bring to the table, let us introduce ourselves real quick.\n\nAbout us\n\nWe are Insider, a B2B SaaS company that drives growth for its clients around the world. How are we achieving this? We are the #1 AI-native platform for Customer Experience and Marketing offers marketers a single platform to deliver unique experiences per person, drive profitable growth, and unleash peak productivity and efficiency. Our platform connects data across channels, predicts future behavior with AI, and individualizes experiences from a single platform.\n\nWe have just celebrated our $500M Series E funding round, led by General Atlantic . Before this, we ve unlocked unicorn status following our Series D round. We are backed by top-notch investors, including Sequoia Capital, QIA, Riverwood, and Endeavor Catalyst , and trusted by 1200+ brands from high-growth startups to the most prestigious Fortune 500 companies such as Samsung, Coca-Cola, Nike, L Oreal, Singapore Airlines, Virgin, Nestle, Nissan, Lenovo, Puma, IKEA, Allianz, Dominos, CNN, and the list goes on.\n\nHaving unlocked unicorn status, Insider was congratulated for becoming one of the only woman-founded, women-led B2B SaaS unicorns in the world, to achieve $200M in CARR (Committed Annual Recurring Revenue). Insider was named a leader in The Forrester Wave for Cross-Channel Campaign Management 2021, and Leader in the IDC MarketScape: Worldwide Omnichannel Marketing Platforms for B2C Enterprises 2023 Assessment. The company has been recognized in The Top 1% of all software companies worldwide in G2 s 2024 Software Awards , and named in The Top 10 Best Software Products with the most #1 rankings alongside other software legends like Google, Zoom, and Monday.com . According to G2 s Spring 24 reports. Insider is also the #1 G2 Leader in 6+ categories , including Customer Data Platforms (CDP), Personalization Engines, Personalization Software, Mobile Marketing, Customer Journey Analytics, and e-commerce Personalization.\n\nWhen our team founded Insider, they not only sought to create a product company but also to build the most socially progressive technology community in the world. Through our corporate social responsibility initiatives like 100Projects SheCodes, SheLeads, and SheMarkables, our community has committed to scaling its impact into our communities across 27+ countries, spearheading transformative projects in areas such as health, education, farming, animal rights, and increasing the proportional representation of women in STEM careers.\n\nBehind all these achievements, there is an exceptionally talented and passionate team across 27+ countries that moves fast and agile, creates cutting-edge products, and focuses on making an impact. If you want to join us on this journey, just keep reading.\n\nAnd now? Now we are looking for a Machine Learning Engineer who wants to take their career one step further. If you think you are one of those people, here you will have the chance to work with the worlds leading brands with Artificial Intelligence & Machine Learning technologies . Right now, while you are reading this, we are sending an average of 2.2 billion requests and almost 2 billion instant notifications to more than 450 servers a day . On the Artificial Intelligence and Predictive side, we have more than 100 TB of historical data . We do not wait for jobs or opportunities to come to our feet, we create them. We have now reached 25% of global users . If all these interests you, read on for more!\n\nOur Engineers and Software Developers always think with an innovative perspective, taking advantage of the inexhaustible power of the digital world. They create impressive and intelligent products like a true artist. Our Product and Development teams are located in our Istanbul office, so we produce and develop the technology we export to the world in our own country . As Insider, we believe in cooperation and adapting the innovations brought by technology by acting fast . We work closely with other Departments with agile teams, and we are not afraid of getting our hands dirty . As we said; we do not wait for jobs or opportunities to come to our feet, we create them ourselves. You can check our Tech Stacks here !: https: / / www.stackshare.io / companies / useinsider\n\nHeres what defines our Search team:\nAt Insider, we re building AI-powered systems that make product discovery faster, more relevant, and deeply personalized. From semantic search to suggestions, from merchandising to analytics, our products are driven by impactful AI/ML techniques.\nWe believe in M-shaped development culture: engineers with depth in few core areas and curiosity to expand across the stack. Youll collaborate with different functions and be hands-on across the full stack: from data and modeling to software systems and observability. You ll grow quickly, owning meaningful pieces of the products with ultimate support from experienced engineers and scientists around you.\nA Machine Learning Engineer in Insider day in and day out:\nDesign, build and release AI products/features that solve real user problems\nDesign and implement streaming/batch data pipelines to support training and inference\nWrite production-ready code, and move it to production with the help of cloud services and CI/CD techniques\nContinuously monitor and improve the quality and performance of the systems\nLearn by doing while owning real problems and demonstrating end-to-end ownership through all the system\nWe want you to join us while we are taking a step into the future if you likely have:\nStrong problem-solving skills and critical thinking ability combined with a growth mindset\nSolid understanding of data structures, algorithms, and object-oriented programming\nExperience with data analysis and management\nExposure to AI/ML concepts: Supervised Learning, NLP, Embeddings, Transformers, Computer Vision, Information Retrieval, LLMs, RAG, Agents, etc.\nInterest in building end-to-end products; not just models or a piece of code of a huge system\n\nand it would be a strong plus if you have any of below:\nInvolvement in academic projects leveraging AI/ML concepts\nFamiliarity with Backend/API development or cloud services (AWS/GCP/Azure)\nA story to tell about a real-world problem solving or business-related achievement\nWhat we value:\nCuriosity and initiative you love to figure things out and solve complex problems\nCollaborative ownership and team/product-first approach\nBreadth and depth you re excited to grow into M-shaped product engineer\nSelf-organization and full ownership through real-world impact\nA strong team that ships and learns together\nContinuous mentorship and technical coaching\nWhile exporting our technology to the world, we also offer you:\nTech Talks with famous and groundbreaking people from the software world, Dev Talks where our Software Developers talk about their career steps, and many events where groundbreaking ideas are discussed,\nHackathons we organize inside that push the boundaries, programming challenges, and coding competitions,\nfree access to exclusive services such as Laracasts, Egghead, LinkedIn Learning, Blinkist, Masterclass, and Spotify,\nInclusive Private Health Insurance,\nSmart Work Model side benefits to support food and bill expenses,\nThe infamous Team Activities that are bursting with fun,\nNo Dress code! This is a fast and innovative startup, you can wear whatever you want.\nRemote Work! Work anywhere youd like in Turkey.\n\nWe provide equal opportunity in a zero-discrimination workplace and not just welcome but also embrace everyone without regard to sex, race, color, nationality, religion, gender identity, sexual orientation, disability status, citizenship, or marital status.\n\nPlease follow Insider on LinkedIn , Instagram , Youtube, and Medium !",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer vision', 'Data analysis', 'Backend', 'Campaign management', 'Coding', 'Artificial Intelligence', 'Machine learning', 'Agile', 'Data structures', 'Analytics']",2025-06-10 15:33:31
Machine Learning Engineer,Target,4 - 9 years,Not Disclosed,['Bengaluru'],"About us:\n\nWorking at Target means helping all families discover the joy of everyday life. We bring that vision to life through our values and culture. Learn more about Target here .\n\n\n\nWe are building Machine Learning Platform to enable MLOPs capabilities to help Data scientists and ML engineers at Target to implement ML solutions at scale. It encompasses building the Featurestore, Model ops, experimentation, iteration, monitoring, explainability, and continuous improvement of the machine learning lifecycle. You will be part of a team building scalable applications by leverage latest technologies. Connect with us if you want to join us in this exiting journey.\n\n\n\n\n\n\n\nAs a Engineer, you ll take the lead as you\n\nYou will build applications for Target s MLPlatform to enable capabilities to help data scientists, ML engineers and Data engineers at Target . You will be part of a team building highly scalable, event driven applications and leverage technologies. You understand Target's business and technical environments, resolve complex challenges via technical solutions as well as be a significant code contributor, manage software development cycle, drive best practices and ensure development of high-quality code with compliance & security standards. The Engineer is a practitioner of rapid prototyping and Agile, DevOps, CI/CD, test-driven development and stays current with new technology to be able to assess viability and applicability to Target's business and technical environments.\n\n\n\n\n\nTech stack Java, SpringBoot, Microservices, Python, Cassandra, Elastic Search, Postgres, Kafka, Docker, CICD, GCP cloud skills, GCP Machine Learning Engineer skills , GCP VertexAI skills\n\n\n\n\n\nAbout you:\n\n4 year degree or equivalent experience\n\n1.5+ years of software development experience\n\nExperience in building applications using JVM languages like Java, Kotlin\n\nExposure in building high-performance scalable APIs.\n\nGood to have experience in building Python applications, Fast API etc\n\nGood to have Machine Learning Engineer skills\n\nHaving GCP cloud skills, GCP Machine Learning Engineer skills , GCP VertexAI skills would be added advantage\n\nExperience in microservices, Spring Boot, cloud development, NoSQL databases, and event driven architecture\n\nExperience with NoSQL technologies Cassandra, Elastic search, MongoDB is a plus\n\nDeep experience writing unit and functional tests and test-driven development\n\nExperience building CI/CD pipelines\n\nStrong problem solving and debugging skills",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software development', 'software testing', 'functional testing', 'java', 'debugging', 'jvm', 'continuous integration', 'python', 'kotlin', 'ci/cd', 'machine learning', 'microservices', 'docker', 'nosql', 'spring boot', 'elastic search', 'postgresql', 'cassandra', 'gcp', 'devops', 'kafka', 'agile', 'api', 'mongodb']",2025-06-10 15:33:34
Machine Learning Engineer,Adobe,12 - 15 years,Not Disclosed,[],"The engineer will be part of a team working on the development, operations and support of Adobe s AI Platform team. They will be responsible for the design, architecture and development of new features and maintenance of existing features. They will also handle all phases of development, from early specs and definition to release. They are encouraged to be hands-on problem solver and we'll conversant in analyzing, architecting and implementing Golang/python-based world class high-quality software. Prior experience on ML solutions and cloud platform services, workflow orchestrators, data pipeline solutions would be a plus.\n\nWhat you'll Do\nThis is an individual contributor position.\nHands on product/solution development knowledge are a must.\nThe position involves conceptualization of a product, design, development, debugging/triaging, deployment at scale, monitoring, analyzing, etc\nPlanning, effort estimation and risk analysis of a project.\nThe incumbent will plan, evaluate industry alternatives, design and drive new components, solutions, workflow, features, etc\nShould take the initiative to drive frugality through optimizations without compromising stability or resiliency.\n  Requirements\nbachelors / masters degree in engineering.\n12+ years of relevant industry experience.\n3+ years of experience as a lead/architect.\nA proven expertise with building large scale platforms on Kubernetes.\nProven programming skills with languages such as python and go-lang.\nExperience of the latest ML development tools.\nTrack record of delivering cloud-scale, data-driven products, and services that are widely adopted with large customer bases\nExposure to container runtime environments\nExperience in building, deploying, and managing infrastructures in public clouds (specifically AWS)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Debugging', 'Machine learning', 'Cloud', 'Conceptualization', 'Programming', 'Product design', 'Adobe', 'Monitoring', 'Python']",2025-06-10 15:33:36
Machine Learning R&D Engineer,Welocalize,6 - 10 years,Not Disclosed,['Noida'],"The Machine Learning R&D Engineer role is responsible for the design, development and implementation of machine learning solutions to serve our organization. This includes ownership or oversight of projects from conception to deployment with appropriate AWS services, Docker, MLFlow, and other. The role also includes responsibility for following best practices with which to optimize and measure the performance of our models and algorithms against business goals.\n\nYou can apply directly using the link below:",,,,"['Cloud Deployment', 'Natural Language Processing', 'Machine Learning', 'Coding', 'Python', 'Java', 'C++', 'Artificial Intelligence', 'Model Building', 'Research And Development', 'Aiml', 'Microsoft Azure', 'Deploying Models', 'AWS']",2025-06-10 15:33:39
Staff Machine Learning Engineer,Zscaler Softech,4 - 8 years,Not Disclosed,['Bengaluru'],"About Zscaler\nServing thousands of enterprise customers around the world including 40% of Fortune 500 companies, Zscaler (NASDAQ: ZS) was founded in 2007 with a mission to make the cloud a safe place to do business and a more enjoyable experience for enterprise users. As the operator of the world’s largest security cloud, Zscaler accelerates digital transformation so enterprises can be more agile, efficient, resilient, and secure. The pioneering, AI-powered Zscaler Zero Trust Exchange™ platform, which is found in our SASE and SSE offerings, protects thousands of enterprise customers from cyberattacks and data loss by securely connecting users, devices, and applications in any location.\nWhat We're Looking for (Minimum Qualifications)\nWhat Will Make You Stand Out (Preferred Qualifications)",,,,"['algorithms', 'kubernetes', 'orchestration', 'anomaly detection', 'networking', 'tools', 'sql', 'cloud', 'tensorflow', 'data science', 'end', 'software engineering', 'ml', 'architecture', 'python', 'software testing', 'airflow', 'time series', 'machine learning', 'r', 'ml algorithms', 'production processes', 'metrics', 'agile', 'statistics']",2025-06-10 15:33:42
Staff Data Engineer - Machine Learning,Netradyne,5 - 8 years,22.5-35 Lacs P.A.,['Bengaluru'],"Role and Responsibilities:\n\nYou will be embedded within a team of machine learning engineers and data scientists; responsible for building and productizing generative AI and deep learning solutions. You will:\nDesign, develop and deploy production ready scalable solutions that utilizes GenAI, Traditional ML models, Data science and ETL pipelines\nCollaborate with cross-functional teams to integrate AI-driven solutions into business operations.\nBuild and enhance frameworks for automation, data processing, and model deployment.\nUtilize Gen-AI tools and workflows to improve the efficiency and effectiveness of AI solutions.\nConduct research and stay updated with the latest advancements in generative AI and related technologies.\nDeliver key product features within cloud analytics.\n\nRequirements:\n\nB. Tech, M. Tech or PhD in Computer Science, Data Science, Electrical Engineering, Statistics, Maths, Operations Research or related domain.\nStrong programming skills in Python, SQL and solid fundamentals in computer science, particularly in algorithms, data structures, and OOP.\nExperience with building end-to-end solutions on AWS cloud infra.\nGood understanding of internals and schema design for various data stores (RDBMS, Vector databases and NoSQL).\nExperience with Gen-AI tools and workflows, and large language models (LLMs).\nExperience with cloud platforms and deploying models at scale.\nStrong analytical and problem-solving skills with a keen attention to detail.\nStrong knowledge of statistics, probability, and estimation theory.\n\nDesired Skills:\n\nFamiliarity with frameworks such as PyTorch, TensorFlow and Hugging Face.\nExperience with data visualization tools like Tableau, Graphana, Plotly-Dash.\nExposure to AWS services like Kinesis, SQS, EKS, ASG, lambda etc.\nExpertise in at least one popular Python web-framework (like FastAPI, Django or Flask).\nExposure to quick prototyping using Streamlit, Gradio, Dash etc.\nExposure to Big Data processing (Snowflake, Redshift, HDFS, EMR)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'AWS', 'Generative Artificial Intelligence', 'Python', 'Big Data Technologies']",2025-06-10 15:33:43
Machine Learning Engineer,Adobe,14 - 19 years,Not Disclosed,"['Noida', 'Bengaluru']","The AI Foundation Team at Adobe Express aims to develop a groundbreaking AI stack using internal and external technologies to improve feature speed and quality. Develop ML models and services, collaborate with teams, improve user experience at Adobe Express.\nWhat Youll Do\nResearch, design, and implement advanced ML models and pipelines for training and inference at scale, including techniques in computer vision, NLP, deep learning, and generative AI.\nIntegrate Large Language Models (LLMs) and agent-based frameworks to support multimodal creative workflows, enabling rich, context-aware content generation and dynamic user experiences.\nCollaborate with multi-functional teams to translate product requirements into ML solutions, iterating from proof-of-concept to fully productionized services.\nDevelop robust platforms for continuous model training, experimentation, A/B testing, and monitoring, ensuring that model quality and relevance remain consistently high.\nLeverage distributed computing technologies and cloud infrastructures to handle large-scale data processing, feature engineering, and real-time inference, optimizing for performance and cost-efficiency.\nImplement reliable APIs and microservices that serve ML models to end users, ensuring alignment to standard methodologies in security, compliance, scalability, and maintainability.\nStay ahead of emerging ML research, tools, and frameworks, evaluating and integrating new technologies such as sophisticated LLMs, reinforcement learning-based agents, and innovative inference optimization techniques.\nIn the near future, we will expand the model coverage to include more creative tasks. We will also improve the model architectures to achieve better latency and accuracy. Additionally, we will integrate federated learning or domain adaptation strategies to reach diverse audiences.\nBasic Qualifications:\nPhD or Master s or Bachelor s in Computer Science or equivalent experience, ML, Applied Mathematics, Data Science, or a related technical field.\n14+years of industry experience.\nProficiency in Python and Java for ML model development and systems integration.\nHands-on experience with deep learning frameworks, including TensorFlow and PyTorch.\nDemonstrated experience working with LLMs and agent frameworks to develop advanced AI-based experiences.\nProficiency in computer vision and NLP techniques for multimodal content understanding and generation.\nWork experience in Creative Domains, Imaging Domains will be highly useful.\nExperience in developing and deploying RESTful web services and microservices architectures for applications involving ML.\nProficiency with UNIX environments, Git for version control, and Jenkins for CI/CD processes.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Unix', 'Computer science', 'Computer vision', 'Version control', 'GIT', 'Machine learning', 'Data processing', 'Adobe', 'Monitoring', 'Python']",2025-06-10 15:33:46
Hiring Machine Learning Engineer,Motivity Labs,5 - 10 years,14-22.5 Lacs P.A.,['Hyderabad'],"Role - Machine Learning Engineer\nRequired Skills & Experience\n\n5+ years of hands-on experience in building, training, and deploying machine learning models in a professional, production-oriented setting.\nDemonstrable experience with database creation and advanced querying (e.g., SQL, NoSQL), with a strong understanding of data warehousing concepts.\nProven expertise in data blending, transformation, and feature engineering, adept at integrating and harmonizing both structured (e.g., relational databases, CSVs) and unstructured (e.g., text, logs, images) data.\nStrong practical experience with cloud platforms for machine learning development and deployment; significant experience with Google Cloud Platform (GCP) services (e.g., Vertex AI, BigQuery, Dataflow) is highly desirable.\nProficiency in programming languages commonly used in data science (e.g., Python is preferred, R).\nSolid understanding of various machine learning algorithms (e.g., regression, classification, clustering, dimensionality reduction) and experience with advanced techniques like Deep Learning, Natural Language Processing (NLP), or Computer Vision.\nExperience with machine learning libraries and frameworks (e.g., scikit-learn, TensorFlow, PyTorch).\nFamiliarity with MLOps tools and practices, including model versioning, monitoring, A/B testing, and continuous integration/continuous deployment (CI/CD) pipelines.\nExperience with containerization technologies like Docker and orchestration tools like Kubernetes for deploying ML models as REST APIs.\nProficiency with version control systems (e.g., Git, GitHub/GitLab) for collaborative development.\n\nInterested candidates share cv to dikshith.nalapatla@motivitylabs.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['GCP', 'Machine Learning', 'Deep Learning', 'Python', 'BigQuery', 'MLOps', 'Git', 'Vertex AI', 'GitHub/GitLab', 'A/B testing', 'Dataflow', 'Kubernetes']",2025-06-10 15:33:48
Machine Learning Engineer,Cadfem Engineering Services,2 - 3 years,Not Disclosed,['Hyderabad'],"Design and develop machine learning models tailored to mechanical engineering challenges, including predictive modelling, simulation optimisation, and failure analysis.\nUtilise deep learning and other advanced ML techniques to improve the accuracy and efficiency of CAE simulations.\nPreprocess and analyse large datasets from CAE simulations, experimental tests, and manufacturing processes for modelling.\nTrain, validate, and fine-tune machine learning models using real-world engineering data.\nOptimise models for performance, scalability, and robustness in production environments.\nCollaborate with CAE engineers to integrate ML models into existing simulation workflows (e.g., FEA, CFD, structural analysis).\nAutomate repetitive simulation tasks and enable predictive analytics for design optimisation.\nWork closely with mechanical engineers, data scientists, and software developers to identify business challenges and develop data-driven solutions.\nDeploy machine learning models into production environments and monitor their performance.\nMaintain and update models to ensure reliability and continuous improvement.\nStay abreast of the latest advancements in machine learning, AI, and CAE technologies.\nApply innovative approaches to solve complex engineering problems.\n\n\nRequirements\nBachelor\\u2019s or Master\\u2019s degree in Mechanical Engineering, Computer Science, or a related field\nProven 2-3 years of experience in developing and deploying machine learning models, preferably in mechanical engineering or CAE domain\nHands-on experience with CAE tools such as ANSYS, Abaqus, or similar FEA/CFD software\nStrong programming skills in Python, R, or Java\nProficiency in machine learning frameworks (TensorFlow, PyTorch, scikit-learn)\nExperience with data preprocessing, feature engineering, and statistical analysis\nSolid understanding of mathematics, statistics, and problem-solving skills\nExcellent analytical thinking and ability to tackle complex engineering challenges\nStrong communication and teamwork skills to collaborate across disciplines\nPreferred: Experience with physics-informed machine learning and digital twin technologies\nPreferred: Familiarity with automation of CAE workflows and predictive modelling for product design\n\n\nBenefits\nChallenging job and a chance to team up with a young and dynamic professional group\nChance to build yourself as WE grow.\nRemuneration that stays competitive and attractive to retain the best.\nOpportunity to join an organization experiencing year on year growth",Industry Type: Engineering & Construction,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['CFD', 'Abaqus', 'Automation', 'Simulation', 'Analytical', 'Failure analysis', 'Ansys', 'Product design', 'Structural analysis', 'Python']",2025-06-10 15:33:51
Machine Learning Engineer,NatWest Markets,4 - 9 years,Not Disclosed,"['Gurugram', 'Bengaluru']","Join us as a Machine Learning Engineer\nWe re looking for someone to deploy, automate, maintain and monitor machine learning models and algorithms to make sure they work effectively in a production environment\nDay-to-day, you ll collaborate with colleagues to design and develop state-of-the-art machine learning products which power our group for our customers\nThis is your opportunity to turn your interests into a diverse and rewarding career, as you solve new problems and create smarter solutions in a non-stop innovation environment\nWhat you ll do\nYour daily responsibilities will see you codifying and automating machine learning model production, including pipeline optimisation, tuning and fault finding, as well as transforming data science prototypes and applying appropriate machine learning algorithms and tools.\nWe ll need you to deploy and maintain adopted end-to-end solutions, including building metrics to improve system performance and identifying and resolving differences in data distribution which affect model performance. You ll also maintain knowledge of data science and machine learning.\nIn addition, you ll be responsible for:\nUnderstanding the needs of our business stakeholders, and how machine learning solutions meet those needs to support the achievement of our business strategy\nWorking with colleagues to produce machine learning models, including pipeline designs, development, testing and deployment to carry on the intent and knowledge into production\nCreating frameworks to make sure the monitoring of machine learning models within the production environment is robust\nDelivering models that adhere to expected quality and performance while understanding and addressing any shortfalls, for example through retraining\nWorking in an Agile way within multi-disciplinary data and the analytics teams to achieve agreed project and Scrum outcomes\nThe skills you ll need\nTo be successful in this role, you ll have an academic background in a STEM discipline, like Mathematics, Physics, Engineering or Computer Science. You ll need experience with machine learning on large datasets and an understanding of machine learning approaches and algorithms.\nAlongside this, you ll have experience of building, testing, supporting and deploying machine learning models into a production environment, using modern CI/CD tools, like TeamCity and CodeDeploy. You ll also have good communication skills to engage with a wide range of stakeholders.\nFurthermore, you ll need:\nExperience of using programming and scripting languages, such as Python and Bash\nAn understanding of how to synthesise, translate and visualise data and insights for key stakeholders\nUnderstanding of the capabilities and experience with Large Language Models and their APIs\nAbility to read and understand a large documentation base, as well as contribute to it\nDesire to understand the business requirements and limitations, and expertise to make relevant suggestions\nStrong software engineering, systems architecture, and unit testing capabilities\nExperience with AWS/other cloud providers\nExperience with GitLab CI/CD pipelines for automated testing and deployments\nExperience using pipeline tools such as Apache Airflow, Amazon SageMaker or similar\nFamiliarity with SQL\nExperience with MLOps and model monitoring tools such as Splunk, Comet ML, etc\nAn understanding of how to present the data and insights for key stakeholders\nFinancial services knowledge and the ability to identify wider business impacts, risks and opportunities to make connections across key outputs and processes",Industry Type: Banking,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Machine learning', 'Agile', 'Scrum', 'Unit testing', 'Apache', 'Analytics', 'Financial services', 'SQL', 'Python']",2025-06-10 15:33:54
Machine Learning Engineer,Adobe,10 - 15 years,Not Disclosed,['Noida'],"Hands-on Machine Learning Engineer who will release models in production.\nDevelop classifiers, predictive models, and multi-variate optimization algorithms on large-scale datasets using advanced statistical modeling, machine learning, and data mining.\nSpecial focus on R&D that will be building predictive models for conversion optimization, Bidding algorithms for pacing & optimization, Reinforcement learning problems, and Forecasting.\nCollaborate with Product Management to bring AI-based Assistive experiences to life. Socialize what s possible now or in the near future to inform the roadmap.\nResponsible for driving all aspects of ML product development: ML modeling, data/ML pipelines, quality evaluations, productization, and ML Ops.\nCreate and instill a team culture that focuses on sound scientific processes and encourages deep engagement with our customers.\nHandle project scope and risks with data, analytics, and creative problem-solving.\n\nWhat you'require:\nSolid foundation in machine learning, classifiers, statistical modeling and multivariate optimization techniques\nExperience with control systems, reinforcement learning problems, and contextual bandit algos.\nExperience with DNN frameworks like TensorFlow or PyTorch on large-scale data sets.\nTensorFlow, R, scikit, pandas\nProficient in one or more: Python, Java/Scala, SQL, Hive, Spark\nGood to have - Git, Docker, Kubernetes\n. GenAI, RAG pipelines a must have technology\n. C loud based solutions is good to have\nGeneral understanding of data structures, algorithms, multi-threaded programming, and distributed computing concepts\nAbility to be a self-starter and work closely with other data scientists and software engineers to design, test, and build production-ready ML and optimization models and distributed algorithms running on large-scale data sets.\n\nIdeal Candidate Profile:\nA total of 10+ years of experience, including at least 5 years in technical roles involving Data Science, Machine Learning, or Statistics.\nMasters or B.Tech in Computer Science/ Statistics\nComfort with ambiguity, adaptability to evolving priorities, and the ability to lead a team while working autonomously.\nProven management experience with highly diverse and global teams.\nDemonstrated ability to influence technical and non-technical stakeholders.\nProven ability to effectively manage in a high-growth, matrixed organization.\nTrack record of delivering cloud-scale, data-driven products, and services that are widely adopted with large customer bases.\nAn ability to think strategically, look around corners, and create a vision for the current quarter, the year, and five years down the road.\nA relentless pursuit of great customer experiences and continuous improvements to the product.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Product management', 'Computer science', 'Bidding', 'GIT', 'Machine learning', 'Data structures', 'Adobe', 'Data mining', 'SQL', 'Python']",2025-06-10 15:33:57
Machine Learning Engineer,Bay Area Tek Solutions LLC,2 - 5 years,Not Disclosed,['Bengaluru'],"Must have: Strong on programming languages like Python, Java One cloud hands-on experience (GCP preferred) Experience working with Dockers Environments managing (e.g venv, pip, poetry, etc.) Experience with orchestrators like Vertex AI pipelines, Airflow, etc Understanding of full ML Cycle end-to-end Data engineering, Feature Engineering techniques Experience with ML modelling and evaluation metrics Experience with Tensorflow, Pytorch or another framework Experience with Models monitoring Advance SQL knowledge Aware of Streaming concepts like Windowing , Late arrival , Triggers etc",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['GCP', 'Machine learning', 'Cloud', 'Programming', 'Management', 'Monitoring', 'SQL', 'Python']",2025-06-10 15:33:59
Machine Learning Engineer,Lendingkart,3 - 8 years,Not Disclosed,"['Ahmedabad', 'Bengaluru']","Roles and Responsibilities:\n• Design, develop, and deploy machine learning models to solve real-world business problems.\n• Develop production-quality machine learning pipelines and frameworks using Python and Java.\n• Collaborate with data scientists, engineers, and business teams to define data requirements, model specifications, and system architecture.\n• Preprocess and clean large datasets, perform feature engineering, and ensure data quality for ML applications.\n• Implement, optimize, and deploy algorithms, ensuring scalability and performance in production systems.\n• Work with cloud-based platforms (AWS, GCP, Azure) for deploying and scaling machine learning models.\n• Stay current with the latest machine learning research and trends, and propose innovative solutions and techniques.\n• Document processes, models, and code to ensure reproducibility, maintainability, and knowledge sharing.\n\nRequired Skills & Qualifications:\n• 5-6 years of professional experience in software engineering, with at least 2-3 years of hands-on experience in machine learning and data science.\n• Proficiency in Python for machine learning, data analysis, and algorithm development.\n• Fair experience with Java, including the development of production-level applications and integration with ML models.\n• Familiarity with data preprocessing techniques, including feature extraction, cleaning, normalization, and transformation.\n• Strong experience with SQL and working with large datasets from databases and data lakes.\n• Proficiency in cloud platforms (AWS, GCP, or Azure) for deploying machine learning models and managing infrastructure.\n• Strong knowledge of version control systems like Git and experience with CI/CD pipelines for machine learning models.\n• Strong problem-solving and debugging skills.\n• Ability to work independently and in a collaborative team environment.\n• Excellent communication skills for technical documentation and presenting solutions to stakeholders.\n\nDesired Skills:\n• Familiarity with big data technologies such as Spark, or Kafka.\n• Experience with DevOps practices for automating ML workflows.\n• Experience in deploying ML models using Docker, Kubernetes, or similar containerization technologies.",Industry Type: NBFC (Micro Finance),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Ci/Cd', 'Ml Pipelines', 'Python', 'SQL']",2025-06-10 15:34:02
Machine Learning Engineer,Welldoc Software,4 - 8 years,Not Disclosed,['Bengaluru'],"We are seeking a skilled and experienced Machine Learning Engineer to join our team.The ideal candidate will have a strong background in Python and PyTorch, along with 4-8 years of experience deploying ML/AI models to production. This role requires excellent analytics skills and a good working knowledge of Databricks. You will work closely with data scientists, clinicians, software engineers, and product teams to design, build, and optimize scalable machine learning solutions.\n\nRole & responsibilities\nDevelop, train, and optimize machine learning models using PyTorch and other ML frameworks.\nDeploy and maintain ML models in production environments, ensuring scalability, performance, and reliability.\nUtilize Databricks for data processing, model training, model deployment, and pipeline optimization.\nDeploy Retrieval-Augmented Generation (RAG) pipelines to production for improved AI-driven applications.\nCollaborate with data engineers to design and implement ETL workflows and data pipelines.\nPerform rigorous testing, validation, and monitoring of deployed models.\nOptimize model inference for low latency and high throughput applications.\nWork with stakeholders to translate business problems into ML solutions.\nStay up to date with the latest advancements in machine learning, deep learning, and AI deployment strategies.\n\nPreferred candidate profile\nProficiency in Python and ML frameworks such as PyTorch.\n4-8 years of experience deploying machine learning models to production.\nKnowledge of MLflow for experiment tracking and model management.\nStrong experience with Databricks for ML development and deployment.\nHands-on experience with MLOps, CI/CD pipelines, and cloud-based deployment (AWS, Azure, or GCP).\nSolid understanding of data structures, algorithms, and software engineering principles.\nExperience working with large-scale datasets and distributed computing frameworks.\nExperience with deploying Retrieval-Augmented Generation (RAG) pipelines to production.\nExcellent analytical and problem-solving skills.\nStrong communication skills and ability to work in a collaborative team environment.\n\nPreferred Qualifications\nExperience deploying models in the healthcare domain.\nExperience with feature engineering, data preprocessing, and model explainability.\nKnowledge of containerization (Docker, Kubernetes) and workflow orchestration tools\nFamiliarity with LLMs, NLP, or reinforcement learning is a plus.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pytorch', 'RAG', 'Data Bricks', 'Python', 'MLops']",2025-06-10 15:34:04
Principal Machine Learning Engineer,Horizon Therapeutics,2 - 7 years,Not Disclosed,['Hyderabad'],"Career Category Information Systems Job Description Join Amgen s Mission of Serving Patients\nAt Amgen, if you feel like you re part of something bigger, it s because you are. Our shared mission to serve patients living with serious illnesses drives all that we do.\nSince 1980, we ve helped pioneer the world of biotech in our fight against the world s toughest diseases. With our focus on four therapeutic areas -Oncology, Inflammation, General Medicine, and Rare Disease- we reach millions of patients each year. As a member of the Amgen team, you ll help make a lasting impact on the lives of patients as we research, manufacture, and deliver innovative medicines to help people live longer, fuller happier lives.\nOur award-winning culture is collaborative, innovative, and science based. If you have a passion for challenges and the opportunities that lay within them, you ll thrive as part of the Amgen team. Join us and transform the lives of patients while transforming your career.\nWhat you will do\nLet s do this. Let s change the world. We are seeking a highly skilled Machine Learning Engineer with a strong MLOps background to join our team. You will play a pivotal role in building and scaling our machine learning models from development to production. Your expertise in both machine learning and operations will be essential in creating efficient and reliable ML pipelines.\nRoles & Responsibilities:\nCollaborate with data scientists to develop, train, and evaluate machine learning models.\nBuild and maintain MLOps pipelines, including data ingestion, feature engineering, model training, deployment, and monitoring.\nLeverage cloud platforms (AWS, GCP, Azure) for ML model development, training, and deployment.\nImplement DevOps/MLOps best practices to automate ML workflows and improve efficiency.\nDevelop and implement monitoring systems to track model performance and identify issues.\nConduct A/B testing and experimentation to optimize model performance.\nWork closely with data scientists, engineers, and product teams to deliver ML solutions.\nGuide and mentor junior engineers in the team\nStay updated with the latest trends and advancements\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nBasic Qualifications:\nDoctorate degree and 2 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nMaster s degree and 8 to 10 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nBachelor s degree and 10 to 14 years of Computer Science, Statistics, and Data Science, Machine Learning experience OR\nDiploma and 14 to 18 years of years of Computer Science, Statistics, and Data Science, Machine Learning experience\nPreferred Qualifications:\nMust-Have Skills:\nStrong foundation in machine learning algorithms and techniques\nExperience in MLOps practices and tools (e.g., MLflow, Kubeflow, Airflow); Experience in DevOps tools (e.g., Docker, Kubernetes, CI/CD)\nProficiency in Python and relevant ML libraries (e.g., TensorFlow, PyTorch, Scikit-learn)\nOutstanding analytical and problem-solving skills; Ability to learn quickly; Excellent communication and interpersonal skills\nGood-to-Have Skills:\nExperience with big data technologies (e.g., Spark), and performance tuning in query and data processing\nExperience with data engineering and pipeline development\nExperience in statistical techniques and hypothesis testing, experience with regression analysis, clustering and classification\nKnowledge of NLP techniques for text analysis and sentiment analysis\nExperience in analyzing time-series data for forecasting and trend analysis\nFamiliar with AWS, Azure, or Google Cloud;\nFamiliar with Databricks platform for data analytics and MLOps\nProfessional Certifications\nCloud Computing and Databricks certificate preferred\nSoft Skills:\nExcellent analytical and fixing skills.\nStrong verbal and written communication skills\nAbility to work effectively with global, virtual teams\nHigh degree of initiative and self-motivation.\nAbility to manage multiple priorities successfully.\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills.\nWhat you can expect of us\nAs we work to develop treatments that take care of others, we also work to care for your professional and personal growth and well-being. From our competitive benefits to our collaborative culture, we ll support your journey every step of the way.\nIn addition to the base salary, Amgen offers competitive and comprehensive Total Rewards Plans that are aligned with local industry standards.\nApply now and make a lasting impact with the Amgen team. careers.amgen.com\nAs an organization dedicated to improving the quality of life for people around the world, Amgen fosters an inclusive environment of diverse, ethical, committed and highly accomplished people who respect each other and live the Amgen values to continue advancing science to serve patients. Together, we compete in the fight against serious disease.\nAmgen is an Equal Opportunity employer and will consider all qualified applicants for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, disability status, or any other basis protected by applicable law.\nWe will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.\n.",Industry Type: Biotechnology,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Computer science', 'Cloud computing', 'Performance tuning', 'GCP', 'Analytical', 'Machine learning', 'Oncology', 'Forecasting', 'Monitoring', 'Python']",2025-06-10 15:34:06
Machine Learning Engineer,Reuters,3 - 8 years,Not Disclosed,['Bengaluru'],"Spearhead the development and technical implementation of machine learning solutions, including configuration and integration, to fulfill business, product, and recommender system objectives.\nCreate machine learning solutions that are scalable, dependable, and secure.\nCraft and sustain technical outputs such as design documentation and representative models.\nContribute to the establishment of machine learning best practices, technical standards, model designs, and quality control, including code reviews.\nProvide expert oversight, guidance on implementation, and solutions for technical challenges.\nCollaborate with an array of stakeholders, cross-functional and product teams, business units, technical specialists, and architects to grasp the project scope, requirements, solutions, data, and services.\nPromote a team-focused culture that values information sharing and diverse viewpoints.\nCultivate an environment of continual enhancement, learning, innovation, and deployment.\nAbout You:\nYou are an excellent candidate for the role of Machine Learning Engineer if you possess:\nAt least 3 years of experience in addressing practical machine learning challenges, particularly with Recommender Systems, to enhance user efficiency, reliability, and consistency.\nA profound comprehension of data processing, machine learning infrastructure, and DevOps/MLOps practices.\nA minimum of 2 years of experience with cloud technologies (AWS SageMaker, AWS is preferred), including services, networking, and security principles.\nDirect experience in machine learning and orchestration, developing intricate multi-tenant machine learning products.\nProficient Python programming skills, SQL, and data modeling expertise, with DBT considered a plus.\nFamiliarity with Spark, Airflow, PyTorch, Scikit-learn, Pandas, Keras, and other relevant ML libraries.\nExperience in leading and supporting engineering teams.\nRobust background in crafting data science and machine learning solutions.\nA creative, resourceful, and effective problem-solving approach.\n#LI-HG1\nWhat s in it For You\nHybrid Work Model: We ve adopted a flexible hybrid working environment (2-3 days a week in the office depending on the role) for our office-based roles while delivering a seamless experience that is digitally and physically connected.\nFlexibility Work-Life Balance: Flex My Way is a set of supportive workplace policies designed to help manage personal and professional responsibilities, whether caring for family, giving back to the community, or finding time to refresh and reset. This builds upon our flexible work arrangements, including work from anywhere for up to 8 weeks per year, empowering employees to achieve a better work-life balance.\nCareer Development and Growth: By fostering a culture of continuous learning and skill development, we prepare our talent to tackle tomorrow s challenges and deliver real-world solutions. Our Grow My Way programming and skills-first approach ensures you have the tools and knowledge to grow, lead, and thrive in an AI-enabled future.\nIndustry Competitive Benefits: We offer comprehensive benefit plans to include flexible vacation, two company-wide Mental Health Days off, access to the Headspace app, retirement savings, tuition reimbursement, employee incentive programs, and resources for mental, physical, and financial wellbeing.\nCulture: Globally recognized, award-winning reputation for inclusion and belonging, flexibility, work-life balance, and more. We live by our values: Obsess over our Customers, Compete to Win, Challenge (Y)our Thinking, Act Fast / Learn Fast, and Stronger Together.\nSocial Impact: Make an impact in your community with our Social Impact Institute. We offer employees two paid volunteer days off annually and opportunities to get involved with pro-bono consulting projects and Environmental, Social, and Governance (ESG) initiatives.\nMaking a Real-World Impact: We are one of the few companies globally that helps its customers pursue justice, truth, and transparency. Together, with the professionals and institutions we serve, we help uphold the rule of law, turn the wheels of commerce, catch bad actors, report the facts, and provide trusted, unbiased information to people all over the world.",Industry Type: Internet,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['orchestration', 'Networking', 'Data modeling', 'Consulting', 'Machine learning', 'Flex', 'Data processing', 'Manager Quality Control', 'SQL', 'Python']",2025-06-10 15:34:09
Machine Learning Engineer,Catalyst Clinical Research,5 - 10 years,Not Disclosed,"['Kolkata', 'Mumbai', 'New Delhi', 'Hyderabad', 'Pune', 'Chennai', 'Bengaluru']","{""company"":""\nCatalyst Clinical Research provides customizable solutions to the biopharmaceutical and biotechnology industries through , a full-service oncology CRO, and multi-therapeutic global functional and CRO services through . The companys customer-centric flexible service model, innovative technology, expert team members, and global presence advance clinical studies. Visit .\n\nThe Machine Learning Engineer is a pivotal contributor responsible for designing and implementing cutting-edge machine learning solutions with a focus on generative AI technologies. You will drive the development and deployment of advanced models and pipelines that enable the creation of AI-driven applications and enhance organizational decision-making capabilities. Additionally, you will support data engineering initiatives to enable utilization of data across the organization. Collaborating closely with internal and external stakeholders, you will translate complex requirements into innovative solutions that advance Catalysts AI strategies while ensuring alignment with broader enterprise goals.\n"",""role"":""\nPosition Responsibilities/ Accountabilities:\n\nDesign, build, and optimize machine learning workflows, with a focus on generative AI models such as large language models (LLMs) and diffusion-based architectures.\nDevelop and deploy scalable machine learning pipelines using frameworks like TensorFlow, PyTorch, and Databricks MLflow.\nDevelop AI solutions using tools like Azure AI/Copilot Studio and Databricks AI Builder.\nLead the creation of domain-specific generative AI models, ensuring ethical AI practices and bias mitigation throughout the model lifecycle.\nDesign, build, and maintain scalable data pipelines with Delta Live Tables for model integration into enterprise applications.\nEnhance and expand CI/CD strategies for automated testing, model monitoring, and continuous delivery of ML artifacts.\nManage data preprocessing, feature engineering, and synthetic data generation for machine learning use cases.\nCollaborate with cross-functional teams to align AI-driven solutions with business goals and ensure high availability for end-to-end systems.\nProvide technical expertise in the exploration of novel generative AI methods, tools, and frameworks.\nSupport team members in understanding data science and AI best practices, encouraging a culture of innovation and continuous learning. Represent AI as a key member of the Data & Architecture Review Committee.\n\nPosition Qualification Requirements :\nEducation\n: B.S. or M.S. Computer Science, Engineering, Economics, Mathematics, related field, or relevant experience.\n\nExperience:\n5+ years of experience in machine learning engineering, including model development and deployment.\nHands-on experience with generative AI models (e.g., GPT, GANs, VAEs) and frameworks like PyTorch or TensorFlow.\n5+ years of experience with cloud computing technologies (Azure, AWS, GCP), especially AI and ML services.\nProficiency in developing data pipelines and integrating ML models into production environments.\nExpertise in model evaluation and monitoring, including techniques for explainability and fairness in AI.\nExperience collaborating with DevOps and MLOps teams to ensure scalability and reliability of AI solutions.\nFamiliarity with project management tools such as JIRA.\n\nRequired Skills:\nAdvanced proficiency in Python or PySpark for ML applications.\nDeep understanding of generative AI principles, model architecture, and training methodologies.\nExpertise in large-scale data processing and engineering using Spark, Kafka, and Databricks.\nProficiency with big data technologies and data structures like delta, parquet, YAML, JSON, and HTML.\nStrong knowledge of cloud-based AI platforms (e.g. Databricks, Azure ML, etc).\nSolid understanding of machine learning pipelines and MLOps practices.\nExceptional problem-solving and analytical skills.\nAbility to manage priorities and workflow effectively.\nProven ability to handle multiple projects and meet tight deadlines.\nStrong interpersonal skills with an ability to work collaboratively across teams.\nCommitment to excellence and high standards.\nCreative, flexible, and innovative team player.\nAbility to work independently and as part of various committees and teams.\nNice to Have: Data Engineering experience, including Webhooks, API, ELT/ETL, rETL, Data Lakehouse Architecture, and Event-Driven Architectures.\n\nFamiliarity with deep learning frameworks for generative AI (e.g., Hugging Face Transformers).\nKnowledge of synthetic data generation techniques and tools.\nExperience with data visualization tools (e.g., Tableau, Power BI) for AI model interpretability.\nFamiliarity with ethical AI principles, including explainability and bias reduction strategies.\nExperience with containerization and orchestration tools like Docker and Kubernetes.\nBackground or familiarity with clinical trials or pharmaceutical development.\n\nWorking Hours\nEveryday: 1:30 PM - 9:00 PM IST\nOR\nMonday, Wednesday, Friday: 2:30 PM - 10:30 PM IST\nTuesday, Thursday: 9:00 AM - 5:00 PM IST\nNote: Working hours may vary based on individual seniority, business demand, and ability to work independently. This will be evaluated on a case-by-case basis.\n""},""",Industry Type: Miscellaneous,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'CRO', 'Project management', 'Pharma', 'Clinical trials', 'Clinical research', 'Data processing', 'Workflow', 'HTML', 'Monitoring']",2025-06-10 15:34:11
Data Scientist,Ford,3 - 7 years,Not Disclosed,['Chennai'],"As a Data Scientist, you will be part of a high performing team working on exciting opportunities in AI/ML within Ford Credit. We are looking for a seasoned Data Scientist with proven expertise in implementing Machine Learning/Optimization solutions with familiarity in Generative AI and a good grasp of Statistics.\nDevelop Machine Learning (Supervised/Unsupervised learning), Neural Networks (ANN, CNN, RNN, LSTM, Decision tree, Encoder, Decoder), Natural Language Processing, Generative AI (LLMs, Lang Chain, RAG, Vector Database) .\nHands-on Expertise in Python programming (OOPs concepts), SQL (relational/non-relational databases), experience in handling various data science libraries (Pandas, NumPy, SciPy, Sklearn, TensorFlow, Keras, Pytorch, etc. ) would be a necessary requirement.\nExposure to Cloud technologies (e. g. , Google Cloud/AWS/Azure), including executing Machine Learning algorithms on Cloud is necessary.\nExposure to Generative AI technologies.\nProfessional Qualification:\nPotential candidates should possess 3 to 7 years of working experience as a Data Scientist.\nBE/MSc/ MTech /ME/PhD (Computer Science/Maths, Statistics).\nPossess a strong analytical mindset and be very comfortable with data.\nExperience with handling both relational and non-relational data.\nHands-on with analytics methods (descriptive / predictive / prescriptive) , Statistical Analysis, Probability and Data Visualization tools (Python-Matplotlib, Seaborn).\nBackground of Computer Science with excellent Data Science working experience.\nTechnical Experience:\nDevelop Machine Learning (Supervised/Unsupervised learning), Neural Networks (ANN, CNN, RNN, LSTM, Decision tree, Encoder, Decoder), Natural Language Processing, Generative AI (LLMs, Lang Chain, RAG, Vector Database) .\nHands-on Expertise in Python programming (OOPs concepts), SQL (relational/non-relational databases), experience in handling various data science libraries (Pandas, NumPy, SciPy, Sklearn, TensorFlow, Keras, Pytorch, etc. ) would be a necessary requirement.\nExposure to Cloud technologies (e. g. , Google Cloud/AWS/Azure), including executing Machine Learning algorithms on Cloud is necessary.\nExposure to Generative AI technologies.\nAbility to scope the problem statement, data preparation, training and making the AI/ML model production ready.\nWork with business partners to understand the problem statement, translate the same into analytical problem.\nAbility to manipulate structured and unstructured data.\nDevelop, test and improve existing machine learning models.\nAnalyse large and complex data sets to derive valuable insights.\nResearch and implement best practices to enhance existing machine learning infrastructure. Develop prototypes for future exploration.\nDesign and evaluate approaches for handling large volume of real data streams.\nAbility to determine appropriate analytical methods to be used.\nCollaborate with data engineers, solutions architects, application engineers, and product teams across time zones to develop data and model pipelines",Industry Type: Auto Components,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'data science', 'Neural networks', 'Analytical', 'Machine learning', 'Natural language processing', 'data visualization', 'Analytics', 'SQL', 'Python']",2025-06-10 15:34:14
Data Scientist,Capgemini,4 - 7 years,Not Disclosed,['Pune'],"\n\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.\n1. Applies scientific methods to analyse and solve software engineering problems.\n2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.\n3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.\n4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.\n5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.\n\n - Grade Specific \nIs highly respected, experienced and trusted. Masters all phases of the software development lifecycle and applies innovation and industrialization. Shows a clear dedication and commitment to business objectives and responsibilities and to the group as a whole. Operates with no supervision in highly complex environments and takes responsibility for a substantial aspect of Capgeminis activity. Is able to manage difficult and complex situations calmly and professionally. Considers the bigger picture when making decisions and demonstrates a clear understanding of commercial and negotiating principles in less-easy situations. Focuses on developing long term partnerships with clients. Demonstrates leadership that balances business, technical and people objectives. Plays a significant part in the recruitment and development of people.\n\n Skills (competencies) \n\nVerbal Communication",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'deep learning', 'data science', 'gsm', 'rf engineering', 'data analysis', 'artificial intelligence', 'r', 'rf optimization', '3g', 'predictive modeling', 'lte', 'rf planning', 'statistics', 'drive test']",2025-06-10 15:34:17
F2F Drive-14th June-Bangalore LTIM - Data Scientist,Ltimindtree,6 - 11 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']",DS\n\nKey Responsibilities\nCombine expertise in mathematics statistics computer science and domain knowledge to create AIML models to solve various business challenges\nCollaborate closely with the AI Technical Manager and GCC Petro technical professionals and data engineers to integrate models into the business framework\nIdentify and frame opportunities to apply advanced analytics modeling and related technologies to data to help businesses gain insight and improve decision making workflow and automation\nUnderstand and communicate the value of proposed opportunity with team members and other stakeholders\nIdentify needed data and appropriate technology to solve identified business challenges\nClean data and develop and test models\nEstablish the life cycle management process for models\nProvide technical mentoring in modeling and analytics technologies the specifics of the modeling process and general consulting skills\nDrive innovation in AIML to enhance capabilities in data driven decision making\nAligns with team on shared goals and outcomes recognizes others contributions and work collaboratively seek diverse perspectives\nTakes actions to develop self and others beyond existing skillset\nEncourages innovative ideas adapts to change and changing technologies\nUnderstand and communicate data insights and model behaviors to stakeholders with varying levels of technical expertise\nRequired Qualification\nMinimum 5 years of experience in designing and developing AIML models and or various optimization algorithms 5 to 9 years of experience\nSolid foundation in mathematics probability and statistics with demonstrated depth of knowledge and experience in advanced analytics and data science methodologies eg supervised and unsupervised learning statistics data science model development\nProficiency in Python and working knowledge of cloud AIML services Azure Machine Learning and Databricks preferred\nDomain knowledge relevant to the energy sector and working knowledge of Oil and Gas value chain eg upstream midstream or downstream and associated business workflows\nProven ability to frame data science opportunities leverage standard foundational tools and Azure services to perform exploratory data analysis for purposes of data cleaning and discovery visualize data and identify actions to reach needed results\nAbility to quickly assess current state and apply technical concepts across cross functional business workflows\nExperience with driving successful execution deliverables and accountabilities to meet quality and schedule goals\nAbility to translate complex data into actionable insights that drive business val\nDemonstrated ability to engage and establish collaborative relationships both inside and outside immediate workgroup at various organizational levels across functional and geographic boundaries to achieve desired outcomes\nDemonstrated ability to adjust behavior based on feedback and provide feedback to other\nTeam oriented mindset with effective communication skills and the ability to work collaboratively\nStrong problem solving skills and attention to detail\nExcellent communication and collaboration skills,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Azure Databricks', 'Machine Learning', 'GCP', 'Data Scientist', 'Python', 'Predictive Modeling', 'Azure', 'Generative AI', 'Natural Language Processing', 'Deep Learning', 'Data Science', 'Azure Machine Learning', 'Computer Vision', 'AWS']",2025-06-10 15:34:20
Data Scientist,Ford,3 - 7 years,Not Disclosed,['Chennai'],"As a Data Scientist, you will be part of a high performing team working on exciting opportunities in AI/ML within Ford Credit. We are looking for a seasoned Data Scientist with proven expertise in implementing Machine Learning/Optimization solutions with familiarity in Generative AI and a good grasp of Statistics.\nDevelop Machine Learning (Supervised/Unsupervised learning), Neural Networks (ANN, CNN, RNN, LSTM, Decision tree, Encoder, Decoder), Natural Language Processing, Generative AI (LLMs, Lang Chain, RAG, Vector Database) .\nHands-on Expertise in Python programming (OOPs concepts), SQL (relational/non-relational databases), experience in handling various data science libraries (Pandas, NumPy, SciPy, Sklearn, TensorFlow, Keras, Pytorch, etc.) would be a necessary requirement.\nExposure to Cloud technologies (e.g., Google Cloud/AWS/Azure), including executing Machine Learning algorithms on Cloud is necessary.\nExposure to Generative AI technologies.\nProfessional Qualification:\nPotential candidates should possess 3 to 7 years of working experience as a Data Scientist.\nBE/MSc/ MTech /ME/PhD (Computer Science/Maths, Statistics).\nPossess a strong analytical mindset and be very comfortable with data.\nExperience with handling both relational and non-relational data.\nHands-on with analytics methods (descriptive / predictive / prescriptive) , Statistical Analysis, Probability and Data Visualization tools (Python-Matplotlib, Seaborn).\nBackground of Computer Science with excellent Data Science working experience.\nTechnical Experience:\nDevelop Machine Learning (Supervised/Unsupervised learning), Neural Networks (ANN, CNN, RNN, LSTM, Decision tree, Encoder, Decoder), Natural Language Processing, Generative AI (LLMs, Lang Chain, RAG, Vector Database) .\nHands-on Expertise in Python programming (OOPs concepts), SQL (relational/non-relational databases), experience in handling various data science libraries (Pandas, NumPy, SciPy, Sklearn, TensorFlow, Keras, Pytorch, etc.) would be a necessary requirement.\nExposure to Cloud technologies (e.g., Google Cloud/AWS/Azure), including executing Machine Learning algorithms on Cloud is necessary.\nExposure to Generative AI technologies.\nAbility to scope the problem statement, data preparation, training and making the AI/ML model production ready.\nWork with business partners to understand the problem statement, translate the same into analytical problem.\nAbility to manipulate structured and unstructured data.\nDevelop, test and improve existing machine learning models.\nAnalyse large and complex data sets to derive valuable insights.\nResearch and implement best practices to enhance existing machine learning infrastructure. Develop prototypes for future exploration.\nDesign and evaluate approaches for handling large volume of real data streams.\nAbility to determine appropriate analytical methods to be used.\nCollaborate with data engineers, solutions architects, application engineers, and product teams across time zones to develop data and model pipelines",Industry Type: Automobile,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'data science', 'Neural networks', 'Analytical', 'Machine learning', 'Natural language processing', 'data visualization', 'Analytics', 'SQL', 'Python']",2025-06-10 15:34:23
Data Scientist I AI Development and Data Science,Seismic Technologies,1 - 2 years,Not Disclosed,['Hyderabad'],"Join us at Seismic, a cutting-edge technology company leading the way in the SaaS industry. We specialize in delivering modern, scalable, and multi-cloud solutions that empower businesses to succeed in today s digital era. Leveraging the latest advancements in technology, including Generative AI, we are committed to driving innovation and transforming the way businesses operate. As we embark on an exciting journey of growth and expansion, we are seeking a talented Data Scientist to join our AI team in Hyderabad, India.\nSeismic AI:\nAI is one of the fastest-growing product areas in Seismic. We believe that AI, particularly Generative AI, will empower and transform how Enterprise sales and marketing organizations operate and interact with customers. Seismic Aura, our leading AI engine, is powering this change in the sales enablement space and is being infused across the Seismic enablement cloud. Our focus is to leverage AI across the Seismic platform to make our customers more productive and efficient in their day-to-day tasks, and to drive more successful sales outcomes.\nWhy Join Us:\nOpportunity to be a key contributor in a rapidly growing company and drive innovation in the SaaS industry.\nWork with cutting-edge technologies and be at the forefront of AI advancements.\nCompetitive compensation package, including salary, bonus, and equity options.\nA supportive, inclusive work culture.\nProfessional development opportunities and career growth potential in a dynamic and collaborative environment.\nWho you are:\nAs a Data scientist I, you will design and develop complex AI applications to build next-gen AI capabilities. You will contribute to high-impact projects and work with cross-functional teams to design, build, and maintain scalable, high-performance models and AI applications that deliver exceptional value to our customers. This position offers a unique opportunity to make an impact on our company s growth and success by bringing AI-powered features to life across our platform, including content discovery, learning and coaching, meeting intelligence and various AI capabilities. This is a hands-on, high-impact role ideal for an individual contributor ready to scale AI in production.\nIf you are a passionate technologist with a strong track record of building AI and data science solutions, and you thrive in a fast-paced, innovative environment, we want to hear from you!\nWhat you ll be doing:\nAI Application Development : Design and develop robust and scalable data science and AI applications, including NLP, classification, retrieval-augmented generation (RAG), and conversational/agentic, and multi-agent systems.\nTechnical Excellence : Demonstrate excellence in various AI engineering aspects and share knowledge across the team.\nModel Optimization : Design and implement high-performance machine learning models and pipelines. Continuously improve latency, robustness, accuracy, and scalability.\nInnovation and Technology Adoption : Evaluate and implement new tools, frameworks, and methodologies to improve the efficiency and quality of AI systems.\nProduct Integration : Collaborate with AI engineers, software engineers, and product managers to seamlessly integrate AI features across Seismic s products.\nCross-functional Collaboration : Partner with UX, engineering, and product teams to design end-to-end intelligent experiences for our users.\nDecision-making and Ownership : Provide inputs to make complex decisions within your domain and contribute to strategy.\nWhat you bring to the team:\nExperience :\nBachelor s degree and 1-2 years of experience, or an advanced degree (Master s or PhD) in data science or AI.\nTechnical Expertise :\nDeep knowledge of AI and data science, including Generative AI, LLMs (OpenAI, Azure, Google, open-source), RAG pipelines, prompt engineering, NLP, and image models.\nStrong proficiency in Python, along with libraries such as Pandas, NumPy, Scikit-learn, PyTorch, or TensorFlow.\nHands-on experience with HuggingFace, LangChain, and cloud-native AI services.\nCloud Expertise :\nExperience with AWS, Azure, or GCP for model training, deployment, and data workflows.\nFamiliarity with MLOps and model lifecycle management in production environments.\nProduct Thinking :\nAbility to translate complex business challenges into technical solutions that scale.\nProven track record of delivering AI-powered features from concept to production.\nEducation:\nBachelor s or Master s degree in Computer Science, Data Science, Engineering, or a related field.\nOther Skills :\nExcellent communication and collaboration skills.\nStrong articulation skills and a thoughtful, data-driven approach to solving problems.\nExperience working in a fast-paced SaaS or tech-driven environment.\nWhat we have for you:\nAt Seismic, we re committed to providing benefits and perks for the whole self. To explore our benefits available in each country, please visit the Global Benefits page .",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'data science', 'GCP', 'SAAS', 'Machine learning', 'Cloud', 'Manager Technology', 'Application development', 'Open source', 'Python']",2025-06-10 15:34:25
Data Scientist,Top Rated Firm in IT Services Domain,3 - 8 years,5-7 Lacs P.A.,['Hyderabad( Nanakramguda )'],"Key Responsibilities:\nDesign and develop machine learning models and algorithms to solve business problems\nWrite clean, efficient, and reusable Python code for data processing and model deployment\nCollaborate with data engineers and product teams to integrate models into production systems\nAnalyze large datasets to derive insights, trends, and patterns\nEvaluate model performance and continuously improve through retraining and tuning\nCreate dashboards, reports, and data visualizations as needed\nMaintain documentation and ensure code quality and version control\n\nPreference\nMust have hands-on experience in building, training, and deploying AI/ML models using relevant frameworks and tools within a Linux environment.\nStrong proficiency in Python with hands-on experience in data science libraries (NumPy, Pandas, Scikit-learn, TensorFlow/PyTorch, etc.)\nExperience working with Hugging Face Transformers, spaCy, ChatGPT (OpenAI APIs), and DeepSeek LLMs for building NLP or generative AI solutions\nSolid understanding of machine learning, statistics, and data modeling\nExperience with data preprocessing, feature engineering, and model evaluation\nFamiliarity with SQL and working with structured/unstructured data\nKnowledge of APIs, data pipelines, and cloud platforms (AWS, GCP, or Azure) is a plus",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Tensorflow', 'Pyspark', 'Artificial Intelligence', 'Natural Language Processing', 'Jupyter Notebook', 'Machine Learning', 'Scikit-Learn', 'Numpy', 'SQL', 'Pytorch', 'Pandas', 'AWS']",2025-06-10 15:34:27
Pyspark Engineer,Barclays,0 - 6 years,Not Disclosed,['Pune'],"Join us as a Pyspark Engineer at Barclays, responsible for supporting the successful delivery of location strategy projects to plan, budget, agreed quality and governance standards. Youll spearhead the evolution of our digital landscape, driving innovation and excellence. You will harness cutting-edge technology to revolutionize our digital offerings, ensuring unparalleled customer experiences.\nTo be successful as a Pyspark Engineer you should have experience with:\nPyspark\nAWS\nSnowflake\nDatawarehouse technologies\nSome other highly valued skills may include:\nDevOps tools\nAirflow\nIceberg\nAgile Methodologies\nYou may be assessed on key critical skills relevant for success in role, such as risk and controls, change and transformation, business acumen, strategic thinking and digital and technology, as well as job-specific technical skills.\nThis role is based out of Pune.\nPurpose of the role\nTo build and maintain the systems that collect, store, process, and analyse data, such as data pipelines, data warehouses and data lakes to ensure that all data is accurate, accessible, and secure.\nAccountabilities\nBuild and maintenance of data architectures pipelines that enable the transfer and processing of durable, complete and consistent data.\nDesign and implementation of data warehoused and data lakes that manage the appropriate data volumes and velocity and adhere to the required security measures.\nDevelopment of processing and analysis algorithms fit for the intended data complexity and volumes.\nCollaboration with data scientist to build and deploy machine learning models.\nAssistant Vice President Expectations\nTo advise and influence decision making, contribute to policy development and take responsibility for operational effectiveness. Collaborate closely with other functions/ business divisions.\nLead a team performing complex tasks, using well developed professional knowledge and skills to deliver on work that impacts the whole business function. Set objectives and coach employees in pursuit of those objectives, appraisal of performance relative to objectives and determination of reward outcomes\nIf the position has leadership responsibilities, People Leaders are expected to demonstrate a clear set of leadership behaviours to create an environment for colleagues to thrive and deliver to a consistently excellent standard. The four LEAD behaviours are: L - Listen and be authentic, E - Energise and inspire, A - Align across the enterprise, D - Develop others.\nOR for an individual contributor, they will lead collaborative assignments and guide team members through structured assignments, identify the need for the inclusion of other areas of specialisation to complete assignments. They will identify new directions for assignments and/ or projects, identifying a combination of cross functional methodologies or practices to meet required outcomes.\nConsult on complex issues; providing advice to People Leaders to support the resolution of escalated issues.\nIdentify ways to mitigate risk and developing new policies/procedures in support of the control and governance agenda.\nTake ownership for managing risk and strengthening controls in relation to the work done.\nPerform work that is closely related to that of other areas, which requires understanding of how areas coordinate and contribute to the achievement of the objectives of the organisation sub-function.\nCollaborate with other areas of work, for business aligned support areas to keep up to speed with business activity and the business strategy.\nEngage in complex analysis of data from multiple sources of information, internal and external sources such as procedures and practises (in other areas, teams, companies, etc). to solve problems creatively and effectively.\nCommunicate complex information. Complex information could include sensitive information or information that is difficult to communicate because of its content or its audience.\nInfluence or convince stakeholders to achieve outcomes.",Industry Type: Financial Services,Department: Other,"Employment Type: Full Time, Permanent","['Machine learning', 'Service excellence', 'Agile', 'Manager Technology', 'Manual', 'Business strategy', 'Assistant Vice President', 'Individual Contributor', 'Operations', 'Data warehousing']",2025-06-10 15:34:29
Data Scientist,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Data Scientist is an advanced subject matter expert, tasked with taking accountability in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nResponsible for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources\nProvides meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nDirects scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualizes the output of the models.\nResponsible for ensuring that industry standards best practices are applied to development activities.\nKnowledge and Attributes:\nAdvanced understanding of data modelling, statistical methods and machine learning techniques.\nStrong ability to thrive in a dynamic, fast-paced environment.\nStrong quantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nAdvanced understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nStrong ability to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nStrong ability to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming certification preferred.\nAgile certification preferred.\nRequired Experience:\nAdvanced demonstrated experience in a data science position in a corporate environment and/or related industry.\nAdvanced demonstrated experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nAdvanced demonstrated experience in programming languages (R, Python, etc.).\nAdvanced demonstrated experience working with and creating data architectures.\nAdvanced demonstrated experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nAdvanced demonstrated experience visualizing and/or presenting data for stakeholder use and reuse across the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'R', 'data modelling', 'data mining', 'statistical modelling', 'machine learning', 'Python', 'SQL']",2025-06-10 15:34:32
Data Analyst,Capgemini,4 - 6 years,Not Disclosed,['Bengaluru'],"Overview\nWe are seeking a highly motivated Data Analyst with strong technical and analytical skills to join our ADAS (Advanced Driver Assistance Systems) team. This role involves working with large-scale data from vehicle systems to drive insights, support data science initiatives, and contribute to the development of safer and smarter automotive technologies.\n\nResponsibilities:\nPerform data cleansing, aggregation, and analysis on large, complex datasets related to ADAS components and systems.\nBuild, maintain, and update dashboards and data visualizations to communicate insights effectively (Power BI preferred).\nDevelop and optimize data pipelines and ETL processes.\nCreate and maintain technical documentation, including data catalogs and process documentation.\nCollaborate with cross-functional teams including data scientists, software engineers, and system engineers.\nContribute actively to the internal data science community by sharing knowledge, tools, and best practices.\nWork independently on assigned projects, managing priorities and delivering results in a dynamic, unstructured environment.Required Qualifications:\nBachelors degree or higher in Computer Science, Data Science, or a related field.\nMinimum 3 years of experience in the IT industry, with at least 2 years in data analytics or data engineering roles.\nProficient in Python or Pyspark with solid software development fundamentals.\nStrong experience with SQL and relational databases.\nHands-on experience with data science, data engineering, or machine learning techniques.\nKnowledge of data modeling, data warehousing concepts, and ETL processes.\nFamiliarity with data visualization tools (Power BI preferred).\nBasic understanding of cloud platforms such as Azure or AWS.\nFundamental knowledge of ADAS functionalities is a plus.\nStrong problem-solving skills, self-driven attitude, and the ability to manage projects independently.Preferred Skills:\nExperience in automotive data or working with sensor data (e.g., radar, lidar, cameras).\nFamiliarity with agile development methodologies.\nUnderstanding of big data tools and platforms such as Databricks or Spark. Works in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.- Grade SpecificIs fully competent in it's own area and has a deep understanding of related programming concepts software design and software development principles. Works autonomously with minimal supervision. Able to act as a key contributor in a complex environment, lead the activities of a team for software design and software development. Acts proactively to understand internal/external client needs and offers advice even when not asked. Able to assess and adapt to project issues, formulate innovative solutions, work under pressure and drive team to succeed against its technical and commercial goals. Aware of profitability needs and may manage costs for specific project/work area. Explains difficult concepts to a variety of audiences to ensure meaning is understood. Motivates other team members and creates informal networks with key contacts outside own area.Skills (competencies)Verbal Communication",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'software development', 'pyspark', 'relational databases', 'sql', 'data analytics', 'software design', 'data warehousing', 'microsoft azure', 'power bi', 'machine learning', 'data engineering', 'data bricks', 'data science', 'data modeling', 'spark', 'adas', 'agile', 'etl', 'aws', 'big data']",2025-06-10 15:34:35
Specialist Data Scientist,NICE,8 - 11 years,Not Disclosed,['Pune'],"So, what’s the role all about?\nNICE provides state-of-the-art enterprise level AI and analytics for all forms of business communications between speech and digital.   We are a world class research team developing new algorithms and approaches to help companies with solving critical issues such as identifying their best performing agents, preventing fraud, categorizing customer issues, and determining overall customer satisfaction.  If you have interacted with a major contact center in the last decade, it is very likely we have processed your call. \nThe research group partners with all areas of NICE’s business to scale out the delivery of new technology and AI models to customers around the world that are tailored to their company, industry, and language needs.",,,,"['python', 'confluence', 'natural language processing', 'presentation skills', 'big data technologies', 'pyspark', 'microsoft azure', 'bert', 'machine learning', 'sql', 'tensorflow', 'data science', 'gcp', 'pytorch', 'machine learning algorithms', 'aws', 'big data', 'communication skills', 'statistics', 'jira']",2025-06-10 15:34:38
Senior Engineer-NLP,Evalueserve,3 - 6 years,Not Disclosed,['Bengaluru'],"Senior Engineer-NLP:\n\nElevate Your Impact Through learning\nEvalueserve is a global leader in delivering innovative and sustainable solutions to a diverse range of clients, including over 30% of Fortune 500 companies. With a presence in more than 45 countries across five continents, we excel in leveraging state-of-the-art technology, artificial intelligence, and unparalleled subject matter expertise to elevate our clients' business impact and strategic decision-making. Our team of over 4, 500 talented professionals operates in countries such as India, China, Chile, Romania, the US, and Canada. Our global network also extends to emerging markets like Colombia, the Middle East, and the rest of Asia-Pacific. Recognized by Great Place to Work in India, Chile, Romania, the US, and the UK in 2022, we offer a dynamic, growth-oriented, and meritocracy-based culture that prioritizes continuous learning and skill development, work-life balance, and equal opportunity for all.\nA bout Innovation and Technology Centre (ITC)\nOur Innovation and Technology Centre specializes in creating modular solutions to meet clients' specific needs. As a member of the team, you will have the opportunity to develop and implement digital products, platforms, and tools specifically designed for research, analytics, and data management domains. We are at the forefront of technological advancements, and our AI efforts rely on our larger platform called AI for Research and Analytics (AIRA).\nWhat you will be doing at Evalueserve\nBuilding and implementing advanced machine learning (ML) and deep learning (DL) algorithms and models\nApplying different natural language processing (NLP) techniques to problems such as text classification, text summarization, questions and answers, information retrieval, knowledge extraction, and design of conversational bots by using traditional and generative AI techniques\nContributing to the design and development of enterprise-grade generative AI applications, including but not limited to advanced RAG, VDB optimization, LLM evaluation, and finetuning\nDesigning and developing a practical and analytical approach while maintaining a focus on aspects such as data quality and availability, feasibility, scalability, and turnaround time\nWhat were Looking for\nAt least a bachelors /master`s degree in computer science, information systems, statistics, mathematics, or a related field\nStrong understanding of data science processes, such as data investigation, cleaning, minimal viable models, and nuances related to the deployment and enhancement\nAbout 38 years of experience in NLP, ML, and DL\nMore than one year of experience in generative AI application development at the production level\nDemonstrated ability in developing NLP / ML / DL / generative AI project solutions here\nHands-on experience and deep theoretical expertise in NLU, NLP, NLG, and common NLP algorithms and DL architectures such as Transformers, BERT, word2vec, FastText, and ELMO\nHands-on experience in building and handling product-level delivery of knowledge graphs, ranking algorithms, recommendation engines, etc\nIn-depth knowledge and experience in handling open-source frameworks, such as TensorFlow, PyTorch, and Huggingface Transformers\nExpert-level programming experience in Python / C++\nFamiliarity with general software design concepts, product development lifecycles, and ML model deployment best practices\nExperience in analyzing large amounts of user-generated content and process data in large-scale environments by using cloud infrastructure\nProficiency in scraping data from external sources and developing architectures to store and organize the information for generating insights\nExperience in contributing to open-source software projects\nExperience and tenacity to go beyond available tools / techniques to design solutions in line with product requirements\nAbility to communicate with internal and external stakeholders and convey complex information clearly and concisely\nUnderstanding of the cultural differences and work styles in a global environment\n\nWant to learn more about our culture and what its like to work with us?\nWrite to us at: careers@evalueserve.com\nDisclaimer: The following job description serves as an informative referencefor the tasks you may be required to perform. However, it does not constitutean integral component of your employment agreement and is subject to periodicmodifications to align with evolving circumstances.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['algorithms', 'python', 'c++', 'process', 'development', 'data scraping', 'natural language processing', 'information retrieval', 'dl', 'bert', 'machine learning', 'artificial intelligence', 'application development', 'analytics', 'gen', 'deep learning', 'tensorflow', 'data science', 'pytorch', 'nisa', 'programming', 'architecture', 'ml']",2025-06-10 15:34:40
AI Engineer / Data Analyst,Meru Software,2 - 5 years,Not Disclosed,['Hyderabad'],Meru Software Pvt Ltd is looking for AI Engineer / Data Analyst to join our dynamic team and embark on a rewarding career journey.\n\nDesigning and developing AI algorithms and models to solve specific business problems. Creating and maintaining databases for storing and processing large amounts of data. Developing and deploying machine learning and deep learning models. Implementing and integrating AI solutions with existing systems and software. Analyzing and interpreting complex data sets to extract insights and drive decision - making. Collaborating with cross - functional teams to develop and deploy AI applications. Ensuring the security and privacy of data used in AI applications. Communicating and presenting technical information to non - technical stakeholders. Excellent communication skills & attention to detail.,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine learning', 'Data Analyst', 'SQL', 'Python']",2025-06-10 15:34:43
Data Scientist,Virtana Corp,3 - 8 years,Not Disclosed,"['Pune', 'Chennai']","Position Overview:\nWe are seeking a Data Scientist Engineer with experience bringing highly scalable enterprise SaaS applications to market. This is a uniquely impactful opportunity to help drive our business forward and directly contribute to long-term growth at Virtana.\nIf you thrive in a fast-paced environment, take initiative, embrace proactivity and collaboration, and you re seeking an environment for continuous learning and improvement, we d love to hear from you!\nVirtana is a remote first work environment so you ll be able to work from the comfort of your home while collaborating with teammates on a variety of connectivity tools and technologies.\nJob Location- Pune/ Chennai/ Remote\nYou can schedule with us through Calendly at https: / / calendly.com / bimla-dhirayan / zoom-meeting-virtana\nRole Responsibilities:\nResearch and test machine learning approaches for analyzing large-scale distributed computing applications.\nImplement different models AI and ML algorithms for prototype and production systems.\nTest and refine the models and algorithms with live customer data to improve accuracy and efficacy.\nWork with other functional teams to integrate implemented systems into the SaaS platform\nSuggest innovative and creative concepts and ideas that would improve the overall platform\nQualifications:\nThe ideal candidate must have the following qualifications:\n3+ years experience in practical implementation and deployment of ML based systems preferred.\nBS/B Tech or M Tech/ MS (preferred) in Applied Mathematics or Statistics, or CS/Engineering with strong mathematical/statistical background\nStrong quantitative and analytical skills, especially statistical and ML techniques, including familiarity with different supervised and unsupervised learning algorithms\nImplementation experiences and deep knowledge of Classification, Time Series Analysis, Pattern Recognition, Reinforcement Learning, Deep Learning, Dynamic Programming and Optimization\nExperience in working on modeling graph structures related to spatiotemporal systems\nProgramming skills in Python\nExperience in developing and deploying on cloud (AWS or Google or Azure)\nExperience in understanding and usage of LLM models and Prompt engineering is preferred.\nGood verbal and written communication skills\nFamiliarity with well-known ML frameworks such as Pandas, Keras and TensorFlow",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Usage', 'Prototype', 'Time series analysis', 'Artificial Intelligence', 'IT operations management', 'Machine learning', 'Cloud', 'Cash flow', 'Pattern recognition', 'Python']",2025-06-10 15:34:46
MLOps Engineer / Data Scientist,CEVA Logistics,3 - 7 years,Not Disclosed,['Mumbai'],"CEVA Logistics provides global supply chain solutions to connect people, products, and providers all around the world\nPresent in 170+ countries and with more than 110,000 employees spread over 1,500 sites, we are proud to be a Top 5 global 3PL\nWe believe that our employees are the key to our success\nWe want to engage and empower our diverse, global team to co-create value with our customers through our solutions in contract logistics and air, ocean, ground, and finished vehicle transport\nThat is why CEVA Logistics offers a dynamic and exceptional work environment that fosters personal growth, innovation, and continuous improvement\nDARE TO GROW! Join CEVA Logistics, and you will be part of a team that values imagination and continued learning and is committed to excellence in everything we do\nJoin us in our mission to shape the future of global logistics\nAs we continue growing at a fast pace, will you Dare to Grow with us\nJoin the forefront of AI-driven logistics innovation as a MLOps Engineer/Data Scientist at CEVA Logistics, a global leader in supply chain solutions\nYOUR ROLE\nAs a MLOps Engineer/Data scientist, you will play a pivotal role in CEVA LogisticsGlobal IT Data & Digital organization, reporting directly to the Global IT Data & Digital BI & Advanced Analytics AI & Data Science Manager\nThis hybrid role combines the expertise of data science with operational practices focused on the industrialization and deployment of AI and machine learning solutions at scale\nYou will collaborate with cross-functional teams in IT, Corporate Support Functions, Business Development, and Operations to drive the development and industrialization of machine learning models\nYour work will ensure that AI-driven insights and use cases are seamlessly integrated, scalable, and continuously optimized to provide ongoing value to CEVA Logistics and its customers\nThis position requires expertise not only in data science and machine learning but also in the processes that turn innovative solutions into robust, enterprise-grade systems\nThis position is open in Spain (Madrid / Barcelona) or Poland (Warsaw) or India (Mumbai)\nWHAT ARE YOU GOING TO DO\nExpertise in data science and machine learning techniques with experience in designing, building, and deploying models to solve business challenges\nProficiency in industrializing use cases, focusing on turning proof-of-concept models into full-scale, production-ready AI solutions that are both scalable and sustainable\nHands-on experience with MLOps tools and technologies (such as Kubernetes, Docker, Jenkins, MLflow, TensorFlow, etc-) for automating the deployment, monitoring, and maintenance of machine learning models\nStrong experience with cloud platforms (AWS, Google Cloud, Azure) and modern deployment architectures for AI/ML workloads\nAdvanced proficiency in Python, SQL, and experience with big data technologies to work with large datasets\nStrong understanding of model governance, model monitoring, and model retraining to ensure AI solutions deliver consistent and ongoing business value\nAbility to work collaboratively across cross-functional teams to ensure smooth transitions from development to deployment and operationalization\nExcellent communication skills to explain complex technical concepts to non-technical stakeholders and influence business strategies through AI-driven insights\nWHAT ARE WE LOOKING FOR\nA minimum of 5 years of professional experience with proven results in AI, Data Science & MLOps\nMasters degree in computer science, Data Science, Engineering, Mathematics, or a related field\nAdvanced certifications in AI, Data Science, Machine Learning, or MLOps would be plus\nProven ability to collaborate effectively with cross-functional teams, including business stakeholders, IT, and operations, to translate business needs into technical solutions\nStrong written and verbal communication skills, with the ability to explain complex technical concepts to non-technical audiences\nTechnical Expertise:\nData Science:\nSolid understanding of machine learning algorithms, statistical methods, and predictive modeling\nProficiency in Python and libraries such as TensorFlow, Keras, scikit-learn, XGBoost, and PyTorch\nMLOps:\nHands-on experience implementing MLOps practices for model deployment, automation, and continuous integration/continuous delivery (CI/CD)\nFamiliarity with tools like MLflow, Kubeflow, Jenkins, Docker, Kubernetes, and Terraform for automating machine learning pipelines\nData Integration & Management:\nProficient in using Snowflake for data integration, storage, and processing at scale\nExperience with Dataiku for creating and managing end-to-end data science workflows\nBig Data Technologies:\nFamiliarity with big data platforms and tools to process and analyze large datasets\nData Visualization & Reporting:\nExpertise in using Qlik Sense, Streamlite, or other BI, webapp & data visualization tools for developing interactive and insightful dashboards and reports to communicate complex results to non-technical stakeholders\nModel Development & Industrialization:\nExperience in transitioning machine learning models from prototype to production at scale, ensuring robustness, scalability, and reliability in real-world applications\nFamiliarity with best practices in model versioning, testing, monitoring, and retraining to maintain model accuracy and performance over time\nCloud Platforms:\nStrong experience with cloud-based platforms like AWS, Google Cloud and Azure for deploying, managing, and scaling AI/ML models\nCollaboration & Communication:\nProven ability to collaborate effectively with cross-functional teams, including business stakeholders, IT, and operations, to translate business needs into technical solutions\nStrong written and verbal communication skills, with the ability to explain complex technical concepts to non-technical audiences\nProblem Solving & Innovation:\nStrong analytical and problem-solving skills, with a creative mindset for leveraging AI and machine learning to solve business problems and drive innovation\nAbility to stay up to date with the latest developments in AI, machine learning, and MLOps, and apply cutting-edge techniques to business challenges\nSoft Skills:\nSelf-motivated, adaptable, and able to thrive in a fast-paced and dynamic work environment\nStrong attention to detail with a focus on quality, accuracy, and reliability in all work\nEffective time management and organizational skills, with the ability to handle multiple projects simultaneously and meet deadlines\nAdditional Information:\nThis position offers the opportunity to work with both existing tools at CEVA and new, modern tools available in the Cloud, leveraging our newly developed CEVA Data Platform\nThe role requires a proactive individual with a strong commitment to driving data-driven strategies and solutions within the organization\nWHAT DO WE HAVE TO OFFER\nWith a genuine culture of recognition, we want our employees to grow, develop and be part of our journey\nYou have access to the CEVA academy for training\nYou receive healthcare benefits, reimbursement of the transportation card (50%) and meal vouchers for each working day\nWe are a team in every sense, and we support each other and work collaboratively to achieve our goals together\nIt is our goal that you will be compensated for your hard work and commitment, so if youd like to work for one of the top Logistics providers in the world then lets work together to help you find your new role",Industry Type: Courier / Logistics,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['model monitoring', 'snowflake', 'python', 'predictive modeling', 'cloud platforms', 'machine learning algorithms', 'sql', 'communication skills']",2025-06-10 15:34:49
GenAI Engineer,Xebia It Architects,5 - 10 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","About Xebia\nXebia is a trusted advisor in the modern era of digital transformation, serving hundreds of leading brands worldwide with end-to-end IT solutions. The company has experts specializing in technology consulting, software engineering, AI, digital products and platforms, data, cloud, intelligent automation, agile transformation, and industry digitization. In addition to providing high-quality digital consulting and state-of-the-art software development, Xebia has a host of standardized solutions that substantially reduce the time-to-market for businesses.\nXebia also offers a diverse portfolio of training courses to help support forward-thinking organizations as they look to upskill and educate their workforce to capitalize on the latest digital capabilities. The company has a strong presence across 16 countries with development centres across the US, Latin America, Western Europe, Poland, the Nordics, the Middle East, and Asia Pacific.\n\nJob Title: Generative AI Engineer\nExp: 5 9 yrs\nLocation: Bengaluru, Chennai, Gurgaon & Pune\nJob Summary:\nWe are seeking a highly skilled Generative AI Engineer with hands-on experience in developing and deploying cutting-edge AI solutions using AWS, Amazon Bedrock, and agentic AI frameworks. The ideal candidate will have a strong background in machine learning and prompt engineering, with a passion for building intelligent, scalable, and secure GenAI applications.\nKey Responsibilities:\n\nDesign, develop, and deploy Generative AI models and pipelines for real-world use cases.\nBuild and optimize solutions using AWS AI/ML services, including Amazon Bedrock, SageMaker, and related cloud-native tools.\nDevelop and orchestrate Agentic AI systems, integrating autonomous agents with structured workflows and dynamic decision-making.\nCollaborate with cross-functional teams including data scientists, cloud engineers, and product managers to translate business needs into GenAI solutions.\nImplement prompt engineering, fine-tuning, and retrieval-augmented generation (RAG) techniques to optimize model performance.\nEnsure robustness, scalability, and compliance in GenAI workloads deployed in production environments.\nRequired Skills & Qualifications:\n\nStrong experience with Generative AI models (e.g., GPT, Claude, Mistral, etc.)\nHands-on experience with Amazon Bedrock and other AWS AI/ML services.\nProficiency in building and managing Agentic AI systems using frameworks like LangChain, AutoGen, or similar.\nSolid understanding of cloud-native architectures and ML Ops on AWS.\nProficiency in Python and relevant GenAI/ML libraries (Transformers, PyTorch, LangChain, etc.)\nFamiliarity with security, cost, and governance best practices for GenAI on cloud.\nPreferred Qualifications:\n\nAWS certifications (e.g., AWS Certified Machine Learning Specialty)\nExperience with LLMOps tools and vector databases (e.g., Pinecone, FAISS, Weaviate)\nBackground in NLP, knowledge graphs, or conversational AI.\nWhy Join Us?\nWork on cutting-edge AI technologies that are transforming industries.\nCollaborative and innovative environment.\nOpportunities for continuous learning and growth.",Industry Type: IT Services & Consulting,"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['GenAI', 'Agentic Ai', 'Ml']",2025-06-10 15:34:51
Lead Machine Learning Engineer - AI,Avalara India,6 - 11 years,Not Disclosed,[],"We are looking for accomplished Machine Learning Engineers with a background in software development and a deep enthusiasm for solving complex problems. You will lead a dynamic team dedicated to designing and implementing a large language model framework to power diverse applications across Avalara. Your responsibilities will span the entire development lifecycle, including conceptualization, prototyping, development, and delivery of the LLM platform features. You will build core agent infrastructure A2A orchestration and MCP-driven tool discovery so teams can launch secure, scalable agent workflows. You will be reporting to Senior Manager, ML Engineering.\n\nWhat you'll Need to be Successful",,,,"['Cloud computing', 'orchestration', 'GCP', 'Machine learning', 'Debugging', 'Conceptualization', 'Data structures', 'Unit testing', 'Python']",2025-06-10 15:34:53
Senior Machine Learning Engineer,Ortseam Technologies,5 - 10 years,Not Disclosed,[],"Job Title: Senior Machine Learning Engineer\nWork Mode: Remote\nBase Location: Bengaluru\nExperience: 5+ Years\n\nStrong problem-solving skills and ability to work in a fast-paced, collaborative environment.\nStrong programming skills in Python and experience with ML frameworks.\nProficiency in containerization (Docker) and orchestration (Kubernetes) technologies.\nSolid understanding of CI/CD principles and tools (e.g., Jenkins, GitLab CI, GitHub Actions).\nKnowledge of data engineering concepts and experience building data pipelines.\nStrong understandings on Computational, Storage and Orchestration resources on cloud platforms.\nDeploying and managing ML models especially on GCP (cloud platform agnostic though) services such as Cloud Run, Cloud Functions, and Vertex AI.\nImplementing MLOps best practices, including model version tracking, governance, and monitoring for performance degradation and drift.\nCreating and using benchmarks, metrics, and monitoring to measure and improve services\nCollaborating with data scientists and engineers to integrate ML workflows from onboarding to decommissioning.\nExperience with MLOps tools like Kubeflow, MLflow, and Data Version Control (DVC).\nManage ML models on any of the following: AWS (SageMaker), Azure (Machine Learning), and GCP (Vertex AI).\n\nTech Stack:\n\nAws or GCP or Azure Experience. (More GCP Specific)\nmust have done Py spark,\nDatabricks is good.\nML Experience,\nDocker and Kubernetes.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pyspark', 'Machine Learning', 'Docker', 'GCP', 'Kubernetes', 'Vertex', 'Hadoop', 'Data Bricks', 'Hive', 'Azure Cloud', 'SCALA', 'Cicd Pipeline', 'AWS', 'Python']",2025-06-10 15:34:55
"Applied Scientist, Amazon Photos",Amazon,3 - 8 years,Not Disclosed,['Bengaluru'],"The Amazon Photos team is looking for a world-class Applied Scientist to join us and use AI to help customers relive their cherished memories. Our team of scientists have developed algorithms and models that power Amazon Photos features for millions of photos and videos daily. As part of the team, we expect that you will develop innovative solutions to hard problems at massive scale, and publish your findings in at peer reviewed conferences and workshops.\n\nWith all the recent advancements in Vision-Language models, Amazon Photos has completely re-thought the product roadmap and is looking for Applied Scientists to deliver both the short-term roadmap working closely with Product and Engineering and make investments for the long-term. Our research themes include, but are not limited to: foundational models, contrastive learning, diffusion models, few-shot and zero-shot learning, transfer learning, unsupervised and semi-supervised methods, active learning and semi-automated data annotation, deep learning, and large scale image and video detection and recognition.\n\n\nCollaborate with cross-functional teams of engineers, product managers, and scientists to identify and solve complex problems in Visual-Language Model space\nDesign and execute experiments to evaluate the performance of different models, and iterate quickly to improve results\nCreate robust evaluation frameworks for assessing model performance across different domains and use cases\nThink big about the Visual-Language Model space over a multi-year horizon, and identify new opportunities to apply these technologies to solve real-world problems within Amazon Photos\nCommunicate results and insights to both technical and non-technical audiences, including through presentations and written reports\n\nAbout the team\nAmazon Photos is the one of the main digital products offered to Prime subscribers along with Amazon Music and Amazon Video. Amazon Photos provides unlimited photo storage and 5 GB for videos to Prime members and is a top Prime benefit in multiple marketplaces. AI-driven experiences based on image and video understanding are core to customer delight for the business. These experiences are delivered in our mobile, web and desktop apps, in Fire TV, and integrated into Alexa devices such as Echo Show. We solve real-world problems using AI while being a positive force for good. 3+ years of building models for business application experience\nPhD, or Masters degree and 4+ years of CS, CE, ML or related field experience\nExperience programming in Java, C++, Python or related language\nExperience in any of the following areas: algorithms and data structures, parsing, numerical optimization, data mining, parallel and distributed computing, high-performance computing PhD in computer science, machine learning, engineering, or related fields\nExperience developing and implementing deep learning algorithms, particularly with respect to computer vision algorithms\nMaterial contributions to the CV/ML/AI field as related to image and video processing",,,,"['Computer science', 'Computer vision', 'deep learning', 'C++', 'Machine learning', 'Programming', 'Data structures', 'high performance computing', 'Data mining', 'Python']",2025-06-10 15:34:58
Mega Walk In | TELUS Digital | Annotation Analyst | For Freshers,TELUS International,0 - 2 years,2.5-3 Lacs P.A.,"['Gandhinagar', 'Ahmedabad']","Job Description:\nWe are looking for motivated and detail-oriented Annotation Analysts who are fresh graduates eager to start their careers in the AI and data annotation field. As an Annotation Analyst, you will play a crucial role in training machine learning models by accurately labeling and annotating data such as images, text, audio, or video.\n\nResponsibilities:",,,,"['Fresher', 'Cad Software', 'Backend', 'Annotation Analyst', 'CAD', 'Back Office Operations', 'Aiml', 'Fresher Hiring', 'Data Annotation', 'Annotation', 'Freshers']",2025-06-10 15:35:01
ML Engineer,Wipro,1 - 4 years,Not Disclosed,['Bengaluru'],"Wipro Limited (NYSEWIT, BSE507685, NSEWIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\n\nAbout The Role\n\n\n\nRole Purpose\n\nThe purpose of this role is to design, test and maintain software programs for operating systems or applications which needs to be deployed at a client end and ensure its meet 100% quality assurance parameters\n\n?\n\n\n\nDo\n\n1. Instrumental in understanding the requirements and design of the product/ software\nDevelop software solutions by studying information needs, studying systems flow, data usage and work processes\nInvestigating problem areas followed by the software development life cycle\nFacilitate root cause analysis of the system issues and problem statement\nIdentify ideas to improve system performance and impact availability\nAnalyze client requirements and convert requirements to feasible design\nCollaborate with functional teams or systems analysts who carry out the detailed investigation into software requirements\nConferring with project managers to obtain information on software capabilities\n\n\n?\n\n2. Perform coding and ensure optimal software/ module development\nDetermine operational feasibility by evaluating analysis, problem definition, requirements, software development and proposed software\nDevelop and automate processes for software validation by setting up and designing test cases/scenarios/usage cases, and executing these cases\nModifying software to fix errors, adapt it to new hardware, improve its performance, or upgrade interfaces.\nAnalyzing information to recommend and plan the installation of new systems or modifications of an existing system\nEnsuring that code is error free or has no bugs and test failure\nPreparing reports on programming project specifications, activities and status\nEnsure all the codes are raised as per the norm defined for project / program / account with clear description and replication patterns\nCompile timely, comprehensive and accurate documentation and reports as requested\nCoordinating with the team on daily project status and progress and documenting it\nProviding feedback on usability and serviceability, trace the result to quality risk and report it to concerned stakeholders\n\n\n?\n\n3. Status Reporting and Customer Focus on an ongoing basis with respect to project and its execution\nCapturing all the requirements and clarifications from the client for better quality work\nTaking feedback on the regular basis to ensure smooth and on time delivery\nParticipating in continuing education and training to remain current on best practices, learn new programming languages, and better assist other team members.\nConsulting with engineering staff to evaluate software-hardware interfaces and develop specifications and performance requirements\nDocument and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code\nDocumenting very necessary details and reports in a formal way for proper understanding of software from client proposal to implementation\nEnsure good quality of interaction with customer w.r.t. e-mail content, fault report tracking, voice calls, business etiquette etc\nTimely Response to customer requests and no instances of complaints either internally or externally\n\n\n?\n\n\n\nDeliver\n\n\n\n\nNo.\n\n\n\nPerformance Parameter\n\n\n\nMeasure 1. Continuous Integration, Deployment & Monitoring of Software 100% error free on boarding & implementation, throughput %, Adherence to the schedule/ release plan 2. Quality & CSAT On-Time Delivery, Manage software, Troubleshoot queries, Customer experience, completion of assigned certifications for skill upgradation 3. MIS & Reporting 100% on time MIS & report generation\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['continuous integration', 'root cause analysis', 'software development life cycle', 'mis', 'ml', 'python', 'c++', 'data analysis', 'c', 'data analytics', 'natural language processing', 'machine learning', 'artificial intelligence', 'sql', 'deep learning', 'r', 'data science', 'computer vision']",2025-06-10 15:35:03
ML Engineer,HARMAN,3 - 5 years,Not Disclosed,['Bengaluru'],"As a technology leader that is rapidly on the move, HARMAN is filled with people who are focused on making life better. Innovation, inclusivity and teamwork are a part of our DNA. When you add that to the challenges we take on and solve together, you'll discover that at HARMAN you can grow, make a difference and be proud of the work you do everyday.\n  Introduction: Digital Transformation Solutions (DTS)\nwe're a global, multi-disciplinary team that s putting the innovative power of technology to work and transforming tomorrow. As a member of HARMAN Lifestyle, you connect consumers with the power of superior sound.",,,,"['C++', 'Linux', 'Image processing', 'Analytical', 'Machine learning', 'Debugging', 'Automotive', 'Python', 'Android']",2025-06-10 15:35:06
Associate Prompt Engineer (On Contract basis),A client of Randstad India,0 - 2 years,5-6 Lacs P.A.,[],*Work from home opportunity*\nNeed mainly from BSc- Physics/Chemistry/Mathematics and Finance and Accounting background.,Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI', 'LLM', 'English Language', 'ML']",2025-06-10 15:35:09
Data Scientist I - Newton,Affle,2 - 5 years,Not Disclosed,['Gurugram'],"The Data Scientist is crucial in leveraging data to derive meaningful insights and solutions for complex business problems. This individual will lead and guide the data science team in developing advanced analytical models, algorithms, and statistical analyses. They will collaborate with cross-functional teams to identify\nopportunities for leveraging data-driven solutions, making strategic decisions, and enhancing overall business performance. The Data Scientist will be responsible for designing and implementing machine learning models, conducting data exploration, and communicating findings to non-technical stakeholders.\nPrimary Responsibilities:\nCollaborate with business stakeholders to understand and translate their goals into data science initiatives.\nLead the development and implementation of machine learning models and algorithms to place ads in the context of cutting-edge privacy frameworks efficiently.\nDevelop strategies to optimize budget allocation in scenarios with high cardinality and uncertainty.\nConduct exploratory data analysis to discover complex data sets' patterns, trends, and insights.\nCommunicate complex analytical findings in a clear and actionable manner to non-technical stakeholders.\nStay abreast of the latest advancements in data science, machine learning, and relevant technologies.\nDevelop and train ML/DL models for forecasting/classification\nBuild AI agents RAG-based systems\nLeverage data-driven insights and predictive modeling to build PoCs.\nLeverage LangChain, LangGraph, or similar for orchestration\nUse SQL for data analysis, feature engineering, and reporting\nRequired Skills:\nQualification in a quantitative field such as Computer Science, Statistics, Physics, or Mathematics.\nExcellent problem-solving skills.\nStrong coding skills.\n2+ years of relevant work experience in data science and machine learning.\nSolid background in statistical analysis, hypothesis testing, and experimental design.\nProficiency in Python and SQL\nPreferred GCP Platform\nExposure to RAG, LLMs, and agentic workflows - Finetuning Evaluation\nFamiliar with LangChain, LangGraph, or similar toolkits\nPlus points if you have experience with Apple Ads (formerly ASA) or have worked in the AdTech space.\nEffective communication skills with the ability to convey technical concepts to non-technical audiences",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['algorithms', 'python', 'modeling', 'hypothesis testing', 'mathematics', 'forecasting', 'dl', 'predictive', 'problem solving', 'machine learning', 'sql', 'coding', 'data science', 'gcp', 'predictive modeling', 'design', 'reporting', 'statistics', 'communication skills', 'ml']",2025-06-10 15:35:12
Mega Walk In | TELUS Digital | Annotation Analyst | @Gandhinagar,TELUS International,0 - 2 years,2.5-3 Lacs P.A.,"['Gandhinagar', 'Ahmedabad']",Responsibilities:\nAnnotate and label datasets accurately using specialized tools and guidelines\nReview and correct existing annotations to ensure data quality\nCollaborate with machine learning engineers and data scientists to understand annotation requirements\nFollow detailed instructions and apply judgment to edge cases and ambiguous data\nMeet project deadlines and maintain high levels of accuracy and efficiency,,,,"['Fresher', 'Cad Software', 'Backend', 'Annotation Analyst', 'CAD', 'Back Office Operations', 'Aiml', 'Fresher Hiring', 'Data Annotation', 'Annotation', 'Freshers']",2025-06-10 15:35:14
AI/ML Engineering,Manufacturing company,0 - 1 years,Not Disclosed,['Bengaluru'],"Role & responsibilities :\n\n1. Data Handling\nCollect and clean data from machines, sensors, and production lines.\n\n2. Model Building\nSupport basic AI/ML model development for quality checks, defect detection, and maintenance prediction.\n\n3. PoC\nAssist in small projects to test AI ideas in real manufacturing settings.\n\n4. Collaboration\nWork with engineers and IT teams to understand problems and implement solutions.\n\nGood to know:\n\nInterest in manufacturing and automation.\n\nPreferred candidate profile\n\nInterested candidate kindly share me your CV at jeevabvr@gmail.com",Industry Type: Automobile (Automobile Dealers),"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Temporary/Contractual","['Predictive Maintenance', 'Artificial Intelligence', 'Machine Learning', 'Manufacturing Engineering', 'Robotics', 'Industrial Equipment', 'Computer Vision', 'Python']",2025-06-10 15:35:16
Data Scientist,Ltimindtree,6 - 11 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","We are looking for Data Scientist with GenAI solution & Python Development experience.\nExperience - 5+ Years\nLocation - Bangalore\nMandatory Skills - Data Science, Gen AI, Python, RAG. AI/ML, NLP, Azure, AWS.\n\nPFB JD\nResponsibilities:\nImplement and optimize AIML models and algorithms with a focus on Agentic AI and Retrieval Augmented Generation RAG\nImplement scalable machine learning models and algorithms to solve complex challenges\nResearch and integrate the latest AI tools and frameworks into existing systems\nStay uptodate with advancements in AIML research and apply them to practical problems\nExperiment with and implement Generative AI technologies across multiple domains\nLeverage cloud platforms like Google Cloud AWS and Azure for scalable AIML deployments\nUtilize opensource large language models LLMs such as LLama3 in AI application development\n\nKey Skills\nStrong understanding of Agentic AI concepts and applications\nHandson experience with RetrievalAugmented Generation RAG models\nExpertise in machine learning and deep learning frameworks eg TensorFlow PyTorch\nExperience with Large language models eg GPT4 LLama Azure OpenAI and integrating them into production systems\nProficiency in programming languages such as Python and familiarity with libraries like Hugging Face Transformers langchain and llama index\nExperience in building and deploying AIML solutions using cloud platforms Azure\nKnowledge of data retrieval natural language processing NLP and reinforcement learning techniques\nStrong problemsolving skills and ability to work in a fastpaced collaborative environment\nExperience with model optimization finetuning and inference strategies to improve system performance\n\nPreferred Skills\nExperience with advanced NLP tasks like text generation summarization and question answering familiarity with reinforcement learning algorithms and their application in intelligent agent design\nFamiliarity with containerization technologies eg Docker Kubernetes\nBackground in computer vision and image generation techniques",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Gen AI', 'Machine Learning']",2025-06-10 15:35:18
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"As an Data Engineer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You'll contribute to data gathering, storage, and both batch and real-time processing.\n\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\n\n In this role, your responsibilities may include: \nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviours’.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modelling results\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another\nDocument solution architectures, design decisions, implementation details, and lessons learned.\nStay up to date with the latest trends and advancements in AI, foundation models, and large language models.\nEvaluate emerging technologies, tools, and frameworks to assess their potential impact on solution design and implementation\n\n\nPreferred technical and professional experience\nExperience and working knowledge in COBOL & JAVA would be preferred\nHaving experience in Code generation, code matching & code translation leveraging LLM capabilities would be a Big plus\nDemonstrate a growth mindset to understand clients' business processes and challenges",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['elastic search', 'java', 'proof of concept', 'cobol', 'splunk', 'targetlink', 'simulink', 'data management', 'stateflow', 'sil', 'big data', 'can bus', 'matlab', 'python', 'c', 'predictive', 'machine learning', 'presales', 'autosar', 'code generation', 'rtw', 'rfi', 'embedded c', 'model based development', 'rfp']",2025-06-10 15:35:20
AI Solutions Engineer,Edwisely,0 - 3 years,Not Disclosed,['Hyderabad'],"Role Overview\nWere seeking an AI Solutions Engineer to lead the integration of GenAI tools such as ChatGPT or Claudeinto our core platform. Youll design, prototype, and deploy features that elevate student outcomes, make teaching exciting, and enrich dashboards with intelligent insights, all while upholding privacy and governance standards.\n\nKey Responsibilities\nDesign and build GenAI-powered features like guided study assistants, automated remediation engine, and intelligent feedback tools.\nDevelop end-to-end pipelines (prompt design model integration CI/CD deployment) that align with Edwiselys Intelligent Learning Infrastructure.\nCollaborate with product teams, faculty, and UX designers to deploy AI features in classrooms and dashboards.\nEnsure all AI implementations meet ISO 27001 security and CERT-In data protection guidelines.\nMeasure adoption and impact via analytics dashboardssupport evidence-based learning outcomes.\nWhat You’ll Bring\nStrong in prompt engineering, RAG, embeddings, or QA systems using frameworks like OpenAI API, LangChain, Hugging Face Transformers.\nFamiliarity with ML deployment—FastAPI, Docker, AWS/GCP—within production-grade applications.\nExperience with education data, knowledge graphs, student modeling, or assessment systems is a big plus.\nResults-driven: ability to turn prototypes into scalable features.\nPassionate about improving higher education with impactful, AI-driven solutions.\nWhy Edwisely?\nBe part of a high-impact EdTech startup, transforming learning journeys of engineering students nationwide.\nWork with a product that uses AI + analytics to personalize learning, support faculty, and guide institutional decisions .\nCareer growth: define your ownership—architecture, implementation, or research-led product development.\nCompetitive package, fast-paced work culture, and freedom to drive real-world impact.\nApplication Process\nSubmit your CV + GitHub or project links (especially showcasing GenAI integrations or NLP projects). @ satish@edwisely.com\nTechnical interview focusing on applied AI scenarios (prompt design, architecture, pipelines).\nWork sample task: prototype an AI feature for Edwisely",Industry Type: E-Learning / EdTech,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Large Language Models', 'API Design & Integration', 'AI/ML Pipeline Development', 'Vector Databases & Embeddings', 'Model Evaluation & Optimization', 'Web Scraping & Data Transformation', 'Product Thinking & Collaboration', 'Natural Language Processing', 'Python']",2025-06-10 15:35:22
Data Scientist,Evnek,2 - 3 years,Not Disclosed,['Bengaluru'],"Job Title: Data Scientist OpenCV\nExperience: 23 Years\nLocation: Bangalore\nNotice Period: Immediate JoinersOnly\n\nJob Overview\nWe are looking for a passionate and driven Data Scientistwith a strong foundation in computer vision, image processing, and OpenCV. Thisrole is ideal for professionals with 23 years of experience who are excitedabout working on real-world visual data problems and eager to contribute toimpactful projects in a collaborative environment.\nKey Responsibilities\nDevelop and implement computer vision solutionsusing OpenCV and Python.\nWork on tasks including object detection,recognition, tracking, and image/video enhancement.\nClean, preprocess, and analyze large image andvideo datasets to extract actionable insights.\nCollaborate with senior data scientists andengineers to deploy models into production pipelines.\nContribute to research and proof-of-conceptprojects in the field of computer vision and machine learning.\nPrepare clear documentation for models,experiments, and technical processes.\nRequired Skills\nProficient in OpenCV and image/video processingtechniques.\nStrong coding skills in Python, with familiarityin libraries such as NumPy, Pandas, Matplotlib.\nSolid understanding of basic machine learningand deep learning concepts.\nHands-on experience with Jupyter Notebooks;exposure to TensorFlow or PyTorch is a plus.\nExcellent analytical, problem-solving, anddebugging skills.\nEffective communication and collaborationabilities.\n  Preferred Qualifications\nBachelor\\u2019s degree in computer science, DataScience, Electrical Engineering, or a related field.\nPractical exposure through internships oracademic projects in computer vision or image analysis.\nFamiliarity with cloud platforms (AWS, GCP,Azure) is an added advantage.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Electrical engineering', 'Computer vision', 'deep learning', 'data science', 'Coding', 'Opencv', 'Analytical', 'Machine learning', 'Debugging', 'Python']",2025-06-10 15:35:25
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"An AI Data Scientist at IBM is not just a job title - it’s a mindset. You’ll leverage the watsonx,AWS Sagemaker,Azure Open AI platform to co-create AI value with clients, focusing on technology patterns to enhance repeatability and delight clients.\n\nWe are seeking an experienced and innovative AI Data Scientist to be specialized in foundation models and large language models. In this role, you will be responsible for architecting and delivering AI solutions using cutting-edge technologies, with a strong focus on foundation models and large language models. You will work closely with customers, product managers, and development teams to understand business requirements and design custom AI solutions that address complex challenges. Experience with tools like Github Copilot, Amazon Code Whisperer etc. is desirable.\n\nSuccess is our passion, and your accomplishments will reflect this, driving your career forward, propelling your team to success, and helping our clients to thrive.\n\nDay-to-Day Duties:\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions. Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\nDocumentation and Knowledge SharingDocument solution architectures, design decisions, implementation details, and lessons learned. Create technical documentation, white papers, and best practice guides. Contribute to internal knowledge sharing initiatives and mentor new team members.\nIndustry Trends and InnovationStay up to date with the latest trends and advancements in AI, foundation models, and large language models. Evaluate emerging technologies, tools, and frameworks to assess their potential impact on solution design and implementation\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nStrong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face. Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms (e.g. Kubernetes, AWS, Azure, GCP) and related services is a plus.\nExperience and working knowledge in COBOL & JAVA would be preferred\no Having experience in Code generation, code matching & code translation leveraging LLM capabilities would be a Big plus (e.g. Amazon Code Whisperer, Github Copilot etc.) Soft\n\nSkills:\nExcellent interpersonal and communication skills. Engage with stakeholders for analysis and implementation. Commitment to continuous learning and staying updated with advancements in the field of AI.\nGrowth mindsetDemonstrate a growth mindset to understand clients' business processes and challenges.\nExperience in python and pyspark will be added advantage\n\n\nPreferred technical and professional experience\nExperienceProven experience in designing and delivering AI solutions, with a focus on foundation models, large language models, exposure to open source, or similar technologies. Experience in natural language processing (NLP) and text analytics is highly desirable. Understanding of machine learning and deep learning algorithms.\nStrong track record in scientific publications or open-source communities\nExperience in full AI project lifecycle, from research and prototyping to deployment in production environments",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'keras', 'kubernetes', 'github', 'natural language processing', 'scikit-learn', 'pyspark', 'microsoft azure', 'artificial intelligence', 'text analytics', 'pandas', 'deep learning', 'java', 'code generation', 'cobol', 'gcp', 'matplotlib', 'aws']",2025-06-10 15:35:28
Lead Engineering - ML || Bharti Airtel || gurgaon,Airtel,5 - 10 years,Not Disclosed,['Gurugram'],"Engineer ML\nAbout the role\nThe mission of the team is to transform terabytes of data into robust models for improving Network Experience and Customer Experience and reducing Operational Expenditure.\nCandidate will be required to understand the different Datasets being supplied from different sources and design a production grade big data architecture for Reporting and Analytics Platform. He will be involved in developing in-house algorithms as per Business Requirements. He will also be involved in vendor reviews of solution designs and related code on the principle of adherence to high-quality development principles while delivering solutions on time and on budget.\nKey Responsibilities\nDevelop best quality software design and Big Data architecture for a Product that is being migrated to Big Data Platform from MYSQL based architecture.\nThis product is spread across dimensions of big data, analytics, machine learning, graph problems, etc.\nThe person is responsible to design and develop systems that use machine learning, or AI, to build models that can automate processes. They use data to create models, perform statistical analysis, and train systems to improve performance.\nIdentify, prioritize and execute tasks in the software development life cycle.\nDevelop tools and applications by producing clean, efficient code, automate tasks through appropriate tools and scripting.\nReview and debug code and perform validation and verification testing\nCollaborate with internal teams and external vendors to fix and improve current Architecture that helps to improve software development process and team productivity.\nDocument development phases and monitor systems. Guide daily DevOps and ensure timely hardware expansions or architecture revamp.\nProvide statistical analysis to develop, test, and optimize databases to their full potential.\nEnsure software is up-to-date with latest technologies.\nReview Vendor Codes and solution designs for on-time deployment.\nExperience & Skills\nMust have experience in Machine Learning and experience in machine learning frameworks like TensorFlow or PyTorch.\nKnowledge of selected programming languages (e.g. Python, JAVA, Scala Python, C++)\nIn-depth knowledge of relational databases (e.g. PostgreSQL, MySQL) and NoSQL databases (e.g. MongoDB or Hadoop)\nHands-on experience working with Big Data technologies like Hadoop, MongodB, Hive, Pig, Oozie, Map Reduce, Spark, Sqoop, Kafka, Flume, etc.\nExtensive experience in software design, development and scripting.\nExperience with real-time streaming tools like Apache Kafka and NiFi is a plus.\nHas hands-on experience working with large volumes of data including different patterns of data ingestion, processing (batch & real-time), movement, storage and access (for both internal and external to BU) and is able to make independent decisions within scope of project. ( Spark, Kafka, Kstream/Flink)\nVery strong analytical skills with the demonstrated ability to research & make decisions based on the day-to-day and complex customer problems\nUnderstanding of HTTP and RESTful web services is a plus\nExperience with version control tools (SVN or Git).\nEducational Qualifications: Bachelor's or Master's Degree in Computer Science or related field; or equivalent related professional experience\nWork Experience: 1-7 years of total experience preferably in Big Data",Industry Type: Telecom / ISP,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'Python', 'Pyspark', 'Artificial Intelligence', 'Big Data', 'Hypothesis Testing', 'Deep Learning', 'SQL', 'Pytorch', 'Machine Learning Algorithms', 'TensorFlow', 'ML']",2025-06-10 15:35:30
Data Scientist-MLOps/LLMOps,IBM,3 - 6 years,Not Disclosed,['Mumbai'],"Role Overview :\nHiring an ML Engineer with experience in Cloudera ML to support end-to-end model development, deployment, and monitoring on the CDP platform.\n\n Key Responsibilities :\nDevelop and deploy models using CML workspaces\nBuild CI/CD pipelines for ML lifecycle\nIntegrate with governance and monitoring tools\nEnable secure model serving via REST APIs\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\n\n Skills Required :\nExperience in Cloudera ML, Spark MLlib, or scikit-learn\nML pipeline automation (MLflow, Airflow, or equivalent)\nModel governance, lineage, and versioning\nAPI exposure for real-time inference",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'rest', 'scikit-learn', 'ci/cd', 'ml', 'cloudera', 'python', 'deploying models', 'natural language processing', 'airflow', 'neural networks', 'machine learning', 'sql', 'deep learning', 'tensorflow', 'data science', 'spark', 'spark mllib', 'model development', 'keras']",2025-06-10 15:35:33
Data Scientist,Qua Xigma IT Solutions Pvt Ltd,2 - 7 years,Not Disclosed,['Tirupati'],"Position Overview:\nWe are seeking a collaborative and analytical Data Scientist who can bridge the gap between business needs and data science capabilities. In this role, you will lead and support projects that apply machine learning, AI, and statistical modeling to generate actionable insights and drive business value.\n\nKey Responsibilities:\nCollaborate with stakeholders to define and translate business challenges into data science solutions.\nConduct in-depth data analysis on structured and unstructured datasets.\nBuild, validate, and deploy machine learning models to solve real-world problems.\nDevelop clear visualizations and presentations to communicate insights.\nDrive end-to-end project delivery, from exploration to production.\nContribute to team knowledge sharing and mentorship activities.\n\nMust-Have Skills:\n3+ years of progressive experience in data science, applied analytics, or a related quantitative role, demonstrating a proven track record of delivering impactful data-driven solutions.\nExceptional programming proficiency in Python, including extensive experience with core libraries such as Pandas, NumPy, Scikit-learn, NLTK and XGBoost.\nExpert-level SQL skills for complex data extraction, transformation, and analysis from various relational databases.\nDeep understanding and practical application of statistical modeling and machine learning techniques, including but not limited to regression, classification, clustering, time series analysis, and dimensionality reduction.\nProven expertise in end-to-end machine learning model development lifecycle, including robust feature engineering, rigorous model validation and evaluation (e.g., A/B testing), and model deployment strategies.\nDemonstrated ability to translate complex business problems into actionable analytical frameworks and data science solutions, driving measurable business outcomes.\nProficiency in advanced data analysis techniques, including Exploratory Data Analysis (EDA), customer segmentation (e.g., RFM analysis), and cohort analysis, to uncover actionable insights.\nExperience in designing and implementing data models, including logical and physical data modeling, and developing source-to-target mappings for robust data pipelines.\nExceptional communication skills, with the ability to clearly articulate complex technical findings, methodologies, and recommendations to diverse business stakeholders (both technical and non-technical audiences).\nExperience in designing and implementing data models, including logical and physical data modeling, and developing source-to-target mappings for robust data pipelines.\nExceptional communication skills, with the ability to clearly articulate complex technical findings, methodologies, and recommendations to diverse business stakeholders (both technical and non-technical audiences).\n\nGood-to-Have Skills:\nExperience with cloud platforms (Azure, AWS, GCP) and specific services like Azure ML, Synapse, Azure Kubernetes and Databricks.\nFamiliarity with big data processing tools like Apache Spark or Hadoop.\nExposure to MLOps tools and practices (e.g., MLflow, Docker, Kubeflow) for model lifecycle management.\nKnowledge of deep learning libraries (TensorFlow, PyTorch) or experience with Generative AI (GenAI) and Large Language Models (LLMs).\nProficiency with business intelligence and data visualization tools such as Tableau, Power BI, or Plotly.\nExperience working within Agile project delivery methodologies.\n\nCompetencies:\nTech Savvy - Anticipating and adopting innovations in business-building digital and technology applications.\nSelf-Development - Actively seeking new ways to grow and be challenged using both formal and informal development channels.\nAction Oriented - Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasm.\nCustomer Focus - Building strong customer relationships and delivering customer-centric solutions.\nOptimizes Work Processes - Knowing the most effective and efficient processes to get things done, with a focus on continuous improvement.\n\nWhy Join Us?\nBe part of a collaborative and agile team driving cutting-edge AI and data engineering solutions.\nWork on impactful projects that make a difference across industries.\nOpportunities for professional growth and continuous learning.\nCompetitive salary and benefits package.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Python', 'SQL', 'End-to-End ML Development', 'Data Analysis', 'Data Modeling & ETL']",2025-06-10 15:35:35
Opportunity | Gen AI Architect | Tavant India,Tavant Technologies,12 - 22 years,Not Disclosed,"['Noida', 'Hyderabad/Secunderabad', 'Bangalore/Bengaluru']","Dear candidate,\n\nWe found your profile suitable for our current opening, please go through the below JD for better understanding of the role,\n\nJob Description :\nRole : Lead Data Scientist / TA\nExp : 12 - 20 years\nMode of work : Hybrid Model (3daya WFO)\nWork Location : Hyderabad/Bangalore/Noida/Pune/Kolkata\nJob Description:\nWe are looking for a highly experienced Lead Data Scientist / ML Engineer to drive innovation in Generative AI (GenAI), search technologies, recommendation engines, and agentic AI systems. This role demands both technical excellence and strategic vision, combining deep hands-on expertise in AI/ML with proven leadership in building and scaling data science teams.\nKey Responsibilities:\n1. Technical & Strategic Leadership\nDefine and execute AI strategies aligned with business goals.\nLead and mentor a high-performing team of data scientists and ML engineers.\nDrive architectural decisions and innovation in AI-powered products.\n2. Generative & Agentic AI\nBuild and deploy GenAI models for text generation and content automation.\nDevelop agentic AI systems with autonomous task planning and decision-making capabilities.\nApply latest deep learning advancements (transformers, diffusion models, etc.) to real-world use cases.\n3. Search & Recommendation Systems\nDesign scalable, high-performance search and recommendation platforms.\nImplement ML models for ranking, personalization, and relevance optimization.\nLeverage real-time feedback loops and experimentation (A/B testing).\n4. Large Language Models (LLMs)\nFine-tune and operationalize LLMs (e.g., GPT, BERT) for NLP tasks.\nWork closely with product teams to integrate LLMs into applications.\nEstablish best practices for LLMOps, including prompt engineering and monitoring.\n5. Machine Learning Engineering & MLOps\nBuild robust ML pipelines for model development, deployment, and monitoring.\nImplement MLOps using CI/CD, Docker, Kubernetes, and cloud platforms (AWS/GCP/Azure).\nEnsure responsible AI practices and data governance compliance.\n6. Collaboration & Stakeholder Engagement\nTranslate business needs into ML solutions in partnership with product and engineering teams.\nCommunicate insights and recommendations to stakeholders across levels.\nPromote a culture of data-driven decision-making.\n7. Research & Innovation\nStay updated on the latest in AI/ML and contribute to R&D efforts.\nEncourage experimentation, POCs, and technical publications.\nRequired Qualifications:\nMasters or PhD in Computer Science, AI, Data Science, or related field.\n12+ years of experience in data science/ML, with 5+ years in leadership roles.\nStrong experience in:\nGenerative AI (e.g., GANs, VAEs, transformer models)\nSearch & Recommendation Systems\nLLMs & NLP using frameworks like Hugging Face, TensorFlow, PyTorch\nAgentic AI and autonomous systems\nML Engineering & MLOps\nLeadership skills with proven success in managing cross-functional teams.\nStrong communication and stakeholder management abilities.\nPreferred Skills:\nExperience with big data tools (Spark, Hadoop, Kafka).\nDevOps tools: Jenkins, GitLab CI, Terraform.\nExposure to edge computing and distributed systems.\nContributions to open-source AI/ML projects or research publications.\n\nPlease check below link for organisation details https://www.tavant.com/\nIf interested , please drop your resume to dasari.gowri@tavant.com\nRegards\nDasari Krishna Gowri\nAssociate Manager - HR\nwww.tavant.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Gen AI', 'Search Engine', 'LLM', 'Recommendation', 'Natural Language Processing', 'Machine Learning']",2025-06-10 15:35:38
Architect - GCP,Rackspace Technology,8 - 12 years,Not Disclosed,[],"About the Role:\n\nWe are looking for a seasoned Machine Learning Operations (MLOPs) Architect to build, and optimize ML inference platform. The role demands an individual with significant expertise in Machine Learning engineering and infrastructure, with an emphasis on building Machine Learning inference systems. Proven experience in building and scaling ML inference platforms in a production environment is crucial. This remote position calls for exceptional communication skills and a knack for independently tackling complex challenges with innovative solutions.",,,,"['Computer science', 'deep learning', 'GCP', 'Machine learning', 'Manager Technology', 'Data structures', 'Natural language processing', 'Apache', 'rackspace', 'Distribution system']",2025-06-10 15:35:40
Sr Dev Ops Engineer(AI/ML),Morningstar,5 - 9 years,Not Disclosed,['Navi Mumbai'],"Job Overview\n\nAs a Senior Dev ops Engineer, Machine Learning (ML) Operations in the Technology & Engineering division, you will be responsible for enabling PitchBook's Machine Learning teams and practitioners by providing tools that optimize all aspects of the Machine Learning Development Life Cycle (MLDLC). Your work will support projects in a variety of domains, including Generative AI (GenAI), Large Language Models (LLMs), Natural Language Processing (NLP), Classification, and Regression.\n\nTeam Overview\nYour teams goal will be to reduce friction and time-to-business-value for teams building Artificial Intelligence (AI) solutions at PitchBook. You will be essential in helping to build exceptional AI solutions relied upon and used by thousands of PitchBook customers every day. You will work with PitchBook professionals around the world with the collective goal of delighting our customers and growing our business.\n\nWhile demonstrating a growth mindset, you will be expected to continuously develop your expertise in a way that enhances PitchBooks AI capabilities in a scalable and repeatable manner. You will be able to solve various common challenges faced in the MLDLC while providing technical guidance to less experienced peers.\n\nOutline of Duties and Responsibilities\nServe as a force multiplier for development teams by creating golden paths that remove roadblocks and improve ideation and innovation.\nCollaborate with other engineers, product managers, and internal stakeholders in an Agile environment.\nProvide mentorship, technical guidance, and perform code reviews for team members.\nDesign and deliver on projects end-to-end with little to no guidance.\nProvide support to teams building and deploying AI applications by addressing common pain points in the MLDLC.\nLearn constantly and be passionate about discovering new tools, technologies, libraries, and frameworks (commercial and open source), that can be leveraged to improve PitchBooks AI capabilities.\nSupport the vision and values of the company through role modeling and encouraging desired behaviors.\nParticipate in various cross-functional company initiatives and projects as requested.\nContribute to strategic planning in a way that ensures the team is building exceptional products that bring real business value.\nEvaluate frameworks, vendors, and tools that can be used to optimize processes and costs with minimal guidance.\n\nExperience, Skills and Qualifications\nDegree in Computer Science, Information Systems, Machine Learning, or a similar field preferred (or commensurate experience).\n5+ years of experience in hands-on development of Machine Learning algorithms.\n5+ years of experience in hands-on deployment of Machine Learning services\n5+ years of experience supporting the entire MLDLC, including post-deployment operations such as monitoring and maintenance\n5+ years of experience with Amazon Web Services (AWS) and/or Google Cloud Platform (GCP)\nExperience with at least 80%: PyTorch, Tensorflow, LangChain, scikit-learn, Redis, Elasticsearch, Amazon SageMaker, Google Vertex AI, Weights & Biases, FastAPI, Prometheus, Grafana, Apache Kafka, Apache Airflow, MLflow, KubeFlow\nAbility to break large, complex problems into well-defined steps, ensuring iterative development and continuous improvement\nExperience in cloud-native delivery, with a deep practical understanding of containerization technologies such as Kubernetes and Docker, and the ability to manage these across different regions.\nProficiency in Git Ops and creation/management of CI/CD pipelines.\nDemonstrated experience building and using SQL/NoSQL databases.\nDemonstrated experience with Python (Java is a plus) and other relevant programming languages and tools.\nExcellent problem-solving skills with a focus on innovation, efficiency, and scalability in a global context.\nStrong communication and collaboration skills, with the ability to engage effectively with internal customers across various cultures and regions.\nAbility to be a team player who can also work independently.\nExperience working across multiple development teams is a plus.\n\nMorningstar is an equal opportunity employer.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Tensorflow', 'Pytorch', 'ml ops', 'Machine Learning', 'Scikit-Learn']",2025-06-10 15:35:43
Solutions Architect Cloud AI,"NTT DATA, Inc.",8 - 12 years,Not Disclosed,"['Chennai', 'Delhi / NCR', 'Bengaluru']","Your day at NTT DATA\nWe are seeking an exceptional Solution Architect/BDM specializing in Hyperscalers. This role requires deep expertise in cloud-based AI services and Large Language Models (LLMs) offered by major cloud providers. As our Cloud AI SME, you will assess client needs, recommend appropriate cloud AI technologies, size opportunities and cloud infrastructure requirements, and collaborate with delivery teams to create end-to-end solutions with accurate costing. This pivotal role demands a strategic thinker with strong technical knowledge and business acumen who can drive innovation and deliver exceptional value to our clients through cloud-based AI solutions.\nWhat you'll be doing\nKey Roles and Responsibilities:\nSolution Architecture & Technical Leadership\nDemonstrate deep expertise in cloud-based AI services and LLMs such as AWS Bedrock, Azure OpenAI Service, Google Vertex AI, and their supported models\nAssess client business requirements and translate them into detailed technical specifications leveraging hyperscaler AI capabilities\nRecommend appropriate cloud AI solutions based on specific business outcomes and use cases\nSize cloud infrastructure requirements and optimize cost models for AI workloads\nDesign scalable and secure Private AI architectures\nCreate technical POCs and prototypes on hyperscaler platforms to demonstrate solution capabilities\nExpertise in fine-tuning, query caching, and optimizing vector embeddings for efficient similarity searches\nBusiness Development\nSize and qualify opportunities in the Cloud AI space\nDevelop compelling proposals and solution presentations for cloud-based AI implementations\nBuild and nurture client relationships at technical and executive levels\nCollaborate with sales teams to create competitive go-to-market strategies\nIdentify new business opportunities through technical consultation on cloud AI solutions\nProject & Delivery Leadership\nWork with delivery teams to develop end-to-end solution approaches and accurate costing\nLead technical discovery sessions with clients\nGuide implementation teams during solution delivery\nEnsure technical solutions meet client requirements and business outcomes\nDevelop reusable solution components and frameworks to accelerate delivery\nAI Agent Development\nArchitect multi-agent systems that leverage cloud platform capabilities\nDevelop frameworks for agent orchestration, evaluation, and governance on cloud platforms\nDesign cloud-native agent solutions that integrate with existing enterprise systems\nImplement agent-based solutions using Cloud tools and services\n\n\nKnowledge, Skills, and Attributes:\nBasic Qualifications:\n8+ years of experience in solution architecture or technical consulting roles\n3+ years of specialized experience working with LLMs and Private AI solutions\nDemonstrated expertise with AWS or Azure or GCP AI/ML services\nStrong understanding of cloud infrastructure sizing, optimization, and cost management for AI workloads\nProven experience converting business requirements into technical specifications\nExperience working with delivery teams to create end-to-end solutions with accurate costing\nStrong understanding of agentic AI systems and orchestration frameworks\nBachelors degree in computer science, AI, or related field\nAbility to travel up to 25%\nPreferred Qualifications:\nMaster's degree or PhD in Computer Science or related technical field.\nCloud certifications such as:\nAWS: AWS Certified Solutions Architect, AWS Certified Machine Learning Specialty\nAzure: Microsoft Certified: Azure Solutions Architect Expert, Azure AI Engineer Associate\nGCP: Google Cloud Professional Cloud Architect, Professional Machine Learning Engineer\nExperience with autonomous agent development using cloud-based AI services\nExperience with deploying and fine-tuning LLMs on cloud platforms\nHands-on experience with prompt engineering and LLM optimization techniques\nUnderstanding of AI governance, security, and compliance requirements\nPrior experience in business development or pre-sales for AI solutions\nExcellent verbal and written communication skills, with the ability to explain complex technical concepts to non-technical stakeholders\nStrong problem-solving abilities and analytical mindset.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Solutions Architecture', 'Azure', 'GCP', 'Artificial Intelligence', 'cloud infrastructure', 'Technical Leadership', 'AWS', 'Machine Learning']",2025-06-10 15:35:46
Data Scientist,Dwplacesolutions,3 - 5 years,Not Disclosed,['Bengaluru'],We are seeking an experienced Data Scientist to join our team.\nThe ideal candidate will have a strong background in developing and deploying\nconversational AI solutions using Large Language Models (LLMs) and RASA\nframework.,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Machine Learning', 'Tensorflow', 'R', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Chatbot', 'Deep Learning', 'Python']",2025-06-10 15:35:48
Data Scientist I,Affle,1 - 5 years,Not Disclosed,"['Mumbai', 'Gurugram', 'Bengaluru']","We are seeking a talented and motivated Data Scientist with 1-3 years of experience to join our Data Science team. If you have a strong passion for data science, expertise in machine learning, and experience working with large-scale datasets, we want to hear from you.\nAs a Data Scientist at RevX, you will play a crucial role in developing and implementing machine learning models to drive business impact. You will work closely with teams across data science, engineering, product, and campaign management to build predictive models, optimize algorithms, and deliver actionable insights. Your work will directly influence business strategy, product development, and campaign optimization.\n\nMajor Responsibilities:\nDevelop and implement machine learning models, particularly neural networks, decision trees, random forests, and XGBoost, to solve complex business problems.\nWork on deep learning models and other advanced techniques to enhance predictive accuracy and model performance.\nAnalyze and interpret large, complex datasets using Python, SQL, and big data technologies to derive meaningful insights.\nCollaborate with cross-functional teams to design, build, and deploy end-to-end data science solutions, including data pipelines and model deployment frameworks.\nUtilize advanced statistical techniques and machine learning methodologies to optimize business strategies and outcomes.\nEvaluate and improve model performance, calibration, and deployment strategies for real-time applications.\nPerform clustering, segmentation, and other unsupervised learning techniques to discover patterns in large datasets.\nConduct A/B testing and other experimental designs to validate model performance and business strategies.\nCreate and maintain data visualizations and dashboards using tools such as matplotlib, seaborn, Grafana, and Looker to communicate findings.\nProvide technical expertise in handling big data, data warehousing, and cloud-based platforms like Google Cloud Platform (GCP).\n\nRequired Experience/Skills:\nBachelors or Masters degree in Data Science, Computer Science, Statistics,\nMathematics, or a related field.\n1-3 years of experience in data science or machine learning roles.\nStrong proficiency in Python for machine learning, data analysis, and deep learning applications.\nExperience in developing, deploying, and monitoring machine learning models, particularly neural networks, and other advanced algorithms.\nExpertise in handling big data technologies, with experience in tools such as BigQuery and cloud platforms (GCP preferred).\nAdvanced SQL skills for data querying and manipulation from large datasets.\nExperience in data visualization tools like matplotlib, seaborn, Grafana, and Looker.\nStrong understanding of A/B testing, statistical tests, experimental design, and methodologies.\nExperience in clustering, segmentation, and other unsupervised learning techniques.\nStrong problem-solving skills and the ability to work with complex datasets and machine learning pipelines.\nExcellent communication skills, with the ability to explain complex technical concepts to non-technical stakeholders.\n\nPreferred Skills:\nExperience with deep learning frameworks such as TensorFlow or PyTorch.\nFamiliarity with data warehousing concepts and big data tools.\nKnowledge of MLOps practices, including model deployment, monitoring, and management.\nExperience with business intelligence tools and creating data-driven dashboards.\nUnderstanding of reinforcement learning, natural language processing (NLP), or other advanced AI techniques.\n  Education:\nBachelor of Engineering or similar degree from any reputed University.",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['advance sql', 'python', 'data analysis', 'big data technologies', 'data warehousing', 'random forest', 'machine learning', 'sql', 'deep learning', 'ab testing', 'tensorflow', 'seaborn', 'data science', 'grafana', 'gcp', 'design', 'matplotlib', 'pytorch', 'bigquery', 'big data', 'xgboost', 'communication skills']",2025-06-10 15:35:50
AI / ML Engineer,Accenture,15 - 20 years,Not Disclosed,['Pune'],"Project Role :AI / ML Engineer\n\n\n\nProject Role Description :Develops applications and systems that utilize AI tools, Cloud AI services, with proper cloud or on-prem application pipeline with production ready quality. Be able to apply GenAI models as part of the solution. Could also include but not limited to deep learning, neural networks, chatbots, image processing.\n\nMust have skills :Large Language Models\n\n\nGood to have skills :NAMinimum\n\n2 year(s) of experience is required\n\n\nEducational Qualification :15 years full time education\nSummary:As an AI / ML Engineer, you will engage in the development of applications and systems that leverage artificial intelligence tools and cloud AI services. Your typical day will involve collaborating with cross-functional teams to design and implement production-ready solutions, ensuring that the applications meet high-quality standards. You will also explore the integration of generative AI models into various projects, contributing to innovative solutions that enhance user experiences and operational efficiency. Your role will require a blend of technical expertise and creative problem-solving to address complex challenges in the field of artificial intelligence and machine learning.\nRoles & Responsibilities:- Expected to perform independently and become an SME.- Required active participation/contribution in team discussions.- Contribute in providing solutions to work related problems.- Assist in the design and implementation of AI-driven applications and systems.- Collaborate with team members to troubleshoot and resolve technical issues.\nProfessional & Technical\n\n\nSkills:\n- Must To Have\n\n\nSkills:\nProficiency in Large Language Models.- Good To Have\n\n\nSkills:\nExperience with cloud-based AI services.- Strong understanding of deep learning frameworks such as TensorFlow or PyTorch.- Familiarity with natural language processing techniques and tools.- Experience in developing and deploying chatbots and conversational agents.\nAdditional Information:- The candidate should have minimum 2 years of experience in Large Language Models.- This position is based at our Pune office.- A 15 years full time education is required.\n\nQualification\n\n15 years full time education",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['deep learning frameworks', 'machine learning', 'artificial intelligence', 'tensorflow', 'pytorch', 'image processing', 'chatbot', 'python', 'cnn', 'natural language processing', 'neural networks', 'numpy', 'sql', 'pandas', 'deep learning', 'r', 'rnn', 'data science', 'matplotlib', 'keras', 'text mining', 'ml']",2025-06-10 15:35:53
"Director, Data Engineering (AI/ML, GenAI, Spark, Java)",Visa,10 - 15 years,Not Disclosed,['Bengaluru'],"Payments Industry is a very exciting and fast-developing area with lot of new and innovative solutions coming to market. With strong demand for new solutions in this space, it promises to be an exciting area of innovation. VISA is a strong leader in the payment industry and is rapidly transitioning into a technology company with significant investments in this area.\nIf you want to be in the exciting payment space, learn fast and make big impacts, Ecosystem & Operational Risk technology which is part of Visa s Value-Added Services business unit is an ideal place for you!\n\nIn Ecosystem & Operational Risk (EOR) technology group, the Payment Fraud Disruption team is responsible for building critical risk and fraud detection and prevention applications and services at Visa. This includes idea generation, architecture, design, development, and testing of products, applications, and services that provide Visa clients with solutions to detect, prevent, and mitigate fraud for Visa and Visa client payment systems.\nWe are in search of inquisitive, creative, and skillful technologists to join our ranks. We are currently looking for a Director of Software Engineering who will take the lead and manage several strategic initiatives within our organization.\nThe right candidate will possess strong software engineering background, with demonstrated leadership experience in driving technical architecture, design and delivery of products and services that have created business value and delivered impact within the payments or payments risk domain or similar industries.\nThis position is ideal for an experienced engineering leader who is passionate about collaborating with business and technology partners and engineers to solve challenging business problems. You will be a key driver in the effort to define the shared strategic vision for the Payment Fraud Disruption platform and defining tools and services that safeguard Visa s payment systems.\nThis is a hybrid position. Expectation of days in office will be confirmed by your Hiring Manager.\n\n\nBasic Qualifications\n10+ years of relevant work experience and a Bachelors degree, OR 13+ years of relevant work experience\n\nPreferred Qualifications\n12 or more years of work experience with a Bachelor s Degree or 8-10 years of experience with an Advanced Degree (e.g. Masters, MBA, JD, MD) or 6+ years of work experience with a PhD\nExperience leading delivery and deployment of ML models, model refresh, and experimentation.\nExperience leading product development & delivery of AI/ML solutions, applied to real-world problems\nExperience leading design and development of mission-critical, secure, reliable systems\nExperience leading delivery across multiple technologies: Python, Java/J2EE, Apache Kafka, Apache Flink, Hive, MySQL, Hadoop, Spark, Scala, design patterns, test automation frameworks\nExperience leading delivery of streaming analytics platforms\nExcellent understanding of algorithms and data structures\nExcellent problem solving and analytics skills. Capable of forming and advocating an independent viewpoint\nStrong experience with agile methodologies\nExcel in partnering with Product leaders and technical product managers on requirements workshops, helping define joint product/technology roadmaps & driving prioritization\nExperience driving continuous improvements to processes/tools for better developer efficiency and productivity\nDemonstrated ability to drive measurable improvements across engineering, delivery and performance metrics\nDemonstrated success in leading high performing, multi-disciplinary and geographically distributed engineering teams. Demonstrated ability to hire, develop and retain high-caliber talent\nMust demonstrate longer-term strategic thinking and staying abreast with latest technologies to assess what s possible technically\nStrong collaboration and effective communication, with focus on win-win outcomes",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Payment systems', 'Operational risk', 'MySQL', 'SCALA', 'Agile', 'Manager Technology', 'Data structures', 'Apache', 'Analytics', 'Python']",2025-06-10 15:35:55
AI Engineer,IBM,1 - 5 years,Not Disclosed,['Bengaluru'],"An AI Engineer at IBM is not just a job title - it's a mindset. You'll leverage the watsonx platform to co-create AI value with clients, focusing on technology patterns to enhance repeatability and delight clients.\nSuccess is our passion, and your accomplishments will reflect this, driving your career forward, propelling your team to success, and helping our clients to thrive.\n\n Day-to-Day Duties: \n\n  \n\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions. Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\n\nCollaboration and Project ManagementCollaborate with cross-functional teams, including data scientists, software engineers, and project managers, to ensure smooth execution and successful delivery of AI solutions. Effectively communicate project progress, risks, and dependencies to stakeholders.\n\nCustomer Engagement and SupportAct as a technical point of contact for customers, addressing their questions, concerns, and feedback. Provide technical support during the solution deployment phase and offer guidance on AI-related best practices and use cases.\n\nDocumentation and Knowledge SharingDocument solution architectures, design decisions, implementation details, and lessons learned. Create technical documentation, white papers, and best practice guides. Contribute to internal knowledge sharing initiatives and mentor new team members.\n\nIndustry Trends and InnovationStay up to date with the latest trends and advancements in AI, foundation models, and large language models. Evaluate emerging technologies, tools, and frameworks to assess their potential impact on solution design and implementation.\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nEducationBachelor's, Master's, or Ph.D. degree in Computer Science, Artificial Intelligence, Data Science or a related field.\nTechnical\n\nSkills:\nStrong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face. Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms (e.g. Kubernetes, AWS, Azure, GCP) and related services is a plus.\nSoft\n\nSkills:\nExcellent interpersonal and communication skills. Engage with stakeholders for analysis and implementation. Commitment to continuous learning and staying updated with advancements in the field of AI.\n\nGrowth mindsetDemonstrate a growth mindset to understand clients' business processes and challenges.\n\n\nPreferred technical and professional experience\nExperienceProven experience in designing and delivering AI solutions, with a focus on foundation models, large language models, exposure to open source, or similar technologies. Experience in natural language processing (NLP) and text analytics is highly desirable. Understanding of machine learning and deep learning algorithms.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'keras', 'kubernetes', 'algorithms', 'natural language processing', 'scikit-learn', 'microsoft azure', 'cloud platforms', 'artificial intelligence', 'text analytics', 'pandas', 'deep learning', 'data science', 'gcp', 'matplotlib', 'aws']",2025-06-10 15:35:57
Ml Engineer,Solix Technologies,5 - 10 years,15-25 Lacs P.A.,['Hyderabad'],"Solix Technologies Inc. is a leading provider of big data applications for enterprise archiving, data privacy, and advanced analytics. We are on a mission to help organizations manage and leverage their data for maximum value, efficiency, and compliance.\nJob Summary:\nWe are seeking a highly skilled and motivated Machine Learning Engineer with hands-on experience in Natural Language Processing (NLP) and Large Language Models (LLMs). You will play a key role in designing, developing, and deploying scalable ML/NLP solutions that drive intelligent automation and data insight across our platforms.\nKey Responsibilities:\nDesign and develop machine learning models, particularly in the domain of NLP and LLMs.\nFine-tune, evaluate, and deploy transformer-based models (e.g., BERT, GPT, T5, LLaMA, etc.).\nApply techniques such as named entity recognition (NER), text classification, semantic search, summarization, and question answering.\nWork with large-scale datasets to extract insights and build data pipelines.\nCollaborate with cross-functional teams including data engineers, product managers, and software developers.\nConduct experiments, model training, and optimization to improve accuracy and performance.\nStay up-to-date with the latest research in NLP, LLMs, and machine learning.\nRequired Skills and Experience:\nBachelor's or Masters degree in Computer Science, Data Science, AI/ML, or a related field.\nMinimum 5+ years of hands-on experience with NLP and LLMs\nProficient in Python and ML frameworks like TensorFlow, PyTorch, Hugging Face Transformers.\nStrong understanding of modern NLP techniques (tokenization, embeddings, attention mechanisms, etc.).\nExperience with ML lifecycle including model development, evaluation, and deployment (MLOps).\nFamiliarity with data handling libraries (Pandas, NumPy) and cloud platforms (AWS, GCP, or Azure).\nGood understanding of data preprocessing, feature engineering, and model validation techniques.\nExperience with open-source LLM fine-tuning and deployment.\nKnowledge of vector databases (e.g., FAISS, Pinecone) and retrieval-augmented generation (RAG).\nPrior experience with large-scale data systems or enterprise data environments.\nPublished papers or open-source contributions in the ML/NLP space.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['LLm', 'Large Language Model', 'Natural Language Processing', 'Ml Algorithms']",2025-06-10 15:36:00
AI/ML Lead Engineer (Senior AI Engineer),Conversehr Business Solutions,7 - 12 years,30-45 Lacs P.A.,['Hyderabad'],"What is AI Engineer team responsible for?\nAs a Senior AI Engineer, youll be a key member of the Data & AI team. This team is responsible for designing and delivering data engineering, analytics, and generative AI solutions that drive meaningful business impact. Were looking for a pragmatic, results-driven problem solver who thrives in a fast-paced environment and is passionate about building solutions at scale.\nThe ideal candidate has a strong technical foundation, a collaborative mindset, and the ability to navigate complex challenges. You should be comfortable working in a fast-moving, startup-like environment within an established enterprise, and should bring strong skill sets to adapt new solutions fast. You will play a crucial role in integrating AI solutions in our existing digital solutions, optimizing our data infrastructure, and enabling insights through data #MID_SENIOR_LEVEL\nWhat is a Digital & AI/ML Lead Engineer (Senior AI Engineer) responsible for?\nServe as a hands-on technical lead, driving project execution and delivery in our growing AI team based in the Hyderabad office.\nCollaborate closely with the U.S.-based team and cross-functional stakeholders to understand business needs and deliver scalable, AI-powered solutions.\nDesign and build AI applications leveraging best smart solutions.\nProvide quick prototype and evaluation AI/ML solutions aligned with business objectives.\nStay current with emerging trends in AI, and machine learning and help implement best practices within the team.\nMentor and support junior engineers, fostering a culture of learning and technical excellence.\nManage unstructured data and generate embeddings that can further be leveraged into AI products.\nWhat ideal qualifications, skills & experience would help someone to be successful?\nBachelors or master’s degree in computer science, data science, engineering, or a related field from a premium institute.\n7+ years of experience in engineering, software engineering, data science, or machine learning, including 3+ years in a technical leadership role.\nStrong understanding with data pipelines, Snowflake ecosystem and master data management.\nProficiency in Python.\nExperience working with unstructured data, large language models (LLMs), embeddings, and building generative AI prototypes.\nSelf-starter with a passion for learning new tools and technologies.\nStrong communication skills and a collaborative, ownership-driven mindset.\nWork Shift Timings - 2:00 PM - 11:00 PM IST",Industry Type: Investment Banking / Venture Capital / Private Equity,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Aiml', 'Python', 'ai/ml', 'genAI', 'Generative Ai', 'Large Language Model', 'Snowflake', 'Master Data Management', 'llm']",2025-06-10 15:36:03
Observability Engineer,Vunet Systems,2 - 4 years,Not Disclosed,['Hyderabad'],"Join Our Journey at VuNet\nAt VuNet, were at the forefront of developing an innovative Business Observability platform. Our approach integrates big data and machine learning to revolutionize how customer journeys are monitored and user experiences enhanced. Our cutting-edge solutions are transforming digital payment experiences for major financial institutions, fostering financial inclusion nationwide. In our dynamic environment, we encourage our teams to tackle challenging customer and business issues. We value creativity and efficiency, rapidly transforming brilliant ideas into exceptional products that our customers adore. Our approach is grounded in teamwork, with cross-functional groups delving into details and engaging in constructive debates, all united by our mission to establish VuNet as a leader in the tech product industry.\nWhat You Can Make Happen\nWe are looking for smart, self-motivated people with excellent communication skills to join our Customer Operations Team as Observability Engineers. Work with customers to understand their Business, application and IT landscape to design and deliver solutions for unified visibility, monitoring and analytics.\nAre you ready to be a part of VuNets trailblazing team? Join us and contribute to making a positive impact on the world.\nRoles & Responsibilities\nExcellent verbal / Written communication (Added Written as well) and good attitude.\nFlexible to work in shifts that includes night shift\nBasic understanding of process and importance of it along with managing reports/documentation.\nExperience in working at NOC / Command Centre driven using SLA , Experience in ITIL Incident Management and Major / P1 incident management\nFluency in MS Excel, power-point is required.\nSkills & Experience\nPreference to the candidates who have experience in NOC monitoring tools such as (ITOM, ITSM) as L1 resource.\nWillingness to learn new technologies and upgrade themselves as and when required.\nUnderstanding of infrastructure and flow, how all the components work hand in hand (Network, server, application and database).\nEducational Qualifications:\nMust have completed Three-year undergraduates such as Bachelors of Science or Bachelors of commerce with minimum 2 years of work experience.\nGood to Have Skills & Attributes\nGood verbal and written communication skills to connect with customers at varying levels of the organization.\nAbility to operate independently and make decisions with little direct supervision.\nAdditional Information\nShould be open to work in 24*7 shifts.\nBenefits\n100% Health Coverage of Medical insurance along with family.\nFinancial protection on disability, Life and accidental death for the employee.\n100% Parents Coverage for Medical insurance.\nMental wellness programs, and counseling with 1:1 sessions.\nOur Culture\nVuNet believes in delivering WoW through service.\nVuNet supports career development programs to expand our People skills and enhance the expertise with various training programs.\nVuNet advocates open culture by having transparency, inclusivity, adaptability, and collaboration\nwith an environment that fosters employee satisfaction, motivation, and trust, and also having an open communication, collaboration, and innovation within the teams.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Career development', 'Monitoring tools', 'Linux', 'Financial inclusion', 'Machine learning', 'Incident management', 'Wellness', 'ITIL process', 'Medical insurance', 'Analytics']",2025-06-10 15:36:06
ML-GenAI Engg,Tech Mahindra,8 - 13 years,Not Disclosed,['Hyderabad'],"Generative AI (GenAI) EngineerJob Summary:We are seeking a talented and highly motivated Generative AI (GenAI) Engineer\nAs a GenAI Engineer, you will be at the forefront of developing and deploying innovative solutions leveraging cutting-edge generative models\nYou will also be responsible for building, training, and fine-tuning GenAI models for various applications, from text generation, image synthesis, code generation, etc\nThis role requires a strong foundation in machine learning, deep learning, and a passion for exploring the potential of generative AI\nQualifications:Education: Masters or PhD degree\nGood to have any certification in Artificial Intelligence, Machine Learning, or a related field\nExperience: 8+ years of experience in developing and deploying machine learning models\n2+ years of experience with generative models\nExperience with cloud platforms such as AWS, Azure, or GCP\nSkills: Technical Expertise: Strong understanding of generative AI models, such as GANs, VAEs, diffusion models, and large language models\nProficiency in Python and other programming languages commonly used in machine learning\nExperience with model training and fine-tuning techniques\nKnowledge of data preprocessing and feature engineering methods\nFamiliarity with model deployment and monitoring tools\nSoft Skills: Strong analytical and problem-solving skills\nExcellent communication, presentation, and interpersonal skills\nAbility to work independently and as part of a team\nCreativity and a passion for exploring the potential of generative AI",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['deep learning', 'Interpersonal skills', 'Monitoring tools', 'GCP', 'Analytical', 'Artificial Intelligence', 'Machine learning', 'Programming', 'Deployment', 'Python']",2025-06-10 15:36:08
Product Owner,Cyncly,7 - 12 years,Not Disclosed,['Bengaluru'],"Job Title: Product Owner\nLocation: Bangalore, India (Hybrid)\nFull time\nAbout Us:\nCyncly & the Power of AI\nAt Cyncly, we believe in unlocking the power of AI to deliver highly personalized and extraordinary experiences for our customers and their clients.\nWe are on a dynamic journey of seeking exceptional talent to add critical AI models and functionality to our products used by over 17,000 customers worldwide. This is an exciting opportunity to be a part of a collaborative team that fosters continuous learning and growth, where youll work on exciting data-driven projects that redefine the Spaces for Living industry. AI is reshaping private and business life at an unprecedented speed, and Cyncly is committed to leading the charge in delivering new sources of value for our customers.\nAbout the Role:\nJoin a world leader in Cloud based software solution for the Space Designing industry. As an AI Product Owner, you will work as part of Cyncly AI COE.\nOur data team is made up of skilled data management, data visualization, engineers, and scientists. We are aggressively hiring to add critical AI models and functionality in our products used by 17000+ customers. If you are looking for a challenging job role in product based organization that offers learning and growth opportunities, apply for this position!\nKey Position Responsibilities include:\nDrive clear product definition and roadmap to achieve business goals, with well-defined metrics and indicators for success.\nDeeply understand customer needs and priorities, and define model and data requirements based on this understanding\nWork with Product management to build the AI/ML roadmap.\nHelp translate company s strategic vision into data science-focused product initiatives\nConduct core research in the area of AI algorithms and capabilities.\nCreates and Maintains: user stories, team backlog, and team roadmap to support features\nKey activities include: backlog refinement, iteration planning, user story acceptance, and PO sync\nPrimary Stakeholders: Customers, the Agile Team, Product Management, Other Agile teams and shared services\nDefine and track metrics to measure product quality and business impact.\nCollaborate closely with our team of AI/ML researchers and engineers, data analysts, QA and other product managers.\nStay up-to-date on AI technology and industry trends, and apply this knowledge to inform product strategy and decision-making\nWork with legal and compliance teams to ensure the AI products meet legal and ethical standards.\nRequired Experience and Qualifications:\nBS/BE in Computer Science, Electrical Engineering, Mathematics, or equivalent required\nExperience:\n7+ years of experience in software development product owner in an Agile environment.\n2+ years of exposure to software development products where AI is part of design.\nBasic familiarity with AI models and their application\nDomain expertise with machine learning (ML) and artificial intelligence techniques for structured and unstructured data (content)\nAbility to run proof-of-concepts and evaluations of emerging technologies\nComfortable with data analyses, A/B testing scenarios and interpreting the significance of data-related observations from the perspective of product goals\nAble to work with data analysts and machine learning engineers closely to define the ML problem being solved, and the solution process\nAnalytical, problem-solving, and decision-making skills\nDemonstrate excellent analytical, technical, interpersonal and organizational skills and be a good team player.\nExperience working in an agile environment as an important part of the team\nExcellent communication skill with stakeholders like product managers.\nWe Value:\nGood working knowledge of Continuous Delivery Practices with Azure DevOps or similar frameworks\nAbility to work within a Team with strong analytical, problem-solving and communication skills\nFlexible and adaptable, able to work in ambiguous situations\nExperience working within an Agile team\nUnderstanding of Agile practices and ability to use tools such as Azure DevOps to enable the delivery of high-quality data resources.\nWorking for Us",Industry Type: IT Services & Consulting,Department: Product Management,"Employment Type: Full Time, Permanent","['Product management', 'Computer science', 'ERP', 'Data management', 'Analytical', 'Artificial Intelligence', 'CAD', 'Machine learning', 'Agile', 'Business process management']",2025-06-10 15:36:11
Data Scientist - SCB,Wipro,8 - 10 years,Not Disclosed,['Chennai'],"About The Role  \n\nRole Purpose\n\nThe purpose of the role is to create exceptional architectural solution design and thought leadership and enable delivery teams to provide exceptional client engagement and satisfaction.\n\n\n ? \n\nMandatory Skills\n\nData Science, ML, DL, NLP or Computer Vision, Python, Tensorflow, Pytorch, Django, PostgreSQL\n\nPreferred Skills\n\nGen AI, LLM, RAG, Lanchain, Vector DB, Azure Cloud, MLOps, Banking exposure\n\n\n ? \n\n \n\n3.Competency Building and Branding  \nEnsure completion of necessary trainings and certifications\nDevelop Proof of Concepts (POCs),case studies, demos etc. for new growth areas based on market and customer research\nDevelop and present a point of view of Wipro on solution design and architect by writing white papers, blogs etc.\nAttain market referencability and recognition through highest analyst rankings, client testimonials and partner credits\nBe the voice of Wipro’s Thought Leadership by speaking in forums (internal and external)\nMentor developers, designers and Junior architects in the project for their further career development and enhancement\nContribute to the architecture practice by conducting selection interviews etc\n\n\n ? \n\nMandatory\nStrong understanding of Data Science, machine learning and deep learning principles and algorithms.\nProficiency in programming languages such as Python, TensorFlow, and PyTorch.\nAbility to work with large datasets and knowledge of data preprocessing techniques.\nStrong Backend Python developer\nExperience in applying machine learning techniques,\n\nNatural Language Processing or Computer Vision using TensorFlow, Pytorch\nBuild and deploy end to end ML models and leverage metrics to support predictions, recommendations, search, and growth strategies\nExpert in applying ML techniques such asclassification, clustering, deep learning, optimization methods, supervised and unsupervised techniques\nOptimize model performance and scalability for real-time inference and deployment.\nExperiment with different hyperparameters and model configurations to improve AI model quality.\nEnsure AI ML solutions are developed, and validations are performed in accordance with Responsible AI guidelines.\n\n\n ? \n\n \n\n4.Team Management  \n\n Resourcing  \nAnticipating new talent requirements as per the market/ industry trends or client requirements\nHire adequate and right resources for the team\nTalent Management\nEnsure adequate onboarding and training for the team members to enhance capability & effectiveness\nBuild an internal talent pool and ensure their career progression within the organization\nManage team attrition\nDrive diversity in leadership positions\nPerformance Management\nSet goals for the team, conduct timely performance reviews and provide constructive feedback to own direct reports\nEnsure that the Performance Nxt is followed for the entire team\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nMandatory\n\nSkills:\nGenerative AI.\n\nExperience8-10 Years.\n\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'deep learning', 'tensorflow', 'algorithms', 'dl', 'azure cloud', 'sql', 'gen', 'django', 'data science', 'postgresql', 'predictive modeling', 'computer vision', 'pytorch', 'statistical modeling', 'vector', 'clustering', 'db', 'ml', 'statistics']",2025-06-10 15:36:14
ML OPS Engineer,Valuebound,3 - 8 years,Not Disclosed,['Chennai'],"What You ll Do\nHandle data: pull, clean, and shape structured & unstructured data.\nManage pipelines: Airflow / Step Functions / ADF your call.\nDeploy models: build, tune, and push to production on SageMaker, Azure ML, or Vertex AI.\nScale: Spark / Databricks for the heavy lifting.\nAutomate processes: Docker, Kubernetes, CI/CD, MLFlow, Seldon, Kubeflow.\nCollaborate effectively: work with engineers, architects, and business professionals to solve real problems promptly.\nWhat You Bring\n3+ years hands-on MLOps (4-5 yrs total software experience).\nProven experience with one hyperscaler (AWS, Azure, or GCP).\nConfidence with Databricks / Spark , Python, SQL, TensorFlow / PyTorch / Scikit-learn.\nExtensive experience handling and troubleshooting Kubernetes and proficiency in Dockerfile management.\nPrototyping with open-source tools, selecting the appropriate solution, and ensuring scalability.\nAnalytical thinker, team player, with a proactive attitude.\nNice-to-Haves\nSagemaker, Azure ML, or Vertex AI in production.\nDedication to clean code, thorough documentation, and precise pull requests.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Scalability', 'GCP', 'spark', 'Analytical', 'Management', 'Troubleshooting', 'Open source', 'AWS', 'SQL', 'Python']",2025-06-10 15:36:16
SAS Data Scientist,Lericon Informatics,2 - 6 years,Not Disclosed,"['Kolkata', 'Pune', 'Chennai']","Job Summary:\nWe are seeking a skilled Data Scientist with experience in both Python and SAS to join our high-performing analytics team. The ideal candidate will be adept at developing predictive models, analyzing large datasets, and delivering actionable insights using modern data science tools and platforms.\n\nKey Responsibilities:\n\nDesign and develop machine learning and statistical models using Python and SAS.\nConduct data exploration, preprocessing, and analysis on structured and unstructured datasets.\nUse SAS (Base, Advanced, Enterprise Guide, Visual Analytics, or SAS Viya) for reporting, data preparation, and statistical modeling as required.\nWork with large-scale datasets using Python libraries such as Pandas, NumPy, Scikit-learn, and TensorFlow.\nTranslate business requirements into technical solutions in collaboration with cross-functional teams.\nBuild data pipelines and automate workflows for data analysis and model deployment.\nPresent data-driven insights through visualizations using tools such as Seaborn, Plotly, Matplotlib, or SAS VA.\nDocument models, code, and methodologies for reproducibility and auditability.\n\nQualifications:\n\n2-10 years of experience in data science, machine learning, or advanced analytics.\nProficient in Python (Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch, etc.) and SAS (Base, Advanced, DI, VA, or Viya).\nStrong knowledge of SQL and experience working with relational databases.\nSolid foundation in statistical analysis, hypothesis testing, regression, classification, clustering, etc.\nExperience in building, evaluating, and deploying predictive models.\nExcellent communication skills and ability to convey complex findings to non-technical stakeholders.\n\nPreferred Qualifications :\n\nExperience with big data tools (Spark, Hive, Hadoop).\nExposure to MLOps tools (MLflow, Airflow, Docker, etc.).\nFamiliarity with cloud platforms (AWS, Azure, GCP).\nUnderstanding of SAS integration with cloud or open-source tools.\nExperience with NLP, image recognition, or deep learning frameworks.\nLocation: Pan India-Delhi / NCR,Bangalore/Bengaluru,Hyderabad/Secunderabad,Chennai,Pune,Kolkata,Ahmedabad,Mumbai",Industry Type: Banking,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SAS', 'Predictive Modeling', 'Data Engineering', 'Scikit-learn', 'Machine Learning', 'NumPy', 'SQL', 'Data Science', 'Cloud Platforms', 'SAS Viya', 'Pandas', 'Data Analysis', 'Statistical Modeling', 'Data Visualization', 'Python']",2025-06-10 15:36:19
Senior AI Engineer,Infilect,3 - 5 years,Not Disclosed,['Bengaluru'],"Reading research papers and implementing state-of-the-art techniques\nRapidly extending publicly available code modules to work on custom problems\nSoftware development of machine learning back-end\nRapid experimentation, analysis, and deployment of machine/deep learning models\nTraining and testing deep learning models at scale\nWorking on cutting-edge technology in object detection, object tracking, OCR in natural scenes, image classification, video analysis, and many more exciting techniques that form the basis of AI (artificial intelligence).\nSkills Required:\nHands-on experience in deep/machine learning for computer vision of 2+ years (extensive experience OpenCV, PyTorch, Tensorflow)\nHands-on experience in Python with 2+ years of in-depth system building experience\nSmart programmers with strong analytical skills\nJob Perks:\nWork on a problem that will have positive impact on millions of users\nWork with experienced computer scientists\nLively and highly collaborative environmen",Industry Type: Software Product,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Supply chain', 'Analytical skills', 'Computer vision', 'deep learning', 'Backend', 'Artificial Intelligence', 'Machine learning', 'Manager Technology', 'Research', 'Python']",2025-06-10 15:36:22
AI/ML Engineer,Leading Client,5 - 8 years,Not Disclosed,['Chennai'],"Experience in CI/CD pipelines, scripting languages, and a deep understanding of version control systems (e.g. Git), containerization (e.g. Docker), and continuous integration/deployment tools (e.g. Jenkins) third party integration is a plus, cloud computing platforms (e.g. AWS, GCP, Azure), Kubernetes and Kafka.\n\nExperience in 4+ years of experience building production-grade ML pipelines.\n\nProficient in Python and frameworks like Tensorflow, Keras, or PyTorch.\n\nExperience with cloud build, deployment, and orchestration tools\n\nExperience with MLOps tools such as MLFlow, Kubeflow, Weights & Biases, AWS Sagemaker, Vertex AI, DVC, Airflow, Prefect, etc.,\n\nExperience in statistical modeling, machine learning, data mining, and unstructured data analytics.\n\nUnderstanding of ML Lifecycle, MLOps & Hands on experience to Productionize the ML Model\n\nDetail-oriented, with the ability to work both independently and collaboratively.\n\nAbility to work successfully with multi-functional teams, principals, and architects, across organizational boundaries and geographies.\n\nEqual comfort driving low-level technical implementation and high-level architecture evolution\n\nExperience working with data engineering pipelines.",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['AI/ML Engineering', 'continuous integration', 'kubernetes', 'python', 'vertex', 'production', 'data mining', 'ci/cd', 'aws sagemaker', 'microsoft azure', 'machine learning', 'artificial intelligence', 'docker', 'tensorflow', 'git', 'gcp', 'kafka', 'pytorch', 'jenkins', 'keras', 'statistical modeling', 'aws', 'ml']",2025-06-10 15:36:25
Machine Learning Associate Advisor,A Large Global Organization,8 - 13 years,Not Disclosed,['Hyderabad'],"Key Skills: Perception AI Machine Learning, Python, Java, C/C++, GPT, VAE.\nRoles and Responsibilities:\nUtilize Large Language Models (LLMs), open-source tools, machine learning, and numerical programming frameworks to build transformative GenAI/Agentic AI solutions.\nAct as a subject matter expert on Generative Artificial Intelligence (AI), contributing to the design, architecture, and development of scalable, resilient, and ethical AI solutions.\nWork with product development teams to align AI capabilities with enterprise goals, ensuring compliance and security in AI model deployments.\nOptimize generative AI models for performance, scalability, and efficiency.\nBuild and maintain AI pipelines including data preprocessing, feature extraction, model training, and evaluation.\nEngage with both open-source frameworks (e.g., TensorFlow, PyTorch, Hugging Face Transformers) and cloud solutions to deliver optimal results.\nEnsure AI solutions align with responsible AI practices and standards.\nContribute to healthcare innovation by integrating AI capabilities that improve products, services, and patient outcomes.\nExperience Requirements:\n8 to 11 years of relevant experience, including prior roles as a Machine Learning Engineer or Prompt Engineer.\nStrong experience in deep learning architectures, generative AI (GPT, VAE, GANs), and transformer-based models.\nHands-on experience in developing recommendation engines, data pipelines, or distributed machine learning systems.\nProficiency in programming languages such as Python, C/C++, or Java.\nSolid background in machine learning libraries and frameworks including TensorFlow, PyTorch, and Keras.\nExperience with natural language processing (NLP) tools such as SpaCy, NLTK, or Hugging Face.\nFamiliarity with cloud platforms like AWS, GCP, or Azure.\nExperience in computer vision, self-supervised learning, transfer learning, and reinforcement learning.\nPrior experience in the healthcare industry and familiarity with Electronic Health Record systems and HIPAA regulations is a plus.\nEducation: B.Tech.",Industry Type: Medical Services / Hospital,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Java', 'C/C++', 'GPT', 'Perception AI Machine Learning', 'Python', 'VAE.']",2025-06-10 15:36:27
Senior AI/ML Engineer - Blackstraw - Work from Office- Chennai,Blackstraw Technologies,4 - 9 years,Not Disclosed,"['Chennai', 'Mumbai (All Areas)']","Job Summary:\nWe are looking for a passionate and skilled AI/ML Engineer to join our team, focusing on cutting edge solutions in vector search, embeddings, and semantic similarity. In this role, you will design, develop, and optimize intelligent search systems that leverage state-of-the-art machine learning and deep learning techniques. You will collaborate with cross-functional teams to build scalable and efficient solutions that transform how we retrieve and process information.",,,,"['Artificial Intelligence', 'Machine Learning', 'Object Detection', 'Algorithm Development', 'Natural Language Processing', 'Image Recognition', 'Deep Learning', 'Pytorch', 'Huggingface', 'Video Processing', 'Opencv', 'Image Processing', 'Computer Vision', 'Optimize Vector Search Systems', 'Python', 'OCR']",2025-06-10 15:36:29
Senior Full Stack Developer - Generative AI,MNC in B2B Insurance Domain,5 - 10 years,Not Disclosed,['Noida'],"Job Title: Full Stack Developer Generative AI\nRange: 5-10 Years\nLocation: Noida\n\nJob Summary\nWe are seeking a Senior Full-Stack Developer to join our Architecture Practice at Xceedance. In this role, you will design and develop AI-powered applications using Python, .NET Core, Angular, and Azure. You will work on integrating AI models, building scalable cloud-native systems, and leveraging tools like GitHub Copilot, Azure Foundry, Agentic frameworks to accelerate development.This is a hands-on role at the intersection of full-stack engineering and AI innovation, including agentic AI, AI-assisted SDLC, and other emerging technologies.\n\nKey ResponsibilitiesFull-Stack Development\nBuild scalable backend services using Python and .NET Core (Web APIs, Entity Framework).\nDevelop responsive frontend applications using Angular (13+) and Stream lit for rapid AI tool prototyping.\nIntegrate AI/ML and LLM models into end-to-end application workflows.\nAI-Driven SDLC\nUse AI coding assistants like GitHub Copilot or Code Whisperer to enhance development speed and code quality.\nAutomate testing, code analysis, and deployment using CI/CD pipelines and AI tools.\nCloud Deployment\nDeploy and manage applications on Azure (App Services, Functions, Azure SQL, AI Studio).\nImplement microservices and event-driven architectures in collaboration with solution architects.\nCollaboration & Leadership\nMentor junior developers on AI/ML integration and modern development practices.\nContribute to architectural decisions and technical strategy.\n\nRequired Skills & Qualifications5-8 years of experience in web-based application development.\n\nMandatory\n5+ years of full-stack development experience with Python and .NET Core.\n3+ years of frontend development using Angular, TypeScript, and RxJS.\nHands-on experience integrating AI/ML models (e.g., scikit-learn, PyTorch) into production applications.\nProficiency in Azure cloud services (App Services, Functions, Azure SQL).\nPreferred\nExperience with AI coding tools like GitHub Copilot or CodeWhisperer.\nFamiliarity with Streamlit for AI/ML UI prototyping.\nKnowledge of Azure Machine Learning, LLM fine-tuning (e.g., GPT, Claude).\nDevOps skills: CI/CD, Docker, Infrastructure as Code (IaC).\nEducation and Experience\nBachelors degree in computer science, Engineering, or a related field (or equivalent practical experience).\n58 years of hands-on development experience, including 2+ years in AI/ML projects.\nPortfolio or GitHub showcasing work in Python, .NET, Angular, and AI/ML (preferred).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['.Net Core', 'Generative Ai', 'Angular', 'Python', 'Pytorch', 'Tensorflow', 'Azure Cloud', 'Typescript', 'Aiml', 'Scikit-Learn', 'Ml']",2025-06-10 15:36:31
Ml Engineer,Ltimindtree,6 - 9 years,Not Disclosed,"['Pune', 'Bengaluru', 'Mumbai (All Areas)']","Job Title: Data Scientist\n\nLooking for someone with 5-8 years of experience manipulating data sets and building statistical models\n\nDesired Skills:\n\nExperience using statistical computer languages (R, Python, etc.) to manage data and draw insights from large data sets.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, XGBoost, KNN, SVM, ANN, etc.).\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nKnowledge and experience in statistical and data mining techniques: GLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.\nExperience creating and using advanced machine learning algorithms and statistics: regression, simulation, scenario analysis, modelling, clustering, decision trees, neural networks, etc.\nExperience visualizing/presenting data for stakeholders.\nExperience with Snowflake will be an added advantage.\nExperience in deployment of machine learning models using cloud technologies.\n\nRoles and responsibilities:\n\n1. Work with stakeholders to identify opportunities for leveraging data to drive business solutions.\n2. Mine and analyse data from databases to drive optimization and improvement of product development and business strategies.\n3. Assess the effectiveness and accuracy of new data sources and data gathering techniques.\n4. Develop custom models and algorithms to apply to data sets.\n5. Use predictive modelling to increase and optimize customer experiences.\n6. Coordinate with different functional teams to implement models and monitor outcomes.\n7. Analyse large amounts of information to discover trends and patterns.\n8. Build predictive models and machine-learning algorithms.\n9. Present information using data visualization techniques .\n10. Good to have a knowledge of ML lifecycle and model governance.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'R', 'Python']",2025-06-10 15:36:33
AI Ml Engineer,Fulcrum Worldwide Software,4 - 8 years,15-30 Lacs P.A.,['Pune'],"The Role\nMachine learning and data science are interdisciplinary fields that require a combination of skills in mathematics, statistics, programming, and domain-specific knowledge to extract meaningful insights from data and develop predictive models.\nSkills Requirements\nMandatory Skillset - ML Techniques, any ML Framework, Gen AI COncepts, Azure, Python\nSecondary Skillset - AWS, or Google Cloud\n\nRequirements\nWork closely with cross-functional teams to understand business requirements and translate them into machine learning solutions.\nCollect, clean, and pre-process large datasets to prepare them for machine learning models.\nDevelop and implement machine learning algorithms and models for solving specific business problems.\nCollaborate with data engineers to ensure seamless integration of machine learning models into production systems.\nFine-tune models for optimal performance and conduct thorough testing and validation.\nStay updated on the latest advancements in machine learning and artificial intelligence and assess their potential impact on our projects.\nEffectively communicate complex technical concepts and findings to non-technical stakeholders.\nMonitor and maintain deployed models and update them as needed to adapt to changes in data or business requirements.\nAdhere to ethical standards and ensure that machine learning solutions comply with relevant regulations.\nProficiency in Python with hands-on experience in cloud platforms including GCP, AWS, and Azure; strong skills in API integration.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['NLP', 'Generative ai', 'Machine Learning', 'Deep Learning']",2025-06-10 15:36:36
ML Engineer,Prescience Decision Solutions,2 - 5 years,Not Disclosed,['Chennai'],"Prescience Decision Solutions is looking for ML Engineer to join our dynamic team and embark on a rewarding career journey.\n\nWe are seeking a highly skilled and motivated Machine Learning Engineer to join our dynamic team. The Machine Learning Engineer will be responsible for designing, developing, and deploying machine learning models to solve complex problems and enhance our products or services. The ideal candidate will have a strong background in machine learning algorithms, programming, and data analysis. Responsibilities : Problem Definition : Collaborate with cross - functional teams to define and understand business problems suitable for machine learning solutions. Translate business requirements into machine learning objectives. Data Exploration and Preparation : Analyze and preprocess large datasets to extract relevant features for model training. Address data quality issues and ensure data readiness for machine learning tasks. Model Development : Develop and implement machine learning models using state - of - the - art algorithms. Experiment with different models and approaches to achieve optimal performance. Training and Evaluation : Train machine learning models on diverse datasets and fine - tune hyperparameters. Evaluate model performance using appropriate metrics and iterate on improvements. Deployment : Deploy machine learning models into production environments. Collaborate with DevOps and IT teams to ensure smooth integration. Monitoring and Maintenance : Implement monitoring systems to track model performance in real - time. Regularly update and retrain models to adapt to evolving data patterns. Documentation : Document the entire machine learning development pipeline, from data preprocessing to model deployment. Create user guides and documentation for end - users and stakeholders. Collaboration : Collaborate with data scientists, software engineers, and domain experts to achieve project goals. Participate in cross - functional team meetings and knowledge - sharing sessions.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent",['ML Engineer'],2025-06-10 15:36:38
Ml Engineer/,Orcapod,3 - 5 years,Not Disclosed,['Pune'],"Dear Candidate,\n\n\nWe are currently hiring for our client in Pune location.\nKey Responsibilities\n\n• •Extraction, Transformation, and Loading (ETL) data from source systems and bringing into the desired format for better decision-making.\n• •Identify, analyze, and interpret trends or patterns in complex data sets (Sensor/Machine Data)\n• •Understand Data warehouses and Enterprise Data Lakes  (EDL) and how they work.\n• •Build and refine machine learning models to solve complex problems.\n• •Develop data pipelines for optimal model training and deployment.\n• •Explore new/advanced Data Science techniques/methodologies.\n• •Monitor and optimize model performance post-deployment.\n• •Building and testing the hypothesis using data.\n• •Maintain thorough documentation and communicate technical insights effectively.\n\nRequired Skills\n\n• •Strong knowledge in SQL & PySpark\n• •Hands-on experience in productionizing the ML models.\n• •Experience in working with cloud technologies will be an added advantage (Databricks)\n• •Hands-on experience on any visualization tool (Tableau Preferred)\n• •Strong knowledge of statistical techniques for data analysis\n• •Experience with data mining, machine learning and deep learning for analytical insights\n• •Good communication skills",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ETL', 'EDL', 'Machine Learning', 'SQL']",2025-06-10 15:36:41
DS / ML / Time-Series Engineer,Biz-metric India,2 - 5 years,Not Disclosed,"['Mumbai', 'Gurugram', 'Bengaluru']","BIZMETRIC INDIA PRIVATE LIMITED is looking for DS / ML / Time-Series Engineer to join our dynamic team and embark on a rewarding career journey\nData Exploration and Preparation:Explore and analyze large datasets to understand patterns and trends\nPrepare and clean datasets for analysis and model development\nFeature Engineering:Engineer features from raw data to enhance the performance of machine learning models\nCollaborate with data scientists to identify relevant features for model training\nModel Development:Design and implement machine learning models to solve business problems\nWork on both traditional statistical models and modern machine learning algorithms\nScalable Data Pipelines:Develop scalable and efficient data pipelines for processing and transforming data\nUtilize technologies like Apache Spark for large-scale data processing\nModel Deployment:Deploy machine learning models into production environments\nCollaborate with DevOps teams to integrate models into existing systems\nPerformance Optimization:Optimize the performance of data pipelines and machine learning models\nFine-tune models for accuracy, efficiency, and scalability\nCollaboration:Collaborate with cross-functional teams, including data scientists, software engineers, and business stakeholders\nCommunicate technical concepts and findings to non-technical audiences\nContinuous Learning:Stay current with advancements in data science and engineering\nImplement new technologies and methodologies to improve data engineering processes\n\n\nLearning Certification Opportunities: Enhance your professional growth.\nComprehensive Medical Coverage and Life Insurance: For your we'll-being.\nFlexible Work Environment: Enjoy a 5-day work week.\nCollaborative Culture: Be part of a fun, innovative workplace.\nJob Description:\nPython, Data Science, Azure Databricks, Machine Learning",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['algorithms', 'python', 'natural language processing', 'neural networks', 'predictive analytics', 'data pipeline', 'machine learning', 'data engineering', 'artificial intelligence', 'sql', 'deep learning', 'data science', 'spark', 'predictive modeling', 'machine learning algorithms', 'ml']",2025-06-10 15:36:43
Artificial Intelligence Engineer,Qiskitq Technology,5 - 10 years,12-18 Lacs P.A.,[],"Key Responsibilities:\n\nDesign, develop, and implement AI-driven chatbots and IVAs to streamline customer interactions.\nWork on conversational AI platforms to create a seamless customer experience, with a focus on natural language processing (NLP), intent recognition, and sentiment analysis.\nCollaborate with cross-functional teams, including product managers and customer support, to translate business requirements into technical solutions.\nBuild, train, and fine-tune machine learning models to enhance IVA capabilities and ensure high accuracy in responses.\nContinuously optimize models based on user feedback and data-driven insights to improve performance.\nIntegrate IVA/chat solutions with internal systems such as CRM and backend databases.\nEnsure scalability, robustness, and security of IVA/chat solutions in compliance with industry standards.\nParticipate in code reviews, testing, and deployment of AI solutions to ensure high quality and reliability.\nRequired Skills and Qualifications:\n\nBachelors or master’s degree in computer science, Data Science, AI/ML, or a related field.\n3+ years of experience in developing IVA/chatbots, conversational AI, or similar AI-driven systems using AWS services\nExpert in using Amazon Lex, Amazon Polly, AWS lambda, AWS connect\nAWS Bedrock experience with Sage maker will have added advantage\nSolid understanding of API integration and experience working with RESTful services.\nStrong problem-solving skills, attention to detail, and ability to work independently and in a team.\nExcellent communication skills in English, both written and verbal.\nPreferred Qualifications:\n\nExperience in financial services or fintech projects.\nKnowledge of data security best practices and compliance requirements in the financial sector.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Part Time, Temporary/Contractual","['Aws Bedrock', 'Aws Connect', 'Aws Lambda', 'Aws Sagemaker', 'Amazon Lex', 'Aws Cloudformation', 'Artificial Intelligence', 'Machine Learning', 'Python']",2025-06-10 15:36:45
Ai Ml Engineer,Confidential,7 - 10 years,8.4-14.4 Lacs P.A.,['Indore'],"Design, develop, and deploy ML models using Python, NLP, CV, RAG.\nOptimize model performance through DevOps practices with Kafka, REST APIs.\nPractical experience in building applications based on Large Language Models (LLMs)\n\n\nWork from home\nFlexi working",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'Artificial Intelligence', 'Natural Language Processing', 'Retrieval Augmented Generation', 'Machine Learning', 'Kafka', 'Computer Vision', 'Devops', 'Deep Learning', 'Restful Web Api Development', 'Python']",2025-06-10 15:36:47
ML Engineer,Randomtrees,3 - 8 years,Not Disclosed,['Chennai'],Role: ML Engineer\nExperience: 3 to 15 Years\nChennai location must or relocation also fine- Hybrid mode\nWe have good budget\n\nJob Description:\nResponsibilities:,,,,"['Generative Ai', 'Aiml', 'RAG', 'LLM', 'Python', 'Data Science', 'Date Scientist', 'Langchain', 'Artificial Intelligence', 'Machine Learning']",2025-06-10 15:36:50
Data/ML Ops Engineer,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Additional Career Level Description:\n\n\nKnowledge and application:\nSeasoned, experienced professional; has complete knowledge and understanding of area of specialization.\nUses evaluation, judgment, and interpretation to select right course of action.\n\n\n\nProblem solving:\nWorks on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\nResolves and assesses a wide range of issues in creative ways and suggests variations in approach.\n\n\n\nInteraction:\nEnhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\nWorks with others outside of own area of expertise, with the ability to adapt style to differing audiences and often advises others on difficult matters.\n\n\n\nImpact:\nImpacts short to medium term goals through personal effort or influence over team members.\n\n\n\nAccountability:\nAccountable for own targets with work reviewed at critical points.\nWork is done independently and is reviewed at critical points.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['ML Ops', 'python', 'spark', 'big data', 'data engineering', 'artificial intelligence', 'ml', 'sql']",2025-06-10 15:36:51
Ml Engineer,Sightspectrum,5 - 10 years,1-6 Lacs P.A.,"['Hyderabad', 'Chennai', 'Bengaluru']","Description:\n\n\n\nStrong experience in ETL development, data modeling, and managing data in large-scale environments. - Proficient in AWS services including SageMaker, S3, Glue, Lambda, and CloudFormation/Terraform. - Hands-on expertise with MLOps best practices, including model versioning, monitoring, and CI/CD for ML pipelines.\n\n- Proficiency in Python and SQL; experience with Java is a plus for streaming jobs.\n- Deep understanding of cloud infrastructure automation using Terraform or similar IaC tools. - Excellent problem-solving skills with the ability to troubleshoot data processing and deployment issues.\n- Experience in fast-paced, agile development environments with frequent delivery cycles.\n- Strong communication and collaboration skills to work effectively across cross-functional team Role & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['MLOps', 'Aws Sagemaker', 'Rasa', 'Serverless', 'Ml']",2025-06-10 15:36:54
Ai Ml Engineer,Randomtrees,3 - 8 years,Not Disclosed,['Chennai( Chennai Central RS )'],"Requirement\nRole: ML Engineer/Data Scientist\nExperience: 3 to 15 Years\nJob Description:\nResponsibilities:\nStrong understanding of ML algorithms, techniques, and best practices.\nStrong understanding of Databricks, Azure AI services and other ML platforms and cloud computing platforms (e.g., AWS, Azure, GCP) and frameworks (e.g., TensorFlow, PyTorch, scikit-learn).",,,,"['Generative Ai', 'Artificial Intelligence', 'Large Language Model', 'Retrieval Augmented Generation', 'Python', 'Langchain', 'Natural Language Processing', 'Neural Networks', 'Machine Learning', 'Deep Learning', 'Pytorch', 'Algorithms', 'Opencv', 'Image Processing', 'Aiml', 'Keras', 'Computer Vision']",2025-06-10 15:36:56
Data Analyst / Data Scientist,Nybl,1 - 4 years,Not Disclosed,[],"nybl is looking for our next generation of data scientists. We pride ourselves on growing our team and are always looking for the brightest talent to join us. Attitude is the most important trait we are looking for above all else.\n\nYou will be working on transforming data into intelligence by developing innovative Artificial Intelligence (AI) solutions and integrating them with cutting-edge Internet of Things (IoT) technologies. Candidates must prove that they have the will, determination and ambition to be part of a team thats going to be the next Camel of the Middle East.\n\nresponsibilities\n\nwork closely with nybl to identify issues and use data to propose solutions for effective decision making\nbuild algorithms and design experiments to merge, manage, interrogate and extract data to supply tailored reports to colleagues, customers or the wider organisation\nuse machine learning tools and statistical techniques to produce solutions to problems\ntest data mining models to select the most appropriate ones for use on a project\nmaintain clear and coherent communication, both verbal and written, to understand data needs and report results\ncreate clear reports that tell compelling stories about how customers or clients work with the business\nassess the effectiveness of data sources and data-gathering techniques and improve data collection methods\nhorizon scan to stay up to date with the latest technology, techniques and methods\nconduct research from which youll develop prototypes and proof of concepts\nstay curious and enthusiastic about using algorithms to solve problems and enthuse others to see the benefit of your work.\n\nrequired skills, abilities, education, and experience\n\nExperience and knowledge in statistical and data mining techniques using (e.g., python, R, SQL)\nExperience and knowledge in applying advance Machine Learning techniques (e.g., Neural networks, supervised and unsupervised ML, computer vision and image processing, text analysis)\nExperience and knowledge in big data analysis and management and distributed computing tools (e.g., Hadoop, Hive, Spark)\nExperience and knowledge in one or more programming languages (C, C#, Java)\nExperience and knowledge in web development frameworks (javascript, React, node.js).\nExperience analyzing data from 3rd party providers: (e.g., Google Analytics, Site Catalyst, Facebook Insights)\nExperience visualizing/presenting data for stakeholders using: Periscope, Business Objects, D3, ggplot, etc.\nExperience working with and creating data architectures.\nKnowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neural networks, etc.) and their real-world advantages/drawbacks.\nKnowledge of advanced statistical techniques and concepts (regression, properties of distributions, statistical tests and proper usage, etc.) and experience with applications.\nExcellent written and verbal communication skills for coordinating across teams.\nA drive to learn and master new technologies and techniques.\nWillingness to learn new technology.\nAble to work independently on researching solutions and applying findings.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data analysis', 'Business objects', 'Google Analytics', 'Image processing', 'Web development', 'Machine learning', 'Data collection', 'Data mining', 'SQL', 'Python']",2025-06-10 15:36:58
AIML Engineer,Throughbit Technologies,1 - 6 years,2-7 Lacs P.A.,['Coimbatore'],"Education:\nBachelor's degree in Computer Science, Data Science, Artificial Intelligence, or a related certifications or experience in NLP & CV.\n\nYears of Experience:\nMinimum 2 years of experience in Deep Learning, NLP,CV, MLOps and its related technologies.\n\nResponsibilities:\n- Design, develop, and deploy state-of-the-art NLP and CV models and algorithm\n- Collaborate with cross-functional teams to understand requirements and develop customised NLP & CV solutions and have experience in building the python backend using Flask / Django.\n- Database integration preferably using MongoDB or any other vector databases.\n- Maintain and improve the performance, accuracy, and efficiency of existing AI/ML models and their deployment on Cloud platforms (AWS) and monitor their performance using MLOps tools such as MLFlow, DVC.\n- Experience in building End to End data pipelines\n- Stay updated with emerging AI/ML technologies, LLMs ,RAG\n- Conduct regular performance evaluations of AI/ML models using production grade MLOps solutions.\n- Troubleshoot and resolve any issues arising from the implementation of NLP & CV models.\n- Develop and monitor the code that runs in production environments using MLOps practices.\n\nRequirements:\n- Strong experience with Deep learning and NLP frameworks such as TensorFlow or other open-source machine learning frameworks.\n- Experience of using both tensorflow and pytorch frameworks\n- Proficient in programming languages, such as Python or Java, and experience with AI/ML libraries.\n- Familiarity with the integration of APIs, such as REST API, OpenAI API, for implementing advanced AI-driven features.\n- Solid understanding of Machine learning and Deep learning algorithms, concepts, and best practices in a production environment using MLOps.\n- Experience with big data technologies, such as Hadoop and Spark, is a plus.\n- Strong problem-solving skills.\n- Excellent communication and teamwork skills, with the ability to collaborate effectively with team members from various disciplines.\n- Eagerness to learn and adapt to new technologies and industry trends.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Natural Language Processing', 'Py', 'Deep Learning', 'Java', 'Deep', 'Python']",2025-06-10 15:37:01
Software Engineer Python,CareerFit.ai,1 - 5 years,Not Disclosed,['Mumbai'],"Job Title: Software Engineer Python\nExperience Required: 34 years\nEmployment Type: Full-Time\nFunction: Software Development / Engineering\nAbout the Role\nWe are looking for a skilled and motivated Software Engineer (Python) with 34 years of experience to join our engineering team\nYoull work closely with machine learning engineers, product managers, and fellow developers to build scalable, event-driven backend systems and services\nIf you're excited about building impactful products and working in a collaborative, fast-paced environment, we'd love to hear from you\nKey Responsibilities\nDevelop, deploy, and maintain microservices using Python\nDesign scalable and high-performance backend systems\nWork with both SQL and NoSQL databases to support data needs\nImplement event-driven architectures using Kafka or RabbitMQ\nUse Elasticsearch for search and analytics features\nSupport the deployment of machine learning inference pipelines\nWork with AWS and Kubernetes for infrastructure and deployment\nCollaborate with ML engineers to integrate models into production systems\nPartner with product managers to understand and implement requirements\nContribute to code quality, reviews, and system architecture discussions\nRequired Qualifications\nBachelors degree in Computer Science, Engineering, or a related field\n34 years of professional experience in software development using Python\nExperience designing and building microservices\nHands-on experience with:\nSQL & NoSQL databases (e g-, PostgreSQL, MySQL, MongoDB, Cassandra)\nMessaging systems (Kafka, RabbitMQ)\nElasticsearch\nAWS services\nKubernetes\nUnderstanding of event-driven systems and scalable architecture\nGood communication and teamwork skills\nNice to Have\nExperience with Python web frameworks (e g-, Flask, Django, FastAPI)\nFamiliarity with CI/CD pipelines\nExposure to ML model deployment or inferencing\nContributions to open-source projects\nShow more Show less",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'cd', 'django', 'ci/cd', 'mysql', 'aws', 'communication skills', 'sql']",2025-06-10 15:37:03
Data Analyst-Having Stratup-Mid-Size companies Exp.@ Bangalore_Urgent,"A leader in this space, we deliver world...",8 - 13 years,Not Disclosed,['Bengaluru'],"Data Analyst\n\nLocation: Bangalore\nExperience: 8 - 15 Yrs\nType: Full-time\n\nRole Overview\n\nWe are seeking a skilled Data Analyst to support our platform powering operational intelligence across airports and similar sectors. The ideal candidate will have experience working with time-series datasets and operational information to uncover trends, anomalies, and actionable insights. This role will work closely with data engineers, ML teams, and domain experts to turn raw data into meaningful intelligence for business and operations stakeholders.\n\nKey Responsibilities\n\nAnalyze time-series and sensor data from various sources\nDevelop and maintain dashboards, reports, and visualizations to communicate key metrics and trends.\nCorrelate data from multiple systems (vision, weather, flight schedules, etc) to provide holistic insights.\nCollaborate with AI/ML teams to support model validation and interpret AI-driven alerts (e.g., anomalies, intrusion detection).\nPrepare and clean datasets for analysis and modeling; ensure data quality and consistency.\nWork with stakeholders to understand reporting needs and deliver business-oriented outputs.\n\n\nQualifications & Required Skills\n\nBachelors or Masters degree in Data Science, Statistics, Computer Science, Engineering, or a related field.\n5+ years of experience in a data analyst role, ideally in a technical/industrial domain.\nStrong SQL skills and proficiency with BI/reporting tools (e.g., Power BI, Tableau, Grafana).\nHands-on experience analyzing structured and semi-structured data (JSON, CSV, time-series).\nProficiency in Python or R for data manipulation and exploratory analysis.\nUnderstanding of time-series databases or streaming data (e.g., InfluxDB, Kafka, Kinesis).\nSolid grasp of statistical analysis and anomaly detection methods.\nExperience working with data from industrial systems or large-scale physical infrastructure.\n\n\nGood-to-Have Skills\n\nDomain experience in airports, smart infrastructure, transportation, or logistics.\nFamiliarity with data platforms (Snowflake, BigQuery, Custom-built using open-source).\nExposure to tools like Airflow, Jupyter Notebooks and data quality frameworks.\nBasic understanding of AI/ML workflows and data preparation requirements.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Kafka', 'SQL', 'airports', 'InfluxDB', 'Airflow', 'structured Data', 'time-series', 'JSON', 'Tableau', 'Grafana', 'R', 'AI/ML', 'Kinesis', 'Snowflake', 'time-series databases', 'Data Preparation', 'Python', 'smart infrastructure', 'BigQuery', 'streaming data', 'Power BI', 'CSV', 'transportation', 'logistic', 'reporting tools']",2025-06-10 15:37:06
Data Analyst,Leading Client,4 - 6 years,Not Disclosed,['Chennai'],"3 - 6 years of experience performing quantitative analysis in the financial services industry preferred but not required.\nSkilled ""hands-on"" user of SAS, R, MATLAB, SQL, and/or other statistically programming language required.",Industry Type: Recruitment / Staffing,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'matlab', 'python', 'data analytics', 'natural language processing', 'sas', 'predictive analytics', 'machine learning', 'financial services', 'sql', 'tableau', 'r', 'data science', 'quantitative', 'predictive modeling', 'data visualization', 'quantitative analysis', 'statistics']",2025-06-10 15:37:08
Full Stack Engineer,Sense7ai,4 - 6 years,Not Disclosed,[],"As a Full Stack Engineer at Sense7AI, you will play a key role in developing, and deploying scalable, high-performance applications. Youll work in a predominantly AWS-focused environment, ensuring top-notch code quality and seamless deployment from ideation to production. Your expertise in React, React Native, Python, and AWS will drive business growth through user-centric innovation and robust system architecture.\nOffshore Project Dynamics:\nThis role involves working with an offshore client, requiring flexibility to align with IST or EST time zones based on project needs. Strong communication, adaptability, and collaboration across time zones are essential.\nKey Responsibilities:\n\nEnd-to-End Development: Design, implement, and deploy mobile and web applications with a focus on performance and scalability.\nCode Quality & Compliance: Write clean, efficient, and maintainable code, ensuring healthcare industry compliance where applicable.\nCollaboration & Coordination: Work closely with domain experts, designers, engineers, AWS specialists, and QA teams to develop seamless user experiences.\nTech Stack: Utilize React, React Native, TypeScript, Python, DynamoDB, and other modern technologies to build robust applications.\nCloud & API Development: Design, integrate, and maintain RESTful APIs while leveraging AWS Serverless (Lambda, DynamoDB) for scalable solutions.\nCross-Time Zone Communication: Effectively coordinate with offshore teams via Slack, email, and other collaboration tools.\n\nTechnical Proficiencies:\n\n4-6 years of experience in developing and deploying large-scale software solutions.\nFront-End: Strong expertise in React + Redux, JavaScript/TypeScript, React Native (3+ years).\nBack-End: Proficiency in Python for server-side logic and API development (3+ years).\nCloud Technologies: Hands-on experience with AWS (Lambda, DynamoDB, Serverless Architecture) (2+ years).\nDatabase Management: Solid understanding of NoSQL databases (DynamoDB, MongoDB, etc.).\nTesting & Debugging: Strong experience in unit testing, integration testing, and performance optimization.\nRESTful APIs: Proven experience in designing, developing, and integrating APIs for scalable applications.\n\nPreferred Experience:\n\nPython: 3+ years\nReact: 3+ years\nReact Native: 2+ years\nTypeScript: 2+ year\nJavaScript: 2+ year\nAWS (Serverless Architecture, Lambda, Dynamo DB): 2+ years\n\nBenefits:\nFlexibility at its best\nRecharge with flexible vacation days.\nComprehensive health insurance: Covers you, your family, and your parents.\nAnnual Performance bonus.\nOther Reimburse benefits.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Computer science', 'Health insurance', 'Compliance', 'GCP', 'Machine learning', 'data privacy', 'Open source', 'Forecasting', 'SQL', 'Python']",2025-06-10 15:37:11
