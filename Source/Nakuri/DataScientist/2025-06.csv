job_title,company,experience,salary,locations,description,industry,department,employment_type,skills,scraped_at
Data Scientist,AMERICAN EXPRESS,1 - 3 years,15-18 Lacs P.A.,"['Gurugram', 'Delhi / NCR']","You Lead the Way. Weve Got Your Back.\n\nWith the right backing, people and businesses have the power to progress in incredible ways. When you join Team Amex, you become part of a global and diverse community of colleagues with an unwavering commitment to back our customers, communities and each other. Here, youll learn and grow as we help you create a career journey thats unique and meaningful to you with benefits, programs, and flexibility that support you personally and professionally.",,,,"['Machine Learning', 'Python', 'SQL', 'Natural Language Processing', 'Ml']",2025-06-12 00:57:40
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Pune'],"As an Associate Data Scientist at IBM, you will work to solve business problems using leading edge and open-source tools such as Python, R, and TensorFlow, combined with IBM tools and our AI application suites. You will prepare, analyze, and understand data to deliver insight, predict emerging trends, and provide recommendations to stakeholders.\n\nIn your role, you may be responsible for:\nImplementing and validating predictive and prescriptive models and creating and maintaining statistical models with a focus on big data & incorporating machine learning. techniques in your projects\nWriting programs to cleanse and integrate data in an efficient and reusable manner\nWorking in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors\nCommunicating with internal and external clients to understand and define business needs and appropriate modelling techniques to provide analytical solutions.\nEvaluating modelling results and communicating the results to technical and non-technical audiences\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\nCollaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\nDocument solution architectures, design decisions, implementation details, and lessons learned.\nCreate technical documentation, white papers, and best practice guides\n\n\nPreferred technical and professional experience\nStrong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face.\nUnderstanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms\nExperience and working knowledge in COBOL & JAVA would be preferred",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'scikit-learn', 'tensorflow', 'pytorch', 'keras', 'natural language processing', 'neural networks', 'predictive', 'huggingface', 'machine learning', 'prototype', 'artificial intelligence', 'sql', 'pandas', 'deep learning', 'r', 'java', 'cobol', 'data science', 'matplotlib', 'big data', 'statistics']",2025-06-12 00:57:43
Data Scientist - L3,Wipro,3 - 5 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions.\n\n\n\nDo\n1. Demand generation through support in Solution development\na. Support Go-To-Market strategy\ni. Contribute to development solutions, proof of concepts aligned to key offerings to enable solution led sales\nb. Collaborate with different colleges and institutes for research initiatives and provide data science courses\n2. Revenue generation through Building & operationalizing Machine Learning, Deep Learning solutions\na. Develop Machine Learning / Deep learning models for decision augmentation or for automation solutions\nb. Collaborate with ML Engineers, Data engineers and IT to evaluate ML deployment options\n3. Team Management\na. Talent Management\ni. Support on boarding and training to enhance capability & effectiveness\n\n\n\nDeliver\n\nNo.Performance ParameterMeasure\n1.Demand generation# PoC supported\n2.Revenue generation through deliveryTimeliness, customer success stories, customer use cases\n3.Capability Building & Team Management# Skills acquired\n\n\n\n\n\n\nMandatory Skills: Data Analysis.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'ML deployment', 'Deep learning models', 'Solution development', 'Talent Management', 'Machine Learning']",2025-06-12 00:57:46
Data Scientist - L3,Wipro,3 - 5 years,Not Disclosed,['Ramdurg'],"Role Purpose\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions.\nDo\n1. Demand generation through support in Solution development\na. Support Go-To-Market strategy\ni. Contribute to development solutions, proof of concepts aligned to key offerings to enable solution led sales\nb. Collaborate with different colleges and institutes for research initiatives and provide data science courses\n2. Revenue generation through Building & operationalizing Machine Learning, Deep Learning solutions\na. Develop Machine Learning / Deep learning models for decision augmentation or for automation solutions\nb. Collaborate with ML Engineers, Data engineers and IT to evaluate ML deployment options\n3. Team Management\na. Talent Management\ni. Support on boarding and training to enhance capability & effectiveness\nDeliver\n\nNo.Performance ParameterMeasure\n1.Demand generation# PoC supported\n2.Revenue generation through deliveryTimeliness, customer success stories, customer use cases\n3.Capability Building & Team Management# Skills acquired\n\n\nMandatory Skills: Data Analysis.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'python', 'team management', 'natural language processing', 'scikit-learn', 'ml deployment', 'machine learning', 'data engineering', 'artificial intelligence', 'sql', 'deep learning', 'tensorflow', 'data science', 'predictive modeling', 'statistical modeling', 'ml']",2025-06-12 00:57:49
Data Scientist,Wipro,2 - 7 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of this role is to design, test and maintain software programs for operating systems or applications which needs to be deployed at a client end and ensure its meet 100% quality assurance parameters\nDo\nInstrumental in understanding the requirements and design of the product/ software\nDevelop software solutions by studying information needs, studying systems flow, data usage and work processes\nInvestigating problem areas followed by the software development life cycle\nFacilitate root cause analysis of the system issues and problem statement\nIdentify ideas to improve system performance and impact availability\nAnalyze client requirements and convert requirements to feasible design\nCollaborate with functional teams or systems analysts who carry out the detailed investigation into software requirements\nConferring with project managers to obtain information on software capabilities\nPerform coding and ensure optimal software/ module development\nDetermine operational feasibility by evaluating analysis, problem definition, requirements, software development and proposed software\nDevelop and automate processes for software validation by setting up and designing test cases/scenarios/usage cases, and executing these cases\nModifying software to fix errors, adapt it to new hardware, improve its performance, or upgrade interfaces.\nAnalyzing information to recommend and plan the installation of new systems or modifications of an existing system\nEnsuring that code is error free or has no bugs and test failure\nPreparing reports on programming project specifications, activities and status\nEnsure all the codes are raised as per the norm defined for project / program / account with clear description and replication patterns\nCompile timely, comprehensive and accurate documentation and reports as requested\nCoordinating with the team on daily project status and progress and documenting it\nProviding feedback on usability and serviceability, trace the result to quality risk and report it to concerned stakeholders\nStatus Reporting and Customer Focus on an ongoing basis with respect to project and its execution\nCapturing all the requirements and clarifications from the client for better quality work\nTaking feedback on the regular basis to ensure smooth and on time delivery\nParticipating in continuing education and training to remain current on best practices, learn new programming languages, and better assist other team members.\nConsulting with engineering staff to evaluate software-hardware interfaces and develop specifications and performance requirements\nDocument and demonstrate solutions by developing documentation, flowcharts, layouts, diagrams, charts, code comments and clear code\nDocumenting very necessary details and reports in a formal way for proper understanding of software from client proposal to implementation\nEnsure good quality of interaction with customer w.r.t. e-mail content, fault report tracking, voice calls, business etiquette etc\nTimely Response to customer requests and no instances of complaints either internally or externally\nStakeholder Interaction\n\nStakeholder Type\nStakeholder Identification\nPurpose of Interaction\nInternal\nLead Software Developer and Project Manager\nRegular reporting & updates\nSoftware Developers\nFor work coordination and support in providing testing solutions\nExternal\nClients\nProvide apt solutions and support as per the requirement\nDisplay\nLists the competencies required to perform this role effectively:\nFunctional Competencies/ Skill\nLeveraging Technology Knowledge of current and upcoming technology along with expertise in programming (automation, tools and systems) to build efficiencies and effectiveness in own function/ Client organization Competent\nProcess Excellence - Ability to follow the standards and norms to produce consistent results, provide effective control and reduction of risk Expert\nTechnical knowledge knowledge of various programming languages, tools, quality management standards and processes - Expert\n\nCompetency Levels\nFoundation\nKnowledgeable about the competency requirements. Demonstrates (in parts) frequently with minimal support and guidance.\nCompetent\nConsistently demonstrates the full range of the competency without guidance. Extends the competency to difficult and unknown situations as well.\nExpert\nApplies the competency in all situations and is serves as a guide to others as well.\nMaster\nCoaches others and builds organizational capability in the competency area. Serves as a key resource for that competency and is recognised within the entire organization.\nBehavioral Competencies\nFormulation & Prioritization\nInnovation\nManaging Complexity\nExecution Excellence\nPassion for Results\nDeliver / No. / Performance Parameter / Measure -\n1. Continuous Integration, Deployment & Monitoring of Software\n100% error free on boarding & implementation, throughput %, Adherence to the schedule/ release plan\n2. Quality & CSAT\nOn-Time Delivery, Manage software, Troubleshoot queries\nCustomer experience, completion of assigned certifications for skill upgradation\n3. MIS & Reporting\n100% on time MIS & report generation\nMandatory Skills: Python, GenAI, AWS\nPreferred Skills: NLP , AI/ML , LLM\nArchitect and implement Al solutions utilizing cutting-edge technologies like LLM, Langchain, and Machine Learning.\nAIML solution development in Azure using Python\nAbility to build and finetune the model to improve the performance\nCreate own technology if off-the-shelf technology is not solving the problem. E.g changes to traditional RAG approaches, finetune LLM, create architectures.\nUse experience and advise leadership and team of data scientists best approaches, architectures for complex ML use cases.\nLead from the front, responsible for coding, designing, and ensuring best practices & frameworks are adhered by the team.\nCreate end to end AI systems with responsible AI principles\nDevelop data pipelines using SQL to extract and transform data from Snowflake for Al model training and inference.\nPossess expertise in Natural Language Processing (NLP) & GenAI to integrate text-based data sources into the Al architecture.\nCollaborate with data scientists and engineers to ensure seamless integration of Al components into existing systems.\nResponsible for continuous communication about the team progress to keystakeholder.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'GenAI', 'NLP', 'Artificial Intelligence', 'LLM', 'AWS', 'Machine Learning', 'Python']",2025-06-12 00:57:53
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"As an Data Engineer at IBM you will harness the power of data to unveil captivating stories and intricate patterns. You'll contribute to data gathering, storage, and both batch and real-time processing.\n\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis. As a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\n\n In this role, your responsibilities may include: \nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviours’.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modelling results\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another\nDocument solution architectures, design decisions, implementation details, and lessons learned.\nStay up to date with the latest trends and advancements in AI, foundation models, and large language models.\nEvaluate emerging technologies, tools, and frameworks to assess their potential impact on solution design and implementation\n\n\nPreferred technical and professional experience\nExperience and working knowledge in COBOL & JAVA would be preferred\nHaving experience in Code generation, code matching & code translation leveraging LLM capabilities would be a Big plus\nDemonstrate a growth mindset to understand clients' business processes and challenges",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['elastic search', 'java', 'proof of concept', 'cobol', 'splunk', 'targetlink', 'simulink', 'data management', 'stateflow', 'sil', 'big data', 'can bus', 'matlab', 'python', 'c', 'predictive', 'machine learning', 'presales', 'autosar', 'code generation', 'rtw', 'rfi', 'embedded c', 'model based development', 'rfp']",2025-06-12 00:57:57
Data Scientist,Capgemini,4 - 7 years,Not Disclosed,['Pune'],"\n\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.\n1. Applies scientific methods to analyse and solve software engineering problems.\n2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.\n3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.\n4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.\n5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.\nWorks in the area of Software Engineering, which encompasses the development, maintenance and optimization of software solutions/applications.1. Applies scientific methods to analyse and solve software engineering problems.2. He/she is responsible for the development and application of software engineering practice and knowledge, in research, design, development and maintenance.3. His/her work requires the exercise of original thought and judgement and the ability to supervise the technical and administrative work of other software engineers.4. The software engineer builds skills and expertise of his/her software engineering discipline to reach standard software engineer skills expectations for the applicable role, as defined in Professional Communities.5. The software engineer collaborates and acts as team player with other software engineers and stakeholders.\n\n - Grade Specific \nIs highly respected, experienced and trusted. Masters all phases of the software development lifecycle and applies innovation and industrialization. Shows a clear dedication and commitment to business objectives and responsibilities and to the group as a whole. Operates with no supervision in highly complex environments and takes responsibility for a substantial aspect of Capgeminis activity. Is able to manage difficult and complex situations calmly and professionally. Considers the bigger picture when making decisions and demonstrates a clear understanding of commercial and negotiating principles in less-easy situations. Focuses on developing long term partnerships with clients. Demonstrates leadership that balances business, technical and people objectives. Plays a significant part in the recruitment and development of people.\n\n Skills (competencies) \n\nVerbal Communication",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'deep learning', 'data science', 'gsm', 'rf engineering', 'data analysis', 'artificial intelligence', 'r', 'rf optimization', '3g', 'predictive modeling', 'lte', 'rf planning', 'statistics', 'drive test']",2025-06-12 00:58:01
Data Scientist - Cybersecurity,Visa,2 - 7 years,Not Disclosed,['Bengaluru'],"As part of Cyber Threat Analytics and Research team (CTAR) , you will leverage cutting-edge technologies to perform statistical profiling, inference, classification, clustering and predictive analysis. As a key member of the technical team, you will create and implement sophisticated machine learning models to help derive new insights to defend against cyber-attacks. You will be working with a large variety of data sets, cutting-edge security technologies, and world-class operation teams to create awesome analytics for security and other business units.\n  Essential Functions:\nAnalyze cyber event logs using Spark and big data technologies and develop deeper insights into products using advanced statistical methods.\nFormulate cyber threat scenarios into technical data problems and develop high fidelity models to capture unseen threats\nDevise and implement deep learning models for building user behavior profiles. This includes data acquisition, feature engineering, model development, and deployment.\nConduct feature engineering on various data sources to build and enrich feature store\nFine tune open source LLM to detect anomalous user behavior\nLeverage Generative AI to perform RAG for helping improve Cyber investigation efficiency\nAs a member of the CTAR team, you will work closely with other data scientists and data engineers to build, design, engineer, and develop analytical software and services that deliver security functionality and improve security efficiency and capabilities through automation.\nAssist in shaping overall direction, life-cycle management, and leadership for Information Security architecture and technology related to Visa.\nCommunicate clean and persuasive data directly to end users, leadership, and other stakeholders, technical and non-technical.\n\n\n\nBasic Qualifications:\n2+ years of relevant work experience and a Bachelors degree, OR 5+ years of relevant work experience\n\nPreferred Qualifications:\n3 or more years of work experience with a Bachelor s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD)\nSolid background and hands on experiences with building Machine learning, deep learning and AI models\nExperience with Generative AI/LLM\nExcellent understanding of algorithms and data structures and proficiency in Python and SQL.\nExperience working with large datasets using tools and Hadoop, Spark, or Hive\nExcellent analytic and problem-solving capability combined with ambition to solve hard problems\nStrong communications skills and ability to collaborate\nHighly driven, resourceful and results oriented\nGood team player and excellent interpersonal skills\nDemonstrated ability to lead and navigate through ambiguity",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Automation', 'Information security', 'Analytical', 'Machine learning', 'Data structures', 'Open source', 'Analytics', 'Monitoring', 'SQL', 'Python']",2025-06-12 00:58:04
Data Scientist - L3,Wipro,3 - 6 years,Not Disclosed,['Bengaluru'],"Wipro Limited (NYSEWIT, BSE507685, NSEWIPRO) is a leading technology services and consulting company focused on building innovative solutions that address clients’ most complex digital transformation needs. Leveraging our holistic portfolio of capabilities in consulting, design, engineering, and operations, we help clients realize their boldest ambitions and build future-ready, sustainable businesses. With over 230,000 employees and business partners across 65 countries, we deliver on the promise of helping our customers, colleagues, and communities thrive in an ever-changing world. For additional information, visit us at www.wipro.com.\n About The Role  \n\nRole Purpose\n\nThe purpose of the role is to define, architect and lead delivery of machine learning and AI solutions.\n\n ? \n\nDo\n\n1. Demand generation through support in Solution development\n\na. Support Go-To-Market strategy\n\ni. Contribute to development solutions, proof of concepts aligned to key offerings to enable solution led sales\n\nb. Collaborate with different colleges and institutes for research initiatives and provide data science courses\n\n2. Revenue generation through Building & operationalizing Machine Learning, Deep Learning solutions\n\na. Develop Machine Learning / Deep learning models for decision augmentation or for automation solutions\n\nb. Collaborate with ML Engineers, Data engineers and IT to evaluate ML deployment options\n\n3. Team Management\n\na. Talent Management\n\ni. Support on boarding and training to enhance capability & effectiveness\n\n ? \n\nDeliver\n\n\nNo.\n\nPerformance Parameter\n\nMeasure 1. Demand generation # PoC supported 2. Revenue generation through delivery Timeliness, customer success stories, customer use cases 3. Capability Building & Team Management # Skills acquired\n\n\n ? \n\n ? \nMandatory\n\nSkills:\nData Analysis.\n\nExperience3-5 Years.\n\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data analysis', 'machine learning', 'deep learning', 'data science', 'ml', 'python', 'natural language processing', 'scikit-learn', 'neural networks', 'ml deployment', 'data engineering', 'artificial intelligence', 'sql', 'tensorflow', 'r', 'predictive modeling', 'statistical modeling', 'statistics']",2025-06-12 00:58:07
Data Scientist,Simplify Healthcare,5 - 10 years,Not Disclosed,"['Pune( Hadapsar, Kharadi, Keshav Nagar, Vishrantwadi, Dhanori, Mundhwa, Viman Nagar )']","Engineer/Sr. Engineer Data Science\nLocation: Pune, India\n\nCompany Overview:\nSimplify Healthcare is one of the fastest-growing healthcare technology solutions providers serving the US health insurance (Payer) industry. Headquartered in Chicago with a Global Delivery Centre in Pune, we are trusted by 65+ payer organizations and supported by a team of 800+ professionals.\nWe specialize in delivering SaaS-based enterprise software solutions focused on product and benefits configuration, provider lifecycle management, and more. In 2023, we launched Simplify Health Cloud, our flagship Payer Platform, establishing our position as a leader in cloud-native, low-code configurable platforms for the healthcare sector.\nWith our strategic acquisition of Virtical.ai in 2024, we’re accelerating innovation through AI integration, particularly in areas such as LLMs, conversational AI, and cloud-based intelligence. Our proprietary Simplify App Fabric™ enables fast, secure, and low-code development for modern Payer solutions.\nOur innovation has earned us repeated recognition in Deloitte Technology Fast 500™, Inc. 5000, and reports by IDC and Gartner.",,,,"['Speech Recognition', 'Artificial Intelligence', 'Natural Language Processing', 'Conversational Ai', 'Chatbot', 'Cognitive Services', 'Text Mining', 'Machine Learning', 'Azure Cognitive Services']",2025-06-12 00:58:10
Data Scientist-Artificial Intelligence,IBM,3 - 7 years,Not Disclosed,['Bengaluru'],"An AI Data Scientist at IBM is not just a job title - it’s a mindset. You’ll leverage the watsonx,AWS Sagemaker,Azure Open AI platform to co-create AI value with clients, focusing on technology patterns to enhance repeatability and delight clients.\n\nWe are seeking an experienced and innovative AI Data Scientist to be specialized in foundation models and large language models. In this role, you will be responsible for architecting and delivering AI solutions using cutting-edge technologies, with a strong focus on foundation models and large language models. You will work closely with customers, product managers, and development teams to understand business requirements and design custom AI solutions that address complex challenges. Experience with tools like Github Copilot, Amazon Code Whisperer etc. is desirable.\n\nSuccess is our passion, and your accomplishments will reflect this, driving your career forward, propelling your team to success, and helping our clients to thrive.\n\nDay-to-Day Duties:\nProof of Concept (POC) DevelopmentDevelop POCs to validate and showcase the feasibility and effectiveness of the proposed AI solutions. Collaborate with development teams to implement and iterate on POCs, ensuring alignment with customer requirements and expectations.\nHelp in showcasing the ability of Gen AI code assistant to refactor/rewrite and document code from one language to another, particularly COBOL to JAVA through rapid prototypes/ PoC\nDocumentation and Knowledge SharingDocument solution architectures, design decisions, implementation details, and lessons learned. Create technical documentation, white papers, and best practice guides. Contribute to internal knowledge sharing initiatives and mentor new team members.\nIndustry Trends and InnovationStay up to date with the latest trends and advancements in AI, foundation models, and large language models. Evaluate emerging technologies, tools, and frameworks to assess their potential impact on solution design and implementation\n\n\nRequired education\nBachelor's Degree\n\nPreferred education\nMaster's Degree\n\nRequired technical and professional expertise\nStrong programming skills, with proficiency in Python and experience with AI frameworks such as TensorFlow, PyTorch, Keras or Hugging Face. Understanding in the usage of libraries such as SciKit Learn, Pandas, Matplotlib, etc. Familiarity with cloud platforms (e.g. Kubernetes, AWS, Azure, GCP) and related services is a plus.\nExperience and working knowledge in COBOL & JAVA would be preferred\no Having experience in Code generation, code matching & code translation leveraging LLM capabilities would be a Big plus (e.g. Amazon Code Whisperer, Github Copilot etc.) Soft\n\nSkills:\nExcellent interpersonal and communication skills. Engage with stakeholders for analysis and implementation. Commitment to continuous learning and staying updated with advancements in the field of AI.\nGrowth mindsetDemonstrate a growth mindset to understand clients' business processes and challenges.\nExperience in python and pyspark will be added advantage\n\n\nPreferred technical and professional experience\nExperienceProven experience in designing and delivering AI solutions, with a focus on foundation models, large language models, exposure to open source, or similar technologies. Experience in natural language processing (NLP) and text analytics is highly desirable. Understanding of machine learning and deep learning algorithms.\nStrong track record in scientific publications or open-source communities\nExperience in full AI project lifecycle, from research and prototyping to deployment in production environments",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'machine learning', 'tensorflow', 'pytorch', 'keras', 'kubernetes', 'github', 'natural language processing', 'scikit-learn', 'pyspark', 'microsoft azure', 'artificial intelligence', 'text analytics', 'pandas', 'deep learning', 'java', 'code generation', 'cobol', 'gcp', 'matplotlib', 'aws']",2025-06-12 00:58:13
Hdfc Bank - Digital Banking - Data Scientist - Generative AI,Hdfc Bank,4 - 9 years,Not Disclosed,['Mumbai (All Areas)'],"Role - Digital Banking-Data Scientist-Digital Experience Analytics\n\nLocation - Mumbai\nGrade - Deputy Manager to Senior Manager\nMinimum 4 years experience\n\nJob Purpose:\nThe Data Scientist will design, develop and deploy advanced AI models to drive digital transformation, enhance customer experience, optimize operations and mitigate risks. This role requires a sound understanding of AI/ML techniques and their application to challenges such as customer engagement and process automation.",,,,"['Data Science', 'Artificial Intelligence', 'Machine Learning', 'Generative AI', 'Risk Analytics', 'Data Analytics']",2025-06-12 00:58:17
Data Scientist,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Data Scientist is an advanced subject matter expert, tasked with taking accountability in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nResponsible for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources\nProvides meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nDirects scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualizes the output of the models.\nResponsible for ensuring that industry standards best practices are applied to development activities.\nKnowledge and Attributes:\nAdvanced understanding of data modelling, statistical methods and machine learning techniques.\nStrong ability to thrive in a dynamic, fast-paced environment.\nStrong quantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nAdvanced understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nStrong ability to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nStrong ability to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming certification preferred.\nAgile certification preferred.\nRequired Experience:\nAdvanced demonstrated experience in a data science position in a corporate environment and/or related industry.\nAdvanced demonstrated experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nAdvanced demonstrated experience in programming languages (R, Python, etc.).\nAdvanced demonstrated experience working with and creating data architectures.\nAdvanced demonstrated experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nAdvanced demonstrated experience visualizing and/or presenting data for stakeholder use and reuse across the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'R', 'data modelling', 'data mining', 'statistical modelling', 'machine learning', 'Python', 'SQL']",2025-06-12 00:58:20
Data Scientist For DMAI,Prodapt Solutions,2 - 5 years,Not Disclosed,['Chennai'],"Overview\n\nThe Senior Data Science Engineer will leverage advanced data science techniques to solve complex business problems, guide decision-making processes, and mentor junior team members. This role requires a combination of technical expertise in data analysis, machine learning, and project management skills.\n\nResponsibilities\n\n Data Analysis and Modeling Analyze large-scale telecom datasets to extract actionable insights and build predictive models for network optimization and customer retention.\n Conduct statistical analyses  to validate models and ensure their effectiveness.\n Machine Learning Development Design and implement machine learning algorithms for fraud detection, churn prediction, and network failure analysis.\n Telecom-Specific Analytics Apply domain knowledge to improve customer experience by analyzing usage patterns, optimizing services, and predicting customer lifetime value.\n ETL Processes Develop robust pipelines for extracting, transforming, and loading telecom data from diverse sources.\n Collaboration Work closely with data scientists, software engineers, and telecom experts to deploy solutions that enhance operational efficiency.\n Data Governance :  Ensure data integrity, privacy, security and compliance with industry standards\n\n\nAdvanced degree in Data Science, Statistics, Computer Science, or a related field.\nExtensive experience in data science roles with a strong focus on machine learning and statistical modeling.\nProficiency in programming languages such as Python or R and strong SQL skills.\nFamiliarity with big data technologies (e.g., Hadoop, Spark) is advantageous.\nExpertise in cloud platforms such as AWS or Azure.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['project management', 'data analysis', 'machine learning', 'sql', 'statistical modeling', 'algorithms', 'python', 'big data technologies', 'microsoft azure', 'cloud platforms', 'r', 'data science', 'spark', 'data governance', 'hadoop', 'aws', 'etl', 'machine learning algorithms', 'statistics']",2025-06-12 00:58:23
Data Scientist,THERMAX,2 - 3 years,Not Disclosed,['Pune'],Job Details:\nWe are seeking a highly motivated and enthusiastic Junior Data Scientist with 2-3 years of experience to join our data science team. This role offers an exciting opportunity to contribute to both traditional Machine Learning projects for our commercial IoT platform and cutting-edge Generative AI initiatives.\n\nExperience,,,,"['Tensorflow', 'Manufacturing', 'Machine Learning', 'IOT', 'Python', 'Pytorch', 'Data Science', 'Aiml', 'Scikit-Learn', 'Ml']",2025-06-12 00:58:26
Specialist Data Scientist,NICE,8 - 11 years,Not Disclosed,['Pune'],"So, what’s the role all about?\nNICE provides state-of-the-art enterprise level AI and analytics for all forms of business communications between speech and digital.   We are a world class research team developing new algorithms and approaches to help companies with solving critical issues such as identifying their best performing agents, preventing fraud, categorizing customer issues, and determining overall customer satisfaction.  If you have interacted with a major contact center in the last decade, it is very likely we have processed your call. \nThe research group partners with all areas of NICE’s business to scale out the delivery of new technology and AI models to customers around the world that are tailored to their company, industry, and language needs.",,,,"['python', 'confluence', 'natural language processing', 'presentation skills', 'big data technologies', 'pyspark', 'microsoft azure', 'bert', 'machine learning', 'sql', 'tensorflow', 'data science', 'gcp', 'pytorch', 'machine learning algorithms', 'aws', 'big data', 'communication skills', 'statistics', 'jira']",2025-06-12 00:58:30
Data Scientist - SCB,Wipro,8 - 10 years,Not Disclosed,['Chennai'],"About The Role  \n\nRole Purpose\n\nThe purpose of the role is to create exceptional architectural solution design and thought leadership and enable delivery teams to provide exceptional client engagement and satisfaction.\n\n\n ? \n\nMandatory Skills\n\nData Science, ML, DL, NLP or Computer Vision, Python, Tensorflow, Pytorch, Django, PostgreSQL\n\nPreferred Skills\n\nGen AI, LLM, RAG, Lanchain, Vector DB, Azure Cloud, MLOps, Banking exposure\n\n\n ? \n\n \n\n3.Competency Building and Branding  \nEnsure completion of necessary trainings and certifications\nDevelop Proof of Concepts (POCs),case studies, demos etc. for new growth areas based on market and customer research\nDevelop and present a point of view of Wipro on solution design and architect by writing white papers, blogs etc.\nAttain market referencability and recognition through highest analyst rankings, client testimonials and partner credits\nBe the voice of Wipro’s Thought Leadership by speaking in forums (internal and external)\nMentor developers, designers and Junior architects in the project for their further career development and enhancement\nContribute to the architecture practice by conducting selection interviews etc\n\n\n ? \n\nMandatory\nStrong understanding of Data Science, machine learning and deep learning principles and algorithms.\nProficiency in programming languages such as Python, TensorFlow, and PyTorch.\nAbility to work with large datasets and knowledge of data preprocessing techniques.\nStrong Backend Python developer\nExperience in applying machine learning techniques,\n\nNatural Language Processing or Computer Vision using TensorFlow, Pytorch\nBuild and deploy end to end ML models and leverage metrics to support predictions, recommendations, search, and growth strategies\nExpert in applying ML techniques such asclassification, clustering, deep learning, optimization methods, supervised and unsupervised techniques\nOptimize model performance and scalability for real-time inference and deployment.\nExperiment with different hyperparameters and model configurations to improve AI model quality.\nEnsure AI ML solutions are developed, and validations are performed in accordance with Responsible AI guidelines.\n\n\n ? \n\n \n\n4.Team Management  \n\n Resourcing  \nAnticipating new talent requirements as per the market/ industry trends or client requirements\nHire adequate and right resources for the team\nTalent Management\nEnsure adequate onboarding and training for the team members to enhance capability & effectiveness\nBuild an internal talent pool and ensure their career progression within the organization\nManage team attrition\nDrive diversity in leadership positions\nPerformance Management\nSet goals for the team, conduct timely performance reviews and provide constructive feedback to own direct reports\nEnsure that the Performance Nxt is followed for the entire team\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nMandatory\n\nSkills:\nGenerative AI.\n\nExperience8-10 Years.\n\nReinvent your world. We are building a modern Wipro. We are an end-to-end digital transformation partner with the boldest ambitions. To realize them, we need people inspired by reinvention. Of yourself, your career, and your skills. We want to see the constant evolution of our business and our industry. It has always been in our DNA - as the world around us changes, so do we. Join a business powered by purpose and a place that empowers you to design your own reinvention. Come to Wipro. Realize your ambitions. Applications from people with disabilities are explicitly welcome.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['python', 'natural language processing', 'machine learning', 'deep learning', 'tensorflow', 'algorithms', 'dl', 'azure cloud', 'sql', 'gen', 'django', 'data science', 'postgresql', 'predictive modeling', 'computer vision', 'pytorch', 'statistical modeling', 'vector', 'clustering', 'db', 'ml', 'statistics']",2025-06-12 00:58:34
Data Scientist / Machine Learning Professional,Infosys,6 - 8 years,Not Disclosed,['Bengaluru'],"Responsibilities\nJob Title:\nLead Analyst - Data Science (Intermediate/Senior)Role Summary:\nWe are looking for candidates to build and implement analytics solutions to our esteemed clients. The incumbent should have strong aptitude for numbers, experience in any domain and willingness to learn some cutting edge technologies\nTechnical and Professional Requirements:\nOther key to have Skills:\nSQL knowledge and experience working with relational databases.\nUnderstanding of any one of domain (Eg: Retail, Supply chain, Logistics, Manufacturing).\nUnderstanding of the project lifecycles: waterfall and agile.\nSoft Skills:\nStrong verbal and written communication skills with the ability to work well in a team.\nStrong customer focus, ownership, urgency and drive.\nAbility to handle multiple, competing priorities in a fast-paced environment.\nWork well with the team members to maintain high credibility\nWork Experience:\nOverall 6-8 of years of experience in Data Analytics, Data Science and Machine Learning.\nEducational Requirements (any of the following):\nBachelor of Engineering/Bachelor of Technology in any stream with consistent academic track record.\nBachelor's degree in a quantitative discipline (e.g., Statistics, Economics, Mathematics, Marketing Analytics) or significant relevant coursework with consistent academic track record.\nPreferred Skills:\nTechnology->Data Science->Machine Learning\nAdditional Responsibilities:\nAdditional Academic Qualification (good to have):\nMasters in any area related to Science, Mathematics, Statistics, Economy and Finance with consistent academic track record.\nPhD in any stream.Location:\nBangalore, Pune, Hyderabad, Chennai, Trivandrum, Mysore\nEducational Requirements\nMCA,MSc,Bachelor of Engineering,BBA,BCom\nService Line\nData & Analytics Unit\n* Location of posting is subject to business requirements",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'waterfall', 'Data Scientist', 'agile', 'Data Analytics', 'relational databases', 'SQL']",2025-06-12 00:58:38
Data Scientist,Global Banking Organization,15 - 18 years,Not Disclosed,['Gurugram'],"Key Skills: Pyspark, Python, Data Visualization\nRoles and Responsibilities:\nBuild and deploy predictive and event-based models to improve marketing effectiveness.\nLead the use of data science techniques to derive customer insights and drive decision-making.\nDesign and develop advanced feature engineering pipelines and feature stores for Marketing use cases.\nLeverage online and offline customer data, digital interactions, and demographics to develop targeted marketing strategies.\nCollaborate with stakeholders including data scientists, engineers, architects, and business teams to deliver impactful data science solutions.\nDeliver insights using advanced data visualization tools and effectively communicate findings to senior stakeholders.\nContinuously explore and implement new analytics methodologies to solve emerging business challenges.\nPromote a culture of data innovation, standardization, and reusability across the Marketing Data Science team.\nSkills Required:\nStrong enthusiasm for analytics and data science with a continuous learning mindset.\nProven experience in solving business problems using machine learning and statistical methods.\nStrategic thinking with a customer-centric focus.\nExcellent problem-solving and documentation skills.\nStrong interpersonal, collaboration, and stakeholder management skills.\nAbility to clearly articulate complex technical concepts to non-technical audiences.\nProficient in:\nPython, PySpark, SQL\nSpark MLlib, Data Science Libraries (e.g., Scikit-learn, XGBoost, etc.)\nData visualization tools (e.g., Tableau, Power BI, Plotly, Matplotlib)\nCloud platforms (Databricks preferred; AWS, Azure, or GCP acceptable)\nSource code control using GitHub\nRequired Experience:\n15+ years of experience in leading data science or machine learning teams.\nProven track record of deploying scalable ML models and delivering measurable business outcomes.\nHands-on experience working with structured, semi-structured, and unstructured data.\nStrong background in customer and marketing data analytics.\nDeep understanding of AI/ML trends and their business applications.\nExperience presenting insights and data-driven recommendations to senior stakeholders.\nDesirable Experience:\nExperience with Adobe Analytics or other digital analytics tools.\nPrior work in financial services or customer lifecycle marketing analytics.\nDevelopment and implementation of AI/ML roadmaps.\nExperience driving continuous improvement in data science practice and innovation culture.\nEducation:\nBachelor's or Master's degree in Statistics, Mathematics, Computer Science, Economics, Engineering, or related fields.\nEvidence of ongoing professional development through certifications or short courses in Data Science or AI.",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pyspark', 'Data Visualization', 'Python']",2025-06-12 00:58:42
Data Scientist,Puresoftware Technology,8 - 13 years,Not Disclosed,['Bengaluru( Whitefield )'],"Job Title: Data Scientist(5 Positions)/ Lead OR Manager -Data Scientist (3 positions)\n\nExperience: Data scientist (8-10 years) / Lead Data scientist(14+ years)\n\nJob Location: Whitefield, Bangalore\nMode of working: Hybrid\n\nInterview Process: First Round: L1-Internal interview\nSecond Round: Assessment shared by us needs to be completed in 48 hours\nThird Round: Client discussion over the submitted assessment.\nFinal Round: HR Discussion\n\nPreferred Domain: Healthcare Insurance/ Insurance agencies / Health Insurance / Any Insurance\n\nWe are looking for a talented Data Scientist to join our growing team. In this role, you will lead efforts to develop, enhance, and optimize advanced AI and machine learning models with a particular focus on Generative AI, Large Language Models (LLMs), Langchain, and Prompt Engineering. You will oversee the application of statistical modeling techniques to derive insights, build models, and lead research initiatives that push the boundaries of AI technologies.\n\nKey Responsibilities:\nLeadership & Collaboration: Lead a team of data scientists, researchers, and engineers working on high-impact projects related to generative models, NLP, and statistical modeling. Collaborate with cross-functional teams, including engineering, product management, and research, to deliver AI-powered products and solutions.\nGenerative AI Development: Spearhead the development and deployment of Generative AI models and algorithms to address complex problems in areas like content generation, conversational AI, and creative automation.\nLLM Implementation & Optimization: Develop, fine-tune, and optimize large language models (LLMs) for diverse applications, ensuring they are robust, scalable, and accurate in real-world scenarios.\nLangchain Integration: Design and integrate Langchain for managing and deploying sophisticated language models with a focus on complex workflows, multi-agent systems, and real-time applications.\nPrompt Engineering: Lead prompt engineering efforts to optimize AI models' output quality, improve interactions, and enable more effective natural language understanding across a variety of use cases.\nStatistical Modeling: Utilize advanced statistical techniques to analyze and interpret data, build predictive models, and solve business-critical challenges through data-driven insights.\nResearch & Innovation: Stay ahead of trends in AI and ML, particularly in the fields of NLP, LLMs, and generative models. Drive innovation by exploring cutting-edge techniques and methodologies in the AI space.\nMentorship & Knowledge Sharing: Mentor junior team members and promote a collaborative, learning-oriented environment. Share knowledge and foster an atmosphere of continuous improvement within the data science team.\nPerformance Optimization: Ensure model performance meets or exceeds company and client expectations by identifying areas of improvement, testing new methods, and scaling the systems accordingly.\nEthical AI Development: Advocate for and implement ethical considerations in the development and deployment of AI models, including fairness, transparency, and privacy.\n\nQualifications:\nRequired:\nEducation: Ph.D. or Masters degree in Computer Science, Data Science, Mathematics, Statistics, or related field, or equivalent practical experience.\nExperience:\n8+ years of experience in data science, with at least 2-3 years in a leadership role.\nProven expertise in Generative AI, particularly in areas like content generation, deep learning, and language modeling.\nStrong background in Large Language Models (LLMs) such as GPT, T5, BERT, or similar architectures.\nHands-on experience with Langchain for building NLP workflows, pipelines, and integrating external systems with LLMs.\nHands-on experience of Prompt Engineering, including techniques to refine and optimize outputs for various NLP tasks.\nExpertise in statistical modeling and quantitative analysis, with the ability to apply techniques to solve real-world problems.\n\nPreferred:\nExperience working with transformer models and fine-tuning LLMs for specific tasks.\nExpertise in AI model evaluation and metrics (e.g., BLEU, ROUGE, perplexity).\nBackground in developing AI-driven products from concept to deployment.\nStrong publication record in AI research, particularly in NLP and machine learning.\n\nUsed cases( Any of them)\nAutomated Underwriting.\nCustomer experience enhancement.\nFraud detection.\nPredictive analytics.\nAccelerated claims processing.\nRisk assessment and premium calculation.\nCustomer profiling.\ncustomer segmentation.\nCredit Risk Assessment.\nPersonalised marketing .\nAnti-Money Laundering (AML).\nPersonalized patient care.\nMedical training and simulations.\nMedical Data Analysis.\n\nPlease share your updated resume at renuka.rathi@puresoftware.com",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Generative Ai', 'data scientist', 'statistical modelling', 'Predictive Modeling', 'Customer profiling', 'Healthcare Insurance', 'Customer Segmentation', 'Automated Underwriting', 'Insurance Domain', 'Credit Risk Assessment', 'insurance agency', 'Fraud detection', 'Healthcare Domain']",2025-06-12 00:58:44
Data Scientist,Ltimindtree,7 - 12 years,Not Disclosed,['Hyderabad'],Data Scientist\n\nJob Description\n\nResponsibilities\n\nWork with team members across multiple disciplines to understand the data behind product features user behaviors the security landscape and our goals\nAnalyze data from several large sources then automate solutions using scheduled processes models and alerts\nWork with partners to design and improve metrics that guide our decisions for the product\nDetect patterns associated with fraudulent accounts and anomalous behavior\nSolve scientific problems and create new methods independently\nTranslate requirements and security questions into data insights\nSet up alerting mechanisms so our leadership is always aware of the security posture\n\nQualifications\n\nPostgraduate degree with specialization in machine learning artificial intelligence statistics or related fields or 2 years of equivalent work experience in applied machine learning and analytics\nExperience with SQL Snowflake and NoSQL databases\nProficiency in Python programming\nFamiliarity with statistics modeling and data visualization\n\nExperience\n\nExperience building statistical and machine learning models applying techniques such as regression classification clustering and anomaly detection Time series and Classical ML modeling\nFamiliarity with Snowflake SQL\nFamiliarity with cloud platforms such as AWS\nSome experience to software development or data engineering\nAnalyze business problems or research questions identify relevant data points and extract meaningful insights,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Snowflake Sql', 'AWS']",2025-06-12 00:58:47
Data Scientist,Devon Software Services,3 - 7 years,12-19 Lacs P.A.,['Bengaluru'],"What you will do\nBuild end-to-end machine learning models to solve business problems in Marketing\nPerform feature engineering and support data engineering to build robust data pipelines on large marketing datasets from different sources\nCollaborate with ML Engineering to build ML Pipelines to Train, Test, Deploy, Serve and Monitor models, Tune Hyperparameters, detect model and data drift and resolve issues\nPresent machine learning models outcomes, and help interpret model predictions to various stakeholders using standard data visualization tools",,,,"['Tensorflow', 'Ai Algorithms', 'Ml Algorithms', 'Machine Learning', 'Python', 'Pytorch', 'Model Development']",2025-06-12 00:58:51
Data Scientist,Ltimindtree,8 - 13 years,19-34 Lacs P.A.,"['Pune', 'Bengaluru', 'Mumbai (All Areas)']",10 years of experience in Data ScienceML domain\nShould have experience in Python and libraries like pandas numpy scikitlearn etc\nHave worked on building ML models and integrating it with application end to end\nHave knowledge on Recommender engines and the ML models running behind it like ALS and LightFM\nHave experience in Azure Machine Learning and Azure Services\nHave experience in deploying models in cloud environment and exposing it as an API\nGood communication and presentation skill\nAbility to deliver ML projects as an individual contributor,Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Machine Learning', 'Data Science', 'Ml']",2025-06-12 00:58:54
"Senior Data Scientist, Operations || Mumbai || 29 LPA",Argus India Price Reporting Services,5 - 10 years,20-25 Lacs P.A.,"['Mumbai Suburban', 'Navi Mumbai', 'Mumbai (All Areas)']","Senior Data Scientist, Operations\nMumbai, India\nAbout Argus:\n\nArgus is the leading independent provider of market intelligence to the global energy and commodity markets. We offer essential price assessments, news, analytics, consulting services, data science tools and industry conferences to illuminate complex and opaque commodity markets.\nHeadquartered in London with 1,500 staff, Argus is an independent media organisation with 30 offices in the worlds principal commodity trading hubs.\nCompanies, trading firms and governments in 160 countries around the world trust Argus data to make decisions, analyse situations, manage risk, facilitate trading and for long-term planning. Argus prices are used as trusted benchmarks around the world for pricing transportation, commodities and energy.\nFounded in 1970, Argus remains a privately held UK-registered company owned by employee shareholders and global growth equity firm General Atlantic.\n\nWhat were looking for:\nJoin our Generative AI team as a Senior Data Scientist, reporting directly to the Lead Data Scientist in India. You will play a crucial role in building, optimizing, and maintaining AI-ready data infrastructure for advanced Generative AI applications. Your focus will be on hands-on implementation of cutting-edge data extraction, curation, and metadata enhancement techniques for both text and numerical data. You will be a key contributor to the development of innovative solutions, ensuring rapid iteration and deployment, and supporting the Lead in achieving the team's strategic goals.\n\nWhat will you be doing:\nAI-Ready Data Development: Design, develop, and maintain high-quality AI-ready datasets, ensuring data integrity, usability, and scalability to support advanced Generative AI models.\nAdvanced Data Processing: Drive hands-on efforts in complex data extraction, cleansing, and curation for diverse text and numerical datasets. Implement sophisticated metadata enrichment strategies to enhance data utility and accessibility for AI systems.\nAlgorithm Implementation & Optimization: Implement and optimize state-of-the-art algorithms and pipelines for efficient data processing, feature engineering, and data transformation tailored for LLM and GenAI applications.\nGenAI Application Development: Apply and integrate frameworks like LangChain and Hugging Face Transformers to build modular, scalable, and robust Generative AI data pipelines and applications.\nPrompt Engineering Application: Apply advanced prompt engineering techniques to optimize LLM performance for specific data extraction, summarization, and generation tasks, working closely with the Lead's guidance.\nLLM Evaluation Support: Contribute to the systematic evaluation of Large Language Models (LLMs) outputs, analysing quality, relevance, and accuracy, and supporting the implementation of LLM-as-a-judge frameworks.\nRetrieval-Augmented Generation (RAG) Contribution: Actively contribute to the implementation and optimization of RAG systems, including working with embedding models, vector databases, and, where applicable, knowledge graphs, to enhance data retrieval for GenAI.\nTechnical Mentorship: Act as a technical mentor and subject matter expert for junior data scientists, providing guidance on best practices in coding and PR reviews, data handling, and GenAI methodologies.\nCross-Functional Collaboration: Collaborate effectively with global data science teams, engineering, and product stakeholders to integrate data solutions and ensure alignment with broader company objectives.\nOperational Excellence: Troubleshoot and resolve data-related issues promptly to minimize potential disruptions, ensuring high operational efficiency and responsiveness.\nDocumentation & Code Quality: Produce clean, well-documented, production-grade code, adhering to best practices for version control and software engineering.\n\nSkills and Experience:\nAcademic Background: Advanced degree in AI, statistics, mathematics, computer science, or a related field.\nProgramming and Frameworks: 2+ years of hands-on experience with Python, TensorFlow or PyTorch, and NLP libraries such as spaCy and Hugging Face.\nGenAI Tools: 1+ years Practical experience with LangChain, Hugging Face Transformers, and embedding models for building GenAI applications.\nPrompt Engineering: Deep expertise in prompt engineering, including prompt tuning, chaining, and optimization techniques.\nLLM Evaluation: Experience evaluating LLM outputs, including using LLM-as-a-judge methodologies to assess quality and alignment.\nRAG and Knowledge Graphs: Practical understanding and experience using vector databases. In addition, familiarity with graph-based RAG architectures and the use of knowledge graphs to enhance retrieval and reasoning would be a strong plus.\nCloud: 2+ years of experience with Gemini/OpenAI models and cloud platforms such as AWS, Google Cloud, or Azure. Proficient with Docker for containerization.\nData Engineering: Strong understanding of data extraction, curation, metadata enrichment, and AI-ready dataset creation.\nCollaboration and Communication: Excellent communication skills and a collaborative mindset, with experience working across global teams.\n\nWhats in it for you:\nCompetitive salary\nHybrid Working Policy (3 days in Mumbai office/ 2 days WFH once fully inducted)\nGroup healthcare scheme\n18 days annual leave\n8 days of casual leave\nExtensive internal and external training\n\nHours:\nThis is a full-time position operating under a hybrid model, with three days in the office and up to two days working remotely.\nThe team supports Argus key business processes every day, as such you will be required to work on a shift-based rota with other members of the team supporting the business until 8pm. Typically support hours run from 11am to 8pm with each member of the team participating up to 2/3 times a week.\n\nFor more details about the company and to apply please make sure you send your CV and cover letter via our website: www.argusmedia.com/en/careers/open-positions\nBy submitting your job application, you automatically acknowledge and consent to the collection, use and/or disclosure of your personal data to the Company. Argus is an equal opportunity employer. We welcome and encourage diversity in the workplace regardless of race, gender, sexual orientation, gender identity, disability or veteran status.",Industry Type: Analytics / KPO / Research,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pytorch', 'Artificial Intelligence', 'LangChain', 'hugging face', 'Spacy', 'Tensorflow']",2025-06-12 00:58:58
