job_title,company,experience,salary,locations,description,industry,department,employment_type,skills,scraped_at
Data and Analytics Architect - L1,Wipro,8 - 10 years,Not Disclosed,['Hyderabad'],"Role Purpose\nThe purpose of the role is to define and develop Enterprise Data Structure along with Data Warehouse, Master Data, Integration and transaction processing with maintaining and strengthening the modelling standards and business information.\n\n\n\nDo\n1. Define and Develop Data Architecture that aids organization and clients in new/ existing deals\na. Partnering with business leadership (adopting the rationalization of the data value chain) to provide strategic, information-based recommendations to maximize the value of data and information assets, and protect the organization from disruptions while also embracing innovation\nb. Assess the benefits and risks of data by using tools such as business capability models to create an data-centric view to quickly visualize what data matters most to the organization, based on the defined business strategy\nc. Create data strategy and road maps for the Reference Data Architecture as required by the clients\nd. Engage all the stakeholders to implement data governance models and ensure that the implementation is done based on every change request\ne. Ensure that the data storage and database technologies are supported by the data management and infrastructure of the enterprise\nf. Develop, communicate, support and monitor compliance with Data Modelling standards\ng. Oversee and monitor all frameworks to manage data across organization\nh. Provide insights for database storage and platform for ease of use and least manual work\ni. Collaborate with vendors to ensure integrity, objectives and system configuration\nj. Collaborate with functional & technical teams and clients to understand the implications of data architecture and maximize the value of information across the organization\nk. Presenting data repository, objects, source systems along with data scenarios for the front end and back end usage\nl. Define high-level data migration plans to transition the data from source to target system/ application addressing the gaps between the current and future state, typically in sync with the IT budgeting or other capital planning processes\nm. Knowledge of all the Data service provider platforms and ensure end to end view.\nn. Oversight all the data standards/ reference/ papers for proper governance\no. Promote, guard and guide the organization towards common semantics and the proper use of metadata\n\n\n\np. Collecting, aggregating, matching, consolidating, quality-assuring, persisting and distributing such data throughout an organization to ensure a common understanding, consistency, accuracy and control\nq. Provide solution of RFPs received from clients and ensure overall implementation assurance\ni. Develop a direction to manage the portfolio of all the databases including systems, shared infrastructure services in order to better match business outcome objectives\nii. Analyse technology environment, enterprise specifics, client requirements to set a collaboration solution for the big/small data\niii. Provide technical leadership to the implementation of custom solutions through thoughtful use of modern technology\niv. Define and understand current issues and problems and identify improvements\nv. Evaluate and recommend solutions to integrate with overall technology ecosystem keeping consistency throughout\nvi. Understand the root cause problem in integrating business and product units\nvii. Validate the solution/ prototype from technology, cost structure and customer differentiation point of view\nviii. Collaborating with sales and delivery leadership teams to identify future needs and requirements\nix. Tracks industry and application trends and relates these to planning current and future IT needs\n\n\n\n2. Building enterprise technology environment for data architecture management\na. Develop, maintain and implement standard patterns for data layers, data stores, data hub & lake and data management processes\nb. Evaluate all the implemented systems to determine their viability in terms of cost effectiveness\nc. Collect all the structural and non-structural data from different places integrate all the data in one database form\nd. Work through every stage of data processing: analysing, creating, physical data model designs, solutions and reports\ne. Build the enterprise conceptual and logical data models for analytics, operational and data mart structures in accordance with industry best practices\nf. Implement the best security practices across all the data bases based on the accessibility and technology\ng. Strong understanding of activities within primary discipline such as Master Data Management (MDM), Metadata Management and Data Governance (DG)\nh. Demonstrate strong experience in Conceptual, Logical and physical database architectures, design patterns, best practices and programming techniques around relational data modelling and data integration\n\n\n\n3. Enable Delivery Teams by providing optimal delivery solutions/ frameworks\na. Build and maintain relationships with delivery and practice leadership teams and other key stakeholders to become a trusted advisor\nb. Define database physical structure, functional capabilities, security, back-up and recovery specifications\nc. Develops and establishes relevant technical, business process and overall support metrics (KPI/SLA) to drive results\nd. Monitor system capabilities and performance by performing tests and configurations\ne. Integrate new solutions and troubleshoot previously occurred errors\nf. Manages multiple projects and accurately reports the status of all major assignments while adhering to all project management standards\ng. Identify technical, process, structural risks and prepare a risk mitigation plan for all the projects\nh. Ensure quality assurance of all the architecture or design decisions and provides technical mitigation support to the delivery teams\ni. Recommend tools for reuse, automation for improved productivity and reduced cycle times\nj. Help the support and integration team for better efficiency and client experience for ease of use by using AI methods.\nk. Develops trust and builds effective working relationships through respectful, collaborative engagement across individual product teams\nl. Ensures architecture principles and standards are consistently applied to all the projects\nm. Ensure optimal Client Engagement\ni. Support pre-sales team while presenting the entire solution design and its principles to the client\nii. Negotiate, manage and coordinate with the client teams to ensure all requirements are met\niii. Demonstrate thought leadership with strong technical capability in front of the client to win the confidence and act as a trusted advisor\nMandatory Skills: Prophecy.AI.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Prophecy.AI', 'metadata management', 'design patterns', 'data governance', 'data warehousing', 'AI methods', 'master data management']",2025-06-11 05:48:26
TS - Data Architect & Database Expert,IT Company,7 - 12 years,Not Disclosed,"['Hyderabad', 'Chennai', 'Bengaluru']","DATA ARCHITECT- Data Architecture, Big Data, Data Modeling, or Database Administration, any DBMS,Oracle/SQL Server/PostgreSQL/MySQL\n\nDatabase Expert-Database Mgmt, SQL, Data Modeling, Data Warehousing, ETL, any DBMS Oracle/SQL Server/PostgreSQL/MySQL",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Database Administration', 'Data Architect', 'Database Management', 'Data Modeling', 'Data Architecture', 'Postgres Database', 'Postgresql', 'Big Data', 'Data Warehousing', 'Oracle', 'SQL', 'Data Warehousing Concepts']",2025-06-11 05:48:28
Data Architect,Acesoft,6 - 10 years,19-22.5 Lacs P.A.,['Bengaluru'],"Hi all,\nWe are hiring fore the Data Architecture\nExperience: 6 - 9 years\nLocation: Bangalore\nNotice Period: Immediate - 15 Days\nSkills:\nData Architecture\nAzure Data Factory\nAzure Data Bricks\nAzure Cloud\nArchitecture\n\nIf you are interested drop your resume at mojesh.p@acesoftlabs.com\nCall: 9701971793",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['Azure Data Factory', 'Architecture', 'Azure Databricks', 'Data Architecture', 'Azure Synapse', 'Data Modeling']",2025-06-11 05:48:29
Big Data Architect,Meritus Management Service,8 - 10 years,20-32.5 Lacs P.A.,"['Nagpur', 'Pune']","Design and implement scalable Big Data architecture and pipelines using tools like Hadoop, Spark, Kafka, and Hive.\nCollaborate with cross-functional teams to build real-time/batch systems, ensure data quality and governance.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Hadoop', 'SQL', 'architect level exposure', 'Pyspark']",2025-06-11 05:48:31
Data Architect | Application Architect,SRS Infoway,12 - 15 years,22.5-25 Lacs P.A.,"['Hyderabad', 'Chennai']","Full-stack developer with expertise in Java, Spring Boot, React JS, Kafka, NoSQL (Cosmos, Cassandra), Azure Cloud, AKS, and Azure SQL. Domain focus: Retail-CPG, Logistics, and Supply Chain.\nMail:kowsalya.k@srsinfoway.com",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Temporary/Contractual","['Java', 'Azure Kubernetes', 'Azure Cloud platform.', 'Supply Chain', 'Nosql Databases', 'PostgreSQL', 'Cassandra', 'Kafka', 'Azure SQL', 'Retail-CPG', 'Spring boot', 'React.Js', 'Transportation/Logistics']",2025-06-11 05:48:32
Snowflake Data Architect,Kasmo Digital,10 - 16 years,Not Disclosed,['Hyderabad'],"Required Skills & Qualifications:\n10-12 years of experience in data architecture, data warehousing, and cloud technologies.\nStrong expertise in Snowflake architecture, data modeling, and optimization.\nSolid hands-on experience with cloud platforms: AWS, Azure, and GCP.\nIn-depth knowledge of SQL, Python, PySpark, and related data engineering tools.\nExpertise in data modeling (both dimensional and normalized models).\nStrong experience with data integration, ETL processes, and pipeline development.\nCertification in Snowflake, AWS, Azure, or related cloud technologies.\nExperience working with large-scale data processing frameworks and platforms.\nExperience in data visualization tools and BI platforms (e.g., Tableau, Power BI).\nExperience in Agile methodologies and project management.\nStrong problem-solving skills with the ability to address complex technical challenges.\nExcellent communication skills and ability to work collaboratively with cross-functional teams.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Snowflake', 'Data Visualization', 'Data Modeling', 'Data Warehousing', 'SQL', 'Data Architecture', 'Python']",2025-06-11 05:48:34
Data Architect,R Systems International,4 - 6 years,20-25 Lacs P.A.,['Noida'],"Technical Requirements\n  SQL (Advanced level):\nStrong command of complex SQL logic, including window functions, CTEs, pivot/unpivot, and be proficient in stored procedure/SQL script development.\nExperience writing maintainable SQL for transformations.\n  Python for ETL:",,,,"['hive', 'continuous integration', 'amazon redshift', 'pyspark', 'ci/cd', 'data warehousing', 'data architecture', 'sql', 'stored procedures', 'etl pipelines', 'postgresql', 'json', 'etl', 'data profiling', 'architecture', 'cd', 'development', 'python', 'data processing', 'elt', 'data bricks', 'sql scripting', 'data quality', 'logic', 'aws']",2025-06-11 05:48:36
Senior Snowflake Data Architect,TechStar Group,9 - 12 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']","JD:\nSenior Snowflake Data Architect:  \nDesign , implements, and optimizes data solutions within the Snowflake cloud data platform, ensuring data security, governance, and performance, while also collaborating with cross-functional teams and providing technical leadership.\nData architect include determining a data strategy.\nunderstanding data management technologies\noversee data inventory.\nmaintain a finger on the pulse of an organization's data management systems.Role & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Snowflake Data Architect', 'Data Architecture', 'Data Modeling']",2025-06-11 05:48:37
Data Architect,Opus Technologies,10 - 16 years,35-50 Lacs P.A.,['Pune'],"Role & responsibilities\nDefine and evolve data engineering & analytics offerings aligned with payments domain needs (e.g., transaction analytics, fraud detection, customer insights).\nLead reference architecture creation for data modernization, real-time analytics, and cloud-native data platforms (e.g., Azure Synapse, GCP BigQuery).\nBuild reusable components, PoCs, and accelerators for ingestion, transformation, data quality, and governance.\nSupport pre-sales engagements with solution design, estimation, and client workshops.\nGuide delivery teams on data platform implementation, optimization, and security.\nMentor and upskill talent pool through learning paths and certifications.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Kafka', 'Spark', 'Python', 'Azure Data Factory']",2025-06-11 05:48:39
Data Architect,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,['Bengaluru'],"Additional Career Level Description\n\n\nKnowledge and application\nApplies advanced wide-ranging experience and in-depth professional knowledge to develop and resolve complex models and procedures in creative way .\nDirects the application of existing principles and guides development of new policies and ideas.\nDetermines own methods and procedures on new assignments .\n\n\n\nProblem solving\nUnderstands and works on complex issues where analysis of situation or data requires an in-depth evaluation of variable factors, solutions may need to be devised from limited informatio n.\nExercises judgment in selecting methods, evaluating, adapting of complex techniques and evaluation criteria for obtaining results.\n\n\n\nInteraction\nFrequently advises key people outside own area of expertise on complex matters, using persuasion in delivering messages.\n\n\n\nImpact\nDevelops and manages operational initiatives to deliver tactical results and achieve medium-term goals.\n\n\n\nAccountability\nMay be accountable through team for delivery of tactical business targets .\nWork is reviewed upon completion and is consistent with departmental objectives.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Architecture', 'data modeling', 'Data Architect', 'artificial intelligence', 'sql']",2025-06-11 05:48:40
Data Architect / Engagement Lead,Ignitho,7 - 10 years,Not Disclosed,['Chennai( Sholinganallur )'],"Job Title: Data Architect / Engagement Lead\nLocation: Chennai\nReports To: CEO\n\nAbout the Company:\nIgnitho Inc. is a leading AI and data engineering company with a global presence, including US, UK, India, and Costa Rica offices.\nVisit our website to learn more about our work and culture: www.ignitho.com.\nIgnitho is a portfolio company of Nuivio Ventures Inc., a venture builder dedicated to developing Enterprise AI product companies across various domains, including AI, Data Engineering, and IoT.\nLearn more about Nuivio at: www.nuivio.com.\n\nJob Summary:\nAs the Data Architect and Engagement Lead, you will define the data architecture strategy and lead client engagements, ensuring alignment between data solutions and business goals. This dual role blends technical leadership with client-facing responsibilities.\n\nKey Responsibilities:\nDesign scalable data architectures, including storage, processing, and integration layers.\nLead technical discovery and requirements gathering sessions with clients.\nProvide architectural oversight for data and AI solutions.\nAct as a liaison between technical teams and business stakeholders.\nDefine data governance, security, and compliance standards.\n\nRequired Qualifications:\nBachelors or Masters in computer science, Information Systems, or similar.\n7+ years of experience in data architecture, with client-facing experience.\nDeep knowledge of data modelling, cloud data platforms (Snowflake / BigQuery/ Redshift / Azure), and orchestration tools.\nExcellent communication, stakeholder management, and technical leadership skills.\nFamiliarity with AI/ML systems and their data requirements is a strong plus.",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Aiml', 'Data Modeling', 'Azure Cloud', 'Bigquery', 'Redshift Aws', 'Artificial Intelligence', 'Snowflake', 'Machine Learning']",2025-06-11 05:48:42
Data Architect Sr. Advisor,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 323777\n\nWe are currently seeking a Data Architect Sr. Advisor to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works""",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'python', 'client engagement', 'ai solutions', 'aiml', 'data architecture', 'machine learning', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'gcp cloud', 'ml']",2025-06-11 05:48:43
Data & AI Technical Solution Architects,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 323775\n\nWe are currently seeking a Data & AI Technical Solution Architects to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'solution design', 'gcp', 'gcp cloud', 'ml']",2025-06-11 05:48:45
Data & AI Technical Solution Architects,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Pune'],"Req ID: 323754\n\nWe are currently seeking a Data & AI Technical Solution Architects to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nJob DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'solution design', 'gcp', 'gcp cloud', 'ml']",2025-06-11 05:48:47
Data Architect,"NTT DATA, Inc.",8 - 13 years,Not Disclosed,['Chennai'],"Req ID: 324664\n\nWe are currently seeking a Data Architect to join our team in Chennai, Tamil Ndu (IN-TN), India (IN).\n\nKey Responsibilities:\n\nDevelop and articulate long-term strategic goals for data architecture vision and establish data standards for enterprise systems.\n\nUtilize various cloud technologies, including Azure, AWS, GCP, and data platforms like Databricks and Snowflake.\n\nConceptualize and create an end-to-end vision outlining the seamless flow of data through successive stages.\n\nInstitute processes for governing the identification, collection, and utilization of corporate metadata, ensuring accuracy and validity.\n\nImplement methods and procedures for tracking data quality, completeness, redundancy, compliance, and continuous improvement.\n\nEvaluate and determine governance, stewardship, and frameworks for effective data management across the enterprise.\n\nDevelop comprehensive strategies and plans for data capacity planning, data security, life cycle data management, scalability, backup, disaster recovery, business continuity, and archiving.\n\nIdentify potential areas for policy and procedure enhancements, initiating changes where required for optimal data management.\n\nFormulate and maintain data models and establish policies and procedures for functional design.\n\nOffer technical recommendations to senior managers and technical staff in the development and implementation of databases and documentation.\n\nStay informed about upgrades and emerging database technologies through continuous research.\n\nCollaborate with project managers and business leaders on all projects involving enterprise data.\n\nDocument the data architecture and environment to ensure a current and accurate understanding of the overall data landscape.\n\nDesign and implement data solutions tailored to meet customer needs and specific use cases.\n\nProvide thought leadership by recommending the most suitable technologies and solutions for various use cases, spanning from the application layer to infrastructure.\n\nBasic Qualifications:\n\n8+ years of hands-on experience with various database technologies\n\n6+ years of experience with Cloud-based systems and Enterprise Data Architecture, driving end-to end technology solutions.\n\nExperience with Azure, Databricks, Snowflake\n\nKnowledgeable on concepts of GenAI\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nPossess certifications in AWS, Azure, and GCP to complement extensive hands-on experience.\n\nDemonstrated expertise with certifications in Snowflake.\n\nValuable ""Big 4"" Management Consulting experience or exposure to multiple industries.\n\nUndergraduate or graduate degree preferred.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['enterprise information architecture', 'microsoft azure', 'gcp', 'database creation', 'aws', 'snowflake', 'data life cycle management', 'metadata', 'data management', 'data security', 'data warehousing', 'data architecture', 'sql', 'data bricks', 'data quality', 'database implementation']",2025-06-11 05:48:49
Data Architect,Coforge,11 - 16 years,Not Disclosed,"['Noida', 'Greater Noida', 'Delhi / NCR']","-Data Architect Department:\nData & Analytics The Data Architect having more than 14 years of experience and should play a pivotal role in designing, developing, and governing scalable data architectures to support enterprise-wide data integration, analytics, and reporting.\nThis role will focus on creating unified data models, optimizing data pipelines, and ensuring compliance with regulatory standards (GDPR) using cloud-based platforms.\nThe ideal candidate is a strategic thinker with deep expertise in data modeling, cloud data platforms, and governance.",,,,"['Data Migration', 'Data Warehousing', 'Data Modeling', 'Informatica', 'SSIS', 'ETL Tool']",2025-06-11 05:48:50
Data Architect,.,7 - 12 years,20-35 Lacs P.A.,"['Hyderabad', 'Bengaluru']","Job Description\nWe are seeking a highly skilled Azure Data Engineer with strong expertise in Data Architecture, PySpark/Python, Azure Databricks, and data streaming solutions. The ideal candidate will have hands-on experience in designing and implementing large-scale data pipelines, along with solid knowledge of data governance and data modeling.\nKey Responsibilities\nDesign, develop, and optimize PySpark/Python-based data streaming jobs on Azure Databricks.\nBuild scalable and efficient data pipelines for batch and real-time processing.\nImplement data governance policies, ensuring data quality, security, and compliance.\nDevelop and maintain data models (dimensional, relational, NoSQL) to support analytics and reporting.\nCollaborate with cross-functional teams (data scientists, analysts, and business stakeholders) to deliver data solutions.\nTroubleshoot performance bottlenecks and optimize Spark jobs for efficiency.\nEnsure best practices in CI/CD, automation, and monitoring of data workflows.\nMentor junior engineers and lead technical discussions (for senior/managerial roles).\nMandatory Skills & Experience\n5+ years of relevant experience as a Data Engineer/Analyst/Architect (8+ years for Manager/Lead positions).\nExpert-level proficiency in PySpark/Python and Azure Databricks (must have worked on real production projects).\nStrong experience in building and optimizing streaming data pipelines (Kafka, Event Hubs, Delta Lake, etc.).\n4+ years of hands-on experience in data governance & data modeling (ER, star schema, data vault, etc.).\nIn-depth knowledge of Azure Data Factory, Synapse, ADLS, and SQL/NoSQL databases.\nExperience with Delta Lake, Databricks Workflows, and performance tuning.\nFamiliarity with data security, metadata management, and lineage tracking.\nExcellent communication skills (must be able to articulate technical concepts clearly).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Azure Databricks', 'Data Modeling', 'Data Governance', 'Python', 'ETL']",2025-06-11 05:48:52
Lead Data Architect,"NTT DATA, Inc.",7 - 12 years,Not Disclosed,['Bengaluru'],"We are currently seeking a Lead Data Architect to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n Position Overview  We are seeking a highly skilled and experienced Data Architect to join our dynamic team. The ideal candidate will have a strong background in designing and implementing data solutions using AWS infrastructure and a variety of core and supplementary technologies. This role requires a deep understanding of data architecture, cloud services, and the ability to drive innovative solutions to meet business needs.\n\n\n\n Key Responsibilities  \n\n- Architect end-to-end data solutions using AWS services, including Lambda, SNS, S3, and EKS, Kafka and Confluent, all within a larger and overarching programme ecosystem\n\n- Architect data processing applications using Python, Kafka, Confluent Cloud and AWS\n\n- Ensure data security and compliance throughout the architecture\n\n- Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions\n\n- Optimize data flows for performance, cost-efficiency, and scalability\n\n- Implement data governance and quality control measures\n\n- Ensure delivery of CI, CD and IaC for NTT tooling, and as templates for downstream teams\n\n- Provide technical leadership and mentorship to development teams and lead engineers\n\n- Stay current with emerging technologies and industry trends\n\n\n\n Required Skills and Qualifications  \n\n\n\n- Bachelor's degree in Computer Science, Engineering, or related field\n\n- 7+ years of experience in data architecture and engineering\n\n- Strong expertise in AWS cloud services, particularly Lambda, SNS, S3, and EKS\n\n- Strong experience with Confluent\n\n- Strong experience in Kafka\n\n- Solid understanding of data streaming architectures and best practices\n\n- Strong problem-solving skills and ability to think critically\n\n- Excellent communication skills to convey complex technical concepts to both technical and non-technical stakeholders\n\n- Knowledge of Apache Airflow for data orchestration\n\n\n\n Preferred Qualifications  \n\n\n\n- An understanding of cloud networking patterns and practises\n\n- Experience with working on a library or other long term product\n\n- Knowledge of the Flink ecosystem\n\n- Experience with Terraform\n\n- Deep experience with CI/CD pipelines\n\n- Strong understanding of the JVM language family\n\n- Understanding of GDPR and the correct handling of PII\n\n- Expertise with technical interface design\n\n- Use of Docker\n\n\n\n Responsibilities  \n\n- Design and implement scalable data architectures using AWS services, Confluent and Kafka\n\n- Develop data ingestion, processing, and storage solutions using Python and AWS Lambda, Confluent and Kafka\n\n- Ensure data security and implement best practices using tools like Synk\n\n- Optimize data pipelines for performance and cost-efficiency\n\n- Collaborate with data scientists and analysts to enable efficient data access and analysis\n\n- Implement data governance policies and procedures\n\n- Provide technical guidance and mentorship to junior team members\n\n- Evaluate and recommend new technologies to improve data architecture",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['continuous integration', 'cloud services', 'data architecture', 'kafka', 'ci cd pipeline', 'jvm', 'python', 'confluent', 'aws iam', 'airflow', 'ci/cd', 'eks', 'aws lambda', 'apache flink', 'docker', 'apache', 'lambda expressions', 'aws cloud', 'data governance', 'sns', 'terraform', 'aws', 'interface design']",2025-06-11 05:48:53
Salesforce Data Cloud Architect,"NTT DATA, Inc.",4 - 8 years,Not Disclosed,"['Chennai', 'Gurugram', 'Bengaluru']","We are currently seeking a Salesforce Data Cloud Architect to join our team in ""‹""‹""‹""‹""‹""‹""‹Hyderabad, Telangana, India.\n\n\nSalesforce Data Cloud Expertise: Extensive knowledge of Salesforce Data Cloud features, capabilities, and best practices.\n\n\nData Modeling: Strong experience in designing and implementing data models.\n\n\nData Integration: Experience with data integration tools and techniques.\n\n\nData Quality: Understanding of data quality concepts and practices.\n\n\nData Governance: Knowledge of data governance principles and practices.\n\n\nSQL: Proficiency in SQL for data querying and manipulation.\n\n\nProblem-Solving: Strong analytical and problem-solving skills.\n\n\nCommunication: Excellent communication and collaboration skills.\n\n\nLocation - Bengaluru,Chennai,Gurugram,Hyderabad,Noida,Pune",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sql', 'salesforce', 'data modeling', 'data governance', 'data integration', 'c#', 'python', 'business analysis', 'sharepoint', 'user stories', 'news writing', 'javascript', 'editing', 'react.js', 'java', 'product management', 'content writing', 'scrum', 'html', 'agile', 'etl', 'jira']",2025-06-11 05:48:55
Master Data Management Data Architect,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will be responsible for designing, building, maintaining, analyzing, and interpreting data deliver actionable insights that drive business decisions. This role involves working with large datasets, developing reports, supporting and driving data governance initiatives, and visualizing data to ensure data is accessible, reliable, and efficiently managed. The ideal candidate has deep technical skills and provides administration support for Master Data Management (MDM) and Data Quality platform, including solution architecture, inbound/outbound data integration (ETL), Data Quality (DQ), and maintenance/tuning of match rules.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing\nCollaborate and communicate with MDM Developers, Data Architects, Product teams, Business SMEs, and Data Scientists to design and develop end-to-end data pipelines to meet fast paced business needs across geographic regions\nIdentify and resolve complex data-related challenges\nAdhere to standard processes for coding, testing, and designing reusable code/component\nParticipate in sprint planning meetings and provide estimations on technical implementation\nAs a SME, work with the team on MDM related product installation, configuration, customization and optimization\nResponsible for the understanding, documentation, maintenance, and additional creation of master data related data-models (conceptual, logical, and physical) and database structures\nReview technical model specifications and participate in data quality testing\nCollaborate with Data Quality & Governance Analyst and Data Governance Organization to monitor and preserve the master data quality\nCreate and maintain system specific master data data-dictionaries for domains in scope\nArchitect MDM Solutions, including data modeling and data source integrations from proof-of-concept through development and delivery\nDevelop the architectural design for Master Data Management domain development, base object integration to other systems and general solutions as related to Master Data Management\nDevelop and deliver solutions individually or as part of a development team\nApproves code reviews and technical work\nMaintains compliance with change control, SDLC and development standards\nContribute to the design, development, and implementation of data pipelines, ETL/ELT processes, and data integration solutions\nCollaborate with multi-functional teams to understand data requirements and design solutions that meet business needs\nImplement data security and privacy measures to protect sensitive data\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions\n\nBasic Qualifications:\nMasters degree and 1 to 3 years of Computer Science, IT or related field experience OR\nBachelors degree and 3 to 5 years of Computer Science, IT or related field experience OR\nDiploma and 7 to 9 years of Computer Science, IT or related field experience.\nPreferred Qualifications:\nExpertise in architecting and designing Master Data Management (MDM) solutions.\nPractical experience with AWS Cloud, Databricks, Apache Spark, workflow orchestration, and optimizing big data processing performance.\nFamiliarity with enterprise source systems and consumer systems for master and reference data, such as CRM, ERP, and Data Warehouse/Business Intelligence.\nAt least 2 to 3 years of experience as an MDM developer using Informatica MDM or Reltio MDM, along with strong proficiency in SQL.\n\n\nGood-to-Have Skills:\nExperience with ETL tools such as Apache Spark, and various Python packages related to data processing, machine learning model development.\nGood understanding of data modeling, data warehousing, and data integration concepts.\nExperience with development using Python, React JS, cloud data platforms.\nCertified Data Engineer / Data Analyst (preferred on Databricks or cloud environments).\n\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nTeam-oriented, with a focus on achieving team goals\nStrong presentation and public speaking skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analysis', 'Business Intelligence', 'Data Warehouse', 'cloud data platforms', 'Databricks', 'ETL', 'React JS', 'Python']",2025-06-11 05:48:57
Principal Architect-Data & Cloud,Tothr,12 - 18 years,40-45 Lacs P.A.,"['Chennai', 'Bengaluru']","Experience in Hadoop, GCP/AWS/Azure Cloud\nETL technologies on Cloud like Spark, Pyspark/Scala, Dataflow\nETL tools like Informatica/DataStage/OWB/Talend\nExperience inS3, Cloud Storage, Athena, Glue, Sqoop, Flume, Hive, Kafka, Pub-Sub\n\nRequired Candidate profile\nMore than 10 years of experience in Technical, Solutioning, and Analytical roles.\n5+ years of experience in building and managing Data Lakes, Data Warehouse, Data Integration,",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Cloud', 'Technical', 'Analytical', 'MongoDB', 'data lake', 'Pyspark', 'Data Migration', 'Data Warehousing', 'Data Integration']",2025-06-11 05:48:58
Data Scientist,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Data Scientist is an advanced subject matter expert, tasked with taking accountability in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nResponsible for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources\nProvides meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nDirects scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualizes the output of the models.\nResponsible for ensuring that industry standards best practices are applied to development activities.\nKnowledge and Attributes:\nAdvanced understanding of data modelling, statistical methods and machine learning techniques.\nStrong ability to thrive in a dynamic, fast-paced environment.\nStrong quantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nAdvanced understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nStrong ability to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nStrong ability to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming certification preferred.\nAgile certification preferred.\nRequired Experience:\nAdvanced demonstrated experience in a data science position in a corporate environment and/or related industry.\nAdvanced demonstrated experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nAdvanced demonstrated experience in programming languages (R, Python, etc.).\nAdvanced demonstrated experience working with and creating data architectures.\nAdvanced demonstrated experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nAdvanced demonstrated experience visualizing and/or presenting data for stakeholder use and reuse across the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['data science', 'R', 'data modelling', 'data mining', 'statistical modelling', 'machine learning', 'Python', 'SQL']",2025-06-11 05:49:00
Data Visualization Expert - Quick sight,"NTT DATA, Inc.",4 - 5 years,Not Disclosed,['Chennai'],"We are currently seeking a Data Visualization Expert - Quick sight to join our team in Chennai, Tamil Ndu (IN-TN), India (IN).\n\n\n\n What awaits you/ Job Profile  \n\n\n\n Location Bangalore and Chennai, Hybrid mode,Immediate to 10 Days Notice period \nDevelop reports using Amazon Quicksight\nData Visualization DevelopmentDesign and develop data visualizations using Amazon Quicksight to present complex data in a clear and understandable format. Create interactive dashboards and reports that allow end-users to explore data and draw meaningful conclusions.\nData AnalysisCollaborate with data analysts and business stakeholders to understand data requirements, gather insights, and transform raw data into actionable visualizations.\nDashboard User Interface (UI) and User Experience (UX)Ensure that the data visualizations are user-friendly, intuitive, and aesthetically pleasing. Optimize the user experience by incorporating best practices in UI/UX design.\nData IntegrationWork closely with data engineers and data architects to ensure seamless integration of data sources into Quicksight, enabling real-time and up-to-date visualizations.\nPerformance OptimizationIdentify and address performance bottlenecks in data queries and visualization rendering to ensure quick and responsive dashboards.\nData Security and GovernanceEnsure compliance with data security policies and governance guidelines when handling sensitive data within Quicksight.\nTraining and DocumentationProvide training and support to end-users and stakeholders on how to interact with and interpret visualizations effectively. Create detailed documentation of the visualization development process.\nStay Updated with Industry TrendsKeep up to date with the latest data visualization trends, technologies, and best practices to continuously enhance the quality and impact of visualizations.\nUsing the Agile Methodology, attending daily standups and use of the Agile tools\nCollaborating with cross-functional teams and stakeholders to ensure data security, privacy, and compliance with regulations.\nusing Scrum/Kanban\nProficiency in Software Development best practices - Secure coding standards, Unit testing frameworks, Code coverage, Quality gates.\nAbility to lead and deliver change in a very productive way\nLead Technical discussions with customers to find the best possible solutions.\nW orking closely with the Project Manager, Solution Architect and managing client communication (as and when required)\n\n What should you bring along  \n\n\n\nMust Have\nPerson should have relevant work experience in analytics, reporting and business intelligence tools.\n4-5 years of hands-on experience in data visualization.\nRelatively 2-year Experience developing visualization using Amazon Quicksight.\nExperience working with various data sources and databases.\nAbility to work with large datasets and design efficient data models for visualization.\n\n\n\nNice to Have\nAI Project implementation and AI methods.\n\n Must have technical skill  \n\nQuick sight , SQL , AWS\n\n Good to have Technical skills  \n\nTableau, Data Engineer\n\n\n\n",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sql', 'data visualization', 'quicksight', 'software development', 'aws', 'hive', 'amazon redshift', 'unit testing', 'data warehousing', 'dashboards', 'business intelligence', 'spark', 'kanban', 'hadoop', 'etl', 'python', 'data analysis', 'ux', 'power bi', 'sql server', 'tableau', 'scrum', 'athena', 'agile', 'ssis']",2025-06-11 05:49:01
Data & AI Technical Solution ArchitectsData & AI Technical Solution,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Pune'],"Title : Data & AI Technical Solution ArchitectsData & AI Technical Solution Architects\n\nReq ID: 323749\n\nWe are currently seeking a Data & AI Technical Solution ArchitectsData & AI Technical Solution Architects to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nJob DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'needs assessment', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'gcp', 'gcp cloud', 'ml']",2025-06-11 05:49:03
Associate Data Engineer,"NTT DATA, Inc.",1 - 3 years,Not Disclosed,"['New Delhi', 'Chennai', 'Bengaluru']","Your day at NTT DATA\nWe are seeking an experienced Data Engineer to join our team in delivering cutting-edge Generative AI (GenAI) solutions to clients. The successful candidate will be responsible for designing, developing, and deploying data pipelines and architectures that support the training, fine-tuning, and deployment of LLMs for various industries. This role requires strong technical expertise in data engineering, problem-solving skills, and the ability to work effectively with clients and internal teams.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesign, develop, and manage data pipelines and architectures to support GenAI model training, fine-tuning, and deployment\nData Ingestion and Integration: Develop data ingestion frameworks to collect data from various sources, transform, and integrate it into a unified data platform for GenAI model training and deployment.\nGenAI Model Integration: Collaborate with data scientists to integrate GenAI models into production-ready applications, ensuring seamless model deployment, monitoring, and maintenance.\nCloud Infrastructure Management: Design, implement, and manage cloud-based data infrastructure (e.g., AWS, GCP, Azure) to support large-scale GenAI workloads, ensuring cost-effectiveness, security, and compliance.\nWrite scalable, readable, and maintainable code using object-oriented programming concepts in languages like Python, and utilize libraries like Hugging Face Transformers, PyTorch, or TensorFlow\nPerformance Optimization: Optimize data pipelines, GenAI model performance, and infrastructure for scalability, efficiency, and cost-effectiveness.\nData Security and Compliance: Ensure data security, privacy, and compliance with regulatory requirements (e.g., GDPR, HIPAA) across data pipelines and GenAI applications.\nClient Collaboration: Collaborate with clients to understand their GenAI needs, design solutions, and deliver high-quality data engineering services.\nInnovation and R&D: Stay up to date with the latest GenAI trends, technologies, and innovations, applying research and development skills to improve data engineering services.\nKnowledge Sharing: Share knowledge, best practices, and expertise with team members, contributing to the growth and development of the team.\n\nBachelors degree in computer science, Engineering, or related fields (Masters recommended)\nExperience with vector databases (e.g., Pinecone, Weaviate, Faiss, Annoy) for efficient similarity search and storage of dense vectors in GenAI applications\n5+ years of experience in data engineering, with a strong emphasis on cloud environments (AWS, GCP, Azure, or Cloud Native platforms)\nProficiency in programming languages like SQL, Python, and PySpark\nStrong data architecture, data modeling, and data governance skills\nExperience with Big Data Platforms (Hadoop, Databricks, Hive, Kafka, Apache Iceberg), Data Warehouses (Teradata, Snowflake, BigQuery), and lakehouses (Delta Lake, Apache Hudi)\nKnowledge of DevOps practices, including Git workflows and CI/CD pipelines (Azure DevOps, Jenkins, GitHub Actions)\nExperience with GenAI frameworks and tools (e.g., TensorFlow, PyTorch, Keras)\nNice to have:\nExperience with containerization and orchestration tools like Docker and Kubernetes\nIntegrate vector databases and implement similarity search techniques, with a focus on GraphRAG is a plus\nFamiliarity with API gateway and service mesh architectures\nExperience with low latency/streaming, batch, and micro-batch processing\nFamiliarity with Linux-based operating systems and REST APIs",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data Engineering', 'Apache Iceberg', 'Faiss', 'PySpark', 'Kafka', 'Pinecone', 'GitHub Actions', 'Snowflake', 'Apache Hudi', 'AWS', 'Azure DevOps', 'Python', 'Azure', 'BigQuery', 'Hadoop', 'Annoy', 'Teradata', 'SQL', 'Jenkins', 'Hive', 'Cloud Native platforms', 'GCP', 'Delta Lake', 'Databricks', 'Weaviate']",2025-06-11 05:49:05
Senior Associate Data Scientist,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Data Scientist is a seasoned subject matter expert, tasked with participating in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nWhat youll be doing\n\nKey Responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nAccountable for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources.\nAccountable for providing meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nAccountable for performing analysis using programming languages or statistical packages such as Python, pandas etc.\nDesigns scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualize the output of the models.\nCreates documentation around processes and procedures and manages code reviews.\nAccountable for ensuring that industry standards best practices are applied to development activities.\nKnowledge and Attributes:\nSeasoned in data modelling, statistical methods and machine learning techniques.\nAbility to thrive in a dynamic, fast-paced environment.\nQuantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nGood understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nAbility to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nAbility to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\nAble to apply data science principles through a business lens.\nDesire to create strategies and solutions that challenge and expand the thinking of peers and business stakeholders.\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming (Python) certification preferred.\nAgile certification preferred.\nRequired Experience:\nSeasoned experience in a data science position in a corporate environment and/or related industry.\nSeasoned experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nSeasoned experience in programming languages (Python, etc.).\nSeasoned experience working in databases (MySQL, Microsoft SQL Server, Azure Synapse, MongoDB)\nSeasoned experience working with and creating data architectures.\nSeasoned experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nSeasoned experience visualizing and/or presenting data for stakeholder use and reuse across the business.\nSeasoned experience on working with API (creating and using APIs)\nAutomation experience using Python scripting, UIPath, Selenium, PowerAutomate.\nSeasoned experience working on Linux operating system (Ubuntu)",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Azure Synapse', 'Microsoft SQL Server', 'MySQL', 'Python scripting', 'PowerAutomate', 'Linux operating system', 'MongoDB', 'Selenium', 'Python', 'UIPath']",2025-06-11 05:49:06
Master Data Management Manager,JINDAL STEEL & POWER,7 - 12 years,15-25 Lacs P.A.,['Gurugram'],"ABOUT THE ROLE\n\nRole is related to Master data management and Transformation of the current process to have simplification, automation in shared service environment including Account payables, Receivables, GL and other activities for Jindal Group of companies\n\nKEY ATTRIBUTE",,,,"['SAP', 'PMP', 'Rpa', 'SAP FICO', 'Sap Hana', 'Process Transformation', 'Shared Services']",2025-06-11 05:49:08
Data & AI Technical Solution Architects,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Hyderabad'],"Req ID: 323774\n\nWe are currently seeking a Data & AI Technical Solution Architects to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n""Job DutiesThe Data & AI Architect is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\nMinimum Skills RequiredAcademic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\nRequired Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Proficient with Snowflake, Databricks, Azure, AWS, GCP cloud, Data Engineering & AI tools\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n""¢ Additional\nAdditional\nAdditional Career Level Description:\nKnowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\nProblem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\nInteraction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject matter often requiring persuasion.\n""¢ Works""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['snowflake', 'microsoft azure', 'data engineering', 'data bricks', 'aws', 'client engagement', 'ai solutions', 'togaf', 'aiml', 'data architecture', 'solution architecting', 'artificial intelligence', 'change management', 'gen', 'service orientation', 'solution design', 'gcp', 'gcp cloud', 'ml']",2025-06-11 05:49:10
Azure Data Engineer/Lead/Architect (5 - 20 Years) (Pan India Location),Allegis Group,5 - 10 years,Not Disclosed,[],"Azure Data Engineer/Lead/Architect (5 - 20 Years) (Pan India Location)\nJob Location : Hyderabad / Bangalore / Chennai / Kolkata / Noida/ Gurgaon / Pune / Indore / Mumbai\n\n\n5 -20 years of relevant hands on development experience. And 4+ years as Azure Data Engineering role\nProficient in Azure technologies like ADB, ADF, SQL(capability of writing complex SQL queries), ADB, PySpark, Python, Synapse, Delta Tables, Unity Catalog\nHands on in Python, PySpark or Spark SQL\nHands on in Azure Analytics and DevOps\nTaking part in Proof of Concepts (POCs) and pilot solutions preparation\nAbility to conduct data profiling, cataloguing, and mapping for technical design and construction of technical data flows\nExperience in business processing mapping of data and analytics solutions",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure Analytics', 'Azure Data Engineering', 'Azure Databricks', 'Devops', 'Python', 'Azure Data Factory', 'Pyspark', 'Azure', 'Adb']",2025-06-11 05:49:11
Senior Data Scientist,"NTT DATA, Inc.",2 - 6 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Data Scientist is an advanced subject matter expert, tasked with taking accountability in the adoption of data science and analytics within the organization.\n\nThe primary responsibility of this role is to participate in the creation and delivery of data-driven solutions that add business value using statistical models, machine learning algorithms, data mining, and visualization techniques.\n\nKey responsibilities:\nDesigns, develops, and programs methods, processes, and systems to consolidate and analyze unstructured, diverse big data sources to generate actionable insights and solutions for client services and product enhancement.\nDesigns and enhances data collection procedures to include information that is relevant for building analytic systems.\nResponsible for ensuring that data used for analysis is processed, cleaned and, integrally verified and build algorithms necessary to find meaningful answers.\nDesigns and codes software programs, algorithms, and automated processes to cleanse, integrate and evaluate large datasets from multiple disparate sources\nProvides meaningful insights from large data and metadata sources; interprets and communicates insights and findings from analysis and experiments to product, service, and business managers.\nDirects scalable and highly available applications leveraging the latest tools and technologies.\nAccountable for creatively visualizing and effectively communicating results of data analysis, insights, and ideas in a variety of formats to key decision-makers within the business.\nCreates SQL queries for the analysis of data and visualizes the output of the models.\nResponsible for ensuring that industry standards best practices are applied to development activities.\n\nTo thrive in this role, you need to have:\nAdvanced understanding of data modelling, statistical methods and machine learning techniques.\nStrong ability to thrive in a dynamic, fast-paced environment.\nStrong quantitative and qualitative analysis skills.\nDesire to acquire more knowledge to keep up to speed with the ever-evolving field of data science.\nCuriosity to sift through data to find answers and more insights.\nAdvanced understanding of the information technology industry within a matrixed organization and the typical business problems such organizations face.\nStrong ability to translate technical findings clearly and fluently to non-technical team business stakeholders to enable informed decision-making.\nStrong ability to create a storyline around the data to make it easy to interpret and understand.\nSelf-driven and able to work independently yet acts as a team player.\n\nAcademic qualifications and certifications:\nBachelors degree or equivalent in Data Science, Business Analytics, Mathematics, Economics, Engineering, Computer Science or a related field.\nRelevant programming certification preferred.\nAgile certification preferred.\n\nRequired experience:\nAdvanced demonstrated experience in a data science position in a corporate environment and/or related industry.\nAdvanced demonstrated experience in statistical modelling and data modelling, machine learning, data mining, unstructured data analytics, natural language processing.\nAdvanced demonstrated experience in programming languages (R, Python, etc.).\nAdvanced demonstrated experience working with and creating data architectures.\nAdvanced demonstrated experience with extracting, cleaning, and transforming data and working with data owners to understand the data.\nAdvanced demonstrated experience visualizing and/or presenting data for stakeholder use and reuse across the business.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'data analytics', 'natural language processing', 'data modeling', 'data mining', 'statistical modeling', 'data architecture', 'machine learning']",2025-06-11 05:49:13
Senior GenAI Data Engineer,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,"['New Delhi', 'Chennai', 'Bengaluru']","Your day at NTT DATA\nSenior GenAI Data Engineer\nWe are seeking an experienced Senior Data Engineer to join our team in delivering cutting-edge Generative AI (GenAI) solutions to clients. The successful candidate will be responsible for designing, developing, and deploying data pipelines and architectures that support the training, fine-tuning, and deployment of LLMs for various industries. This role requires strong technical expertise in data engineering, problem-solving skills, and the ability to work effectively with clients and internal teams.\nWhat you'll be doing\nKey Responsibilities:\nDesign, develop, and manage data pipelines and architectures to support GenAI model training, fine-tuning, and deployment\nData Ingestion and Integration: Develop data ingestion frameworks to collect data from various sources, transform, and integrate it into a unified data platform for GenAI model training and deployment.\nGenAI Model Integration: Collaborate with data scientists to integrate GenAI models into production-ready applications, ensuring seamless model deployment, monitoring, and maintenance.\nCloud Infrastructure Management: Design, implement, and manage cloud-based data infrastructure (e.g., AWS, GCP, Azure) to support large-scale GenAI workloads, ensuring cost-effectiveness, security, and compliance.\nWrite scalable, readable, and maintainable code using object-oriented programming concepts in languages like Python, and utilize libraries like Hugging Face Transformers, PyTorch, or TensorFlow\nPerformance Optimization: Optimize data pipelines, GenAI model performance, and infrastructure for scalability, efficiency, and cost-effectiveness.\nData Security and Compliance: Ensure data security, privacy, and compliance with regulatory requirements (e.g., GDPR, HIPAA) across data pipelines and GenAI applications.\nClient Collaboration: Collaborate with clients to understand their GenAI needs, design solutions, and deliver high-quality data engineering services.\nInnovation and R&D: Stay up to date with the latest GenAI trends, technologies, and innovations, applying research and development skills to improve data engineering services.\nKnowledge Sharing: Share knowledge, best practices, and expertise with team members, contributing to the growth and development of the team.\nRequirements:\nBachelors degree in computer science, Engineering, or related fields (Master's recommended)\nExperience with vector databases (e.g., Pinecone, Weaviate, Faiss, Annoy) for efficient similarity search and storage of dense vectors in GenAI applications\n5+ years of experience in data engineering, with a strong emphasis on cloud environments (AWS, GCP, Azure, or Cloud Native platforms)\nProficiency in programming languages like SQL, Python, and PySpark\nStrong data architecture, data modeling, and data governance skills\nExperience with Big Data Platforms (Hadoop, Databricks, Hive, Kafka, Apache Iceberg), Data Warehouses (Teradata, Snowflake, BigQuery), and lakehouses (Delta Lake, Apache Hudi)\nKnowledge of DevOps practices, including Git workflows and CI/CD pipelines (Azure DevOps, Jenkins, GitHub Actions)\nExperience with GenAI frameworks and tools (e.g., TensorFlow, PyTorch, Keras)\nNice to have:\nExperience with containerization and orchestration tools like Docker and Kubernetes\nIntegrate vector databases and implement similarity search techniques, with a focus on GraphRAG is a plus\nFamiliarity with API gateway and service mesh architectures\nExperience with low latency/streaming, batch, and micro-batch processing\nFamiliarity with Linux-based operating systems and REST APIs\nLocation: Delhi or Bangalore\nWorkplace type:\nHybrid Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['GenAI', 'hive', 'continuous integration', 'kubernetes', 'ci/cd', 'pyspark', 'data architecture', 'sql', 'docker', 'tensorflow', 'git', 'data modeling', 'gcp', 'devops', 'linux', 'jenkins', 'pytorch', 'keras', 'hadoop', 'bigquery', 'python', 'microsoft azure', 'data engineering', 'data bricks', 'data governance', 'aws']",2025-06-11 05:49:14
Data Engineer,"NTT DATA, Inc.",4 - 9 years,Not Disclosed,['Chennai'],"Req ID: 324631\n\nWe are currently seeking a Data Engineer to join our team in Chennai, Tamil Ndu (IN-TN), India (IN).\n\nKey Responsibilities:\n\nDesign and implement tailored data solutions to meet customer needs and use cases, spanning from streaming to data lakes, analytics, and beyond within a dynamically evolving technical stack.\n\nProvide thought leadership by recommending the most appropriate technologies and solutions for a given use case, covering the entire spectrum from the application layer to infrastructure.\n\nDemonstrate proficiency in coding skills, utilizing languages such as Python, Java, and Scala to efficiently move solutions into production while prioritizing performance, security, scalability, and robust data integrations.\n\nCollaborate seamlessly across diverse technical stacks, including Cloudera, Databricks, Snowflake, and AWS.\n\nDevelop and deliver detailed presentations to effectively communicate complex technical concepts.\n\nGenerate comprehensive solution documentation, including sequence diagrams, class hierarchies, logical system views, etc.\n\nAdhere to Agile practices throughout the solution development process.\n\nDesign, build, and deploy databases and data stores to support organizational requirements.\n\nBasic Qualifications:\n\n4+ years of experience supporting Software Engineering, Data Engineering, or Data Analytics projects.\n\n2+ years of experience leading a team supporting data related projects to develop end-to-end technical solutions.\n\nExperience with Informatica, Python, Databricks, Azure Data Engineer\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nDemonstrate production experience in core data platforms such as Snowflake, Databricks, AWS, Azure, GCP, Hadoop, and more.\n\nPossess hands-on knowledge of Cloud and Distributed Data Storage, including expertise in HDFS, S3, ADLS, GCS, Kudu, ElasticSearch/Solr, Cassandra, or other NoSQL storage systems.\n\nExhibit a strong understanding of Data integration technologies, encompassing Informatica, Spark, Kafka, eventing/streaming, Streamsets, NiFi, AWS Data Migration Services, Azure DataFactory, Google DataProc.\n\nShowcase professional written and verbal communication skills to effectively convey complex technical concepts.\n\nUndergraduate or Graduate degree preferred",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'nosql', 'elastic search', 'cassandra', 'solr', 'core data', 'cloudera', 'python', 'data analytics', 'scala', 'kudu', 'microsoft azure', 'data engineering', 'data bricks', 'gen', 'java', 'apache nifi', 'spark', 'gcp', 'kafka', 'software engineering', 'hadoop', 'aws', 'data integration']",2025-06-11 05:49:16
Data Engineer,"NTT DATA, Inc.",4 - 9 years,Not Disclosed,['Chennai'],"Req ID: 324632\n\nWe are currently seeking a Data Engineer to join our team in Chennai, Tamil Ndu (IN-TN), India (IN).\n\nKey Responsibilities:\n\nDesign and implement tailored data solutions to meet customer needs and use cases, spanning from streaming to data lakes, analytics, and beyond within a dynamically evolving technical stack.\n\nProvide thought leadership by recommending the most appropriate technologies and solutions for a given use case, covering the entire spectrum from the application layer to infrastructure.\n\nDemonstrate proficiency in coding skills, utilizing languages such as Python, Java, and Scala to efficiently move solutions into production while prioritizing performance, security, scalability, and robust data integrations.\n\nCollaborate seamlessly across diverse technical stacks, including Cloudera, Databricks, Snowflake, and AWS.\n\nDevelop and deliver detailed presentations to effectively communicate complex technical concepts.\n\nGenerate comprehensive solution documentation, including sequence diagrams, class hierarchies, logical system views, etc.\n\nAdhere to Agile practices throughout the solution development process.\n\nDesign, build, and deploy databases and data stores to support organizational requirements.\n\nBasic Qualifications:\n\n4+ years of experience supporting Software Engineering, Data Engineering, or Data Analytics projects.\n\n2+ years of experience leading a team supporting data related projects to develop end-to-end technical solutions.\n\nExperience with Informatica, Python, Databricks, Azure Data Engineer\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nDemonstrate production experience in core data platforms such as Snowflake, Databricks, AWS, Azure, GCP, Hadoop, and more.\n\nPossess hands-on knowledge of Cloud and Distributed Data Storage, including expertise in HDFS, S3, ADLS, GCS, Kudu, ElasticSearch/Solr, Cassandra, or other NoSQL storage systems.\n\nExhibit a strong understanding of Data integration technologies, encompassing Informatica, Spark, Kafka, eventing/streaming, Streamsets, NiFi, AWS Data Migration Services, Azure DataFactory, Google DataProc.\n\nShowcase professional written and verbal communication skills to effectively convey complex technical concepts.\n\nUndergraduate or Graduate degree preferred",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'nosql', 'elastic search', 'cassandra', 'solr', 'core data', 'cloudera', 'python', 'data analytics', 'scala', 'kudu', 'microsoft azure', 'data engineering', 'data bricks', 'gen', 'java', 'apache nifi', 'spark', 'gcp', 'kafka', 'software engineering', 'hadoop', 'aws', 'data integration']",2025-06-11 05:49:18
Data Engineer,"NTT DATA, Inc.",4 - 9 years,Not Disclosed,['Pune'],"Req ID: 324609\n\nWe are currently seeking a Data Engineer to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nKey Responsibilities:\n\nDesign and implement tailored data solutions to meet customer needs and use cases, spanning from streaming to data lakes, analytics, and beyond within a dynamically evolving technical stack.\n\nProvide thought leadership by recommending the most appropriate technologies and solutions for a given use case, covering the entire spectrum from the application layer to infrastructure.\n\nDemonstrate proficiency in coding skills, utilizing languages such as Python, Java, and Scala to efficiently move solutions into production while prioritizing performance, security, scalability, and robust data integrations.\n\nCollaborate seamlessly across diverse technical stacks, including Cloudera, Databricks, Snowflake, and AWS.\n\nDevelop and deliver detailed presentations to effectively communicate complex technical concepts.\n\nGenerate comprehensive solution documentation, including sequence diagrams, class hierarchies, logical system views, etc.\n\nAdhere to Agile practices throughout the solution development process.\n\nDesign, build, and deploy databases and data stores to support organizational requirements.\n\nBasic Qualifications:\n\n4+ years of experience supporting Software Engineering, Data Engineering, or Data Analytics projects.\n\n2+ years of experience leading a team supporting data related projects to develop end-to-end technical solutions.\n\nExperience with Informatica, Python, Databricks, Azure Data Engineer\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nDemonstrate production experience in core data platforms such as Snowflake, Databricks, AWS, Azure, GCP, Hadoop, and more.\n\nPossess hands-on knowledge of Cloud and Distributed Data Storage, including expertise in HDFS, S3, ADLS, GCS, Kudu, ElasticSearch/Solr, Cassandra, or other NoSQL storage systems.\n\nExhibit a strong understanding of Data integration technologies, encompassing Informatica, Spark, Kafka, eventing/streaming, Streamsets, NiFi, AWS Data Migration Services, Azure DataFactory, Google DataProc.\n\nShowcase professional written and verbal communication skills to effectively convey complex technical concepts.\n\nUndergraduate or Graduate degree preferred",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'nosql', 'elastic search', 'cassandra', 'solr', 'core data', 'cloudera', 'python', 'data analytics', 'scala', 'kudu', 'microsoft azure', 'data engineering', 'data bricks', 'gen', 'java', 'apache nifi', 'spark', 'gcp', 'kafka', 'software engineering', 'hadoop', 'aws', 'data integration']",2025-06-11 05:49:19
Data Engineer,"NTT DATA, Inc.",4 - 9 years,Not Disclosed,['Pune'],"Req ID: 324653\n\nWe are currently seeking a Data Engineer to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nKey Responsibilities:\n\nDesign and implement tailored data solutions to meet customer needs and use cases, spanning from streaming to data lakes, analytics, and beyond within a dynamically evolving technical stack.\n\nProvide thought leadership by recommending the most appropriate technologies and solutions for a given use case, covering the entire spectrum from the application layer to infrastructure.\n\nDemonstrate proficiency in coding skills, utilizing languages such as Python, Java, and Scala to efficiently move solutions into production while prioritizing performance, security, scalability, and robust data integrations.\n\nCollaborate seamlessly across diverse technical stacks, including Cloudera, Databricks, Snowflake, and AWS.\n\nDevelop and deliver detailed presentations to effectively communicate complex technical concepts.\n\nGenerate comprehensive solution documentation, including sequence diagrams, class hierarchies, logical system views, etc.\n\nAdhere to Agile practices throughout the solution development process.\n\nDesign, build, and deploy databases and data stores to support organizational requirements.\n\nBasic Qualifications:\n\n4+ years of experience supporting Software Engineering, Data Engineering, or Data Analytics projects.\n\n2+ years of experience leading a team supporting data related projects to develop end-to-end technical solutions.\n\nExperience with Informatica, Python, Databricks, Azure Data Engineer\n\nAbility to travel at least 25%.""\n\nPreferred\n\nSkills:\n\n\nDemonstrate production experience in core data platforms such as Snowflake, Databricks, AWS, Azure, GCP, Hadoop, and more.\n\nPossess hands-on knowledge of Cloud and Distributed Data Storage, including expertise in HDFS, S3, ADLS, GCS, Kudu, ElasticSearch/Solr, Cassandra, or other NoSQL storage systems.\n\nExhibit a strong understanding of Data integration technologies, encompassing Informatica, Spark, Kafka, eventing/streaming, Streamsets, NiFi, AWS Data Migration Services, Azure DataFactory, Google DataProc.\n\nShowcase professional written and verbal communication skills to effectively convey complex technical concepts.\n\nUndergraduate or Graduate degree preferred",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['azure data lake', 'nosql', 'elastic search', 'cassandra', 'solr', 'core data', 'cloudera', 'python', 'data analytics', 'scala', 'kudu', 'microsoft azure', 'data engineering', 'data bricks', 'gen', 'java', 'apache nifi', 'spark', 'gcp', 'kafka', 'software engineering', 'hadoop', 'aws', 'data integration']",2025-06-11 05:49:21
Network Architect- Data Center,Konverge Technologies,5 - 10 years,Not Disclosed,['Gurugram'],"POSITION SUMMARY:\nWe are seeking an experienced Network Architect with expertise in Cisco Application Centric Infrastructure (ACI), Software-Defined Access (SDA), and Data Center networking technologies. The ideal candidate will design, implement, and optimise scalable, secure, and automated network solutions for enterprise and data centre environments.\n\nKey Roles & Responsibilities:\nIn this position, you will be required to:\nArchitect and design Cisco ACI-based data center network solutions, ensuring scalability and automation.\nImplement and optimize Cisco SDA for campus networking with DNA Center and ISE.\nDefine high-level network strategies, roadmaps, and architectures aligned with business objectives.\nLead data center network transformations, ensuring high availability and security.\nDeploy and configure Cisco Nexus switches, UCS, and Hyper converged infrastructure for data center environments.\nIntegrate and manage Cisco DNA Center for automation, policy enforcement, and assurance.\nImplement Zero Trust principles and micro-segmentation strategies across ACI and SDA networks.\nCollaborate with security, cloud, and infrastructure teams to develop integrated solutions.\nEvaluate emerging network technologies and provide recommendations for continuous improvement.\nDevelop and maintain technical documentation, including HLDs, LLDs, and operational guidelines.\nTroubleshoot complex network issues and provide expert-level support to operational teams.\nProvide mentorship and training to junior engineers and network teams.\n\nEducation/Experience:\nBachelors or Master’s in IT, or a related field.\n10+ years of experience in network engineering and architecture, with expertise in Cisco ACI, SDA, and Data Center technologies.\nDeep knowledge of Cisco ACI, APIC controllers, and multi-site fabric architectures.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['SDA', 'Vxlan', 'Apic', 'Cisco Aci', 'Network Architecture']",2025-06-11 05:49:22
QA-Data Migration Professional,"NTT DATA, Inc.",8 - 10 years,Not Disclosed,['Chennai'],"Job TitleQA Data Migration ""“ Core Banking (Transact)\n\n: We are looking for a highly skilled Quality Analyst with expertise in the banking sector, specifically in Core Banking (Transact) along with migration experience. The successful candidate will be responsible for ensuring the quality and integrity of data during migration from legacy systems to new platforms.\n\nKey Responsibilities:\nDevelop and execute test plans, test cases and test scripts to ensure data integrity, accuracy and completeness during migration.\nWork across multiple functional projects to understand data usage and implications for data migration.\nIdentify, Document and track data quality issues and collaborate with cross functional teams to resolve them.\nValidate data migrated to new systems, ensuring it meets business requirements and free from defects.\nIdentify, report and track defects found during testing and collaborate with development teams to resolve them.\n\n\n\nSkills and Qualifications:\n8-10 years of overall experience with a minimum of 3+ years as Core banking QA.\nProven experience as a Quality Analyst in the banking sector.\nIn-depth knowledge of Core Banking Transact and migration processes.\nFamiliarity with agile methodologies and project management principles.\nStrong analytical and problem-solving skills.\nExcellent communication and interpersonal abilities.\nAbility to work independently and as part of a team.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['automation testing', 'test cases', 'process migration', 'core banking', 'agile methodology', 'project management', 'operations management', 'software testing', 'team management', 'regression testing', 'manual testing', 'selenium webdriver', 'functional testing', 'quality assurance']",2025-06-11 05:49:24
Sr. Network Architect - Data Centre,Konverge Technologies,5 - 10 years,Not Disclosed,['Gurugram( Civil Lines )'],"Department: IT\nTitle: Network Architect (Minimum 10 Yrs. EXP)\nLocation: Gurgaon\nStatus: Regular, Full-Time:\nTravel: Across the Globe for Project and Business meetings\n\nPOSITION SUMMARY:\nWe are seeking an experienced Network Architect with expertise in Cisco Application Centric Infrastructure (ACI), Software-Defined Access (SDA), and Data Center networking technologies. The ideal candidate will design, implement, and optimise scalable, secure, and automated network solutions for enterprise and data centre environments.\nKey Roles & Responsibilities:\nIn this position, you will be required to:\nArchitect and design Cisco ACI-based data center network solutions, ensuring scalability and automation.\nImplement and optimize Cisco SDA for campus networking with DNA Center and ISE.\nDefine high-level network strategies, roadmaps, and architectures aligned with business objectives.\nLead data center network transformations, ensuring high availability and security.\nDeploy and configure Cisco Nexus switches, UCS, and Hyper converged infrastructure for data center environments.\nIntegrate and manage Cisco DNA Center for automation, policy enforcement, and assurance.\nImplement Zero Trust principles and micro-segmentation strategies across ACI and SDA networks.\nCollaborate with security, cloud, and infrastructure teams to develop integrated solutions.\nEvaluate emerging network technologies and provide recommendations for continuous improvement.\nDevelop and maintain technical documentation, including HLDs, LLDs, and operational guidelines.\nTroubleshoot complex network issues and provide expert-level support to operational teams.\nProvide mentorship and training to junior engineers and network teams.\nEducation/Experience:\nBachelors or Masters in IT, or a related field.\n10+ years of experience in network engineering and architecture, with expertise in Cisco ACI, SDA, and Data Center technologies.\nDeep knowledge of Cisco ACI, APIC controllers, and multi-site fabric architectures.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['SDA', 'Aci', 'Apic', 'Data Center Design', 'High Level Design', 'Low Level Design', 'Network Design', 'Ise', 'Architectural Design']",2025-06-11 05:49:25
QA - Core Banking Data migration,"NTT DATA, Inc.",8 - 10 years,Not Disclosed,"['Noida', 'Hyderabad', 'Bengaluru']","Req ID: 309049\n\nWe are currently seeking a QA - Core Banking Data migration to join our team in Noida, Uttar Pradesh (IN-UP), India (IN).\n\nJob TitleQA Data Migration ""“ Core Banking (Transact)\n\n: We are looking for a highly skilled Quality Analyst with expertise in the banking sector, specifically in Core Banking (Transact) along with migration experience. The successful candidate will be responsible for ensuring the quality and integrity of data during migration from legacy systems to new platforms.\n\nKey Responsibilities:\nDevelop and execute test plans, test cases and test scripts to ensure data integrity, accuracy and completeness during migration.\nWork across multiple functional projects to understand data usage and implications for data migration.\nIdentify, Document and track data quality issues and collaborate with cross functional teams to resolve them.\nValidate data migrated to new systems, ensuring it meets business requirements and free from defects.\nIdentify, report and track defects found during testing and collaborate with development teams to resolve them.\n\n\n\nSkills and Qualifications:\n8-10 years of overall experience with a minimum of 3+ years as Core banking QA.\nProven experience as a Quality Analyst in the banking sector.\nIn-depth knowledge of Core Banking Transact and migration processes.\nFamiliarity with agile methodologies and project management principles.\nStrong analytical and problem-solving skills.\nExcellent communication and interpersonal abilities.\nAbility to work independently and as part of a team.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['project management', 'data integrity', 'process migration', 'core banking', 'agile methodology', 'capa', 'operations management', 'data analysis', 'data validation', 'business analysis', 'data migration', 'gmp', 'sql', 'change control', 'oos', 'quality assurance', 'qms', 'banking sector']",2025-06-11 05:49:27
Digital Solution Architect Sr. Advisor,"NTT DATA, Inc.",10 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 323226\n\nWe are currently seeking a Digital Solution Architect Sr. Advisor to join our team in Bengaluru, India, Karntaka (IN-KA), India (IN).\n\nKey Responsibilities:\nDesign data platform architectures (data lakes, lakehouses, DWH) using modern cloud-native tools (e.g., Databricks, Snowflake, BigQuery, Synapse, Redshift).\nArchitect data ingestion, transformation, and consumption pipelines using batch and streaming methods.\nEnable real-time analytics and machine learning through scalable and modular data frameworks.\nDefine data governance models, metadata management, lineage tracking, and access controls.\nCollaborate with AI/ML, application, and business teams to identify high-impact use cases and optimize data usage.\nLead modernization initiatives from legacy data warehouses to cloud-native and distributed architectures.\nEnforce data quality and observability practices for mission-critical workloads.\n\nRequired\n\nSkills:\n\n10+ years in data architecture, with strong grounding in modern data platforms and pipelines.\nDeep knowledge of SQL/NoSQL, Spark, Delta Lake, Kafka, ETL/ELT frameworks.\nHands-on experience with cloud data platforms (AWS, Azure, GCP).\nUnderstanding of data privacy, security, lineage, and compliance (GDPR, HIPAA, etc.).\nExperience implementing data mesh/data fabric concepts is a plus.\nExpertise in technical solutions writing and presenting using tools such as Word, PowerPoint, Excel, Visio etc.\nHigh level of executive presence to be able to articulate the solutions to CXO level executives.\n\nPreferred Qualifications:\nCertifications in Snowflake, Databricks, or cloud-native data platforms.\nExposure to AI/ML data pipelines, MLOps, and real-time data applications.\nFamiliarity with data visualization and BI tools (Power BI, Tableau, Looker, etc.).",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['sql', 'nosql', 'spark', 'kafka', 'etl', 'metadata management', 'microsoft azure', 'power bi', 'data warehousing', 'data architecture', 'elt', 'machine learning', 'distributed architecture', 'tableau', 'gcp', 'visio', 'data governance', 'platform architecture', 'data visualization', 'aws']",2025-06-11 05:49:28
Director Data Science,Astar Data,10 - 17 years,Not Disclosed,['Bengaluru'],"Sigmoid enables business transformation using data and analytics, leveraging real-time insights to make accurate and fast business decisions, by building modern data architectures using cloud and open source. Some of the worlds largest data producers engage with Sigmoid to solve complex business problems. Sigmoid brings deep expertise in data engineering, predictive analytics, artificial intelligence, and DataOps. Sigmoid has been recognized as one of the fastest growing technology companies in North America, 2021, by Financial Times, Inc. 5000, and Deloitte Technology Fast 500.\nOffices: New York | Dallas | San Francisco | Lima | Bengaluru\nThe below role is for our Bengaluru office.\n\nWhy Join Sigmoid?\n• Sigmoid provides the opportunity to push the boundaries of what is possible by seamlessly\ncombining technical expertise and creativity to tackle intrinsically complex business\nproblems and convert them into straight-forward data solutions.\n• Despite being continuously challenged, you are not alone. You will be part of a fast-paced\ndiverse environment as a member of a high-performing team that works together to\nenergize and inspire each other by challenging the status quo\n• Vibrant inclusive culture of mutual respect and fun through both work and play\nRoles and Responsibilities:\n• Convert broad vision and concepts into a structured data science roadmap, and guide a\nteam to successfully execute on it.\n• Handling end-to-end client AI & analytics programs in a fluid environment. Your role will be a\ncombination of hands-on contribution, technical team management, and client interaction.\n• Proven ability to discover solutions hidden in large datasets and to drive business results\nwith their data-based insights\n• Contribute to internal product development initiatives related to data science.\n• Drive excellent project management required to deliver complex projects, including\neffort/time estimation.\n• Be proactive, with full ownership of the engagement. Build scalable client engagement level\nprocesses for faster turnaround & higher accuracy\n• Define Technology/ Strategy and Roadmap for client accounts, and guides implementation\nof that strategy within projects\n• Manage the team-members, to ensure that the project plan is being adhered to over the\ncourse of the project\n• Build a trusted advisor relationship with the IT management at clients and internal accounts\nleadership.\nMandated Skills:\n• A B-Tech/M-Tech/MBA from a top tier Institutepreferably in a quantitativesubject\n• 10+ years of hands-onexperience in applied Machine Learning, AI and analytics\n• Experience of scientific programming in scripting languages like Python, R, SQL, NoSQL,\nSpark with ML tools & Cloud Technology (AWS, Azure, GCP)\n• Experience in Python libraries such as numpy, pandas, scikit-learn, tensor-flow, scrapy, BERT\netc. Strong grasp of depth and breadth of machine learning, deep learning, data mining, and\nstatistical concepts and experience in developing models and solutions in these areas\n• Expertise with client engagement, understanding complex problem statements, and offering\nsolutions in the domains of Supply Chain, Manufacturing, CPG, Marketing etc.\nDesired Skills:\nDeep understanding of ML algorithms for common use cases in both structured and\nunstructured data ecosystems.\nComfortable with large scale data processing and distributed computing\nProviding required inputs to sales, and pre-sales activities\nA self-starter who can work well with minimalguidance\nExcellent written and verbal communication skills",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Science', 'Machine Learning', 'Algorithm Development', 'Pattern Recognition', 'Opencv', 'Image Processing', 'Artificial Intelligence', 'Natural Language Processing', 'Neural Networks', 'Computer Vision', 'Deep Learning']",2025-06-11 05:49:30
Data Engineer,Sorice Solutions,4 - 8 years,6-12 Lacs P.A.,['Chennai'],"Location: Chennai\n\n\nRole & responsibilities\n\n\nBackend data model and data architecture, data migration, using python/java to build data ingestion pipelines and data validation processes, develop task schedulers for different data sources",Industry Type: Miscellaneous,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Migration', 'Data Modeling', 'Python', 'SQL']",2025-06-11 05:49:31
Data Engineer Graph – Research Data and Analytics,Amgen Inc,2 - 4 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will be part Researchs Semantic Graph Team is seeking a qualified individual to design, build, and maintain solutions for scientific data that drive business decisions for Research. The successful candidate will construct scalable and high-performance data engineering solutions for extensive scientific datasets and collaborate with Research partners to address their data requirements. The ideal candidate should have experience in the pharmaceutical or biotech industry, leveraging their expertise in semantics, taxonomies, and linked data principles to ensure data harmonization and interoperability. Additionally, this individual should demonstrate robust technical skills, proficiency with data engineering technologies, and a thorough understanding of data architecture and ETL processes.\nRoles & Responsibilities:\nDesign, develop, and implement data pipelines, ETL/ELT processes, and data integration solutions\nTake ownership of data pipeline projects from inception to deployment, manage scope, timelines, and risks\nDevelop and maintain semantic data models for biopharma scientific data, data dictionaries, and other documentation to ensure data accuracy and consistency\nOptimize large datasets for query performance\nCollaborate with global multi-functional teams including research scientists to understand data requirements and design solutions that meet business needs\nImplement data security and privacy measures to protect sensitive data\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions\nCollaborate with Data Architects, Business SMEs, Software Engineers and Data Scientists to design and develop end-to-end data pipelines to meet fast paced business needs across geographic regions\nIdentify and resolve [complex] data-related challenges\nAdhere to standard processes for coding, testing, and designing reusable code/component\nExplore new tools and technologies that will help to improve ETL platform performance\nParticipate in sprint planning meetings and provide estimations on technical implementation\nMaintain comprehensive documentation of processes, systems, and solutions\n\n\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients. T\nBasic Qualifications and Experience:\nDoctorate Degree OR Masters degree with 2- 4years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nBachelors degree with 4- 6years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field OR\nDiploma with 7- 9 years of experience in Computer Science, IT, Computational Chemistry, Computational Biology/Bioinformatics or related field\n\n\nPreferred Qualifications and Experience:\n4+ years of experience in designing and supporting biopharma scientific research data analytics (software platforms)\n\n\nFunctional Skills:\nMust-Have Skills:\nProficiency in SQL and Python for data engineering, test automation frameworks (pytest), and scripting tasks\nHands on experience with data technologies and platforms, such as Databricks, workflow orchestration, performance tuning on big data processing.\nExcellent problem-solving skills and the ability to work with large, complex datasets\n\n\nGood-to-Have Skills:\nA passion for tackling complex challenges in drug discovery with technology and data\nExperience with system administration skills, such as managing Linux and Windows servers, configuring network infrastructure, and automating tasks with shell scripting. Examples include setting up and maintaining virtual machines, troubleshooting server issues, and ensuring data security through regular updates and backups.\nSolid understanding of data modeling, data warehousing, and data integration concepts\nSolid experience using RDBMS (e.g. Oracle, MySQL, SQL server, PostgreSQL)\nKnowledge of cloud data platforms (AWS preferred)\nExperience with data visualization tools (e.g. Dash, Plotly, Spotfire)\nExperience with diagramming and collaboration tools such as Miro, Lucidchart or similar tools for process mapping and brainstorming\nExperience writing and maintaining user documentation in Confluence\nUnderstanding of data governance frameworks, tools, and standard processes\n\n\nProfessional Certifications:\nDatabricks Certified Data Engineer Professional preferred\n\n\nSoft Skills:\nExcellent critical-thinking and problem-solving skills\nGood communication and collaboration skills\nDemonstrated awareness of how to function in a team setting\nDemonstrated presentation skills",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Analytics', 'PostgreSQL', 'MySQL', 'ETL', 'ELT', 'Oracle', 'SQL server', 'AWS']",2025-06-11 05:49:33
Data Engineer,Tekskills India pvt ltd,7 - 9 years,8-15 Lacs P.A.,['Hyderabad'],"Role & Responsibilities Role Overview: We are seeking a talented and forward-thinking Data Engineer for one of the large financial services GCC based in Hyderabad with responsibilities that include designing and constructing data pipelines, integrating data from multiple sources, developing scalable data solutions, optimizing data workflows, collaborating with cross-functional teams, implementing data governance practices, and ensuring data security and compliance.\n\nTechnical Requirements: • Proficiency in ETL, Batch, and Streaming Process • Experience with BigQuery, Cloud Storage, and CloudSQL • Strong programming skills in Python, SQL, and Apache Beam for data processing • Understanding of data modeling and schema design for analytics • Knowledge of data governance, security, and compliance in GCP • Familiarity with machine learning workflows and integration with GCP ML tools • Ability to optimize performance within data pipelines\n\nFunctional Requirements: • Ability to collaborate with Data Operations, Software Engineers, Data Scientists, and Business SMEs to develop Data Product Features • Experience in leading and mentoring peers within an existing development team • Strong communication skills to craft and communicate robust solutions • Proficient in working with Engineering Leads, Enterprise and Data Architects, and Business Architects to build appropriate data foundations • Willingness to work on contemporary data architecture in Public and Private Cloud environments This role offers a compelling opportunity for a seasoned Data Engineering to drive transformative cloud initiatives within the financial sector, leveraging unparalleled experience and expertise to deliver innovative cloud solutions that align with business imperatives and regulatory requirements. Qualification o Engineering Grad / Postgraduate CRITERIA o Proficient in ETL, Python, and Apache Beam for data processing efficiency. o Demonstrated expertise in BigQuery, Cloud Storage, and CloudSQL utilization. o Strong collaboration skills with cross-functional teams for data product development. o Comprehensive knowledge of data governance, security, and compliance in GCP. o Experienced in optimizing performance within data pipelines for efficiency.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['ETL', 'GCP', 'Apache beam', 'Bigquery', 'Cloud sql', 'Cloudstorage', 'Python']",2025-06-11 05:49:34
"Sustainable, Client and Regulatory Reporting Data Product Owner",Capital Markets,15 - 20 years,Not Disclosed,['Bengaluru'],"Hiring, Sustainable, Client and Regulatory Reporting Data Product Owner - ISS Data (Associate Director)\nAbout your team\n\nThe Technology function provides IT services that are integral to running an efficient run-the business operating model and providing change-driven solutions to meet outcomes that deliver on our business strategy. These include the development and support of business applications that underpin our revenue, operational, compliance, finance, legal, marketing and customer service functions. The broader organisation incorporates Infrastructure services that the firm relies on to operate on a day-to-day basis including data centre, networks, proximity services, security, voice, incident management and remediation.\nThe Technology group is responsible for providing Technology solutions to the Investment Solutions & Services business (which covers Investment Management, Asset Management Operations & Distribution business units globally)\n\nThe Technology team supports and enhances existing applications as well as designs, builds and procures new solutions to meet requirements and enable the evolving business strategy.\nAs part of this group, a dedicated Data Programme team has been mobilised as a key foundational programme to support the execution of the overarching Investment Solutions and Service strategy.\n\nAbout your role\nThe Investment Reporting Data Product Owner role is instrumental in the creation and execution of a future state data reporting product to enable Regulatory, Client, Vendor, Internal & MI reporting and analytics. The successful candidate will have an in- depth knowledge of all data domains that represent institutional clients , the investment life cycle , regulatory and client reporting data requirements.\nThe role will sit within the ISS Delivery Data Analysis chapter and fully aligned with our cross functional ISS Data Programme in Technology, and the candidate will leverage their extensive industry knowledge to build a future state platform in collaboration with Business Architecture, Data Architecture, and business stakeholders.\nThe role is to maintain strong relationships with the various business contacts to ensure a superior service to our internal business stakeholders and our clients.\n\nKey Responsibilities\n\nLeadership and Management:\nLead the ISS distribution, Client Propositions, Sustainable Investing and Regulatory reporting data outcomes defining the data roadmap and capabilities and supporting the execution and delivery of the data solutions as a Data Product lead within the ISS Data Programme.\nLine management responsibilities for junior data analysts within the chapter, coaching, influencing and motivating them for high performance.\nDefine the data product vision and strategy with end-to-end thought leadership.\nLead and define the data product backlog , documentation, enable peer-reviews, analysis effort estimation, maintain backlog, and support end to end planning.\nBe a catalyst of change for driving efficiencies, scale and innovation.\n\nData Quality and Integrity:\nDefine data quality use cases for all the required data sets and contribute to the technical frameworks of data quality.\nAlign the functional solution with the best practice data architecture & engineering.\n\nCoordination and Communication:\nSenior management level communication to influence senior tech and business stakeholders globally, get alignment on the roadmaps.\nCoordinate with internal and external teams to communicate with those impacted by data flows.\nAn advocate for the ISS Data Programme.\nCollaborate closely with Data Governance, Business Architecture, and Data owners etc.\nConduct workshops within the scrum teams and across business teams, effectively document the minutes and drive the actions.\n\nAbout you\nThe Investment Reporting Data Product Owner role is instrumental in the creation and execution of a future state data reporting product to enable Regulatory, Client, Vendor, Internal & MI reporting and analytics. The successful candidate will have an in- depth knowledge of all data domains that represent institutional clients , the investment life cycle , regulatory and client reporting data requirements.\nThe role will sit within the ISS Delivery Data Analysis chapter and fully aligned with cross functional ISS Data Programme in Technology, and the candidate will leverage their extensive industry knowledge to build a future state platform in collaboration with Business Architecture, Data Architecture, and business stakeholders.\nThe role is to maintain strong relationships with the various business contacts to ensure a superior service to our internal business stakeholders and our clients.\n\nKey Responsibilities\n\nLeadership and Management:\nLead the ISS distribution, Client Propositions, Sustainable Investing and Regulatory reporting data outcomes defining the data roadmap and capabilities and supporting the execution and delivery of the data solutions as a Data Product lead within the ISS Data Programme.\nLine management responsibilities for junior data analysts within the chapter, coaching, influencing and motivating them for high performance.\nDefine the data product vision and strategy with end-to-end thought leadership.\nLead and define the data product backlog , documentation, enable peer-reviews, analysis effort estimation, maintain backlog, and support end to end planning.\nBe a catalyst of change for driving efficiencies, scale and innovation.\n\nData Quality and Integrity:\nDefine data quality use cases for all the required data sets and contribute to the technical frameworks of data quality.\nAlign the functional solution with the best practice data architecture & engineering.\n\nCoordination and Communication:\nSenior management level communication to influence senior tech and business stakeholders globally, get alignment on the roadmaps.\nCoordinate with internal and external teams to communicate with those impacted by data flows.\nAn advocate for the ISS Data Programme.\nCollaborate closely with Data Governance, Business Architecture, and Data owners etc.\nConduct workshops within the scrum teams and across business teams, effectively document the minutes and drive the actions.\n\nYour Skills and Experience\n\nStrong leadership and senior management level communication, internal and external client management and influencing skills.\nAt least 15 years of proven experience as a senior business/technical/data analyst within technology and/or business change delivering data led business outcomes within the financial services/asset management industry.\n5-10 years as a data product owner adhering to agile methodology, delivering data solutions using industry leading data platforms such as Snowflake, State Street Alpha Data, Refinitiv Eikon, SimCorp Dimension, BlackRock Aladdin, FactSet etc.\nOutstanding knowledge of Client life cycle covering institutional & wholesale with a focus on CRM data, Transfer agency data.\nVery good understanding of the data generated by investment management processes and how that is leveraged in Go-to market capabilities such as client reporting, Sales, Marketing.\nExcellent knowledge of regulatory environment with a focus on European regulations and ESG specific ones such as MIFID II, EMIR, SFDR.\nWork effortlessly in different operating models such as insourcing, outsourcing and hybrid models.\nAutomation mindset that can drive efficiencies and quality in the reporting landscape.\nKnowledge of industry standard data calcs for fund factsheets, Institutional admin and investment reports would be an added advantage.\nIn Depth expertise in data and calculations across the investment industry covering the below.\nClient Specific data: This includes institutional and wholesale client, account and channels data, client preferences and data sets needed for client analytics. Knowledge of Salesforce desirable.\nTransfer Agency & Platform data: This includes granular client holdings at various levels, client transactions and relevant ref data. Knowledge of role of TPAs as TA and integrating external feeds/products with strategic inhouse data platforms.\nInvestment data: This includes investment life cycle data covering data domains such as trading, ABOR, IBOR, Security and fund reference.\nShould possess Problem Solving, Attention to detail, Critical thinking.\nTechnical Skills: Hands on SQL, Advanced Excel, Python, ML (optional) and knowledge of end-to-end tech solutions involving data platforms.\nKnowledge of data management, data governance, and data engineering practices\nHands on experience with data modelling techniques such as dimensional, data vault.\nWillingness to own and drive things, collaboration across business and tech stakeholders.",Industry Type: Investment Banking / Venture Capital / Private Equity,Department: Product Management,"Employment Type: Full Time, Permanent","['Data Transformation', 'ESG Framework', 'Snowflake', 'Asset Management', 'Product Owner', 'Product Manager', 'MIFID II', 'alphastate street', 'SQL', 'EMIR', 'Data Quality', 'Data Analysis', 'charles river', 'Agile', 'UK Regulatory Reporting', 'data roadmap', 'Capital Market Operations', 'Aladdin', 'SFDR.', 'Python', 'ML']",2025-06-11 05:49:36
OAC ODI Architect (Senior Oracle Analytics Consultant),Mastek,10 - 15 years,15-30 Lacs P.A.,"['Ahmedabad', 'Chennai']","We are looking for OAC ODI Architect to be based in Ahemdabad or Chennai\nMinimum Architect exp 4 Yrs\nOracle Analytics Consultant (OAC, ODI, FDI) Tech Architect\nLocation: [Specify Location or Remote] Chennai Ahmedabad\nExpected DOJ June\nEmployment Type: Full-time\nExperience Level: 10 - 15+ Years\nJob Summary:\nWe are seeking an experienced and results-driven Senior Oracle Analytics Consultant with over 10 years of hands-on experience in Oracle Analytics Cloud (OAC), Oracle Data Integrator (ODI), and Fusion Data Intelligence (FDI). The ideal candidate will have a deep understanding of enterprise data architecture, data integration best practices, and cloud-based analytics solutions. This role involves working closely with cross-functional teams to design, implement, and support advanced analytics and data integration solutions that drive business value.\nKey Responsibilities:\nLead the design, development, and deployment of analytics solutions using Oracle Analytics Cloud (OAC).\nArchitect and implement data integration pipelines using Oracle Data Integrator (ODI) for on-prem and cloud data sources.\nCollaborate with business and IT stakeholders to design and deploy Fusion Data Intelligence (FDI) based dashboards and KPIs.\nOptimize performance of OAC dashboards and reports, including data modeling and visualization best practices.\nDevelop and manage data models, RPDs, and semantic layers within OAC.\nBuild and maintain ETL mappings, packages, and workflows in ODI.\nIntegrate Oracle Fusion Applications with OAC and FDI for near-real-time reporting.\nDrive data governance and quality initiatives across analytics platforms.\nTroubleshoot technical issues and provide solutions in a timely manner.\nMentor junior developers and provide technical leadership on complex projects.\nQualifications:\nBachelors or Masters degree in Computer Science, Information Systems, or related field.\n10+ years of relevant experience with strong focus on:\nOracle Analytics Cloud (OAC) - Must\nOracle Data Integrator (ODI) - Must\nFusion Data Intelligence (FDI) Good to Have\nExpertise in Oracle Fusion ERP/HCM data models and subject areas.\nExperience integrating multiple data sources, including on-premise and cloud systems.\nStrong understanding of SQL, PL/SQL, and performance tuning.\nFamiliarity with data lake architecture, data warehousing, and ELT/ETL design patterns.\nProven experience working in Agile/DevOps environments.\nExcellent communication, analytical thinking, and problem-solving skills.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Oac', 'ODI', 'Odi Architecture', 'FDI']",2025-06-11 05:49:37
Lead Data Analyst-Business Intelligence,Tresvista Financial Services,6 - 10 years,Not Disclosed,['Bengaluru'],"Roles and Responsibilities\nArchitect and incorporate an effective Data framework enabling end to end Data Solution.\nUnderstand business needs, use cases and drivers for insights and translate them into detailed technical specifications.\nCreate epics, features and user stories with clear acceptance criteria for execution and delivery by the data engineering team.\nCreate scalable and robust data solution designs that incorporate governance, security and compliance aspects.\nDevelop and maintain logical and physical data models and work closely with data engineers, data analysts and data testers for successful implementation of them.\nAnalyze, assess and design data integration strategies across various sources and platforms.\nCreate project plans and timelines while monitoring and mitigating risks and controlling progress of the project.\nConduct daily scrum with the team with a clear focus on meeting sprint goals and timely resolution of impediments.\nAct as a liaison between technical teams and business stakeholders and ensure.\nGuide and mentor the team for best practices on Data solutions and delivery frameworks.\nActively work, facilitate and support the stakeholders/ clients to complete User Acceptance Testing ensure there is strong adoption of the data products after the launch.\nDefining and measuring KPIs/KRA for feature(s) and ensuring the Data roadmap is verified through measurable outcomes\n\nPrerequisites\n5 to 8 years of professional, hands on experience building end to end Data Solution on Cloud based Data Platforms including 2+ years working in a Data Architect role.\nProven hands on experience in building pipelines for Data Lakes, Data Lake Houses, Data Warehouses and Data Visualization solutions\nSound understanding of modern Data technologies like Databricks, Snowflake, Data Mesh and Data Fabric.\nExperience in managing Data Life Cycle in a fast-paced, Agile / Scrum environment.\nExcellent spoken and written communication, receptive listening skills, and ability to convey complex ideas in a clear, concise fashion to technical and non-technical audiences\nAbility to collaborate and work effectively with cross functional teams, project stakeholders and end users for quality deliverables withing stipulated timelines\nAbility to manage, coach and mentor a team of Data Engineers, Data Testers and Data Analysts. Strong process driver with expertise in Agile/Scrum framework on tools like Azure DevOps, Jira or Confluence\nExposure to Machine Learning, Gen AI and modern AI based solutions.\n\nExperience\nTechnical Lead Data Analytics with 6+ years of overall experience out of which 2+ years is on Data architecture.\n\nEducation\nEngineering degree from a Tier 1 institute preferred.\n\nCompensation\nThe compensation structure will be as per industry standards",Industry Type: Financial Services,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'Data Bricks', 'Data Lake', 'Data Warehousing', 'Python', 'Business Intelligence', 'Databricks Engineer', 'Machine Learning', 'Redshift Aws', 'Snowflake', 'Data Visualization', 'ETL', 'Data Mesh']",2025-06-11 05:49:40
Data Engineer - SAS Migration,Crisil,2 - 4 years,Not Disclosed,['Mumbai'],"The SAS to Databricks Migration Developer will be responsible for migrating existing SAS code, data processes, and workflows to the Databricks platform. This role requires expertise in both SAS and Databricks, with a focus on converting SAS logic into scalable PySpark and Python code. The developer will design, implement, and optimize data pipelines, ensuring seamless integration and functionality within the Databricks environment. Collaboration with various teams is essential to understand data requirements and deliver solutions that meet business needs",Industry Type: Financial Services,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['hive', 'scala', 'pyspark', 'data warehousing', 'data migration', 'sql', 'spark', 'gcp', 'mysql', 'hadoop', 'bigquery', 'big data', 'etl', 'python', 'sas', 'teradata', 'airflow', 'microsoft azure', 'data engineering', 'sql server', 'dataproc', 'data bricks', 'cloud data flow', 'kafka', 'migration', 'sqoop', 'data flow']",2025-06-11 05:49:41
Senior Data Engineer,Straive,6 - 10 years,Not Disclosed,['Mumbai (All Areas)'],Senior Data Engineer\nYou will have the following responsibilities:\nDesign\nAnalyse relevant internally and externally sourced data (raw data) to generate BI and Advanced\nAnalytics datasets based on your stakeholders requirements,,,,"['AWS', 'Postgresql', 'Snowflake', 'Data Warehousing', 'ETL', 'Aws Rds Oracle']",2025-06-11 05:49:43
Solutions Architect,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,"['New Delhi', 'Chennai', 'Bengaluru']","Your day at NTT DATA\nWe are seeking an experienced Data Architect to join our team in designing and delivering innovative data solutions to clients. The successful candidate will be responsible for architecting, developing, and implementing data management solutions and data architectures for various industries. This role requires strong technical expertise, excellent problem-solving skills, and the ability to work effectively with clients and internal teams to design and deploy scalable, secure, and efficient data solutions.\nWhat you'll be doing\nWe are seeking an experienced Data Architect to join our team in designing and delivering innovative data solutions to clients. The successful candidate will be responsible for architecting, developing, and implementing data management solutions and data architectures for various industries. This role requires strong technical expertise, excellent problem-solving skills, and the ability to work effectively with clients and internal teams to design and deploy scalable, secure, and efficient data solutions.\nExperience and Leadership:\nProven experience in data architecture, with a recent role as a Lead Data Solutions Architect, or a similar senior position in the field.\nProven experience in leading architectural design and strategy for complex data solutions and then overseeing their delivery.\nExperience in consulting roles, delivering custom data architecture solutions across various industries.\nArchitectural Expertise:\nStrong expertise in designing and overseeing delivery of data streaming and event-driven architectures, with a focus on Kafka and Confluent platforms.\nIn-depth knowledge in architecting and implementing data lakes and lakehouse platforms, including experience with Databricks and Unity Catalog.\nProficiency in conceptualising and applying Data Mesh and Data Fabric architectural patterns.\nExperience in developing data product strategies, with a strong inclination towards a product-led approach in data solution architecture.\nExtensive familiarity with cloud data architecture on platforms such as AWS, Azure, GCP, and Snowflake.\nUnderstanding of cloud platform infrastructure and its impact on data architecture.\nData Technology Skills:\nA solid understanding of big data technologies such as Apache Spark, and knowledge of Hadoop ecosystems.\nKnowledge of programming languages such as Python or R is beneficial.\nExposure to ETL/ ELT processes, SQL, NoSQL databases is a nice-to-have, providing a well-rounded background.\nExperience with data visualization tools and DevOps principles/tools is advantageous.\nFamiliarity with machine learning and AI concepts, particularly in how they integrate into data architectures.\nDesign and Lifecycle Management:\nProven background in designing modern, scalable, and robust data architectures.\nComprehensive grasp of the data architecture lifecycle, from concept to deployment and consumption.\nData Management and Governance:\nStrong knowledge of data management principles and best practices, including data governance frameworks.\nExperience with data security and compliance regulations (GDPR, CCPA, HIPAA, etc.)\nLeadership and Communication:\nExceptional leadership skills to manage and guide a team of architects and technical experts.\nExcellent communication and interpersonal skills, with a proven ability to influence architectural decisions with clients and guide best practices\nProject and Stakeholder Management:\nExperience with agile methodologies (e.g. SAFe, Scrum, Kanban) in the context of architectural projects.\nAbility to manage project budgets, timelines, and resources, maintaining focus on architectural deliverables.\nLocation: Delhi or Bangalore\nWorkplace type:\nHybrid Working",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Solution architecture', 'snowflake', 'python', 'data management', 'big data technologies', 'microsoft azure', 'data architecture', 'sql', 'data bricks', 'spark', 'gcp', 'devops', 'kanban', 'kafka', 'architectural patterns', 'scrum', 'agile', 'hadoop', 'conceptualization', 'aws', 'etl', 'data lake']",2025-06-11 05:49:45
Lead AWS Glue Data Engineer,Allegis Group,8 - 13 years,Not Disclosed,[],"Lead AWS Glue Data Engineer\nJob Location : Hyderabad / Bangalore / Chennai / Noida/ Gurgaon / Pune / Indore / Mumbai/ Kolkata\n\nWe are seeking a skilled Lead AWS Data Engineer with 8+ years of strong programming and SQL skills to join our team. The ideal candidate will have hands-on experience with AWS Data Analytics services and a basic understanding of general AWS services. Additionally, prior experience with Oracle and Postgres databases and secondary skills in Python and Azure DevOps will be an advantage.\n\nKey Responsibilities:\nDesign, develop, and optimize data pipelines using AWS Data Analytics services such as RDS, DMS, Glue, Lambda, Redshift, and Athena.\nImplement data migration and transformation processes using AWS DMS and Glue.\nWork with SQL (Oracle & Postgres) to query, manipulate, and analyse large datasets.\nDevelop and maintain ETL/ELT workflows for data ingestion and transformation.\nUtilize AWS services like S3, IAM, CloudWatch, and VPC to ensure secure and efficient data operations.\nWrite clean and efficient Python scripts for automation and data processing.\nCollaborate with DevOps teams using Azure DevOps for CI/CD pipelines and infrastructure management.\nMonitor and troubleshoot data workflows to ensure high availability and performance.\n\nPreferred Qualifications:\nAWS certifications in Data Analytics, Solutions Architect, or DevOps.\nExperience with data warehousing concepts and data lake implementations.\nHands-on experience with Infrastructure as Code (IaC) tools like Terraform or CloudFormation.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['RDS', 'Glue', 'DMS', 'Lambda', 'Redshift', 'Athena']",2025-06-11 05:49:47
Technical Lead - Sr. Data Engineer,Edgematics Consulting,8 - 13 years,Not Disclosed,['Pune'],"About This Role :\n\nWe are looking for a talented and experienced Data Engineer with Tech Lead with hands-on expertise in any ETL Tool with full knowledge about CI/CD practices with leading a team technically more than 5 and client facing and create Data Engineering, Data Quality frameworks. As a tech lead must ensure to build ETL jobs, Data Quality Jobs, Big Data Jobs performed performance optimization by understanding the requirements, create re-usable assets and able to perform production deployment and preferably worked in DWH appliances Snowflake / redshift / Synapse\n\nResponsibilities\nWork with a team of engineers in designing, developing, and maintaining scalable and efficient data solutions using Any Data Integration (any ETL tool like Talend / Informatica) and any Big Data technologies.\nDesign, develop, and maintain end-to-end data pipelines using Any ETL Data Integration (any ETL tool like Talend / Informatica) to ingest, process, and transform large volumes of data from heterogeneous sources.\nHave good experience in designing cloud pipelines using Azure Data Factory or AWS Glues/Lambda.\nImplemented Data Integration end to end with any ETL technologies.\nImplement database solutions for storing, processing, and querying large volumes of structured and unstructured and semi-structured data\nImplement Job Migrations of ETL Jobs from Older versions to New versions.\nImplement and write advanced SQL scripts in SQL Database at medium to expert level. \nWork with technical team with client and provide guidance during technical challenges.\nIntegrate and optimize data flows between various databases, data warehouses, and Big Data platforms.\nCollaborate with cross-functional teams to gather data requirements and translate them into scalable and efficient data solutions.\nOptimize ETL, Data Load performance, scalability, and cost-effectiveness through optimization techniques.\nInteract with Client on a daily basis and provide technical progress and respond to technical questions.\nImplement best practices for data integration.\nImplement complex ETL data pipelines or similar frameworks to process and analyze massive datasets.\nEnsure data quality, reliability, and security across all stages of the data pipeline.\nTroubleshoot and debug data-related issues in production systems and provide timely resolution.\nStay current with emerging technologies and industry trends in data engineering technologies, CI/CD, and incorporate them into our data architecture and processes.\nOptimize data processing workflows and infrastructure for performance, scalability, and cost-effectiveness.\nProvide technical guidance and foster a culture of continuous learning and improvement.\nImplement and automate CI/CD pipelines for data engineering workflows, including testing, deployment, and monitoring.\nPerform migration to production deployment from lower environments, test & validate\n\nMust Have Skills\nMust be certified in any ETL tools, Database, Cloud.(Snowflake certified is more preferred)\nMust have implemented at least 3 end-to-end projects in Data Engineering.\nMust have worked on performance management optimization and tuning for data loads, data processes, data transformation in big data\nMust be flexible to write code using JAVA/Scala/Python etc. as required\nMust have implemented CI/CD pipelines using tools like Jenkins, GitLab CI, or AWS CodePipeline.\nMust have managed a team technically of min 5 members and guided the team technically.\nMust have the Technical Ownership capability of Data Engineering delivery.\nStrong communication capabilities with client facing.\nBachelor's or Master's degree in Computer Science, Engineering, or a related field.\n5 years of experience in software engineering or a related role, with a strong focus on Any ETL Tool, database, integration.\nProficiency in Any ETL tools like Talend , Informatica etc for Data Integration for building and orchestrating data pipelines.\nHands-on experience with relational databases such as MySQL, PostgreSQL, or Oracle, and NoSQL databases such as MongoDB, Cassandra, or Redis.\nSolid understanding of database design principles, data modeling, and SQL query optimization.\nExperience with data warehousing, Data Lake , Delta Lake concepts and technologies, data modeling, and relational databases.",Industry Type: IT Services & Consulting,"Department: Production, Manufacturing & Engineering","Employment Type: Full Time, Permanent","['Data Engineering', 'Snowflake', 'ETL', 'Azure Aws', 'Data Management', 'Big Data', 'Ci/Cd', 'Data Integration', 'Data Quality', 'Data Pipeline', 'Data Warehousing', 'Data Modeling', 'Data Governance']",2025-06-11 05:49:48
Data Migration Engineer,A Global Engineering and Technology Solu...,4 - 6 years,Not Disclosed,['Pune'],"Roles and Responsibilities\nDesign, develop, test, and deploy data migration solutions using various tools such as PTC, WBM, CAD, PDM Link, Java Utilities, Loaders, SQL, and Oracle.\nCollaborate with cross-functional teams to identify business requirements and design data migration strategies that meet those needs.\nDevelop complex database queries to extract relevant data from legacy systems for migration into new platforms.\nConduct thorough testing of migrated data to ensure accuracy and integrity.\nProvide technical guidance on best practices for data management and governance.\nDesired Candidate Profile\n4-6 years of experience in Data Migration Engineering with expertise in one or more of the following areas: PTC/WBM/CAD/PDM Link/Java Utilities/Loaders/SQL/Oracle.\nBachelor's degree in Any Specialization (B.Tech/B.E.).\nStrong understanding of software development life cycle (SDLC) principles and methodologies.\nProficiency in writing efficient code using programming languages like Java or Python.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['WBM', 'Pdm Link', 'Java utilities', 'Oracle', 'Windchill', 'loaders', 'SQL']",2025-06-11 05:49:50
Salesforce Data Cloud Developer,Avenoir Technologies,3 - 8 years,Not Disclosed,"['Bengaluru', 'Delhi / NCR', 'Mumbai (All Areas)']","Develop and implement solutions within Salesforce Data Cloud, focusing on data-driven insights and integrations.\nDesign, develop, and maintain custom solutions using Apex and Lightning Web Components (LWC).\nIntegrate Salesforce Data Cloud\n\nRequired Candidate profile\n3 years of experience as a Salesforce Developer with a strong focus on Salesforce Data Cloud.\nCompleted 2 successful Salesforce Data Cloud projects.\nStrong skills in Apex and Lightning Web Components.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Salesforce Data Cloud', 'Data Transformation', 'Einstein Analytics', 'Einstein Bots', 'modeling', 'duplicate management', 'LWC', 'data architecture', 'Tableau', 'identity resolution', 'Apex']",2025-06-11 05:49:51
Data Migration Expert - Talend,Maddisoft Solutions,10 - 20 years,Not Disclosed,['Hyderabad'],"Job Title: Data Migration Expert - Talend\nLocation: Hyderabad, India\n\nJob Description:\nMinimum of 9+ years of experience in data migration in Talend projects\nHandsons experience 5+ mandatory knowledge of Talend/SQL tools(Basic knowledge of SAP Routing and SAP Production order tables Individually is an add on)\nProficiency in data migration tools and methodologies, SAP ECC AND S/4HANA Migration Cockpit.\nHands-on experience Data Replication, Data Quality, Data Workbench, Talend or similar ETL tools.\nFamiliarity with Talend (ETL) is plus.\nStrong understanding of data modeling concepts, data mapping techniques, and data transformation rules.\nExcellent SQL skills for data extraction, manipulation, and analysis.\nExperience with SAP all Cross functional modules such as Finance (FI), Controlling (CO), Material Management (MM), Sales and Distribution (SD), or Production Planning (PP).\nStrong analytical, problem-solving, and troubleshooting skills.\nExcellent communication, presentation, and interpersonal skills.\nAbility to work independently and as part of a team in a fast-paced, dynamic environment.\nSAP certification in Data Migration or related field is a plus.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['SAP ECC', 'Data Migration', 'Talend']",2025-06-11 05:49:53
APAC Presales Solution Architect,"NTT DATA, Inc.",12 - 15 years,Not Disclosed,['Bengaluru'],"Req ID: 328244\n\nWe are currently seeking a APAC Presales Solution Architect to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n""Job DutiesSenior Data and AI Architect ""“ Presales\nGrade 11\n\nSeeking a senior data solution architect to closely work with India and APAC sales teams for technical solutioning and presales work.\n\nThe Consultant is a seasoned level expert who is responsible for participating in the delivery of multi-technology consulting services to clients by providing strategies and solutions on all aspects of infrastructure and related technology components.\n\nThis role collaborates with other stakeholders on the development of the architectural approach for one or more layer of a solution. This role has the primary objective is to work on strategic projects that ensure the optimal functioning of the client""™s technology infrastructure.\n""¢ Key Responsibilities:\n""¢ Ability and experience to have conversations with the CEO, Business owners and CTO/CDO\n""¢ Break down intricate business challenges, devise effective solutions, and focus on client needs.\n""¢ Craft high level innovative solution approach for complex business problems\n""¢ Utilize best practices and creativity to address challenges\n""¢ Leverage market research, formulate perspectives, and communicate insights to clients\n""¢ Establish strong client relationships\n""¢ Interact at appropriate levels to ensure client satisfaction\n\nMinimum Skills Required""¢ Knowledge and Attributes:\n""¢ Ability to focus on detail with an understanding of how it impacts the business strategically.\n""¢ Excellent client service orientation.\n""¢ Ability to work in high-pressure situations.\n""¢ Ability to establish and manage processes and practices through collaboration and the understanding of business.\n""¢ Ability to create new and repeat business for the organization.\n""¢ Ability to contribute information on relevant vertical markets\n""¢ Ability to contribute to the improvement of internal effectiveness by contributing to the improvement of current methodologies, processes and tools.\n\n""¢ Academic Qualifications and Certifications:\n""¢ BE/BTech or equivalent in Information Technology and/or Business Management or a related field.\n""¢ Scaled Agile certification desirable.\n""¢ Relevant consulting and technical certifications preferred, for example TOGAF.\n\n""¢ Required Experience12-15 years\n""¢ Seasoned demonstrable experience in a similar role within a large scale (preferably multi- national) technology services environment.\n""¢ Very good understanding of Data, AI, Gen AI and Agentic AI\n""¢ Must have Data Architecture and Solutioning experience. Capable of E2E Data Architecture and GenAI Solution design.\n""¢ Must be able to work on Data & AI RFP responses as Solution Architect\n""¢ 10+ years of experience in Solution Architecting of Data & Analytics, AI/ML & Gen AI Technical Architect\n""¢ Develop On-prem, Cloud-native technical approach and proposal plans identifying the best practice solutions meeting the requirements for a successful proposal. Create, edit, and review documents, diagrams, and other artifacts in response to RPPs RFQs and Contribute to and participate in presentations to customers regarding proposed solutions.\n""¢ Experience with large scale consulting and program execution engagements in AI and data\n""¢ Seasoned multi-technology infrastructure design experience.\n""¢ Seasoned demonstrable level of expertise coupled with consulting and client engagement experience, demonstrating good experience in client needs assessment and change management.\n\n""¢ Additional\n""¢ Knowledge and application:\n""¢ Seasoned, experienced professional; has complete knowledge and understanding of area of specialization.\n""¢ Uses evaluation, judgment, and interpretation to select right course of action.\n""¢ Problem solving:\n""¢ Works on problems of diverse scope where analysis of information requires evaluation of identifiable factors.\n""¢ Resolves and assesses a wide range of issues in creative ways and suggests variations in approach.\n""¢ Interaction:\n""¢ Enhances relationships and networks with senior internal/external partners who are not familiar with the subject m""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['client engagement', 'data architecture', 'change management', 'artificial intelligence', 'service orientation', 'needs assessment', 'architecting', 'python', 'project management', 'rfqs', 'togaf', 'aiml', 'market research', 'presales', 'solution architecting', 'gen', 'solution design', 'aws', 'rfp', 'ml']",2025-06-11 05:49:55
"ETL Developer - ODI, Oracle Data Integrator - 5+ yrs - Chennai",MNC Client,6 - 11 years,15-25 Lacs P.A.,"['Chennai( Okkiyam Thuraipakkam, Pallavaram, Sholinganallur, Perungudi, Pallikaranai )']","Hi,\n\nWishes from GSN!!! Pleasure connecting with you!!!\n\nWe been into Corporate Search Services for Identifying & Bringing in Stellar Talented Professionals for our reputed IT / Non-IT clients in India. We have been successfully providing results to various potential needs of our clients for the last 20 years.\n\nAt present, GSN is hiring ETL - Oracle ODI developers for one of our leading MNC client. PFB the details for your better understanding:\n\n\n******* Looking for SHORT JOINERS *******\n\n\n\nWORK LOCATION: CHENNAI\nJob Role: ETL ODI Developer\nEXPERIENCE: 5+ yrs\nCTC Range: 15 LPA to 25 LPA\nWork Type: WFO\n\n\nMandatory Skills :\nHands on development experience in ETL using ODI 11G/12C is MUST\nProficient in Data migration technique and Data Integration\nOracle SQL and PL/SQL programming experience\nExperience in Data Warehouse and/or Data Marts\n\n\n******* Looking for SHORT JOINERS *******\n\n\nAppreciate your valuable references, if any.\n\nThanks & Regards\nSathya K\nGSN Consulting\nMob: 8939666794\nMail ID: sathya@gsnhr.net; Web: https://g.co/kgs/UAsF9W",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Data migration', 'Oracle Data Integrator', 'ODI', 'Data Warehouse', 'ETL', 'Data Marts', 'Data Integration']",2025-06-11 05:49:56
"Data Conversion & ETL Test Lead (Ab Initio, SQL, Python)",Teamware Solutions a division of Quantu...,6 - 11 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","About the Company\nGreetings from Teamware Solutions a division of Quantum Leap Consulting Pvt. Ltd\n\nAbout the Role\nWe are hiring a Data Conversion & ETL Test Lead (Ab Initio, SQL, Python)\nLocation: Bangalore, Hyderabad\nWork Model: Hybrid - 2nd Shift 2-11 PM\nExperience: 6-12 Years\nNotice Period: Immediate to 15 Days\n\nData Conversion Test Lead / ETL Lead\nCollaborate with upstream/downstream to understand Data workflows and requirements.\nCollaborate with business analysts, data architects, and developers to understand ETL requirements and data mapping documents.\nExperience with ETL tools such as Ab initio or similar\nDesign and execute functional and integration test cases for ETL processes involving Oracle databases and related systems.\nValidate data transformations, mappings, and data loads (initial and incremental).\nPerform source-to-target data validation, data quality checks, and reconciliation.\nAnalyze ETL job logs, and error reports, and track defects through resolution using tools like JIRA or ALM.\nWork closely with Oracle implementation teams to test data from Oracle EBS/ERP, Oracle Fusion, or other modules as applicable.\nAutomate test cases where applicable using SQL or data testing tools.\nPerform data validation and testing to ensure data accuracy and integrity.\nSolid understanding of SQL and database concepts.\nProven experience in ETL testing and automation.\nStrong proficiency in Python programming.\nEnsure compliance with industry standards and best practices in data testing.\nKnowledge of data warehousing and data modeling concepts.\n\nMandatory skills:\nData Conversion Testing | Ab Initio | SQL | ETL | Data Quality | Data Validation | Upstream/Downstream Validations |\nOne year of experience in Python.\n\nNice to Have:\nOracle GL Implementation | R2R | P2P | Functional Testing\n\nPlease let me know if you are interested in this position and send me your resumes to netra.s@twsol.com",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Data Conversion Test', 'Ab Initio', 'ETL Testing', 'Data Validation', 'Data Quality', 'Oracle GL', 'ETL Lead', 'SQL']",2025-06-11 05:49:58
Digital Solution Architect Lead Advisor,"NTT DATA, Inc.",7 - 12 years,Not Disclosed,['Pune'],"Req ID: 301930\n\nWe are currently seeking a Digital Solution Architect Lead Advisor to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\n Position Overview  We are seeking a highly skilled and experienced Data Solution Architect to join our dynamic team. The ideal candidate will have a strong background in designing and implementing data solutions using AWS infrastructure and a variety of core and supplementary technologies. This role requires a deep understanding of data architecture, cloud services, and the ability to drive innovative solutions to meet business needs.\n\n\n\n Key Responsibilities  \n\n- Architect end-to-end data solutions using AWS services, including Lambda, SNS, S3, and EKS\n\n- Design and implement data streaming pipelines using Kafka/Confluent Kafka\n\n- Develop data processing applications using Python\n\n- Ensure data security and compliance throughout the architecture\n\n- Collaborate with cross-functional teams to understand business requirements and translate them into technical solutions\n\n- Optimize data flows for performance, cost-efficiency, and scalability\n\n- Implement data governance and quality control measures\n\n- Provide technical leadership and mentorship to development teams\n\n- Stay current with emerging technologies and industry trends\n\n\n\n Required Skills and Qualifications  \n\n\n\n- Bachelor's degree in Computer Science, Engineering, or related field\n\n- 7+ years of experience in data architecture and engineering\n\n- Strong expertise in AWS cloud services, particularly Lambda, SNS, S3, and EKS\n\n- Proficiency in Kafka/Confluent Kafka and Python\n\n- Experience with Synk for security scanning and vulnerability management\n\n- Solid understanding of data streaming architectures and best practices\n\n- Strong problem-solving skills and ability to think critically\n\n- Excellent communication skills to convey complex technical concepts to both technical and non-technical stakeholders",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['python', 'cloud services', 'data architecture', 'aws cloud', 'kafka', 'emerging technologies', 'kubernetes', 'aws iam', 'technical leadership', 'aws infrastructure', 'vulnerability management', 'eks', 'docker', 'ansible', 'java', 'lambda expressions', 'devops', 'data governance', 'sns', 'terraform', 'aws']",2025-06-11 05:49:59
Salesforce Marketing Cloud Architect,"NTT DATA, Inc.",10 - 15 years,Not Disclosed,['Hyderabad'],"We are currently seeking a Salesforce Marketing Cloud Architect to join our team in ""‹""‹""‹""‹""‹""‹""‹Hyderabad, Telangana, ""‹""‹""‹""‹""‹""‹""‹India.\n\nRoleSalesforce Marketing Cloud Architect\n\n\n\nResponsibilities:\nServe as a trusted advisor to key stakeholders within our Enterprise clients.\nEnsure scalable, best-practice solutions that meet or exceed customer expectations.\nEvaluate and translate business and technical requirements into well-architected solutions that effectively leverage Salesforce products.\nIdentify and mitigate solution and business design risks.\nBuild and maintain strong relationships with key stakeholders and team members.\nLead overall architecture alignment and coordinate efforts across multiple architects.\nCollaborate with project and engagement managers to support planning and execution in partnership with the client.\nOversee project vision, direction, and the review of key deliverables.\nDrive early solution evaluations, manage issues proactively, and engage with executive teams, engineering, and product management.\nDirect and mentor diverse teams in both technical and non-technical aspects, including communication strategies and executive influence.\nContribute to internal growth through initiatives, knowledge-sharing, and the development of strategic assets.\nSupport the Pre-Sales team in developing proposals, including target and transition architectures, security and compliance considerations, integration strategies, data migration plans, and implementation roadmaps.\n\n\n:\n\n\nProven Experience: 10+ years proven experience in enterprise consulting, including implementing enterprise software solutions in the Commerce space as a lead developer or architect\n\n\nSalesforce certificationsMarketing Architect\n\n\nMarketing Cloud Expertise:\nSalesforce Composable marketing offerings and able to shape end-to-end solutions using the Salesforce marketing platform\nKnowledgeable on key areas including\nProducts, Product Catalogues & Product Items\nPricing & Promotions\nOrders\nBaskets, Checkouts & Payment Methods\nShipping Methods\nShopper Login (SLAS)\n\n\nStrong knowledge on Headless Marketing concepts and design patterns\nExperience of Managed Runtime (fka Mobify) strongly beneficial\nCompetence with SFCC's PWA Kit & Node JS\nExperience building pixel-perfect/custom front ends with React\nExperience with headless integration patterns including SCAPI\nKnowledge of DevOps best practices\nKnowledge of Quality Code & Code Review best practices\nSuccessful candidates will join an existing SFCC delivery team and will be expected to reuse/leverage existing build components into an expanding delivery team.\nCandidates will be asked to contribute to overall multi-cloud solution architectures and end-to-end business processes, whilst taking technical ownership within the SFCC domain.\nExperience with integration technologies, master data management, and familiarity with other cloud platforms (e.g., AWS) is preferred.\nExtensive experience with Agile, Scrum, and Waterfall methodologies.\n\n\nPreferred Qualifications:\n\n\nSalesforce Commerce Knowledge: Knowledge in Salesforce Order Management and Salesforce B2B/D2C Commerce\n\n\nSalesforce Knowledge: Additional Salesforce certifications (Salesforce Administrator, Experience cloud, Experience implementing Salesforce Clouds, Multi-cloud scenarios - Sales, Service and\n\nMarketing)\n\n\nTechnical Familiarity: Familiarity with Salesforce""™s technical architectureAPIs, Standard and Custom Objects, APEX, AI concepts, Customer Data Platforms or Data LakesAdditional Salesforce certifications such as Marketing Cloud Consultant, Integration Architect, AI Associate, or AI Specialist.\nIn-depth knowledge of web services, data modelling, and enterprise application integration, including experience with ESBs, ETL tools, and common integration design patterns with systems like CMS, ERP, HRIS, and data warehouses.\nAgile Methodology certification, such as Scaled Agile Framework (SAFe), is a plus.\n\nRoles and Responsibilities-\n\nUtilisation of relevant modules within Marketing Cloud Builder customer journeys Analytics of campaigns and making recommendations Personalisation using AMPscript Implementing SFMC Configuration beyond declarative methods (beyond point-and-click) Setting up new modules Integrating with other clouds and third-party platforms\n\n\n\nSkills required- A good level of hands-on experience with SFMC Experience using Journey Builder with the ability to build more complex journeys for common use cases. Some knowledge of AMPscript Ability to build data extensions Previous experience with integration projects Experience with SFMC Connector Good knowledge of APIs Advanced AMPscript knowledge - Email Specialist certification",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['web services', 'waterfall', 'design patterns', 'scrum', 'agile', 'ampscript', 'erp', 'hris', 'cms', 'technology integration', 'master data management', 'salesforce', 'enterprise application integration', 'marketing', 'node.js', 'b2b', 'data modeling', 'esb', 'devops', 'pwa', 'sfmc', 'aws', 'etl', 'marketing cloud']",2025-06-11 05:50:01
Azure Solution Architect,Tanisha Systems,12 - 18 years,40-45 Lacs P.A.,"['Pune', 'Gurugram', 'Bengaluru']","Role & responsibilities\nWe are looking for Azure Solution Architect for MNC company permanent position for Remote.\n\nPreferred candidate profile\nIndustry: Financial Services / Banking\nKey Responsibilities\n\nArchitect, design, and lead the migration of Sybase ASE/IQ databases to Azure SQL\nConduct in-depth assessments of existing on-prem Sybase infrastructure and define the cloud migration blueprint\nDefine and implement scalable, secure, and high-performing Azure SQL architectures tailored to financial workloads\nCollaborate with cloud engineering, security, infrastructure, and business teams to ensure alignment\nLead end-to-end migration execution, including schema conversion, data movement, validation, and cutover\nEstablish automated ETL pipelines, backup/recovery strategies, and rollback mechanisms in Azure\nEnsure compliance with financial data regulations (SOX, GDPR, PCI-DSS, etc.)\nOptimize workloads post-migration for performance, cost efficiency, and maintainability\nLead governance reviews, technical workshops, and create documentation and runbooks\n\n\nRequired Skills & Experience\n\n12+ years of overall experience in enterprise data architecture and cloud solutions\nMandatory experience in migrating Sybase ASE/IQ to Azure SQL in large-scale environments\nDeep understanding of Azure SQL, Azure Data Factory, Azure Migrate, BACPAC, and SSMA\nExperience with cloud-native data tools for transformation, validation, and monitoring\nProficiency in scripting (PowerShell, Python) for automation and orchestration\nStrong understanding of data lineage, data masking, encryption, and compliance frameworks\nDemonstrated success in leading multi-terabyte data migrations in financial or regulated environments\nExcellent communication skills with experience in dealing with onsite and offshore teams\n\n\nPreferred Qualifications\n\nMicrosoft Certified: Azure Solutions Architect Expert or Data Engineer Associate\nFamiliarity with performance tuning and resource optimization in Azure SQL\nExperience with application re-platforming or modernization post-migration",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Azure data migration', 'financial domain', 'Azure services', 'Sybase', 'Architect', 'Azure Migrate', 'Azure', 'Power shell', 'Azure Certified', 'Azure SQL', 'SQL', 'Azure Data Factory', 'scripting', 'SSMA', 'ETL', 'BACPAC', 'Python']",2025-06-11 05:50:03
Data Engineer,Amgen Inc,1 - 3 years,Not Disclosed,['Hyderabad'],"What you will do\nIn this vital role you will responsible for designing, building, maintaining, analyzing, and interpreting data to provide actionable insights that drive business decisions. This role involves working with large datasets, developing reports, supporting and executing data governance initiatives, and visualizing data to ensure data is accessible, reliable, and efficiently managed. The ideal candidate has strong technical skills, experience with big data technologies, and a deep understanding of data architecture and ETL processes.\nRoles & Responsibilities:\nDesign, develop, and maintain data solutions for data generation, collection, and processing.\nBe a key team member that assists in the design and development of the data pipeline.\nCreate data pipelines and ensure data quality by implementing ETL processes to migrate and deploy data across systems.\nContribute to the design, development, and implementation of data pipelines, ETL/ELT processes, and data integration solutions.\nTake ownership of data pipeline projects from inception to deployment, manage scope, timelines, and risks.\nCollaborate with cross-functional teams to understand data requirements and design solutions that meet business needs.\nDevelop and maintain data models, data dictionaries, and other documentation to ensure data accuracy and consistency.\nImplement data security and privacy measures to protect sensitive data.\nLeverage cloud platforms (AWS preferred) to build scalable and efficient data solutions.\nCollaborate and communicate effectively with product teams.\nWhat we expect of you\nWe are all different, yet we all use our unique contributions to serve patients.\nBasic Qualifications and Experience\nMasters degree and 1 to 3 years of experience in Computer Science, IT, or related field OR\nBachelors degree and 3 to 5 years of experience in Computer Science, IT, or related field OR\nDiploma and 7 to 9 years of experience in Computer Science, IT, or related field\nMust-Have Skills:\nHands-on experience with big data technologies and platforms, such as Databricks, Apache Spark (PySpark, SparkSQL), workflow orchestration, performance tuning on big data processing.\nProficiency in data analysis tools (e.g., SQL) and experience with data visualization tools.\nExcellent problem-solving skills and the ability to work with large, complex datasets.\nPreferred Qualifications:\nGood-to-Have Skills:\nExperience with ETL tools such as Apache Spark, and various Python packages related to data processing, machine learning model development.\nStrong understanding of data modeling, data warehousing, and data integration concepts.\nKnowledge of Python/R, Databricks, SageMaker, cloud data platforms.\nProfessional Certifications:\nCertified Data Engineer / Data Analyst (preferred on Databricks or cloud environments).\nCertified Data Scientist (preferred on Databricks or Cloud environments).\nMachine Learning Certification (preferred on Databricks or Cloud environments).\nSoft Skills:\nExcellent critical-thinking and problem-solving skills.\nStrong communication and collaboration skills.\nDemonstrated awareness of how to function in a team setting.\nDemonstrated presentation skills.",Industry Type: Pharmaceutical & Life Sciences,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Data Engineering', 'SageMaker', 'R', 'data modeling', 'data warehousing', 'cloud data platforms', 'Databricks', 'ETL', 'data integration', 'Python']",2025-06-11 05:50:05
Senior Software Engineer - Adobe Experience Platform ( AEP ),Wells Fargo,4 - 8 years,Not Disclosed,['Hyderabad'],"About this role:\nWells Fargo is seeking a senior Software Engineer - Adobe Experience Platform (AEP)\nIn this role, you will:\nLead moderately complex initiatives and deliverables within technical domain environments\nContribute to large scale planning of strategies\nDesign, code, test, debug, and document for projects and programs associated with technology domain, including upgrades and deployments\nReview moderately complex technical challenges that require an in-depth evaluation of technologies and procedures\nResolve moderately complex issues and lead a team to meet existing client needs or potential new clients needs while leveraging solid understanding of the function, policies, procedures, or compliance requirements\nCollaborate and consult with peers, colleagues, and mid-level managers to resolve technical challenges and achieve goals\nLead projects and act as an escalation point, provide guidance and direction to less experienced staff\n\nRequired Qualifications:\n4+ years of Software Engineering experience, or equivalent demonstrated through one or a combination of the following: work experience, training, military experience, education\nDesired Qualifications :\n4+years of overall IT experience and at least 3 years of experience in developing digital marketing / digital analytics solutions using Adobe products.\nMinimum 2 years experience in Adobe Experience Cloud products and recent experience with Adobe Experience Platform or similar CDP\nGood knowledge of Data Science workspace and building intelligent Services on AEP\nStrong knowledge of datasets in Adobe Experience Platform, load data into Platform through data source connectors, APIs, and streaming ingestion connectors\nExperience in creating all required Adobe XDM (Experience Data Model) in JSON based on approved data model for all loading data files.\nKnowledge on utilizing Adobe Experience Platform (AEP) UI & POSTMAN to automate all customer schema data lake & profile design setups within each sandbox environment.\nExperience in configuration within Adobe Experience Platform all necessary identities & privacy settings and creating new segments within AEP to meet customer use cases. Test/Validate the segments with the required destinations.\nManaging customer data by using Real-Time Customer Data Platform (RTCDP), and analyze customer data by using Customer Journey Analytics (CJA)\nExperience with creating connection, data views, and dashboard in CJA\nHands-on experience in configuration and integration of Adobe Marketing Cloud modules like Audience Manager, Analytics, Campaign and Target\nAdobe Experience Cloud tool certifications (Adobe Campaign, Adobe Experience Platform, Adobe Target, Adobe Analytics) are desirable.\nProven ability to communicate in both verbal and writing in a high performance, collaborative environment.\nExperience with data analysis, modeling, and mapping to coordinate closely with Data Architect(s)\nBuild the necessary schemas, workflows to ingest customers data, transform the data & load the data into AEP successfully.\nBuild Audiences (segmentations) and create necessary pipeline for Destination activation.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Software Engineering', 'Data Science', 'data model', 'Adobe XDM', 'data analysis', 'configuration', 'technical domain']",2025-06-11 05:50:06
Data Analyst,Talent Hire It Solutions,5 - 10 years,Not Disclosed,"['Kochi', 'Thiruvananthapuram']","Collaborate with business stakeholders to understand data needs and translate them into analytical\nrequirements.\nAnalyze large datasets to uncover trends, patterns, and actionable insights.\nDesign and build dashboards and reports using Power BI.\nPerform ad-hoc analysis and develop data-driven narratives to support decision-making.\nEnsure data accuracy, consistency, and integrity through data validation and quality checks.\nBuild and maintain SQL queries, views, and data models for reporting purposes.\nCommunicate findings clearly through presentations, visualizations, and written summaries.\nPartner with data engineers and architects to improve data pipelines and architecture.\nContribute to the definition of KPIs, metrics, and data governance standards.\n\nJob Specification / Skills and Competencies\nBachelors or Master’s degree in Statistics, Mathematics, Computer Science,\nEconomics, or a related field.\n5+ years of experience in a data analyst or business intelligence role.\nAdvanced proficiency in SQL and experience working with relational databases (e.g.,\nSQL Server, Redshift, Snowflake).\n\nJob Description\n\n2\n\nHands-on experience in Power BI.\nProficiency in Python, Excel and data storytelling.\nUnderstanding of data modelling, ETL concepts, and basic data architecture.\nStrong analytical thinking and problem-solving skills.\nExcellent communication and stakeholder management skills\nTo adhere to the Information Security Management policies and procedures.\n\nSoft Skills Required\nMust be a good team player with good communication skills\nMust have good presentation skills\nMust be a pro-active problem solver and a leader by self\nManage & nurture a team of data engineersRole & responsibilities\n\n\nPreferred candidate profile",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['SQL', 'Power BI', 'Amazon Athena', 'Python']",2025-06-11 05:50:08
Snowflake Data Engineer / Database Lead,TechStar Group,9 - 14 years,15-20 Lacs P.A.,['Hyderabad'],"Job Description:\nSQL & Database Management: Deep knowledge of relational databases (PostgreSQL), cloud-hosted data platforms (AWS, Azure, GCP), and data warehouses like Snowflake.\nETL/ELT Tools: Experience with SnapLogic, StreamSets, or DBT for building and maintaining data pipelines. / ETL Tools Extensive Experience on data Pipelines\nData Modeling & Optimization: Strong understanding of data modeling, OLAP systems, query optimization, and performance tuning.\nCloud & Security: Familiarity with cloud platforms and SQL security techniques (e.g., data encryption, TDE).\nData Warehousing: Experience managing large datasets, data marts, and optimizing databases for performance.\nAgile & CI/CD: Knowledge of Agile methodologies and CI/CD automation tools.\n\n\nRole & responsibilities\nBuild the data pipeline for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud database technologies.\nWork with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data needs.\nWork with data and analytics experts to strive for greater functionality in our data systems.\nAssemble large, complex data sets that meet functional / non-functional business requirements.\n– Ability to quickly analyze existing SQL code and make improvements to enhance performance, take advantage of new SQL features, close security gaps, and increase robustness and maintainability of the code.\n– Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery for greater scalability, etc.\n– Unit Test databases and perform bug fixes.\n– Develop best practices for database design and development activities.\n– Take on technical leadership responsibilities of database projects across various scrum teams.\nManage exploratory data analysis to support dashboard development (desirable)\n\n\nRequired Skills:\n– Strong experience in SQL with expertise in relational database(PostgreSQL preferrable cloud hosted in AWS/Azure/GCP) or any cloud-based Data Warehouse (like Snowflake, Azure Synapse).\n– Competence in data preparation and/or ETL/ELT tools like SnapLogic, StreamSets, DBT, etc. (preferably strong working experience in one or more) to build and maintain complex data pipelines and flows to handle large volume of data.\n– Understanding of data modelling techniques and working knowledge with OLAP systems\n– Deep knowledge of databases, data marts, data warehouse enterprise systems and handling of large datasets.\n– In-depth knowledge of ingestion techniques, data cleaning, de-dupe, etc.\n– Ability to fine tune report generating queries.\n– Solid understanding of normalization and denormalization of data, database exception handling, profiling queries, performance counters, debugging, database & query optimization techniques.\n– Understanding of index design and performance-tuning techniques\n– Familiarity with SQL security techniques such as data encryption at the column level, Transparent Data Encryption(TDE), signed stored procedures, and assignment of user permissions\n– Experience in understanding the source data from various platforms and mapping them into Entity Relationship Models (ER) for data integration and reporting(desirable).\n– Adhere to standards for all database e.g., Data Models, Data Architecture and Naming Conventions\n– Exposure to Source control like GIT, Azure DevOps\n– Understanding of Agile methodologies (Scrum, Itanban)\n– experience with NoSQL database to migrate data into other type of databases with real time replication (desirable).\n– Experience with CI/CD automation tools (desirable)\n– Programming language experience in Golang, Python, any programming language, Visualization tools (Power\nBI/Tableau) (desirable).",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['ETL', 'Snowflake Developer', 'SQL', 'Snowflake Sql', 'Snowflake Data Engineer', 'Snowsql', 'Snowflake', 'Schema', 'Data Engineer', 'Data Sharing', 'Snowpipe', 'Streams']",2025-06-11 05:50:09
Python Data Engineer,GAVS Technologies,4 - 6 years,5.5-15.5 Lacs P.A.,['Pune'],"Skill Expectations\nMust-Have Skills:\nStrong hands-on experience in Python development\nExperience working with Fast API\nData migration and data engineering experience (ETL, pipelines, transformations)\nExperience in web scraping and data extraction techniques\nExperience working with GCP",,,,"['Data Extraction', 'Web Scraping', 'Python', 'GCP', 'Fast Api']",2025-06-11 05:50:11
Senior Cloud Services Client Partner,"NTT DATA, Inc.",6 - 10 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Cloud Services Sales Specialist is an advanced subject matter expert and is also a quota-bearing sales persona. This role has the primary responsibility to work with services teams to identify, develop, and close managed service and outsourcing deals.\n\nThis role is recognized as the clients trusted cloud managed services advisor and applies consulting led sales skills to engage and close opportunities with decision-makers.\n\nThis role works directly with clients at a variety of levels, as well as other internal sales and delivery expert teams such as Client Managers and pre-sales services-type architects and post the sale; the delivery teams that will manage the clients outsourced solution. Deals often involve alignment on business outcome led multi-product/multi-vendor cloud solutions with services.\n\nThis role champions the delivery teams understanding of the clients solution requirements, and initiates improvement programs ensuring that the client remains committed to solutions which leads to more sales opportunities.\n\nBuilding and developing excellent stakeholder relationships with clients, fully understanding the client and the industry in which they operate will be a core focus of this role. The focus of this role remains on converting the client to a managed services client resulting in multi-year renewals; deals may involve a long sales cycle.\n\nAs a Senior Cloud Services Sales Specialist, this role has the opportunity to partner with some of the biggest global organizations, helping them to convert to new business models.\nWhat you'll be doing\nKey Responsibilities:\nCreates demand and selling Cloud Managed Services solutions -\nCreates demand by assisting clients to identify and qualify current needs and effectively articulates how the company can add value through its Cloud services and solutions offering.\nResponsible for addressing the objections that a client may pose in moving to a Cloud managed services solution.\nAppropriately allocates and decides sales time between assigned clients and new prospect opportunities; yet ensure focus remains on the top clients/prospects and balance opportunity size with likely outcomes\nSales partnership -\nThe success of the services agenda and successful sales will rely on successful partnership with others; this will include regional leads and services teams to work on the best outcome for the client.\nCollaborates with partners and/ or vendors to drive select deals through vendor-based opportunities.\nCollaborates with broader organization such as the Offer Management, Commercial Architecture and Delivery teams to promote and support high-value services opportunities.\nDirects regional sales governance processes and Deal Clinics to profile opportunities.\nManaged Services industry trusted advisor -\nResponsible for building deep and long-term relationships with client leaders in a Managed Services opportunity and execute a competitive win strategy through understanding the clients business requirements and competitive landscape.\nDirects the maintenance of a high level of relevant service knowledge to have meaningful conversations with clients; including the industry that the client operates in.\nCreates the knowledge base of organizational services solutions within a services practice by sharing best practices with internal teams as well as client teams; ensuring that internal teams are aware of typical client challenges\nDeal construct -\nDirects the build and supports commercial solutions for Managed Services solutions and design deals that meet clients needs and ensure win/win solutions for both client and the company.\nResponsible for constructing the managed services deal including the commercial modelling, negotiate contractual terms, mitigate legal risk and obstacles, and move the proposal to close to meet assigned quota.\nDrives the sales process -\nAccountable for managing a pipeline of opportunities and creating and documenting a shared strategy to meet sales target such as net new customer pursuit plans to land new logos, activities to achieve client satisfaction, minimize churn, cross-sell, upsell, revenue, and margin goals.\nWorks across multiple sales teams and commercial architects to successfully position the service and see the opportunity through to closure.\nWorks across multiple internal teams to ensure scope of work and proposals are tracked, managed and delivered on time.\nCreates and consults on the implementation of an opportunity plan, to provide regular check-ins with the primary point of contact and have an established process for getting buy-in from all stakeholders.\nResponsible for ensuring data is accurate based on sales reporting standards to provide data-driven insights.\nConsults on the negotiation of deals with clients and lead the internal account management team to enable conclusion of services deals.\nConsults on the knowledge base of organizational solutions and services by sharing best practices, industry and technology trends with internal stakeholders and clients.\nParticipates in regional reporting cadence as it relates to regional performance and major deal reviews.\n\nKnowledge and Attributes:\nStrong knowledge of cloud infrastructure principles and products.\nUnderstanding how networking works in a cloud environment to enable the design of effective solutions.\nAdvanced understanding of and the ability to position the companys services offerings that may span multiple technology domains across Managed Services, Support Services, Consulting Services and Technical Services.\nAdvanced understanding of platform delivered services and how to articulate the value of standardized, centralized and optimized services.\nProficiency in working with major cloud platforms such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and others.\nAdvanced understanding of broader IT infrastructure components, such as servers, storage, virtualization, and data centers.\nConversant with a business outcome led approach to sales.\nAdvanced familiarity with document management platforms.\nAdvanced understanding of cybersecurity principles to ensure data security and protection during collaboration efforts.\nAdvanced understanding of financial statements and metrics, including revenue, expense control, and growth relative to market in order to hold strategic client conversations.\nHave the legal knowledge to discuss contracting with the client and understand how to position terms as a value exchange.\nAdvanced client-centricity coupled with problem solving.\nAdvanced business acumen and negotiation skills to craft solutions that are beneficial to the organization and the client.\nAbility to pro-actively and independently identify and qualify opportunities, an entrepreneurial mindset if key.\nNatural team player ability to coordinate and liaise with delivery teams across multiple business areas.\nQuick learner to understand any new solutions that are ready to take to market.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent in a Technical or Sales field or related.\nCertifications such as Scotworks and Solution selling is desired.\nSolution Selling/SPIN certifications is desired.\nDesired technology certifications include (any one or more) - Azure (AZ900 Azure Fundamentals), AWS (AWS Cloud Practitioner), VMWare (VTSP or VTSP for AWS/Azure), ITIL (Version 3 or later).\n\nRequired Experience:\nAdvanced demonstrated track record of managed services solutions to large enterprise accounts.\nAdvanced demonstrated experience structuring large, multi-year profitable contracts.\nAdvanced demonstrated ability of building strong relationships with clients across all levels; but especially the C-suite.\nAdvanced demonstrated experience of networking with senior internal and external people in the specialist area of expertise.\nAdvanced demonstrated experience in managing the entire sales process, contracting process and legal implications of a deal.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Sales', 'sales management', 'VMWare', 'relationship building', 'selling', 'sales planning', 'AWS']",2025-06-11 05:50:12
"Data engineer with Gen AI- Balewadi, pune- hybrid",Indian MNC,5 - 10 years,15-30 Lacs P.A.,['Pune( Balewadi )'],"Role & responsibilities\nWe are seeking a skilled Data Engineer with advanced expertise in Python, PySpark, Databricks, and Machine Learning, along with a working knowledge of Generative and Agentic AI. This role is critical in ensuring data integrity and driving innovation across enterprise systems. You will design and implement ML-driven solutions to enhance Data Governance & Data Privacy initiatives through automation, self-service capabilities, and scalable, AI-enabled innovation.\nKey Responsibilities:\nImplement ML and Generative/Agentic AI solutions to optimize Data Governance processes.\nDesign, develop, and maintain scalable data pipelines using Python, PySpark, and Databricks.\nDevelop automation frameworks to support data quality, lineage, classification, and access control.\nDevelop and deploy machine learning models to uncover data patterns, detect anomalies, and enhance data governance and privacy compliance\nCollaborate with data stewards, analysts, and governance teams to build self-service data capabilities.\nWork with Databricks, Azure Data Lake, AWS, and other cloud-based data platforms for data engineering.\nBuild, configure, and integrate APIs for seamless system interoperability.\nEnsure data integrity, consistency, and compliance across systems and workflows.\nIntegrate AI models to support data discovery, metadata enrichment, and intelligent recommendations.\nOptimize data architecture to support analytics, reporting, and governance use cases.\nMonitor and improve the performance of ML/AI components in production environments.\nStay updated with emerging AI and data engineering technologies to drive continuous innovation.\nTechnical Skills:\nStrong programming skills in Python, PySpark, SQL for data processing and automation.\nExperience with Databricks and Snowflake (preferred) for building and maintaining data pipelines.\nExperience with Machine Learning model development and Generative/Agentic AI frameworks (e.g. LLMs, Transformers, LangChain) especially in the Data Management space\nExperience working with REST APIs & JSON for service integration\nExperience working with cloud-based platforms such as Azure, AWS, or GCP\nPower BI dashboard development experience is a plus.\nSoft Skills:\nStrong problem-solving skills and attention to detail.\nExcellent communication and collaboration abilities, with experience working across technical and business teams",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Pyspark', 'Generative Ai', 'Azure Databricks', 'Ml']",2025-06-11 05:50:14
Sr BODS Developer,"NTT DATA, Inc.",6 - 8 years,Not Disclosed,['Hyderabad'],"Req ID: 327359\n\nWe are currently seeking a Sr BODS Developer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n Job  \n\n6-8 Yrs. of overall technical experience in SAP BODS with all the SAP BODS application modules (Extract, Transform, Load)\n\n5+ Yrs. of experience with Data Migration experience with S/4 HANA/ECC Implementations\n\nExperience in BODS Designer Components- Projects, Jobs, Workflow, Data Flow, Scripts, Data Stores and Formats\n\nExperience in BODS performance tuning techniques using parallel processing (Degree of Parallelism), Multithreading, Partitioning, and Database Throughputs to improve job performance\n\nExtensive experience in ETL using SAP BODS and SAP IS with respect to SAP Master / Transaction Data Objects in SAP FICO, SAP SD, SAP MM/WM, SAP Plant Maintenance, SAP Quality Management etc. is desirable\n\nExperience with Data Migration using LSMW, IDOCS, LTMC",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data migration', 'wm', 'sap mm', 'etl', 'sap bods', 'fico', 'lsmw', 'ecc', 'sap sd', 'sap mm wm', 'apex', 'sql', 'sap s hana', 'salesforce', 'idocs', 'sap fico', 'multithreading', 'sap quality management', 'sap qm', 'sap', 'performance tuning', 'triggers', 'bods', 'quality management', 'sap pp', 'sap plant maintenance']",2025-06-11 05:50:16
Senior .NET/Angular Developer - Remote,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,['Chennai'],"Req ID: 315626\n\nWe are currently seeking a Senior .NET/Angular Developer - Remote to join our team in Chennai, Tamil Ndu (IN-TN), India (IN).\n\nSenior .NET/Angular Developer - Remote\n\n\n\nHow You""™ll Help Us:\n\nA Senior .NET/Angular Developer is part of a team focused on delivering quality software for our clients. Our team members perform a variety of tasks including building and supporting cloud and on-prem applications and services hosted on Azure.\n\n\n\nHow We Will Help You:\n\nJoining our team is not only a job, but a chance to grow your career. We will make sure to equip you with the skills you need to produce robust applications that you can be proud of. Whether it is providing you with training on a new programming language or helping you get certified in a new technology, we will help you grow your skills so you can continue to deliver increasingly valuable work.\n\n\n\nOnce You Are Here, You Will:\n\nProvide input and support for, and perform full systems life cycle management activities (e.g., analyses, technical requirements, design, coding, testing, implementation of systems and applications software, etc.). You will participate in component and data architecture design, technology planning, and testing for Applications Development (AD) initiatives to meet business requirements. This position provides input to applications development project plans and integrations. Additionally, you will collaborate with teams and support emerging technologies to ensure effective communication and achievement of objectives. The Senior Applications Developer provides knowledge / support for applications development, integration, and maintenance as well as providing input to department and project teams on decisions supporting projects.\n\n\n\nBasic Qualifications:\nExperience with Angular and Azure stack.\nExperience with C",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c', 'angular', 'azure stack', '.net', 'angular development', 'c#', 'application software', 'css', 'software testing', 'vmware', 'microsoft azure', 'hyper-v', 'javascript', 'sql server', 'docker', 'active directory', 'devops', 'asp.net', 'powershell', 'microsoft windows', 'web api', 'html', 'mvc', 'aws']",2025-06-11 05:50:18
"Master Data Analyst, Commercial",NKT Operations,3 - 6 years,Not Disclosed,['Chennai'],"Commercial Data Analyst\n\nThe Position\nAre you driven by turning complex data into insights that shape commercial strategies and decision-making? Do you enjoy solving business challenges with data in a dynamic, collaborative environment?\n\nWe are looking for a Commercial Data Analyst to join our growing Master Data Management team in Chennai, India. In this role, you will support our commercial functions by managing, analysing, and improving master and transactional data related to sales, customers, pricing, and market performance. Your insights will directly support improved commercial performance, customer experience, and business growth.\n\nPrimary Responsibilities\nCommercial Data Support: Assist the Master Data Management (MDM) team in ensuring high data quality and consistency for key commercial data objects such as customers, pricing, and sales hierarchies.\nData Analysis & Insights: Analyse commercial data (e.g., sales performance, customer segmentation, pricing trends) to identify patterns, trends, and improvement opportunities.\nData Validation: Ensure completeness, accuracy, and consistency of commercial master data across systems.\nReporting: Develop and maintain dashboards and reports that provide actionable insights to stakeholders in sales, marketing, and business management.\nCollaboration: Work closely with commercial teams, master data stewards, and data owners to understand data needs and ensure alignment on data structures and definitions.\nData Quality Management: Apply data profiling techniques to detect anomalies and support initiatives to improve and maintain data quality.\nDocumentation: Help define and maintain documentation of data definitions, processes, and standards for commercial data.\nSystem Support: Support integration and consistency of commercial data across ERP, CRM, and analytics platforms.\nData Projects: Contribute to data migration, cleansing, and enrichment efforts in relation to commercial systems and reporting structures.\n\nQualifications\nAs a Commercial Data Analyst, you bring both analytical acumen and collaborative skills that help turn commercial data into business value.\n\nProfessional Skills:\n3+ years of experience working with data analysis in a commercial, sales, or marketing context.\nStrong skills in data cleaning, analysis, and visualization of sales/customer-related data.\nProficiency in tools such as Excel, SQL, and BI platforms (e.g., Power BI, Tableau).\nExperience with CRM and ERP systems (e.g. SAP ECC, SAP S4 Hana, C4C) is a strong advantage.\nUnderstanding of commercial metrics and KPIs (e.g., revenue, margin, customer growth, pricing).\nExperience working with master data domains like Customer, Pricing, and Product.\nGood understanding of data quality principles and ability to identify and correct data issues.\nExperience in supporting data consistency across platforms and contributing to system/data projects.\n\nPersonal Attributes:\nAnalytical and detail-oriented, with a keen eye for commercial patterns and data integrity.\nBusiness-minded and able to translate data into actionable insights for commercial stakeholders.\nExcellent communication and collaboration skills to partner effectively with sales and marketing teams.\nStructured, self-driven, and able to manage multiple tasks in a fast-paced environment.\nProactive and curious, with a continuous improvement mindset.\n\nWe Offer\nAn exciting opportunity to shape commercial success through impactful data insights and quality management.\nCollaboration with global commercial and data teams in a dynamic, cross-functional environment.",Industry Type: Oil & Gas,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Sap Hana', 'sales', 'Marketing', 'MDM', 'SAP MDM', 'Data Validation', 'Power Bi', 'Tableau', 'SQL', 'Pricing', 'Master Data Management', 'Data Analytics', 'Python']",2025-06-11 05:50:19
Sr BODS Developer,"NTT DATA, Inc.",6 - 8 years,Not Disclosed,['Hyderabad'],"Req ID: 323607\n\nWe are currently seeking a Sr BODS Developer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n Sr SAP BODS Developer ""“ Track Lead  \n Position Overview \nUnderstand and execute data migration blueprints (migration concepts, transformation rules, mappings, selection criteria)\nUnderstand and contribute to the documentation of the data mapping specifications, conversion rules, technical design specifications as required\nBuild the conversion processes and associated programs that will migrate the data per the design and conversion rules that have been signed-off by the client\nExecution of all data migration technical steps (extract, transform & load) as well as Defect Management and Issue Resolution\nPerform data load activities for each mock load, cutover simulation and production deployment identified in L1 plan into environments identified\nProvide technical support, defect management, and issue resolution during all testing cycles, including Mock Data Load cycles\nComplete all necessary data migration documentation necessary to support system validation / compliance requirements\nSupport the development of unit and end-to-end data migration test plans and test scripts (including testing for data extraction, transformation, data loading, and data validation)\n\n Job  \n6-8 Yrs. of overall technical experience in SAP BODS with all the SAP BODS application modules (Extract, Transform, Load)\n5+ Yrs. of experience with Data Migration experience with S/4 HANA/ECC Implementations\nExperience in BODS Designer Components- Projects, Jobs, Workflow, Data Flow, Scripts, Data Stores and Formats\nExperience in BODS performance tuning techniques using parallel processing (Degree of Parallelism), Multithreading, Partitioning, and Database Throughputs to improve job performance\nExtensive experience in ETL using SAP BODS and SAP IS with respect to SAP Master / Transaction Data Objects in SAP FICO, SAP SD, SAP MM/WM, SAP Plant Maintenance, SAP Quality Management etc. is desirable\nExperience with Data Migration using LSMW, IDOCS, LTMC\nNight shift will be from 3 PM to 12 AM IST with Work from home option unless otherwise mentioned.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data migration', 'wm', 'sap mm', 'etl', 'sap bods', 'fico', 'lsmw', 'simulation', 'sap sd', 'test scripts', 'data mapping', 'sap mm wm', 'sql', 'plsql', 'sap s hana', 'idocs', 'data extraction', 'data loader', 'java', 'sap fico', 'multithreading', 'sap', 'performance tuning', 'technical design', 'bods', 'as']",2025-06-11 05:50:21
SAP DATA Steward,Maddisoft Solutions,10 - 20 years,Not Disclosed,['Hyderabad'],"Job Title: SAP DATA STEWARD (CONTRACT)\nLocation: HYDERABAD, INDIA\n\nAs the SAP Data Steward is responsible for creating, maintaining, and deactivating master data and data attributes in SAP with focus on data migration. The Data Stewards has an essential role in establishing in monitoring existing and new data against and ensuring timely and high-quality creation of new data in the system.\nBachelors Degree or Associates degree with additional 9+ years of work experience required or an equivalent combination of education and experience.\nRequires SAP functional knowledge on SAP Routings with Migration Perspective.\nShould have complete knowledge on SAP Routings tables. Need to have basic knowledge on linking between the tables and joins needed for getting the extract template ready as per Client's Format.\nExcellent attention to detail, exceptional interest in creating order and consistency required.\n10+ years of experience in data management and/or data governance activities and responsibilities.\nExperience working with SAP ECC required.\nDemonstrated expert-level experience and capability with MS Excel required.\nHigh degree of initiative and ownership, as well as a proven history of delivering results while working with several different departments in a fast-paced environment required.\nExperience creating and running business reports and data queries is preferred.\nConfident user of Microsoft Office (Word, Excel, Outlook, PowerPoint, Teams).\nExperience working with teams across multiple functions.\nAbility to multi-task and work under tight timelines required.\nExcellent communication skills both verbal and written.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['SAP ECC', 'Data Stewardship', 'Data Management', 'Data Governance', 'SAP Routing']",2025-06-11 05:50:22
Senior MCIS Client Partner,"NTT DATA, Inc.",7 - 10 years,Not Disclosed,['Bengaluru'],"Your day at NTT DATA\nThe Senior Cloud Services Sales Specialist is an advanced subject matter expert and is also a quota-bearing sales persona. This role has the primary responsibility to work with services teams to identify, develop, and close managed service and outsourcing deals.\n\nThis role is recognized as the clients trusted cloud managed services advisor and applies consulting led sales skills to engage and close opportunities with decision-makers.\n\nThis role works directly with clients at a variety of levels, as well as other internal sales and delivery expert teams such as Client Managers and pre-sales services-type architects and post the sale; the delivery teams that will manage the clients outsourced solution. Deals often involve alignment on business outcome led multi-product/multi-vendor cloud solutions with services.\n\nThis role champions the delivery teams understanding of the clients solution requirements, and initiates improvement programs ensuring that the client remains committed to solutions which leads to more sales opportunities.\n\nBuilding and developing excellent stakeholder relationships with clients, fully understanding the client and the industry in which they operate will be a core focus of this role. The focus of this role remains on converting the client to a managed services client resulting in multi-year renewals; deals may involve a long sales cycle.\n\nAs a Senior Cloud Services Sales Specialist, this role has the opportunity to partner with some of the biggest global organizations, helping them to convert to new business models.\nWhat you'll be doing\nKey Responsibilities:\nCreates demand and selling Cloud Managed Services solutions -\nCreates demand by assisting clients to identify and qualify current needs and effectively articulates how the company can add value through its Cloud services and solutions offering.\nResponsible for addressing the objections that a client may pose in moving to a Cloud managed services solution.\nAppropriately allocates and decides sales time between assigned clients and new prospect opportunities; yet ensure focus remains on the top clients/prospects and balance opportunity size with likely outcomes\nSales partnership -\nThe success of the services agenda and successful sales will rely on successful partnership with others; this will include regional leads and services teams to work on the best outcome for the client.\nCollaborates with partners and/ or vendors to drive select deals through vendor-based opportunities.\nCollaborates with broader organization such as the Offer Management, Commercial Architecture and Delivery teams to promote and support high-value services opportunities.\nDirects regional sales governance processes and Deal Clinics to profile opportunities.\nManaged Services industry trusted advisor -\nResponsible for building deep and long-term relationships with client leaders in a Managed Services opportunity and execute a competitive win strategy through understanding the clients business requirements and competitive landscape.\nDirects the maintenance of a high level of relevant service knowledge to have meaningful conversations with clients; including the industry that the client operates in.\nCreates the knowledge base of organizational services solutions within a services practice by sharing best practices with internal teams as well as client teams; ensuring that internal teams are aware of typical client challenges\nDeal construct -\nDirects the build and supports commercial solutions for Managed Services solutions and design deals that meet clients needs and ensure win/win solutions for both client and the company.\nResponsible for constructing the managed services deal including the commercial modelling, negotiate contractual terms, mitigate legal risk and obstacles, and move the proposal to close to meet assigned quota.\nDrives the sales process -\nAccountable for managing a pipeline of opportunities and creating and documenting a shared strategy to meet sales target such as net new customer pursuit plans to land new logos, activities to achieve client satisfaction, minimize churn, cross-sell, upsell, revenue, and margin goals.\nWorks across multiple sales teams and commercial architects to successfully position the service and see the opportunity through to closure.\nWorks across multiple internal teams to ensure scope of work and proposals are tracked, managed and delivered on time.\nCreates and consults on the implementation of an opportunity plan, to provide regular check-ins with the primary point of contact and have an established process for getting buy-in from all stakeholders.\nResponsible for ensuring data is accurate based on sales reporting standards to provide data-driven insights.\nConsults on the negotiation of deals with clients and lead the internal account management team to enable conclusion of services deals.\nConsults on the knowledge base of organizational solutions and services by sharing best practices, industry and technology trends with internal stakeholders and clients.\nParticipates in regional reporting cadence as it relates to regional performance and major deal reviews.\n\nKnowledge and Attributes:\nStrong knowledge of cloud infrastructure principles and products.\nUnderstanding how networking works in a cloud environment to enable the design of effective solutions.\nAdvanced understanding of and the ability to position the companys services offerings that may span multiple technology domains across Managed Services, Support Services, Consulting Services and Technical Services.\nAdvanced understanding of platform delivered services and how to articulate the value of standardized, centralized and optimized services.\nProficiency in working with major cloud platforms such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and others.\nAdvanced understanding of broader IT infrastructure components, such as servers, storage, virtualization, and data centers.\nConversant with a business outcome led approach to sales.\nAdvanced familiarity with document management platforms.\nAdvanced understanding of cybersecurity principles to ensure data security and protection during collaboration efforts.\nAdvanced understanding of financial statements and metrics, including revenue, expense control, and growth relative to market in order to hold strategic client conversations.\nHave the legal knowledge to discuss contracting with the client and understand how to position terms as a value exchange.\nAdvanced client-centricity coupled with problem solving.\nAdvanced business acumen and negotiation skills to craft solutions that are beneficial to the organization and the client.\nAbility to pro-actively and independently identify and qualify opportunities, an entrepreneurial mindset if key.\nNatural team player ability to coordinate and liaise with delivery teams across multiple business areas.\nQuick learner to understand any new solutions that are ready to take to market.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent in a Technical or Sales field or related.\nCertifications such as Scotworks and Solution selling is desired.\nSolution Selling/SPIN certifications is desired.\nDesired technology certifications include (any one or more) - Azure (AZ900 Azure Fundamentals), AWS (AWS Cloud Practitioner), VMWare (VTSP or VTSP for AWS/Azure), ITIL (Version 3 or later).\n\nRequired Experience:\nAdvanced demonstrated track record of managed services solutions to large enterprise accounts.\nAdvanced demonstrated experience structuring large, multi-year profitable contracts.\nAdvanced demonstrated ability of building strong relationships with clients across all levels; but especially the C-suite.\nAdvanced demonstrated experience of networking with senior internal and external people in the specialist area of expertise.\nAdvanced demonstrated experience in managing the entire sales process, contracting process and legal implications of a deal.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: Sales & Business Development,"Employment Type: Full Time, Permanent","['Cloud Services Sales', 'GCP', 'Consulting Services', 'negotiation', 'Microsoft Azure', 'ITIL', 'Technical Services', 'Support Services']",2025-06-11 05:50:24
Salesforce Developer - Service and Experience Cloud,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,"['Chennai', 'Gurugram', 'Bengaluru']","Req ID: 326791\n\nWe are currently seeking a Digital Solution Cnslt. Sr. Consultant to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nHow You""™ll Help Us:\nAs a B2B Developer, you will have the opportunity to get in on the ground floor of a new division created\nwithin one of the largest technology providers in the world. We are building the next generation of\ndigital services company and believe clients are ready for a more nimble, agile partner to deliver\noutcomes across the SFDC platform- including Sales, Service, Marketing, Vlocity, MuleSoft, Tableau, etc.\nYou""™ll help us by viewing this opportunity as more than a job, but an opportunity to mold the business\nand as a place to grow your career with a core group of highly talented individuals across the US, Costa\nRica, Canada, and India. We put an emphasis on training, improving consulting skills and helping you\nachieve certifications. You""™d be joining a company that has 3,000+ SF certifications, so you know you are\npart of a highly skilled team that values investing in team education and skill building.\nWhy the Role Is Important:\nOur B2B Developers are fundamental to ensuring the digital technology and related services that NTT\nDATA builds for our clients are valuable, intuitive, and impactful. The work of CPQ Jr. Developers provides\nour clients and team with support, leadership, and direction to make sure projects are executed well and\nto deliver the engagement as promised.\nOnce You Are Here, You Will:\n— Develop custom solutions using Salesforce functionality (APEX, SOQL, Visual Force, SOSL, Service CLOUD\nLightning Components, integrations to third party solutions etc.)\n— Develop solutions based on requirements with direction from SA, & work to unit test work from\nthe entire team with Service CLOUD\n— Translate simple to complex user stories into functional and actionable software within the\nSalesforce environment\n— Participate in daily stand ups, team status meetings, bug reviews and triaging and contribute\ninformation to status, risk, and issue reports, experince Cloud\n39\nMaster | EAS - SFDC\n— Ensure functionality is delivered per the SOW. Identify deviations and communicate to project\nleadership.\n— Follow all project standard operating procedures (SOP) related to time reporting, DevOps,\nreporting status, updating PM/ticketing system for assignments,\no bugs, events, incidents, requests, changes, problems, etc.\n— Implement enhancements, custom objects, & extensions including pleasing UI/UX screens.\nUtilize your expertise to address UI/UX requirements effectively in\no the B2B Space to design cutting edge store fronts.\nRequired Qualifications:\n— Minimum 5+ years""™ experience in SFDC Development using Apex Classes, Visualforce Pages,\nTriggers, Service CLOUD , experience cloud\n— Minimum 3+ years in IT consulting\n— Minimum of 1 E2E project in the B2B space\n— Experience developing on the B2B Lightning product, minimum 2+ years of experience with with\nlightning web components, Aura, etc.\n— 6 months of experience designing, implementing, or maintaining Cloud Craze Solutions\n— Certified Salesforce Platform Developer I Certification Required\nPreferred Qualifications:\n— 7+ years in the Salesforce development space\n— 10+ years of I.T. experience in the development space\n— Additional Salesforce developer track certifications\n— Experience Providing Security controllers to users by using Profiles, Roles, Permission sets and\nOWD Setting\n— Experience with developing extensions using custom objects & adding custom fields, page\nlayouts, record types, lookup relationship, master-detail\no relationships\n— Experience with RESTful Service Architecture is a plus, experience with API development\nexperience a plus\n— Experience cloud / Communities experience a big plus\n— Knowledge of E2E Order Management lifecycle also appreciated but not a requirement\n— Experience with data migration using Data Loader\n— Understanding of CloudCraze architecture (Service Layers, Logic Layers, Data Layers), data\nmodels, customizations & extensions.\n— Knowledge of End-to-End Order Management lifecycle also appreciated but not a requirement\n— Nice to haveCloudCraze or B2B Lightning configuration experience and system administration\n— Technical skills related to Apex, ability to design & develop visual force pages and other\nprogramming languages desirable\n— Experience with RESTful Service Architecture is a plus\n— Experience with API development experience a plus\n— Experience cloud / Communities experience a big plus\nIdeal Mindset:\n— Problem Solver. You are creative but also practical in finding solutions to problems that may arise\nin the project to avoid potential escalations.\n40\nMaster | EAS - SFDC\n— Analytical. You like to dissect complex processes and can help forge a path based on your\nfindings.\n""¢ Strong work ethic. You are a team player and lead by example.\n\n\nLocation - Bengaluru,Chennai,Gurugram,Hyderabad,Noida,Pune",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sfdc development', 'salesforce lightning', 'cloud craze', 'it consulting', 'salesforce', 'sosl', 'visualforce', 'soql', 'sfdc', 'lightning components', 'apex', 'sales force development', 'vlocity', 'marketing', 'system administration', 'tableau', 'data loader', 'b2b', 'mule esb', 'api', 'visualforce pages']",2025-06-11 05:50:25
Software Dev. Sr. Specialist Advisor,"NTT DATA, Inc.",2 - 7 years,Not Disclosed,['Bengaluru'],"Role: Billing Support Analyst (Grade 5 - 12)\n\nLocationIndia (preferably Bengaluru)\n\n\n\nDescription:\n\nThe purpose of this role is to support Billing and payment applications of MVNE (Mobile Virtual Network Enabler) platform hosted both on-prem and on cloud (AWS). This role is also responsible for managing billing and payment processing for the MVNE.\n\n\n\nJob Responsibilities\nProvide L1/L2/L3 support for Billing and payment applications. Support coverage is 24x7 with full support provided during Irish business hours and on on-call rota basis outside of Irish business hours, including weekends\nResponsible for resolution of billing and payment incidents in accordance with established Service Level Agreements\nCo-ordinate resolution of incidents with third parties that are responsible for applications in their scope\nCarry out daily Application Health Check proactively to catch any symptoms that might lead to incidents and take measures proactively to avoid incident occurrence.\nMonitor application alerts raised by the application monitoring platform and resolve issues as and when identified by the monitoring platform\nMaintain up to date operational documentation, such as SOPs and application Runbooks\nConduct thorough impact and root cause analysis of the incident and publish findings in incident report.\nConduct end-to-end testing of new functionality developed prior to rolling out to production.\nPerform analysis on frequently occurring issues and make service improvement recommendations to resolve such issues from occurring.\nResponsible for SIM ordering process\nCarry out bill simulation run and validation\nCarry out scheduled billing run\nResponsible for payment processing for credit card and direct debit payments, including the handling of payment reversals and rejects\nResponsible for deployment of application code or configuration changes in the production environment.\nCreate or update knowledge articles based on the incident and problem learning.\nMaintain up to date operational documentation, such as SOPs and application Runbooks\nResponding to business user queries\n\n\n\nMust Have\n\nSkills:\n\nStrong Telecom knowledge.\nHands-on experience with supporting Billing and payment applications\nHands-on experience in running billing process and payment processing\nKnowledge of ITIL framework, with required experience in incident management, change management\nExperience in Application Monitoring tools such as Nagios, Xymon and cloudwatch\nExperience in handling high priority incidents (crisis calls)\nStrong skills on\n\nJava technologies vis- -vis Springboot, React, SOAP-UI web services,\nExcellent skills in\n\nLinux OS and shell scripting\nStrong\n\nPostgreSQL and Oracle database knowledge\nGood English verbal communication skills with the ability to explain things in a clear and non-technical way.\nStrong attention to detail and the ability to deliver high quality work.\nShould have the ability to identify right prioritization of incidents, which requires in-depth domain knowledge.\nShould be able to switch between various tasks seamlessly.\n\n\n\nNice to have\nITSM v3/v4 foundation certification.\nCapable of analysing new requirements and provide solution delivery estimates.\nStrong knowledge of the entire software development lifecycle.\n\n\n\nExperience / Qualification\nBachelor""™s and/or Master""™s degree in Computer Science, Engineering or related technical discipline.\n2 to 15+ years of IT professional experience within a global organization.\n2 to 15+ years of experience in Telecommunications service.\n2 to 15+ years of experience working as billing support analyst experience\nHave a good understanding of application architecture, data architecture, infrastructure and business processes.\n\n\n\nQualities\nAccountable for professional working behavior including, building and maintaining constructive working relationships, implementing proactive and concise communication, acting as a resource to colleagues, and engaging in collaborative thinking and problem solving while demonstrating CSGs core competencies and values.\nExercises independent judgment after considering alternatives.\nWorks under the general guidance of more senior members of the team with occasional consultation and collaboration.\nCoordinates own tasks and those of junior team members to meet project schedules.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['software development life cycle', 'postgresql', 'oracle database', 'linux', 'shell scripting', 'oracle', 'web services', 'nagios', 'itil framework', 'java technologies', 'telecommunication', 'change management', 'spring boot', 'react.js', 'java', 'ui', 'incident management', 'telecom', 'soap']",2025-06-11 05:50:27
Digital Solution Cnslt. Sr. Consultant,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['Pune'],"Req ID: 316242\n\nWe are currently seeking a Digital Solution Cnslt. Sr. Consultant to join our team in Pune, Mahrshtra (IN-MH), India (IN).\nWhy the Role Is Important:\nOur Developers are fundamental to ensuring the digital technology and related services that NTT DATA builds for our clients are valuable, intuitive, and impactful. The work of Salesforce Developers provides our clients and team with support, leadership, and direction to make sure projects are executed well and to deliver the engagement as promised.\nOnce You Are Here, You Will:\n""¢ Perform development, testing, implementation, documentation within the SalesForce.com platform\n""¢ Salesforce developer resource who will support dashboarding, data analysis and visualization needs for the team.\n""¢ Develop and maintain Lightening Web Components, Visualforce, Apex, and integrations to other third-party solutions\n""¢ Act as the first point of escalation for daily service issues along with PM and be a primary point of contact for Stakeholders\n""¢ Prepare/Review Test Scripts and Unit testing of changes\n""¢ Provide training, support, and leadership to the larger project team\n""¢ Develop Apex Class and Visual force pages in compliance with Salesforce.com recommended standards\n""¢ Develop Apex Test classes with a minimum of 90% coverage as all functionalities and bulk operations might be validated.\n""¢ Force.com""Apex, Visualforce, Triggers, SOQL, SOSL, API, Flows, LWC, Web Services (SOAP & REST)Sales Cloud, LWC, Javascript, CSS, Salesforce Packages, Jenkins, Agile methodology, CI/CD""\n\nRequired Qualifications:\n""¢ 5+ years""™ experience in a Salesforce consulting role that include completing at least 5 projects in a development role\n""¢ Salesforce Platform Developer II Certification\n""¢ Salesforce Certified Platform Developer-I\n""¢ Salesforce Certified App Builder\n""¢ Familiarity with Ja vascript, CSS, Splunk Analytics\n\n""¢ 5 years+ experience developing custom business logic in APEX, writing test classes, creating Lightning Web Components, Visualforce Pages and Triggers\n""¢ 5 Years+ experience in SFDC Developing custom business logic in Apex, creating Lightning Web Components, Visualforce Pages, and Triggers\n\nPreferred Experience:\n""¢ Prior experience with a software development methodology, Agile\n""¢ Knowledge of Reports & Dashboards, SOQL & SOSL\n""¢ Knowledge of Lightning Application on Aura Framework\n""¢ Knowledge with Providing Security controllers to users by using Profiles, Roles, Permission sets and OWD Setting\n""¢ Experience with data migration using Data Loader",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sosl', 'soql', 'aura framework', 'dashboards', 'reports and dashboards', 'visualforce', 'sfdc development', 'css', 'salesforce lightning', 'sfdc', 'triggers', 'javascript', 'sales', 'apex', 'salesforce', 'sales force development', 'data loader', 'java', 'business logic', 'splunk', 'agile', 'visualforce pages']",2025-06-11 05:50:29
Digital Engineering Sr. Engineer,"NTT DATA, Inc.",4 - 6 years,Not Disclosed,['Hyderabad'],"Req ID: 320609\n\nWe are currently seeking a Digital Engineering Sr. Engineer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\nJob\n4-6 Yrs. of overall technical experience in SAP BODS with all the SAP BODS application modules (Extract, Transform, Load)\n2-4 Yrs. of experience with Data Migration experience with S/4 HANA/ECC Implementations\nExperience in BODS Designer Components- Projects, Jobs, Workflow, Data Flow, Scripts, Data Stores and Formats\nExperience in BODS performance tuning techniques using parallel processing (Degree of Parallelism), Multithreading, Partitioning, and Database Throughputs to improve job performance\nExperience in ETL using SAP BODS and SAP IS with respect to SAP Master / Transaction Data Objects in SAP FICO, SAP SD, SAP MM/WM, SAP Plant Maintenance, SAP Quality Management etc. is desirable\nExperience with Data Migration using LSMW, IDOCS, LTMC\nAbility to Debug LTMC errors is highly desirable",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data migration', 'wm', 'sap mm', 'sap', 'sap bods', 'lsmw', 'ecc', 'warehouse management', 'sap sd', 'sap mm wm', 'apex', 'sap s hana', 'salesforce', 'sap production planning', 'idocs', 'sap fico', 'sap quality management', 'etl', 'sap hana', 'sap qm', 'triggers', 'bods', 'sap pp', 'sap plant maintenance', 'sap pm']",2025-06-11 05:50:31
Digital Solution Consultant Sr. Analyst,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['Noida'],"Req ID: 328175\n\nWe are currently seeking a Digital Solution Consultant Sr. Analyst to join our team in Noida, Uttar Pradesh (IN-UP), India (IN).\n\nAs a Revenue Cloud and CPQ Sr. Developer, you will have the opportunity to get in on the ground floor of a new division\ncreated within one of the largest technology providers in the world. We are building the next generation\nof digital services company and believe clients are ready for a more nimble, agile partner to deliver outcomes across the SFDC platform- including Sales, Service, Marketing, Vlocity, MuleSoft, Tableau, etc.\nYou""™ll help us by viewing this opportunity as more than a job, but an opportunity to mold the business\nand as a place to grow your career with a core group of highly talented individuals across the US, Costa\nRica, Canada, and India. We put an emphasis on training, improving consulting skills and helping you\nachieve certifications. You""™d be joining a company that has 3,000+ SF certifications, so you know you are\npart of a highly skilled team that values investing in team education and skill building.\nWhy the Role Is Important:\nOur CPQ Sr. Developers are fundamental to ensuring the digital technology and related services that NTT\nDATA builds for our clients are valuable, intuitive, and impactful. The work of CPQ Sr.\nDevelopers provides our clients and team with support, technical/code ownership & direction to make\nsure projects are executed well and to deliver the engagement as promised.\n\nDevelop primarily custom and occasional OOB solutions using Salesforce functionality (APEX, SOQL,\nSOSL, Lightning Components, integrations to third party solutions etc.)\n— Design Salesforce solutions and assist our project leaders to form accurate project plans and\nprovide high level technical/code solution design\n— Act as primary team contact for code design and first point of contact for code/bug issues during UAT\n& system testing\n— Manage and monitor the delivery of any needed point to point integration services (implement\nSalesforce CPQ API solutions)\n— Train other development resources on Salesforce development practices as needed\n— Participate in daily stand ups, team status meetings, bug reviews and triaging and contribute\ninformation to status, risk, and issue reports\n— Ensure functionality is delivered per the SOW, identifying deviations and communicate to project\nleadership\n— Follow all project standard operating procedures (SOP) related to time reporting, DevOps, reporting\nstatus, updating PM/ticketing system for assignments, bugs, events, incidents, requests, changes,\nproblems, etc.\n\nMinimum 5+ years""™ experience in SFDC Development using Apex Classes, Visualforce Pages,\nTriggers\n— Minimum 1+ years""™ experience with Lightning Component Development (prefer 2+ years""™\nexperience)\n— Minimum of 4 E2E projects in the Salesforce space\n— Certified Salesforce Platform Developer II and Sales or Service Certification Required\n— Minimum 1+ years""™ experience with Lightning Web Components\n— Minimum 1 years""™ experience in Integration projects using Web Services / Integration tools\n— Minimum 1 years""™ experience in SOQL query writing.\n— Experience in Custom Objects, Custom Tabs, Custom Fields, Validation Rules, Workflow Rules,\nPage Layouts, Record Types, Lookup Relationship, Master-detail\nRelationships.\nPreferred Qualifications:\n— Salesforce CPQ Specialist Certification\n— 2 E2E project in the Salesforce CPQ space\n— Experience with both LWC and Aura\n— UI/UX Experience (even if light)\n— Salesforce CPQ API experience a big plus\n— Salesforce CPQ QCP (quote calculator plug-in) and Javascript a big plus.\n— Experience Providing Security controllers to users by using Profiles, Roles, Permission sets and\nOWD Setting\n— Experience with data migration using Data Loader.\nProblem Solver. You are creative but also practical in finding solutions to problems that may arise\nin the project to avoid potential escalations.\n— Analytical. You like to dissect complex processes and can help forge a path based on your\nfindings.\n42\nMaster | EAS - SFDC\n— Strong work ethic. You are a team player and lead by example",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sfdc development', 'soql query', 'salesforce lightning', 'component development', 'query writing', 'standard operating procedures', 'soql', 'ux', 'web services', 'lightning components', 'javascript', 'salesforce cpq', 'vlocity', 'tableau', 'data loader', 'ui', 'mule esb', 'lwc', 'api']",2025-06-11 05:50:32
SAP C4C Sr.Consultant,"NTT DATA, Inc.",8 - 13 years,Not Disclosed,['Hyderabad'],"Req ID: 314521\n\nWe are currently seeking a SAP C4C Sr.Consultant to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\nConsultant needs to work in 12to 10pm or 3.30pm to 1.30 AM shift and needs to have a good communication skills. Needs to have 8+ yrs of experience in implementation & Support of C4C SDK module.\n\nHighly skilful in ABSL, UI Script, UI designer in SAP Cloud Applications Studio (SDK) to develop, deploy & Support complex SAP Sales/Service cloud solutions\nStrong debugging and problem-solving skills in SAP C4C, CPI, ECC and S4 and familiarity with ABAP Development of Proxys, RFC modules and Idoc related development\nFamiliarity with Cloud Platform Integration / SAP BTP Integration\nExperience in design and development of SAP Sales and Service cloud Custom Business Objects, Extensions and BAdI's.\nExperience in integrations with SAP and non-SAP systems using SOAP, REST and ODATA web services including Mash-ups and integration with external systems\nExperience with data workbench, data templates and conversions\n\nExperience defining systems strategy, developing systems requirements, designing and prototyping, testing, training, defining support procedures, and implementing practical business solutions under multiple deadlines.\nIdentify technical requirements, perform requirements management, lead technical design prototyping, process design, including scenario design and flow mapping, supervise technical consultants in developing code for additional non-standard functionality requirements as well as testing, training, defining support procedures and supporting implementations.\nWork independently or as part of a team to manage and complete multiple task assignments\n\nIdentify business requirements with client team and facilitate solution development\n\nDemonstrate strong verbal and written communications skills",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['ecc', 'debugging', 'cpi', 'c4c sdk', 'sap c4c', 'css', 'abap dictionary', 'web services', 'sap cloud platform', 'data migration', 'sap crm', 'odata', 'java', 'ui', 'sap abap crm', 'absl', 'html', 'sap hana', 'absl scripting', 'rest', 'sap', 'c', 'sap crm technical', 'web ui', 'bods', 'sap cpi', 'sdk', 'sap abap', 'abap', 'soap']",2025-06-11 05:50:34
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Bengaluru'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:50:36
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Bengaluru'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['database migration', 'Knowledge management', 'Performance Management', 'Talent Management', 'disaster recovery', 'middleware']",2025-06-11 05:50:37
IT Audit,KPMG Assurance and Consulting Services LLP,4 - 8 years,Not Disclosed,['Bengaluru'],"KPMG in India, a professional services firm, is the Indian member firm affiliated with KPMG International and was established in September 1993. Our professionals leverage the global network of firms, providing detailed knowledge of local laws, regulations, markets, and competition. KPMG has offices across India in Ahmedabad, Bengaluru, Chandigarh, Chennai, Gurugram, Hyderabad, Jaipur, Kochi, Kolkata, Mumbai, Noida, Pune, and Vadodara.\nKPMG in India offers services to national and international clients in India across sectors. We strive to provide rapid, performance-based, industry-focussed, and technology-enabled services, which reflect a shared knowledge of global and local industries and our experience of the Indian business environment\nKPMG Advisory professionals provide advice and assistance to enable companies, intermediaries, and public sector bodies to mitigate risk, improve performance, and create value. KPMG firms provide a wide range of Risk Advisory and Financial Advisory Services that can help clients respond to immediate needs as well as put in place the strategies for the longer term.\nProjects in IT Advisory focus on the assessment and/or evaluation of IT systems and the mitigation of IT-related business risks. They are either IS audit, SOX reviews, Internal audit engagements, IT infrastructure review and/or risk advisory including but not limited to IT audit supports in nature\n\nRole & responsibilities\nPerform testing of IT Application Controls/ITAC/Automated controls, IPE, and Interface Controls through code reviews, IT General Controls/ITGC/GITC review covering areas such as Change Management, Access Management, Backup Management, Incident and Problem Management, SDLC, Data Migration, Batch Job scheduling/monitoring and Business Continuity and Disaster Recovery\nPerform Risk Assessment, identification, and Evaluation of Controls, prepare process flow diagrams and document the same in Risk & Control Matrix.\nPerform business process walkthrough and controls testing for IT Audits.\nPerforming planning and executing audits, including - SOX, Internal Audits, External Audits\nConducting controls assessment in manual/ automated environment\nPrepare/Review of Policies, Procedures, SOPs\nMaintain relationships with client management and the project Manager to manage expectations of service, including work products, timing, and deliverables.\nDemonstrate a thorough understanding of complex information systems and apply it to client situations. Use extensive knowledge of the client's business/industry to identify technological developments and evaluate impacts on the work to be performed.\nCoordinate effectively and efficiently with the Engagement manager and the client management keeping both constantly updated regarding projects progress. Collaborate with other members of the engagement team to plan the engagement and develop relevant workpapers/deliverables.\nPerform fieldwork and share the daily progress of fieldwork, informing supervisors of engagement status.\n\n\nPreferred candidate profile\n\nMBA/Mtech/MS full time with minimum 3 year experience.\nIT Audit + SAP experience with knowledge of IT governance practices\nPrior IT Audit knowledge in areas of ITGC, ITAC (application/automated controls) SOX 404, SOC-1 and SOC-2 Audits\nGood to have knowledge of other IT regulations, standards and benchmarks used by the IT industry (e.g. NIST, PCI-DSS, ITIL, OWASP, SOX, COBIT, SSAE18/ISAE 3402 etc.)\nTechnical Knowledge of IT Audit Tools with excellent knowledge of IT Audit process and methodology\nExposure to Risk Management and Governance Frameworks/ Systems will be an added advantage\nExposure to ERP systems will be added advantage\nStrong project management, communication (written and verbal) and presentation skills\nKnowledge of security measures and auditing practices within various applications, operating systems, and databases.\nStrong self-directed work habits, exhibiting initiative, drive, creativity, maturity, self-assurance, and professionalism\nPreferred Certifications CISA/CISSP//CISM\nExposure to automation Data Analytics tools such as QlikView/Qlik sense, ACL, Power BI will be an advantage\nProficiency with Microsoft Word, Excel, Visio, and other MS Office tools",Industry Type: Accounting / Auditing,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['ITAC', 'Itgc', 'Control Testing']",2025-06-11 05:50:39
GCP Lead Developer,Wipro,5 - 8 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\nDeliver\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['GCP', 'Team Management', 'database migration', 'troubleshooting', 'middleware', 'database architecture']",2025-06-11 05:50:41
SQL Server 2012/SQL Server Engineer,INTERNAL,5 - 10 years,Not Disclosed,['Bengaluru'],"Skill Name :SQL Server 2012/SQL Server Engineer (5 - 10 years)\nWork Location : Bangalore (preferred) / Any Deloitte USI location\n\nKey responsibilities:\nUnderstand customer use case, available data to prepare for automated & ongoing data\ningestion to meet customer requirements\n• Design technical solution with all data ingestion, transformation & scheduling to\nreview & sign-off with customer\n• Play role of the tech lead and responsible for end-to-end technical solutions\n• Identifying AEP enhancements, extending frameworks and incorporating new ideas\n• Closely collaborating with other AEP team members (sales teams, engineers,\nconsultants) and onshore teams for delivering projects\n• Enterprise level software development leveraging Big Data, Cloud technologies &\nPython\n• Building/operating highly scalable, fault tolerant, distributed systems for extraction,\ningestion to process large data sets\n• Experience with data analysis, modeling and mapping to coordinate closely with\nData Architect(s)\n• Build the necessary schemas, workflows to ingest customers data into AEP\nsuccessfully\n• Create necessary identity namespaces, privacy settings and merge poilicys required\nto build the solution\n• Build Audiences (segmentations) and create necessary pipeline for Destination\nactivation\n• Deploying the final solution to a production environment (or end-state\nenvironment)\n• Post-Deployment, provide ongoing maintenance & support of solution & knowledge\ntransfer to offshore support team",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Part Time, Temporary/Contractual","['AEP Architect', 'Data Architect', 'SQL Server', 'Data base', 'SQL']",2025-06-11 05:50:43
Senior/Principal MS-SQL Engineer,Modicare,8 - 13 years,Not Disclosed,['Delhi / NCR( New Friends Colony )'],"Job Overview\nSeeking an exceptionally skilled Senior/ Principal MS-SQL Engineer to join IT team within India's largest, and most fast-paced Direct Selling organization.\n> 70 % of your time will be spent deep in T-SQL, query plans, indexes, HA/DR, algorithmic payout simulations, and performance forensics..\nKey Responsibilities\nTake full technical ownership of a complex, high-impact marketing plan system currently built using Node.js and SQL.",,,,"['T-SQL', 'Cloud Sql', 'Restfull Api', 'Postgresql', 'Node.Js', 'Rabbitmq', 'Kafka', '.Net']",2025-06-11 05:50:45
GCP Lead Developer,Wipro,5 - 8 years,Not Disclosed,['Bengaluru'],"Role Purpose\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\nDeliver\n\nNo Performance Parameter Measure\n1Operations of the towerSLA adherence Knowledge management\nCSAT/ Customer Experience Identification of risk issues and mitigation plans\nKnowledge management\n2New projectsTimely delivery Avoid unauthorised changes No formal escalations\n\nMandatory Skills: Cloud-PaaS-GCP-Google Cloud Platform.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['GCP', 'architectural design', 'Performance Management', 'Talent Management', 'Cloud-PaaS', 'root cause analysis']",2025-06-11 05:50:46
GCP Lead Developer,Wipro,5 - 8 years,Not Disclosed,['Bengaluru'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer Experience\nIdentification of risk issues and mitigation plans\nKnowledge management2New projectsTimely delivery\nAvoid unauthorised changes\nNo formal escalations\n\n\n\nMandatory Skills: Cloud-PaaS-GCP-Google Cloud Platform.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['GCP', 'configuration functions', 'test plans', 'architecture planning', 'troubleshooting', 'data architecture', 'middleware']",2025-06-11 05:50:48
Senior Cloud Client Partner,"NTT DATA, Inc.",3 - 7 years,Not Disclosed,['Gurugram'],"Key Responsibilities:\nCreates demand and selling Cloud Managed Services solutions -\nCreates demand by assisting clients to identify and qualify current needs and effectively articulates how the company can add value through its Cloud services and solutions offering.\nResponsible for addressing the objections that a client may pose in moving to a Cloud managed services solution.\nAppropriately allocates and decides sales time between assigned clients and new prospect opportunities; yet ensure focus remains on the top clients/prospects and balance opportunity size with likely outcomes\nSales partnership -\nThe success of the services agenda and successful sales will rely on successful partnership with others; this will include regional leads and services teams to work on the best outcome for the client.\nCollaborates with partners and/ or vendors to drive select deals through vendor-based opportunities.\nCollaborates with broader organization such as the Offer Management, Commercial Architecture and Delivery teams to promote and support high-value services opportunities.\nDirects regional sales governance processes and Deal Clinics to profile opportunities.\nManaged Services industry trusted advisor -\nResponsible for building deep and long-term relationships with client leaders in a Managed Services opportunity and execute a competitive win strategy through understanding the clients business requirements and competitive landscape.\nDirects the maintenance of a high level of relevant service knowledge to have meaningful conversations with clients; including the industry that the client operates in.\nCreates the knowledge base of organizational services solutions within a services practice by sharing best practices with internal teams as well as client teams; ensuring that internal teams are aware of typical client challenges\nDeal construct -\nDirects the build and supports commercial solutions for Managed Services solutions and design deals that meet clients needs and ensure win/win solutions for both client and the company.\nResponsible for constructing the managed services deal including the commercial modelling, negotiate contractual terms, mitigate legal risk and obstacles, and move the proposal to close to meet assigned quota.\nDrives the sales process -\nAccountable for managing a pipeline of opportunities and creating and documenting a shared strategy to meet sales target such as net new customer pursuit plans to land new logos, activities to achieve client satisfaction, minimize churn, cross-sell, upsell, revenue, and margin goals.\nWorks across multiple sales teams and commercial architects to successfully position the service and see the opportunity through to closure.\nWorks across multiple internal teams to ensure scope of work and proposals are tracked, managed and delivered on time.\nCreates and consults on the implementation of an opportunity plan, to provide regular check-ins with the primary point of contact and have an established process for getting buy-in from all stakeholders.\nResponsible for ensuring data is accurate based on sales reporting standards to provide data-driven insights.\nConsults on the negotiation of deals with clients and lead the internal account management team to enable conclusion of services deals.\nConsults on the knowledge base of organizational solutions and services by sharing best practices, industry and technology trends with internal stakeholders and clients.\nParticipates in regional reporting cadence as it relates to regional performance and major deal reviews.\n\nKnowledge and Attributes:\nStrong knowledge of cloud infrastructure principles and products.\nUnderstanding how networking works in a cloud environment to enable the design of effective solutions.\nAdvanced understanding of and the ability to position the companys services offerings that may span multiple technology domains across Managed Services, Support Services, Consulting Services and Technical Services.\nAdvanced understanding of platform delivered services and how to articulate the value of standardized, centralized and optimized services.\nProficiency in working with major cloud platforms such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and others.\nAdvanced understanding of broader IT infrastructure components, such as servers, storage, virtualization, and data centers.\nConversant with a business outcome led approach to sales.\nAdvanced familiarity with document management platforms.\nAdvanced understanding of cybersecurity principles to ensure data security and protection during collaboration efforts.\nAdvanced understanding of financial statements and metrics, including revenue, expense control, and growth relative to market in order to hold strategic client conversations.\nHave the legal knowledge to discuss contracting with the client and understand how to position terms as a value exchange.\nAdvanced client-centricity coupled with problem solving.\nAdvanced business acumen and negotiation skills to craft solutions that are beneficial to the organization and the client.\nAbility to pro-actively and independently identify and qualify opportunities, an entrepreneurial mindset if key.\nNatural team player ability to coordinate and liaise with delivery teams across multiple business areas.\nQuick learner to understand any new solutions that are ready to take to market.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent in a Technical or Sales field or related.\nCertifications such as Scotworks and Solution selling is desired.\nSolution Selling/SPIN certifications is desired.\nDesired technology certifications include (any one or more) - Azure (AZ900 Azure Fundamentals), AWS (AWS Cloud Practitioner), VMWare (VTSP or VTSP for AWS/Azure), ITIL (Version 3 or later).\n\nRequired Experience:\nAdvanced demonstrated track record of managed services solutions to large enterprise accounts.\nAdvanced demonstrated experience structuring large, multi-year profitable contracts.\nAdvanced demonstrated ability of building strong relationships with clients across all levels; but especially the C-suite.\nAdvanced demonstrated experience of networking with senior internal and external people in the specialist area of expertise.\nAdvanced demonstrated experience in managing the entire sales process, contracting process and legal implications of a deal.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Cloud', 'Azure', 'VMWare', 'VTSP', 'ITIL', 'AWS']",2025-06-11 05:50:50
Senior Cloud Client Partner,"NTT DATA, Inc.",7 - 10 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Senior Cloud Client Partner is an advanced subject matter expert and is also a quota-bearing sales persona. This role has the primary responsibility to work with services teams to identify, develop, and close managed service and outsourcing deals.\n\nThis role is recognized as the clients trusted cloud managed services advisor and applies consulting led sales skills to engage and close opportunities with decision-makers.\n\nThis role works directly with clients at a variety of levels, as well as other internal sales and delivery expert teams such as Client Managers and pre-sales services-type architects and post the sale; the delivery teams that will manage the clients outsourced solution. Deals often involve alignment on business outcome led multi-product/multi-vendor cloud solutions with services.\n\nThis role champions the delivery teams understanding of the clients solution requirements, and initiates improvement programs ensuring that the client remains committed to solutions which leads to more sales opportunities.\n\nBuilding and developing excellent stakeholder relationships with clients, fully understanding the client and the industry in which they operate will be a core focus of this role. The focus of this role remains on converting the client to a managed services client resulting in multi-year renewals; deals may involve a long sales cycle.\n\nAs a Senior Cloud Client Partner, this role has the opportunity to partner with some of the biggest global organizations, helping them to convert to new business models.\nWhat you'll be doing\nKey Responsibilities:\nCreates demand and selling Cloud Managed Services solutions -\nCreates demand by assisting clients to identify and qualify current needs and effectively articulates how the company can add value through its Cloud services and solutions offering.\nResponsible for addressing the objections that a client may pose in moving to a Cloud managed services solution.\nAppropriately allocates and decides sales time between assigned clients and new prospect opportunities; yet ensure focus remains on the top clients/prospects and balance opportunity size with likely outcomes\nSales partnership -\nThe success of the services agenda and successful sales will rely on successful partnership with others; this will include regional leads and services teams to work on the best outcome for the client.\nCollaborates with partners and/ or vendors to drive select deals through vendor-based opportunities.\nCollaborates with broader organization such as the Offer Management, Commercial Architecture and Delivery teams to promote and support high-value services opportunities.\nDirects regional sales governance processes and Deal Clinics to profile opportunities.\nManaged Services industry trusted advisor -\nResponsible for building deep and long-term relationships with client leaders in a Managed Services opportunity and execute a competitive win strategy through understanding the clients business requirements and competitive landscape.\nDirects the maintenance of a high level of relevant service knowledge to have meaningful conversations with clients; including the industry that the client operates in.\nCreates the knowledge base of organizational services solutions within a services practice by sharing best practices with internal teams as well as client teams; ensuring that internal teams are aware of typical client challenges\nDeal construct -\nDirects the build and supports commercial solutions for Managed Services solutions and design deals that meet clients needs and ensure win/win solutions for both client and the company.\nResponsible for constructing the managed services deal including the commercial modelling, negotiate contractual terms, mitigate legal risk and obstacles, and move the proposal to close to meet assigned quota.\nDrives the sales process -\nAccountable for managing a pipeline of opportunities and creating and documenting a shared strategy to meet sales target such as net new customer pursuit plans to land new logos, activities to achieve client satisfaction, minimize churn, cross-sell, upsell, revenue, and margin goals.\nWorks across multiple sales teams and commercial architects to successfully position the service and see the opportunity through to closure.\nWorks across multiple internal teams to ensure scope of work and proposals are tracked, managed and delivered on time.\nCreates and consults on the implementation of an opportunity plan, to provide regular check-ins with the primary point of contact and have an established process for getting buy-in from all stakeholders.\nResponsible for ensuring data is accurate based on sales reporting standards to provide data-driven insights.\nConsults on the negotiation of deals with clients and lead the internal account management team to enable conclusion of services deals.\nConsults on the knowledge base of organizational solutions and services by sharing best practices, industry and technology trends with internal stakeholders and clients.\nParticipates in regional reporting cadence as it relates to regional performance and major deal reviews.\n\nKnowledge and Attributes:\nStrong knowledge of cloud infrastructure principles and products.\nUnderstanding how networking works in a cloud environment to enable the design of effective solutions.\nAdvanced understanding of and the ability to position the companys services offerings that may span multiple technology domains across Managed Services, Support Services, Consulting Services and Technical Services.\nAdvanced understanding of platform delivered services and how to articulate the value of standardized, centralized and optimized services.\nProficiency in working with major cloud platforms such as Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP), and others.\nAdvanced understanding of broader IT infrastructure components, such as servers, storage, virtualization, and data centers.\nConversant with a business outcome led approach to sales.\nAdvanced familiarity with document management platforms.\nAdvanced understanding of cybersecurity principles to ensure data security and protection during collaboration efforts.\nAdvanced understanding of financial statements and metrics, including revenue, expense control, and growth relative to market in order to hold strategic client conversations.\nHave the legal knowledge to discuss contracting with the client and understand how to position terms as a value exchange.\nAdvanced client-centricity coupled with problem solving.\nAdvanced business acumen and negotiation skills to craft solutions that are beneficial to the organization and the client.\nAbility to pro-actively and independently identify and qualify opportunities, an entrepreneurial mindset if key.\nNatural team player ability to coordinate and liaise with delivery teams across multiple business areas.\nQuick learner to understand any new solutions that are ready to take to market.\n\nAcademic Qualifications and Certifications:\nBachelor's degree or equivalent in a Technical or Sales field or related.\nCertifications such as Scotworks and Solution selling is desired.\nSolution Selling/SPIN certifications is desired.\nDesired technology certifications include (any one or more) - Azure (AZ900 Azure Fundamentals), AWS (AWS Cloud Practitioner), VMWare (VTSP or VTSP for AWS/Azure), ITIL (Version 3 or later).\n\nRequired Experience:\nAdvanced demonstrated track record of managed services solutions to large enterprise accounts.\nAdvanced demonstrated experience structuring large, multi-year profitable contracts.\nAdvanced demonstrated ability of building strong relationships with clients across all levels; but especially the C-suite.\nAdvanced demonstrated experience of networking with senior internal and external people in the specialist area of expertise.\nAdvanced demonstrated experience in managing the entire sales process, contracting process and legal implications of a deal.\nWorkplace type:\nOn-site Working",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['cloud infrastructure', 'VMWare', 'Google Cloud Platform', 'Microsoft Azure', 'networking', 'ITIL', 'technology domains']",2025-06-11 05:50:52
Cloud Amaze - DB Lead,Hexaware Technologies,6 - 10 years,Not Disclosed,"['Pune', 'Chennai', 'Bengaluru']",Experience : 6-10yrs \nWork location : Chennai / Bangalore / Pune\nPrimary Skills set :SSIS SSRS ADF + Cloud Migration (Azure only)\nWork Mode : Hybrid \nNotice Period : Imm - 30 days\nSharing JD for your reference :,,,,"['Azure Data Factory', 'SSRS', 'Cloud Migration', 'SSIS']",2025-06-11 05:50:53
NetSuite Architect_Night Shift,Oracle,10 - 20 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Job Description:\nWe are seeking a seasoned consultant with extensive expertise in NetSuite or similar ERP/CRM solutions to join our dynamic team as a Senior NetSuite Consultant. With a deep understanding of industry best practices and a broad knowledge of technology, this role will make a significant impact on our client engagements.\nDaily Responsibilities:\nThe day-to-day activities in this role are diverse and engaging, offering a unique opportunity to those seeking a non-traditional work environment. Here's a breakdown of the typical workload:\nScripting, QA, and Testing (30%): Crafting and executing test plans, ensuring the quality of our solutions.\nClient Engagement (30%): Interacting with clients, understanding their use cases, and providing solutions to their challenges.\nInternal Collaboration (15%): Participating in meetings, mentoring junior resources, and contributing to strategic initiatives.\nIntegration Consulting (10%): Working with clients to integrate NetSuite with their existing systems and third-party applications.\nProject Management (10%): Providing executive updates, maintaining documentation, and overseeing project progress.\nData Migration (5%): Assisting in the migration of data to NetSuite.\nKey Responsibilities:\nProject Tracking and Reporting: Utilize NetSuite and Jira to track and communicate project progress to stakeholders.\nCustom Scripting: Define and develop custom scripts on NetSuite's SuiteCloud platform to meet specific client requirements.\nRequirements Gathering: Collaborate with colleagues to analyze and understand client needs through interviews and requirement gathering sessions.\nSystem Design: Produce comprehensive system design documents and lead technical walkthroughs.\nTechnical Leadership: Lead technical teams, design and validate scripts, and coordinate with developers and QA for successful deployments.\nCode Reviews: Conduct thorough code reviews to ensure code quality and adherence to best practices.\nUser Acceptance Testing: Facilitate user acceptance testing for complex solutions, ensuring client satisfaction.\nDevelopment and Deployment: Assist in the entire software development lifecycle, including development, QA, and deployment, to meet project goals.\nGlobal Teamwork: Work effectively in a global team environment, providing guidance and mentorship to less experienced consultants.\nQualifications and Skills:\nERP/CRM Experience: 8+ years of hands-on experience with NetSuite or similar ERP/CRM solutions, with a strong preference for NetSuite expertise.\nEducational Background: A degree in Mathematics, Computer Science, or Engineering is preferred.\nSuiteCloud Expertise: Proficiency in SuiteCloud development, design, testing, and code review, including third-party integration.\nTechnical Leadership: Proven experience leading technical work streams, managing developers, and collaborating with global teams.\nSystem Architecture: Familiarity with system architecture, object-oriented design, web frameworks, and design patterns.\nDocumentation Skills: Ability to create detailed documentation for workflows, use cases, exception handling, and test cases.\nConsulting Experience: Prior success in a consulting role, engaging with clients and delivering solutions.\nSDLC Knowledge: Understanding of the software development lifecycle and its practical application.\nSoftware Development: Proficiency in JavaScript or other programming languages, with a preference for JavaScript.\nError Handling: Skilled in error resolution, debugging, and ensuring code stability.\nDevelopment Tools: Experience with WebStorm (preferred) or other IDEs, GIT for source control, unit-testing tools, and defect management systems.\nWeb Technologies: Proficient in XML/XSL, Web Services (SOAP, WSDL, REST, JSON), JSP/Servlets, DHTML, and JavaScript.\nJira Proficiency: Practical knowledge of Jira for project management and issue tracking.\nCommunication Skills: Excellent interpersonal and communication abilities to interact with clients and team members effectively.\nIf you have a passion for technology, a problem-solving mindset, and a desire to mentor and lead, we encourage you to apply. This role offers a dynamic and rewarding career path within the Oracle ecosystem.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Restlet', 'Netsuite', 'Suitescript', 'Integration']",2025-06-11 05:50:55
Digital Engineering Staff Engineer,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Bengaluru'],"Req ID: 310007\n\nWe are currently seeking a Digital Engineering Staff Engineer to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nData Modeler\n\n\n\nPosition Overview: The Data Modeler will be responsible for designing and implementing data models that support the organization's data management and analytics needs.\n\nThis role involves collaborating with various stakeholders to understand data sources, relationships, and business requirements, and translating them into effective data structures.\n\n\n\nKey Responsibilities:\n\n\nCollaborate with Business Analysts: Understand different data sources and their relationships.\n\n\nPrepare Conformed Dimension Matrix: Identify different grains of facts, finalize dimensions, and harmonize data across sources.\n\n\nCreate Data Models: Develop Source to Target Mapping (STMs) documentation and custom mappings (both technical and non-technical).\n\n\nInclude Transformation Rules: Ensure STMs include pseudo SQL queries for transformation rules.\n\n\nCoordinate Reviews: Work with Data Architects, Product Owners, and Enablement teams to review and approve models, STMs, and custom mappings.\n\n\nEngage with Data Engineers: Clarify any questions related to STMs and custom mappings.\n\n\n\nRequired Technical\n\nSkills:\n\n\n\nProficiency in SQL: Strong understanding of SQL and database management systems.\n\n\nData Modeling Tools: Familiarity with tools such as ERwin, IBM InfoSphere Data Architect, or similar.\n\n\nData Warehousing Concepts: Solid knowledge of data warehousing principles, ETL processes, and OLAP.\n\n\nData Governance and Compliance: Understanding of data governance frameworks and compliance requirements.\n\n\n\nKey Competencies:\n\n\nAnalytical\n\nSkills:\nAbility to analyze complex data sets and derive meaningful insights.\n\n\nAttention to Detail: Ensure accuracy and consistency in data models.\n\n\nCommunication\n\nSkills:\nEffectively collaborate with stakeholders and articulate technical concepts to non-technical team members.\n\n\nProject Management\n\nSkills:\nAbility to prioritize tasks, manage timelines, and coordinate with cross-functional teams.\n\n\nContinuous Learning and Adaptability: Commitment to ongoing professional development and adaptability to changing business needs and technologies.\n\n\n\nAdditional :\n\n\nProblem-Solving Abilities: Innovative solutions to data integration, quality, and performance challenges.\n\n\nKnowledge of Data Modeling Methodologies: Entity-relationship modeling, dimensional modeling, normalization techniques.\n\n\nFamiliarity with Business Intelligence Tools: Enhance ability to design data structures that facilitate data analysis and visualization.\n\n\n\nPreferred Qualifications:\n\n\nExperience in SDLC: Understanding of all phases of the Software Development Life Cycle.\n\n\nCertifications: Relevant certifications in data modeling, data warehousing, or related fields.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['database management system', 'data warehousing', 'sql', 'olap', 'etl process', 'c#', 'ibm infosphere', 'dimensional modeling', 'erwin', 'business intelligence', 'javascript', 'sql server', 'software development life cycle', 'linq', 'java', 'data modeling', 'asp.net', 'data structures', 'etl', 'sdlc']",2025-06-11 05:50:56
Principal NetSuite Technical Consultant_Night Shift,Oracle,5 - 10 years,Not Disclosed,"['Hyderabad', 'Bengaluru']","Job Description:\nWe are seeking a seasoned consultant with extensive expertise in NetSuite or similar ERP/CRM solutions to join our dynamic team as a Senior NetSuite Consultant. With a deep understanding of industry best practices and a broad knowledge of technology, this role will make a significant impact on our client engagements.\nDaily Responsibilities:\nThe day-to-day activities in this role are diverse and engaging, offering a unique opportunity to those seeking a non-traditional work environment. Here's a breakdown of the typical workload:\nScripting, QA, and Testing (30%): Crafting and executing test plans, ensuring the quality of our solutions.\nClient Engagement (30%): Interacting with clients, understanding their use cases, and providing solutions to their challenges.\nInternal Collaboration (15%): Participating in meetings, mentoring junior resources, and contributing to strategic initiatives.\nIntegration Consulting (10%): Working with clients to integrate NetSuite with their existing systems and third-party applications.\nProject Management (10%): Providing executive updates, maintaining documentation, and overseeing project progress.\nData Migration (5%): Assisting in the migration of data to NetSuite.\nKey Responsibilities:\nProject Tracking and Reporting: Utilize NetSuite and Jira to track and communicate project progress to stakeholders.\nCustom Scripting: Define and develop custom scripts on NetSuite's SuiteCloud platform to meet specific client requirements.\nRequirements Gathering: Collaborate with colleagues to analyze and understand client needs through interviews and requirement gathering sessions.\nSystem Design: Produce comprehensive system design documents and lead technical walkthroughs.\nTechnical Leadership: Lead technical teams, design and validate scripts, and coordinate with developers and QA for successful deployments.\nCode Reviews: Conduct thorough code reviews to ensure code quality and adherence to best practices.\nUser Acceptance Testing: Facilitate user acceptance testing for complex solutions, ensuring client satisfaction.\nDevelopment and Deployment: Assist in the entire software development lifecycle, including development, QA, and deployment, to meet project goals.\nGlobal Teamwork: Work effectively in a global team environment, providing guidance and mentorship to less experienced consultants.\nQualifications and Skills:\nERP/CRM Experience: 6+ years of hands-on experience with NetSuite or similar ERP/CRM solutions, with a strong preference for NetSuite expertise.\nEducational Background: A degree in Mathematics, Computer Science, or Engineering is preferred.\nSuiteCloud Expertise: Proficiency in SuiteCloud development, design, testing, and code review, including third-party integration.\nTechnical Leadership: Proven experience leading technical work streams, managing developers, and collaborating with global teams.\nSystem Architecture: Familiarity with system architecture, object-oriented design, web frameworks, and design patterns.\nDocumentation Skills: Ability to create detailed documentation for workflows, use cases, exception handling, and test cases.\nConsulting Experience: Prior success in a consulting role, engaging with clients and delivering solutions.\nSDLC Knowledge: Understanding of the software development lifecycle and its practical application.\nSoftware Development: Proficiency in JavaScript or other programming languages, with a preference for JavaScript.\nError Handling: Skilled in error resolution, debugging, and ensuring code stability.\nDevelopment Tools: Experience with WebStorm (preferred) or other IDEs, GIT for source control, unit-testing tools, and defect management systems.\nWeb Technologies: Proficient in XML/XSL, Web Services (SOAP, WSDL, REST, JSON), JSP/Servlets, DHTML, and JavaScript.\nJira Proficiency: Practical knowledge of Jira for project management and issue tracking.\nCommunication Skills: Excellent interpersonal and communication abilities to interact with clients and team members effectively.\nIf you have a passion for technology, a problem-solving mindset, and a desire to mentor and lead, we encourage you to apply. This role offers a dynamic and rewarding career path within the Oracle ecosystem.",Industry Type: Software Product,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Restlet', 'Netsuite', 'Suitescript', 'Integration']",2025-06-11 05:50:58
Systems Integration Advisor,"NTT DATA, Inc.",5 - 8 years,Not Disclosed,"['Noida', 'Chennai', 'Bengaluru']","Req ID: 324406\n\nWe are currently seeking a Systems Integration Advisor to join our team in Noida, Uttar Pradesh (IN-UP), India (IN).\n\nPosition Summary:\nPerforms IT functions such as design, analysis, evaluation, testing, installation, acquisition, modification and support of operating systems, database, or software. Plans, conducts, and directs the analysis of business problems to be solved with troubleshooting and automated systems. This position operates with minimal direction and requires a professional who can take ownership over their work.\n\nThis position is in support of the Core Services team in Corporate IT at Enlyte. Core Services includes the management of Active Directory, Microsoft Azure, Exchange O365, DNS, Microsoft Teams, SharePoint, OneDrive, and Identity and Access Management for corporate colleagues and contractors.\n\nMust Have skills\n\n1) Must have experience on Windows Active Directory\n\n2) Must have work experience on collpasing domains\n\n3) Must have experience of scheduled/ regular maintainence and Patching\n\n4) Must have exposure AD auditing\n\n5) Work Epxerience with SSSD integration skills\n\n6) Progressive experience with MS Windows uptill Windows 2019, 2022 exposure preferred\n\n7) Migration of AD from OnPrem to Cloud (Azure/ AWS)\n\n8) Work Experience with ADMT tool and good to have with Quest Migration tool\n\nRequired Experience:\n\n5-8 years of experience with Active Directory administration\n\n5-8 years of experience with Domain Name Service (DNS), including zone management\n\n5-8 years of experience with Windows PowerShell, with ability to develop scripts as needed\n\n5-8 years of experience with Microsoft Azure AD (now Entra ID)\n\n5-8 years of experience with Microsoft Exchange and Exchange O365\n\n5-8 years of experience with Mergers & Acquisitions involving Active Directory and Azure\n\n5-8 years of experience working in GxP or other regulated environments\n\n5-8 years of experience with documentation for systems management\n\n1-3 years of experience with SharePoint for O365, Teams, and OneDrive administration\n\n1-3 years of experience with Identity and Access Management, and Identity Governance\n\n1-3 years of experience with Amazon Web Services (AWS) IAM a plus\n\nRequired Education:\n\nAssociates Degree in Computer Science or equivalent. Bachelor""™s degree a plus.\n\nAssociated certificates in the above technologies a plus\n\nPrimary:\nWindows Server 2008 - 2022 (10 years)\nActive Directory (10 years) DNS (6 years+)\nLinux Server (4 years+)\nPowerShell (2 years+)\nMicrosoft Azure (2 years+)\nADMT (2 years+)\n\nGood To have skills\n\nQuest Migration Tools\nAWS Cloud\nRoute 53 Crowdstrike\nNetwrix",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['windows active directory', 'auditing', 'sharepoint', 'patching', 'onedrive', 'linux server', 'dns', 'microsoft azure', 'access management', 'mergers', 'identity access management', 'system administration', 'powershell', 'ms exchange', 'acquisition', 'active directory administration', 'aws', 'gxp']",2025-06-11 05:51:00
"Senior Automation Engineer, Robotics",NICE,4 - 7 years,Not Disclosed,['Pune'],"At NICE, we don’t limit our challenges. We challenge our limits. Always. We’re ambitious. We’re game changers. And we play to win. We set the highest standards and execute beyond them. And if you’re like us, we can offer you the ultimate career opportunity that will light a fire within you.\nSo, what’s the role all about? \nIn this position we are looking for a Strong Robotic Process Automation Engineer to work with Professional Services teams, Solution Architects, and Engineering teams, managing an On-prem to Azure Cloud onboarding and customer data ingestion automation solutions.The Engineer will work with US and Pune Cloud Services and Operations Team as well as other support teams across the Globe. \n\nWe are seeking a talented RPA Engineer with hands on experience designing and building Robotic Process Automation with both attended and unattended workflows to join our team. As a RPA Engineer, you will be responsible for developing and implementing cloud automation workflows and enhancing our cloud monitoring and self-healing capabilities as well as managing our infrastructure and ensuring its reliability, scalability, and security.",,,,"['rpa', 'cloud services', 'analytical', 'verbal communication', 'robotics', 'object oriented languages', 'nice', 'scalability', 'application development', 'sql', 'rts', 'cloud', 'java', 'apa', 'automation', 'linux', 'integration', 'robotic process automation', 'microsoft server', 'communication skills', 'architecture', 'deployment']",2025-06-11 05:51:01
Ncino Developer,"NTT DATA, Inc.",8 - 13 years,Not Disclosed,"['Chennai', 'Gurugram', 'Bengaluru']","Job TitlenCino/Salesforce Developer\n\nSummary:\nAre you passionate about transforming the banking and financial services landscape through cutting-edge technologyAs an nCino/Salesforce Developer, you will play a pivotal role in our digital transformation journey, leveraging your expertise to design, develop, and implement solutions that optimize our workflows and enhance client experiences. You will work closely with a collaborative team of professionals who are committed to leveraging the nCino platform/Salesforce to drive operational excellence and deliver innovative solutions. Join us in shaping the future of our organization while advancing your career in a dynamic and supportive environment!\n\nDetailed Responsibilities:\n- Design, develop, and implement robust nCino/Salesforce applications tailored to enhance business operations and user experience.\n- Collaborate with stakeholders to gather requirements, translate them into technical specifications, and provide innovative solutions that meet business needs.\n- Customize Salesforce and nCino functionality, including but not limited to data modeling, user interface design, and workflow automation.\n- Conduct thorough testing and debugging of applications to ensure high performance, security, and reliability.\n- Perform ongoing maintenance and enhancements for existing nCino and Salesforce applications, ensuring they stay current with evolving internal processes and industry standards.\n- Stay updated with the latest industry trends, nCino development best practices, and Salesforce features to continuously improve our platforms.\n- Provide training and support to end-users, promoting effective utilization and adoption of nCino and Salesforce applications across teams.\n- Collaborate with cross-functional teams, including business analysts, project managers, and UI/UX designers, to ensure seamless project execution and delivery.\n\nMust-Have Qualifications:\n- Min. 8+ years of overall experience in IT.\n\n- nCino experience is a must.\n- Proven experience as a Salesforce Developer with hands-on experience in nCino development and customization.\n- Strong proficiency in Salesforce Apex, Visualforce, Lightning components, and SOQL, as well as nCino""™s capabilities and functionalities.\n- Familiarity with Salesforce integrations, REST/SOAP APIs, and data migration tools.\n- Experience with Agile development methodologies and version control systems (e.g., Git).\n- Excellent problem-solving skills, with a keen attention to detail and the ability to work independently.\n\n\nLocation - Bengaluru,Chennai,Gurugram,Hyderabad,Noida,Pune",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['visualforce', 'soql', 'lightning components', 'ncino', 'salesforce', 'rest', 'version control', 'user interface designing', 'data migration', 'sales', 'apex', 'as', 'git', 'data modeling', 'salesforce integration', 'debugging', 'technical specifications', 'agile', 'digital transformation', 'soap']",2025-06-11 05:51:03
Senior SAP MM Functional Consultant,Sopra Steria,14 - 18 years,Not Disclosed,['Chennai'],"Role & responsibilities\nLead the workshop and identify the GAP\nShould be autonomous, able to challenge the Business, to orient the business on core solutions without customizations\nConfigure and customize the SAP MM module in alignment with client-specific needs\nLead full-cycle SAP MM implementation projects, including requirements gathering, design, testing, training, and post-implementation support.",,,,"['SAP MM', 'implementation', 'Hana Implementation', 'Sap Mm Hana', 'SAP MM Implementation']",2025-06-11 05:51:05
SAP SD/BP Consultant,"NTT DATA, Inc.",1 - 2 years,Not Disclosed,['Bengaluru'],"Req ID: 309527\n\nWe are currently seeking a SAP SD/BP Consultant to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\nJob\n8+ of Overall experience in SAP SD (Sales and Distribution processes) Implementations / Rollouts\n1 - 2 Yrs. of experience with S/4 HANA Implementations / Rollout experience\nSAP S/4 HANA data migration expertise in SAP Sales and Distribution Master / transaction data including Customer Master (BP), Routes, Route Determination, Pricing Conditions, Rebates, Customer Credit Data, Customer Material info-records etc.\nExperience with creating functional documentation for data migration field mapping, rules etc.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['sap sd', 'distribution', 'sap presales', 'sap s hana', 'sd', 'sap', 'lsmw', 'hana implementation', 'sap implementation', 'sap support', 'determination', 'sap ecc', 'data migration', 'sap sales and distribution', 'sales', 'sto', 'sap consulting', 'idocs', 'sap logistics', 'sap mm', 'sap hana', 'pricing', 'idoc']",2025-06-11 05:51:06
SAP eWM Functional Consultant,"NTT DATA, Inc.",3 - 8 years,Not Disclosed,['Bengaluru'],"Req ID: 322958\n\nWe are currently seeking a SAP eWM Functional Consultant to join our team in Bangalore, Karntaka (IN-KA), India (IN).\n\n SAP eWM Functional Consultant  \n Position Overview \n\nOur SAP Implementation eWM Functional Consultant will lead others through the implementation of SAP. Duties include but may not be limited to\nAbility to lead business workshops for blueprinting activities\nAnalyzing legacy data, quality check of submitted load files, testing load quality, leading user testing and acceptance of load process, providing input into specifications for automated data migration transformation rules, analysis and identification of duplicate records and other activities required for successful and on time data migration\nPerform high-level analysis of customer business processes and requirements to support project Data Migration requirements with proposed solutions\nPerform detailed analysis of customer requirements to produce custom solution specifications\nProvide direction to SAP BODS / ADM development teams for solution realization and participate, as necessary, during coding, testing, documentation, and maintenance activities\nWork closely with Data Migration team to document data migration requirements, on project planning and load scheduling, testing, troubleshooting, and issue resolution\n\n Job  \n8+ of Overall experience in SAP MM/WM/eWM Implementations / Rollouts\n3+ Yrs. of experience with S/4 HANA MM/WM/eWM Implementations / Rollout experience\nSAP S/4 HANA data migration expertise in SAP MM/WM/eWM Master / transaction data including Material Masters, Vendors (BP), Purchasing Info. Records, Source List, Storage Bins, Warehouse Product Master (EWM), Control Cycles (EWM), Handling Units, Material Inventory, Free Goods, Purchase Agreements etc.\nExperience with creating functional documentation for data migration field mapping, rules etc.\n\nNight shift will be from 3 PM to 12 AM IST with Work from home option unless otherwise mentioned",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['sap', 'sap s hana', 'wm', 'sap mm', 'ewm', 'software testing', 'warehouse management', 'warehouse operations', 'sap sd', 'sap implementation', 'logistics', 'warehouse', 'sap ewm', 'sap wms', 'sap wm', 'supply chain management', 'sap abap', 'sap hana', 'inventory management', 'oo abap']",2025-06-11 05:51:08
Lead Administrator - L2,Wipro,8 - 10 years,Not Disclosed,['Chennai'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Lead Administrator', 'troubleshooting', 'architecture planning', 'aws devops', 'root cause analysis', 'middleware']",2025-06-11 05:51:09
Lead Administrator - L2,Wipro,6 - 11 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Lead Administrator', 'talent management', 'service improvement', 'troubleshooting', 'root cause analysis', 'middleware']",2025-06-11 05:51:11
Lead Administrator - L2,Wipro,10 - 13 years,Not Disclosed,['Pune'],"Handled large database estates and managed TB size of databases Installation and administration of multiple versions of databases on multiple Unix platforms and Windows servers Design and implement the high availability solutions (RAC, Golden Gate and Dataguard) Install, configure and manage ASM instances in oracle Plan and execute major migrations and upgrades\nDefine and configure the disk and diskgroups in ASM and troubleshoot Manage and administer the databases on Exadata machine Plan the database upgrade, migration and patching Plan and implement the backup/recovery on need basis Hardware tech refresh (host to host database move) Coordinate and work with database vendors for resolution on major incidents Database refresh, re-org, backup using RMAN and 3rd party tools Install and configure grid control database monitoring tools Install, Administer, manage and troubleshoot Oracle grid control\nDefine performance benchmarks and metrics Periodic database instance performance review and tuning recommendation Proactive database analysis and suggestion to application team / business Write and troubleshoot shell scripting, SQL and PL/SQL scripts Primarily role is supporting the production and non-prod database environments Ensure the reduction of repeated errors through implementation of necessary checkpoints Contribute towards evaluation of tools, products and software selection SLA tracking and reporting to Higher management Prepare and Maintain Standard Operating Procedure for all activities\nProactive identification of risks and mitigation of the same Technical presentation on emerging technologies. Foresee the need for newer technology based trainings on customer needs and provide suggestions for such trainings to Project Manager.\nImplement and Periodical check on Automation Implement and Periodical check on DB Security Identify, document and track Technology related risks and mitigation plan in the project Technical and Process guidance to L2 and L1 DBA Provide 24x7 and on call support for critical application databases\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer Experience\nIdentification of risk issues and mitigation plans\nKnowledge management\n2New projectsTimely delivery\nAvoid unauthorised changes\nNo formal escalations\n\nMandatory Skills: Oracle Database Admin.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Oracle Database Administration', 'Team Management', 'SQL and PL/SQL', 'Oracle RMAN', 'Oracle Golden Gate', 'Oracle RAC', 'middleware']",2025-06-11 05:51:12
Informatica Admin,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Informatica Admin', 'troubleshooting', 'architecture planning', 'informatica', 'root cause analysis', 'middleware']",2025-06-11 05:51:14
Oracle Goldengate DBA,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Oracle', 'oracle database', 'oracle dba', 'troubleshooting', 'root cause analysis', 'middleware']",2025-06-11 05:51:16
Systems Integration Advisor,"NTT DATA, Inc.",5 - 8 years,Not Disclosed,['Noida'],"Req ID: 324412\n\nWe are currently seeking a Systems Integration Advisor to join our team in Noida, Uttar Pradesh (IN-UP), India (IN).\n\nPosition Summary:\nPerforms IT functions such as design, analysis, evaluation, testing, installation, acquisition, modification and support of operating systems, database, or software. Plans, conducts, and directs the analysis of business problems to be solved with troubleshooting and automated systems. This position operates with minimal direction and requires a professional who can take ownership over their work.\n\nThis position is in support of the Core Services team in Corporate IT at Enlyte. Core Services includes the management of Active Directory, Microsoft Azure, Exchange O365, DNS, Microsoft Teams, SharePoint, OneDrive, and Identity and Access Management for corporate colleagues and contractors.\n\nMust Have skills\n\n1) Must have experience on Windows Active Directory\n\n2) Must have work experience on collpasing domains\n\n3) Must have experience of scheduled/ regular maintainence and Patching\n\n4) Must have exposure AD auditing\n\n5) Work Epxerience with SSSD integration skills\n\n6) Progressive experience with MS Windows uptill Windows 2019, 2022 exposure preferred\n\n7) Migration of AD from OnPrem to Cloud (Azure/ AWS)\n\n8) Work Experience with ADMT tool and good to have with Quest Migration tool\n\nRequired Experience:\n\n5-8 years of experience with Active Directory administration\n\n5-8 years of experience with Domain Name Service (DNS), including zone management\n\n5-8 years of experience with Windows PowerShell, with ability to develop scripts as needed\n\n5-8 years of experience with Microsoft Azure AD (now Entra ID)\n\n5-8 years of experience with Microsoft Exchange and Exchange O365\n\n5-8 years of experience with Mergers & Acquisitions involving Active Directory and Azure\n\n5-8 years of experience working in GxP or other regulated environments\n\n5-8 years of experience with documentation for systems management\n\n1-3 years of experience with SharePoint for O365, Teams, and OneDrive administration\n\n1-3 years of experience with Identity and Access Management, and Identity Governance\n\n1-3 years of experience with Amazon Web Services (AWS) IAM a plus\n\nRequired Education:\n\nAssociates Degree in Computer Science or equivalent. Bachelor""™s degree a plus.\n\nAssociated certificates in the above technologies a plus\n\nPrimary:\nWindows Server 2008 - 2022 (10 years)\nActive Directory (10 years) DNS (6 years+)\nLinux Server (4 years+)\nPowerShell (2 years+)\nMicrosoft Azure (2 years+)\nADMT (2 years+)\n\nGood To have skills\n\nQuest Migration Tools\nAWS Cloud\nRoute 53 Crowdstrike\nNetwrix",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['windows active directory', 'auditing', 'sharepoint', 'patching', 'onedrive', 'linux server', 'dns', 'microsoft azure', 'access management', 'mergers', 'identity access management', 'system administration', 'powershell', 'ms exchange', 'acquisition', 'active directory administration', 'aws', 'gxp']",2025-06-11 05:51:18
BODS Developer,"NTT DATA, Inc.",4 - 6 years,Not Disclosed,['Hyderabad'],"Req ID: 320660\n\nWe are currently seeking a BODS Developer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\nJob\n4-6 Yrs. of overall technical experience in SAP BODS with all the SAP BODS application modules (Extract, Transform, Load)\n2-4 Yrs. of experience with Data Migration experience with S/4 HANA/ECC Implementations\nExperience in BODS Designer Components- Projects, Jobs, Workflow, Data Flow, Scripts, Data Stores and Formats\nExperience in BODS performance tuning techniques using parallel processing (Degree of Parallelism), Multithreading, Partitioning, and Database Throughputs to improve job performance\nExperience in ETL using SAP BODS and SAP IS with respect to SAP Master / Transaction Data Objects in SAP FICO, SAP SD, SAP MM/WM, SAP Plant Maintenance, SAP Quality Management etc. is desirable\nExperience with Data Migration using LSMW, IDOCS, LTMC\nAbility to Debug LTMC errors is highly desirable",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data migration', 'wm', 'sap mm', 'sap', 'sap bods', 'fico', 'lsmw', 'ecc', 'sap sd', 'sap mm wm', 'sql', 'plsql', 'sap s hana', 'sap production planning', 'idocs', 'sap fico', 'multithreading', 'sap quality management', 'etl', 'sap qm', 'performance tuning', 'triggers', 'bods', 'sap pp', 'sap plant maintenance']",2025-06-11 05:51:19
Enterprise Resource Planning Advisor,"NTT DATA, Inc.",12 - 17 years,Not Disclosed,['Chennai'],"Req ID: 303369\n\nWe are currently seeking a Enterprise Resource Planning Advisor to join our team in Chennai, Tamil Ndu (IN-TN), India (IN).\n\nHas more than 12 years of relevant experience with Oracle ERP Cloud Data migration and minimum 4 end to end ERP cloud implementation.\n\n\n\nAnalyze Data and Mapping Work with functional teams to understand data requirements and develop mappings to enable smooth migration using FBDI (File-Based Data Import) and ADFdi.\n\n\n\nDevelop and Manage FBDI Templates Design, customize, and manage FBDI templates to facilitate data import into Oracle SaaS applications, ensuring data structure compatibility and completeness.\n\n\n\nConfigure ADFdi for Data Uploads Use ADFdi (Application Development Framework Desktop Integration) for interactive data uploads, enabling users to manipulate and validate data directly within Excel.\n\n\n\nData Validation and Quality Checks Implement data validation rules and perform pre- and post-load checks to maintain data integrity and quality, reducing errors during migration.\n\n\n\nExecute and Troubleshoot Data Loads Run data loads, monitor progress, troubleshoot errors, and optimize performance during the data migration process.\n\n\n\nCollaborate with Stakeholders Coordinate with cross-functional teams, including project managers and business analysts, to align on timelines, resolve data issues, and provide migration status updates.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['project management', 'sql', 'oracle erp', 'cloud data migration', 'erp cloud', 'snowflake', 'python', 'erp', 'oracle', 'oic', 'erp implementation', 'data warehousing', 'microsoft azure', 'oracle fusion', 'plsql', 'data modeling', 'hadoop', 'agile', 'big data', 'aws', 'informatica', 'unix', 'oracle apps']",2025-06-11 05:51:21
Digital Consultant - Innovation Group,"NTT DATA, Inc.",18 - 23 years,Not Disclosed,['Pune'],"Req ID: 317103\n\nWe are currently seeking a Digital Consultant - Innovation Group to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nJob DutiesWe are seeking a highly skilled and experienced Digital Consultant to join our Innovation Group. The ideal candidate will have a strong background in Big Data, Cloud, and AI/ML projects, with a focus on the health insurance or retail domains or manufacturing domains. This role involves engaging with clients for architecture and design, building accelerators for cloud migration, and developing innovative solutions using GenAI technologies.\nKey Responsibilities:\n""¢ Engage with clients to understand their requirements and provide architectural and design solutions.\n""¢ Develop and implement accelerators to facilitate faster cloud migration.\n""¢ Create innovative use cases or solutions to solve day to day data engineering problems using AI and GenAI tools.\n""¢ Develop reference architectures for various use cases using modern cloud data platforms.\n""¢ Understanding of Legacy toolsets, be it ETL, reporting etc is needed.\n""¢ Create migration suites for cataloging, migrating, and verifying data from legacy systems to modern platforms like Databricks and Snowflake.\n\nMinimum Skills RequiredQualifications:\n""¢ EducationB.E. in Electronics & Telecommunication or related field.\n""¢ Experience18+ years in IT, with significant experience in Big Data, Cloud, and AI/ML projects.\n""¢ Technical\n\nSkills:\nProficiency in Databricks, Snowflake, AWS, GenAI (RAG and GANs), Python, C/C++/C",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['c++', 'big data', 'snowflake', 'python', 'aws', 'legacy', 'web services', 'soa', 'as400', 'data migration', 'artificial intelligence', 'retail', 'java', 'ms office outlook', 'etl', 'ml', 'mainframes', 'project management', 'erp', 'c', 'sap', 'sql server', 'data bricks', 'as', 'cobol', 'web technologies']",2025-06-11 05:51:23
BODS Developer,"NTT DATA, Inc.",4 - 6 years,Not Disclosed,['Hyderabad'],"Req ID: 322971\n\nWe are currently seeking a BODS Developer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n SAP BODS Developer  \n Position Overview \nUnderstand and execute data migration blueprints (migration concepts, transformation rules, mappings, selection criteria)\nUnderstand and contribute to the documentation of the data mapping specifications, conversion rules, technical design specifications as required\nBuild the conversion processes and associated programs that will migrate the data per the design and conversion rules that have been signed-off by the client\nExecution of all data migration technical steps (extract, transform & load) as well as Defect Management and Issue Resolution\nPerform data load activities for each mock load, cutover simulation and production deployment identified in L1 plan into environments identified\nProvide technical support, defect management, and issue resolution during all testing cycles, including Mock Data Load cycles\nComplete all necessary data migration documentation necessary to support system validation / compliance requirements\nSupport the development of unit and end-to-end data migration test plans and test scripts (including testing for data extraction, transformation, data loading, and data validation)\n\n Job  \n4-6 Yrs. of overall technical experience in SAP BODS with all the SAP BODS application modules (Extract, Transform, Load)\n2-4 Yrs. of experience with Data Migration experience with S/4 HANA/ECC Implementations\nExperience in BODS Designer Components- Projects, Jobs, Workflow, Data Flow, Scripts, Data Stores and Formats\nExperience in BODS performance tuning techniques using parallel processing (Degree of Parallelism), Multithreading, Partitioning, and Database Throughputs to improve job performance\nExperience in ETL using SAP BODS and SAP IS with respect to SAP Master / Transaction Data Objects in SAP FICO, SAP SD, SAP MM/WM, SAP Plant Maintenance, SAP Quality Management etc. is desirable\nExperience with Data Migration using LSMW, IDOCS, LTMC\nAbility to Debug LTMC errors is highly desirable\nNight shift will be from 3 PM to 12 AM IST with Work from home option unless otherwise mentioned.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data migration', 'sap mm wm', 'wm', 'sap mm', 'sap bods', 'fico', 'lsmw', 'simulation', 'warehouse management', 'sap sd', 'test scripts', 'data mapping', 'sql', 'sap s hana', 'idocs', 'data extraction', 'data loader', 'sap fico', 'multithreading', 'etl', 'sap', 'performance tuning', 'technical design', 'bods', 'as']",2025-06-11 05:51:24
Oracle Cloud PLM Functional consultant,"NTT DATA, Inc.",8 - 13 years,Not Disclosed,['Hyderabad'],"Req ID: 324283\n\nWe are currently seeking a Oracle Cloud PLM Functional consultant to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n\nAbout the role\n\n\n\nFunctional consultant with 8+ years""™ experience in Oracle Cloud PLM .\n\n\n\n\nResponsibilities\nImplementation and IntegrationLead the deployment and integration of Oracle Cloud PLM modules - PD (Product Development) and PDH (Product Data Hub), ensuring alignment with business processes.\n\n\nFacilitate Business Process workshop sessions for Key Stakeholders and Business Users high\n\n\nRequirement and Fit Gap AnalysisGather requirements to understand client needs and propose solutions/workarounds to translate them to design for implementation\n\n\nConfiguration and CustomizationOversee the configuration and customization of the PLM module.\n\n\nProject ManagementDevelop and manage project plans, timelines, and deliverables.\n\n\nTraining and DocumentationFacilitate training sessions and create detailed documentation for end-users.\n\n\n\n\n\n\n\n\n\n\nSkillset requirements\n\n\nStrong expertise in Oracle Cloud PLM and Agile PLM functional consulting.\nProficiency in PL/SQL reporting for Oracle Cloud.\nDeep understanding of Oracle Cloud database tables and structure.\nExperience with data loads into Oracle Cloud using FBDI (File-Based Data Import).\nProven experience in PD (Product Development) and PDH (Product Data Hub) modules.\nHands-on experience with data migration across Oracle Cloud PLM and Agile PLM environments.\nExcellent analytical, problem-solving, and communication skills.\nAbility to collaborate with both technical and business teams effectively.\nA results-driven and proactive approach with a track record of successful project delivery.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['oracle cloud', 'agile plm', 'sql', 'plsql', 'plm', 'oracle order management', 'oracle', 'order management', 'iprocurement', 'data migration', 'oracle scm', 'oracle e-business suite', 'fbdi', 'inv', 'product data hub', 'oracle apps functional', 'r12', 'oracle purchasing', 'pdh', 'om', 'oracle apps']",2025-06-11 05:51:26
YASH Technologies is Hiring - SAP Plant Maintenance,Yash Technologies,8 - 10 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Our SAP service line is currently looking for an industry-leading SAP Plant Maintenance\nPlease go through below JD and if have the required please share your updated resume to discuss further to me at shubham.satav@yash.com\nOnsite Business travel required to Middle East Iraq as per business need.\n\nRequired Skills - SAP Plant Maintenance, S4 HANA, implementation\nLocation Hyderabad,\nWork model Hybrid.",,,,"['SAP Plant Maintenance', 'S4 HANA', 'Implementation']",2025-06-11 05:51:28
Digital Engineering Lead Engineer,"NTT DATA, Inc.",2 - 4 years,Not Disclosed,['Hyderabad'],"\n Jr SAP BODS Developer  \n Position Overview \nUnderstand and execute data migration blueprints (migration concepts, transformation rules, mappings, selection criteria)\nUnderstand and contribute to the documentation of the data mapping specifications, conversion rules, technical design specifications as required\nBuild the conversion processes and associated programs that will migrate the data per the design and conversion rules that have been signed-off by the client\nExecution of all data migration technical steps (extract, transform & load) as well as Defect Management and Issue Resolution\nPerform data load activities for each mock load, cutover simulation and production deployment identified in L1 plan into environments identified\nProvide technical support, defect management, and issue resolution during all testing cycles, including Mock Data Load cycles\nComplete all necessary data migration documentation necessary to support system validation / compliance requirements\nSupport the development of unit and end-to-end data migration test plans and test scripts (including testing for data extraction, transformation, data loading, and data validation)\n\n Job  \n2-4 Yrs. of overall technical experience in SAP BODS with all the SAP BODS application modules (Extract, Transform, Load)\n1-2 Yrs. of experience with Data Migration experience with S/4 HANA/ECC Implementations\nExperience in BODS Designer Components- Projects, Jobs, Workflow, Data Flow, Scripts, Data Stores and Formats\nExperience in BODS performance tuning techniques using parallel processing (Degree of Parallelism), Multithreading, Partitioning, and Database Throughputs to improve job performance\nExperience in ETL using SAP BODS and SAP IS with respect to SAP Master / Transaction Data Objects in SAP FICO, SAP SD, SAP MM/WM, SAP Plant Maintenance, SAP Quality Management etc. is desirable\nExperience with Data Migration using LSMW, IDOCS, LTMC\nNight shift will be from 3 PM to 12 AM IST with Work from home option unless otherwise mentioned.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['data migration', 'sap mm wm', 'wm', 'sap mm', 'sap bods', 'lsmw', 'warehouse management', 'sap sd', 'apex', 'sap s hana', 'salesforce', 'sap production planning', 'idocs', 'sap wm', 'sap fico', 'sap quality management', 'etl', 'sap hana', 'sap qm', 'sap', 'triggers', 'bods', 'sap pp', 'sap plant maintenance', 'sap pm']",2025-06-11 05:51:29
Sales and CPQ developer,"NTT DATA, Inc.",4 - 9 years,Not Disclosed,['New Delhi'],"Req ID: 323395\n\nWe are currently seeking a Sales and CPQ developer to join our team in Remote, Delhi (IN-DL), India (IN).\n\nBasic Qualifications—4+ years of Salesforce consulting experience\n\n\n\n— 4 years within CPQ and sales cloud space (i.e., 2+ years in Salesforce CPQ implementation, Additional 3+ years""™ experience in other CPQ platforms)\n\n— 2+ years Salesforce CPQ implementations\n\n— Proven experience implementing CPQ solutions including enterprise architecture, leading a team through ERP integration, & understanding of down-stream processes such as billing, provisioning, etc.\n\n— Salesforce CPQ and sales cloud Specialist Certification\n\nPreferred Qualifications:\n\n— 4+ years CPQ and sales cloud end to end project implementations\n\n— Experience with Salesforce administration, configuration, & tools like process builder\n\n— Experience with RESTful Service Architecture & CPQ API""™s & QCP (quote calculator plug-in) is a plus\n\n— Experience with CPQ deployment tools such as Prodly\n\n— Strong CPQ configuration experience and system administration\n\n""¢ Troubleshoot and resolve CPQ-related issues, including pricing, discounts, and product configuration logic.\n\n— Strong functional knowledge of OOTB Capabilities\n\n— Strong knowledge of designing Architecture Diagrams and Data flows\n\n— Strong problem-solving skills\n\n— Knowledge of End-to-End Order Management lifecycle\n\n— Knowledge of Agile methodologies and understanding of software development process\n\n— Knowledge of lightning web components & how to address UI/UX requirements effectively when deploying CPQ to channel/distributors/partners\n\n— Well-versed with Salesforce security model and Communities experience is a plus\n\n— In depth understanding of CPQ architecture (Data, Logic Layers, Data Layers), data models, customizations & extensions\n\n— Excellent verbal and written communication skills with ability to tailor messaging to audience —\n\nCapable of recommending best practice solutions based on project and business needs and owning overall design of the technical application\n\n— Hands on experience on Salesforce Data Loader\n\n— Sales Cloud Certification, Salesforce Administrator Certification, App Builder —\n\nTechnical skills related to Apex and other languages is appreciated but not a requirement\n\nSkills\nSalesforce CPQ Apex Visualforce\nSOQL\nREST/SOAP APIs\nJavaScript\nSalesforce Lightning\nData Migration""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['cognos architecture', 'cpq', 'system administration', 'data modeling', 'data flow', 'visualforce', 'rest', 'soql', 'project implementation', 'distribution', 'salesforce security model', 'salesforce cpq', 'sales', 'javascript', 'apex', 'salesforce', 'ootb', 'salesforce administration', 'agile', 'soap']",2025-06-11 05:51:31
Salesforce sales CPQ Developer,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['New Delhi'],"Req ID: 323389\n\nWe are currently seeking a Salesforce sales CPQ Developer to join our team in Remote, Delhi (IN-DL), India (IN).\n\nBasic Qualifications— 5+ years of Salesforce consulting experience\n\n— 5+ years within CPQ and sales cloud space (i.e., 2+ years in Salesforce CPQ implementation, Additional 3+ years""™ experience in other CPQ platforms)\n\n— 3+ years Salesforce CPQ implementations as a solution lead\n\n— Proven experience implementing CPQ solutions including enterprise architecture, leading a team through ERP integration, & understanding of down-stream processes such as billing, provisioning, etc.\n\n— Salesforce CPQ Specialist and sales Cloud Certification\n\n— Ability to guide software developers (code development)\n\n\n\nPreferred Qualifications:\n\n— 5+ CPQ end to end project implementations\n\n— Experience with Salesforce administration, configuration, & tools like process builder\n\nWorking experience and salesand CPQ cloud projects\n\n— Experience with RESTful Service Architecture & CPQ API""™s & QCP (quote calculator plug-in) is a plus\n\n— Experience with CPQ deployment tools such as Prodly\n\n— Strong CPQ configuration experience and system administration\n\n""¢ Troubleshoot and resolve CPQ-related issues, including pricing, discounts, and product configuration logic.\n\n— Strong functional knowledge of OOTB Capabilities\n\n— Strong knowledge of designing Architecture Diagrams and Data flows\n\n— Strong problem-solving skills\n\n— Knowledge of End-to-End Order Management lifecycle\n\n— Knowledge of Agile methodologies and understanding of software development process\n\n— Knowledge of lightning web components & how to address UI/UX requirements effectively when deploying CPQ to channel/distributors/partners\n\n— Well-versed with Salesforce security model and Communities experience is a plus\n\n— In depth understanding of CPQ architecture (Data, Logic Layers, Data Layers), data models, customizations & extensions\n\n— Excellent verbal and written communication skills with ability to tailor messaging to audience —\n\nCapable of recommending best practice solutions based on project and business needs and owning overall design of the technical application\n\n— Hands on experience on Salesforce Data Loader\n\n— Sales Cloud Certification, Salesforce Administrator Certification, App Builder —\n\nTechnical skills related to Apex and other languages is appreciated but not a requirement\n\nSkills\nSalesforce CPQ\nApex\nVisualforce\nSOQL\nREST/SOAP APIs\nJavaScript\nSalesforce Lightning\nData Migration""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['cognos architecture', 'cpq', 'system administration', 'data modeling', 'data flow', 'visualforce', 'rest', 'soql', 'salesforce lightning', 'cognos', 'salesforce security model', 'salesforce cpq', 'sales', 'javascript', 'apex', 'salesforce', 'ootb', 'salesforce administration', 'agile', 'soap']",2025-06-11 05:51:33
Digital Engineering Lead Engineer,"NTT DATA, Inc.",6 - 8 years,Not Disclosed,['Hyderabad'],"Req ID: 315127\n\nWe are currently seeking a Digital Engineering Lead Engineer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n Sr SAP BODS Developer ""“ Track Lead  \n Position Overview \nUnderstand and execute data migration blueprints (migration concepts, transformation rules, mappings, selection criteria)\nUnderstand and contribute to the documentation of the data mapping specifications, conversion rules, technical design specifications as required\nBuild the conversion processes and associated programs that will migrate the data per the design and conversion rules that have been signed-off by the client\nExecution of all data migration technical steps (extract, transform & load) as well as Defect Management and Issue Resolution\nPerform data load activities for each mock load, cutover simulation and production deployment identified in L1 plan into environments identified\nProvide technical support, defect management, and issue resolution during all testing cycles, including Mock Data Load cycles\nComplete all necessary data migration documentation necessary to support system validation / compliance requirements\nSupport the development of unit and end-to-end data migration test plans and test scripts (including testing for data extraction, transformation, data loading, and data validation)\n\n Job  \n6-8 Yrs. of overall technical experience in SAP BODS with all the SAP BODS application modules (Extract, Transform, Load)\n5+ Yrs. of experience with Data Migration experience with S/4 HANA/ECC Implementations\nExperience in BODS Designer Components- Projects, Jobs, Workflow, Data Flow, Scripts, Data Stores and Formats\nExperience in BODS performance tuning techniques using parallel processing (Degree of Parallelism), Multithreading, Partitioning, and Database Throughputs to improve job performance\nExtensive experience in ETL using SAP BODS and SAP IS with respect to SAP Master / Transaction Data Objects in SAP FICO, SAP SD, SAP MM/WM, SAP Plant Maintenance, SAP Quality Management etc. is desirable\nExperience with Data Migration using LSMW, IDOCS, LTMC\nNight shift will be from 3 PM to 12 AM IST with Work from home option unless otherwise mentioned.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sap bods', 'data migration', 'wm', 'sap mm', 'etl', 'sap', 'lsmw', 'warehouse management', 'sap sd', 'purchase', 'logistics', 'sap mm wm', 'sap s hana', 'sap mm module', 'bods', 'idocs', 'sap wm', 'material management', 'sap mm implementation', 'procurement', 'sap fico', 'sap hana', 'inventory management']",2025-06-11 05:51:34
nCino Developer,"NTT DATA, Inc.",8 - 13 years,Not Disclosed,['Noida'],"Req ID: 312203\n\nWe are currently seeking a nCino Developer to join our team in Noida, Uttar Pradesh (IN-UP), India (IN).\n\nJob TitlenCino/Salesforce Developer\n\nSummary:\nAre you passionate about transforming the banking and financial services landscape through cutting-edge technologyAs an nCino/Salesforce Developer, you will play a pivotal role in our digital transformation journey, leveraging your expertise to design, develop, and implement solutions that optimize our workflows and enhance client experiences. You will work closely with a collaborative team of professionals who are committed to leveraging the nCino platform/Salesforce to drive operational excellence and deliver innovative solutions. Join us in shaping the future of our organization while advancing your career in a dynamic and supportive environment!\n\nDetailed Responsibilities:\n- Design, develop, and implement robust nCino/Salesforce applications tailored to enhance business operations and user experience.\n- Collaborate with stakeholders to gather requirements, translate them into technical specifications, and provide innovative solutions that meet business needs.\n- Customize Salesforce and nCino functionality, including but not limited to data modeling, user interface design, and workflow automation.\n- Conduct thorough testing and debugging of applications to ensure high performance, security, and reliability.\n- Perform ongoing maintenance and enhancements for existing nCino and Salesforce applications, ensuring they stay current with evolving internal processes and industry standards.\n- Stay updated with the latest industry trends, nCino development best practices, and Salesforce features to continuously improve our platforms.\n- Provide training and support to end-users, promoting effective utilization and adoption of nCino and Salesforce applications across teams.\n- Collaborate with cross-functional teams, including business analysts, project managers, and UI/UX designers, to ensure seamless project execution and delivery.\n\nMust-Have Qualifications:\n- Min. 8+ years of overall experience in IT.\n\n- nCino experience is a must.\n- Proven experience as a Salesforce Developer with hands-on experience in nCino development and customization.\n- Strong proficiency in Salesforce Apex, Visualforce, Lightning components, and SOQL, as well as nCino""™s capabilities and functionalities.\n- Familiarity with Salesforce integrations, REST/SOAP APIs, and data migration tools.\n- Experience with Agile development methodologies and version control systems (e.g., Git).\n- Excellent problem-solving skills, with a keen attention to detail and the ability to work independently.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['visualforce', 'soql', 'lightning components', 'ncino', 'salesforce', 'rest', 'version control', 'user interface designing', 'data migration', 'sales', 'apex', 'as', 'git', 'data modeling', 'salesforce integration', 'debugging', 'technical specifications', 'agile', 'digital transformation', 'soap']",2025-06-11 05:51:36
Salesforce Developer,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['Hyderabad'],"Req ID: 316214\n\nWe are currently seeking a Salesforce Developer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\nWhy the Role Is Important:\nOur Developers are fundamental to ensuring the digital technology and related services that NTT DATA builds for our clients are valuable, intuitive, and impactful. The work of Salesforce Developers provides our clients and team with support, leadership, and direction to make sure projects are executed well and to deliver the engagement as promised.\nOnce You Are Here, You Will:\n""¢ Perform development, testing, implementation, documentation within the SalesForce.com platform\n""¢ Salesforce developer resource who will support dashboarding, data analysis and visualization needs for the team.\n""¢ Develop and maintain Lightening Web Components, Visualforce, Apex, and integrations to other third-party solutions\n""¢ Act as the first point of escalation for daily service issues along with PM and be a primary point of contact for Stakeholders\n""¢ Prepare/Review Test Scripts and Unit testing of changes\n""¢ Provide training, support, and leadership to the larger project team\n""¢ Develop Apex Class and Visual force pages in compliance with Salesforce.com recommended standards\n""¢ Develop Apex Test classes with a minimum of 90% coverage as all functionalities and bulk operations might be validated.\n""¢ Force.com""Apex, Visualforce, Triggers, SOQL, SOSL, API, Flows, LWC, Web Services (SOAP & REST)Sales Cloud, LWC, Javascript, CSS, Salesforce Packages, Jenkins, Agile methodology, CI/CD""\n\nRequired Qualifications:\n""¢ 5+ years""™ experience in a Salesforce consulting role that include completing at least 5 projects in a development role\n""¢ Salesforce Platform Developer II Certification\n""¢ Salesforce Certified Platform Developer-I\n""¢ Salesforce Certified App Builder\n""¢ Familiarity with Ja vascript, CSS, Splunk Analytics\n\n""¢ 5 years+ experience developing custom business logic in APEX, writing test classes, creating Lightning Web Components, Visualforce Pages and Triggers\n""¢ 5 Years+ experience in SFDC Developing custom business logic in Apex, creating Lightning Web Components, Visualforce Pages, and Triggers\n\nPreferred Experience:\n""¢ Prior experience with a software development methodology, Agile\n""¢ Knowledge of Reports & Dashboards, SOQL & SOSL\n""¢ Knowledge of Lightning Application on Aura Framework\n""¢ Knowledge with Providing Security controllers to users by using Profiles, Roles, Permission sets and OWD Setting\n""¢ Experience with data migration using Data Loader",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sosl', 'soql', 'aura framework', 'dashboards', 'reports and dashboards', 'visualforce', 'sfdc development', 'css', 'salesforce lightning', 'sfdc', 'javascript', 'apex', 'salesforce', 'sales force development', 'data loader', 'business logic', 'splunk', 'lwc', 'agile', 'visualforce pages', 'app builder']",2025-06-11 05:51:38
SAP SD/BP Consultant,"NTT DATA, Inc.",1 - 2 years,Not Disclosed,['Hyderabad'],"Req ID: 309749\n\nWe are currently seeking a SAP SD/BP Consultant to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\nOur SAP Implementation SD Functional Consultant will lead others through the implementation of SAP. Duties include but may not be limited to\nAbility to lead business workshops for blueprinting activities\nAnalyzing legacy data, quality check of submitted load files, testing load quality, leading user testing and acceptance of load process, providing input into specifications for automated data migration transformation rules, analysis and identification of duplicate records and other activities required for successful and on time data migration\nPerform high-level analysis of customer business processes and requirements to support project Data Migration requirements with proposed solutions\nPerform detailed analysis of customer requirements to produce custom solution specifications\nProvide direction to SAP BODS / ADM development teams for solution realization and participate, as necessary, during coding, testing, documentation, and maintenance activities\nWork closely with Data Migration team to document data migration requirements, on project planning and load scheduling, testing, troubleshooting, and issue resolution\n\n Job  \n8+ of Overall experience in SAP SD (Sales and Distribution processes) Implementations / Rollouts\n1 - 2 Yrs. of experience with S/4 HANA Implementations / Rollout experience\nSAP S/4 HANA data migration expertise in SAP Sales and Distribution Master / transaction data including Customer Master (BP), Routes, Route Determination, Pricing Conditions, Rebates, Customer Credit Data, Customer Material info-records etc.\nExperience with creating functional documentation for data migration field mapping, rules etc.\nNight shift will be from 3 PM to 12 AM IST with work from office on rotational basis",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['sap', 'sap sd', 'distribution', 'sap presales', 'sap s hana', 'software testing', 'hana implementation', 'sap bods', 'sap implementation', 'sap support', 'determination', 'data migration', 'sap sales and distribution', 'sales', 'sd', 'sap consulting', 'bods', 'sap fico', 'sap mm', 'sap hana', 'pricing', 'idoc']",2025-06-11 05:51:40
Agentforce Developer,"NTT DATA, Inc.",5 - 10 years,Not Disclosed,['Hyderabad'],"Req ID: 321100\n\nWe are currently seeking a Agentforce Developer to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\nWhy the Role Is Important:\nOur Developers are fundamental to ensuring the digital technology and related services that NTT DATA builds for our clients are valuable, intuitive, and impactful. The work of Salesforce Developers provides our clients and team with support, leadership, and direction to make sure projects are executed well and to deliver the engagement as promised.\nOnce You Are Here, You Will:\n""¢ Perform development, testing, implementation, documentation within the SalesForce.com platform\n""¢ Salesforce developer resource who will support dashboarding, data analysis and visualization needs for the team.\n""¢ Develop and maintain Lightening Web Components, Visualforce, Apex, and integrations to other third-party solutions\n""¢ Act as the first point of escalation for daily service issues along with PM and be a primary point of contact for Stakeholders\n""¢ Prepare/Review Test Scripts and Unit testing of changes\n""¢ Provide training, support, and leadership to the larger project team\n""¢ Develop Apex Class and Visual force pages in compliance with Salesforce.com recommended standards\n""¢ Develop Apex Test classes with a minimum of 90% coverage as all functionalities and bulk operations might be validated.\n""¢ Force.com""Apex, Visualforce, Triggers, SOQL, SOSL, API, Flows, LWC, Web Services (SOAP & REST)Sales Cloud, LWC, Javascript, CSS, Salesforce Packages, Jenkins, Agile methodology, CI/CD""\n\nRequired Qualifications:\n""¢ 5+ years""™ experience in a Salesforce consulting role that include completing at least 5 projects in a development role\n""¢ Salesforce Platform Developer II Certification\n""¢ Salesforce Certified Platform Developer-I\n""¢ Salesforce Certified App Builder\n""¢ Familiarity with Ja vascript, CSS, Splunk Analytics\n\n""¢ 5 years+ experience developing custom business logic in APEX, writing test classes, creating Lightning Web Components, Visualforce Pages and Triggers\n""¢ 5 Years+ experience in SFDC Developing custom business logic in Apex, creating Lightning Web Components, Visualforce Pages, and Triggers\n\nPreferred Experience:\n""¢ Prior experience with a software development methodology, Agile\n""¢ Knowledge of Reports & Dashboards, SOQL & SOSL\n""¢ Knowledge of Lightning Application on Aura Framework\n""¢ Knowledge with Providing Security controllers to users by using Profiles, Roles, Permission sets and OWD Setting\n""¢ Experience with data migration using Data Loader",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['sosl', 'soql', 'aura framework', 'dashboards', 'reports and dashboards', 'visualforce', 'continuous integration', 'rest', 'sfdc development', 'css', 'salesforce lightning', 'sfdc', 'ci/cd', 'javascript', 'apex', 'salesforce', 'data loader', 'business logic', 'splunk', 'agile', 'visualforce pages', 'soap']",2025-06-11 05:51:41
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:43
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:44
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:46
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Kochi'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:47
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Chennai'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:49
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:50
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Mumbai'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:52
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['database migration', 'Knowledge management', 'Performance Management', 'Talent Management', 'disaster recovery', 'middleware']",2025-06-11 05:51:54
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['database migration', 'Knowledge management', 'Performance Management', 'Talent Management', 'disaster recovery', 'middleware']",2025-06-11 05:51:55
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Mumbai'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:51:57
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Mumbai'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['database migration', 'Knowledge management', 'Performance Management', 'Talent Management', 'disaster recovery', 'middleware']",2025-06-11 05:51:59
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:00
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Coimbatore'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['database migration', 'Knowledge management', 'Performance Management', 'Talent Management', 'disaster recovery', 'middleware']",2025-06-11 05:52:02
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Kochi'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:03
Lead Administrator - L2,Wipro,8 - 10 years,Not Disclosed,['Mumbai'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:05
Lead Administrator - L2,Wipro,8 - 10 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\n\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:07
Oracle Cloud PLM Technical consultant,"NTT DATA, Inc.",8 - 13 years,Not Disclosed,['Hyderabad'],"Req ID: 324284\n\nWe are currently seeking a Oracle Cloud PLM Technical consultant to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n\nAbout the role\n\n\n\nTechnical consultant with 8+ years""™ experience in Oracle Cloud PLM .\n\n\n\n\nResponsibilities\nImplementation and IntegrationLead the deployment and integration of Oracle Cloud PLM modules - PD (Product Development) and PDH (Product Data Hub), ensuring alignment with business processes.\n\n\nRequirement AnalysisGather requirements to understand client needs.\n\n\nConfiguration and CustomizationOversee the configuration and customization of the PLM module.\n\n\nData Migration Support ""“ Generation of FBDI files from Custom Tables, different Data Sources/PLM""™s. Programming expertise for extraction , Validation, cleanup of Data for migration.\n\n\n\n\n\n\n\n\n\n\n\n\nSkillset requirements\n\n\nExpertise in Oracle Cloud PLM and Agile PLM Technical aspects.\nStrong programming skills - expertise in Groovy script (Example Validation rules, Triggers, Object functions).\nExpertise on Integrating Oracle PLM Cloud with External Systems using Webservices, OCI etc.\nProgramming Expertise (Java etc.) for supporting Data Extraction, Cleanup, Validation, Transformation etc.\nMake application changes using Application Composer\nConfiguring objects\nProficiency in PL/SQL reporting for Oracle Cloud.\nDeep understanding of Oracle Cloud database tables and structure.\nExperience with data loads into Oracle Cloud using FBDI (File-Based Data Import).\nProven experience in PD (Product Development) and PDH (Product Data Hub) modules.\nHands-on experience with data migration across Oracle Cloud PLM and Agile PLM environments.\nExcellent analytical, problem-solving, and communication skills.\nAbility to collaborate with both technical and business teams effectively.\nA results-driven and proactive approach with a track record of successful project delivery.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['groovy scripting', 'sql', 'oracle', 'oracle cloud', 'plm', 'web services', 'jsp', 'oracle apps technical', 'oracle fusion', 'plsql', 'spring', 'java', 'xml', 'aspect', 'j2ee', 'html', 'xml publisher reports', 'rest', 'bi publisher', 'rice components', 'otm', 'agile plm', 'fbdi', 'javascript', 'data hub', 'pdh', 'aws', 'soap']",2025-06-11 05:52:09
Sales and CPQ developer,"NTT DATA, Inc.",4 - 9 years,Not Disclosed,['Pune'],"Req ID: 323394\n\nWe are currently seeking a Sales and CPQ developer to join our team in Pune, Mahrshtra (IN-MH), India (IN).\n\nBasic Qualifications—4+ years of Salesforce consulting experience\n\n\n\n— 4 years within CPQ and sales cloud space (i.e., 2+ years in Salesforce CPQ implementation, Additional 3+ years""™ experience in other CPQ platforms)\n\n— 2+ years Salesforce CPQ implementations\n\n— Proven experience implementing CPQ solutions including enterprise architecture, leading a team through ERP integration, & understanding of down-stream processes such as billing, provisioning, etc.\n\n— Salesforce CPQ and sales cloud Specialist Certification\n\nPreferred Qualifications:\n\n— 4+ years CPQ and sales cloud end to end project implementations\n\n— Experience with Salesforce administration, configuration, & tools like process builder\n\n— Experience with RESTful Service Architecture & CPQ API""™s & QCP (quote calculator plug-in) is a plus\n\n— Experience with CPQ deployment tools such as Prodly\n\n— Strong CPQ configuration experience and system administration\n\n""¢ Troubleshoot and resolve CPQ-related issues, including pricing, discounts, and product configuration logic.\n\n— Strong functional knowledge of OOTB Capabilities\n\n— Strong knowledge of designing Architecture Diagrams and Data flows\n\n— Strong problem-solving skills\n\n— Knowledge of End-to-End Order Management lifecycle\n\n— Knowledge of Agile methodologies and understanding of software development process\n\n— Knowledge of lightning web components & how to address UI/UX requirements effectively when deploying CPQ to channel/distributors/partners\n\n— Well-versed with Salesforce security model and Communities experience is a plus\n\n— In depth understanding of CPQ architecture (Data, Logic Layers, Data Layers), data models, customizations & extensions\n\n— Excellent verbal and written communication skills with ability to tailor messaging to audience —\n\nCapable of recommending best practice solutions based on project and business needs and owning overall design of the technical application\n\n— Hands on experience on Salesforce Data Loader\n\n— Sales Cloud Certification, Salesforce Administrator Certification, App Builder —\n\nTechnical skills related to Apex and other languages is appreciated but not a requirement\n\nSkills\nSalesforce CPQ Apex\nVisualforce\nSOQL\nREST/SOAP APIs\nJavaScript\nSalesforce Lightning\nData Migration""",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['cognos architecture', 'cpq', 'system administration', 'data modeling', 'data flow', 'visualforce', 'rest', 'soql', 'project implementation', 'distribution', 'salesforce security model', 'salesforce cpq', 'sales', 'javascript', 'apex', 'salesforce', 'ootb', 'salesforce administration', 'agile', 'soap']",2025-06-11 05:52:10
SAP MM Consultant,"NTT DATA, Inc.",2 - 7 years,Not Disclosed,['Hyderabad'],"Req ID: 324882\n\nWe are currently seeking a SAP MM Consultant to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n SAP MM Functional Consultant  \n\nPosition Overview\n\nOur SAP Implementation MM Functional Consultant will lead others through the implementation of SAP. Duties include but may not be limited to\nAbility to lead business workshops for blueprinting activities\nAnalyzing legacy data, quality check of submitted load files, testing load quality, leading user testing and acceptance of load process, providing input into specifications for automated data migration transformation rules, analysis and identification of duplicate records and other activities required for successful and on time data migration\nPerform high-level analysis of customer business processes and requirements to support project Data Migration requirements with proposed solutions\nPerform detailed analysis of customer requirements to produce custom solution specifications\nProvide direction to SAP BODS / ADM development teams for solution realization and participate, as necessary, during coding, testing, documentation, and maintenance activities\nWork closely with Data Migration team to document data migration requirements, on project planning and load scheduling, testing, troubleshooting, and issue resolution\n\n\nJob\n8+ of Overall experience in SAP MM/WM/eWM Implementations / Rollouts\n2+ Yrs. of experience with S/4 HANA MM/WM/eWM Implementations / Rollout experience.\nSAP S/4 HANA data migration expertise in SAP MM/WM/eWM Master / transaction data including Material Masters, Vendors (BP), Purchasing Info. Records, Source List, Storage Bins, Warehouse Product Master (EWM), Control Cycles (EWM), Handling Units, Material Inventory, free Goods, Purchase Agreements etc.\nExperience with creating functional documentation for data migration field mapping, rules etc.\nExperience with Maintenance Master Data (FL,EQ,BOM) and Materials Master Data\nMotivated self-starter with exceptional team building, leadership, and interpersonal skills\nHe is a team player with the aptitude to work in time sensitive environments making him an effective member of any data migration team\nCandidate possesses excellent communication and organization skills with the ability of adapting to new environments quickly",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['sap', 'sap s hana', 'wm', 'sap mm', 'ewm', 'master data', 'software testing', 'warehouse management', 'sap sd', 'sap bods', 'sap implementation', 'data migration', 'sap mm module', 'bods', 'sap wm', 'material management', 'sap mm implementation', 'procurement', 'mm module', 'inventory management']",2025-06-11 05:52:12
SAP PP/QM Functional Consultant,"NTT DATA, Inc.",8 - 13 years,Not Disclosed,['Hyderabad'],"Req ID: 324860\n\nWe are currently seeking a SAP PP/QM Functional Consultant to join our team in Hyderabad, Telangana (IN-TG), India (IN).\n\n SAP PP/QM Functional Consultant  \n Position Overview \n\nOur SAP Implementation PP/QM Functional Consultant will lead others through the implementation of SAP. Duties include but may not be limited to\nEducate local teams on SAP Production Planning/Quality Management functionality, and SAP, in general\nRefine the Plan to Manufacture process scope, identifying any gaps when necessary\nDesign and prototype SAP PP/QM functionality facilitating key decision discussions in terms of functionality use\nPerform system demonstrations designed to showcase the existing standard SAP functionality and secure buy-in from customers, while identifying any gaps, and/or requirements\nTranslate local business requirements into related configuration requirements and perform system set-ups in SAP to meet customer requirements\nIdentify any Reports, Interfaces, Conversions, Enhancements, Forms, Workflows and/or any other development objects necessary to bridge requirements with SAP functionality through the creation of Functional Specification documentation. Interface effectively with developers to translate Functional Specification documentation into Technical Specifications and the development of technical designs\nIdentify local security requirements and work with Security staff on the creation of security profiles necessary to support local needs\nPerform field and value mappings associated with data conversion efforts\nPerform demonstrations of the updated system, post build (Configuration and Development) activities to showcase the incorporation and validate localization requirements\nProvide support and subject matter expertise during the execution of testing activities and resolve any specific issues identified during testing\nWork on the development training materials incorporating requirements and deliver end user training or train the trainer workshops according to the training plans/schedules\nProvide subject matter expert support during cutover and go-live activities and perform tasks assigned as part of cutover plan and schedules\nProvide support post go-live and resolve post go-live issues\n\n Job  \nRequired Experience\nRequires 8+ years of experience in SAP design, prototyping, configuration/build, and testing activities, specifically in Plan to Manufacture SAP PP/QM processes\nMultiple (over 4) SAP implementation full life-cycle experience\nData Migration Experience\nProject Management and Team Leadership experience\nEducation and Certifications\nUndergraduate degree or equivalent combination of education and work experience\n\n\n\n\nSkills\nSolid knowledge of system development methodology, project management and system architecture. Preferably involving the implementation of SAP, particularly Plan to Manufacture processes\nSolid analytical / problem solving skills\nAbility to evaluate IT and business challenges from a broad perspective.\nStrong influencing and excellent communication skills. Ability to translate between non-technical business users and technical IT resources.\nStrong client service attitude\nStrong organizational and time management skills\nLanguages\nEnglish fluency mandatory\n\nNight shift will be from 3 PM to 12 AM IST with Work from home option unless otherwise mentioned",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['project management', 'prototyping', 'client servicing', 'system architecture', 'system development methodologies', 'sap', 'sap implementation', 'sap production planning', 'end user training', 'linux', 'sap pp', 'production planning', 'sap quality management', 'sap pp qm', 'sap qm', 'unix']",2025-06-11 05:52:14
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:15
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Hyderabad'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:17
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Coimbatore'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:18
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:20
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:21
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer Experience\nIdentification of risk issues and mitigation plans\nKnowledge management\n2New projectsTimely delivery\nAvoid unauthorised changes\nNo formal escalations\n\n\n\nMandatory Skills: Apache Cassandra database.",Industry Type: IT Services & Consulting,Department: Human Resources,"Employment Type: Full Time, Permanent","['Apache Cassandra', 'Team Management', 'database migration', 'troubleshooting', 'middleware', 'database architecture']",2025-06-11 05:52:23
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Coimbatore'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\nDeliver\nNoPerformance ParameterMeasure1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['architecture planning', 'Customer management', 'Knowledge management', 'Performance Management', 'Talent Management', 'CSAT']",2025-06-11 05:52:24
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\nDeliver\n\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer Experience\nIdentification of risk issues and mitigation plans\nKnowledge management\n2New projectsTimely delivery\nAvoid unauthorised changes\nNo formal escalations\n\n\nMandatory Skills: ServiceNow - System Administration.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['ServiceNow', 'Team Management', 'System Administration', 'troubleshooting', 'disaster recovery', 'middleware']",2025-06-11 05:52:26
Technical Lead,PwC India,8 - 10 years,Not Disclosed,"['Mumbai', 'Navi Mumbai', 'Mumbai (All Areas)']","Loction :Mumbai\n\nJob Description:\n\nLooking for Candidates with 8 to 10 years of experience\nHands on experience of implementing data pipelines using traditional DWH, Big data & Cloud ecosystem",,,,"['Generative Ai Tools', 'Data Pipeline', 'Big Data', 'Data Governance', 'Data Quality', 'Aiml']",2025-06-11 05:52:27
Lead Administrator - L1,Wipro,5 - 8 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\n\nDeliver\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer Experience\nIdentification of risk issues and mitigation plans\nKnowledge management\n2New projectsTimely delivery\nAvoid unauthorised changes\nNo formal escalations\n\n\nMandatory Skills: Citrix Admin.",Industry Type: IT Services & Consulting,Department: Engineering - Hardware & Networks,"Employment Type: Full Time, Permanent","['Citrix Administration', 'Team Management', 'technical support', 'capacity planning', 'disaster recovery', 'middleware']",2025-06-11 05:52:29
Functional Consultant - L1,Wipro,5 - 8 years,Not Disclosed,['Hyderabad'],"Assist in gathering and analyzing client business requirements.\nParticipate in functional workshops and documentation of process flows.\nSupport the configuration and testing of ERP/CRM/enterprise applications.\nCreate user manuals, training materials, and functional specifications.\nAssist in user acceptance testing (UAT) and end-user training.\nProvide first-line support for issues reported by users.\nDocument and track client feedback, change requests, and resolutions.\nWork closely with senior consultants, developers, and project managers to ensure successful project delivery.\nPerform data migration tasks under guidance.\nMaintain up-to-date knowledge of the supported application/modules.\nMandatory Skills: SAP PP - Production Planning.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['functional design', 'SAP PP', 'documentation', 'user acceptance testing', 'data migration']",2025-06-11 05:52:30
Lead Administrator - L2,Wipro,8 - 10 years,Not Disclosed,['Pune'],"Role Purpose\n\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\n\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\n\n\n\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\n\n\nDeliver\n\nNoPerformance ParameterMeasure\n1Operations of the towerSLA adherence\nKnowledge management\nCSAT/ Customer Experience\nIdentification of risk issues and mitigation plans\nKnowledge management\n2New projectsTimely delivery\nAvoid unauthorised changes\nNo formal escalations\n\n\n\nMandatory Skills: DevOps-Terraform.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['DevOps', 'Terraform', 'troubleshooting', 'disaster recovery', 'performance management', 'middleware']",2025-06-11 05:52:32
Database Administrator - Oracle-4,"NTT DATA, Inc.",2 - 5 years,Not Disclosed,['Mumbai'],"The Associate Database Administrator works closely with Change Control, Release Management, Asset and Configuration Management and Capacity and Availability Management to establish the needs of users, monitoring user access and security.\nWhat you'll be doing\nKey Responsibilities:\nUnder guidance, assists with the installation, configuration, and maintenance of database management systems (DBMS), including SQL Server, Oracle, MySQL, or others, as required.\nUnder guidance, collaborates with software developers/architects to design and optimize database schemas, data models, and database-related applications.\nParticipates in the writing of database documentation, including data standards, data flow diagrams, standard operating procedures and definitions for the data dictionary (metadata).\nUnder guidance, monitors database performance, identifies performance bottlenecks, and optimizes queries and indexing for optimal database performance.\nDesigns and implements robust backup and disaster recovery strategies to ensure data availability and business continuity.\nUnder guidance, monitors production databases regularly or respond to any database issues by bringing down the database or taking the database offline.\nWorks closely with the Change Control and Release Management functions to commission and install new applications and customizing existing applications in order to make them fit for purpose.\nUnder guidance, plans and executes database software upgrades and applies patches to keep systems up-to-date and secure.\nImplements and manages security measures to safeguard databases from unauthorized access, data breaches, and data loss.\nEnsures data integrity and consistency by performing regular data validation, integrity checks, and data cleansing activities.\nUnder guidance, conducts regular security audits and vulnerability assessments to maintain compliance with data protection standards and regulations.\nWorks collaboratively with cross-functional teams, including developers, system administrators, network engineers, and business stakeholders, to support database-related initiatives.\nProvides technical support to end-users, assists with database-related enquiries, and conducts training sessions as needed.\nPerforms any other related task as required.\n\nKnowledge and Attributes:\nBasic proficiency in database administration tasks, including database installation, configuration, maintenance, and performance tuning.\nBasic knowledge of SQL (Structured Query Language) to write complex queries, stored procedures, and functions.\nBasic understanding of database security principles, access controls, and data encryption methods.\nBasic working knowledge in database backup and recovery strategies to ensure data availability and business continuity.\nAbility to monitor database performance, identify and resolve issues, and optimize database operations.\nAbility to learn new technologies as needed to provide the best solutions to all stakeholders.\nCan communicate IT information in simplified form depending on the target audience.\nEffective communication and collaboration skills to work with cross-functional teams and stakeholders.\nBasic proficiency understanding of the principles of data architecture and data services.\nBasic knowledge of application development lifecycle and data access layers.\nDisplays some problem-solving skills to troubleshoot database-related issues and implement effective solutions.\nDisplays some ability to manipulate, process and extract value from large, disconnected datasets.\n\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in computer science, engineering, information technology or related field\nRelevant certification, such as MCSE DBA, oracles associate or equivalent\nRelevant certifications such as Microsoft Certified: Azure Database Administrator Associate; Oracle Certified Professional (OCP) - Database Administrator; MySQL Database Administrator; PostgreSQL Certified Professional\nCompletion of database management courses covering topics like database administration, data modelling, SQL, and performance tuning can provide foundational knowledge\n\nRequired Experience:\nEntry level experience working as a Database Administrator within an Information Technology organization.\nEntry level experience with database backup and recovery best practices.\nEntry level experience running and creating health assessment reports.\nEntry level experience working with suppliers to deliver solutions.\nEntry level experience in Oracle Enterprise.\nEntry level experience in Microsoft SQL Server.\nEntry level experience managing databases.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Database Administration', 'MySQL', 'DBMS', 'Oracle', 'Azure Database Administration', 'SQL']",2025-06-11 05:52:33
Senior Manager-Storage Lead,Sun Pharma,8 - 13 years,Not Disclosed,['Mumbai'],"Hi,\n\nWe are having an opening for Senior Manager 2-Storage Lead at our Mumbai location.\n\nJob Summary :\nWe are seeking an experienced and strategic IT Storage Lead to manage enterprise storage infrastructure across on-premises and cloud environments, with an emphasis on secure, compliant, and high-performance storage systems. This role will support a wide range of functions including R&D, clinical trials, manufacturing, quality, regulatory compliance, and enterprise applications.The ideal candidate will bring deep technical expertise in storage architecture, security, operations, vendor management, governance, disaster recovery, and regulatory compliance (e.g., GxP, 21 CFR Part 11, HIPAA, SOX), particularly in regulated sectors such as Pharma/Life Sciences, BFSI, and Healthcare.",,,,"['Storage Domain', 'SAN', 'Storage Management', 'storage architect', 'Netapp', 'NAS', 'EMC Storage']",2025-06-11 05:52:35
Oracle Goldengate DBA,Wipro,8 - 10 years,Not Disclosed,['Pune'],"Role Purpose\nThe purpose of this role is to provide significant technical expertise in architecture planning and design of the concerned tower (platform, database, middleware, backup etc) as well as managing its day-to-day operations\n\nDo\nProvide adequate support in architecture planning, migration & installation for new projects in own tower (platform/dbase/ middleware/ backup)\nLead the structural/ architectural design of a platform/ middleware/ database/ back up etc. according to various system requirements to ensure a highly scalable and extensible solution\nConduct technology capacity planning by reviewing the current and future requirements\nUtilize and leverage the new features of all underlying technologies to ensure smooth functioning of the installed databases and applications/ platforms, as applicable\nStrategize & implement disaster recovery plans and create and implement backup and recovery plans\nManage the day-to-day operations of the tower\nManage day-to-day operations by troubleshooting any issues, conducting root cause analysis (RCA) and developing fixes to avoid similar issues.\nPlan for and manage upgradations, migration, maintenance, backup, installation and configuration functions for own tower\nReview the technical performance of own tower and deploy ways to improve efficiency, fine tune performance and reduce performance challenges\nDevelop shift roster for the team to ensure no disruption in the tower\nCreate and update SOPs, Data Responsibility Matrices, operations manuals, daily test plans, data architecture guidance etc.\nProvide weekly status reports to the client leadership team, internal stakeholders on database activities w.r.t. progress, updates, status, and next steps\nLeverage technology to develop Service Improvement Plan (SIP) through automation and other initiatives for higher efficiency and effectiveness\nTeam Management\nResourcing\nForecast talent requirements as per the current and future business needs\nHire adequate and right resources for the team\nTrain direct reportees to make right recruitment and selection decisions\nTalent Management\nEnsure 100% compliance to Wipros standards of adequate onboarding and training for team members to enhance capability & effectiveness\nBuild an internal talent pool of HiPos and ensure their career progression within the organization\nPromote diversity in leadership positions\nPerformance Management\nSet goals for direct reportees, conduct timely performance reviews and appraisals, and give constructive feedback to direct reports.\nEnsure that organizational programs like Performance Nxt are well understood and that the team is taking the opportunities presented by such programs to their and their levels below\nEmployee Satisfaction and Engagement\nLead and drive engagement initiatives for the team\nTrack team satisfaction scores and identify initiatives to build engagement within the team\nProactively challenge the team with larger and enriching projects/ initiatives for the organization or team\nExercise employee recognition and appreciation\nDeliver\n\nNo Performance Parameter Measure\n1Operations of the tower SLA adherence Knowledge management CSAT/ Customer Experience Identification of risk issues and mitigation plans Knowledge management\n2 New projectsTimely deliveryAvoid unauthorised changes No formal escalations\n\nMandatory Skills: Oracle Database Admin.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Oracle Database Admin', 'Team Management', 'DBA', 'capacity planning', 'architecture planning', 'Talent Management', 'Performance Management']",2025-06-11 05:52:37
Technical Specialist Database Administrator-Oracle-5,"NTT DATA, Inc.",2 - 6 years,Not Disclosed,['Mumbai'],"Your day at NTT DATA\nThe Database Administrator is a seasoned subject matter expert, responsible for ensuring the availability, integrity and performance of critical data assets.\n\nThis role works closely with cross-functional teams to support data-driven applications, troubleshoot issues, and implement robust backup and recovery strategies.\n\nThe Database Administrator works closely with closely with Change Control, Release Management, Asset and Configuration Management and Capacity and Availability Management to establish the needs of users, monitoring user access and security and assists in controlling access to databases environments through permissions and privileges.\nWhat you'll be doing\nKey Responsibilities:\nPerforms the installation, configuration, and maintenance of database management systems (DBMS), including SQL Server, Oracle, MySQL, or others, as required.\nCollaborates with software developers/architects to design and optimize database schemas, data models, and database-related applications.\nAssists with the mapping out of the conceptual design for a planned database.\nParticipates in the writing of database documentation, including data standards, data flow diagrams, standard operating procedures and definitions for the data dictionary (metadata).\nMonitors database performance, identifies performance bottlenecks, and optimizes queries and indexing for optimal database performance.\nContinuously monitors database systems to ensure availability, proactively identify potential issues, and takes appropriate actions.\nDesigns and implements robust backup and disaster recovery strategies to ensure data availability and business continuity.\nMonitors production databases regularly or respond to any database issues by bringing down the database or taking the database offline.\nProactively supports the development of database utilities and automated reporting.\nWorks closely with the Change Control and Release Management functions to commission and install new applications and customizing existing applications in order to make them fit for purpose.\nPlans and executes database software upgrades and applies patches to keep systems up-to-date and secure.\nCommunicates regularly with technical, applications and operational employees to ensure database integrity and security.\nEnsures data integrity and consistency by performing regular data validation, integrity checks, and data cleansing activities.\nWorks collaboratively with cross-functional teams, including developers, system administrators, network engineers, and business stakeholders, to support database-related initiatives.\nProvides technical support to end-users, assists with database-related enquiries, and conducts training sessions as needed.\nPerforms any other related task as required.\n\nKnowledge and Attributes:\nSeasoned proficiency in database administration tasks, including database installation, configuration, maintenance, and performance tuning.\nSeasoned knowledge of SQL (Structured Query Language) to write complex queries, stored procedures, and functions.\nSeasoned understanding of database security principles, access controls, and data encryption methods.\nSeasoned working knowledge in database backup and recovery strategies to ensure data availability and business continuity.\nAbility to monitor database performance, identify and resolve issues, and optimize database operations.\nAbility to manage multiple projects concurrently while maintaining a high level of attention to detail on each project.\nAbility to learn new technologies as needed to provide the best solutions to all stakeholders.\nAbility to communicate complex IT information in simplified form depending on the target audience.\nEffective communication and collaboration skills to work with cross-functional teams and stakeholders.\nSeasoned proficiency understanding of the principles of data architecture and data services.\nSeasoned knowledge of application development lifecycle and data access layers.\nExcellent problem-solving skills to troubleshoot database-related issues and implement effective solutions.\nExcellent analytical skills related to working with unstructured datasets\nAbility to manipulate, process and extract value from large, disconnected datasets.\n\nAcademic Qualifications and Certifications:\nBachelors degree or equivalent in computer science, engineering, information technology or related field.\nRelevant certification, such as MCSE DBA, oracles associate or equivalent preferred.\nRelevant certifications such as Microsoft Certified; Azure Database Administrator Associate; Oracle Certified Professional (OCP) - Database Administrator; MySQL Database Administrator; PostgreSQL Certified Professional preferred.\nCompletion of database management courses covering topics like database administration, data modelling, SQL, and performance tuning can provide foundational knowledge.\n\nRequired Experience:\nSeasoned experience working as a Database Administrator within an Information Technology organization.\nSeasoned experience with database backup and recovery best practices.\nSeasoned experience running and creating health assessment reports.\nSeasoned experience working with suppliers to deliver solutions.\nSeasoned experience in Oracle Enterprise.\nSeasoned experience in Microsoft SQL Server.\nSeasoned experience managing databases.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Database Administration', 'database management', 'performance tuning', 'Microsoft SQL Server', 'data modelling', 'Oracle Enterprise', 'SQL']",2025-06-11 05:52:38
Oracle Ebs Scm Functional Consultant,IT Services Organization,5 - 10 years,Not Disclosed,['Pune'],"Key Skills: Oracle, Oracle Ebs, Oracle SCM, EPM Oracle SaaS, Oracle Application Framework, Oracle 11g, Inventory Management, Supply Chain Management, Oracle BPM, Oracle 8i, Oracle Apps\nRoles and Responsibilities:\nAct as the primary liaison between business stakeholders and technical teams to translate business requirements into system solutions within Oracle EBS SCM modules\nConfigure and support key Oracle SCM modules including:\nInventory (INV)\nPurchasing (PO)\nOrder Management (OM)\niProcurement\nAdvanced Supply Chain Planning (ASCP)\nShipping Execution\nWIP (Work in Process) / BOM (Bill of Materials)\nPerform functional analysis, prepare functional specifications, and participate in solution design and implementation\nCollaborate with developers for customizations, extensions, interfaces, and reports (CEMLI)\nSupport UAT, training, and post-implementation activities for end users\nTroubleshoot issues in production and support enhancements and upgrades\nParticipate in data migration, system integration testing, and go-live support\nDocument configurations, processes, and business requirements thoroughly\nSkills Required:\nStrong functional knowledge of Oracle SCM modules listed above\nProficient in SQL, PL/SQL, and Oracle workflows\nAbility to analyze and document business processes and system flows\nStrong problem-solving, communication, and analytical skills\nExperience working with cross-functional teams in a global environment\nAbility to manage multiple priorities in a fast-paced environment\nEducation: Bachelor's or Master's degree in Computer Science, Engineering, or a related technical field",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Oracle SCM', 'Oracle Application Framework', 'EPM Oracle SaaS', 'Oracle', 'Oracle Ebs', 'Oracle Apps', 'Oracle 8i', 'Oracle BPM', 'Inventory Management', 'Supply Chain Management', 'Oracle 11g']",2025-06-11 05:52:40
SAP HCM Consultant,Rox Hi-tech,3 - 8 years,Not Disclosed,['Chennai'],"Job Title: SAP HCM Time Consultant Experience: 3 5 Years. Job Summary: The SAP HCM Time Consultant is responsible for providing expertise in the implementation, configuration, and support of the SAP Human Capital Management (HCM) Time Management module. This role involves collaborating with clients to understand their business requirements, configuring the SAP HCM Time Management module to meet those requirements, and providing ongoing support and maintenance. The consultant will also be involved in troubleshooting issues, conducting testing, and providing training to end-users. Key Responsibilities: 1. Collaborate with clients to gather and analyze business requirements related to time management and attendance tracking. 2. Configure the SAP HCM Time Management module based on client requirements, including setting up time recording rules, work schedules, and absence quotas. 3. Customize SAP Time Management functionalities as per business needs, such as shift planning, overtime calculation, and leave management. 4. Provide guidance and best practices to clients on utilizing SAP HCM Time Management effectively. 5. Conduct testing to ensure the configured solution meets the specified requirements and is free of defects. 6. Troubleshoot and resolve issues related to the SAP HCM Time Management module, providing timely support to end-users. 7. Assist in data migration activities, including data cleansing and validation, during SAP HCM Time Management implementations or upgrades. 8. Develop and deliver end-user training sessions and documentation to ensure smooth adoption of the SAP HCM Time Management system. 9. Stay updated with the latest SAP HCM Time Management module features, enhancements, and best practices. 10. Collaborate with other SAP functional consultants and technical teams to integrate SAP HCM Time Management with other modules or external systems, as required.\nQualifications and Skills: • Bachelors degree in computer science, Information Systems, Business Administration, or related field. • In-depth knowledge of SAP HCM Time Management module functionalities, configurations, and integration with other SAP modules. • Hands-on experience in configuring SAP HCM Time Management settings, including time recording, attendance, and absence management. • Strong analytical and problem-solving skills, with the ability to understand complex business processes and translate them into SAP HCM Time Management solutions. • Excellent communication and interpersonal skills, with the ability to effectively interact with clients, stakeholders, and team members. • Certification in the SAP HCM Time Management module is preferred. • Experience with SAP SuccessFactors Employee Central Time Management module would be a plus.",,,,"['SAP HCM', 'HCM consultant', 'Hcm Modules']",2025-06-11 05:52:42
SAP FICO Consultant,NTT DATA Business Solutions,8 - 13 years,Not Disclosed,[],"Position: SAP FICO Consultant\nLocation: Remote (Hyderabad / Chennai / Mumbai / Pune / New Delhi / Bangalore)\nShift: Night Shift (9:30 PM 6:30 AM IST)\nNotice Period: Immediate to 30 Days\n\nRole Overview\nWe are seeking an experienced SAP FICO Consultant with strong expertise in SAP Financials and Controlling to support our global clients in a remote, night-shift role. The ideal candidate will have a deep understanding of S/4HANA changes, FIORI applications, and hands-on experience in the configuration and support of FICO modules. This role requires strong analytical skills, process knowledge, and a focus on delivering quality support within defined SLAs.",,,,"['Controlling', 'Accounts Receivable', 'Accounts Payable', 'SAP FICO', 'Asset Accounting', 'Co Module', 'Profit Centre', 'GL', 'Implementation And Support', 'Co-cca', 'Profit Center Accounting', 'S4 Hana', 'S4HANA', 'FICO', 'AP', 'Product Costing', 'SAP CO', 'AR', 'FI-GL', 'General Ledger', 'Copa', 'Cost Center Accounting']",2025-06-11 05:52:43
"SAP FICO, CO-CEA Consultant (S/4HANA | Implementation | Support)",NTT DATA Business Solutions,7 - 12 years,Not Disclosed,[],"Role: SAP FICO, CO-CEA Senior Consultant\nExperience: 7 to 15 Years\nJob Location: Hyderabad / Bangalore / Pune / Mumbai / Noida / Remote\nWork Mode: Hybrid / Remote\nShift: Flexible to work in US Shifts (9:30 PM to 6:30 AM)\nNotice Period: Immediate to 15 Days\n\nJob Description:",,,,"['Implementation', 'SAP FICO', 'Copa', 'S/4 HANA', 'FI', 'Support', 'Controlling', 'SAP FICO Implementation', 'Co-cca', 'SAP Controlling', 'FI-AR', 'Co', 'S4HANA', 'FICO', 'Product Costing', 'SAP CO', 'FI-GL', 'SAP HANA', 'Rollout', 'Cost Center Accounting', 'Cca', 'Integration', 'Co Module', 'Sap Copa', 'GST', 'Profit Center Accounting', 'CO-CEA']",2025-06-11 05:52:45
Database Administration,Kyndryl,3 - 6 years,Not Disclosed,['Bengaluru'],"Who We Are\nAt Kyndryl, we design, build, manage and modernize the mission-critical technology systems that the world depends on every day. So why work at Kyndryl? We are always moving forward – always pushing ourselves to go further in our efforts to build a more equitable, inclusive world for our employees, our customers and our communities.\n\nThe Role\nWithin our Database Administration team at Kyndryl, you'll be a master of managing and administering the backbone of our technological infrastructure. You'll be the architect of the system, shaping the base definition, structure, and documentation to ensure the long-term success of our business operations. \n\nYour expertise will be crucial in configuring, installing and maintaining database management systems, ensuring that our systems are always running at peak performance. You'll also be responsible for managing user access, implementing the highest standards of security to protect our valuable data from unauthorized access.\n\nIn addition, you'll be a disaster recovery guru, developing strong backup and recovery plans to ensure that our system is always protected in the event of a failure. Your technical acumen will be put to use, as you support end users and application developers in solving complex problems related to our database systems.\n\nAs a key player on the team, you'll implement policies and procedures to safeguard our data from external threats. You will also conduct capacity planning and growth projections based on usage, ensuring that our system is always scalable to meet our business needs.\n\nYou'll be a strategic partner, working closely with various teams to coordinate systematic database project plans that align with our organizational goals. Your contributions will not go unnoticed - you'll have the opportunity to propose and implement enhancements that will improve the performance and reliability of the system, enabling us to deliver world-class services to our customers.\n\nYour Future at Kyndryl\nEvery position at Kyndryl offers a way forward to grow your career, from Junior Administrator to Architect. We have training and upskilling programs that you won’t find anywhere else, including hands-on experience, learning opportunities, and the chance to certify in all four major platforms. One of the benefits of Kyndryl is that we work with customers in a variety of industries, from banking to retail. Whether you want to broaden your knowledge base or narrow your scope and specialize in a specific sector, you can find your opportunity here.",,,,"['functional', 'development', 'python', 'sql queries', 'analytical', 'performance tuning', 'administration', 'data warehousing', 'triggers', 'sql server', 'stored procedures', 'sql', 'nosql', 'sql database development', 'postgresql', 'collaboration', 'database creation', 'troubleshooting', 'mysql', 'communication skills']",2025-06-11 05:52:47
Senior Principal Engineer - IT Business Analysis,Mercer,5 - 8 years,11-16 Lacs P.A.,['Mumbai (All Areas)'],"Job Description For Posting\nWe are seeking a talented individual to join our team at Marsh .This role will be based in Mumbai .This is a hybrid role that has a requirement of working at least three days a week in the office.\n\nSenior Principal Engineer - IT Business Analysis\n\nWe will count on you to:\nBe a highly motivated team player working within MMC Agile culture, within a specified Agile framework of Scrum or KANBAN and maintain a willingness for continuously improving your agile mindset. \nWork with the Product Owner to communicate the product vision, roadmap, value, and MVP to the Agile team to enable empathy and a shared understanding thereby helping the team to formulate an appropriate solution. \nCollaborate with the Pod Leadership and Product Owner to create Personas, Story Maps, and a Release Plan for the project.\nWork with the Product Owner to communicate the product vision, roadmap, value, and MVP to the agile teams to enable empathy and a shared understanding thereby helping the team to formulate an appropriate solution.\nWork in partnership with the Product Owner and agile teams in the creation and maintenance of Product Backlog Items ensuring that Epics and User Stories are continuously prioritized and aligned to the Product Roadmap and MVP.\nFacilitate refinement sessions with the Agile Teams and Business to sufficiently detail out User Stories, to include dependencies.\nFacilitate the Sprint Review ceremony by working with the agile teams, Product Owner, Business and Customer to review, assess and adapt the latest product increment by incorporating customer insights and feedback into the Product Backlog.\nActively work with Pod Leadership by running assessments processes for the POD and provide constructive feedback towards continuously improving the Systems Analyst function, standards and processes in Global Technology.\nFacilitate discussions and collaborate with data engineers, data architects, technical experts and AI engineers to integrate AI solutions into application design.\nDemonstrate an awareness of MMC and Mercer Technical, Security and Process Standards and work with the team to incorporate them in product delivery through the software development life cycle. \n\nWhat you need to have:\nHighly motivated candidate who is inquisitive, a rapid learner that is comfortable working as part of a remote team. \nPossess strong communication skills with the capability of working collaboratively within the organization, regardless of boundaries.\nAn effective communicator for both technical and business-oriented audiences.  \nDemonstrated requirements gathering skills showcasing the capture of customer needs and business drivers using a variety of techniques into product backlog items such as Epics and User Stories.\nProven quantitative, analytical, and problem-solving skills.\nAbility to find resolutions regarding own work methods requiring minimal direction.  \nBe willing to respond to emergent changes rather than focused on existing plans. \nFamiliarity with AI concepts and technologies, including machine learning, natural language processing, and data analytics, while ensuring compliance with AI governance frameworks. Leverage these technologies to enhance user experiences and improve decision-making processes within applications.\n\nWhat makes you stand out?\nAbility to craft effective prompts that optimize AI responses, enhancing the functionality of AI-driven applications for problem-solving, analysis, and content generation.\nStay open to learning about emerging AI tools and methodologies.\nAn Agile Mindset with an in-depth understanding of Agile Principles.\nPrior experience as an IT Systems Analyst or IT Business Analyst working as part of an agile team using an Agile Workflow tool such as JIRA or TFS. \nAgile Certification, such as CSM, PSM, CSPO, PSPO, PMI-ACP, Certified SAFe Practitioner, Azure AI Fundamentals is desirable.\n\n\nMarsh McLennan (NYSE: MMC) is a global leader in risk, strategy and people, advising clients in 130 countries across four businesses: Marsh, Guy Carpenter, Mercer and Oliver Wyman. With annual revenue of $24 billion and more than 90,000 colleagues, Marsh McLennan helps build the confidence to thrive through the power of perspective. For more information, visit marshmclennan.com, or follow on LinkedIn and X.\n\nMarsh McLennan is committed to embracing a diverse, inclusive and flexible work environment. We aim to attract and retain the best people and embrace diversity of age, background, caste, disability, ethnic origin, family duties, gender orientation or expression, gender reassignment, marital status, nationality, parental status, personal or social status, political affiliation, race, religion and beliefs, sex/gender, sexual orientation or expression, skin color, or any other characteristic protected by applicable law.\n\nMarsh McLennan is committed to hybrid work, which includes the flexibility of working remotely and the collaboration, connections and professional development benefits of working together in the office. All Marsh McLennan colleagues are expected to be in their local office or working onsite with clients at least three days per week. Office-based teams will identify at least one anchor day” per week on which their full team will be together in person.",Industry Type: IT Services & Consulting,Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Business Analysis', 'Use Cases', 'Requirement Gathering']",2025-06-11 05:52:48
Sr. Project Manager,Useready,15 - 18 years,30-40 Lacs P.A.,"['Mohali', 'Bengaluru']","Job Summary:\nWe are seeking an experienced and detail-oriented Technical Project Manager, with strong interpersonal skills to lead and manage Data, Business Intelligence (BI), and Analytics initiatives across single and multiple client engagements. The ideal candidate will have a solid background in data project delivery, knowledge of modern cloud platforms, and familiarity with tools like Snowflake, Tableau, and Power BI. Understanding of AI and machine learning projects is a strong plus.\nThis role requires strong communication and leadership skills, with the ability to translate complex technical requirements into actionable plans and ensure successful, timely, and high-quality delivery with attention to details.\nKey Responsibilities:\nProject & Program Delivery\nManage end-to-end, the full lifecycle of data engineering and analytics, projects including data platform migrations, dashboard/report development, and advanced analytics initiatives.\nDefine project scope, timelines, milestones, resource needs, and deliverables in alignment with stakeholder objectives.\nManage budgets, resource allocation, and risk mitigation strategies to ensure successful program delivery.\nUse Agile, Scrum, or hybrid methodologies to ensure iterative delivery and continuous improvement.\nMonitor performance, track KPIs, and adjust plans to maintain scope, schedule, and quality.\nExcellence in execution and ensure client satisfaction\nClient & Stakeholder Engagement\nServe as the primary point of contact for clients and internal teams across all data initiatives.\nTranslate business needs into actionable technical requirements and facilitate alignment across teams.\nConduct regular status meetings, monthly and quarterly reviews, executive updates, and retrospectives.\nManage Large teams\nAbility to manage up to 50+ resources working on different projects for different clients.\nWork with practice and talent acquisition teams for resourcing needs\nManage P & L\nManage allocation, gross margin, utilization etc effectively\nTeam Coordination\nLead and coordinate cross-functional teams including data engineers, BI developers, analysts, and QA testers.\nEnsure appropriate allocation of resources across concurrent projects and clients.\nFoster collaboration, accountability, and a results-oriented team culture.\n  Data, AI and BI Technology Oversight\nManage project delivery using modern cloud data platforms\nOversee BI development using Tableau and/or Power BI, ensuring dashboards meet user needs and follow visualization best practices. Conduct UATs\nManage initiatives involving ETL/ELT processes, data modeling, and real-time analytics pipelines.\nEnsure compatibility with data governance, security, and privacy requirements.\nManage AL ML projects\nData & Cloud Understanding\nOversee delivery of solutions involving cloud data platforms (e.g., Azure, AWS, GCP), data lakes, and modern data stacks.\nSupport planning for data migrations, ETL processes, data modeling, and analytics pipelines.\nBe conversant in tools such as Power BI, Tableau, Snowflake, Databricks, Azure Synapse, or BigQuery.\nRisk, Quality & Governance\nIdentify and mitigate risks related to data quality, project timelines, and resource availability.\nEnsure adherence to governance, compliance, and data privacy standards (e.g., GDPR, HIPAA).\nMaintain thorough project documentation including charters, RACI matrices, RAID logs, and retrospectives.\nQualifications:\n  Bachelor’s degree in Computer Science, Information Systems, Business, or a related field.\nCertifications (Preferred):\nPMP, PRINCE2, or Certified ScrumMaster (CSM)\nCloud certifications (e.g., AWS Cloud Practitioner, Azure Fundamentals, Google Cloud Certified)\nBI/analytics certifications (e.g., Tableau Desktop Specialist, Power BI Data Analyst Associate, DA-100)\nMust Have Skills:\nStrong communication skills\nStrong interpersonal\nAbility to work collaboratively\nExcellent Organizing skills\nStakeholder Management\nCustomer Management\nPeople Management\nContract Management\nRisk & Compliance Management\nC-suite reporting\nTeam Management\nResourcing\nExperience using tools like JIRA, MS Plan etc.\nDesirable Skills:\n15 years of IT experience with 8+ years of proven project management experience, in delivering data, AI Ml, BI / analytics-focused environments.\nExperience delivering projects with cloud platforms (e.g., Azure, AWS, GCP) and data platforms like Snowflake.\nProficiency in managing BI projects preferably Tableau and/or Power BI.\nKnowledge or hands on experience on legacy tools is a plus.\nSolid understanding of the data lifecycle including ingestion, transformation, visualization, and reporting.\nComfortable using PM tools like Jira, Azure DevOps, Monday.com, or Smartsheet.\nExperience managing projects involving data governance, metadata management, or master data management (MDM).",Industry Type: IT Services & Consulting,Department: Project & Program Management,"Employment Type: Full Time, Permanent","['delivery', 'bi projects', 'project management', 'data', 'interpersonal skills', 'microsoft azure', 'power bi', 'aiml', 'machine learning', 'business intelligence', 'artificial intelligence', 'tableau', 'stakeholder management', 'gcp', 'leadership', 'project delivery', 'scrum', 'agile', 'organizing', 'aws', 'communication skills']",2025-06-11 05:52:50
Business Analyst,R Systems International,4 - 8 years,20-25 Lacs P.A.,['Noida'],"We are seeking a skilled and detail-oriented Business Analyst with expertise in payroll systems to support the seamless migration of payroll data from an existing platform to a new system. This role involves collaborating with HR, IT, and external vendors to ensure data integrity, compliance, and operational continuity throughout the migration process.\n\nRoles and Responsibilities\nPayroll Data Analysis & Mapping: Collaborate with OSC and GPMS teams to analyze current payroll data structures and define mapping for OSC to GPMS. Ensure that all data fields are accurately translated and validated.",,,,"['data analysis', 'software testing', 'data validation', 'test case execution', 'documentation', 'test cases', 'business analysis', 'data integrity', 'data migration', 'transformation', 'technical hiring', 'data cleansing', 'system', 'system integration', 'payroll processing', 'recruitment', 'payroll']",2025-06-11 05:52:52
Senior Test Engineer,Valuelabs,5 - 10 years,Not Disclosed,['Bahrain'],"We are hiring a skilled Functional Tester with strong experience in Core Banking systems and Retail Banking modules for an onsite role in Bahrain. The role involves testing digital banking platforms (web/mobile), validating banking workflows, and ensuring quality through SIT and UAT phases.\n\nKey Responsibilities\nDesign and execute manual test cases for core and digital banking systems.",,,,"['Retail Banking', 'Core Banking', 'Loans', 'Cheque Clearing', 'Branch Operations', 'Flexcube', 'Finacle']",2025-06-11 05:52:53
Immediate Openings For ETL Developer - Delhi,Trigyn Technologies,5 - 10 years,Not Disclosed,['New Delhi'],"We are seeking a skilled Data Engineer with at least 5 years of experience to join our data analytics team, focusing on building robust data pipelines and systems to support the creation of dynamic dashboards. The role involves designing, building, and optimizing data architecture, enabling real-time data flow for visualization and analytics. The Data Engineer will be responsible for managing ETL processes, ensuring data quality, and supporting the scalable integration of various data sources into our analytics platform.\nThe ideal candidate should have extensive experience in working with complex data architectures, managing ETL workflows, and ensuring seamless data integration across platforms. They should also have a deep understanding of cloud technologies and database management.\nKey Responsibilities:\n•Data Pipeline Development\no Design, build, and maintain scalable ETL (Extract, Transform, Load) processes for collecting, storing, and processing structured and unstructured data from multiple sources.\no Develop workflows to automate data extraction from APIs, databases, and external sources.\no Ensure data pipelines are optimized for performance and handle large data volumes with minimal latency.\n•Data Integration and Management\no Integrate data from various sources (e.g., databases, APIs, cloud storage) into the centralized daIta warehouse or data lake to support real-time dashboards.\no Ensure smooth data flow and seamless integration with analytics tools like Power BI and Tableau.\no Manage and maintain data storage solutions, including relational (SQL-based) and NoSQL databases.\nData Quality and Governance\no Implement data validation checks and quality assurance processes to ensure data accuracy, consistency, and integrity.\no Develop monitoring systems to identify and troubleshoot data inconsistencies, duplications, or errors during ingestion and processing.\no Ensure compliance with data governance policies and standards, including data protection regulations such as the Digital Personal Data Protection (DPDP) Act.\n•Database Management and Optimization\no Design and manage both relational and NoSQL databases, ensuring efficient storage, query performance, and reliability.\no Optimize database performance, ensuring fast query execution times and efficient data retrieval for dashboard visualization.\no Implement data partitioning, indexing, and replication strategies to support large-scale data operations.\n•Data Security and Compliance\no Ensure that all data processes adhere to security best practices, including encryption, authentication, and access control.\no Implement mechanisms for secure data storage and transmission, especially for sensitive government or public sector data.\no Conduct regular audits of data pipelines and storage systems to ensure compliance with relevant data protection regulations.\n• Cloud Infrastructure and Deployment\nDeploy and manage cloud-based data solutions using AWS, Azure, or GCP, including data lakes, data warehouses, and cloud-native ETL tools.\no Set up cloud infrastructure to support high availability, fault tolerance, and scalability of data systems.\no Monitor cloud usage and optimize costs for data storage, processing, and retrieval.\n•Performance Monitoring and Troubleshooting\no Continuously monitor data pipeline performance and data ingestion times to identify bottlenecks and areas for improvement\nTroubleshoot and resolve any data flow issues, ensuring high availability and reliability of data for dashboards and analytics.\no Implement logging and alerting mechanisms to detect and address any operational issues proactively.\nQualifications:\n•Education: Bachelors degree in Computer Science, Information Technology, Data Engineering, or a related field. A Master’s degree is a plus.\n•Experience: At least 5 years of hands-on experience as a Data Engineer, preferably in a data analytics or dashboarding environment.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Informatica', 'ETL', 'Azure Data Factory', 'SQL']",2025-06-11 05:52:55
Senior Artificial Intelligence Engineer,Ignitho,4 - 6 years,Not Disclosed,['Chennai( Sholinganallur )'],"Job Title: Senior AI Engineer\nLocation: Chennai\nReports To: Data Architect\n\nAbout the Company:\nIgnitho Inc. is a leading AI and data engineering company with a global presence, including US, UK, India, and Costa Rica offices.\nVisit our website to learn more about our work and culture: www.ignitho.com.\nIgnitho is a portfolio company of Nuivio Ventures Inc., a venture builder dedicated to developing Enterprise AI product companies across various domains, including AI, Data Engineering, and IoT.\nLearn more about Nuivio at: www.nuivio.com.\n\nJob Summary:\nAs a Senior AI Engineer, the candidate will lead the design, development, and deployment of cutting-edge machine learning and artificial intelligence solutions. The candidate will work closely with cross-functional teams to understand business needs and translate them into scalable AI-driven applications.\n\nKey Responsibilities:\nDesign and implement machine learning models and AI agents/LLMs.\nDevelop and optimize AI pipelines (LLM, RAG, fine-tuning)\nCollaborate with product, engineering, and data teams to define and implement AI-driven features.\nEvaluate model performance and iterate to improve accuracy and efficiency.\nMentor junior engineers and contribute to team best practices.\nStay up to date with state-of-the-art AI technologies and research.\n\nRequired Qualifications:\nBachelors or master’s in computer science, AI, or related field.\n5+ years of experience in AI/ML development.\nExperience working with LLMs, Agentic AI, RAG, and model fine-tuning\nStrong programming skills in Python and familiarity with frameworks such as TensorFlow, PyTorch, and Scikit-learn.\nExperience with cloud platforms (Azure preferred).\nSolid understanding of data preprocessing, model training, validation, and deployment.",Industry Type: Emerging Technologies (AI/ML),Department: Data Science & Analytics,"Employment Type: Full Time, Permanent","['Python', 'Pytorch', 'Azure Cloud', 'RAG', 'LLM', 'Ai Platform', 'AWS', 'Scikit-Learn', 'TensorFlow']",2025-06-11 05:52:57
It Auditor,Hiring for Big4,3 - 7 years,Not Disclosed,"['Bangalore Rural', 'Bengaluru']","Level: Associate Consultant / Consultant / Assistant Manager\nSkills: IT Audit\nLocation: Bangalore(local candidates are preferred)\nNotice period : Immediate to 30 days  \nSkills Required:\nPerform testing of IT Application Controls(ITAC), IPE, and Interface Controls through code reviews, IT General Controls(ITGC) review covering areas such as Change Management, Access Management, Backup Management, Incident and Problem Management, SDLC, Data Migration, Batch Job scheduling/monitoring and Business Continuity and Disaster Recovery\nPerform Risk Assessment, identification, and Evaluation of Controls, prepare process flow diagrams and document the same in Risk & Control Matrix.\nPerform business process walkthrough and controls testing for IT Audits.\nPerforming planning and executing audits, including:\nInformation Security reviews\nInformation Technology Infrastructure reviews\nApplication reviews\nUse extensive knowledge of the client's business/industry to identify technological developments and evaluate impacts on the work to be performed\n                Risk Based IT Internal Audit for Financial Services Entities\n                IT SOX 404 Controls Testing, Quality Assurance\n                Internal Financial Controls related to IT General Controls as part of Financial Statements Audits\n                IT Risk & Control Self-Assessment\n                Business Systems Controls / IT Application Controls\n                Auditing Emerging Technologies such as Cloud Security, Intelligent Automation, RPA, IoT etc.\n       Working knowledge of programming languages(C/C++/Java/SQL)\nConducting IT audits, IT Internal Audit, Robotics Process Automation (RPA) Audits",Industry Type: IT Services & Consulting,Department: Finance & Accounting,"Employment Type: Full Time, Permanent","['ITGC', 'code reviews', 'ITAC']",2025-06-11 05:52:58
Senior Software Engineer,WebMD,5 - 10 years,Not Disclosed,['Navi Mumbai'],"Headquartered in El Segundo, Calif., Internet Brands is a fully integrated online media and software services organization focused on four high-value vertical categories: Health, Automotive, Legal, and Home/Travel. The company's award- winning consumer websites lead their categories and serve more than 250 million monthly visitors, while a full range of web presence offerings has established deep, long-term relationships with SMB and enterprise clients. Internet Brands' powerful, proprietary operating platform provides the flexibility and\nscalability to fuel the company's continued growth. Internet Brands is a portfolio company of KKR and Temasek.\n\nWebMD Health Corp., an Internet Brands Company, is the leading provider of health information services, serving patients, physicians, health care professionals, employers, and health plans through our public and private online portals, mobile platforms, and health-focused publications. The WebMD Health Network includes WebMD Health, Medscape, Jobson Healthcare Information, prIME Oncology, MediQuality, Frontline, QxMD, Vitals Consumer Services, MedicineNet, eMedicineHealth, RxList, OnHealth, Medscape Education, and other owned WebMD sites. WebMD, Medscape, CME Circle®, Medpulse®, eMedicine®, MedicineNet®, theheart.org®, and RxList® are among the trademarks of WebMD Health Corp. or its subsidiaries.\n\nAll qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or veteran status\n\nFor Company details, visit our website: www.webmd.com / www.internetbrands.com\n\nEducation: B.E. Computer Science/IT degree (or any other engineering discipline)\nExperience: 5+ years\nWork timings: 2 PM to 11 PM IST\n\n\nMinimum 5 years experience with\nMinimum 2 years experience with databases other than Oracle/MSSQL/PostgreSQL, such as Vertica, MongoDB, or HDFS/HIVE\nMinimum 5 years hands on\nExperience with\nExperience working closely with Business Intelligence, Finance, Marketing and Sales teams\nKnowledge of scripting languages such as Perl or Python is good to have\nExperience with the reporting platforms such as Tableau or Cognos will be an added advantage\nKnowledge about Web analytics or Business Intelligence is good to have\nKnowledge of GCP is good to have\nExcellent communication and documentation skills\nSelf-motivated with willingness to learn new technologies and business, and willing to take initiative beyond basic responsibilities\n\nDesign, develop and support multiple data projects in traditional relational databases such as Oracle, MSSQL, and PostgreSQL as well as non-traditional databases such as Vertica and MongoDB\nAnalyse business requirements, design, and implement required data model and ETL processes\nParticipate in data architecture and engineering decision making/planning\nCreate an enterprise-level data inventory regardless of source, format, structure\nConnect and integrate individual datasets for better analysis and transparency between the data\nTranslate complex technical subjects into terms that can be understood by both technical and non- technical audiences",,,,"['ETL', 'SQL', 'Data Integration']",2025-06-11 05:53:00
IBM DB2 Database,Acesoft,4 - 6 years,10-12 Lacs P.A.,['Bengaluru'],"Hi all,\nWere Hiring: IBM DB2 Database Administrator (with Data Integration Experience)\nLocation: [Specify location or mention Remote if applicable]\nExperience: 3-6 Years | Notice Period: Immediate – 15 Days\nEmail: mojesh.p@acesoftlabs.com | Contact: 9701971793\nWe’re looking for a highly skilled IBM DB2 DBA & Data Integration Specialist to join our team at Acesoft Labs. If you’re an expert in DB2 installation, administration, and data migration/ETL, this is the opportunity for you!\nKey Responsibilities & Skills:\nStrong hands-on experience with IBM DB2 installation, configuration, and administration\nProficient in data migration across environments (on-prem/cloud)\nExpertise in SQL programming – queries, stored procedures, triggers, and performance tuning\nExperience in designing and implementing data integration and ETL pipelines\nFamiliarity with ETL tools and industry best practices\nStrong grasp of data modeling and relational database structures\nAbility to troubleshoot complex data integration issues efficiently\nExcellent communication and problem-solving skills\nNice to Have:\nExperience with tools like IBM DataStage, Informatica, or SSIS\nExposure to CI/CD in data pipeline deployment\nFamiliarity with data governance and security practices\nIf you’re ready to work on exciting, data-driven projects and bring innovation to database and ETL operations, we want to hear from you!\nApply Now: mojesh.p@acesoftlabs.com\nCall Us: 9701971793",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Temporary/Contractual","['IBM DB2 Database', 'ETL', 'SQL', 'skills', 'data modeling', 'triggers', 'stored procedure']",2025-06-11 05:53:02
Salesforce Devops,Infobeans,5 - 10 years,15-25 Lacs P.A.,['Indore'],Task Description: Skills:\nPipeline Management (> 3 years)\nGitHub Actions\nSonarQube\nFortify\nJenkins Cloudbees\nCopado,,,,"['Jenkins', 'Github Actions', 'Sonarqube', 'Fortify', 'Salesforce', 'Copado', 'apex']",2025-06-11 05:53:03
Senior Teamcenter Developer,IDS Infotech,3 - 7 years,10-13 Lacs P.A.,[],"A Teamcenter Developer is responsible for the development, customization, and enhancement of the Siemens Teamcenter PLM software to align with organizational needs. The developer collaborates with architects, administrators, and business stakeholders to implement robust solutions, ensuring seamless integration, performance, and usability. This role requires hands-on coding, troubleshooting, and implementing new features while adhering to best practices and quality standards.\n\nResponsibilities",,,,"['Teamcenter Development', 'CATIA', 'ITK', 'ERP', 'SOA', 'CAD', 'SQL Server', 'change management', 'RAC', 'TCXML', 'BOM management', 'SolidWorks', 'Oracle']",2025-06-11 05:53:05
Senior NetSuite Engagement Lead - Chennai,Rainbow Integrated Multitech,12 - 22 years,25-27.5 Lacs P.A.,['Chennai( Porur )'],"SME in Field Service Management, Order to Cash, Procure to Pay, Lead to Quote process\nLeverage NetSuite ERP capabilities to assess client requirements\nOversee the entire lifecycle of NetSuite implementation projects, ensuring on-time delivery.\n\nRequired Candidate profile\nNetSuite modules, Field Service, financials,Sales & Operations.\nNetSuite SuiteCloud, SuiteScript, workflows.\nFamiliarity with scripting languages (Suite Script), Suite Analytics,Suite flow\n8072363518",Industry Type: IT Services & Consulting,"Department: Customer Success, Service & Operations","Employment Type: Full Time, Permanent","['Field Service Management', 'Suitescript', 'Netsuite', 'Netsuite Erp', 'Suiteflow', 'ERP', 'Netsuite Scripting', 'Workflow', 'Field Service', 'P2P', 'suite cloud', 'Data Migration', 'ERP Implementation', 'Order To Cash', 'Procure To Pay', 'Netsuite Implementations']",2025-06-11 05:53:06
Oracle Hcm Functional Consultant,Mastek,5 - 10 years,Not Disclosed,"['Pune', 'Ahmedabad', 'Chennai']","IMP Skills: Oracle fusion HCM Functional, Payroll UK / US\n\nJob Location: Ahmedabad, Pune, Chennai, NCR, Bangalore\n\nRole & responsibilities\n\nMust understand Global HR module along with at least one other modules (preferably UK/AMEA Payroll, Absence).\nShould have conducted client Workshops/Solution Designing and Configuration on the module.\nPreferred to have knowledge & experience with data migration to Oracle Cloud.\nAbility to handle multiple tasks simultaneously and switch between tasks quickly.\nMust have experience in migration of setup changes from non-Production to Production environment.\nMust have worked on at least two implementation projects.\nMust be able to manage customer facing role.\nMust be comfortable to travel as per business needs.\nMust be flexible to work in different time-zone as per client meeting schedules.\n\nPreferred candidate profile\nOpen to work from Office in Hybrid mode",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Oracle Payroll', 'Oracle Fusion Hcm', 'ERP Implementation']",2025-06-11 05:53:08
OIC Developer,Elfonze Technologie,3 - 8 years,Not Disclosed,[],"Job Summary:\nWe are seeking a skilled Oracle Integration Cloud (OIC) Developer to design, develop, and implement integrations between Oracle ERP Cloud and various on-premises or third-party applications. The ideal candidate will have hands-on experience with OIC, REST APIs, and BI Publisher (BIP) reports, both seeded and custom. Experience with File-Based Data Import (FBDI) processes is a plus.\nKey Responsibilities:\nIntegration Development: Design and develop integrations using Oracle Integration Cloud to connect Oracle ERP Cloud with other systems.\nAPI Management: Develop and manage RESTful APIs for seamless data exchange between applications.\nReporting: Create and customize BI Publisher (BIP) reports to meet business requirements.\nData Import: Utilize FBDI templates for bulk data uploads into Oracle ERP Cloud.\nCollaboration: Work closely with functional teams to understand integration requirements and deliver solutions accordingly.\nTroubleshooting: Monitor and resolve issues related to integrations and data flows.\nDocumentation: Maintain comprehensive documentation for all integrations and related processes.\nMandatory Skills:\nOracle Integration Cloud (OIC): Proven experience in developing integrations using OIC.\nREST APIs: Strong understanding and hands-on experience with RESTful web services.\nBI Publisher (BIP): Expertise in creating and customizing both seeded and custom BIP reports.\nNice to Have Skills:\nFile-Based Data Import (FBDI): Experience with FBDI processes for data migration into Oracle ERP Cloud.\nSOAP Web Services: Familiarity with SOAP-based integrations.\nOracle ERP Modules: Understanding of Oracle ERP Cloud modules such as Finance, Procurement, and Supply Chain.\nVisual Builder Cloud Service (VBCS): Experience in developing applications using VBCS.",Industry Type: IT Services & Consulting,Department: Other,"Employment Type: Full Time, Permanent","['Oracle Integration Cloud', 'FBDI', 'HDL', 'REST and SOAP APIs', 'BIP reports for data exchange']",2025-06-11 05:53:10
IDMC Manager,Teamware Solutions,5 - 7 years,Not Disclosed,['Bengaluru'],"About the Company\nGreetings from Teamware Solutions a division of Quantum Leap Consulting Pvt. Ltd\n\nAbout the Role\nWe are hiring an IDMC Manager\nLocations: Bangalore\nWork Model: Hybrid\nExperience: 5-7 years\nNotice Period: Immediate to 15 Days\n\nJob Description:\nJD for IDMC Manager: 8+ years of experience in MDM development, with at least 2 years on the Informatica IDMC platform.\n\nJob Description:\n\n""JD for IDMC Manager: 8+ years of experience in MDM development, with at least 2 years on the Informatica IDMC platform. Key Responsibilities: • Lead the development and implementation of MDM solutions on the Informatica IDMC platform. • Design and configure Business 360 (B360), Customer 360 (C360), Product 360 (P360), and Reference 360 (R360) solutions. • Implement match/merge logic, survivorship rules, business validations, and workflow orchestration using Cloud Application Integration (CAI). • Configure Data Quality (DQ) services and perform data profiling to support cleansing and validation processes. • Integrate MDM with enterprise systems such as ERP, CRM, and data warehouses using IDMCs standard connectors, APIs, and real-time integration patterns. • Collaborate with data architects, business stakeholders, and project teams to gather requirements and translate them into scalable MDM solutions. • Utilize data modeling best practices to design and maintain golden records for domains like Customer, Product. • Work with real-time REST APIs exposed by Informatica for operations such as search, create, update, and delete. • Provide leadership in solution design reviews, troubleshooting, performance tuning, and production support. JD for IDMC Developer: 4+ years of experience in MDM development, with at least 1 year on the Informatica IDMC platform. Key Responsibilities: • Develop and implement Master Data Management (MDM) solutions on the Informatica IDMC platform. • Configure and maintain IDMC components such as Customer 360 (C360), Product 360 (P360), Business 360 (B360), and Reference 360 (R360). • Design and implement match rules, business rules, survivorship rules, and data validations. • Build and orchestrate workflows using Cloud Application Integration (CAI). • Perform data profiling and implement data quality (DQ) rules and transformations. • Develop data pipelines and workflows using IDMC Data Integration service. • Integrate IDMC MDM with external systems like ERP, CRM, and data lakes using connectors and APIs. • Use real-time REST APIs provided by IDMC for operations such as search, create, update, and delete. • Collaborate with data architects, analysts, and business users to gather requirements and deliver scalable solutions.""\n\nAdditional Information:\n\nMandatory Skills IDMC MDM\nNice to have skills CDQ, IDQ\nInterview Mode Virtual Interview\n\nPlease let me know if you are interested in this position and send me your resumes to netra.s@twsol.com",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Informatica Mdm', 'IDMC', 'IDMC MDM', 'Master Data Management', 'CDQ', 'Idq', 'Informatica']",2025-06-11 05:53:12
Sap Mm Consultant,Pan Asia,11 - 18 years,Not Disclosed,"['Chennai', 'Bengaluru', 'Delhi / NCR']","Job Title: SAP MM Consultant S/4HANA (10+ Years Experience)\nLocation: Bangalore / Kolkata / Pune / Hyderabad / Chennai / Bhubaneswar / Delhi / Gurgaon\nExperience Required: 10+ years\nEmployment Type: Full-time\nFace To Face Interview: 13th & 14th June 2025\n\nJob Description:\nWe are seeking a highly experienced SAP MM (Materials Management) Consultant with a strong background in S/4HANA implementations to join our dynamic team. The ideal candidate should have a proven track record of delivering end-to-end implementations, enhancement projects, and system integrations using SAP MM in S/4HANA environments.\n\nKey Responsibilities:\nLead or support end-to-end S/4HANA implementations (minimum 1-2 full lifecycle projects).\nDesign, configure, and deploy SAP MM solutions to meet business requirements.\nCollaborate with cross-functional teams to integrate MM with other SAP modules (SD, PP, FI, etc.).\nWork on enhancements, custom developments, and functional specifications.\nDevelop and support interfaces, including IDocs, BAPIs, and middleware.\nSupport Fiori app integration and usability enhancements in SAP MM workflows.\nPerform unit testing, system integration testing, and user acceptance testing.\nProvide post-go-live support and user training.\nAct as a SME for SAP MM in S/4HANA projects, upgrades, and transformation initiatives.\n\nKey Skills & Qualifications:\n10+ years of relevant SAP MM experience, including configuration and process knowledge.\nMinimum 1-2 end-to-end S/4HANA implementation projects.\nStrong experience with enhancements, customizations, and integrations in SAP MM.\nHands-on experience in working with IDocs, BAPIs, and data migration tools.\nProficiency in Fiori applications relevant to MM.\nStrong communication, client-facing, and stakeholder management skills.\nBachelor's degree in Engineering, Computer Science, or related field; SAP Certification (preferred).\n\nNice to Have:\nExposure to Agile project methodologies.\nExperience working in global delivery models.\nKnowledge of Ariba, SRM, or other procurement tools is a plus.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['SAP MM', 'S4 Hana', 'IDOC', 'SAP MM Implementation', 'Fiori Apps', 'Material Management']",2025-06-11 05:53:13
Syniti ADM For SAP - Application Developer/Lead,Fortune Global 500 IT Services Firm,5 - 10 years,Not Disclosed,"['Hyderabad', 'Pune', 'Bengaluru']","Roles & Responsibilities:\n- Expected to be an SME\n- Collaborate and manage the team to perform\n- Responsible for team decisions\n- Engage with multiple teams and contribute on key decisions\n- Provide solutions to problems for their immediate team and across multiple teams\n- Lead the application development process\n- Ensure successful project delivery\n- Mentor junior team members\n\nProfessional & Technical Skills:\n- Must To Have Skills: Proficiency in Syniti ADM for SAP\n- Good To Have Skills: Experience with SAP HANA DB Administration, SAP BusinessObjects Data Services, SAP Legacy System Migration Workbench\n- Strong understanding of SAP data migration tools\n- Experience in SAP application development\n- Knowledge of SAP data management best practices\nLocation- Pan India\nEmail me- maya@mounttalent.com",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Syniti', 'Syniti Adm', 'Sap Bods', 'Sap Data Services', 'Sap Module', 'Data Migration', 'Syniti ADM for SAP', 'SAP data migration', 'SAP BusinessObjects Data Services', 'Sap Configuration', 'SAP HANA DB Administration', 'Data Services', 'Sap Integration', 'SAP Implementation', 'ADM for SAP']",2025-06-11 05:53:15
Opening For SAP MM with SAP Company,Kaar Technologies,3 - 8 years,Not Disclosed,"['Chennai', 'Bengaluru']","Job Title: SAP MM Consultant\nExperience Required: 3 to 8 Years\nWork Locations: Chennai / Bangalore\nJob Type: Full-Time\nEmployment Type: Permanent\n\nJob Description:\nWe are looking for a skilled and experienced SAP MM (Materials Management) Consultant with 3 to 8 years of hands-on experience in SAP implementation and support projects. The ideal candidate will have strong domain knowledge, good communication skills, and the ability to work independently or as part of a team in a dynamic environment.",,,,"['SAP MM', 'Implementation And Support', 'HANA']",2025-06-11 05:53:17
SAP MM Senior Consultant,Sopra Steria,10 - 15 years,Not Disclosed,['Noida'],"We are looking for a highly experienced Senior SAP MM Consultant with deep expertise in S/4HANA Cloud to join our team. The ideal candidate will bring 14+ years of SAP MM implementation experience, including hands-on involvement in Greenfield S/4HANA projects (preferably in European contexts), and possess the ability to lead end-to-end project life cycles, collaborate with global stakeholders, and ensure solution excellence across business processes.\nLocation: Chennai / Noida\nExperience: 14 – 18 years",,,,"['pp', 'sap master data', 'pvcs', 'fi', 'logistics', 'sales process', 'data migration', 'sap cpq', 'sap s hana', 'sap mm module', 'manufacturing', 'sap mm', 'material ledger', 'flow', 'mm', 'greenfield', 'sap', 'saps', 'software testing', 'european', 'variant configuration', 's', 'business process', 'sap mm implementation', 'integration', 'vc++', 'abap']",2025-06-11 05:53:19
Database Administrator (DBA),Mynd,6 - 10 years,11-12 Lacs P.A.,['Gurugram'],"Immediate openings for the position of Database Administrator (DBA) for one of the reputed company Mynd Integrated Solutions located in Gurgaon Sector 68\nKey Skills : Hands on Experience in MS SQL and My SQL is Mandatory\nNotice Period: Immediate joiners are preferred\nExperience: 7-10 Years\nQualification: Any Graduation\nCTC that we can offer: 12 LPA\nIt is work from office from Day 1 (5 days working)\nJob Location: Gurgaon Sector 68\nInterested and serious candidates can send me your updated CV on\nvishnu.peramsetty@myndsol.com\nFeel free to contact me for further clarifications if any -- Vishnu Vardhan - 8332951064\n\nJD For DBA\n-----------------\n**Responsibilities: **\n* Install, configure, and maintain database Servers.\n* Develop, implement, and test database backup and recovery plans.\n* Ensure database security, integrity, and availability.\n* Monitor database performance, identify bottlenecks, and implement optimizations.\n* Troubleshoot database issues and provide timely resolutions.\n* Develop and maintain database documentation, including standards, procedures etc.\n* Collaborate with development teams to design and implement efficient database schemas.\n* Perform database upgrades and migrations.\n* Implement and maintain database security measures, including user access control and auditing.\n* Stay up-to-date with the latest database technologies and best practices.\n* Experience of ETL tools for data migration between various instances of SQL Engines\n* Configuring of Audit policies on database and the way of its monitoring\n* Creating Database Tasks, Jobs\n* Good understanding of RBAC of different SQL Engines\n**Qualifications: **\n* Bachelor's degree in Computer Science or a related field (or equivalent experience).\n* Proven experience as a Database Administrator.\n* Strong knowledge of MS SQL, MySQL, PostgreSQL.\n* Experience with database backup and recovery procedures.\n* Understanding of database security principles and practices.\n* Proficiency in database performance tuning and optimization.\n* Excellent troubleshooting and problem-solving skills.\n* Strong communication and collaboration skills.\n* Ability to work independently and as part of a team.\n* Should have an experience of Change Management and Incident Management\n* Should have experience of writing CRON/Batch jobs for automation\n**Good-To-Have: **\n* Experience of managing NoSQL databases preferably MongoDB Atlas.\n* Indexing, Backup, Restoration of Collections, Configuring Audit Policies",Industry Type: BPM / BPO,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['Database Administration', 'Ms Sql Server Administration', 'MySQL Database Administration']",2025-06-11 05:53:20
Oracle Fusion Scm Consultant,Infidocs Technologies,7 - 10 years,Not Disclosed,['Qatar'],"Roles and Responsibilities\nTroubleshoot issues related to data migration, system configuration, and application performance.\nDevelop reports and dashboards using BIP (Business Intelligence Publisher) to provide actionable insights to stakeholders.\nImplement and configure Oracle Fusion SCM applications to meet client needs, ensuring seamless integration with other systems.\nCollaborate with clients to understand their business requirements and design solutions using Oracle Fusion SCM Cloud.\nProvide expert-level support for Oracle Fusion SCM modules such as Procurement, Inventory, Order Management, and Supply Chain Planning.\nDesired Candidate Profile\n7-10 years of experience in implementing Oracle Fusion SCM projects or similar ERP systems.\nStrong understanding of Oracle Scm Cloud architecture and its various modules including Procurement, Inventory, Order Management, etc. .\nProficiency in developing complex queries on SQL Server for reporting purposes.\nExperience working with Agile methodologies and ability to work collaboratively within a team environment.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Temporary/Contractual","['Oracle Fusion Scm', 'Oracle Supply Chain Management', 'Oracle Inventory', 'Oracle Scm', 'Fusion Scm', 'Scm Cloud', 'Fusion Procurement', 'Oracle Order Management']",2025-06-11 05:53:22
Erp Support & Implementation Engineer,Zipbooks Software Solutions,1 - 6 years,Not Disclosed,['Ahmedabad( Ahmedabad Cantonment )'],"We are looking for a hands-on ERP Support & Implementation Engineer to join our team. The ideal candidate should have prior experience working with ERP systems, handling client support, troubleshooting functional and technical issues, and assisting in ERP implementations.\nKey Responsibilities:\nProvide day-to-day support to end users for ERP-related queries, issues, and troubleshooting.\nCollaborate with internal teams and clients to gather requirements and assist in ERP system implementation.\nPerform initial system setups, user configurations, and data migration activities.\nMonitor system performance and coordinate with technical teams for resolution of bugs or integration issues.\nConduct user training sessions and prepare user manuals or support documents as required.\nAssist in testing new features and updates before deployment.\nMaintain detailed records of client issues, resolutions, and ongoing support activities.\nRequired Skills and Experience:\n1 to 5 years of experience in ERP support and implementation.\nStrong understanding of ERP processes (finance, inventory, purchase, sales, etc.).\nFamiliarity with any ERP platform .\nGood problem-solving and communication skills.\nExperience in client handling and providing remote or onsite support.\nAbility to work independently and manage multiple support tickets or tasks.\nPreferred:\nBackground in IT, Computer Science, or related technical field.\nBasic knowledge of SQL or system integrations is a plus.Role & responsibilities",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['Erp Support', 'ERP Implementation', 'Technical Support', 'Crystal Report', 'Support Services']",2025-06-11 05:53:23
Principal Software Engineer (Full Stack),Insightsoftware,10 - 14 years,Not Disclosed,['Hyderabad'],"We are looking for future Insighters who can demonstrate teamwork, results orientation, a growth mindset, disciplined execution, and a winning attitude to join our growing team.\n\n Role Principal Software Engineer \n\ninsightsoftware is seeking a Principal Software Engineer to join our team. The ideal candidate will have a strong full-stack development background, with expertise in Java coding, particularly using Spring Boot for backend development. Additionally, proficiency in front-end technologies, especially ReactJS/Vue.js, is essential.\n\nThis critical role would requireworking with the development team to ensure accessibility for all users by developing a front end that functions across browsers, platforms, and devices while meeting accessibility and security requirements.\n\nWe provide powerful tools to our clients which empower enterprises and organizations in business planning, consolidation, and performance monitoring.\n\nAre you ready to lead in this new era of technology and solve Enterprise Performance Management’s most challenging problems\n\nOur Engineering team\n\nOur engineers participate in all phases of the application development lifecycle, focusing on design, coding, and keeping the production platform up and running.\n\nOur engineering culture also values curiosity, humility, trust and team spirit.\n\nOur technical stack is Java with Spring Boot and Hibernate frameworks, SQL, ORM, JPA, Vue.js, JavaScript, SCSS, Amazon Web Services, Maven\n\n This is What You Will do in This Role: \nDesign, develop, and maintain complex web applications using Vue.js and associated frameworks.\nLead the architecture and design of scalable frontend applications.\nCollaborate with backend developers to integrate APIs and ensure seamless functionality.\nMentor junior developers, conduct code reviews, and ensure adherence to best practices.\nOptimize applications for maximum speed, scalability, and performance.\nStay updated with the latest trends and advancements in Vue.js and frontend development.\nDebug and troubleshoot application issues to maintain high quality and performance.\nWork with Quality Assurance (QA) team to get the product tested, address any issues\n\n\n Qualifications \n\n  - \n10-14 years of web application development experience in afast-pacedagile environment experience required\nProficiency in Springboot and ReactJS/ Vue.js ecosystem (Vue Router, Vuex/Pinia, Composition API).\nStrong experience with JavaScript, TypeScript, HTML, and CSS.\nFamiliarity with modern build tools (e.g., Webpack, Vite).\nKnowledge of RESTful APIs and integration techniques.\nFamiliarity with version control systems like Git.\nStrong problem-solving skills and attention to detail.\nExcellent communication and leadership skills.\nCollaborate with team members to define project requirements, priorities, and timelines.\n\n\n Additional Information \n\n**  At this time insightsoftware is not able to offer sponsorship to candidates who are not eligible to work in the country where the position is located . **\n\ninsightsoftware About UsHear From Our Team - InsightSoftware (wistia.com)\n\nBackground checks are required for employment with insightsoftware, where permitted by country, state/province.",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['css', 'vue.js', 'react.js', 'html', 'javascript', 'vuex', 'hibernate', 'java coding', 'hibernate framework', 'sql', 'spring', 'java', 'git', 'webpack', 'jpa', 'typescript', 'sass', 'api', 'rest', 'frontend development', 'vue cli', 'maven', 'orm', 'spring boot', 'full stack', 'aws', 'web application development']",2025-06-11 05:53:25
Functional Consultant - HCM with Basic GL knowledge,Smartncode,8 - 10 years,Not Disclosed,[],"We are looking for an experienced Functional Consultant HCM with Basic GL knowledge to join our ERP consulting team. The ideal candidate will have a strong understanding of Human Capital Management (HCM) modules along with foundational knowledge in General Ledger (GL). This role will involve client interaction, requirements gathering, system configuration, testing, and support across HCM and GL modules.\nKey Responsibilities:\nGather and analyze business requirements related to HCM and GL processes.\nConfigure and implement HCM modules (Core HR, Payroll, Absence, Performance, etc.) and basic General Ledger functions.\nPrepare functional design documents and work with technical teams for any custom developments.\nConduct testing (unit, system, UAT) and resolve issues in coordination with the client and internal stakeholders.\nTrain end-users and prepare user manuals and documentation.\nSupport ongoing maintenance and troubleshooting post go-live.\nLiaise with cross-functional teams to ensure smooth project delivery and support.\nStay updated with ERP/HCM best practices and recommend improvements where necessary.\nRequired Skills & Qualifications:\n8–10 years of functional consulting experience in HCM modules (Oracle Fusion HCM / EBS / SAP / any ERP).\nStrong knowledge of Core HR, Payroll, and at least one additional HCM sub-module.\nWorking knowledge of General Ledger (GL) and basic finance integrations.\nExperience in preparing documentation like BRDs, FRDs, test cases, and training materials.\nProven track record of successful end-to-end ERP implementations.\nExcellent communication, presentation, and stakeholder management skills.\nAbility to work independently and collaboratively in a team environment.\nPreferred Qualifications:\nCertification in HCM or ERP modules (e.g., Oracle HCM Cloud Certified).\nPrior experience with cloud ERP systems (like Oracle Fusion, Workday, SAP SuccessFactors).\nExposure to integration tools or middleware is a plus.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['HCM', 'UAT processes', 'ERP', 'Data Migration', 'GL', 'EBS', 'Core HR']",2025-06-11 05:53:27
SAP Group reporting,SRS Infoway,4 - 7 years,18-20 Lacs P.A.,"['Noida', 'Hyderabad', 'Pune']","Hiring SAP Group Reporting Consultant (4–7 yrs) for Noida/Hyd/Pune. Must have GR implementation, BPC/FICO migration, table-level knowledge, and strong FICO consolidation. Join in 20 days.\nMail:kowsalya.k@srsinfoway.com",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['GR tables', 'BPC/FICO', 'SAP Group reporting', 'FICO consolidation', 'data migration']",2025-06-11 05:53:28
.NET Software Developer,NeoSOFT,3 - 8 years,10-20 Lacs P.A.,"['Ahmedabad', 'Bengaluru', 'Mumbai (All Areas)']","Designing, Developing, and Delivering scalable web applications using ASP.Net Core and Angular.\nMonitor cloud infrastructure (AWS), implement CI/CD pipelines.\nStrong hands-on experience with ASP.Net Core (MVC & Web API).\n\nRequired Candidate profile\nASP.Net Core\nAngular (latest versions preferred)\nAWS (Amazon Web Services)\nMongoDB\nAzure",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['ASP.Net', 'Microsoft Azure', 'MongoDB', 'AWS', 'Angular', 'Aws Cloud', 'Azure Cloud']",2025-06-11 05:53:30
Oracle Apps Dba Consultant,E Solutions It Services,4 - 7 years,2-7 Lacs P.A.,['Navi Mumbai'],"Location: Navi Mumbai\n\nRole & responsibilities\nRequirements and Skills\nOracle EBS Administration: Manage Oracle E-Business Suite (EBS) systems, including Concurrent Manager administration tasks.\nMiddleware Support: Support Oracle WebLogic Server administration (a plus).\nData Migration: Assist with data migrations and schema updates.\nTechnical Expertise: Possess strong expertise in EBS R12.2.x system administration.\nSQL and PL/SQL: Review and provide recommendations to tune SQL and PL/SQL code.\nWait Events: Proactively review wait events and provide recommendations.\nRequirements and Skills\nStrong knowledge of EBS 12.2 architecture, including WebLogic, Oracle Fusion Middleware, and database dependencies.\nExperience with EBS upgrades, especially from 12.2.5 to 12.2.14.\nHands-on expertise in ADOP (Online Patching) and patch management.\nTroubleshooting and performance tuning of EBS components (Forms, Concurrent Managers, Workflow, etc.).\nExperience with WebLogic Server upgrade from 12.2.1.3 to 14.1.\nConfiguration of WebLogic domain, managed servers, clusters, and Node Manager.\nExperience with IDCS, Asserter SSO integration with WebLogic.\nHands-on experience with Oracle Database 19c (Multitenant).\nExperience with DataGuard, RMAN backup & restore.\nUnderstanding of performance tuning, AWR, ASH, and optimizer improvements.\nExperience applying Critical Patch Updates (CPU), one-off patches, and consolidated patches.\nKnowledge of adpatch, adop (Online Patching), and patch merging.\nHands-on experience in cloning multi-node environments.\nExperience with Oracle Wallet, encryption, and auditing.\nProficiency in SQL and SQL server tools\nAdvanced understanding of database security, backup and recovery, and performance monitoring requirements\nModelling of relational and dimensional data\nPowerShell and Unix shell scripting abilities are required.\nImpeccable attention to detail, excellent mathematics, and statistical expertise\nStrong written and oral communication abilities\nBachelor's degree in IT or a similar discipline\nKnowledge of Linux and Windows Server infrastructures\nThorough understanding of database technologies (MySQL, MS SQL, Oracle)\nKnowledge of Oracle Real Application Clusters (RAC), ASM, Disaster Recovery (DR) and Active Data Guard, ORDS.\nPrior knowledge of DBA case tools (frontend/backend) and third-party tools is required.\nExtensive knowledge of database standards and end-user applications and the ability to translate capacity needs into infrastructure deployment technologies.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Temporary/Contractual","['Oracle Apps Dba', 'Dataguard', 'Exadata', 'RAC', 'Datapump', 'Oracle RAC', 'Golden Gate', 'RMAN']",2025-06-11 05:53:32
Sap Fico Lead (Only Immediate Joiners),Callaway Digital Technologies,8 - 13 years,Not Disclosed,['Hyderabad'],"JOB OVERVIEW\nSAP Finance Lead will be the functional lead for retail processes and capabilities and be an advocate for both business and technology decisions within our global IT organization.\nThis position is responsible for the design and management of business system solutions for Callaway Golf. We leverage ECC and SAP S/4. The incumbent will partner with corporate IT, business leaders and stakeholders to identify solutions to business needs, leveraging technology to add value to the company.\nMust have superior business relationship skills and functional knowledge with change management experience. Our company is going through a technology evolution and this role will be key to many of these initiatives. This role will need to be a strong team leader who can develop their own resources while building strong cross-team collaboration and solutions.",,,,"['SAP FICO', 'FICO', 'S/4HANA', 'ECC', 'FSCM']",2025-06-11 05:53:33
DevOps Engineer - Salesforce,Infogrowth,5 - 8 years,Not Disclosed,['Indore'],"Hiring Salesforce DevOps Engineer with 5+ years of experience in SFDX CLI, Apex, GitHub Actions, Jenkins, Copado. Role includes CI/CD pipeline management, code quality automation, and performance optimization.\n\nRequired Candidate profile\nSalesforce DevOps Engineer with expertise in SFDX CLI, CI/CD tools, Apex, and performance tuning. Skilled in GitHub Actions, Jenkins, Copado, and code quality tools.\n\n\n\n\n\n\n\n\n\n.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['SFDX CLI', 'Github Actions', 'Jenkins Cloudbees', 'Copado', 'Salesforce Devops', 'DevOps Pipeline Management', 'Salesforce Performance Optimization', 'Sonarqube', 'Fortify', 'Lightning Web Components', 'Data Migration', 'Service Cloud', 'CI/CD', 'Aura', 'Apex', 'Visualforce']",2025-06-11 05:53:35
Consultant - MDM IDQ Developer,Thryve Digital,6 - 9 years,Not Disclosed,"['Hyderabad', 'Chennai']","Role Summary:\nDrive the end-to-end solution architecture of MDM solutions including data model definition and refinement, data quality assessment and remediation design, data migration strategy, data stewardship process and system interaction design.\nUnderstand the technical landscape current as well as desired future state Assess the current state architecture & understand current business processes for managing Master Data Management solutions.",,,,"['Mdm Informatica', 'Idq', 'Cloud MDM']",2025-06-11 05:53:36
Informatica Developer,bourntec solutions,6 - 11 years,Not Disclosed,['Hyderabad'],"Position: Informatica Developer\nLocation: India\nExperience: 6+ Years\nAbout the Role:\nWe are looking for an experienced Informatica Developer (IDMC) to design, build, and manage cloud-based data integration solutions. This role focuses on managing batch processes and ensuring seamless data exchange across systems.\nKey Responsibilities:\nDesign and implement data integration workflows using Informatica Intelligent Cloud Services (IDMC).\nDevelop and maintain Salesforce-centric data pipelines, including data extraction, transformation, and loading (ETL).\nManage and optimize batch processes to handle large volumes of Salesforce data.\nEnsure accurate and efficient data movement between Salesforce and other applications/databases.\nIdentify and resolve integration-related issues and optimize performance.\nCollaborate with business and technical teams to gather integration requirements.\nMaintain detailed technical documentation for integration components and processes.\nKey Skills & Experience:\nHands-on experience in Informatica Cloud (IDMC) development.\nMandatory experience in Salesforce data integration and understanding of Salesforce objects, data model, API usage, and best practices.\nProficiency in designing cloud data integration workflows and batch processes.\nGood understanding of various data sources and cloud databases, APIs, flat files.\nStrong analytical, debugging, and troubleshooting abilities.\nAbility to work both independently and within cross-functional teams.",Industry Type: IT Services & Consulting,Department: IT & Information Security,"Employment Type: Full Time, Permanent","['Cloud Data Migration', 'Informatica Development', 'Application Integration', 'Salesforce data integration', 'Salesforce Database', 'Informatica', 'Data Modeling', 'ETL Tool', 'API usage', 'Flat Files', 'Data Integration']",2025-06-11 05:53:37
Palantir Developer,Algoleap Technologies,5 - 10 years,Not Disclosed,['Hyderabad'],"Work Responsibilities\n\nThe Palantir Developer will be responsible for designing and implementing modern data architecture solutions that facilitate enterprise-level transformation. Key responsibilities include:\n\nData Architecture Design: Create and optimize modern data architectures that support advanced analytics and operational requirements.\n\nPipelining: Develop and maintain efficient data pipelines using Palantir Foundry to ensure seamless data flow and accessibility for analytics.\n\nAdvanced Analytics: Create and deploy advanced analytics products that provide actionable insights to stakeholders, enhancing decision-making processes.\n\nArtificial Intelligence Integration: Collaborate with data scientists to incorporate AI and machine learning models into data pipelines and analytics products, enabling predictive capabilities.\n\nAgentic AI Exposure: Leverage knowledge of Agentic AI to develop systems that can autonomously make decisions and take actions based on data insights, enhancing operational capabilities.\n\nCollaboration: Work closely with cross-functional teams, including data scientists, engineers, and business analysts, to gather requirements and deliver tailored solutions.\n\nCloud Technologies: Utilize cloud-based tools and services to enhance scalability, security, and performance of data solutions.\n\nBest Practices: Implement best practices for data governance, quality, and security to maintain data integrity and compliance with relevant regulations.\n\nContinuous Improvement: Identify opportunities for process improvements and automation to enhance operational efficiency within data ecosystems.\n\nDocumentation: Maintain comprehensive documentation of data architecture designs, pipeline configurations, and analytics processes.\n\n\n\nArtificial Intelligence & Data Engineering: In this age of disruption, organizations need to embrace data-driven decision-making to\n\nDeliver Enterprise Value. Our Team Leverages Data, Analytics, Robotics, And Cognitive Technologies To Uncover Insights And Drive Transformation In Business. Key Initiatives Include\n\nData Ecosystem Implementation: Collaborate with clients to implement large-scale data ecosystems that integrate structured and unstructured data for comprehensive insights.\n\nPredictive Analytics: Utilize machine learning and predictive modeling techniques to derive actionable insights and predict future scenarios.\n\nAI Solutions Development: Work on developing AI-driven solutions that enhance data analytics capabilities, including natural language processing (NLP), computer vision, and recommendation systems.\n\nAgentic AI Development: Engage in projects that involve the development and deployment of Agentic AI systems capable of autonomous decision-making and action-taking based on real-time data.\n\nOperational Efficiency: Drive operational efficiency by utilizing automation and cognitive techniques for data management, ensuring timely and accurate reporting.\n\nClient Engagement: Engage with clients to understand their unique challenges and tailor solutions that align with their strategic objectives.\n\nInnovative Solutions: Research and implement innovative technologies and methodologies that enhance data analytics capabilities and drive business value.\n\nTraining and Support: Provide training and support to clients on data tools and platforms to ensure they can maximize the value of their data assets.\n\n\n\nRequired:\n\nEducation: Bachelors degree in Computer Science, Data Science, Engineering, or a related field.\n\n\n\n3+ years of hands-on experience in data extraction and manipulation using various tools and programming languages.\n\n3+ years of experience in engineering and developing Palantir pipelines, with a strong understanding of data integration techniques.\n\n3+ years of experience collaborating with Palantir Foundry data scientists and engineers on complex data projects.\n\n2+ years of experience working with AI and machine learning technologies, including model development, deployment, and performance tuning.\n\nFamiliarity with Agentic AI concepts and applications, including experience developing or working with autonomous systems is a plus.\n\nTechnical Skills: Proficiency in programming languages such as Python, SQL, or R, along with experience in statistical analysis and machine learning techniques.\n\nProblem-Solving: Strong analytical and problem-solving skills, with the ability to think critically and creatively.\n\nCommunication: Excellent interpersonal and communication skills to effectively convey technical concepts to non-technical stakeholders.",,,,"['Palantir Pipelines', 'Data Extraction', 'Agentic Ai', 'R', 'Artificial Intelligence', 'Palantir Foundry', 'Performance Tuning', 'manipulation', 'Machine Learning', 'Model Development', 'Python', 'SQL']",2025-06-11 05:53:39
Dot Net Fullstack Developer,BriskWin IT (BWIT),6 - 11 years,Not Disclosed,"['Pune', 'Chennai', 'Mumbai (All Areas)']","Req 1. Microsoft Cloud .Net + Angular + React (Basics)\nExp: 6 to 12 Yrs\nNP : Immediate to 15 Days (Serving Notice Max 20 Days)\nLocation Chennai / Mumbai / Pune / Bangalore\n\nReq 2. API Technical Lead Azure Cloud Integration\nExp: 9+ yrs\nNP : Immediate to 30 Days\nLocation: Chennai, Mumbai, Pune, Noida, Ahmadabad, Bangalore\n\nKey Skills & Experience:\n\nProven experience in a technical leadership role focused on backed/API development, with strong proficiency in Java.\nIn-depth knowledge of Microsoft Azure services, including:\nAzure Table Storage\nAzure Data Lake Storage Gen2\nAzure Functions\nAzCopy for efficient data migration to Azure( Good to have )\nStrong grasp of Restful API design principles, cloud-native architectures, and server less computing models",Industry Type: IT Services & Consulting,Department: Engineering - Software & QA,"Employment Type: Full Time, Permanent","['.Net Core', 'Cloud', 'React.Js', 'Angular']",2025-06-11 05:53:40
Sap Abap Consultant,Tech Mahindra,6 - 10 years,13-23 Lacs P.A.,['Hyderabad'],"Role & responsibilities\n\nCustom SAP Development: Designing and developing custom SAP solutions to meet business requirements, using programming languages such as ABAP (Advanced Business Application Programming) or SAPUI5.\nIntegration: Integrating SAP with other systems and applications within the organization's IT landscape.\nWorking with various integration technologies and platforms to ensure seamless data exchange and process workflows.\nSystem Configuration and Customization: Configuring SAP modules according to business needs.\nData Management and Migration: Managing SAP data and ensuring its accuracy and integrity. Performance Tuning: Optimizing SAP applications and systems for better performance.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['SAP ABAP', 'SAPUI', 'Data Management', 'Workflow', 'Sap Integration', 'Data Migration']",2025-06-11 05:53:42
SAP SD & PLM PP Functional Consultant,BIBA Fashion Ltd,1 - 4 years,5-6 Lacs P.A.,['Gurugram'],"About BIBA\nBIBA Fashion Limited, the Indian fashion giant, stands true to its name. The brand has\nbeen dressing and embellishing demure maidens from every corner of India since 1986.  With\nBIBA, always expect a truly unique, wow-inspiring ethnic experience!\nhttps://www.biba.in\n\nPurpose of the Job\n• Functional Support in SAP - SD (Sales & Distribution) & PLM (Product Lifecycle\nManagement) Or Production Planning\n• Testing of new Customized / Installed processes as per BIBA Policy/Processes.\n• Training of SAP SD & PLM Or PP to End Users.\n\nKey Result Areas for the Incumbent\nProcess Responsibilities\n• Understanding & Expertise in SAP SD, PLM or PP modules.\n• Gather business requirements and design end-to-end SD processes in S/4HANA.\n• Configure SAP SD modules (Order to Cash, Pricing, Billing, Shipping, Credit Management,\netc.) to meet business needs.\n• Work closely with cross-functional teams (FI, MM, PP, WM, TM) to ensure seamless\nintegration.\n• Design and implement business process improvements and enhancements in SAP SD.\n• Support SAP S/4HANA implementation, data migration, cutover activities, and go-live.\n• Conduct user training, prepare documentation, and provide post-go-live support.\n• Analyse and resolve issues in existing SD processes (support & AMS).\n• Work with Fiori apps and leverage innovations available in S/4HANA SD.\n• Participate in Fit-Gap analysis and contribute to solution design workshops.\n• Prepare Functional Specifications for RICEFW (Reports, Interfaces, Conversions,\nEnhancements, Forms, Workflows).\n• Should have clear understanding of Master Data Management in Fashion\n• Should have clear understanding on Vendor Master Data Management\n• Knowledge of SAP Fashion Vertical, Product Lifecycle Management Tools will be an\nadded advantage.\n• Must have at least 1 implementation experience in SD & PLM or PP\n• Understanding of third party interfaces, IDocs and integration\n• Strong project documentation such as AS-IS, TO-BE/BBP, Functional Specifications, KDS\netc\n• Must understand users requirements and build solutions\n• Should be able to work with the Technical team for custom solutions\n• Excellent client interactions & handling\n• Excellent communication & presentation skills\n• Understanding of master data and cut over data for go-live, must have done cut-over\nindependently\n• Integration & basic Knowledge of other modules like FI/WM/QM \n• Should have clear understanding of SD (Sales and Distribution) module.\n• Should have clear understanding of pricing procudure.\nSAP Experience\nAt Least 1-3 years as SAP SD & PLM Consultant",Industry Type: Textile & Apparel (Fashion),Department: IT & Information Security,"Employment Type: Full Time, Permanent","['SAP SD', 'SAP PP', 'SAP PLM']",2025-06-11 05:53:43
Sap Plm PP Consultant,Cyient,4 - 7 years,Not Disclosed,['Pune'],"Required Skills: A minimum of 3 years of experience in the design, configuration, testing, and integration of complex SAP PLM / PP solutions. Essential: At least 3 years of demonstrated expertise in SAP configuration for Material, ECM, BOM, and DIR. Essential: A minimum of 3 years of experience in systems integration technologies, specifically PI and MB support. Essential: At least 3 years of experience in the design, development, and testing of utilities for PLM data migration tools, or experience with SAP LSMW/BODS. Desired Skills: Experience working in an Agile/Scrum team environment and familiarity with active control tools.",Industry Type: IT Services & Consulting,Department: Consulting,"Employment Type: Full Time, Permanent","['SAP PLM', 'SAP PP', 'Bom Preparation', 'Sap Lsmw', 'Bom', 'Sap Bods', 'SAP Production Planning', 'SAP PP Module', 'ECM']",2025-06-11 05:53:45
