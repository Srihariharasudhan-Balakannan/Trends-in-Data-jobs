job_title,company_name,experience,salary,location,industry,job_description,skills,scraped_at
Data Architect,Virtusa,9-13 Years,,Chennai,Consulting,"Bachelor's Degree or equivalent number of years of experience in a Computer Science or Data Management related field.\nExperience in leading and delivering enterprise data platform architectural thinking, and its practical application.\nExperience in the use of conceptual and logical data modelling technologies.\nExperience in defining and working with information and data regulatory governances.\nThe role holder will possess a blend of data/information architecture, analysis, and engineering skills.\nExperience in known industry IT architectural patterns and IT architecture ways of working/methodologies (e.g. FAIR data principles, Data Mesh).\nUnderstanding the appropriate data structure and technology based on business use case and completely familiar with data lifecycles.\nDesirable:\nExperience in a data architect role with practical examples of designing and providing data engineering/architectural blueprints that have been implemented.\nExperience of Information and Data Governance frameworks and their application in a commercial organization.\nUnderstands Data Platforms concepts and cloud-based containerization strategies for hybrid cloud environments.\nExperience in Agile data definition scrums.\nExperience in the use of tooling, e.g. metadata cataloguing tools, data modelling tools, EA tools.\nUnderstanding of or familiarity with,Data Mesh approaches (as distinct from Data Fabric or Data Platform).\nQualification\nDetailed Job Description forInformation Architect at PAN India:\nBachelor's Degree or equivalent number of years of experience in a Computer Science or Data Management related field.\nExperience in leading and delivering enterprise data platform architectural thinking, and its practical application.\nExperience in the use of conceptual and logical data modelling technologies.\nExperience in defining and working with information and data regulatory governances.\nThe role holder will possess a blend of data/information architecture, analysis, and engineering skills.\nExperience in known industry IT architectural patterns and IT architecture ways of working/methodologies (e.g. FAIR data principles, Data Mesh).\nUnderstanding the appropriate data structure and technology based on business use case and completely familiar with data lifecycles.","['FAIR data principles', 'Data Mesh', 'data lifecycles', 'data regulatory governances']",2025-06-12 01:32:10
Data Architect,Virtusa,9-13 Years,,Chennai,Consulting,"Bachelor's Degree or equivalent number of years of experience in a Computer Science or Data Management related field.\nExperience in leading and delivering enterprise data platform architectural thinking, and its practical application.\nExperience in the use of conceptual and logical data modelling technologies.\nExperience in defining and working with information and data regulatory governances.\nThe role holder will possess a blend of data/information architecture, analysis, and engineering skills.\nExperience in known industry IT architectural patterns and IT architecture ways of working/methodologies (e.g. FAIR data principles, Data Mesh).\nUnderstanding the appropriate data structure and technology based on business use case and completely familiar with data lifecycles.\nDesirable:\nExperience in a data architect role with practical examples of designing and providing data engineering/architectural blueprints that have been implemented.\nExperience of Information and Data Governance frameworks and their application in a commercial organization.\nUnderstands Data Platforms concepts and cloud-based containerization strategies for hybrid cloud environments.\nExperience in Agile data definition scrums.\nExperience in the use of tooling, e.g. metadata cataloguing tools, data modelling tools, EA tools.\nUnderstanding of or familiarity with,Data Mesh approaches (as distinct from Data Fabric or Data Platform).\nQualification\nDetailed Job Description forInformation Architect at PAN India:\nBachelor's Degree or equivalent number of years of experience in a Computer Science or Data Management related field.\nExperience in leading and delivering enterprise data platform architectural thinking, and its practical application.\nExperience in the use of conceptual and logical data modelling technologies.\nExperience in defining and working with information and data regulatory governances.\nThe role holder will possess a blend of data/information architecture, analysis, and engineering skills.\nExperience in known industry IT architectural patterns and IT architecture ways of working/methodologies (e.g. FAIR data principles, Data Mesh).\nUnderstanding the appropriate data structure and technology based on business use case and completely familiar with data lifecycles.","['FAIR data principles', 'Data Mesh', 'data lifecycles', 'data regulatory governances']",2025-06-12 01:32:11
Data Architect,Virtusa,9-13 Years,,Chennai,Consulting,"Bachelor's Degree or equivalent number of years of experience in a Computer Science or Data Management related field.\nExperience in leading and delivering enterprise data platform architectural thinking, and its practical application.\nExperience in the use of conceptual and logical data modelling technologies.\nExperience in defining and working with information and data regulatory governances.\nThe role holder will possess a blend of data/information architecture, analysis, and engineering skills.\nExperience in known industry IT architectural patterns and IT architecture ways of working/methodologies (e.g. FAIR data principles, Data Mesh).\nUnderstanding the appropriate data structure and technology based on business use case and completely familiar with data lifecycles.\nDesirable:\nExperience in a data architect role with practical examples of designing and providing data engineering/architectural blueprints that have been implemented.\nExperience of Information and Data Governance frameworks and their application in a commercial organization.\nUnderstands Data Platforms concepts and cloud-based containerization strategies for hybrid cloud environments.\nExperience in Agile data definition scrums.\nExperience in the use of tooling, e.g. metadata cataloguing tools, data modelling tools, EA tools.\nUnderstanding of or familiarity with,Data Mesh approaches (as distinct from Data Fabric or Data Platform).\nQualification\nDetailed Job Description forInformation Architect at PAN India:\nBachelor's Degree or equivalent number of years of experience in a Computer Science or Data Management related field.\nExperience in leading and delivering enterprise data platform architectural thinking, and its practical application.\nExperience in the use of conceptual and logical data modelling technologies.\nExperience in defining and working with information and data regulatory governances.\nThe role holder will possess a blend of data/information architecture, analysis, and engineering skills.\nExperience in known industry IT architectural patterns and IT architecture ways of working/methodologies (e.g. FAIR data principles, Data Mesh).\nUnderstanding the appropriate data structure and technology based on business use case and completely familiar with data lifecycles.","['FAIR data principles', 'Data Mesh', 'data lifecycles', 'data regulatory governances']",2025-06-12 01:32:16
Data Architect,Tata Consultancy Services Limited,4-8 Years,,"Gurugram, Delhi, Hyderabad",IT Infrastructure,"Position Title- Data Architect / Solution Architect\nLocation: Pan india\nThis position description should represent your role and responsibilities at the time of appointment, however due to the dynamic nature of our business, your job title, key tasks and responsibilities are likely to evolve over time. The flexibility to adapt to any changes should be considered a key requirement of working at TPG Telecom.\nRole Purpose & Environment\nIn this role you will work hand-in-hand with various technology and business stakeholders to design and build TPGs modern data platform in the cloud and manage the legacy applications. You will provide strategic direction and leadership guidance driving architecture and implementation initiatives leveraging your knowledge and experience in the area. The role also extends into the consumption side of data and will allow you to deliver business intelligence capabilities (including Advanced Analytics) and strategies for information delivery and data exploration to support business objectives and requirements.\nWe are seeking someone with the passion for understanding and leveraging data, with the attitude and behaviour to deliver on commitments and take ownership of data products when required.\nKey Responsibilities\nDefine and design the overall data architecture, strategy, and data capabilities roadmap that are consistent with our technology direction.\nDefine and design the data platforms, tools and governing process\nCreate, maintain and communicate go-forward strategies for business intelligence capabilities and tools.\nResponsible and accountable for producing the data solution and data product architecture design ensuring that they are submitted and progress via the prescribed governance process through to approval (ARB) in a timely manner aligned with project prescribed timelines.\nDefine and review data solutions for re-usability, scalability, synergy opportunities and alignment to defined best practice and guidelines\nCreate and evolve data technology roadmap, to align with continuously evolving business needs.\nHelp defining and improving best practices, guidelines, and integration with other enterprise solutions.\nParticipates in planning, dependency identification, and management as well as estimation with Project Managers.\nLeads Work Breakdown identification and workshops utilising Architecture designs as input\nDemonstrated grasp of Architecture techniques and ability to work effectively with senior business stakeholders and initiative owners.\nAct as Technology advisors on data to business leaders and strategic leaders on technology direction.\nKey Experience, Skills, and Qualifications\nDomain Expertise\n7 years+ of professional experience in data architecture or data engineering role. Demonstrating a high degree of proficiency in designing and developing complex, high quality data solutions according to our architecture governance policies guidelines.\nStrong experience in developing and maintaining data warehouses (e.g., Redshift, Teradata)\nAble to work independently and develop the solution architecture according to the business requirements and compliance requirements.\nStrong Data warehouse development experience using different ETL tools (e.g. SAS DI, Glue, DBT)\nExperience with data streaming platforms (e.g., Kafka/Kinesis)\nFamiliarity with different operational orchestration platforms (e.g., Airflow, LSF scheduler etc)\nExperience with data catalogue and data governance tools.\nUnderstanding of CLDM, Star Schema, Data Mesh and Data Product concepts\nExposure to machine learning, reporting, data sharing, data intensive application-oriented use cases\nExtensive experience in consulting with business stakeholders and other user groups to deliver both strategic and tactical information management solution.\nExperience working within matrix structures, with demonstrated ability to broker outcomes effectively and collaboratively with colleagues and peers.\nExperience on different delivery methodologies (e.g., Waterfall, Agile)\nTelecommunication Industry experience\nBachelor's degree in computer science, computer programming or related field preferred\nIndividual Skills, Mindset & Behaviours\nStrong communication skills with ability to communicate complex technical concepts in a digestible way\nAbility to effortlessly switch gears from summary view for leadership to hands-on discussion with practitioners\nAssertive, with the confidence to be voice of authority what is best for team\nHigh-energy and passionate outlook to the role and can influence those around her/him\nAbility to build a sense of trust and rapport that creates a comfortable, respectful, and effective workplace","['Teradata', 'Kafka', 'Redshift', 'Etl']",2025-06-12 01:32:17
Data Architect,Tata Consultancy Services Limited,4-8 Years,,"Thane, Kolkata, Mumbai",IT Infrastructure,"Job Description\nPosition Title- Data Architect / Solution Architect\nLocation: Pan india\nThis position description should represent your role and responsibilities at the time of appointment, however due to the dynamic nature of our business, your job title, key tasks and responsibilities are likely to evolve over time. The flexibility to adapt to any changes should be considered a key requirement of working at TPG Telecom.\nRole Purpose & Environment\nIn this role you will work hand-in-hand with various technology and business stakeholders to design and build TPGs modern data platform in the cloud and manage the legacy applications. You will provide strategic direction and leadership guidance driving architecture and implementation initiatives leveraging your knowledge and experience in the area. The role also extends into the consumption side of data and will allow you to deliver business intelligence capabilities (including Advanced Analytics) and strategies for information delivery and data exploration to support business objectives and requirements.\nWe are seeking someone with the passion for understanding and leveraging data, with the attitude and behaviour to deliver on commitments and take ownership of data products when required.\nKey Responsibilities\nDefine and design the overall data architecture, strategy, and data capabilities roadmap that are consistent with our technology direction.\nDefine and design the data platforms, tools and governing process\nCreate, maintain and communicate go-forward strategies for business intelligence capabilities and tools.\nResponsible and accountable for producing the data solution and data product architecture design ensuring that they are submitted and progress via the prescribed governance process through to approval (ARB) in a timely manner aligned with project prescribed timelines.\nDefine and review data solutions for re-usability, scalability, synergy opportunities and alignment to defined best practice and guidelines\nCreate and evolve data technology roadmap, to align with continuously evolving business needs.\nHelp defining and improving best practices, guidelines, and integration with other enterprise solutions.\nParticipates in planning, dependency identification, and management as well as estimation with Project Managers.\nLeads Work Breakdown identification and workshops utilising Architecture designs as input\nDemonstrated grasp of Architecture techniques and ability to work effectively with senior business stakeholders and initiative owners.\nAct as Technology advisors on data to business leaders and strategic leaders on technology direction.\nKey Experience, Skills, and Qualifications\nDomain Expertise\n7 years+ of professional experience in data architecture or data engineering role. Demonstrating a high degree of proficiency in designing and developing complex, high quality data solutions according to our architecture governance policies guidelines.\nStrong experience in developing and maintaining data warehouses (e.g., Redshift, Teradata)\nAble to work independently and develop the solution architecture according to the business requirements and compliance requirements.\nStrong Data warehouse development experience using different ETL tools (e.g. SAS DI, Glue, DBT)\nExperience with data streaming platforms (e.g., Kafka/Kinesis)\nFamiliarity with different operational orchestration platforms (e.g., Airflow, LSF scheduler etc)\nExperience with data catalogue and data governance tools.\nUnderstanding of CLDM, Star Schema, Data Mesh and Data Product concepts\nExposure to machine learning, reporting, data sharing, data intensive application-oriented use cases\nExtensive experience in consulting with business stakeholders and other user groups to deliver both strategic and tactical information management solution.\nExperience working within matrix structures, with demonstrated ability to broker outcomes effectively and collaboratively with colleagues and peers.\nExperience on different delivery methodologies (e.g., Waterfall, Agile)\nTelecommunication Industry experience\nBachelor's degree in computer science, computer programming or related field preferred\nIndividual Skills, Mindset & Behaviours\nStrong communication skills with ability to communicate complex technical concepts in a digestible way\nAbility to effortlessly switch gears from summary view for leadership to hands-on discussion with practitioners\nAssertive, with the confidence to be voice of authority what is best for team\nHigh-energy and passionate outlook to the role and can influence those around her/him\nAbility to build a sense of trust and rapport that creates a comfortable, respectful, and effective workplace","['Architect', 'Data Architect', 'Kafka', 'Etl']",2025-06-12 01:32:18
Data Architect,Tata Consultancy Services Limited,4-8 Years,,"Noida, Delhi NCR, Pune",IT Infrastructure,"Position Title- Data Architect / Solution Architect\nLocation: Pan india\nThis position description should represent your role and responsibilities at the time of appointment, however due to the dynamic nature of our business, your job title, key tasks and responsibilities are likely to evolve over time. The flexibility to adapt to any changes should be considered a key requirement of working at TPG Telecom.\nRole Purpose & Environment\nIn this role you will work hand-in-hand with various technology and business stakeholders to design and build TPGs modern data platform in the cloud and manage the legacy applications. You will provide strategic direction and leadership guidance driving architecture and implementation initiatives leveraging your knowledge and experience in the area. The role also extends into the consumption side of data and will allow you to deliver business intelligence capabilities (including Advanced Analytics) and strategies for information delivery and data exploration to support business objectives and requirements.\nWe are seeking someone with the passion for understanding and leveraging data, with the attitude and behaviour to deliver on commitments and take ownership of data products when required.\nKey Responsibilities\nDefine and design the overall data architecture, strategy, and data capabilities roadmap that are consistent with our technology direction.\nDefine and design the data platforms, tools and governing process\nCreate, maintain and communicate go-forward strategies for business intelligence capabilities and tools.\nResponsible and accountable for producing the data solution and data product architecture design ensuring that they are submitted and progress via the prescribed governance process through to approval (ARB) in a timely manner aligned with project prescribed timelines.\nDefine and review data solutions for re-usability, scalability, synergy opportunities and alignment to defined best practice and guidelines\nCreate and evolve data technology roadmap, to align with continuously evolving business needs.\nHelp defining and improving best practices, guidelines, and integration with other enterprise solutions.\nParticipates in planning, dependency identification, and management as well as estimation with Project Managers.\nLeads Work Breakdown identification and workshops utilising Architecture designs as input\nDemonstrated grasp of Architecture techniques and ability to work effectively with senior business stakeholders and initiative owners.\nAct as Technology advisors on data to business leaders and strategic leaders on technology direction.\nKey Experience, Skills, and Qualifications\nDomain Expertise\n7 years+ of professional experience in data architecture or data engineering role. Demonstrating a high degree of proficiency in designing and developing complex, high quality data solutions according to our architecture governance policies guidelines.\nStrong experience in developing and maintaining data warehouses (e.g., Redshift, Teradata)\nAble to work independently and develop the solution architecture according to the business requirements and compliance requirements.\nStrong Data warehouse development experience using different ETL tools (e.g. SAS DI, Glue, DBT)\nExperience with data streaming platforms (e.g., Kafka/Kinesis)\nFamiliarity with different operational orchestration platforms (e.g., Airflow, LSF scheduler etc)\nExperience with data catalogue and data governance tools.\nUnderstanding of CLDM, Star Schema, Data Mesh and Data Product concepts\nExposure to machine learning, reporting, data sharing, data intensive application-oriented use cases\nExtensive experience in consulting with business stakeholders and other user groups to deliver both strategic and tactical information management solution.\nExperience working within matrix structures, with demonstrated ability to broker outcomes effectively and collaboratively with colleagues and peers.\nExperience on different delivery methodologies (e.g., Waterfall, Agile)\nTelecommunication Industry experience\nBachelor's degree in computer science, computer programming or related field preferred\nIndividual Skills, Mindset & Behaviours\nStrong communication skills with ability to communicate complex technical concepts in a digestible way\nAbility to effortlessly switch gears from summary view for leadership to hands-on discussion with practitioners\nAssertive, with the confidence to be voice of authority what is best for team\nHigh-energy and passionate outlook to the role and can influence those around her/him\nAbility to build a sense of trust and rapport that creates a comfortable, respectful, and effective workplace","['Teradata', 'Kafka', 'Redshift', 'Etl']",2025-06-12 01:32:19
Data Architect,Tata Consultancy Services Limited,4-8 Years,,"Gurugram, Delhi, Hyderabad",IT Infrastructure,"Job Description\nPosition Title- Data Architect / Solution Architect\nLocation: Pan india\nThis position description should represent your role and responsibilities at the time of appointment, however due to the dynamic nature of our business, your job title, key tasks and responsibilities are likely to evolve over time. The flexibility to adapt to any changes should be considered a key requirement of working at TPG Telecom.\nRole Purpose & Environment\nIn this role you will work hand-in-hand with various technology and business stakeholders to design and build TPGs modern data platform in the cloud and manage the legacy applications. You will provide strategic direction and leadership guidance driving architecture and implementation initiatives leveraging your knowledge and experience in the area. The role also extends into the consumption side of data and will allow you to deliver business intelligence capabilities (including Advanced Analytics) and strategies for information delivery and data exploration to support business objectives and requirements.\nWe are seeking someone with the passion for understanding and leveraging data, with the attitude and behaviour to deliver on commitments and take ownership of data products when required.\nKey Responsibilities\nDefine and design the overall data architecture, strategy, and data capabilities roadmap that are consistent with our technology direction.\nDefine and design the data platforms, tools and governing process\nCreate, maintain and communicate go-forward strategies for business intelligence capabilities and tools.\nResponsible and accountable for producing the data solution and data product architecture design ensuring that they are submitted and progress via the prescribed governance process through to approval (ARB) in a timely manner aligned with project prescribed timelines.\nDefine and review data solutions for re-usability, scalability, synergy opportunities and alignment to defined best practice and guidelines\nCreate and evolve data technology roadmap, to align with continuously evolving business needs.\nHelp defining and improving best practices, guidelines, and integration with other enterprise solutions.\nParticipates in planning, dependency identification, and management as well as estimation with Project Managers.\nLeads Work Breakdown identification and workshops utilising Architecture designs as input\nDemonstrated grasp of Architecture techniques and ability to work effectively with senior business stakeholders and initiative owners.\nAct as Technology advisors on data to business leaders and strategic leaders on technology direction.\nKey Experience, Skills, and Qualifications\nDomain Expertise\n7 years+ of professional experience in data architecture or data engineering role. Demonstrating a high degree of proficiency in designing and developing complex, high quality data solutions according to our architecture governance policies guidelines.\nStrong experience in developing and maintaining data warehouses (e.g., Redshift, Teradata)\nAble to work independently and develop the solution architecture according to the business requirements and compliance requirements.\nStrong Data warehouse development experience using different ETL tools (e.g. SAS DI, Glue, DBT)\nExperience with data streaming platforms (e.g., Kafka/Kinesis)\nFamiliarity with different operational orchestration platforms (e.g., Airflow, LSF scheduler etc)\nExperience with data catalogue and data governance tools.\nUnderstanding of CLDM, Star Schema, Data Mesh and Data Product concepts\nExposure to machine learning, reporting, data sharing, data intensive application-oriented use cases\nExtensive experience in consulting with business stakeholders and other user groups to deliver both strategic and tactical information management solution.\nExperience working within matrix structures, with demonstrated ability to broker outcomes effectively and collaboratively with colleagues and peers.\nExperience on different delivery methodologies (e.g., Waterfall, Agile)\nTelecommunication Industry experience\nBachelor's degree in computer science, computer programming or related field preferred\nIndividual Skills, Mindset & Behaviours\nStrong communication skills with ability to communicate complex technical concepts in a digestible way\nAbility to effortlessly switch gears from summary view for leadership to hands-on discussion with practitioners\nAssertive, with the confidence to be voice of authority what is best for team\nHigh-energy and passionate outlook to the role and can influence those around her/him\nAbility to build a sense of trust and rapport that creates a comfortable, respectful, and effective workplace","['Architect', 'Data Architect', 'Kafka', 'Etl']",2025-06-12 01:32:21
Data Architect,Tata Consultancy Services Limited,4-8 Years,,"Ahmedabad, Bengaluru, Chennai",IT Infrastructure,"Job Description\nPosition Title- Data Architect / Solution Architect\nLocation: Pan india\nThis position description should represent your role and responsibilities at the time of appointment, however due to the dynamic nature of our business, your job title, key tasks and responsibilities are likely to evolve over time. The flexibility to adapt to any changes should be considered a key requirement of working at TPG Telecom.\nRole Purpose & Environment\nIn this role you will work hand-in-hand with various technology and business stakeholders to design and build TPGs modern data platform in the cloud and manage the legacy applications. You will provide strategic direction and leadership guidance driving architecture and implementation initiatives leveraging your knowledge and experience in the area. The role also extends into the consumption side of data and will allow you to deliver business intelligence capabilities (including Advanced Analytics) and strategies for information delivery and data exploration to support business objectives and requirements.\nWe are seeking someone with the passion for understanding and leveraging data, with the attitude and behaviour to deliver on commitments and take ownership of data products when required.\nKey Responsibilities\nDefine and design the overall data architecture, strategy, and data capabilities roadmap that are consistent with our technology direction.\nDefine and design the data platforms, tools and governing process\nCreate, maintain and communicate go-forward strategies for business intelligence capabilities and tools.\nResponsible and accountable for producing the data solution and data product architecture design ensuring that they are submitted and progress via the prescribed governance process through to approval (ARB) in a timely manner aligned with project prescribed timelines.\nDefine and review data solutions for re-usability, scalability, synergy opportunities and alignment to defined best practice and guidelines\nCreate and evolve data technology roadmap, to align with continuously evolving business needs.\nHelp defining and improving best practices, guidelines, and integration with other enterprise solutions.\nParticipates in planning, dependency identification, and management as well as estimation with Project Managers.\nLeads Work Breakdown identification and workshops utilising Architecture designs as input\nDemonstrated grasp of Architecture techniques and ability to work effectively with senior business stakeholders and initiative owners.\nAct as Technology advisors on data to business leaders and strategic leaders on technology direction.\nKey Experience, Skills, and Qualifications\nDomain Expertise\n7 years+ of professional experience in data architecture or data engineering role. Demonstrating a high degree of proficiency in designing and developing complex, high quality data solutions according to our architecture governance policies guidelines.\nStrong experience in developing and maintaining data warehouses (e.g., Redshift, Teradata)\nAble to work independently and develop the solution architecture according to the business requirements and compliance requirements.\nStrong Data warehouse development experience using different ETL tools (e.g. SAS DI, Glue, DBT)\nExperience with data streaming platforms (e.g., Kafka/Kinesis)\nFamiliarity with different operational orchestration platforms (e.g., Airflow, LSF scheduler etc)\nExperience with data catalogue and data governance tools.\nUnderstanding of CLDM, Star Schema, Data Mesh and Data Product concepts\nExposure to machine learning, reporting, data sharing, data intensive application-oriented use cases\nExtensive experience in consulting with business stakeholders and other user groups to deliver both strategic and tactical information management solution.\nExperience working within matrix structures, with demonstrated ability to broker outcomes effectively and collaboratively with colleagues and peers.\nExperience on different delivery methodologies (e.g., Waterfall, Agile)\nTelecommunication Industry experience\nBachelor's degree in computer science, computer programming or related field preferred\nIndividual Skills, Mindset & Behaviours\nStrong communication skills with ability to communicate complex technical concepts in a digestible way\nAbility to effortlessly switch gears from summary view for leadership to hands-on discussion with practitioners\nAssertive, with the confidence to be voice of authority what is best for team\nHigh-energy and passionate outlook to the role and can influence those around her/him\nAbility to build a sense of trust and rapport that creates a comfortable, respectful, and effective workplace","['Architect', 'Data Architect', 'Kafka', 'Etl']",2025-06-12 01:32:22
Data Architect,Tata Consultancy Services Limited,4-8 Years,,"Thane, Kolkata, Mumbai",IT Infrastructure,"Position Title- Data Architect / Solution Architect\nLocation: Pan india\nThis position description should represent your role and responsibilities at the time of appointment, however due to the dynamic nature of our business, your job title, key tasks and responsibilities are likely to evolve over time. The flexibility to adapt to any changes should be considered a key requirement of working at TPG Telecom.\nRole Purpose & Environment\nIn this role you will work hand-in-hand with various technology and business stakeholders to design and build TPGs modern data platform in the cloud and manage the legacy applications. You will provide strategic direction and leadership guidance driving architecture and implementation initiatives leveraging your knowledge and experience in the area. The role also extends into the consumption side of data and will allow you to deliver business intelligence capabilities (including Advanced Analytics) and strategies for information delivery and data exploration to support business objectives and requirements.\nWe are seeking someone with the passion for understanding and leveraging data, with the attitude and behaviour to deliver on commitments and take ownership of data products when required.\nKey Responsibilities\nDefine and design the overall data architecture, strategy, and data capabilities roadmap that are consistent with our technology direction.\nDefine and design the data platforms, tools and governing process\nCreate, maintain and communicate go-forward strategies for business intelligence capabilities and tools.\nResponsible and accountable for producing the data solution and data product architecture design ensuring that they are submitted and progress via the prescribed governance process through to approval (ARB) in a timely manner aligned with project prescribed timelines.\nDefine and review data solutions for re-usability, scalability, synergy opportunities and alignment to defined best practice and guidelines\nCreate and evolve data technology roadmap, to align with continuously evolving business needs.\nHelp defining and improving best practices, guidelines, and integration with other enterprise solutions.\nParticipates in planning, dependency identification, and management as well as estimation with Project Managers.\nLeads Work Breakdown identification and workshops utilising Architecture designs as input\nDemonstrated grasp of Architecture techniques and ability to work effectively with senior business stakeholders and initiative owners.\nAct as Technology advisors on data to business leaders and strategic leaders on technology direction.\nKey Experience, Skills, and Qualifications\nDomain Expertise\n7 years+ of professional experience in data architecture or data engineering role. Demonstrating a high degree of proficiency in designing and developing complex, high quality data solutions according to our architecture governance policies guidelines.\nStrong experience in developing and maintaining data warehouses (e.g., Redshift, Teradata)\nAble to work independently and develop the solution architecture according to the business requirements and compliance requirements.\nStrong Data warehouse development experience using different ETL tools (e.g. SAS DI, Glue, DBT)\nExperience with data streaming platforms (e.g., Kafka/Kinesis)\nFamiliarity with different operational orchestration platforms (e.g., Airflow, LSF scheduler etc)\nExperience with data catalogue and data governance tools.\nUnderstanding of CLDM, Star Schema, Data Mesh and Data Product concepts\nExposure to machine learning, reporting, data sharing, data intensive application-oriented use cases\nExtensive experience in consulting with business stakeholders and other user groups to deliver both strategic and tactical information management solution.\nExperience working within matrix structures, with demonstrated ability to broker outcomes effectively and collaboratively with colleagues and peers.\nExperience on different delivery methodologies (e.g., Waterfall, Agile)\nTelecommunication Industry experience\nBachelor's degree in computer science, computer programming or related field preferred\nIndividual Skills, Mindset & Behaviours\nStrong communication skills with ability to communicate complex technical concepts in a digestible way\nAbility to effortlessly switch gears from summary view for leadership to hands-on discussion with practitioners\nAssertive, with the confidence to be voice of authority what is best for team\nHigh-energy and passionate outlook to the role and can influence those around her/him\nAbility to build a sense of trust and rapport that creates a comfortable, respectful, and effective workplace","['Teradata', 'Kafka', 'Redshift', 'Etl']",2025-06-12 01:32:23
Network Data Architect,Aspire Systems India Private Limited,12-16 Years,,Chennai,Software,"Minimum 12+ years of relevant hands on experience in configuring and troubleshooting Network devices, Cisco routers, ACI, Switches, Firewalls and F5 Load Balancers.\nAbility to troubleshoot and upgrade Cisco routers, Switches, Firewalls and F5 Load Balancers.\nMust be skilled to perform router/switch network hardware/software upgrades.\nMust have hands on experience in Routing Protocol Development (BGP, OSPF, VPN and Static.), providing IP Addressing Strategy - NAT, Re-Addressing, WAN - IP Routed Network Integration Wireless LAN technologies.\nExperience with Cisco LAN routing, switching, Security, Voice, and Wireless LAN products.\nExperience in network protocols VPN, OSPF, BGP, TCP/IP.\nExperience in Cisco nexus and Datacenter support.\nExperience and hands on with Cisco Client/ Cisco Prime/ Public DNS services.\nExperience in providing Network Engineering services in support of the large enterprise customer data networks.\nConfigure, administer firewall infrastructure, working with Cisco and Palo alto.\nWork with customer technical teams to provide solutions for customers internetworking communications requirements.\nExperience in proposal presentation and participating in Pre-sales engagement is an added advantage.\nProvide valuable solutions for colleagues and stakeholders, both tactically and strategically and ensure compliance to process, procedure, and tools within the operations.\nExcellent written and verbal communications skills are essential.\nProven analytic skills and the ability to isolate and resolve complex issues.\nGood understanding of Migration Effort, Resources and Timelines estimation.\nDesign public cloud infrastructure and DevOps solutions, architectures and roadmaps.\nEvolve and build best practice materials for Infrastructure-as-Code and Configuration Management.\nEnable sales including knowledge transfer, architecture and design, as well as participate in the sales cycle as needed.\nParticipate in community and market activities including participation in trade shows.\nCreate, build and grow partnerships with various organizations relevant to the practice,\nEnable development teams to leverage cloud and cloud-native architectures with new and existing applications.","['Network Data Architect', 'Tcp/ip', 'BGP', 'OSPF']",2025-06-12 01:32:25
Data Architect,Citiustech Healthcare Technology Private Limited,5-10 Years,,"Mumbai City, Bengaluru, Mumbai",Health Care,"We are looking for a data architect with below skillset\nHands on skills withImage data (preferably DICOM) parsing\nArchitect and implement data warehousing solutions using AWS (Redshift, S3, Lambda)\nDevelop and maintain ETL pipelines using Informatica PowerCenter or AWS Glue\nCollaborate with cross-functional teams to identify and prioritize data requirements\nAnalyze complex data sets using SQL, Python, and Java and or/Apex languageto inform business decisions\nImplement data visualization tools (Tableau, Power BI) for stakeholder reporting\nEnsure data integrity, security, and compliance with HIPAA, GDPR, and CCPA\nRequirements:> 5 years of experience in data management with focus in image metadata/bigdata\nStrong expertise in:\nPACS& RIS, SYNAPSE/XNAT, systems\nAWS (Redshift, S3, Lambda, Glue)\nData governance, quality, and security\nETL pipelines (Informatica PowerCenter or AWS Glue)\nData warehousing and visualization","['Data Warehousing', 'Tableau', 'Python', 'AWS']",2025-06-12 01:32:26
Data Lake/Big Data Architect,Infosys Limited,10-12 Years,,"Delhi, India",IT/Computers - Software,Job Description:\nThe resource should mandatorily have minimum 10 Years of experience in solution planning and system architecture designing with at least 4 years of experience as a Lead Architect for DW BI or Big Data Systems\nThe resource should have demonstrated extensive experience in the use of various techniques to develop robust data warehouse business intelligence solutions which have significant weightage to statistical and advanced analytics\nKey Responsibilities:\nROLE AND RESPONSIBILITIES\nAs a Data Lake Big Data Architect lead the engagement efforts at different stages from problem definition to diagnosis to solution design development deployment in large government implementation programs\nCreate detailed design and architecture and process artifacts implement the solution and the deployment plan\nConnect with senior client business and IT stakeholders demonstrating thought leadership in domain process and technology\nREQUIRED SKILLS AND EXPERIENCE\nDomain process functional technical\nStrong hands on and in depth knowledge in Data Lakes Big Data modules\nStrong understanding of Data modelling concepts\nStrong understanding of the Data Warehousing Business Intelligence AI solutions good understanding of airlines industry\nThorough understanding of Agile methodologies\nGood understanding of business processes in the airlines domain or with government organizations\nExperience in leading and driving Business process workshops and Fit GAP analysis\nShould have working experience in a highly regulated environment\nShould be aware of release governance processes and have experience in working on any incident management tool\nPreferred Skills:\nFoundational->Development process generic->SaaS Development Process,"['Data Lakes', 'Business Intelligence', 'Data modelling concepts', 'Big Data modules', 'AI solutions', 'Data Warehousing', 'Agile Methodologies']",2025-06-12 01:32:28
Celonis Data Architect,Harman Connected Services Corporation India Private Limited,12-15 Years,INR 2 - 3 LPA,Bengaluru,Software,"A Celonis data architect is responsible for designing and implementing the data architecture required for effective utilization of the Celonis process mining tool within an organization. They work closely with various stakeholders, including data engineers, business analysts, and process owners, to define data requirements, ensure data integrity, and enable seamless data integration.\nThe role requires a strong understanding of data architecture principles, data modeling techniques, and relational and non-relational databases. Candidate should also be proficient in ETL processes and tools, as well as have experience in data integration and data governance. Additionally, candidate should have a good understanding of business processes, data visualization, and analytics to effectively implement process mining initiatives within the customer organization\nRole and Responsibilities\nOver all 12-15 years of IT experience with minimum 5+ years experience in Process Mining using Celonis\nStrong experience in Data Integration, Data Modeling, Data quality, Data pipeline management, Dashboard design\nExperience in delivering at least 1 to 2 large scale end-to-end Celonis process mining implementations as Data Architect\nExperience in leading team of data modelers, data engineers\nStrong experience in providing multiple solutions and reviewing the implementations in parallel\nExpertise in defining the governance, security, roles around Data pools and dashboards in Celonis\nExperience in implementing object centric process mining\nMajor accountabilities:\nCollaborating with business stakeholders to understand their data requirements and process mining goals.\nEngage with customers C-level their strategic objectives with the Celonis technical strategy\nDesigning and implementing data models, schemas, and structures that align with the organization's data governance policies and standards.\nIdentifying and documenting data sources, including databases, systems, and applications, that need to be integrated with Celonis.\nEnsuring proper data extraction, transformation, and loading (ETL) processes to populate the necessary data into Celonis.\nSupervising data engineers in the development and maintenance of data pipelines and workflows.\nAssessing data quality, consistency, and accuracy and taking proactive measures to resolve issues. Implementing data security measures, including access controls and data encryption, to protect sensitive information within Celonis.\nProviding technical support and guidance to business analysts and end-users in data preparation, analysis, and reporting using Celonis.\nStaying updated with the latest trends and advancements in data management and process mining technologies, including Celonis updates and new features.","['Celonis Data Architect', 'Etl']",2025-06-12 01:32:29
Data Architect /Senior Engineer,Vaiticka Solution Private Limited,6-12 Years,,Bengaluru,Login to check your skill match score,"We are looking for a seasoned Data Architect (Senior Engineer) to lead the design and implementation of scalable, secure, and privacy-compliant data architectures that support feedback-driven AI systems. This role will focus on developing robust data ingestion pipelines, managing complex data flows, and integrating frameworks for model evaluationincluding fairness, bias, drift analysis, and KPI visualization. The ideal candidate brings both deep technical expertise in modern data architectures and a strong grasp of responsible AI practices.\nKey Responsibilities:\nData Architecture & Ingestion:\nDesign, build, and optimize data ingestion pipelines for high-volume, real-time, and batch dataparticularly focused on user feedback and model output data.\nArchitect and implement data pipelines that comply with data privacy, security, and governance policies, ensuring encryption, anonymization, and access control.\nDefine data modeling standards for structured, semi-structured, and unstructured data to support training, inference, and monitoring use cases.\nCollaborate with ML engineers and data scientists to ensure seamless flow of feedback data into model evaluation and retraining loops.\nData Handling & Compliance:\nImplement and enforce best practices in data lifecycle management, including classification, retention, and secure disposal.\nEnsure compliance with data regulations such as GDPR, HIPAA, and other regional privacy standards.\nWork closely with security and legal teams to conduct data privacy impact assessments (DPIAs) and ensure audit readiness.\nModel Evaluation & Monitoring:\nSupport data scientists by enabling access to relevant features and data slices for model performance evaluation, bias detection, and drift monitoring.\nBuild or integrate tools for model benchmarking and fairness audits, enabling transparency and accountability in deployed AI systems.\nDevelop dashboards or visualization layers that track model KPIs, performance metrics, and data health indicators over time.\nRequired Qualifications:\nBachelor's or master's degree in computer science, Data Engineering, or a related technical field.\n6+ years of experience in data engineering, architecture, or analytics, including at least 2 years in a senior or lead role.\nProven experience designing and building data ingestion pipelines using technologies like Apache Kafka, Apache Airflow, Spark, or cloud-native tools (e.g., AWS Glue, GCP Dataflow).\nStrong understanding of data privacy laws and security best practices, including encryption, tokenization, RBAC, and secure data zones.\nFamiliarity with tools and frameworks for model evaluation and monitoring (e.g., Evidently AI, Fiddler, WhyLabs, MLflow, or custom dashboards).\nProficiency in SQL and Python; experience with data visualization libraries (e.g., Plotly, Dash, D3.js) is a plus.\nPreferred Qualifications:\nExperience working with feedback loops in production AI/ML systems (e.g., user ratings, action logs, predictions vs outcomes).\nFamiliarity with MLOps practices and how data pipelines interface with CI/CD and model retraining workflows.\nKnowledge of responsible AI principles and bias/fairness mitigation strategies.\nStrong communication and stakeholder management skills, with experience presenting technical concepts to non-technical audiences.","['Apache Kafka', 'Spark', 'Sql', 'Python']",2025-06-12 01:32:30
Big Data Architect,Trellix,5-10 Years,,Bengaluru,"Cyber Security, Network Security","Job Description\nRole Overview:\nThe Big Data Architect will be responsible for the design, implementation, and management of the organizations big data infrastructure. The ideal candidate will have a strong technical background in big data technologies, excellent problem-solving skills, and the ability to work in a fast-paced environment. The role requires a deep understanding of data architecture, data modeling, and data integration techniques.\nAbout the Role:\nDesign and implement scalable and efficient big data architecture solutions to meet business requirements.\nDevelop and maintain data pipelines, ensuring the availability and quality of data.\nCollaborate with data scientists, data engineers, and other stakeholders to understand data needs and provide technical solutions.\nLead the evaluation and selection of big data tools and technologies.\nEnsure data security and privacy compliance.\nOptimize and tune big data systems for performance and cost-efficiency.\nDocument data architecture, data flows, and processes.\nStay up-to-date with the latest industry trends and best practices in big data technologies.\nAbout You:\nBachelors or Masters degree in Computer Science, Information Technology, or a related field.\nover all 10+ years exp with 5+ years of experience in big data architecture and engineering.\nProficiency in big data technologies such as Hadoop mapredue, Spark batch and streaming, Kafka, HBase, Scala, Elastic Search and others.\nExperience with AWS cloud platform.\nStrong knowledge of data modeling, ETL processes, and data warehousing.\nProficiency in programming languages such as Java, Scala, Spark\nFamiliarity with data visualization tools and techniques.\nExcellent communication and collaboration skills.\nStrong problem-solving abilities and attention to detail.","['big data architecture', 'Spark batch', 'Hadoop mapredue', 'Aws Cloud', 'Java', 'Spark And Scala']",2025-06-12 01:32:32
Data Engineering Architect (ATC),Virtusa,10-13 Years,,Hyderabad,IT Management,"Proficiency in PySpark for distributed data processing and transformation.\nSolid experience with AWS Glue for ETL jobs and managing data workflows.\nHands-on experience with AWS Data Pipeline (DPL) for workflow orchestration.\nStrong experience with AWS services such as S3, Lambda, Redshift, RDS, and EC2.\nTechnical Skills:\nProficiency in Python and PySpark for data processing and transformation tasks.\nDeep understanding of ETL concepts and best practices.\nFamiliarity with AWS Glue (ETL jobs, Data Catalog, and Crawlers).\nExperience building and maintaining data pipelines with AWS Data Pipeline or similar orchestration tools.\nFamiliarity with AWS S3 for data storage and management, including file formats (CSV, Parquet, Avro).\nStrong knowledge of SQL for querying and manipulating relational and semi-structured data.\nExperience with Data Warehousing and Big Data technologies, specifically within AWS.\nAdditional Skills:\nExperience with AWS Lambda for serverless data processing and orchestration.\nUnderstanding of AWS Redshift for data warehousing and analytics.\nFamiliarity with Data Lakes, Amazon EMR, and Kinesis for streaming data processing.\nKnowledge of data governance practices, including data lineage and auditing.\nFamiliarity with CI/CD pipelines and Git for version control.\nExperience with Docker and containerization for building and deploying applications.\nDesign and Build Data Pipelines: Design, implement, and optimize data pipelines on AWS using PySpark, AWS Glue, and AWS Data Pipeline to automate data integration, transformation, and storage processes.\nETL Development: Develop and maintain Extract, Transform, and Load (ETL) processes using AWS Glue and PySpark to efficiently process large datasets.\nData Workflow Automation: Build and manage automated data workflows using AWS Data Pipeline, ensuring seamless scheduling, monitoring, and management of data jobs.\nData Integration: Work with different AWS data storage services (e.g., S3, Redshift, RDS) to ensure smooth integration and movement of data across platforms.\nOptimization and Scaling: Optimize and scale data pipelines for high performance and cost efficiency, utilizing AWS services like Lambda, S3, and EC2.","['Analytics - Kinesis', 'S3', 'Aws Lambda', 'Platform', 'Pyspark', 'Apache Kafka', 'Redshift', 'Python']",2025-06-12 01:32:42
