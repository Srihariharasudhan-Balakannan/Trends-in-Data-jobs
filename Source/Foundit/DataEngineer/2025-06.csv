job_title,company_name,experience,salary,location,industry,job_description,skills,scraped_at
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:12
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:16
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:18
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:20
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:22
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:24
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:26
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:28
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:31
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:33
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:36
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:40
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:42
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:44
Data Engineer,Virtusa,6-8 Years,,Hyderabad,Information Technology,"Seeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nWorking with modern data orchestration tools\nQualification\nSeeking a skilled Data Engineer to work on cloud-based data pipelines and analytics platforms. The ideal candidate will have hands-on experience in PySpark and AWS, with proficiency in designing Data Lakes and working with modern data orchestration tools.\nData Engineer to work on cloud-based data pipelines and analytics platforms\nPySpark and AWS, with proficiency in designing Data Lakes\nworking with modern data orchestration tools","['CI & CD', 'Cloudera Data platform', 'Terraform', 'Jenkins', 'Devops', 'Cloudformation', 'Docker', 'Pyspark']",2025-06-12 01:20:47
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:20:57
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:01
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:03
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:05
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:07
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:08
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:10
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:12
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:14
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:16
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:17
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:19
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:21
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:22
Data Engineer-Data Platforms-Azure,IBM,6-10 Years,,Bengaluru,Information Technology,"Your role and responsibilities\nAs Data Engineer, you will develop, maintain, evaluate and test big data solutions. You will be involved in the development of data solutions using Spark Framework with Python or Scala on Hadoop and Azure Cloud Data Platform\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nStrong and proven background in Information Technology & working knowledge of .NET Core, C#, REST API, LINQ, Entity Framework, XUnit.\nTroubleshooting issues related to code performance.\nWorking knowledge of Angular 15 or later, Typescript, Jest Framework, HTML 5 and CSS 3 & MS SQL Databases, troubleshooting issues related to DB performance\nGood understanding of CQRS, mediator, repository pattern.\nGood understanding of CI/CD pipelines and SonarQube & messaging and reverse proxy\nPreferred technical and professional experience\nGood understanding of AuthN and AuthZ techniques like (windows, basic, JWT).\nGood understanding of GIT and it's process like Pull request.\nMerge, pull, commit Methodology skills like AGILE, TDD, UML","['.NET', 'Sql', 'Rest', 'Html', 'Ms Sql']",2025-06-12 01:21:24
Data Engineer-Data Platforms-Google,IBM,0-5 Years,,Hyderabad,Software,"In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\nYour role and responsibilities\nAs an Associate Software Developer at IBM you will harness the power of data to unveil captivating stories and intricate patterns.\nYou'll contribute to data gathering, storage, and both batch and real-time processing.\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis.\nAs a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\nIn this role, your responsibilities may include:\nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nDevelop/Convert the database (Hadoop to GCP) of the specific objects (tables, views, procedures, functions, triggers, etc.) from one database to another database platform Implementation of a specific Data Replication mechanism (CDC, file data transfer, bulk data transfer, etc.).\nExpose data as API Participation in modernization roadmap journey Analyze discovery and analysis outcomes Lead discovery and analysis workshops/playbacks Identification of the applications dependencies, source, and target database incompatibilities.\nAnalyze the non-functional requirements (security, HA, RTO/RPO, storage, compute, network, performance bench, etc.).\nPrepare the effort estimates, WBS, staffing plan, RACI, RAID etc. .\nLeads the team to adopt right tools for various migration and modernization method\nPreferred technical and professional experience\nYou thrive on teamwork and have excellent verbal and written communication skills.\nAbility to communicate with internal and external clients to understand and define business needs, providing analytical solutions\nAbility to communicate results to technical and non-technical audiences","['predictive models', 'data engineering', 'Machine Learning', 'Elasticsearch', 'Splunk', 'Database Migration']",2025-06-12 01:21:34
Data Engineer-Data Platforms-Google,IBM,0-5 Years,,Hyderabad,Software,"In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\nYour role and responsibilities\nAs an Associate Software Developer at IBM you will harness the power of data to unveil captivating stories and intricate patterns.\nYou'll contribute to data gathering, storage, and both batch and real-time processing.\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis.\nAs a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\nIn this role, your responsibilities may include:\nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nDevelop/Convert the database (Hadoop to GCP) of the specific objects (tables, views, procedures, functions, triggers, etc.) from one database to another database platform Implementation of a specific Data Replication mechanism (CDC, file data transfer, bulk data transfer, etc.).\nExpose data as API Participation in modernization roadmap journey Analyze discovery and analysis outcomes Lead discovery and analysis workshops/playbacks Identification of the applications dependencies, source, and target database incompatibilities.\nAnalyze the non-functional requirements (security, HA, RTO/RPO, storage, compute, network, performance bench, etc.).\nPrepare the effort estimates, WBS, staffing plan, RACI, RAID etc. .\nLeads the team to adopt right tools for various migration and modernization method\nPreferred technical and professional experience\nYou thrive on teamwork and have excellent verbal and written communication skills.\nAbility to communicate with internal and external clients to understand and define business needs, providing analytical solutions\nAbility to communicate results to technical and non-technical audiences","['predictive models', 'data engineering', 'Machine Learning', 'Elasticsearch', 'Splunk', 'Database Migration']",2025-06-12 01:21:39
Data Engineer-Data Platforms-Google,IBM,0-5 Years,,Hyderabad,Software,"In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\nYour role and responsibilities\nAs an Associate Software Developer at IBM you will harness the power of data to unveil captivating stories and intricate patterns.\nYou'll contribute to data gathering, storage, and both batch and real-time processing.\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis.\nAs a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\nIn this role, your responsibilities may include:\nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nDevelop/Convert the database (Hadoop to GCP) of the specific objects (tables, views, procedures, functions, triggers, etc.) from one database to another database platform Implementation of a specific Data Replication mechanism (CDC, file data transfer, bulk data transfer, etc.).\nExpose data as API Participation in modernization roadmap journey Analyze discovery and analysis outcomes Lead discovery and analysis workshops/playbacks Identification of the applications dependencies, source, and target database incompatibilities.\nAnalyze the non-functional requirements (security, HA, RTO/RPO, storage, compute, network, performance bench, etc.).\nPrepare the effort estimates, WBS, staffing plan, RACI, RAID etc. .\nLeads the team to adopt right tools for various migration and modernization method\nPreferred technical and professional experience\nYou thrive on teamwork and have excellent verbal and written communication skills.\nAbility to communicate with internal and external clients to understand and define business needs, providing analytical solutions\nAbility to communicate results to technical and non-technical audiences","['predictive models', 'data engineering', 'Machine Learning', 'Elasticsearch', 'Splunk', 'Database Migration']",2025-06-12 01:21:40
Data Engineer-Data Platforms-Google,IBM,0-5 Years,,Hyderabad,Software,"In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\nYour role and responsibilities\nAs an Associate Software Developer at IBM you will harness the power of data to unveil captivating stories and intricate patterns.\nYou'll contribute to data gathering, storage, and both batch and real-time processing.\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis.\nAs a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\nIn this role, your responsibilities may include:\nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nDevelop/Convert the database (Hadoop to GCP) of the specific objects (tables, views, procedures, functions, triggers, etc.) from one database to another database platform Implementation of a specific Data Replication mechanism (CDC, file data transfer, bulk data transfer, etc.).\nExpose data as API Participation in modernization roadmap journey Analyze discovery and analysis outcomes Lead discovery and analysis workshops/playbacks Identification of the applications dependencies, source, and target database incompatibilities.\nAnalyze the non-functional requirements (security, HA, RTO/RPO, storage, compute, network, performance bench, etc.).\nPrepare the effort estimates, WBS, staffing plan, RACI, RAID etc. .\nLeads the team to adopt right tools for various migration and modernization method\nPreferred technical and professional experience\nYou thrive on teamwork and have excellent verbal and written communication skills.\nAbility to communicate with internal and external clients to understand and define business needs, providing analytical solutions\nAbility to communicate results to technical and non-technical audiences","['predictive models', 'data engineering', 'Machine Learning', 'Elasticsearch', 'Splunk', 'Database Migration']",2025-06-12 01:21:42
Data Engineer-Data Platforms-Google,IBM,0-5 Years,,Hyderabad,Software,"In this role, you'll work in one of our IBM Consulting Client Innovation Centers (Delivery Centers), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.\nYour role and responsibilities\nAs an Associate Software Developer at IBM you will harness the power of data to unveil captivating stories and intricate patterns.\nYou'll contribute to data gathering, storage, and both batch and real-time processing.\nCollaborating closely with diverse teams, you'll play an important role in deciding the most suitable data management systems and identifying the crucial data required for insightful analysis.\nAs a Data Engineer, you'll tackle obstacles related to database integration and untangle complex, unstructured data sets.\nIn this role, your responsibilities may include:\nImplementing and validating predictive models as well as creating and maintain statistical models with a focus on big data, incorporating a variety of statistical and machine learning techniques\nDesigning and implementing various enterprise search applications such as Elasticsearch and Splunk for client requirements\nWork in an Agile, collaborative environment, partnering with other scientists, engineers, consultants and database administrators of all backgrounds and disciplines to bring analytical rigor and statistical methods to the challenges of predicting behaviors.\nBuild teams or writing programs to cleanse and integrate data in an efficient and reusable manner, developing predictive or prescriptive models, and evaluating modeling results\nRequired education\nBachelor's Degree\nPreferred education\nMaster's Degree\nRequired technical and professional expertise\nDevelop/Convert the database (Hadoop to GCP) of the specific objects (tables, views, procedures, functions, triggers, etc.) from one database to another database platform Implementation of a specific Data Replication mechanism (CDC, file data transfer, bulk data transfer, etc.).\nExpose data as API Participation in modernization roadmap journey Analyze discovery and analysis outcomes Lead discovery and analysis workshops/playbacks Identification of the applications dependencies, source, and target database incompatibilities.\nAnalyze the non-functional requirements (security, HA, RTO/RPO, storage, compute, network, performance bench, etc.).\nPrepare the effort estimates, WBS, staffing plan, RACI, RAID etc. .\nLeads the team to adopt right tools for various migration and modernization method\nPreferred technical and professional experience\nYou thrive on teamwork and have excellent verbal and written communication skills.\nAbility to communicate with internal and external clients to understand and define business needs, providing analytical solutions\nAbility to communicate results to technical and non-technical audiences","['predictive models', 'data engineering', 'Machine Learning', 'Elasticsearch', 'Splunk', 'Database Migration']",2025-06-12 01:21:44
