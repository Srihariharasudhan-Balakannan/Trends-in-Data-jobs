{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41bbfbe3",
   "metadata": {
    "papermill": {
     "duration": 0.005796,
     "end_time": "2025-06-11T23:49:54.003731",
     "exception": false,
     "start_time": "2025-06-11T23:49:53.997935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7fa261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:49:54.016470Z",
     "iopub.status.busy": "2025-06-11T23:49:54.016078Z",
     "iopub.status.idle": "2025-06-11T23:51:13.817573Z",
     "shell.execute_reply": "2025-06-11T23:51:13.815928Z"
    },
    "papermill": {
     "duration": 79.811235,
     "end_time": "2025-06-11T23:51:13.820445",
     "exception": false,
     "start_time": "2025-06-11T23:49:54.009210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Update package list silently\n",
    "!apt-get update -qq > /dev/null 2>&1\n",
    "# Install required libraries silently\n",
    "!apt-get install -qq \\\n",
    "libglib2.0-0 \\\n",
    "libnss3 \\\n",
    "libdbus-glib-1-2 \\\n",
    "libgconf-2-4 \\\n",
    "libfontconfig1 \\\n",
    "libvulkan1 \\\n",
    "gconf2-common \\\n",
    "libwayland-server0 \\\n",
    "libgbm1 \\\n",
    "udev \\\n",
    "libu2f-udev > /dev/null 2>&1\n",
    "# Fix broken installs if any\n",
    "!apt --fix-broken install -y > /dev/null 2>&1\n",
    "# Download Chrome binary\n",
    "!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chrome-linux64.zip > /dev/null 2>&1\n",
    "# Unzip Chrome to /usr/bin\n",
    "!unzip /tmp/chrome-linux64.zip -d /usr/bin/ > /dev/null 2>&1\n",
    "# Download ChromeDriver\n",
    "!wget -P /tmp https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/116.0.5845.96/linux64/chromedriver-linux64.zip > /dev/null 2>&1\n",
    "# Unzip ChromeDriver to /usr/bin\n",
    "!unzip /tmp/chromedriver-linux64.zip -d /usr/bin/ > /dev/null 2>&1\n",
    "# Install Selenium Python bindings\n",
    "!apt install -y python3-selenium > /dev/null 2>&1\n",
    "# Install specific Selenium version\n",
    "!pip install selenium==3.141.0 > /dev/null 2>&1\n",
    "# Install PyGithub\n",
    "!pip install PyGithub > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf25b4e",
   "metadata": {
    "papermill": {
     "duration": 0.004921,
     "end_time": "2025-06-11T23:51:13.831001",
     "exception": false,
     "start_time": "2025-06-11T23:51:13.826080",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf18433",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:13.843872Z",
     "iopub.status.busy": "2025-06-11T23:51:13.843441Z",
     "iopub.status.idle": "2025-06-11T23:51:13.857221Z",
     "shell.execute_reply": "2025-06-11T23:51:13.855974Z"
    },
    "papermill": {
     "duration": 0.023912,
     "end_time": "2025-06-11T23:51:13.860150",
     "exception": false,
     "start_time": "2025-06-11T23:51:13.836238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import csv\n",
    "import datetime\n",
    "import html\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import smtplib\n",
    "import time\n",
    "import urllib.parse\n",
    "from email.message import EmailMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a969e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:13.873801Z",
     "iopub.status.busy": "2025-06-11T23:51:13.873401Z",
     "iopub.status.idle": "2025-06-11T23:51:15.016990Z",
     "shell.execute_reply": "2025-06-11T23:51:15.016042Z"
    },
    "papermill": {
     "duration": 1.153378,
     "end_time": "2025-06-11T23:51:15.019634",
     "exception": false,
     "start_time": "2025-06-11T23:51:13.866256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import github\n",
    "from github.GithubException import GithubException\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException,NoSuchElementException,StaleElementReferenceException,InvalidSelectorException,WebDriverException,InvalidArgumentException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335be0a9",
   "metadata": {
    "papermill": {
     "duration": 0.004969,
     "end_time": "2025-06-11T23:51:15.030341",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.025372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43bfaefd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.042712Z",
     "iopub.status.busy": "2025-06-11T23:51:15.042205Z",
     "iopub.status.idle": "2025-06-11T23:51:15.048300Z",
     "shell.execute_reply": "2025-06-11T23:51:15.046988Z"
    },
    "papermill": {
     "duration": 0.015117,
     "end_time": "2025-06-11T23:51:15.050660",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.035543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_driver_options(options):\n",
    "    chrome_options = Options()\n",
    "    for opt in options:\n",
    "        chrome_options.add_argument(opt)\n",
    "    return chrome_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818a32a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.063244Z",
     "iopub.status.busy": "2025-06-11T23:51:15.062706Z",
     "iopub.status.idle": "2025-06-11T23:51:15.069289Z",
     "shell.execute_reply": "2025-06-11T23:51:15.068254Z"
    },
    "papermill": {
     "duration": 0.015656,
     "end_time": "2025-06-11T23:51:15.071689",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.056033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_driver()->webdriver.Chrome:\n",
    "    driver_config = {\n",
    "        \"options\": [\n",
    "            \"--headless\",\n",
    "            \"--no-sandbox\",\n",
    "            \"--start-fullscreen\",\n",
    "            \"--allow-insecure-localhost\",\n",
    "            \"--disable-dev-shm-usage\",\n",
    "            \"user-agent=Chrome/116.0.5845.96\"\n",
    "        ],\n",
    "    }\n",
    "    CHROME_BINARY_LOCATION = \"/usr/bin/chrome-linux64/chrome\"\n",
    "    CHROMEDRIVER_BINARY_LOCATION = \"/usr/bin/chromedriver-linux64/chromedriver\"\n",
    "    options = add_driver_options(driver_config[\"options\"])\n",
    "    options.binary_location = CHROME_BINARY_LOCATION\n",
    "    driver = webdriver.Chrome(executable_path=CHROMEDRIVER_BINARY_LOCATION,options=options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8588f0",
   "metadata": {
    "papermill": {
     "duration": 0.005241,
     "end_time": "2025-06-11T23:51:15.082408",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.077167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d19ce6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.095096Z",
     "iopub.status.busy": "2025-06-11T23:51:15.094640Z",
     "iopub.status.idle": "2025-06-11T23:51:15.100362Z",
     "shell.execute_reply": "2025-06-11T23:51:15.099224Z"
    },
    "papermill": {
     "duration": 0.01491,
     "end_time": "2025-06-11T23:51:15.102687",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.087777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_driver_options(options):\n",
    "    chrome_options = Options()\n",
    "    for opt in options:\n",
    "        chrome_options.add_argument(opt)\n",
    "    return chrome_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7965fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.115609Z",
     "iopub.status.busy": "2025-06-11T23:51:15.114554Z",
     "iopub.status.idle": "2025-06-11T23:51:15.120923Z",
     "shell.execute_reply": "2025-06-11T23:51:15.119709Z"
    },
    "papermill": {
     "duration": 0.015247,
     "end_time": "2025-06-11T23:51:15.123240",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.107993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_repository()->github.Repository.Repository:\n",
    "    access_token = UserSecretsClient().get_secret('access_token')\n",
    "    repo_str = UserSecretsClient().get_secret('repo_str')\n",
    "    g = github.Github(access_token)\n",
    "    repo = g.get_repo(repo_str)\n",
    "    return repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1b3ff1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.135723Z",
     "iopub.status.busy": "2025-06-11T23:51:15.135336Z",
     "iopub.status.idle": "2025-06-11T23:51:15.141529Z",
     "shell.execute_reply": "2025-06-11T23:51:15.140321Z"
    },
    "papermill": {
     "duration": 0.015079,
     "end_time": "2025-06-11T23:51:15.143740",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.128661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_new_file(folder:str,branch:str='master')->str:\n",
    "    repo = get_repository()\n",
    "    contents = repo.get_contents(folder,ref=branch)\n",
    "    path = ''\n",
    "    for c in contents:\n",
    "        if path < c.path:\n",
    "            path = c.path\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e0232d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.156371Z",
     "iopub.status.busy": "2025-06-11T23:51:15.155898Z",
     "iopub.status.idle": "2025-06-11T23:51:15.163519Z",
     "shell.execute_reply": "2025-06-11T23:51:15.162315Z"
    },
    "papermill": {
     "duration": 0.016676,
     "end_time": "2025-06-11T23:51:15.165843",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.149167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_file_path(folder:str,path_type:str,branch:str='master')->str:\n",
    "    github_url = 'https://github.com'\n",
    "    repo_str = UserSecretsClient().get_secret('repo_str')\n",
    "    file_path = get_new_file(folder=folder,branch=branch)\n",
    "    file_url = github_url+'/'+repo_str+'/blob/'+branch+'/'+file_path\n",
    "    if path_type == 'url':\n",
    "        return file_url\n",
    "    elif path_type == 'raw':\n",
    "        return file_url.replace('github','raw.githubusercontent').replace('blob/','')\n",
    "    else:\n",
    "        raise Exception(\"path_type is either 'url' or 'raw'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "339f8a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.178843Z",
     "iopub.status.busy": "2025-06-11T23:51:15.178453Z",
     "iopub.status.idle": "2025-06-11T23:51:15.185105Z",
     "shell.execute_reply": "2025-06-11T23:51:15.183934Z"
    },
    "papermill": {
     "duration": 0.015828,
     "end_time": "2025-06-11T23:51:15.187370",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.171542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text_for_csv(text:str)->str:\n",
    "    if not isinstance(text,str):\n",
    "        return text\n",
    "    cleaned_text = urllib.parse.unquote(text)\n",
    "    cleaned_text = html.unescape(cleaned_text)\n",
    "    cleaned_text = cleaned_text.replace('\\\\','\\\\\\\\') \n",
    "    cleaned_text = cleaned_text.replace('\\n','\\\\n')\n",
    "    cleaned_text = cleaned_text.replace('\\t','\\\\t') \n",
    "    cleaned_text = cleaned_text.replace('\\r','\\\\r') \n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4059d5b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.200039Z",
     "iopub.status.busy": "2025-06-11T23:51:15.199639Z",
     "iopub.status.idle": "2025-06-11T23:51:15.209684Z",
     "shell.execute_reply": "2025-06-11T23:51:15.208769Z"
    },
    "papermill": {
     "duration": 0.019016,
     "end_time": "2025-06-11T23:51:15.211884",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.192868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_lst_as_csv(data:list[dict],folder:str,filename:str,branch:str='master'):\n",
    "    cleaned_data = [\n",
    "        {k: clean_text_for_csv(v) for k,v in row.items()} for row in data\n",
    "    ]\n",
    "    df = pd.DataFrame(cleaned_data)\n",
    "    repo = get_repository()\n",
    "    csv_content = df.to_csv(index=False)\n",
    "    file_pth = folder+'/'+filename\n",
    "    try:\n",
    "        repo.create_file(file_pth,\"create source file\",csv_content,branch=branch)\n",
    "        print(f\"{file_pth} created!\")\n",
    "    except:\n",
    "        file = repo.get_contents(file_pth,ref=branch)\n",
    "        full_raw_pth = get_file_path(folder=folder,path_type='raw',branch=branch)\n",
    "        existing_df = pd.read_csv(full_raw_pth)\n",
    "        updated_df = pd.concat([existing_df,df],ignore_index=True)\n",
    "        updated_csv_content = updated_df.to_csv(index=False)\n",
    "        repo.update_file(file_pth,'update source file',updated_csv_content,file.sha,branch=branch)\n",
    "        print(f\"{file_pth} updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024a46f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.225349Z",
     "iopub.status.busy": "2025-06-11T23:51:15.224518Z",
     "iopub.status.idle": "2025-06-11T23:51:15.230628Z",
     "shell.execute_reply": "2025-06-11T23:51:15.229547Z"
    },
    "papermill": {
     "duration": 0.014988,
     "end_time": "2025-06-11T23:51:15.232629",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.217641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def check_file_exists_in_folder(folder:str,filename:str,branch:str='master')->bool:\n",
    "    try:\n",
    "        repo = get_repository()\n",
    "        contents = repo.get_contents(folder,ref=branch)\n",
    "        for content_file in contents:\n",
    "            if content_file.name == filename:\n",
    "                return True\n",
    "        return False\n",
    "    except GithubException as e:\n",
    "        if e.status == 404:\n",
    "            return False\n",
    "        else:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffe7471",
   "metadata": {
    "papermill": {
     "duration": 0.005127,
     "end_time": "2025-06-11T23:51:15.243236",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.238109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2647ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.256287Z",
     "iopub.status.busy": "2025-06-11T23:51:15.255412Z",
     "iopub.status.idle": "2025-06-11T23:51:15.260823Z",
     "shell.execute_reply": "2025-06-11T23:51:15.259796Z"
    },
    "papermill": {
     "duration": 0.014224,
     "end_time": "2025-06-11T23:51:15.263026",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.248802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_days_filter_for_current_month():\n",
    "    today = datetime.datetime.today()\n",
    "    days_passed = today.day\n",
    "    available_days = [30,15,7,3,1]  \n",
    "    for days in available_days:\n",
    "        if days <= days_passed:\n",
    "            return str(days)\n",
    "    return \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cf24304",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.275660Z",
     "iopub.status.busy": "2025-06-11T23:51:15.275287Z",
     "iopub.status.idle": "2025-06-11T23:51:15.290489Z",
     "shell.execute_reply": "2025-06-11T23:51:15.289274Z"
    },
    "papermill": {
     "duration": 0.024273,
     "end_time": "2025-06-11T23:51:15.292827",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.268554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrapeNakuri(job_role:str,driver,is_full_load:bool):\n",
    "    job_lst = []\n",
    "    query = \"-\".join(job_role.lower().split())\n",
    "    base_url = f\"https://www.naukri.com/{query}-jobs?jobAge=1\"\n",
    "    if is_full_load:\n",
    "        base_url = f\"https://www.naukri.com/{query}-jobs?jobAge={get_days_filter_for_current_month()}\"\n",
    "    wait1,wait2 = WebDriverWait(driver,10),WebDriverWait(driver,30)\n",
    "    driver.get(base_url)\n",
    "    try:\n",
    "        xpth = \"/html/body/div/div/main/div[1]/div[1]/div[1]/div[@class='styles_nrc__heading__dLYOD']\"\n",
    "        wait1.until(EC.presence_of_all_elements_located((By.XPATH,xpth)))\n",
    "        no_results_text = driver.find_element(By.XPATH,xpth).text\n",
    "        print(f\"{no_results_text} for {job_role}!\")\n",
    "        return []\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        return []\n",
    "    job_links = []\n",
    "    page_count = 0\n",
    "    xpth1 = \"/html/body/div/div/main/div[1]/div[2]/\"\n",
    "    while page_count < 26:\n",
    "        wait2.until(EC.presence_of_all_elements_located((By.XPATH,f\"{xpth1}div[2]/div/div[@class='srp-jobtuple-wrapper']\")))\n",
    "        elements = driver.find_elements(By.XPATH,f\"{xpth1}div[2]/div/div[@class='srp-jobtuple-wrapper']\")\n",
    "        for div_element in elements:\n",
    "            link = div_element.find_element(By.CLASS_NAME,\"title \").get_attribute(\"href\")\n",
    "            job_links.append(link)\n",
    "        try:\n",
    "            next_page = wait2.until(EC.element_to_be_clickable((By.XPATH,f\"{xpth1}div[3]/div/a[2]\")))\n",
    "            next_url = next_page.get_attribute(\"href\")+\"?jobAge=1\"\n",
    "            driver.get(next_url)\n",
    "            page_count += 1\n",
    "        except:\n",
    "            break\n",
    "    job_links = job_links[:500]\n",
    "    xpth2 = \"/html/body/div/div/main/div[@class='styles_jdc__content__EZJMQ ']/div[1]/\"\n",
    "    for url in job_links:\n",
    "        try:  \n",
    "            driver.get(url)\n",
    "            driver.refresh()\n",
    "            wait2.until(EC.presence_of_element_located((By.XPATH,xpth2+\"section[1]/div[1]/div[1]/header/h1\")))\n",
    "            job_title = driver.find_element(By.XPATH,xpth2+\"section[1]/div[1]/div[1]/header/h1\").text\n",
    "            company = driver.find_element(By.XPATH,xpth2+\"section[1]/div[1]/div[1]/div/a\").text\n",
    "            experience = driver.find_element(By.XPATH,xpth2+\"section[1]/div[1]/div[2]/div[1]/div[1]/span\").text\n",
    "            salary = driver.find_element(By.XPATH,xpth2+\"section[1]/div[1]/div[2]/div[1]/div[2]/span\").text\n",
    "            locations = [loc.text for loc in driver.find_elements(By.XPATH,xpth2+\"section[1]/div[1]/div[2]/div[@class='styles_jhc__loc___Du2H']/span/a\")]\n",
    "            description = driver.find_element(By.XPATH,xpth2+\"section[2]/div[2]/div[@class='styles_JDC__dang-inner-html__h0K4t']\").text\n",
    "            industry = driver.find_element(By.XPATH,xpth2+\"section[2]/div[2]/div[2]/div[2]\").text\n",
    "            department = driver.find_element(By.XPATH,xpth2+\"section[2]/div[2]/div[2]/div[3]\").text\n",
    "            employment_type = driver.find_element(By.XPATH,xpth2+\"section[2]/div[2]/div[2]/div[4]\").text\n",
    "            skills = [skill.text for skill in driver.find_elements(By.XPATH,xpth2+\"section[2]/div[3]/div/a[@target='_blank']\")]\n",
    "            job_dict = {\n",
    "                'job_title': job_title,\n",
    "                'company': company,\n",
    "                'experience': experience,\n",
    "                'salary': salary,\n",
    "                'locations': locations,\n",
    "                'description': description,\n",
    "                'industry': industry,\n",
    "                'department': department,\n",
    "                'employment_type': employment_type,\n",
    "                'skills': skills,\n",
    "                'scraped_at': datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            job_lst.append(job_dict)\n",
    "        except:\n",
    "            pass\n",
    "    return job_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b9b7bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.306061Z",
     "iopub.status.busy": "2025-06-11T23:51:15.305650Z",
     "iopub.status.idle": "2025-06-11T23:51:15.318446Z",
     "shell.execute_reply": "2025-06-11T23:51:15.317461Z"
    },
    "papermill": {
     "duration": 0.02232,
     "end_time": "2025-06-11T23:51:15.320775",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.298455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scrapeFoundit(job_role:str,driver,is_full_load:bool):\n",
    "    query = \"+\".join(job_role.split())\n",
    "    base_url = f\"https://www.foundit.in/srp/results?query={query}&jobFreshness=1\"\n",
    "    if is_full_load:\n",
    "        base_url = f\"https://www.foundit.in/srp/results?query={query}&jobFreshness={get_days_filter_for_current_month()}\"\n",
    "    url = base_url.encode(\"ascii\",\"ignore\").decode(\"unicode_escape\")\n",
    "    wait = WebDriverWait(driver,30)\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        no_results_text = driver.find_element(By.XPATH,\"/html/body/div[3]/div/div[6]/div/div/div[2]/div[1]/div[2]/p[1]\").text\n",
    "        print(f\"{no_results_text} {job_role}!\")\n",
    "        return []\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        return []\n",
    "    job_list = []\n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            driver.refresh()\n",
    "            base_xpath = \"/html/body/div[@id='srpThemeDefault']/div[@class='srpContainer']/div[@id='srpContent']\"\n",
    "            card_container_xpath = f\"{base_xpath}/div[@class='srpCardContainer']/div[@class='srpResultCard']\"\n",
    "            wait.until(EC.presence_of_element_located((By.XPATH,card_container_xpath+\"/div[@class='srpCardsWrapper']\")))\n",
    "            job_cards = driver.find_elements(By.XPATH,card_container_xpath+\"/div[@class='srpCardsWrapper']\")\n",
    "            for card in job_cards:\n",
    "                card.click()\n",
    "                try:\n",
    "                    try:\n",
    "                        accept_cookies = driver.find_element(By.XPATH,'/html/body/div[5]/div/div/div[3]/button')\n",
    "                        accept_cookies.click()\n",
    "                    except:\n",
    "                        pass\n",
    "                    detail_xpath = f\"{base_xpath}/div[@class='srpJdContainer']\"\n",
    "                    detail_element = wait.until(EC.presence_of_element_located((By.XPATH,detail_xpath)))\n",
    "                    job_data = {}\n",
    "                    job_data['job_title'] = detail_element.find_element(By.CLASS_NAME,\"jdTitle\").text\n",
    "                    job_data['company_name'] = detail_element.find_element(By.CLASS_NAME,\"jdCompanyName\").text\n",
    "                    highlights = detail_element.find_elements(By.CLASS_NAME,\"highlightsRow\")\n",
    "                    job_data['experience'] = highlights[0].find_element(By.XPATH,\"./div[1]\").text\n",
    "                    try:\n",
    "                        job_data['salary'] = highlights[0].find_element(By.XPATH,\"./div[2]\").text\n",
    "                    except Exception:\n",
    "                        job_data['salary'] = None\n",
    "                    job_data['location'] = highlights[1].text\n",
    "                    job_data['industry'] = highlights[2].text\n",
    "                    job_data['job_description'] = detail_element.find_element(By.CLASS_NAME,\"jobDescInfoNew\").text\n",
    "                    job_data['skills'] = [skill.text for skill in detail_element.find_elements(By.CLASS_NAME,\"pillItem\")]\n",
    "                    job_data['scraped_at'] = datetime.datetime.now(pytz.timezone('Asia/Kolkata')).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                    job_list.append(job_data)\n",
    "                    count += 1\n",
    "                    if count == 500: \n",
    "                        return job_list\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "            pagination = driver.find_element(By.XPATH,card_container_xpath+\"/div[@class='pagination']\")\n",
    "            pagination.find_element(By.CLASS_NAME,\"mqfisrp-right-arrow\").click()\n",
    "        except Exception as e:\n",
    "            return job_list\n",
    "    return job_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8744df",
   "metadata": {
    "papermill": {
     "duration": 0.005112,
     "end_time": "2025-06-11T23:51:15.331436",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.326324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79395907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.344802Z",
     "iopub.status.busy": "2025-06-11T23:51:15.343707Z",
     "iopub.status.idle": "2025-06-11T23:51:15.349265Z",
     "shell.execute_reply": "2025-06-11T23:51:15.348153Z"
    },
    "papermill": {
     "duration": 0.01432,
     "end_time": "2025-06-11T23:51:15.351288",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.336968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4dbed40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:15.364729Z",
     "iopub.status.busy": "2025-06-11T23:51:15.363680Z",
     "iopub.status.idle": "2025-06-11T23:51:17.870857Z",
     "shell.execute_reply": "2025-06-11T23:51:17.869502Z"
    },
    "papermill": {
     "duration": 2.516727,
     "end_time": "2025-06-11T23:51:17.873628",
     "exception": false,
     "start_time": "2025-06-11T23:51:15.356901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_roles = [\n",
    "    \"Data Engineer\",\n",
    "    \"Data Analyst\",\n",
    "    \"Data Architect\",\n",
    "    \"Data Scientist\",\n",
    "    \"Machine Learning Engineer\"\n",
    "]\n",
    "branch = \"test\"\n",
    "yrmn_str = str(datetime.datetime.now(pytz.timezone('Asia/Kolkata')))[:7].replace(' ','-')\n",
    "csv_file_str = f\"{yrmn_str}.csv\"\n",
    "driver = get_driver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76459013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-11T23:51:17.886804Z",
     "iopub.status.busy": "2025-06-11T23:51:17.886392Z",
     "iopub.status.idle": "2025-06-12T01:14:54.839713Z",
     "shell.execute_reply": "2025-06-12T01:14:54.838012Z"
    },
    "papermill": {
     "duration": 5016.963469,
     "end_time": "2025-06-12T01:14:54.842971",
     "exception": false,
     "start_time": "2025-06-11T23:51:17.879502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Nakuri Started ---\n",
      "\n",
      "Job-role: Data Engineer\n",
      "Number of jobs extracted: 500\n",
      "Source/Nakuri/DataEngineer/2025-06.csv created!\n",
      "\n",
      "Job-role: Data Analyst\n",
      "Number of jobs extracted: 475\n",
      "Source/Nakuri/DataAnalyst/2025-06.csv created!\n",
      "\n",
      "Job-role: Data Architect\n",
      "Number of jobs extracted: 166\n",
      "Source/Nakuri/DataArchitect/2025-06.csv created!\n",
      "\n",
      "Job-role: Data Scientist\n",
      "Number of jobs extracted: 347\n",
      "Source/Nakuri/DataScientist/2025-06.csv created!\n",
      "\n",
      "Job-role: Machine Learning Engineer\n",
      "Number of jobs extracted: 350\n",
      "Source/Nakuri/MachineLearningEngineer/2025-06.csv created!\n",
      "\n",
      "\n",
      "--- Scraping Nakuri Ended ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Scraping Nakuri Started ---\\n\")\n",
    "driver = get_driver()\n",
    "for role in job_roles:\n",
    "    print(\"Job-role: \"+role)\n",
    "    folder = f\"Source/Nakuri/{role.replace(' ','')}\"\n",
    "    is_full_load = not check_file_exists_in_folder(folder=folder,filename=csv_file_str,branch=branch)\n",
    "    lst = scrapeNakuri(role,driver,is_full_load)\n",
    "    print(\"Number of jobs extracted: \"+str(len(lst)))\n",
    "    if lst:\n",
    "        save_lst_as_csv(data=lst,folder=folder,filename=csv_file_str,branch=branch)\n",
    "    print()\n",
    "print(\"\\n--- Scraping Nakuri Ended ---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4bdcc59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:14:54.860301Z",
     "iopub.status.busy": "2025-06-12T01:14:54.859090Z",
     "iopub.status.idle": "2025-06-12T01:21:14.382624Z",
     "shell.execute_reply": "2025-06-12T01:21:14.381400Z"
    },
    "papermill": {
     "duration": 379.536484,
     "end_time": "2025-06-12T01:21:14.386088",
     "exception": false,
     "start_time": "2025-06-12T01:14:54.849604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Scraping Foundit Started ---\n",
      "\n",
      "Job-role: Data Engineer\n",
      "Number of jobs extracted: 31\n",
      "Source/Foundit/DataEngineer/2025-06.csv created!\n",
      "\n",
      "Job-role: Data Analyst\n",
      "Number of jobs extracted: 30\n",
      "Source/Foundit/DataAnalyst/2025-06.csv created!\n",
      "\n",
      "Job-role: Data Architect\n",
      "Number of jobs extracted: 32\n",
      "Source/Foundit/DataArchitect/2025-06.csv created!\n",
      "\n",
      "Job-role: Data Scientist\n",
      "Number of jobs extracted: 51\n",
      "Source/Foundit/DataScientist/2025-06.csv created!\n",
      "\n",
      "Job-role: Machine Learning Engineer\n",
      "Number of jobs extracted: 8\n",
      "Source/Foundit/MachineLearningEngineer/2025-06.csv created!\n",
      "\n",
      "\n",
      "--- Scraping Foundit Ended ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Scraping Foundit Started ---\\n\")\n",
    "for role in job_roles:\n",
    "    print(\"Job-role: \"+role)\n",
    "    folder = f\"Source/Foundit/{role.replace(' ','')}\"\n",
    "    is_full_load = not check_file_exists_in_folder(folder=folder,filename=csv_file_str,branch=branch)\n",
    "    lst = scrapeFoundit(role,driver,is_full_load)\n",
    "    print(\"Number of jobs extracted: \"+str(len(lst)))\n",
    "    if lst:\n",
    "        save_lst_as_csv(data=lst,folder=folder,filename=csv_file_str,branch=branch)\n",
    "    print()\n",
    "print(\"\\n--- Scraping Foundit Ended ---\\n\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e52c374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:21:14.413099Z",
     "iopub.status.busy": "2025-06-12T01:21:14.412557Z",
     "iopub.status.idle": "2025-06-12T01:21:14.419349Z",
     "shell.execute_reply": "2025-06-12T01:21:14.418195Z"
    },
    "papermill": {
     "duration": 0.023232,
     "end_time": "2025-06-12T01:21:14.422588",
     "exception": false,
     "start_time": "2025-06-12T01:21:14.399356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "total_time_minutes = total_time / 60\n",
    "total_time_hours = total_time_minutes / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f1b246c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-12T01:21:14.451551Z",
     "iopub.status.busy": "2025-06-12T01:21:14.451067Z",
     "iopub.status.idle": "2025-06-12T01:21:14.459116Z",
     "shell.execute_reply": "2025-06-12T01:21:14.457866Z"
    },
    "papermill": {
     "duration": 0.023541,
     "end_time": "2025-06-12T01:21:14.461331",
     "exception": false,
     "start_time": "2025-06-12T01:21:14.437790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-taken: 5399.07 secs (or) 89.98 mins (or) 1.50 hrs.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Time-taken: {total_time:.2f} secs (or) {total_time_minutes:.2f} mins (or) {total_time_hours:.2f} hrs.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c351e",
   "metadata": {
    "papermill": {
     "duration": 0.006818,
     "end_time": "2025-06-12T01:21:14.475866",
     "exception": false,
     "start_time": "2025-06-12T01:21:14.469048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30553,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5485.384455,
   "end_time": "2025-06-12T01:21:15.218989",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-11T23:49:49.834534",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
